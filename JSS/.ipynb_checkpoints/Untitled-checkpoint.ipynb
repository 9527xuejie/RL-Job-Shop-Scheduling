{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have detected 80 CPUs here, so I'm going to create 79 actors\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import multiprocessing as mp\n",
    "import plotly.io as pio\n",
    "import ray\n",
    "from ray import tune\n",
    "\n",
    "from JSS.CustomCallbacks import CustomCallbacks\n",
    "from JSS.env.JSS import JSS\n",
    "from ray.rllib.agents.ppo import ppo, PPOTrainer\n",
    "\n",
    "from ray.tune.logger import DEFAULT_LOGGERS\n",
    "from ray.tune.integration.wandb import WandbLogger\n",
    "\n",
    "from JSS.env_wrapper import BestActionsWrapper\n",
    "\n",
    "from JSS.models import FCMaskedActionsModel\n",
    "\n",
    "pio.orca.config.use_xvfb = True\n",
    "import wandb\n",
    "\n",
    "'''\n",
    "            'lr': {\n",
    "                'values': [5e-5, 1e-5]\n",
    "            },\n",
    "            'lambda': {\n",
    "                'values': [0.90, 0.95, 1.0]\n",
    "            },\n",
    "            'clip_param': {\n",
    "                'values': [0.2, 0.3, 0.4]\n",
    "            },\n",
    "            'num_sgd_iter': {\n",
    "                'values': [30, 35, 40]\n",
    "            },\n",
    "            'entropy_coeff': {\n",
    "                'values': [0.0, 1e-4]\n",
    "            }\n",
    "'''\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"I have detected {} CPUs here, so I'm going to create {} actors\".format(mp.cpu_count(), mp.cpu_count() - 1))\n",
    "    os.environ[\"WANDB_API_KEY\"] = '3487a01956bf67cc7882bca2a38f70c8c95f8463'\n",
    "    sweep_config = {\n",
    "        'program': 'RandomGreedy.py',\n",
    "        'method': 'grid',\n",
    "        'metric': {\n",
    "            'name': 'time_step_min',\n",
    "            'goal': 'minimize',\n",
    "        },\n",
    "        'parameters': {\n",
    "            'instance_path': {\n",
    "                'values': ['/JSS/JSS/env/instances/ta51', '/JSS/JSS/env/instances/ta52', '/JSS/JSS/env/instances/ta53', '/JSS/JSS/env/instances/ta54',\n",
    "                           '/JSS/JSS/env/instances/ta55', '/JSS/JSS/env/instances/ta56', '/JSS/JSS/env/instances/ta57', '/JSS/JSS/env/instances/ta58',\n",
    "                           '/JSS/JSS/env/instances/ta59', '/JSS/JSS/env/instances/ta60']\n",
    "            }\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: u34ll0uk\n",
      "Sweep URL: https://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/u34ll0uk\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"RLLIB_SWEEP_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Starting wandb agent üïµÔ∏è\n",
      "2020-10-12 14:18:04,700 - wandb.wandb_agent - INFO - Running runs: []\n",
      "2020-10-12 14:18:05,135 - wandb.wandb_agent - INFO - Agent received command: run\n",
      "2020-10-12 14:18:05,136 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
      "\tinstance_path: /JSS/JSS/env/instances/ta51\n",
      "2020-10-12 14:18:05,137 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --instance_path=/JSS/JSS/env/instances/ta51\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "2020-10-12 14:18:10,153 - wandb.wandb_agent - INFO - Running runs: ['ghl8l9jj']\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mtrim-sweep-1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/u34ll0uk\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/ghl8l9jj\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201012_141806-ghl8l9jj\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
      "\n",
      "2020-10-12 14:18:10,755\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
      "== Status ==\n",
      "Memory usage on this node: 11.5/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+-------------------------+----------+-------+\n",
      "| Trial name              | status   | loc   |\n",
      "|-------------------------+----------+-------|\n",
      "| PPO_jss_env_c29f8_00000 | RUNNING  |       |\n",
      "+-------------------------+----------+-------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=70054)\u001b[0m 2020-10-12 14:18:13,502\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=70052)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70052)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70034)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70034)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70041)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70041)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70019)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70019)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70045)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70045)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70044)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70044)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70068)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70068)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70070)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70070)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70077)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70077)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70017)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70017)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70032)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70032)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70020)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70020)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70033)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70033)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70035)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70035)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70042)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70042)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70055)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70055)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70046)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70046)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70025)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70025)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70084)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70084)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70076)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70076)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70048)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70048)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70030)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70030)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=69979)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=69979)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=69958)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=69958)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=69945)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=69945)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70016)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70016)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70026)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70026)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70027)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70027)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70028)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70028)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=69959)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=69959)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=69962)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=69962)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70057)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70057)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=69946)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=69946)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=69963)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=69963)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=69987)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=69987)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70023)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70023)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=69953)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=69953)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=69950)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=69950)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70060)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70060)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70009)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70009)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=69981)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=69981)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=69965)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=69965)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=69986)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=69986)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=69947)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=69947)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70056)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70056)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70082)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70082)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70018)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70018)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70010)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70010)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=69972)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=69972)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=69968)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=69968)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=69984)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=69984)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=69966)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=69966)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=69967)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=69967)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70051)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70051)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=69956)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=69956)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=69949)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=69949)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70059)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70059)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70021)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70021)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70066)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70066)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70011)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70011)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70072)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70072)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=69955)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=69955)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70007)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70007)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70064)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70064)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=69975)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=69975)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=69961)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=69961)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=69951)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=69951)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70014)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70014)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70015)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70015)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70024)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70024)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=69954)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=69954)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=69960)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=69960)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70022)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70022)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=69973)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=69973)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=69978)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=69978)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70029)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70029)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=69948)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=69948)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70086)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70086)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70013)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70013)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "Result for PPO_jss_env_c29f8_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4054\n",
      "    time_step_mean: 3615.0923076923077\n",
      "    time_step_min: 3379\n",
      "  date: 2020-10-12_14-18-46\n",
      "  done: false\n",
      "  episode_len_mean: 891.1139240506329\n",
      "  episode_reward_max: 258.59595959595964\n",
      "  episode_reward_mean: 216.07678046285614\n",
      "  episode_reward_min: 145.7171717171716\n",
      "  episodes_this_iter: 158\n",
      "  episodes_total: 158\n",
      "  experiment_id: 824facd13c99490c857fa26d81a874e0\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.20000000000000004\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 1.1851047078768413\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.004071502441850801\n",
      "        model: {}\n",
      "        policy_loss: -0.00785889983914482\n",
      "        total_loss: 507.07567087809247\n",
      "        vf_explained_var: 0.540532648563385\n",
      "        vf_loss: 507.0832926432292\n",
      "    num_steps_sampled: 161792\n",
      "    num_steps_trained: 161792\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 172.17.0.4\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.659374999999997\n",
      "    gpu_util_percent0: 0.24875000000000003\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.0\n",
      "    ram_util_percent: 3.55625\n",
      "    vram_util_percent0: 0.08526873565103313\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.0\n",
      "  pid: 70054\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.16994892060296626\n",
      "    mean_env_wait_ms: 1.169091189632669\n",
      "    mean_inference_ms: 5.872200097004254\n",
      "    mean_raw_obs_processing_ms: 0.45335577092961277\n",
      "  time_since_restore: 27.71648859977722\n",
      "  time_this_iter_s: 27.71648859977722\n",
      "  time_total_s: 27.71648859977722\n",
      "  timers:\n",
      "    learn_throughput: 8874.446\n",
      "    learn_time_ms: 18231.223\n",
      "    sample_throughput: 17216.996\n",
      "    sample_time_ms: 9397.226\n",
      "    update_time_ms: 45.065\n",
      "  timestamp: 1602512326\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 161792\n",
      "  training_iteration: 1\n",
      "  trial_id: c29f8_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 27.6/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_c29f8_00000 | RUNNING  | 172.17.0.4:70054 |      1 |          27.7165 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_c29f8_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4054\n",
      "    time_step_mean: 3614.4305555555557\n",
      "    time_step_min: 3250\n",
      "  date: 2020-10-12_14-19-13\n",
      "  done: false\n",
      "  episode_len_mean: 890.8607594936709\n",
      "  episode_reward_max: 273.5959595959592\n",
      "  episode_reward_mean: 217.6365234624726\n",
      "  episode_reward_min: 145.7171717171716\n",
      "  episodes_this_iter: 158\n",
      "  episodes_total: 316\n",
      "  experiment_id: 824facd13c99490c857fa26d81a874e0\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.10000000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 1.1561074058214824\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.007923512797181806\n",
      "        model: {}\n",
      "        policy_loss: -0.010965243893830726\n",
      "        total_loss: 127.46906661987305\n",
      "        vf_explained_var: 0.8076093792915344\n",
      "        vf_loss: 127.47981770833333\n",
      "    num_steps_sampled: 323584\n",
      "    num_steps_trained: 323584\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 172.17.0.4\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 25.34193548387097\n",
      "    gpu_util_percent0: 0.3187096774193548\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.0\n",
      "    ram_util_percent: 3.748387096774193\n",
      "    vram_util_percent0: 0.10437848474909812\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.0\n",
      "  pid: 70054\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.16561765606620044\n",
      "    mean_env_wait_ms: 1.165680428994888\n",
      "    mean_inference_ms: 5.6226371336530185\n",
      "    mean_raw_obs_processing_ms: 0.4413906555255206\n",
      "  time_since_restore: 54.19657015800476\n",
      "  time_this_iter_s: 26.48008155822754\n",
      "  time_total_s: 54.19657015800476\n",
      "  timers:\n",
      "    learn_throughput: 8799.877\n",
      "    learn_time_ms: 18385.711\n",
      "    sample_throughput: 18754.589\n",
      "    sample_time_ms: 8626.795\n",
      "    update_time_ms: 41.168\n",
      "  timestamp: 1602512353\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 323584\n",
      "  training_iteration: 2\n",
      "  trial_id: c29f8_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 28.1/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_c29f8_00000 | RUNNING  | 172.17.0.4:70054 |      2 |          54.1966 | 323584 |  217.637 |              273.596 |              145.717 |            890.861 |\n",
      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_c29f8_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4054\n",
      "    time_step_mean: 3601.8677130044844\n",
      "    time_step_min: 3250\n",
      "  date: 2020-10-12_14-19-39\n",
      "  done: false\n",
      "  episode_len_mean: 885.132911392405\n",
      "  episode_reward_max: 273.5959595959592\n",
      "  episode_reward_mean: 219.87009333844756\n",
      "  episode_reward_min: 145.7171717171716\n",
      "  episodes_this_iter: 158\n",
      "  episodes_total: 474\n",
      "  experiment_id: 824facd13c99490c857fa26d81a874e0\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.10000000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 1.1456398169199626\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.008224547879459957\n",
      "        model: {}\n",
      "        policy_loss: -0.013529085864623388\n",
      "        total_loss: 61.275455474853516\n",
      "        vf_explained_var: 0.8916645646095276\n",
      "        vf_loss: 61.28873507181803\n",
      "    num_steps_sampled: 485376\n",
      "    num_steps_trained: 485376\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 172.17.0.4\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.036666666666665\n",
      "    gpu_util_percent0: 0.4583333333333333\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.0\n",
      "    ram_util_percent: 3.766666666666666\n",
      "    vram_util_percent0: 0.10437848474909811\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.0\n",
      "  pid: 70054\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.16292763164001656\n",
      "    mean_env_wait_ms: 1.1660419208572714\n",
      "    mean_inference_ms: 5.433839896911039\n",
      "    mean_raw_obs_processing_ms: 0.4330986534385022\n",
      "  time_since_restore: 80.38152575492859\n",
      "  time_this_iter_s: 26.184955596923828\n",
      "  time_total_s: 80.38152575492859\n",
      "  timers:\n",
      "    learn_throughput: 8760.554\n",
      "    learn_time_ms: 18468.239\n",
      "    sample_throughput: 19699.668\n",
      "    sample_time_ms: 8212.93\n",
      "    update_time_ms: 40.926\n",
      "  timestamp: 1602512379\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 485376\n",
      "  training_iteration: 3\n",
      "  trial_id: c29f8_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 28.0/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_c29f8_00000 | RUNNING  | 172.17.0.4:70054 |      3 |          80.3815 | 485376 |   219.87 |              273.596 |              145.717 |            885.133 |\n",
      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_c29f8_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4054\n",
      "    time_step_mean: 3596.0099337748343\n",
      "    time_step_min: 3231\n",
      "  date: 2020-10-12_14-20-04\n",
      "  done: false\n",
      "  episode_len_mean: 878.7689873417721\n",
      "  episode_reward_max: 276.47474747474763\n",
      "  episode_reward_mean: 220.6047340493541\n",
      "  episode_reward_min: 145.7171717171716\n",
      "  episodes_this_iter: 158\n",
      "  episodes_total: 632\n",
      "  experiment_id: 824facd13c99490c857fa26d81a874e0\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.10000000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 1.1263898611068726\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.008100568510902425\n",
      "        model: {}\n",
      "        policy_loss: -0.013406771836647144\n",
      "        total_loss: 47.16934140523275\n",
      "        vf_explained_var: 0.9198758602142334\n",
      "        vf_loss: 47.18250052134196\n",
      "    num_steps_sampled: 647168\n",
      "    num_steps_trained: 647168\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 172.17.0.4\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 25.53103448275862\n",
      "    gpu_util_percent0: 0.2900000000000001\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.0\n",
      "    ram_util_percent: 3.768965517241379\n",
      "    vram_util_percent0: 0.10437848474909811\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.0\n",
      "  pid: 70054\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.16094661920745734\n",
      "    mean_env_wait_ms: 1.167455903288604\n",
      "    mean_inference_ms: 5.2910087094709635\n",
      "    mean_raw_obs_processing_ms: 0.42653092723086955\n",
      "  time_since_restore: 105.78936982154846\n",
      "  time_this_iter_s: 25.407844066619873\n",
      "  time_total_s: 105.78936982154846\n",
      "  timers:\n",
      "    learn_throughput: 8772.696\n",
      "    learn_time_ms: 18442.677\n",
      "    sample_throughput: 20485.045\n",
      "    sample_time_ms: 7898.054\n",
      "    update_time_ms: 40.294\n",
      "  timestamp: 1602512404\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 647168\n",
      "  training_iteration: 4\n",
      "  trial_id: c29f8_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 28.2/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_c29f8_00000 | RUNNING  | 172.17.0.4:70054 |      4 |          105.789 | 647168 |  220.605 |              276.475 |              145.717 |            878.769 |\n",
      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_c29f8_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4054\n",
      "    time_step_mean: 3581.6985583224114\n",
      "    time_step_min: 3204\n",
      "  date: 2020-10-12_14-20-30\n",
      "  done: false\n",
      "  episode_len_mean: 872.4867256637168\n",
      "  episode_reward_max: 280.5656565656565\n",
      "  episode_reward_mean: 222.48133675567283\n",
      "  episode_reward_min: 145.7171717171716\n",
      "  episodes_this_iter: 159\n",
      "  episodes_total: 791\n",
      "  experiment_id: 824facd13c99490c857fa26d81a874e0\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.10000000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 1.0873714486757915\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.006956188706681132\n",
      "        model: {}\n",
      "        policy_loss: -0.011262792395427823\n",
      "        total_loss: 34.19948164621989\n",
      "        vf_explained_var: 0.9459590911865234\n",
      "        vf_loss: 34.2105925877889\n",
      "    num_steps_sampled: 808960\n",
      "    num_steps_trained: 808960\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 172.17.0.4\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.066666666666663\n",
      "    gpu_util_percent0: 0.43766666666666665\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.0\n",
      "    ram_util_percent: 3.7666666666666657\n",
      "    vram_util_percent0: 0.10437848474909811\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.0\n",
      "  pid: 70054\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.15940651242537818\n",
      "    mean_env_wait_ms: 1.169971635752512\n",
      "    mean_inference_ms: 5.180106083655211\n",
      "    mean_raw_obs_processing_ms: 0.4212780660858121\n",
      "  time_since_restore: 131.2926995754242\n",
      "  time_this_iter_s: 25.503329753875732\n",
      "  time_total_s: 131.2926995754242\n",
      "  timers:\n",
      "    learn_throughput: 8760.483\n",
      "    learn_time_ms: 18468.388\n",
      "    sample_throughput: 21079.592\n",
      "    sample_time_ms: 7675.291\n",
      "    update_time_ms: 36.471\n",
      "  timestamp: 1602512430\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 808960\n",
      "  training_iteration: 5\n",
      "  trial_id: c29f8_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 28.2/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_c29f8_00000 | RUNNING  | 172.17.0.4:70054 |      5 |          131.293 | 808960 |  222.481 |              280.566 |              145.717 |            872.487 |\n",
      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_c29f8_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4054\n",
      "    time_step_mean: 3564.887755102041\n",
      "    time_step_min: 3204\n",
      "  date: 2020-10-12_14-20-56\n",
      "  done: false\n",
      "  episode_len_mean: 860.6943942133815\n",
      "  episode_reward_max: 280.5656565656565\n",
      "  episode_reward_mean: 225.7112809834327\n",
      "  episode_reward_min: 145.7171717171716\n",
      "  episodes_this_iter: 315\n",
      "  episodes_total: 1106\n",
      "  experiment_id: 824facd13c99490c857fa26d81a874e0\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.10000000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 1.0886386533578236\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.007588425030310948\n",
      "        model: {}\n",
      "        policy_loss: -0.01092883839737624\n",
      "        total_loss: 30.730765342712402\n",
      "        vf_explained_var: 0.9611188769340515\n",
      "        vf_loss: 30.741480032602947\n",
      "    num_steps_sampled: 970752\n",
      "    num_steps_trained: 970752\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 172.17.0.4\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 25.18965517241379\n",
      "    gpu_util_percent0: 0.2837931034482758\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.0\n",
      "    ram_util_percent: 3.7620689655172406\n",
      "    vram_util_percent0: 0.10437848474909811\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.0\n",
      "  pid: 70054\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.15734562235197594\n",
      "    mean_env_wait_ms: 1.1756497799942263\n",
      "    mean_inference_ms: 5.0326967604555675\n",
      "    mean_raw_obs_processing_ms: 0.41464838863890185\n",
      "  time_since_restore: 156.71548414230347\n",
      "  time_this_iter_s: 25.422784566879272\n",
      "  time_total_s: 156.71548414230347\n",
      "  timers:\n",
      "    learn_throughput: 8759.305\n",
      "    learn_time_ms: 18470.871\n",
      "    sample_throughput: 21462.045\n",
      "    sample_time_ms: 7538.517\n",
      "    update_time_ms: 36.673\n",
      "  timestamp: 1602512456\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 970752\n",
      "  training_iteration: 6\n",
      "  trial_id: c29f8_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 28.2/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_c29f8_00000 | RUNNING  | 172.17.0.4:70054 |      6 |          156.715 | 970752 |  225.711 |              280.566 |              145.717 |            860.694 |\n",
      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_c29f8_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4054\n",
      "    time_step_mean: 3552.704692556634\n",
      "    time_step_min: 3179\n",
      "  date: 2020-10-12_14-21-21\n",
      "  done: false\n",
      "  episode_len_mean: 855.0387658227849\n",
      "  episode_reward_max: 284.35353535353545\n",
      "  episode_reward_mean: 227.46978487405684\n",
      "  episode_reward_min: 145.7171717171716\n",
      "  episodes_this_iter: 158\n",
      "  episodes_total: 1264\n",
      "  experiment_id: 824facd13c99490c857fa26d81a874e0\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.10000000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 1.0706470410029094\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.007387861027382314\n",
      "        model: {}\n",
      "        policy_loss: -0.013462736414415607\n",
      "        total_loss: 19.742233912150066\n",
      "        vf_explained_var: 0.9632093906402588\n",
      "        vf_loss: 19.75549300511678\n",
      "    num_steps_sampled: 1132544\n",
      "    num_steps_trained: 1132544\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 172.17.0.4\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 25.182758620689658\n",
      "    gpu_util_percent0: 0.30241379310344835\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.0\n",
      "    ram_util_percent: 3.775862068965517\n",
      "    vram_util_percent0: 0.10437848474909811\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.0\n",
      "  pid: 70054\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.15659944710447274\n",
      "    mean_env_wait_ms: 1.1781296386862312\n",
      "    mean_inference_ms: 4.979102261022608\n",
      "    mean_raw_obs_processing_ms: 0.41223103840983283\n",
      "  time_since_restore: 182.10720825195312\n",
      "  time_this_iter_s: 25.391724109649658\n",
      "  time_total_s: 182.10720825195312\n",
      "  timers:\n",
      "    learn_throughput: 8762.399\n",
      "    learn_time_ms: 18464.35\n",
      "    sample_throughput: 21732.82\n",
      "    sample_time_ms: 7444.593\n",
      "    update_time_ms: 36.744\n",
      "  timestamp: 1602512481\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1132544\n",
      "  training_iteration: 7\n",
      "  trial_id: c29f8_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 28.1/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_c29f8_00000 | RUNNING  | 172.17.0.4:70054 |      7 |          182.107 | 1132544 |   227.47 |              284.354 |              145.717 |            855.039 |\n",
      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wandb agent u34ll0uk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
