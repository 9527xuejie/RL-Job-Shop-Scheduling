{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have detected 80 CPUs here, so I'm going to create 79 actors\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import multiprocessing as mp\n",
    "import plotly.io as pio\n",
    "import ray\n",
    "from ray import tune\n",
    "\n",
    "from JSS.CustomCallbacks import CustomCallbacks\n",
    "from JSS.env.JSS import JSS\n",
    "from ray.rllib.agents.ppo import ppo, PPOTrainer\n",
    "\n",
    "from ray.tune.logger import DEFAULT_LOGGERS\n",
    "from ray.tune.integration.wandb import WandbLogger\n",
    "\n",
    "from JSS.env_wrapper import BestActionsWrapper\n",
    "\n",
    "from JSS.models import FCMaskedActionsModel\n",
    "\n",
    "pio.orca.config.use_xvfb = True\n",
    "import wandb\n",
    "import torch\n",
    "\n",
    "'''\n",
    "            'lr': {\n",
    "                'values': [5e-5, 1e-5]\n",
    "            },\n",
    "            'lambda': {\n",
    "                'values': [0.90, 0.95, 1.0]\n",
    "            },\n",
    "            'clip_param': {\n",
    "                'values': [0.2, 0.3, 0.4]\n",
    "            },\n",
    "            'num_sgd_iter': {\n",
    "                'values': [30, 35, 40]\n",
    "            },\n",
    "            'entropy_coeff': {\n",
    "                'values': [0.0, 1e-4]\n",
    "            }\n",
    "'''\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"I have detected {} CPUs here, so I'm going to create {} actors\".format(mp.cpu_count(), mp.cpu_count() - 1))\n",
    "    os.environ[\"WANDB_API_KEY\"] = '3487a01956bf67cc7882bca2a38f70c8c95f8463'\n",
    "    sweep_config = {\n",
    "        'program': 'train.py',\n",
    "        'method': 'grid',\n",
    "        'metric': {\n",
    "            'name': 'time_step_min',\n",
    "            'goal': 'minimize',\n",
    "        },\n",
    "        'parameters': {\n",
    "            'instance_path': {\n",
    "                'values': ['/JSS/JSS/env/instances/ta51', '/JSS/JSS/env/instances/ta52', '/JSS/JSS/env/instances/ta53', '/JSS/JSS/env/instances/ta54', '/JSS/JSS/env/instances/ta55',\n",
    "                           '/JSS/JSS/env/instances/ta56', '/JSS/JSS/env/instances/ta57', '/JSS/JSS/env/instances/ta58', '/JSS/JSS/env/instances/ta59',\n",
    "                           '/JSS/JSS/env/instances/ta60']\n",
    "            }\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 2rk3apl0\n",
      "Sweep URL: https://wandb.ai/ingambe/RLLIB_SWEEP_4/sweeps/2rk3apl0\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"RLLIB_SWEEP_4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Starting wandb agent üïµÔ∏è\n",
      "2020-11-13 15:44:42,612 - wandb.wandb_agent - INFO - Running runs: []\n",
      "2020-11-13 15:44:42,954 - wandb.wandb_agent - INFO - Agent received command: run\n",
      "2020-11-13 15:44:42,954 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
      "\tinstance_path: /JSS/JSS/env/instances/ta51\n",
      "2020-11-13 15:44:42,956 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --instance_path=/JSS/JSS/env/instances/ta51\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mrural-sweep-1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_4/sweeps/2rk3apl0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_4/runs/tdepb25x\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /JSS/JSS/wandb/run-20201113_154444-tdepb25x\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
      "\n",
      "2020-11-13 15:44:47,971 - wandb.wandb_agent - INFO - Running runs: ['tdepb25x']\n",
      "2020-11-13 15:44:48,035\tINFO services.py:1090 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
      "== Status ==\n",
      "Memory usage on this node: 17.0/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------+\n",
      "| Trial name              | status   | loc   |\n",
      "|-------------------------+----------+-------|\n",
      "| PPO_jss_env_c897a_00000 | RUNNING  |       |\n",
      "+-------------------------+----------+-------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=44156)\u001b[0m 2020-11-13 15:44:51,979\tINFO trainer.py:617 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=44113)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44113)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44109)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44109)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44153)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44153)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44141)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44141)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44143)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44143)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44154)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44154)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44138)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44138)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44151)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44151)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44119)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44119)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44121)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44121)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44122)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44122)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44115)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44115)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44097)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44097)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44094)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44094)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44132)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44132)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44127)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44127)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44150)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44150)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44062)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44062)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44148)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44148)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44077)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44077)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44081)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44081)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44130)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44130)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44056)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44056)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44069)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44069)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44075)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44075)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44070)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44070)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44078)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44078)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44100)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44100)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44125)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44125)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44096)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44096)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44145)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44145)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44092)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44092)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44082)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44082)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44133)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44133)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44098)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44098)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44101)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44101)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44064)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44064)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44089)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44089)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44103)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44103)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44021)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44021)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44074)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44074)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44025)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44025)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44039)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44039)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44031)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44031)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44059)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44059)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44093)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44093)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44076)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44076)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44036)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44036)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44104)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44104)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44026)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44026)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44023)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44023)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44040)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44040)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44024)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44024)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44086)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44086)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44080)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44080)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44057)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44057)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44022)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44022)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44019)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44019)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44032)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44032)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44030)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44030)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44027)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44027)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44068)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44068)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44123)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44123)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44066)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44066)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44043)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44043)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44083)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44083)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44088)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44088)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44038)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44038)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44051)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44051)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44079)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44079)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44071)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44071)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44018)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44018)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44085)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44085)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44020)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44020)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44033)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44033)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44054)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44054)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44029)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44029)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44034)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44034)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=44028)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=44028)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "Result for PPO_jss_env_c897a_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4054\n",
      "    time_step_mean: 3615.0923076923077\n",
      "    time_step_min: 3379\n",
      "  date: 2020-11-13_15-45-28\n",
      "  done: false\n",
      "  episode_len_mean: 891.1139240506329\n",
      "  episode_reward_max: 258.59595959595964\n",
      "  episode_reward_mean: 216.07678046285614\n",
      "  episode_reward_min: 145.7171717171716\n",
      "  episodes_this_iter: 158\n",
      "  episodes_total: 158\n",
      "  experiment_id: 5612dbec6380475ba519f8b5cbafbcdd\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.20000000000000004\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 1.18510103225708\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.004075655674872299\n",
      "        model: {}\n",
      "        policy_loss: -0.007856482533194745\n",
      "        total_loss: 507.0764414469401\n",
      "        vf_explained_var: 0.5405313372612\n",
      "        vf_loss: 507.0840657552083\n",
      "    num_steps_sampled: 161792\n",
      "    num_steps_trained: 161792\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 31.305555555555557\n",
      "    gpu_util_percent0: 0.3430555555555556\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.8933333333333332\n",
      "    ram_util_percent: 4.297222222222223\n",
      "    vram_util_percent0: 0.087401151561532\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.9949178691351303\n",
      "  pid: 44156\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.16951353103152472\n",
      "    mean_env_wait_ms: 1.1785322061546353\n",
      "    mean_inference_ms: 6.575505676811292\n",
      "    mean_raw_obs_processing_ms: 0.4761212340988248\n",
      "  time_since_restore: 29.26448655128479\n",
      "  time_this_iter_s: 29.26448655128479\n",
      "  time_total_s: 29.26448655128479\n",
      "  timers:\n",
      "    learn_throughput: 8701.189\n",
      "    learn_time_ms: 18594.241\n",
      "    sample_throughput: 15316.621\n",
      "    sample_time_ms: 10563.165\n",
      "    update_time_ms: 22.687\n",
      "  timestamp: 1605278728\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 161792\n",
      "  training_iteration: 1\n",
      "  trial_id: c897a_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 33.4/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_c897a_00000 | RUNNING  | 172.17.0.14:44156 |      1 |          29.2645 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
      "+-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_c897a_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4139\n",
      "    time_step_mean: 3610.4270833333335\n",
      "    time_step_min: 3250\n",
      "  date: 2020-11-13_15-45-55\n",
      "  done: false\n",
      "  episode_len_mean: 891.1518987341772\n",
      "  episode_reward_max: 273.5959595959592\n",
      "  episode_reward_mean: 217.01799641989493\n",
      "  episode_reward_min: 138.89898989898958\n",
      "  episodes_this_iter: 158\n",
      "  episodes_total: 316\n",
      "  experiment_id: 5612dbec6380475ba519f8b5cbafbcdd\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.10000000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 1.1560785472393036\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.007777089563508828\n",
      "        model: {}\n",
      "        policy_loss: -0.010900724065625885\n",
      "        total_loss: 130.1934757232666\n",
      "        vf_explained_var: 0.804860532283783\n",
      "        vf_loss: 130.20417594909668\n",
      "    num_steps_sampled: 323584\n",
      "    num_steps_trained: 323584\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.884375\n",
      "    gpu_util_percent0: 0.2953125\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.899375\n",
      "    ram_util_percent: 4.5406249999999995\n",
      "    vram_util_percent0: 0.10749426041325025\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.9949178691351303\n",
      "  pid: 44156\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1656061677009799\n",
      "    mean_env_wait_ms: 1.171555727676357\n",
      "    mean_inference_ms: 6.138062299104497\n",
      "    mean_raw_obs_processing_ms: 0.4604037368121517\n",
      "  time_since_restore: 55.92251420021057\n",
      "  time_this_iter_s: 26.65802764892578\n",
      "  time_total_s: 55.92251420021057\n",
      "  timers:\n",
      "    learn_throughput: 8727.425\n",
      "    learn_time_ms: 18538.343\n",
      "    sample_throughput: 17335.473\n",
      "    sample_time_ms: 9333.002\n",
      "    update_time_ms: 23.311\n",
      "  timestamp: 1605278755\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 323584\n",
      "  training_iteration: 2\n",
      "  trial_id: c897a_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 34.0/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_c897a_00000 | RUNNING  | 172.17.0.14:44156 |      2 |          55.9225 | 323584 |  217.018 |              273.596 |              138.899 |            891.152 |\n",
      "+-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_c897a_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4139\n",
      "    time_step_mean: 3608.6502242152465\n",
      "    time_step_min: 3250\n",
      "  date: 2020-11-13_15-46-21\n",
      "  done: false\n",
      "  episode_len_mean: 885.7721518987341\n",
      "  episode_reward_max: 273.5959595959592\n",
      "  episode_reward_mean: 218.33320547244574\n",
      "  episode_reward_min: 138.89898989898958\n",
      "  episodes_this_iter: 158\n",
      "  episodes_total: 474\n",
      "  experiment_id: 5612dbec6380475ba519f8b5cbafbcdd\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.10000000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 1.1430676678816478\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.009299060601430634\n",
      "        model: {}\n",
      "        policy_loss: -0.012110602440467725\n",
      "        total_loss: 62.27398872375488\n",
      "        vf_explained_var: 0.891941487789154\n",
      "        vf_loss: 62.285740534464516\n",
      "    num_steps_sampled: 485376\n",
      "    num_steps_trained: 485376\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 27.275\n",
      "    gpu_util_percent0: 0.35843749999999996\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.7421875\n",
      "    ram_util_percent: 4.5625\n",
      "    vram_util_percent0: 0.10749426041325025\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.9949178691351303\n",
      "  pid: 44156\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.16344628290291857\n",
      "    mean_env_wait_ms: 1.1697627890334574\n",
      "    mean_inference_ms: 5.86210697758658\n",
      "    mean_raw_obs_processing_ms: 0.4502896430399709\n",
      "  time_since_restore: 82.00250744819641\n",
      "  time_this_iter_s: 26.07999324798584\n",
      "  time_total_s: 82.00250744819641\n",
      "  timers:\n",
      "    learn_throughput: 8733.695\n",
      "    learn_time_ms: 18525.035\n",
      "    sample_throughput: 18544.433\n",
      "    sample_time_ms: 8724.559\n",
      "    update_time_ms: 23.118\n",
      "  timestamp: 1605278781\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 485376\n",
      "  training_iteration: 3\n",
      "  trial_id: c897a_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 33.9/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_c897a_00000 | RUNNING  | 172.17.0.14:44156 |      3 |          82.0025 | 485376 |  218.333 |              273.596 |              138.899 |            885.772 |\n",
      "+-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_c897a_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4139\n",
      "    time_step_mean: 3605.1456953642382\n",
      "    time_step_min: 3250\n",
      "  date: 2020-11-13_15-46-47\n",
      "  done: false\n",
      "  episode_len_mean: 882.6962025316456\n",
      "  episode_reward_max: 273.5959595959592\n",
      "  episode_reward_mean: 219.41011379618956\n",
      "  episode_reward_min: 138.89898989898958\n",
      "  episodes_this_iter: 158\n",
      "  episodes_total: 632\n",
      "  experiment_id: 5612dbec6380475ba519f8b5cbafbcdd\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.10000000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 1.1274765332539876\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.007994393236003816\n",
      "        model: {}\n",
      "        policy_loss: -0.013344118488021195\n",
      "        total_loss: 47.00141525268555\n",
      "        vf_explained_var: 0.9183452129364014\n",
      "        vf_loss: 47.014522552490234\n",
      "    num_steps_sampled: 647168\n",
      "    num_steps_trained: 647168\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 27.271875\n",
      "    gpu_util_percent0: 0.3684375\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.900625\n",
      "    ram_util_percent: 4.55625\n",
      "    vram_util_percent0: 0.10749426041325025\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.9949178691351303\n",
      "  pid: 44156\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.16190575985713307\n",
      "    mean_env_wait_ms: 1.168902568876956\n",
      "    mean_inference_ms: 5.67313112826204\n",
      "    mean_raw_obs_processing_ms: 0.44307479154447116\n",
      "  time_since_restore: 108.27025032043457\n",
      "  time_this_iter_s: 26.26774287223816\n",
      "  time_total_s: 108.27025032043457\n",
      "  timers:\n",
      "    learn_throughput: 8731.183\n",
      "    learn_time_ms: 18530.365\n",
      "    sample_throughput: 19134.845\n",
      "    sample_time_ms: 8455.36\n",
      "    update_time_ms: 23.099\n",
      "  timestamp: 1605278807\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 647168\n",
      "  training_iteration: 4\n",
      "  trial_id: c897a_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 34.0/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_c897a_00000 | RUNNING  | 172.17.0.14:44156 |      4 |           108.27 | 647168 |   219.41 |              273.596 |              138.899 |            882.696 |\n",
      "+-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_c897a_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4139\n",
      "    time_step_mean: 3592.522309711286\n",
      "    time_step_min: 3227\n",
      "  date: 2020-11-13_15-47-14\n",
      "  done: false\n",
      "  episode_len_mean: 879.5113924050632\n",
      "  episode_reward_max: 277.08080808080774\n",
      "  episode_reward_mean: 221.4287175552996\n",
      "  episode_reward_min: 138.89898989898958\n",
      "  episodes_this_iter: 158\n",
      "  episodes_total: 790\n",
      "  experiment_id: 5612dbec6380475ba519f8b5cbafbcdd\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.10000000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 1.0952738622824352\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.007509567774832249\n",
      "        model: {}\n",
      "        policy_loss: -0.014093573903664947\n",
      "        total_loss: 34.00634447733561\n",
      "        vf_explained_var: 0.941519558429718\n",
      "        vf_loss: 34.02023537953695\n",
      "    num_steps_sampled: 808960\n",
      "    num_steps_trained: 808960\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.75625\n",
      "    gpu_util_percent0: 0.36312500000000003\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.9003125000000001\n",
      "    ram_util_percent: 4.55625\n",
      "    vram_util_percent0: 0.10749426041325025\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.9949178691351303\n",
      "  pid: 44156\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.16070723758751132\n",
      "    mean_env_wait_ms: 1.1689393772733163\n",
      "    mean_inference_ms: 5.5350602790067756\n",
      "    mean_raw_obs_processing_ms: 0.43731158157843913\n",
      "  time_since_restore: 134.65218043327332\n",
      "  time_this_iter_s: 26.381930112838745\n",
      "  time_total_s: 134.65218043327332\n",
      "  timers:\n",
      "    learn_throughput: 8744.923\n",
      "    learn_time_ms: 18501.249\n",
      "    sample_throughput: 19378.11\n",
      "    sample_time_ms: 8349.215\n",
      "    update_time_ms: 23.344\n",
      "  timestamp: 1605278834\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 808960\n",
      "  training_iteration: 5\n",
      "  trial_id: c897a_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 34.1/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_c897a_00000 | RUNNING  | 172.17.0.14:44156 |      5 |          134.652 | 808960 |  221.429 |              277.081 |              138.899 |            879.511 |\n",
      "+-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_c897a_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4139\n",
      "    time_step_mean: 3572.0923656927425\n",
      "    time_step_min: 3198\n",
      "  date: 2020-11-13_15-47-40\n",
      "  done: false\n",
      "  episode_len_mean: 870.8677685950413\n",
      "  episode_reward_max: 281.4747474747472\n",
      "  episode_reward_mean: 224.96530038678782\n",
      "  episode_reward_min: 138.89898989898958\n",
      "  episodes_this_iter: 299\n",
      "  episodes_total: 1089\n",
      "  experiment_id: 5612dbec6380475ba519f8b5cbafbcdd\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.10000000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 1.08013117313385\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.007601154929337402\n",
      "        model: {}\n",
      "        policy_loss: -0.01200175506528467\n",
      "        total_loss: 30.201109727223713\n",
      "        vf_explained_var: 0.9620200991630554\n",
      "        vf_loss: 30.212891737620037\n",
      "    num_steps_sampled: 970752\n",
      "    num_steps_trained: 970752\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 27.71290322580645\n",
      "    gpu_util_percent0: 0.342258064516129\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.9012903225806452\n",
      "    ram_util_percent: 4.551612903225806\n",
      "    vram_util_percent0: 0.10749426041325019\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.99491786913513\n",
      "  pid: 44156\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1591912259062767\n",
      "    mean_env_wait_ms: 1.1714102234848216\n",
      "    mean_inference_ms: 5.359115156847671\n",
      "    mean_raw_obs_processing_ms: 0.42980892006654126\n",
      "  time_since_restore: 160.7242467403412\n",
      "  time_this_iter_s: 26.07206630706787\n",
      "  time_total_s: 160.7242467403412\n",
      "  timers:\n",
      "    learn_throughput: 8751.988\n",
      "    learn_time_ms: 18486.314\n",
      "    sample_throughput: 19677.932\n",
      "    sample_time_ms: 8222.002\n",
      "    update_time_ms: 23.836\n",
      "  timestamp: 1605278860\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 970752\n",
      "  training_iteration: 6\n",
      "  trial_id: c897a_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 34.0/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_c897a_00000 | RUNNING  | 172.17.0.14:44156 |      6 |          160.724 | 970752 |  224.965 |              281.475 |              138.899 |            870.868 |\n",
      "+-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_c897a_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4139\n",
      "    time_step_mean: 3562.4935275080907\n",
      "    time_step_min: 3186\n",
      "  date: 2020-11-13_15-48-06\n",
      "  done: false\n",
      "  episode_len_mean: 866.1985759493671\n",
      "  episode_reward_max: 283.2929292929289\n",
      "  episode_reward_mean: 226.52281517708712\n",
      "  episode_reward_min: 138.89898989898958\n",
      "  episodes_this_iter: 175\n",
      "  episodes_total: 1264\n",
      "  experiment_id: 5612dbec6380475ba519f8b5cbafbcdd\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.10000000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 1.076461374759674\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.008046677685342729\n",
      "        model: {}\n",
      "        policy_loss: -0.012926654831971973\n",
      "        total_loss: 19.407774448394775\n",
      "        vf_explained_var: 0.9647086262702942\n",
      "        vf_loss: 19.42043463389079\n",
      "    num_steps_sampled: 1132544\n",
      "    num_steps_trained: 1132544\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 27.015625\n",
      "    gpu_util_percent0: 0.30562500000000004\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.9012500000000001\n",
      "    ram_util_percent: 4.55\n",
      "    vram_util_percent0: 0.10749426041325025\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.9949178691351303\n",
      "  pid: 44156\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1585477710778587\n",
      "    mean_env_wait_ms: 1.1729450027813149\n",
      "    mean_inference_ms: 5.286395931515398\n",
      "    mean_raw_obs_processing_ms: 0.4267400586937735\n",
      "  time_since_restore: 186.81998419761658\n",
      "  time_this_iter_s: 26.09573745727539\n",
      "  time_total_s: 186.81998419761658\n",
      "  timers:\n",
      "    learn_throughput: 8749.767\n",
      "    learn_time_ms: 18491.006\n",
      "    sample_throughput: 19927.556\n",
      "    sample_time_ms: 8119.009\n",
      "    update_time_ms: 23.252\n",
      "  timestamp: 1605278886\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1132544\n",
      "  training_iteration: 7\n",
      "  trial_id: c897a_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 34.0/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_c897a_00000 | RUNNING  | 172.17.0.14:44156 |      7 |           186.82 | 1132544 |  226.523 |              283.293 |              138.899 |            866.199 |\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_c897a_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4139\n",
      "    time_step_mean: 3552.8407460545195\n",
      "    time_step_min: 3186\n",
      "  date: 2020-11-13_15-48-32\n",
      "  done: false\n",
      "  episode_len_mean: 862.8403656821379\n",
      "  episode_reward_max: 283.2929292929289\n",
      "  episode_reward_mean: 227.86843114691197\n",
      "  episode_reward_min: 138.89898989898958\n",
      "  episodes_this_iter: 158\n",
      "  episodes_total: 1422\n",
      "  experiment_id: 5612dbec6380475ba519f8b5cbafbcdd\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.10000000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 1.0585119326909382\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.007668271350363891\n",
      "        model: {}\n",
      "        policy_loss: -0.012480537193672111\n",
      "        total_loss: 16.27054516474406\n",
      "        vf_explained_var: 0.9697962403297424\n",
      "        vf_loss: 16.282788276672363\n",
      "    num_steps_sampled: 1294336\n",
      "    num_steps_trained: 1294336\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 27.583870967741934\n",
      "    gpu_util_percent0: 0.39032258064516134\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.8987096774193548\n",
      "    ram_util_percent: 4.561290322580644\n",
      "    vram_util_percent0: 0.10749426041325019\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.99491786913513\n",
      "  pid: 44156\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1580668465167416\n",
      "    mean_env_wait_ms: 1.1743092711284302\n",
      "    mean_inference_ms: 5.2309012751459125\n",
      "    mean_raw_obs_processing_ms: 0.4243311448293778\n",
      "  time_since_restore: 212.64683651924133\n",
      "  time_this_iter_s: 25.826852321624756\n",
      "  time_total_s: 212.64683651924133\n",
      "  timers:\n",
      "    learn_throughput: 8759.913\n",
      "    learn_time_ms: 18469.589\n",
      "    sample_throughput: 20140.466\n",
      "    sample_time_ms: 8033.181\n",
      "    update_time_ms: 23.132\n",
      "  timestamp: 1605278912\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1294336\n",
      "  training_iteration: 8\n",
      "  trial_id: c897a_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 34.0/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_c897a_00000 | RUNNING  | 172.17.0.14:44156 |      8 |          212.647 | 1294336 |  227.868 |              283.293 |              138.899 |             862.84 |\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_c897a_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4139\n",
      "    time_step_mean: 3543.840850515464\n",
      "    time_step_min: 3186\n",
      "  date: 2020-11-13_15-48-58\n",
      "  done: false\n",
      "  episode_len_mean: 859.286075949367\n",
      "  episode_reward_max: 283.2929292929289\n",
      "  episode_reward_mean: 229.3170950006391\n",
      "  episode_reward_min: 138.89898989898958\n",
      "  episodes_this_iter: 158\n",
      "  episodes_total: 1580\n",
      "  experiment_id: 5612dbec6380475ba519f8b5cbafbcdd\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.10000000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 1.0313109755516052\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.007441527986278136\n",
      "        model: {}\n",
      "        policy_loss: -0.01324609311510964\n",
      "        total_loss: 16.99935007095337\n",
      "        vf_explained_var: 0.9665364623069763\n",
      "        vf_loss: 17.012367725372314\n",
      "    num_steps_sampled: 1456128\n",
      "    num_steps_trained: 1456128\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.987499999999997\n",
      "    gpu_util_percent0: 0.366875\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.89625\n",
      "    ram_util_percent: 4.55625\n",
      "    vram_util_percent0: 0.10749426041325025\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.9949178691351303\n",
      "  pid: 44156\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.15764011394870361\n",
      "    mean_env_wait_ms: 1.175618790211554\n",
      "    mean_inference_ms: 5.18271302468138\n",
      "    mean_raw_obs_processing_ms: 0.4221392000568585\n",
      "  time_since_restore: 238.52028369903564\n",
      "  time_this_iter_s: 25.87344717979431\n",
      "  time_total_s: 238.52028369903564\n",
      "  timers:\n",
      "    learn_throughput: 8766.471\n",
      "    learn_time_ms: 18455.774\n",
      "    sample_throughput: 20306.209\n",
      "    sample_time_ms: 7967.612\n",
      "    update_time_ms: 24.633\n",
      "  timestamp: 1605278938\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1456128\n",
      "  training_iteration: 9\n",
      "  trial_id: c897a_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 34.1/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_c897a_00000 | RUNNING  | 172.17.0.14:44156 |      9 |           238.52 | 1456128 |  229.317 |              283.293 |              138.899 |            859.286 |\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_c897a_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4139\n",
      "    time_step_mean: 3531.6284122562674\n",
      "    time_step_min: 3171\n",
      "  date: 2020-11-13_15-49-24\n",
      "  done: false\n",
      "  episode_len_mean: 854.0087767416346\n",
      "  episode_reward_max: 285.5656565656566\n",
      "  episode_reward_mean: 231.12367780936057\n",
      "  episode_reward_min: 138.89898989898958\n",
      "  episodes_this_iter: 243\n",
      "  episodes_total: 1823\n",
      "  experiment_id: 5612dbec6380475ba519f8b5cbafbcdd\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.10000000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 0.9931153257687887\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.006967792481494446\n",
      "        model: {}\n",
      "        policy_loss: -0.01132376214566951\n",
      "        total_loss: 23.327927271525066\n",
      "        vf_explained_var: 0.9691898822784424\n",
      "        vf_loss: 23.339050769805908\n",
      "    num_steps_sampled: 1617920\n",
      "    num_steps_trained: 1617920\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.831249999999997\n",
      "    gpu_util_percent0: 0.4134375\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.9009375000000001\n",
      "    ram_util_percent: 4.553125\n",
      "    vram_util_percent0: 0.10749426041325025\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.9949178691351303\n",
      "  pid: 44156\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1570651854476064\n",
      "    mean_env_wait_ms: 1.1776449423077409\n",
      "    mean_inference_ms: 5.119254125089252\n",
      "    mean_raw_obs_processing_ms: 0.41919299090117945\n",
      "  time_since_restore: 265.0258996486664\n",
      "  time_this_iter_s: 26.505615949630737\n",
      "  time_total_s: 265.0258996486664\n",
      "  timers:\n",
      "    learn_throughput: 8763.635\n",
      "    learn_time_ms: 18461.745\n",
      "    sample_throughput: 20322.773\n",
      "    sample_time_ms: 7961.118\n",
      "    update_time_ms: 25.763\n",
      "  timestamp: 1605278964\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1617920\n",
      "  training_iteration: 10\n",
      "  trial_id: c897a_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 33.9/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_c897a_00000 | RUNNING  | 172.17.0.14:44156 |     10 |          265.026 | 1617920 |  231.124 |              285.566 |              138.899 |            854.009 |\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_c897a_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4139\n",
      "    time_step_mean: 3518.6692991115497\n",
      "    time_step_min: 3171\n",
      "  date: 2020-11-13_15-49-51\n",
      "  done: false\n",
      "  episode_len_mean: 849.722005842259\n",
      "  episode_reward_max: 285.5656565656566\n",
      "  episode_reward_mean: 233.0073077414848\n",
      "  episode_reward_min: 138.89898989898958\n",
      "  episodes_this_iter: 231\n",
      "  episodes_total: 2054\n",
      "  experiment_id: 5612dbec6380475ba519f8b5cbafbcdd\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.10000000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 0.9928835034370422\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.006921343971043825\n",
      "        model: {}\n",
      "        policy_loss: -0.011892432919315373\n",
      "        total_loss: 15.681842168172201\n",
      "        vf_explained_var: 0.9735597968101501\n",
      "        vf_loss: 15.693539381027222\n",
      "    num_steps_sampled: 1779712\n",
      "    num_steps_trained: 1779712\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 27.274193548387096\n",
      "    gpu_util_percent0: 0.41483870967741937\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.9003225806451615\n",
      "    ram_util_percent: 4.551612903225806\n",
      "    vram_util_percent0: 0.10749426041325019\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.99491786913513\n",
      "  pid: 44156\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.15664141420520206\n",
      "    mean_env_wait_ms: 1.1796274700725184\n",
      "    mean_inference_ms: 5.0730749828329325\n",
      "    mean_raw_obs_processing_ms: 0.4171052327272783\n",
      "  time_since_restore: 291.31596755981445\n",
      "  time_this_iter_s: 26.29006791114807\n",
      "  time_total_s: 291.31596755981445\n",
      "  timers:\n",
      "    learn_throughput: 8752.156\n",
      "    learn_time_ms: 18485.959\n",
      "    sample_throughput: 21174.256\n",
      "    sample_time_ms: 7640.977\n",
      "    update_time_ms: 27.16\n",
      "  timestamp: 1605278991\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1779712\n",
      "  training_iteration: 11\n",
      "  trial_id: c897a_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 34.0/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_c897a_00000 | RUNNING  | 172.17.0.14:44156 |     11 |          291.316 | 1779712 |  233.007 |              285.566 |              138.899 |            849.722 |\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_c897a_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4139\n",
      "    time_step_mean: 3511.260531135531\n",
      "    time_step_min: 3171\n",
      "  date: 2020-11-13_15-50-17\n",
      "  done: false\n",
      "  episode_len_mean: 846.8137432188065\n",
      "  episode_reward_max: 285.5656565656566\n",
      "  episode_reward_mean: 234.16037408442455\n",
      "  episode_reward_min: 138.89898989898958\n",
      "  episodes_this_iter: 158\n",
      "  episodes_total: 2212\n",
      "  experiment_id: 5612dbec6380475ba519f8b5cbafbcdd\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.10000000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 0.9700071861346563\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.007261571746009092\n",
      "        model: {}\n",
      "        policy_loss: -0.014008159041016674\n",
      "        total_loss: 10.695897976557413\n",
      "        vf_explained_var: 0.9790127277374268\n",
      "        vf_loss: 10.709664901097616\n",
      "    num_steps_sampled: 1941504\n",
      "    num_steps_trained: 1941504\n",
      "  iterations_since_restore: 12\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 27.184375\n",
      "    gpu_util_percent0: 0.30281250000000004\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.8703125\n",
      "    ram_util_percent: 4.5625\n",
      "    vram_util_percent0: 0.10749426041325025\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.9949178691351303\n",
      "  pid: 44156\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.15638177549799592\n",
      "    mean_env_wait_ms: 1.1807850412151435\n",
      "    mean_inference_ms: 5.044705513639501\n",
      "    mean_raw_obs_processing_ms: 0.4157691622152319\n",
      "  time_since_restore: 317.5393776893616\n",
      "  time_this_iter_s: 26.22341012954712\n",
      "  time_total_s: 317.5393776893616\n",
      "  timers:\n",
      "    learn_throughput: 8752.337\n",
      "    learn_time_ms: 18485.578\n",
      "    sample_throughput: 21300.243\n",
      "    sample_time_ms: 7595.782\n",
      "    update_time_ms: 28.433\n",
      "  timestamp: 1605279017\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1941504\n",
      "  training_iteration: 12\n",
      "  trial_id: c897a_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 34.5/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_c897a_00000 | RUNNING  | 172.17.0.14:44156 |     12 |          317.539 | 1941504 |   234.16 |              285.566 |              138.899 |            846.814 |\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_c897a_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4139\n",
      "    time_step_mean: 3503.7648314127186\n",
      "    time_step_min: 3171\n",
      "  date: 2020-11-13_15-50-43\n",
      "  done: false\n",
      "  episode_len_mean: 844.3428932939688\n",
      "  episode_reward_max: 285.5656565656566\n",
      "  episode_reward_mean: 235.38174234968818\n",
      "  episode_reward_min: 138.89898989898958\n",
      "  episodes_this_iter: 159\n",
      "  episodes_total: 2371\n",
      "  experiment_id: 5612dbec6380475ba519f8b5cbafbcdd\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.10000000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 0.9459350109100342\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.007110723488343258\n",
      "        model: {}\n",
      "        policy_loss: -0.011107290939738354\n",
      "        total_loss: 13.010012149810791\n",
      "        vf_explained_var: 0.9747781157493591\n",
      "        vf_loss: 13.020881573359171\n",
      "    num_steps_sampled: 2103296\n",
      "    num_steps_trained: 2103296\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 27.01875\n",
      "    gpu_util_percent0: 0.2940625\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.7575000000000001\n",
      "    ram_util_percent: 4.5625\n",
      "    vram_util_percent0: 0.10749426041325025\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.9949178691351303\n",
      "  pid: 44156\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.15614837316132107\n",
      "    mean_env_wait_ms: 1.1818733799596173\n",
      "    mean_inference_ms: 5.018852540628139\n",
      "    mean_raw_obs_processing_ms: 0.4145400273075942\n",
      "  time_since_restore: 343.79971265792847\n",
      "  time_this_iter_s: 26.260334968566895\n",
      "  time_total_s: 343.79971265792847\n",
      "  timers:\n",
      "    learn_throughput: 8753.392\n",
      "    learn_time_ms: 18483.349\n",
      "    sample_throughput: 21245.096\n",
      "    sample_time_ms: 7615.499\n",
      "    update_time_ms: 28.473\n",
      "  timestamp: 1605279043\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2103296\n",
      "  training_iteration: 13\n",
      "  trial_id: c897a_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 34.1/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_c897a_00000 | RUNNING  | 172.17.0.14:44156 |     13 |            343.8 | 2103296 |  235.382 |              285.566 |              138.899 |            844.343 |\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_c897a_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4139\n",
      "    time_step_mean: 3490.7743902439024\n",
      "    time_step_min: 3171\n",
      "  date: 2020-11-13_15-51-10\n",
      "  done: false\n",
      "  episode_len_mean: 840.88197586727\n",
      "  episode_reward_max: 285.5656565656566\n",
      "  episode_reward_mean: 237.26683120800755\n",
      "  episode_reward_min: 138.89898989898958\n",
      "  episodes_this_iter: 281\n",
      "  episodes_total: 2652\n",
      "  experiment_id: 5612dbec6380475ba519f8b5cbafbcdd\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.10000000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 0.9221189667781194\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.006802427698858082\n",
      "        model: {}\n",
      "        policy_loss: -0.010663663658003012\n",
      "        total_loss: 15.559588193893433\n",
      "        vf_explained_var: 0.9785810112953186\n",
      "        vf_loss: 15.570032835006714\n",
      "    num_steps_sampled: 2265088\n",
      "    num_steps_trained: 2265088\n",
      "  iterations_since_restore: 14\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.984375\n",
      "    gpu_util_percent0: 0.3196875\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.9015625\n",
      "    ram_util_percent: 4.546875\n",
      "    vram_util_percent0: 0.10749426041325025\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.9949178691351303\n",
      "  pid: 44156\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1557863774811957\n",
      "    mean_env_wait_ms: 1.1836248358340156\n",
      "    mean_inference_ms: 4.979054993072672\n",
      "    mean_raw_obs_processing_ms: 0.41264225565316004\n",
      "  time_since_restore: 370.3109862804413\n",
      "  time_this_iter_s: 26.511273622512817\n",
      "  time_total_s: 370.3109862804413\n",
      "  timers:\n",
      "    learn_throughput: 8753.342\n",
      "    learn_time_ms: 18483.455\n",
      "    sample_throughput: 21180.043\n",
      "    sample_time_ms: 7638.889\n",
      "    update_time_ms: 28.382\n",
      "  timestamp: 1605279070\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2265088\n",
      "  training_iteration: 14\n",
      "  trial_id: c897a_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 34.0/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_c897a_00000 | RUNNING  | 172.17.0.14:44156 |     14 |          370.311 | 2265088 |  237.267 |              285.566 |              138.899 |            840.882 |\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_c897a_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4139\n",
      "    time_step_mean: 3483.7240767045455\n",
      "    time_step_min: 3171\n",
      "  date: 2020-11-13_15-51-36\n",
      "  done: false\n",
      "  episode_len_mean: 838.6817862165964\n",
      "  episode_reward_max: 289.8080808080805\n",
      "  episode_reward_mean: 238.31402633934263\n",
      "  episode_reward_min: 138.89898989898958\n",
      "  episodes_this_iter: 192\n",
      "  episodes_total: 2844\n",
      "  experiment_id: 5612dbec6380475ba519f8b5cbafbcdd\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.10000000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 0.9070422649383545\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.00644140166696161\n",
      "        model: {}\n",
      "        policy_loss: -0.011113252956420183\n",
      "        total_loss: 11.404633442560831\n",
      "        vf_explained_var: 0.9799684882164001\n",
      "        vf_loss: 11.415556112925211\n",
      "    num_steps_sampled: 2426880\n",
      "    num_steps_trained: 2426880\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.9375\n",
      "    gpu_util_percent0: 0.2996875\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.90125\n",
      "    ram_util_percent: 4.546875\n",
      "    vram_util_percent0: 0.10749426041325025\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.9949178691351303\n",
      "  pid: 44156\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1555654127313557\n",
      "    mean_env_wait_ms: 1.1847531833403733\n",
      "    mean_inference_ms: 4.955822166541129\n",
      "    mean_raw_obs_processing_ms: 0.4115499787179512\n",
      "  time_since_restore: 396.4263029098511\n",
      "  time_this_iter_s: 26.11531662940979\n",
      "  time_total_s: 396.4263029098511\n",
      "  timers:\n",
      "    learn_throughput: 8751.111\n",
      "    learn_time_ms: 18488.167\n",
      "    sample_throughput: 21271.163\n",
      "    sample_time_ms: 7606.166\n",
      "    update_time_ms: 28.012\n",
      "  timestamp: 1605279096\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2426880\n",
      "  training_iteration: 15\n",
      "  trial_id: c897a_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 34.0/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_c897a_00000 | RUNNING  | 172.17.0.14:44156 |     15 |          396.426 | 2426880 |  238.314 |              289.808 |              138.899 |            838.682 |\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_c897a_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4139\n",
      "    time_step_mean: 3478.1365164761264\n",
      "    time_step_min: 3171\n",
      "  date: 2020-11-13_15-52-03\n",
      "  done: false\n",
      "  episode_len_mean: 836.9157228514324\n",
      "  episode_reward_max: 289.8080808080805\n",
      "  episode_reward_mean: 239.1832448401401\n",
      "  episode_reward_min: 138.89898989898958\n",
      "  episodes_this_iter: 158\n",
      "  episodes_total: 3002\n",
      "  experiment_id: 5612dbec6380475ba519f8b5cbafbcdd\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.10000000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 0.896520584821701\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.006536177165495853\n",
      "        model: {}\n",
      "        policy_loss: -0.010504661060015982\n",
      "        total_loss: 10.821569522221884\n",
      "        vf_explained_var: 0.9786182045936584\n",
      "        vf_loss: 10.831868728001913\n",
      "    num_steps_sampled: 2588672\n",
      "    num_steps_trained: 2588672\n",
      "  iterations_since_restore: 16\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.571875\n",
      "    gpu_util_percent0: 0.3603125\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.8984375\n",
      "    ram_util_percent: 4.5625\n",
      "    vram_util_percent0: 0.10749426041325025\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.9949178691351303\n",
      "  pid: 44156\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.15540263376734464\n",
      "    mean_env_wait_ms: 1.1855746482478962\n",
      "    mean_inference_ms: 4.938190573875376\n",
      "    mean_raw_obs_processing_ms: 0.4107032854241815\n",
      "  time_since_restore: 422.76325130462646\n",
      "  time_this_iter_s: 26.33694839477539\n",
      "  time_total_s: 422.76325130462646\n",
      "  timers:\n",
      "    learn_throughput: 8747.461\n",
      "    learn_time_ms: 18495.881\n",
      "    sample_throughput: 21219.826\n",
      "    sample_time_ms: 7624.568\n",
      "    update_time_ms: 27.215\n",
      "  timestamp: 1605279123\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2588672\n",
      "  training_iteration: 16\n",
      "  trial_id: c897a_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 34.0/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_c897a_00000 | RUNNING  | 172.17.0.14:44156 |     16 |          422.763 | 2588672 |  239.183 |              289.808 |              138.899 |            836.916 |\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_c897a_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4139\n",
      "    time_step_mean: 3471.6878374087014\n",
      "    time_step_min: 3125\n",
      "  date: 2020-11-13_15-52-29\n",
      "  done: false\n",
      "  episode_len_mean: 834.902423670129\n",
      "  episode_reward_max: 292.5353535353536\n",
      "  episode_reward_mean: 240.09594528857968\n",
      "  episode_reward_min: 138.89898989898958\n",
      "  episodes_this_iter: 175\n",
      "  episodes_total: 3177\n",
      "  experiment_id: 5612dbec6380475ba519f8b5cbafbcdd\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.10000000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 0.8638751854499181\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.00689789423874269\n",
      "        model: {}\n",
      "        policy_loss: -0.009188439952898383\n",
      "        total_loss: 12.445635000864664\n",
      "        vf_explained_var: 0.9786007404327393\n",
      "        vf_loss: 12.454565842946371\n",
      "    num_steps_sampled: 2750464\n",
      "    num_steps_trained: 2750464\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.025\n",
      "    gpu_util_percent0: 0.3628125\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.900625\n",
      "    ram_util_percent: 4.553125\n",
      "    vram_util_percent0: 0.10749426041325025\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.9949178691351303\n",
      "  pid: 44156\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1552432639836916\n",
      "    mean_env_wait_ms: 1.1864826765221341\n",
      "    mean_inference_ms: 4.9204104540069435\n",
      "    mean_raw_obs_processing_ms: 0.40985791627205337\n",
      "  time_since_restore: 449.00256609916687\n",
      "  time_this_iter_s: 26.239314794540405\n",
      "  time_total_s: 449.00256609916687\n",
      "  timers:\n",
      "    learn_throughput: 8752.848\n",
      "    learn_time_ms: 18484.499\n",
      "    sample_throughput: 21167.381\n",
      "    sample_time_ms: 7643.459\n",
      "    update_time_ms: 27.72\n",
      "  timestamp: 1605279149\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2750464\n",
      "  training_iteration: 17\n",
      "  trial_id: c897a_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 34.1/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_c897a_00000 | RUNNING  | 172.17.0.14:44156 |     17 |          449.003 | 2750464 |  240.096 |              292.535 |              138.899 |            834.902 |\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_c897a_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4139\n",
      "    time_step_mean: 3461.4914269107817\n",
      "    time_step_min: 3125\n",
      "  date: 2020-11-13_15-52-56\n",
      "  done: false\n",
      "  episode_len_mean: 831.8613433266071\n",
      "  episode_reward_max: 292.5353535353536\n",
      "  episode_reward_mean: 241.6433402925186\n",
      "  episode_reward_min: 138.89898989898958\n",
      "  episodes_this_iter: 292\n",
      "  episodes_total: 3469\n",
      "  experiment_id: 5612dbec6380475ba519f8b5cbafbcdd\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.10000000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 0.852044016122818\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.005957545712590218\n",
      "        model: {}\n",
      "        policy_loss: -0.010851058197052529\n",
      "        total_loss: 12.632285197575888\n",
      "        vf_explained_var: 0.9817772507667542\n",
      "        vf_loss: 12.642966111501059\n",
      "    num_steps_sampled: 2912256\n",
      "    num_steps_trained: 2912256\n",
      "  iterations_since_restore: 18\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.734375\n",
      "    gpu_util_percent0: 0.3875\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.89875\n",
      "    ram_util_percent: 4.55\n",
      "    vram_util_percent0: 0.10749426041325025\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.9949178691351303\n",
      "  pid: 44156\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.15498233521265914\n",
      "    mean_env_wait_ms: 1.187863699166851\n",
      "    mean_inference_ms: 4.893229032369082\n",
      "    mean_raw_obs_processing_ms: 0.4085200923517304\n",
      "  time_since_restore: 475.5669467449188\n",
      "  time_this_iter_s: 26.564380645751953\n",
      "  time_total_s: 475.5669467449188\n",
      "  timers:\n",
      "    learn_throughput: 8745.692\n",
      "    learn_time_ms: 18499.623\n",
      "    sample_throughput: 21009.457\n",
      "    sample_time_ms: 7700.913\n",
      "    update_time_ms: 27.835\n",
      "  timestamp: 1605279176\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2912256\n",
      "  training_iteration: 18\n",
      "  trial_id: c897a_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 34.0/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_c897a_00000 | RUNNING  | 172.17.0.14:44156 |     18 |          475.567 | 2912256 |  241.643 |              292.535 |              138.899 |            831.861 |\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_c897a_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4139\n",
      "    time_step_mean: 3456.812257348863\n",
      "    time_step_min: 3125\n",
      "  date: 2020-11-13_15-53-22\n",
      "  done: false\n",
      "  episode_len_mean: 830.1596037424326\n",
      "  episode_reward_max: 292.5353535353536\n",
      "  episode_reward_mean: 242.42553215145387\n",
      "  episode_reward_min: 138.89898989898958\n",
      "  episodes_this_iter: 165\n",
      "  episodes_total: 3634\n",
      "  experiment_id: 5612dbec6380475ba519f8b5cbafbcdd\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.10000000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 0.8423722982406616\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.005703799504165848\n",
      "        model: {}\n",
      "        policy_loss: -0.012257898789054403\n",
      "        total_loss: 9.137722810109457\n",
      "        vf_explained_var: 0.9817180037498474\n",
      "        vf_loss: 9.149831453959147\n",
      "    num_steps_sampled: 3074048\n",
      "    num_steps_trained: 3074048\n",
      "  iterations_since_restore: 19\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.28125\n",
      "    gpu_util_percent0: 0.385625\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.9015625\n",
      "    ram_util_percent: 4.5625\n",
      "    vram_util_percent0: 0.10749426041325025\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.9949178691351303\n",
      "  pid: 44156\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.15485488555292282\n",
      "    mean_env_wait_ms: 1.1886348597948226\n",
      "    mean_inference_ms: 4.879770302391044\n",
      "    mean_raw_obs_processing_ms: 0.40786805489153627\n",
      "  time_since_restore: 502.02141189575195\n",
      "  time_this_iter_s: 26.45446515083313\n",
      "  time_total_s: 502.02141189575195\n",
      "  timers:\n",
      "    learn_throughput: 8741.29\n",
      "    learn_time_ms: 18508.939\n",
      "    sample_throughput: 20890.722\n",
      "    sample_time_ms: 7744.682\n",
      "    update_time_ms: 31.175\n",
      "  timestamp: 1605279202\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3074048\n",
      "  training_iteration: 19\n",
      "  trial_id: c897a_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 34.0/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_c897a_00000 | RUNNING  | 172.17.0.14:44156 |     19 |          502.021 | 3074048 |  242.426 |              292.535 |              138.899 |             830.16 |\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_c897a_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4139\n",
      "    time_step_mean: 3452.1272582359193\n",
      "    time_step_min: 3125\n",
      "  date: 2020-11-13_15-53-49\n",
      "  done: false\n",
      "  episode_len_mean: 828.6360759493671\n",
      "  episode_reward_max: 292.5353535353536\n",
      "  episode_reward_mean: 243.0997394834419\n",
      "  episode_reward_min: 138.89898989898958\n",
      "  episodes_this_iter: 158\n",
      "  episodes_total: 3792\n",
      "  experiment_id: 5612dbec6380475ba519f8b5cbafbcdd\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.10000000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 0.8330753048261007\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.00570860574953258\n",
      "        model: {}\n",
      "        policy_loss: -0.00988401377495999\n",
      "        total_loss: 10.681349515914917\n",
      "        vf_explained_var: 0.978595495223999\n",
      "        vf_loss: 10.691078980763754\n",
      "    num_steps_sampled: 3235840\n",
      "    num_steps_trained: 3235840\n",
      "  iterations_since_restore: 20\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 27.09375\n",
      "    gpu_util_percent0: 0.3815625\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.9\n",
      "    ram_util_percent: 4.559375\n",
      "    vram_util_percent0: 0.10749426041325025\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.9949178691351303\n",
      "  pid: 44156\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1547385482579278\n",
      "    mean_env_wait_ms: 1.189309945422883\n",
      "    mean_inference_ms: 4.867530278520614\n",
      "    mean_raw_obs_processing_ms: 0.4072560970581565\n",
      "  time_since_restore: 528.5414574146271\n",
      "  time_this_iter_s: 26.520045518875122\n",
      "  time_total_s: 528.5414574146271\n",
      "  timers:\n",
      "    learn_throughput: 8738.857\n",
      "    learn_time_ms: 18514.091\n",
      "    sample_throughput: 20904.618\n",
      "    sample_time_ms: 7739.534\n",
      "    update_time_ms: 31.529\n",
      "  timestamp: 1605279229\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3235840\n",
      "  training_iteration: 20\n",
      "  trial_id: c897a_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 34.1/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_c897a_00000 | RUNNING  | 172.17.0.14:44156 |     20 |          528.541 | 3235840 |    243.1 |              292.535 |              138.899 |            828.636 |\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_c897a_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4139\n",
      "    time_step_mean: 3445.434825870647\n",
      "    time_step_min: 3121\n",
      "  date: 2020-11-13_15-54-16\n",
      "  done: false\n",
      "  episode_len_mean: 826.5256916996047\n",
      "  episode_reward_max: 293.1414141414142\n",
      "  episode_reward_mean: 244.02209595959584\n",
      "  episode_reward_min: 138.89898989898958\n",
      "  episodes_this_iter: 256\n",
      "  episodes_total: 4048\n",
      "  experiment_id: 5612dbec6380475ba519f8b5cbafbcdd\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.10000000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 0.8068411350250244\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.005653477894763152\n",
      "        model: {}\n",
      "        policy_loss: -0.011089038700447418\n",
      "        total_loss: 14.805326143900553\n",
      "        vf_explained_var: 0.9791650176048279\n",
      "        vf_loss: 14.816253105799357\n",
      "    num_steps_sampled: 3397632\n",
      "    num_steps_trained: 3397632\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 27.0375\n",
      "    gpu_util_percent0: 0.3565625\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.9003125000000001\n",
      "    ram_util_percent: 4.553125\n",
      "    vram_util_percent0: 0.10749426041325025\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.9949178691351303\n",
      "  pid: 44156\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1545632270787233\n",
      "    mean_env_wait_ms: 1.1903334389994178\n",
      "    mean_inference_ms: 4.849002681801813\n",
      "    mean_raw_obs_processing_ms: 0.4063213169565321\n",
      "  time_since_restore: 555.191632270813\n",
      "  time_this_iter_s: 26.650174856185913\n",
      "  time_total_s: 555.191632270813\n",
      "  timers:\n",
      "    learn_throughput: 8760.202\n",
      "    learn_time_ms: 18468.981\n",
      "    sample_throughput: 20686.741\n",
      "    sample_time_ms: 7821.048\n",
      "    update_time_ms: 29.933\n",
      "  timestamp: 1605279256\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3397632\n",
      "  training_iteration: 21\n",
      "  trial_id: c897a_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 34.0/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_c897a_00000 | RUNNING  | 172.17.0.14:44156 |     21 |          555.192 | 3397632 |  244.022 |              293.141 |              138.899 |            826.526 |\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_c897a_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4139\n",
      "    time_step_mean: 3439.769230769231\n",
      "    time_step_min: 3121\n",
      "  date: 2020-11-13_15-54-43\n",
      "  done: false\n",
      "  episode_len_mean: 825.1211908110643\n",
      "  episode_reward_max: 293.1414141414142\n",
      "  episode_reward_mean: 244.85080765460503\n",
      "  episode_reward_min: 138.89898989898958\n",
      "  episodes_this_iter: 218\n",
      "  episodes_total: 4266\n",
      "  experiment_id: 5612dbec6380475ba519f8b5cbafbcdd\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.10000000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 0.7990769445896149\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.0058574858121573925\n",
      "        model: {}\n",
      "        policy_loss: -0.011235467779139677\n",
      "        total_loss: 10.091817061106363\n",
      "        vf_explained_var: 0.9826228618621826\n",
      "        vf_loss: 10.102866093317667\n",
      "    num_steps_sampled: 3559424\n",
      "    num_steps_trained: 3559424\n",
      "  iterations_since_restore: 22\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.430303030303033\n",
      "    gpu_util_percent0: 0.3596969696969697\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.6866666666666666\n",
      "    ram_util_percent: 4.56060606060606\n",
      "    vram_util_percent0: 0.10749426041325025\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.9949178691351304\n",
      "  pid: 44156\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1544327715740121\n",
      "    mean_env_wait_ms: 1.1912040122719683\n",
      "    mean_inference_ms: 4.835254492201214\n",
      "    mean_raw_obs_processing_ms: 0.4056611774717027\n",
      "  time_since_restore: 581.8482103347778\n",
      "  time_this_iter_s: 26.656578063964844\n",
      "  time_total_s: 581.8482103347778\n",
      "  timers:\n",
      "    learn_throughput: 8748.357\n",
      "    learn_time_ms: 18493.986\n",
      "    sample_throughput: 20637.719\n",
      "    sample_time_ms: 7839.626\n",
      "    update_time_ms: 28.513\n",
      "  timestamp: 1605279283\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3559424\n",
      "  training_iteration: 22\n",
      "  trial_id: c897a_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 34.1/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_c897a_00000 | RUNNING  | 172.17.0.14:44156 |     22 |          581.848 | 3559424 |  244.851 |              293.141 |              138.899 |            825.121 |\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_c897a_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4139\n",
      "    time_step_mean: 3435.400363967243\n",
      "    time_step_min: 3121\n",
      "  date: 2020-11-13_15-55-09\n",
      "  done: true\n",
      "  episode_len_mean: 824.3594032549729\n",
      "  episode_reward_max: 293.1414141414142\n",
      "  episode_reward_mean: 245.5013037244049\n",
      "  episode_reward_min: 138.89898989898958\n",
      "  episodes_this_iter: 158\n",
      "  episodes_total: 4424\n",
      "  experiment_id: 5612dbec6380475ba519f8b5cbafbcdd\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.10000000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 0.7958766669034958\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.006034458444143335\n",
      "        model: {}\n",
      "        policy_loss: -0.01285849836616156\n",
      "        total_loss: 8.110500057538351\n",
      "        vf_explained_var: 0.9831976890563965\n",
      "        vf_loss: 8.123153448104858\n",
      "    num_steps_sampled: 3721216\n",
      "    num_steps_trained: 3721216\n",
      "  iterations_since_restore: 23\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 27.381249999999998\n",
      "    gpu_util_percent0: 0.4221875\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.9009375000000001\n",
      "    ram_util_percent: 4.5625\n",
      "    vram_util_percent0: 0.10749426041325025\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.9949178691351303\n",
      "  pid: 44156\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.15434275007384932\n",
      "    mean_env_wait_ms: 1.1917490643464306\n",
      "    mean_inference_ms: 4.825758736416518\n",
      "    mean_raw_obs_processing_ms: 0.40518835230229516\n",
      "  time_since_restore: 607.933819770813\n",
      "  time_this_iter_s: 26.085609436035156\n",
      "  time_total_s: 607.933819770813\n",
      "  timers:\n",
      "    learn_throughput: 8750.769\n",
      "    learn_time_ms: 18488.889\n",
      "    sample_throughput: 20679.032\n",
      "    sample_time_ms: 7823.964\n",
      "    update_time_ms: 30.684\n",
      "  timestamp: 1605279309\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3721216\n",
      "  training_iteration: 23\n",
      "  trial_id: c897a_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 34.1/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 TERMINATED)\n",
      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_c897a_00000 | TERMINATED |       |     23 |          607.934 | 3721216 |  245.501 |              293.141 |              138.899 |            824.359 |\n",
      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Memory usage on this node: 34.1/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 TERMINATED)\n",
      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_c897a_00000 | TERMINATED |       |     23 |          607.934 | 3721216 |  245.501 |              293.141 |              138.899 |            824.359 |\n",
      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "2020-11-13 15:55:10,061\tINFO tune.py:439 -- Total run time: 619.71 seconds (619.09 seconds for the tuning loop).\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 43861\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: /JSS/JSS/wandb/run-20201113_154444-tdepb25x/logs/debug.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: /JSS/JSS/wandb/run-20201113_154444-tdepb25x/logs/debug-internal.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3121\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 626\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1605279310\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 4139\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 3435.40036\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 293.14141\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 138.89899\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 245.5013\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 4424\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 23\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mrural-sweep-1\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_4/runs/tdepb25x\u001b[0m\n",
      "2020-11-13 15:55:19,218 - wandb.wandb_agent - INFO - Cleaning up finished run: tdepb25x\n",
      "2020-11-13 15:55:20,669 - wandb.wandb_agent - INFO - Agent received command: run\n",
      "2020-11-13 15:55:20,669 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
      "\tinstance_path: /JSS/JSS/env/instances/ta52\n",
      "2020-11-13 15:55:20,672 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --instance_path=/JSS/JSS/env/instances/ta52\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdriven-sweep-2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_4/sweeps/2rk3apl0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_4/runs/1owodlzz\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /JSS/JSS/wandb/run-20201113_155522-1owodlzz\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
      "\n",
      "2020-11-13 15:55:25,683 - wandb.wandb_agent - INFO - Running runs: ['1owodlzz']\n",
      "2020-11-13 15:55:25,874\tINFO services.py:1090 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
      "== Status ==\n",
      "Memory usage on this node: 17.0/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------+\n",
      "| Trial name              | status   | loc   |\n",
      "|-------------------------+----------+-------|\n",
      "| PPO_jss_env_44bc1_00000 | RUNNING  |       |\n",
      "+-------------------------+----------+-------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=70481)\u001b[0m 2020-11-13 15:55:29,729\tINFO trainer.py:617 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=70436)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70436)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70429)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70429)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70413)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70413)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70452)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70452)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70420)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70420)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70421)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70421)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70426)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70426)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70478)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70478)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70412)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70412)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70410)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70410)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70447)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70447)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70407)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70407)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70464)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70464)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70459)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70459)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70468)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70468)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70392)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70392)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70465)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70465)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70442)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70442)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70474)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70474)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70398)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70398)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70416)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70416)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70438)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70438)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70406)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70406)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70444)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70444)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70397)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70397)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70409)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70409)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70423)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70423)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70476)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70476)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70425)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70425)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70428)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70428)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70472)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70472)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70435)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70435)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70404)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70404)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70354)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70354)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70355)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70355)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70386)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70386)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70352)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70352)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70403)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70403)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70351)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70351)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70466)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70466)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70389)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70389)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70433)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70433)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70469)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70469)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70396)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70396)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70340)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70340)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70399)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70399)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70402)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70402)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70385)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70385)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70364)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70364)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70391)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70391)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70400)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70400)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70448)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70448)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70415)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70415)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70418)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70418)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70388)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70388)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70341)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70341)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70342)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70342)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70349)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70349)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70456)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70456)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70358)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70358)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70345)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70345)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70390)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70390)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70382)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70382)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70393)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70393)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70363)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70363)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70350)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70350)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70343)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70343)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70394)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70394)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70401)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70401)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70357)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70357)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70395)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70395)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70356)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70356)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70362)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70362)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70353)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70353)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70346)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70346)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70347)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70347)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70381)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70381)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70348)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70348)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=70344)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=70344)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "Result for PPO_jss_env_44bc1_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4248\n",
      "    time_step_mean: 3616.3166666666666\n",
      "    time_step_min: 3355\n",
      "  date: 2020-11-13_15-56-05\n",
      "  done: false\n",
      "  episode_len_mean: 904.8481012658228\n",
      "  episode_reward_max: 246.595959595959\n",
      "  episode_reward_mean: 201.8721391126452\n",
      "  episode_reward_min: 106.74747474747424\n",
      "  episodes_this_iter: 158\n",
      "  episodes_total: 158\n",
      "  experiment_id: 1fe2dba03034492ab71511d2fd867765\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.20000000000000004\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 1.1692165732383728\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.004276340866150956\n",
      "        model: {}\n",
      "        policy_loss: -0.008549409530436\n",
      "        total_loss: 369.2430826822917\n",
      "        vf_explained_var: 0.5880423188209534\n",
      "        vf_loss: 369.25135548909503\n",
      "    num_steps_sampled: 161792\n",
      "    num_steps_trained: 161792\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 31.659999999999997\n",
      "    gpu_util_percent0: 0.3048571428571429\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.8931428571428572\n",
      "    ram_util_percent: 4.297142857142858\n",
      "    vram_util_percent0: 0.08827484421121677\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.9949178691351303\n",
      "  pid: 70481\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.17028178797713325\n",
      "    mean_env_wait_ms: 1.1871040364259846\n",
      "    mean_inference_ms: 6.455719683706927\n",
      "    mean_raw_obs_processing_ms: 0.46668335919617204\n",
      "  time_since_restore: 28.874195098876953\n",
      "  time_this_iter_s: 28.874195098876953\n",
      "  time_total_s: 28.874195098876953\n",
      "  timers:\n",
      "    learn_throughput: 8701.79\n",
      "    learn_time_ms: 18592.957\n",
      "    sample_throughput: 15863.101\n",
      "    sample_time_ms: 10199.267\n",
      "    update_time_ms: 43.646\n",
      "  timestamp: 1605279365\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 161792\n",
      "  training_iteration: 1\n",
      "  trial_id: 44bc1_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 33.4/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_44bc1_00000 | RUNNING  | 172.17.0.14:70481 |      1 |          28.8742 | 161792 |  201.872 |              246.596 |              106.747 |            904.848 |\n",
      "+-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_44bc1_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4331\n",
      "    time_step_mean: 3616.4028776978416\n",
      "    time_step_min: 3254\n",
      "  date: 2020-11-13_15-56-31\n",
      "  done: false\n",
      "  episode_len_mean: 904.6803797468355\n",
      "  episode_reward_max: 257.35353535353516\n",
      "  episode_reward_mean: 200.58330136811122\n",
      "  episode_reward_min: 94.17171717171675\n",
      "  episodes_this_iter: 158\n",
      "  episodes_total: 316\n",
      "  experiment_id: 1fe2dba03034492ab71511d2fd867765\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.10000000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 1.137185702721278\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.008476226241327822\n",
      "        model: {}\n",
      "        policy_loss: -0.010403861941692108\n",
      "        total_loss: 86.70168813069661\n",
      "        vf_explained_var: 0.8360044360160828\n",
      "        vf_loss: 86.71181297302246\n",
      "    num_steps_sampled: 323584\n",
      "    num_steps_trained: 323584\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.08125\n",
      "    gpu_util_percent0: 0.3690625\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.89875\n",
      "    ram_util_percent: 4.5406249999999995\n",
      "    vram_util_percent0: 0.10749426041325025\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.9949178691351303\n",
      "  pid: 70481\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.16644090553554405\n",
      "    mean_env_wait_ms: 1.1840642219609412\n",
      "    mean_inference_ms: 6.060050674009707\n",
      "    mean_raw_obs_processing_ms: 0.4525606971936636\n",
      "  time_since_restore: 55.13876128196716\n",
      "  time_this_iter_s: 26.26456618309021\n",
      "  time_total_s: 55.13876128196716\n",
      "  timers:\n",
      "    learn_throughput: 8767.896\n",
      "    learn_time_ms: 18452.774\n",
      "    sample_throughput: 17953.906\n",
      "    sample_time_ms: 9011.521\n",
      "    update_time_ms: 32.504\n",
      "  timestamp: 1605279391\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 323584\n",
      "  training_iteration: 2\n",
      "  trial_id: 44bc1_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 34.0/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_44bc1_00000 | RUNNING  | 172.17.0.14:70481 |      2 |          55.1388 | 323584 |  200.583 |              257.354 |              94.1717 |             904.68 |\n",
      "+-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_44bc1_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4331\n",
      "    time_step_mean: 3619.5022935779816\n",
      "    time_step_min: 3254\n",
      "  date: 2020-11-13_15-56-57\n",
      "  done: false\n",
      "  episode_len_mean: 899.8291139240506\n",
      "  episode_reward_max: 257.35353535353516\n",
      "  episode_reward_mean: 200.48420918041145\n",
      "  episode_reward_min: 94.17171717171675\n",
      "  episodes_this_iter: 158\n",
      "  episodes_total: 474\n",
      "  experiment_id: 1fe2dba03034492ab71511d2fd867765\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.10000000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 1.1263935069243114\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.009663396903003255\n",
      "        model: {}\n",
      "        policy_loss: -0.01133050469798036\n",
      "        total_loss: 42.13448842366537\n",
      "        vf_explained_var: 0.9133780002593994\n",
      "        vf_loss: 42.14541435241699\n",
      "    num_steps_sampled: 485376\n",
      "    num_steps_trained: 485376\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 27.858064516129033\n",
      "    gpu_util_percent0: 0.33064516129032256\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.900967741935484\n",
      "    ram_util_percent: 4.561290322580644\n",
      "    vram_util_percent0: 0.10749426041325019\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.99491786913513\n",
      "  pid: 70481\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1640286515043223\n",
      "    mean_env_wait_ms: 1.1837888147708044\n",
      "    mean_inference_ms: 5.804112214913262\n",
      "    mean_raw_obs_processing_ms: 0.44354038460959805\n",
      "  time_since_restore: 81.09153270721436\n",
      "  time_this_iter_s: 25.952771425247192\n",
      "  time_total_s: 81.09153270721436\n",
      "  timers:\n",
      "    learn_throughput: 8782.64\n",
      "    learn_time_ms: 18421.797\n",
      "    sample_throughput: 19029.184\n",
      "    sample_time_ms: 8502.309\n",
      "    update_time_ms: 35.524\n",
      "  timestamp: 1605279417\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 485376\n",
      "  training_iteration: 3\n",
      "  trial_id: 44bc1_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 33.9/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_44bc1_00000 | RUNNING  | 172.17.0.14:70481 |      3 |          81.0915 | 485376 |  200.484 |              257.354 |              94.1717 |            899.829 |\n",
      "+-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_44bc1_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4331\n",
      "    time_step_mean: 3618.925925925926\n",
      "    time_step_min: 3254\n",
      "  date: 2020-11-13_15-57-24\n",
      "  done: false\n",
      "  episode_len_mean: 893.0553797468355\n",
      "  episode_reward_max: 258.11111111111154\n",
      "  episode_reward_mean: 202.18955376550286\n",
      "  episode_reward_min: 94.17171717171675\n",
      "  episodes_this_iter: 158\n",
      "  episodes_total: 632\n",
      "  experiment_id: 1fe2dba03034492ab71511d2fd867765\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.10000000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 1.110435922940572\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.008405348984524608\n",
      "        model: {}\n",
      "        policy_loss: -0.011238279791238407\n",
      "        total_loss: 33.4731019337972\n",
      "        vf_explained_var: 0.9288856387138367\n",
      "        vf_loss: 33.484055836995445\n",
      "    num_steps_sampled: 647168\n",
      "    num_steps_trained: 647168\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.91935483870967\n",
      "    gpu_util_percent0: 0.3438709677419355\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.9003225806451616\n",
      "    ram_util_percent: 4.561290322580644\n",
      "    vram_util_percent0: 0.10749426041325019\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.99491786913513\n",
      "  pid: 70481\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.16230551845795205\n",
      "    mean_env_wait_ms: 1.1851355919792208\n",
      "    mean_inference_ms: 5.625104883739576\n",
      "    mean_raw_obs_processing_ms: 0.43653612567275607\n",
      "  time_since_restore: 107.19719433784485\n",
      "  time_this_iter_s: 26.105661630630493\n",
      "  time_total_s: 107.19719433784485\n",
      "  timers:\n",
      "    learn_throughput: 8779.043\n",
      "    learn_time_ms: 18429.344\n",
      "    sample_throughput: 19563.748\n",
      "    sample_time_ms: 8269.99\n",
      "    update_time_ms: 35.32\n",
      "  timestamp: 1605279444\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 647168\n",
      "  training_iteration: 4\n",
      "  trial_id: 44bc1_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 34.0/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_44bc1_00000 | RUNNING  | 172.17.0.14:70481 |      4 |          107.197 | 647168 |   202.19 |              258.111 |              94.1717 |            893.055 |\n",
      "+-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_44bc1_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4331\n",
      "    time_step_mean: 3614.363031914894\n",
      "    time_step_min: 3254\n",
      "  date: 2020-11-13_15-57-50\n",
      "  done: false\n",
      "  episode_len_mean: 886.3240506329114\n",
      "  episode_reward_max: 258.11111111111154\n",
      "  episode_reward_mean: 202.50236542641585\n",
      "  episode_reward_min: 94.17171717171675\n",
      "  episodes_this_iter: 158\n",
      "  episodes_total: 790\n",
      "  experiment_id: 1fe2dba03034492ab71511d2fd867765\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.10000000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 1.0816011130809784\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.0075309024735664325\n",
      "        model: {}\n",
      "        policy_loss: -0.011756445242402455\n",
      "        total_loss: 30.053621133168537\n",
      "        vf_explained_var: 0.9416897892951965\n",
      "        vf_loss: 30.06516472498576\n",
      "    num_steps_sampled: 808960\n",
      "    num_steps_trained: 808960\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.7375\n",
      "    gpu_util_percent0: 0.39375\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.9012500000000001\n",
      "    ram_util_percent: 4.553125\n",
      "    vram_util_percent0: 0.10749426041325025\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.9949178691351303\n",
      "  pid: 70481\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.16102815735811524\n",
      "    mean_env_wait_ms: 1.187127290149888\n",
      "    mean_inference_ms: 5.49261688269376\n",
      "    mean_raw_obs_processing_ms: 0.43103153393828825\n",
      "  time_since_restore: 133.0531919002533\n",
      "  time_this_iter_s: 25.855997562408447\n",
      "  time_total_s: 133.0531919002533\n",
      "  timers:\n",
      "    learn_throughput: 8797.173\n",
      "    learn_time_ms: 18391.362\n",
      "    sample_throughput: 19947.488\n",
      "    sample_time_ms: 8110.896\n",
      "    update_time_ms: 34.554\n",
      "  timestamp: 1605279470\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 808960\n",
      "  training_iteration: 5\n",
      "  trial_id: 44bc1_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 34.1/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_44bc1_00000 | RUNNING  | 172.17.0.14:70481 |      5 |          133.053 | 808960 |  202.502 |              258.111 |              94.1717 |            886.324 |\n",
      "+-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_44bc1_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4331\n",
      "    time_step_mean: 3606.659090909091\n",
      "    time_step_min: 3254\n",
      "  date: 2020-11-13_15-58-16\n",
      "  done: false\n",
      "  episode_len_mean: 877.1457142857142\n",
      "  episode_reward_max: 258.11111111111154\n",
      "  episode_reward_mean: 204.48528138528118\n",
      "  episode_reward_min: 94.17171717171675\n",
      "  episodes_this_iter: 260\n",
      "  episodes_total: 1050\n",
      "  experiment_id: 1fe2dba03034492ab71511d2fd867765\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.10000000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 1.0457039376099904\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.0070358754601329565\n",
      "        model: {}\n",
      "        policy_loss: -0.010302343541601052\n",
      "        total_loss: 35.57674217224121\n",
      "        vf_explained_var: 0.9546704888343811\n",
      "        vf_loss: 35.58686447143555\n",
      "    num_steps_sampled: 970752\n",
      "    num_steps_trained: 970752\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 27.91935483870968\n",
      "    gpu_util_percent0: 0.28225806451612906\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.900967741935484\n",
      "    ram_util_percent: 4.554838709677418\n",
      "    vram_util_percent0: 0.10749426041325019\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.99491786913513\n",
      "  pid: 70481\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1595095727050427\n",
      "    mean_env_wait_ms: 1.1908716815195073\n",
      "    mean_inference_ms: 5.340708961853831\n",
      "    mean_raw_obs_processing_ms: 0.42495837525267444\n",
      "  time_since_restore: 158.9288833141327\n",
      "  time_this_iter_s: 25.875691413879395\n",
      "  time_total_s: 158.9288833141327\n",
      "  timers:\n",
      "    learn_throughput: 8810.131\n",
      "    learn_time_ms: 18364.313\n",
      "    sample_throughput: 20175.223\n",
      "    sample_time_ms: 8019.341\n",
      "    update_time_ms: 34.565\n",
      "  timestamp: 1605279496\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 970752\n",
      "  training_iteration: 6\n",
      "  trial_id: 44bc1_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 34.0/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_44bc1_00000 | RUNNING  | 172.17.0.14:70481 |      6 |          158.929 | 970752 |  204.485 |              258.111 |              94.1717 |            877.146 |\n",
      "+-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_44bc1_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4331\n",
      "    time_step_mean: 3593.2985318107667\n",
      "    time_step_min: 3254\n",
      "  date: 2020-11-13_15-58-41\n",
      "  done: false\n",
      "  episode_len_mean: 871.7270569620254\n",
      "  episode_reward_max: 258.11111111111154\n",
      "  episode_reward_mean: 206.3003612070066\n",
      "  episode_reward_min: 94.17171717171675\n",
      "  episodes_this_iter: 214\n",
      "  episodes_total: 1264\n",
      "  experiment_id: 1fe2dba03034492ab71511d2fd867765\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.10000000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 1.050749957561493\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.008043673432742557\n",
      "        model: {}\n",
      "        policy_loss: -0.01141265300490583\n",
      "        total_loss: 22.299853483835857\n",
      "        vf_explained_var: 0.960827112197876\n",
      "        vf_loss: 22.310986200968426\n",
      "    num_steps_sampled: 1132544\n",
      "    num_steps_trained: 1132544\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 27.367741935483867\n",
      "    gpu_util_percent0: 0.3058064516129032\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.6864516129032261\n",
      "    ram_util_percent: 4.554838709677418\n",
      "    vram_util_percent0: 0.10749426041325019\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.99491786913513\n",
      "  pid: 70481\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.15866952298949474\n",
      "    mean_env_wait_ms: 1.1929110158252079\n",
      "    mean_inference_ms: 5.252214170748684\n",
      "    mean_raw_obs_processing_ms: 0.42140585519380264\n",
      "  time_since_restore: 184.76769065856934\n",
      "  time_this_iter_s: 25.838807344436646\n",
      "  time_total_s: 184.76769065856934\n",
      "  timers:\n",
      "    learn_throughput: 8806.083\n",
      "    learn_time_ms: 18372.755\n",
      "    sample_throughput: 20428.195\n",
      "    sample_time_ms: 7920.034\n",
      "    update_time_ms: 34.901\n",
      "  timestamp: 1605279521\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1132544\n",
      "  training_iteration: 7\n",
      "  trial_id: 44bc1_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 34.0/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_44bc1_00000 | RUNNING  | 172.17.0.14:70481 |      7 |          184.768 | 1132544 |    206.3 |              258.111 |              94.1717 |            871.727 |\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_44bc1_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4331\n",
      "    time_step_mean: 3582.9942196531792\n",
      "    time_step_min: 3254\n",
      "  date: 2020-11-13_15-59-08\n",
      "  done: false\n",
      "  episode_len_mean: 867.4268635724331\n",
      "  episode_reward_max: 258.11111111111154\n",
      "  episode_reward_mean: 207.98697949963753\n",
      "  episode_reward_min: 94.17171717171675\n",
      "  episodes_this_iter: 158\n",
      "  episodes_total: 1422\n",
      "  experiment_id: 1fe2dba03034492ab71511d2fd867765\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.10000000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 1.0294969379901886\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.006697238772176206\n",
      "        model: {}\n",
      "        policy_loss: -0.011775831662816927\n",
      "        total_loss: 17.086002031962078\n",
      "        vf_explained_var: 0.9662084579467773\n",
      "        vf_loss: 17.097622553507488\n",
      "    num_steps_sampled: 1294336\n",
      "    num_steps_trained: 1294336\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.590625000000003\n",
      "    gpu_util_percent0: 0.40093749999999995\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.899375\n",
      "    ram_util_percent: 4.565625\n",
      "    vram_util_percent0: 0.10749426041325025\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.9949178691351303\n",
      "  pid: 70481\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.15815842258243049\n",
      "    mean_env_wait_ms: 1.194387319772234\n",
      "    mean_inference_ms: 5.199207157361404\n",
      "    mean_raw_obs_processing_ms: 0.4192429238764713\n",
      "  time_since_restore: 210.85888862609863\n",
      "  time_this_iter_s: 26.091197967529297\n",
      "  time_total_s: 210.85888862609863\n",
      "  timers:\n",
      "    learn_throughput: 8804.82\n",
      "    learn_time_ms: 18375.391\n",
      "    sample_throughput: 20535.808\n",
      "    sample_time_ms: 7878.531\n",
      "    update_time_ms: 37.125\n",
      "  timestamp: 1605279548\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1294336\n",
      "  training_iteration: 8\n",
      "  trial_id: 44bc1_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 34.0/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_44bc1_00000 | RUNNING  | 172.17.0.14:70481 |      8 |          210.859 | 1294336 |  207.987 |              258.111 |              94.1717 |            867.427 |\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_44bc1_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4331\n",
      "    time_step_mean: 3573.862516212711\n",
      "    time_step_min: 3254\n",
      "  date: 2020-11-13_15-59-34\n",
      "  done: false\n",
      "  episode_len_mean: 863.9613924050633\n",
      "  episode_reward_max: 258.11111111111154\n",
      "  episode_reward_mean: 209.2149661168647\n",
      "  episode_reward_min: 94.17171717171675\n",
      "  episodes_this_iter: 158\n",
      "  episodes_total: 1580\n",
      "  experiment_id: 1fe2dba03034492ab71511d2fd867765\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.10000000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 1.0066712647676468\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.007880310877226293\n",
      "        model: {}\n",
      "        policy_loss: -0.012617902363369163\n",
      "        total_loss: 19.517973105112713\n",
      "        vf_explained_var: 0.9615465998649597\n",
      "        vf_loss: 19.530305862426758\n",
      "    num_steps_sampled: 1456128\n",
      "    num_steps_trained: 1456128\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 27.56129032258064\n",
      "    gpu_util_percent0: 0.39032258064516134\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.8987096774193549\n",
      "    ram_util_percent: 4.558064516129031\n",
      "    vram_util_percent0: 0.10749426041325019\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.99491786913513\n",
      "  pid: 70481\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.15771198029920874\n",
      "    mean_env_wait_ms: 1.1957063269794654\n",
      "    mean_inference_ms: 5.15319137058607\n",
      "    mean_raw_obs_processing_ms: 0.41729389370710623\n",
      "  time_since_restore: 236.985582113266\n",
      "  time_this_iter_s: 26.12669348716736\n",
      "  time_total_s: 236.985582113266\n",
      "  timers:\n",
      "    learn_throughput: 8812.656\n",
      "    learn_time_ms: 18359.051\n",
      "    sample_throughput: 20554.681\n",
      "    sample_time_ms: 7871.297\n",
      "    update_time_ms: 37.103\n",
      "  timestamp: 1605279574\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1456128\n",
      "  training_iteration: 9\n",
      "  trial_id: 44bc1_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 34.1/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_44bc1_00000 | RUNNING  | 172.17.0.14:70481 |      9 |          236.986 | 1456128 |  209.215 |              258.111 |              94.1717 |            863.961 |\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_44bc1_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4331\n",
      "    time_step_mean: 3562.1980369515013\n",
      "    time_step_min: 3239\n",
      "  date: 2020-11-13_16-00-00\n",
      "  done: false\n",
      "  episode_len_mean: 859.3762711864407\n",
      "  episode_reward_max: 259.6262626262624\n",
      "  episode_reward_mean: 211.1254922102378\n",
      "  episode_reward_min: 94.17171717171675\n",
      "  episodes_this_iter: 190\n",
      "  episodes_total: 1770\n",
      "  experiment_id: 1fe2dba03034492ab71511d2fd867765\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.10000000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 0.9599226117134094\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.006828356456632416\n",
      "        model: {}\n",
      "        policy_loss: -0.011588859987872032\n",
      "        total_loss: 18.616418997446697\n",
      "        vf_explained_var: 0.9711003303527832\n",
      "        vf_loss: 18.62780507405599\n",
      "    num_steps_sampled: 1617920\n",
      "    num_steps_trained: 1617920\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.228125000000002\n",
      "    gpu_util_percent0: 0.37531250000000005\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.9021875\n",
      "    ram_util_percent: 4.553125\n",
      "    vram_util_percent0: 0.10749426041325025\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.9949178691351303\n",
      "  pid: 70481\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.15722836876145782\n",
      "    mean_env_wait_ms: 1.1974080035883716\n",
      "    mean_inference_ms: 5.105349160017012\n",
      "    mean_raw_obs_processing_ms: 0.4152023101963641\n",
      "  time_since_restore: 262.9953718185425\n",
      "  time_this_iter_s: 26.00978970527649\n",
      "  time_total_s: 262.9953718185425\n",
      "  timers:\n",
      "    learn_throughput: 8807.28\n",
      "    learn_time_ms: 18370.257\n",
      "    sample_throughput: 20666.491\n",
      "    sample_time_ms: 7828.712\n",
      "    update_time_ms: 37.338\n",
      "  timestamp: 1605279600\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1617920\n",
      "  training_iteration: 10\n",
      "  trial_id: 44bc1_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 33.9/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_44bc1_00000 | RUNNING  | 172.17.0.14:70481 |     10 |          262.995 | 1617920 |  211.125 |              259.626 |              94.1717 |            859.376 |\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_44bc1_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4331\n",
      "    time_step_mean: 3544.9464285714284\n",
      "    time_step_min: 3211\n",
      "  date: 2020-11-13_16-00-26\n",
      "  done: false\n",
      "  episode_len_mean: 853.889970788705\n",
      "  episode_reward_max: 271.59595959595924\n",
      "  episode_reward_mean: 213.72299922299908\n",
      "  episode_reward_min: 94.17171717171675\n",
      "  episodes_this_iter: 284\n",
      "  episodes_total: 2054\n",
      "  experiment_id: 1fe2dba03034492ab71511d2fd867765\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.10000000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 0.9598761051893234\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.007150520958627264\n",
      "        model: {}\n",
      "        policy_loss: -0.011371820039736727\n",
      "        total_loss: 18.399611949920654\n",
      "        vf_explained_var: 0.9717357754707336\n",
      "        vf_loss: 18.410749276479084\n",
      "    num_steps_sampled: 1779712\n",
      "    num_steps_trained: 1779712\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 27.21290322580645\n",
      "    gpu_util_percent0: 0.38225806451612904\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.900967741935484\n",
      "    ram_util_percent: 4.548387096774193\n",
      "    vram_util_percent0: 0.10749426041325019\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.99491786913513\n",
      "  pid: 70481\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.15664004664878334\n",
      "    mean_env_wait_ms: 1.199433626580824\n",
      "    mean_inference_ms: 5.047133516828721\n",
      "    mean_raw_obs_processing_ms: 0.4126319022389094\n",
      "  time_since_restore: 289.1062467098236\n",
      "  time_this_iter_s: 26.110874891281128\n",
      "  time_total_s: 289.1062467098236\n",
      "  timers:\n",
      "    learn_throughput: 8818.688\n",
      "    learn_time_ms: 18346.493\n",
      "    sample_throughput: 21358.709\n",
      "    sample_time_ms: 7574.99\n",
      "    update_time_ms: 37.07\n",
      "  timestamp: 1605279626\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1779712\n",
      "  training_iteration: 11\n",
      "  trial_id: 44bc1_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 34.0/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_44bc1_00000 | RUNNING  | 172.17.0.14:70481 |     11 |          289.106 | 1779712 |  213.723 |              271.596 |              94.1717 |             853.89 |\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_44bc1_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4331\n",
      "    time_step_mean: 3533.980680772769\n",
      "    time_step_min: 3211\n",
      "  date: 2020-11-13_16-00-52\n",
      "  done: false\n",
      "  episode_len_mean: 850.7938517179024\n",
      "  episode_reward_max: 271.59595959595924\n",
      "  episode_reward_mean: 215.18526585931633\n",
      "  episode_reward_min: 94.17171717171675\n",
      "  episodes_this_iter: 158\n",
      "  episodes_total: 2212\n",
      "  experiment_id: 1fe2dba03034492ab71511d2fd867765\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.10000000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 0.9368449399868647\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.006484963504287104\n",
      "        model: {}\n",
      "        policy_loss: -0.013402911776211113\n",
      "        total_loss: 12.153167327245077\n",
      "        vf_explained_var: 0.9760757088661194\n",
      "        vf_loss: 12.166390180587769\n",
      "    num_steps_sampled: 1941504\n",
      "    num_steps_trained: 1941504\n",
      "  iterations_since_restore: 12\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.374193548387094\n",
      "    gpu_util_percent0: 0.36806451612903224\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.9003225806451615\n",
      "    ram_util_percent: 4.564516129032256\n",
      "    vram_util_percent0: 0.10749426041325019\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.99491786913513\n",
      "  pid: 70481\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1563618452017943\n",
      "    mean_env_wait_ms: 1.2004406362319977\n",
      "    mean_inference_ms: 5.019744209858781\n",
      "    mean_raw_obs_processing_ms: 0.41141323685496994\n",
      "  time_since_restore: 315.02318263053894\n",
      "  time_this_iter_s: 25.916935920715332\n",
      "  time_total_s: 315.02318263053894\n",
      "  timers:\n",
      "    learn_throughput: 8819.651\n",
      "    learn_time_ms: 18344.49\n",
      "    sample_throughput: 21439.718\n",
      "    sample_time_ms: 7546.368\n",
      "    update_time_ms: 38.249\n",
      "  timestamp: 1605279652\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1941504\n",
      "  training_iteration: 12\n",
      "  trial_id: 44bc1_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 34.0/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_44bc1_00000 | RUNNING  | 172.17.0.14:70481 |     12 |          315.023 | 1941504 |  215.185 |              271.596 |              94.1717 |            850.794 |\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_44bc1_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4331\n",
      "    time_step_mean: 3524.106346483705\n",
      "    time_step_min: 3137\n",
      "  date: 2020-11-13_16-01-19\n",
      "  done: false\n",
      "  episode_len_mean: 847.8029535864979\n",
      "  episode_reward_max: 275.0808080808078\n",
      "  episode_reward_mean: 216.70956399437398\n",
      "  episode_reward_min: 94.17171717171675\n",
      "  episodes_this_iter: 158\n",
      "  episodes_total: 2370\n",
      "  experiment_id: 1fe2dba03034492ab71511d2fd867765\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.10000000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 0.9191362957159678\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.006582636230935653\n",
      "        model: {}\n",
      "        policy_loss: -0.011873599124858933\n",
      "        total_loss: 12.296206394831339\n",
      "        vf_explained_var: 0.9736312031745911\n",
      "        vf_loss: 12.307880957921347\n",
      "    num_steps_sampled: 2103296\n",
      "    num_steps_trained: 2103296\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.378125\n",
      "    gpu_util_percent0: 0.35281250000000003\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.9015625\n",
      "    ram_util_percent: 4.55625\n",
      "    vram_util_percent0: 0.10749426041325025\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.9949178691351303\n",
      "  pid: 70481\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.15610174093054538\n",
      "    mean_env_wait_ms: 1.2014015980185921\n",
      "    mean_inference_ms: 4.994742166684988\n",
      "    mean_raw_obs_processing_ms: 0.4102812644021682\n",
      "  time_since_restore: 341.42578744888306\n",
      "  time_this_iter_s: 26.402604818344116\n",
      "  time_total_s: 341.42578744888306\n",
      "  timers:\n",
      "    learn_throughput: 8812.666\n",
      "    learn_time_ms: 18359.029\n",
      "    sample_throughput: 21345.622\n",
      "    sample_time_ms: 7579.634\n",
      "    update_time_ms: 36.355\n",
      "  timestamp: 1605279679\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2103296\n",
      "  training_iteration: 13\n",
      "  trial_id: 44bc1_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 34.0/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_44bc1_00000 | RUNNING  | 172.17.0.14:70481 |     13 |          341.426 | 2103296 |   216.71 |              275.081 |              94.1717 |            847.803 |\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_44bc1_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4331\n",
      "    time_step_mean: 3511.4209708737862\n",
      "    time_step_min: 3137\n",
      "  date: 2020-11-13_16-01-45\n",
      "  done: false\n",
      "  episode_len_mean: 843.9781859931113\n",
      "  episode_reward_max: 275.0808080808078\n",
      "  episode_reward_mean: 218.6553595658072\n",
      "  episode_reward_min: 94.17171717171675\n",
      "  episodes_this_iter: 243\n",
      "  episodes_total: 2613\n",
      "  experiment_id: 1fe2dba03034492ab71511d2fd867765\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.10000000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 0.8822224934895834\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.0060440420638769865\n",
      "        model: {}\n",
      "        policy_loss: -0.00965571446189036\n",
      "        total_loss: 18.076210180918377\n",
      "        vf_explained_var: 0.9740740656852722\n",
      "        vf_loss: 18.085702578226726\n",
      "    num_steps_sampled: 2265088\n",
      "    num_steps_trained: 2265088\n",
      "  iterations_since_restore: 14\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.403030303030302\n",
      "    gpu_util_percent0: 0.3848484848484849\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.9027272727272728\n",
      "    ram_util_percent: 4.551515151515151\n",
      "    vram_util_percent0: 0.10749426041325025\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.9949178691351304\n",
      "  pid: 70481\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.15573144000876263\n",
      "    mean_env_wait_ms: 1.2028278078208832\n",
      "    mean_inference_ms: 4.960968403008039\n",
      "    mean_raw_obs_processing_ms: 0.40876779949941844\n",
      "  time_since_restore: 367.8457407951355\n",
      "  time_this_iter_s: 26.41995334625244\n",
      "  time_total_s: 367.8457407951355\n",
      "  timers:\n",
      "    learn_throughput: 8815.807\n",
      "    learn_time_ms: 18352.488\n",
      "    sample_throughput: 21261.718\n",
      "    sample_time_ms: 7609.545\n",
      "    update_time_ms: 41.804\n",
      "  timestamp: 1605279705\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2265088\n",
      "  training_iteration: 14\n",
      "  trial_id: 44bc1_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 34.0/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_44bc1_00000 | RUNNING  | 172.17.0.14:70481 |     14 |          367.846 | 2265088 |  218.655 |              275.081 |              94.1717 |            843.978 |\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_44bc1_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4331\n",
      "    time_step_mean: 3499.6650035637917\n",
      "    time_step_min: 3137\n",
      "  date: 2020-11-13_16-02-11\n",
      "  done: false\n",
      "  episode_len_mean: 841.007735583685\n",
      "  episode_reward_max: 275.0808080808078\n",
      "  episode_reward_mean: 220.3711055704725\n",
      "  episode_reward_min: 94.17171717171675\n",
      "  episodes_this_iter: 231\n",
      "  episodes_total: 2844\n",
      "  experiment_id: 1fe2dba03034492ab71511d2fd867765\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.10000000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 0.869914228717486\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.006756370111058156\n",
      "        model: {}\n",
      "        policy_loss: -0.010439761041197926\n",
      "        total_loss: 10.453549146652222\n",
      "        vf_explained_var: 0.9820606708526611\n",
      "        vf_loss: 10.46374797821045\n",
      "    num_steps_sampled: 2426880\n",
      "    num_steps_trained: 2426880\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 27.454838709677425\n",
      "    gpu_util_percent0: 0.332258064516129\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.9\n",
      "    ram_util_percent: 4.548387096774193\n",
      "    vram_util_percent0: 0.10749426041325019\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.99491786913513\n",
      "  pid: 70481\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.15543573874792355\n",
      "    mean_env_wait_ms: 1.2039204889617638\n",
      "    mean_inference_ms: 4.932749428763862\n",
      "    mean_raw_obs_processing_ms: 0.4075121123122301\n",
      "  time_since_restore: 393.8634331226349\n",
      "  time_this_iter_s: 26.01769232749939\n",
      "  time_total_s: 393.8634331226349\n",
      "  timers:\n",
      "    learn_throughput: 8802.726\n",
      "    learn_time_ms: 18379.76\n",
      "    sample_throughput: 21278.158\n",
      "    sample_time_ms: 7603.666\n",
      "    update_time_ms: 41.821\n",
      "  timestamp: 1605279731\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2426880\n",
      "  training_iteration: 15\n",
      "  trial_id: 44bc1_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 34.1/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_44bc1_00000 | RUNNING  | 172.17.0.14:70481 |     15 |          393.863 | 2426880 |  220.371 |              275.081 |              94.1717 |            841.008 |\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_44bc1_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4331\n",
      "    time_step_mean: 3492.272267206478\n",
      "    time_step_min: 3137\n",
      "  date: 2020-11-13_16-02-38\n",
      "  done: false\n",
      "  episode_len_mean: 839.6252498334444\n",
      "  episode_reward_max: 275.0808080808078\n",
      "  episode_reward_mean: 221.38953155808574\n",
      "  episode_reward_min: 94.17171717171675\n",
      "  episodes_this_iter: 158\n",
      "  episodes_total: 3002\n",
      "  experiment_id: 1fe2dba03034492ab71511d2fd867765\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.10000000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 0.8655613213777542\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.006051631411537528\n",
      "        model: {}\n",
      "        policy_loss: -0.009812191880579727\n",
      "        total_loss: 11.92350180943807\n",
      "        vf_explained_var: 0.9765844345092773\n",
      "        vf_loss: 11.933141708374023\n",
      "    num_steps_sampled: 2588672\n",
      "    num_steps_trained: 2588672\n",
      "  iterations_since_restore: 16\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 25.971875\n",
      "    gpu_util_percent0: 0.31156249999999996\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.7378125\n",
      "    ram_util_percent: 4.5625\n",
      "    vram_util_percent0: 0.10749426041325025\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.9949178691351303\n",
      "  pid: 70481\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.15524793732102354\n",
      "    mean_env_wait_ms: 1.204554695422878\n",
      "    mean_inference_ms: 4.915526762895821\n",
      "    mean_raw_obs_processing_ms: 0.4067600038666165\n",
      "  time_since_restore: 420.24772572517395\n",
      "  time_this_iter_s: 26.384292602539062\n",
      "  time_total_s: 420.24772572517395\n",
      "  timers:\n",
      "    learn_throughput: 8785.341\n",
      "    learn_time_ms: 18416.132\n",
      "    sample_throughput: 21243.537\n",
      "    sample_time_ms: 7616.057\n",
      "    update_time_ms: 42.16\n",
      "  timestamp: 1605279758\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2588672\n",
      "  training_iteration: 16\n",
      "  trial_id: 44bc1_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 33.9/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_44bc1_00000 | RUNNING  | 172.17.0.14:70481 |     16 |          420.248 | 2588672 |   221.39 |              275.081 |              94.1717 |            839.625 |\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_44bc1_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4331\n",
      "    time_step_mean: 3486.134529147982\n",
      "    time_step_min: 3137\n",
      "  date: 2020-11-13_16-03-04\n",
      "  done: false\n",
      "  episode_len_mean: 838.4851265822784\n",
      "  episode_reward_max: 275.0808080808078\n",
      "  episode_reward_mean: 222.3473021352767\n",
      "  episode_reward_min: 94.17171717171675\n",
      "  episodes_this_iter: 158\n",
      "  episodes_total: 3160\n",
      "  experiment_id: 1fe2dba03034492ab71511d2fd867765\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.10000000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 0.8529934187730154\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.00609724607784301\n",
      "        model: {}\n",
      "        policy_loss: -0.01221277475512276\n",
      "        total_loss: 11.20840040842692\n",
      "        vf_explained_var: 0.977841317653656\n",
      "        vf_loss: 11.220430135726929\n",
      "    num_steps_sampled: 2750464\n",
      "    num_steps_trained: 2750464\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.76875\n",
      "    gpu_util_percent0: 0.3046875\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.9003125000000001\n",
      "    ram_util_percent: 4.5625\n",
      "    vram_util_percent0: 0.10749426041325025\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.9949178691351303\n",
      "  pid: 70481\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.15507150615768875\n",
      "    mean_env_wait_ms: 1.205124807273066\n",
      "    mean_inference_ms: 4.899512820813055\n",
      "    mean_raw_obs_processing_ms: 0.4060501963971917\n",
      "  time_since_restore: 446.4961271286011\n",
      "  time_this_iter_s: 26.248401403427124\n",
      "  time_total_s: 446.4961271286011\n",
      "  timers:\n",
      "    learn_throughput: 8786.673\n",
      "    learn_time_ms: 18413.339\n",
      "    sample_throughput: 21123.096\n",
      "    sample_time_ms: 7659.483\n",
      "    update_time_ms: 41.956\n",
      "  timestamp: 1605279784\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2750464\n",
      "  training_iteration: 17\n",
      "  trial_id: 44bc1_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 34.1/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_44bc1_00000 | RUNNING  | 172.17.0.14:70481 |     17 |          446.496 | 2750464 |  222.347 |              275.081 |              94.1717 |            838.485 |\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_44bc1_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4331\n",
      "    time_step_mean: 3476.3706769139817\n",
      "    time_step_min: 3137\n",
      "  date: 2020-11-13_16-03-30\n",
      "  done: false\n",
      "  episode_len_mean: 836.8444899152295\n",
      "  episode_reward_max: 275.0808080808078\n",
      "  episode_reward_mean: 223.73200877527086\n",
      "  episode_reward_min: 94.17171717171675\n",
      "  episodes_this_iter: 261\n",
      "  episodes_total: 3421\n",
      "  experiment_id: 1fe2dba03034492ab71511d2fd867765\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.10000000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 0.8076178232828776\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.006340657981733481\n",
      "        model: {}\n",
      "        policy_loss: -0.010811606732507547\n",
      "        total_loss: 14.727666219075521\n",
      "        vf_explained_var: 0.979902982711792\n",
      "        vf_loss: 14.738247791926065\n",
      "    num_steps_sampled: 2912256\n",
      "    num_steps_trained: 2912256\n",
      "  iterations_since_restore: 18\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.109375\n",
      "    gpu_util_percent0: 0.41875\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.9006250000000001\n",
      "    ram_util_percent: 4.55\n",
      "    vram_util_percent0: 0.10749426041325025\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.9949178691351303\n",
      "  pid: 70481\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1547976793006102\n",
      "    mean_env_wait_ms: 1.2059350347411184\n",
      "    mean_inference_ms: 4.8752279456839736\n",
      "    mean_raw_obs_processing_ms: 0.4049525095118234\n",
      "  time_since_restore: 472.4524428844452\n",
      "  time_this_iter_s: 25.956315755844116\n",
      "  time_total_s: 472.4524428844452\n",
      "  timers:\n",
      "    learn_throughput: 8788.561\n",
      "    learn_time_ms: 18409.385\n",
      "    sample_throughput: 21149.262\n",
      "    sample_time_ms: 7650.007\n",
      "    update_time_ms: 41.592\n",
      "  timestamp: 1605279810\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2912256\n",
      "  training_iteration: 18\n",
      "  trial_id: 44bc1_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 34.0/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_44bc1_00000 | RUNNING  | 172.17.0.14:70481 |     18 |          472.452 | 2912256 |  223.732 |              275.081 |              94.1717 |            836.844 |\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_44bc1_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4331\n",
      "    time_step_mean: 3469.389599555061\n",
      "    time_step_min: 3137\n",
      "  date: 2020-11-13_16-03-57\n",
      "  done: false\n",
      "  episode_len_mean: 835.7493120528344\n",
      "  episode_reward_max: 275.0808080808078\n",
      "  episode_reward_mean: 224.70714853543683\n",
      "  episode_reward_min: 94.17171717171675\n",
      "  episodes_this_iter: 213\n",
      "  episodes_total: 3634\n",
      "  experiment_id: 1fe2dba03034492ab71511d2fd867765\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.10000000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 0.8023275434970856\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.006623488656866054\n",
      "        model: {}\n",
      "        policy_loss: -0.013457847574803358\n",
      "        total_loss: 10.511393785476685\n",
      "        vf_explained_var: 0.9825028777122498\n",
      "        vf_loss: 10.524590412775675\n",
      "    num_steps_sampled: 3074048\n",
      "    num_steps_trained: 3074048\n",
      "  iterations_since_restore: 19\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.506451612903227\n",
      "    gpu_util_percent0: 0.3258064516129032\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.9038709677419354\n",
      "    ram_util_percent: 4.548387096774193\n",
      "    vram_util_percent0: 0.10749426041325019\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.99491786913513\n",
      "  pid: 70481\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1546185149221406\n",
      "    mean_env_wait_ms: 1.2065403139138615\n",
      "    mean_inference_ms: 4.858175879814769\n",
      "    mean_raw_obs_processing_ms: 0.40423188251269754\n",
      "  time_since_restore: 498.6512351036072\n",
      "  time_this_iter_s: 26.198792219161987\n",
      "  time_total_s: 498.6512351036072\n",
      "  timers:\n",
      "    learn_throughput: 8776.075\n",
      "    learn_time_ms: 18435.577\n",
      "    sample_throughput: 21205.466\n",
      "    sample_time_ms: 7629.731\n",
      "    update_time_ms: 41.749\n",
      "  timestamp: 1605279837\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3074048\n",
      "  training_iteration: 19\n",
      "  trial_id: 44bc1_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 34.1/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_44bc1_00000 | RUNNING  | 172.17.0.14:70481 |     19 |          498.651 | 3074048 |  224.707 |              275.081 |              94.1717 |            835.749 |\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_44bc1_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4331\n",
      "    time_step_mean: 3464.39557805008\n",
      "    time_step_min: 3137\n",
      "  date: 2020-11-13_16-04-23\n",
      "  done: false\n",
      "  episode_len_mean: 834.5690928270042\n",
      "  episode_reward_max: 275.0808080808078\n",
      "  episode_reward_mean: 225.48824478966873\n",
      "  episode_reward_min: 94.17171717171675\n",
      "  episodes_this_iter: 158\n",
      "  episodes_total: 3792\n",
      "  experiment_id: 1fe2dba03034492ab71511d2fd867765\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.10000000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 0.7999656200408936\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.006276474799960852\n",
      "        model: {}\n",
      "        policy_loss: -0.012805758247850463\n",
      "        total_loss: 8.937258243560791\n",
      "        vf_explained_var: 0.981889545917511\n",
      "        vf_loss: 8.949836254119873\n",
      "    num_steps_sampled: 3235840\n",
      "    num_steps_trained: 3235840\n",
      "  iterations_since_restore: 20\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 25.90606060606061\n",
      "    gpu_util_percent0: 0.38030303030303036\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.9006060606060605\n",
      "    ram_util_percent: 4.5606060606060606\n",
      "    vram_util_percent0: 0.10749426041325025\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.9949178691351304\n",
      "  pid: 70481\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.15448627605125717\n",
      "    mean_env_wait_ms: 1.2069134314191945\n",
      "    mean_inference_ms: 4.84618722054316\n",
      "    mean_raw_obs_processing_ms: 0.4037122599157926\n",
      "  time_since_restore: 525.3857052326202\n",
      "  time_this_iter_s: 26.73447012901306\n",
      "  time_total_s: 525.3857052326202\n",
      "  timers:\n",
      "    learn_throughput: 8771.844\n",
      "    learn_time_ms: 18444.469\n",
      "    sample_throughput: 21030.281\n",
      "    sample_time_ms: 7693.288\n",
      "    update_time_ms: 41.181\n",
      "  timestamp: 1605279863\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3235840\n",
      "  training_iteration: 20\n",
      "  trial_id: 44bc1_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 34.0/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_44bc1_00000 | RUNNING  | 172.17.0.14:70481 |     20 |          525.386 | 3235840 |  225.488 |              275.081 |              94.1717 |            834.569 |\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_44bc1_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4331\n",
      "    time_step_mean: 3460.355975485189\n",
      "    time_step_min: 3137\n",
      "  date: 2020-11-13_16-04-50\n",
      "  done: false\n",
      "  episode_len_mean: 833.5460293373799\n",
      "  episode_reward_max: 275.0808080808078\n",
      "  episode_reward_mean: 226.09428120353752\n",
      "  episode_reward_min: 94.17171717171675\n",
      "  episodes_this_iter: 162\n",
      "  episodes_total: 3954\n",
      "  experiment_id: 1fe2dba03034492ab71511d2fd867765\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.10000000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 0.7837512443463007\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.006301244177545111\n",
      "        model: {}\n",
      "        policy_loss: -0.009973630212092152\n",
      "        total_loss: 12.000240484873453\n",
      "        vf_explained_var: 0.9783788323402405\n",
      "        vf_loss: 12.009976069132486\n",
      "    num_steps_sampled: 3397632\n",
      "    num_steps_trained: 3397632\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 27.158064516129038\n",
      "    gpu_util_percent0: 0.34161290322580645\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.9006451612903228\n",
      "    ram_util_percent: 4.561290322580644\n",
      "    vram_util_percent0: 0.10749426041325019\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.99491786913513\n",
      "  pid: 70481\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.15435908301872345\n",
      "    mean_env_wait_ms: 1.2072847034739855\n",
      "    mean_inference_ms: 4.8346830445873215\n",
      "    mean_raw_obs_processing_ms: 0.40321873130467956\n",
      "  time_since_restore: 551.4643113613129\n",
      "  time_this_iter_s: 26.078606128692627\n",
      "  time_total_s: 551.4643113613129\n",
      "  timers:\n",
      "    learn_throughput: 8767.308\n",
      "    learn_time_ms: 18454.011\n",
      "    sample_throughput: 21068.918\n",
      "    sample_time_ms: 7679.179\n",
      "    update_time_ms: 41.169\n",
      "  timestamp: 1605279890\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3397632\n",
      "  training_iteration: 21\n",
      "  trial_id: 44bc1_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 34.2/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_44bc1_00000 | RUNNING  | 172.17.0.14:70481 |     21 |          551.464 | 3397632 |  226.094 |              275.081 |              94.1717 |            833.546 |\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_44bc1_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4331\n",
      "    time_step_mean: 3452.2257604562737\n",
      "    time_step_min: 3137\n",
      "  date: 2020-11-13_16-05-16\n",
      "  done: false\n",
      "  episode_len_mean: 831.3320772491757\n",
      "  episode_reward_max: 277.95959595959596\n",
      "  episode_reward_mean: 227.39724850958942\n",
      "  episode_reward_min: 94.17171717171675\n",
      "  episodes_this_iter: 292\n",
      "  episodes_total: 4246\n",
      "  experiment_id: 1fe2dba03034492ab71511d2fd867765\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.10000000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 0.7486037959655126\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.0056666231248527765\n",
      "        model: {}\n",
      "        policy_loss: -0.008480945301319784\n",
      "        total_loss: 12.359157085418701\n",
      "        vf_explained_var: 0.9832012057304382\n",
      "        vf_loss: 12.367445786794027\n",
      "    num_steps_sampled: 3559424\n",
      "    num_steps_trained: 3559424\n",
      "  iterations_since_restore: 22\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.493939393939396\n",
      "    gpu_util_percent0: 0.35909090909090907\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.9021212121212121\n",
      "    ram_util_percent: 4.548484848484848\n",
      "    vram_util_percent0: 0.10749426041325025\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.9949178691351304\n",
      "  pid: 70481\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.15414772605404603\n",
      "    mean_env_wait_ms: 1.2079376887755962\n",
      "    mean_inference_ms: 4.815548063419979\n",
      "    mean_raw_obs_processing_ms: 0.40242248697139055\n",
      "  time_since_restore: 577.9976608753204\n",
      "  time_this_iter_s: 26.53334951400757\n",
      "  time_total_s: 577.9976608753204\n",
      "  timers:\n",
      "    learn_throughput: 8751.512\n",
      "    learn_time_ms: 18487.32\n",
      "    sample_throughput: 20995.064\n",
      "    sample_time_ms: 7706.192\n",
      "    update_time_ms: 41.491\n",
      "  timestamp: 1605279916\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3559424\n",
      "  training_iteration: 22\n",
      "  trial_id: 44bc1_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 34.0/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_44bc1_00000 | RUNNING  | 172.17.0.14:70481 |     22 |          577.998 | 3559424 |  227.397 |               277.96 |              94.1717 |            831.332 |\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_44bc1_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4331\n",
      "    time_step_mean: 3448.140218878249\n",
      "    time_step_min: 3137\n",
      "  date: 2020-11-13_16-05-43\n",
      "  done: true\n",
      "  episode_len_mean: 830.0617088607595\n",
      "  episode_reward_max: 277.95959595959596\n",
      "  episode_reward_mean: 228.04384715144195\n",
      "  episode_reward_min: 94.17171717171675\n",
      "  episodes_this_iter: 178\n",
      "  episodes_total: 4424\n",
      "  experiment_id: 1fe2dba03034492ab71511d2fd867765\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.10000000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 0.747838502128919\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.005688092593724529\n",
      "        model: {}\n",
      "        policy_loss: -0.01070123784787332\n",
      "        total_loss: 8.68484377861023\n",
      "        vf_explained_var: 0.9842017292976379\n",
      "        vf_loss: 8.69535001118978\n",
      "    num_steps_sampled: 3721216\n",
      "    num_steps_trained: 3721216\n",
      "  iterations_since_restore: 23\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.36875\n",
      "    gpu_util_percent0: 0.3909375\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.900625\n",
      "    ram_util_percent: 4.553125\n",
      "    vram_util_percent0: 0.10749426041325025\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.9949178691351303\n",
      "  pid: 70481\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.15403377957775954\n",
      "    mean_env_wait_ms: 1.2082577670281556\n",
      "    mean_inference_ms: 4.804941391019974\n",
      "    mean_raw_obs_processing_ms: 0.4019684953009985\n",
      "  time_since_restore: 604.2819340229034\n",
      "  time_this_iter_s: 26.284273147583008\n",
      "  time_total_s: 604.2819340229034\n",
      "  timers:\n",
      "    learn_throughput: 8746.237\n",
      "    learn_time_ms: 18498.47\n",
      "    sample_throughput: 21068.725\n",
      "    sample_time_ms: 7679.25\n",
      "    update_time_ms: 44.481\n",
      "  timestamp: 1605279943\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3721216\n",
      "  training_iteration: 23\n",
      "  trial_id: 44bc1_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 34.1/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 TERMINATED)\n",
      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_44bc1_00000 | TERMINATED |       |     23 |          604.282 | 3721216 |  228.044 |               277.96 |              94.1717 |            830.062 |\n",
      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Memory usage on this node: 34.1/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 TERMINATED)\n",
      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_44bc1_00000 | TERMINATED |       |     23 |          604.282 | 3721216 |  228.044 |               277.96 |              94.1717 |            830.062 |\n",
      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "2020-11-13 16:05:43,907\tINFO tune.py:439 -- Total run time: 615.76 seconds (615.17 seconds for the tuning loop).\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 70183\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: /JSS/JSS/wandb/run-20201113_155522-1owodlzz/logs/debug.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: /JSS/JSS/wandb/run-20201113_155522-1owodlzz/logs/debug-internal.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3137\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 621\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1605279943\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 4331\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 3448.14022\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 277.9596\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 94.17172\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 228.04385\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 4424\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 23\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mdriven-sweep-2\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_4/runs/1owodlzz\u001b[0m\n",
      "2020-11-13 16:05:54,259 - wandb.wandb_agent - INFO - Cleaning up finished run: 1owodlzz\n",
      "2020-11-13 16:05:54,572 - wandb.wandb_agent - INFO - Agent received command: run\n",
      "2020-11-13 16:05:54,572 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
      "\tinstance_path: /JSS/JSS/env/instances/ta53\n",
      "2020-11-13 16:05:54,574 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --instance_path=/JSS/JSS/env/instances/ta53\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mancient-sweep-3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_4/sweeps/2rk3apl0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_4/runs/85mbst4n\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /JSS/JSS/wandb/run-20201113_160556-85mbst4n\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
      "\n",
      "2020-11-13 16:05:59,589 - wandb.wandb_agent - INFO - Running runs: ['85mbst4n']\n",
      "2020-11-13 16:05:59,737\tINFO services.py:1090 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
      "== Status ==\n",
      "Memory usage on this node: 17.0/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------+\n",
      "| Trial name              | status   | loc   |\n",
      "|-------------------------+----------+-------|\n",
      "| PPO_jss_env_be844_00000 | RUNNING  |       |\n",
      "+-------------------------+----------+-------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=14213)\u001b[0m 2020-11-13 16:06:03,562\tINFO trainer.py:617 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=14173)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14173)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14155)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14155)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14078)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14078)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14094)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14094)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14090)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14090)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14084)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14084)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14093)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14093)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14085)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14085)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14091)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14091)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14127)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14127)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14210)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14210)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14154)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14154)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14197)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14197)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14129)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14129)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14126)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14126)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14138)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14138)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14134)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14134)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14199)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14199)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14150)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14150)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14184)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14184)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14149)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14149)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14164)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14164)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14141)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14141)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14145)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14145)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14189)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14189)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14148)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14148)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14192)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14192)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14167)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14167)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14153)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14153)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14188)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14188)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14165)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14165)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14160)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14160)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14215)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14215)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14143)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14143)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14179)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14179)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14137)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14137)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14139)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14139)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14186)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14186)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14169)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14169)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14161)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14161)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14152)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14152)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14202)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14202)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14136)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14136)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14079)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14079)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14120)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14120)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14088)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14088)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14124)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14124)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14099)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14099)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14092)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14092)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14080)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14080)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14121)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14121)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14204)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14204)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14133)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14133)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14101)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14101)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14130)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14130)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14206)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14206)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14103)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14103)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14096)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14096)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14182)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14182)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14083)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14083)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14082)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14082)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14086)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14086)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14089)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14089)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14081)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14081)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14140)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14140)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14144)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14144)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14158)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14158)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14132)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14132)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14097)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14097)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14175)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14175)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14128)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14128)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14087)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14087)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14131)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14131)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14125)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14125)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14172)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14172)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14135)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14135)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14151)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14151)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14176)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14176)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=14187)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=14187)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "Result for PPO_jss_env_be844_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 3669\n",
      "    time_step_mean: 3363.603448275862\n",
      "    time_step_min: 3125\n",
      "  date: 2020-11-13_16-06-40\n",
      "  done: false\n",
      "  episode_len_mean: 881.5316455696203\n",
      "  episode_reward_max: 283.8080808080806\n",
      "  episode_reward_mean: 244.05069684183616\n",
      "  episode_reward_min: 164.4141414141411\n",
      "  episodes_this_iter: 158\n",
      "  episodes_total: 158\n",
      "  experiment_id: dcc88113fcfd4d659700d89b6d0bf564\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.20000000000000004\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 1.1715543866157532\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.00394408325276648\n",
      "        model: {}\n",
      "        policy_loss: -0.007785314014957597\n",
      "        total_loss: 516.1754811604818\n",
      "        vf_explained_var: 0.48966696858406067\n",
      "        vf_loss: 516.1830622355143\n",
      "    num_steps_sampled: 161792\n",
      "    num_steps_trained: 161792\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 30.886111111111113\n",
      "    gpu_util_percent0: 0.2511111111111111\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.7450000000000001\n",
      "    ram_util_percent: 4.316666666666666\n",
      "    vram_util_percent0: 0.08761069203017381\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.9949178691351303\n",
      "  pid: 14213\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.17069182082361997\n",
      "    mean_env_wait_ms: 1.1491829953689787\n",
      "    mean_inference_ms: 6.437734131019547\n",
      "    mean_raw_obs_processing_ms: 0.46933520388625294\n",
      "  time_since_restore: 29.765793561935425\n",
      "  time_this_iter_s: 29.765793561935425\n",
      "  time_total_s: 29.765793561935425\n",
      "  timers:\n",
      "    learn_throughput: 8303.607\n",
      "    learn_time_ms: 19484.544\n",
      "    sample_throughput: 15837.342\n",
      "    sample_time_ms: 10215.856\n",
      "    update_time_ms: 32.938\n",
      "  timestamp: 1605280000\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 161792\n",
      "  training_iteration: 1\n",
      "  trial_id: be844_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 33.4/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_be844_00000 | RUNNING  | 172.17.0.14:14213 |      1 |          29.7658 | 161792 |  244.051 |              283.808 |              164.414 |            881.532 |\n",
      "+-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_be844_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 3887\n",
      "    time_step_mean: 3383.4598540145985\n",
      "    time_step_min: 3125\n",
      "  date: 2020-11-13_16-07-08\n",
      "  done: false\n",
      "  episode_len_mean: 881.2373417721519\n",
      "  episode_reward_max: 283.8080808080806\n",
      "  episode_reward_mean: 241.74920086945414\n",
      "  episode_reward_min: 164.4141414141411\n",
      "  episodes_this_iter: 158\n",
      "  episodes_total: 316\n",
      "  experiment_id: dcc88113fcfd4d659700d89b6d0bf564\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.10000000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 1.1413444181283314\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.007237302178206543\n",
      "        model: {}\n",
      "        policy_loss: -0.008619486619863892\n",
      "        total_loss: 138.6196492513021\n",
      "        vf_explained_var: 0.7862326502799988\n",
      "        vf_loss: 138.62811660766602\n",
      "    num_steps_sampled: 323584\n",
      "    num_steps_trained: 323584\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 27.318181818181813\n",
      "    gpu_util_percent0: 0.3054545454545455\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.8975757575757576\n",
      "    ram_util_percent: 4.542424242424242\n",
      "    vram_util_percent0: 0.10749426041325025\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.9949178691351304\n",
      "  pid: 14213\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.16700294004995186\n",
      "    mean_env_wait_ms: 1.1441726760130417\n",
      "    mean_inference_ms: 6.062729440884565\n",
      "    mean_raw_obs_processing_ms: 0.454724498730335\n",
      "  time_since_restore: 57.07484984397888\n",
      "  time_this_iter_s: 27.309056282043457\n",
      "  time_total_s: 57.07484984397888\n",
      "  timers:\n",
      "    learn_throughput: 8380.159\n",
      "    learn_time_ms: 19306.554\n",
      "    sample_throughput: 17658.451\n",
      "    sample_time_ms: 9162.298\n",
      "    update_time_ms: 26.92\n",
      "  timestamp: 1605280028\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 323584\n",
      "  training_iteration: 2\n",
      "  trial_id: be844_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 34.0/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_be844_00000 | RUNNING  | 172.17.0.14:14213 |      2 |          57.0748 | 323584 |  241.749 |              283.808 |              164.414 |            881.237 |\n",
      "+-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_be844_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 3887\n",
      "    time_step_mean: 3389.472222222222\n",
      "    time_step_min: 3125\n",
      "  date: 2020-11-13_16-07-35\n",
      "  done: false\n",
      "  episode_len_mean: 875.8354430379746\n",
      "  episode_reward_max: 283.8080808080806\n",
      "  episode_reward_mean: 241.80514000767175\n",
      "  episode_reward_min: 164.4141414141411\n",
      "  episodes_this_iter: 158\n",
      "  episodes_total: 474\n",
      "  experiment_id: dcc88113fcfd4d659700d89b6d0bf564\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.10000000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 1.1273849407831829\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.0100278170624127\n",
      "        model: {}\n",
      "        policy_loss: -0.012776134710293263\n",
      "        total_loss: 56.055432637532554\n",
      "        vf_explained_var: 0.8890635967254639\n",
      "        vf_loss: 56.06777127583822\n",
      "    num_steps_sampled: 485376\n",
      "    num_steps_trained: 485376\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.424242424242426\n",
      "    gpu_util_percent0: 0.26878787878787874\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.8978787878787878\n",
      "    ram_util_percent: 4.557575757575758\n",
      "    vram_util_percent0: 0.10749426041325025\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.9949178691351304\n",
      "  pid: 14213\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1646005657474401\n",
      "    mean_env_wait_ms: 1.1426141677440527\n",
      "    mean_inference_ms: 5.809013339159433\n",
      "    mean_raw_obs_processing_ms: 0.4450430515663428\n",
      "  time_since_restore: 84.04224634170532\n",
      "  time_this_iter_s: 26.96739649772644\n",
      "  time_total_s: 84.04224634170532\n",
      "  timers:\n",
      "    learn_throughput: 8396.236\n",
      "    learn_time_ms: 19269.586\n",
      "    sample_throughput: 18657.125\n",
      "    sample_time_ms: 8671.861\n",
      "    update_time_ms: 25.71\n",
      "  timestamp: 1605280055\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 485376\n",
      "  training_iteration: 3\n",
      "  trial_id: be844_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 33.8/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_be844_00000 | RUNNING  | 172.17.0.14:14213 |      3 |          84.0422 | 485376 |  241.805 |              283.808 |              164.414 |            875.835 |\n",
      "+-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_be844_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 3887\n",
      "    time_step_mean: 3384.905084745763\n",
      "    time_step_min: 3073\n",
      "  date: 2020-11-13_16-08-02\n",
      "  done: false\n",
      "  episode_len_mean: 871.1629746835443\n",
      "  episode_reward_max: 289.5656565656569\n",
      "  episode_reward_mean: 241.86571410305595\n",
      "  episode_reward_min: 164.4141414141411\n",
      "  episodes_this_iter: 158\n",
      "  episodes_total: 632\n",
      "  experiment_id: dcc88113fcfd4d659700d89b6d0bf564\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.10000000000000002\n",
      "        cur_lr: 5.0e-05\n",
      "        entropy: 1.1123367249965668\n",
      "        entropy_coeff: 0.0005000000000000001\n",
      "        kl: 0.008589126247291764\n",
      "        model: {}\n",
      "        policy_loss: -0.01170988604038333\n",
      "        total_loss: 45.69587484995524\n",
      "        vf_explained_var: 0.9131764769554138\n",
      "        vf_loss: 45.70728079477946\n",
      "    num_steps_sampled: 647168\n",
      "    num_steps_trained: 647168\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.254545454545454\n",
      "    gpu_util_percent0: 0.36363636363636365\n",
      "    gpu_util_percent1: 0.0\n",
      "    gpu_util_percent2: 0.9018181818181819\n",
      "    ram_util_percent: 4.5606060606060606\n",
      "    vram_util_percent0: 0.10749426041325025\n",
      "    vram_util_percent1: 0.0\n",
      "    vram_util_percent2: 0.9949178691351304\n",
      "  pid: 14213\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.16287073731544346\n",
      "    mean_env_wait_ms: 1.1426755431155544\n",
      "    mean_inference_ms: 5.630816383098376\n",
      "    mean_raw_obs_processing_ms: 0.43763058341130745\n",
      "  time_since_restore: 110.91626715660095\n",
      "  time_this_iter_s: 26.87402081489563\n",
      "  time_total_s: 110.91626715660095\n",
      "  timers:\n",
      "    learn_throughput: 8424.026\n",
      "    learn_time_ms: 19206.019\n",
      "    sample_throughput: 19179.186\n",
      "    sample_time_ms: 8435.811\n",
      "    update_time_ms: 38.522\n",
      "  timestamp: 1605280082\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 647168\n",
      "  training_iteration: 4\n",
      "  trial_id: be844_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 34.0/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_be844_00000 | RUNNING  | 172.17.0.14:14213 |      4 |          110.916 | 647168 |  241.866 |              289.566 |              164.414 |            871.163 |\n",
      "+-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wandb agent 2rk3apl0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
