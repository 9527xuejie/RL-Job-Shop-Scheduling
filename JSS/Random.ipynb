{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have detected 80 CPUs here, so I'm going to create 79 actors\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import multiprocessing as mp\n",
    "import plotly.io as pio\n",
    "import ray\n",
    "from ray import tune\n",
    "\n",
    "from JSS.CustomCallbacks import CustomCallbacks\n",
    "from JSS.env.JSS import JSS\n",
    "from ray.rllib.agents.ppo import ppo, PPOTrainer\n",
    "\n",
    "from ray.tune.logger import DEFAULT_LOGGERS\n",
    "from ray.tune.integration.wandb import WandbLogger\n",
    "\n",
    "from JSS.env_wrapper import BestActionsWrapper\n",
    "\n",
    "from JSS.models import FCMaskedActionsModel\n",
    "\n",
    "pio.orca.config.use_xvfb = True\n",
    "import wandb\n",
    "\n",
    "'''\n",
    "            'lr': {\n",
    "                'values': [5e-5, 1e-5]\n",
    "            },\n",
    "            'lambda': {\n",
    "                'values': [0.90, 0.95, 1.0]\n",
    "            },\n",
    "            'clip_param': {\n",
    "                'values': [0.2, 0.3, 0.4]\n",
    "            },\n",
    "            'num_sgd_iter': {\n",
    "                'values': [30, 35, 40]\n",
    "            },\n",
    "            'entropy_coeff': {\n",
    "                'values': [0.0, 1e-4]\n",
    "            }\n",
    "'''\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"I have detected {} CPUs here, so I'm going to create {} actors\".format(mp.cpu_count(), mp.cpu_count() - 1))\n",
    "    os.environ[\"WANDB_API_KEY\"] = '3487a01956bf67cc7882bca2a38f70c8c95f8463'\n",
    "    sweep_config = {\n",
    "        'program': 'random_loop.py',\n",
    "        'method': 'grid',\n",
    "        'metric': {\n",
    "            'name': 'time_step_min',\n",
    "            'goal': 'minimize',\n",
    "        },\n",
    "        'parameters': {\n",
    "            'instance_path': {\n",
    "                'values': ['/JSS/JSS/env/instances/ta51', '/JSS/JSS/env/instances/ta52', '/JSS/JSS/env/instances/ta53', '/JSS/JSS/env/instances/ta54',\n",
    "                           '/JSS/JSS/env/instances/ta55', '/JSS/JSS/env/instances/ta56', '/JSS/JSS/env/instances/ta57', '/JSS/JSS/env/instances/ta58',\n",
    "                           '/JSS/JSS/env/instances/ta59', '/JSS/JSS/env/instances/ta60']\n",
    "            }\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: a1j4vbxx\n",
      "Sweep URL: https://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/a1j4vbxx\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"RLLIB_SWEEP_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Starting wandb agent üïµÔ∏è\n",
      "2020-10-13 10:35:50,641 - wandb.wandb_agent - INFO - Running runs: []\n",
      "2020-10-13 10:35:50,967 - wandb.wandb_agent - INFO - Agent received command: run\n",
      "2020-10-13 10:35:50,967 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
      "\tinstance_path: /JSS/JSS/env/instances/ta51\n",
      "2020-10-13 10:35:50,969 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python random_loop.py --instance_path=/JSS/JSS/env/instances/ta51\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfeasible-sweep-1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/a1j4vbxx\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/aj5xawms\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201013_103552-aj5xawms\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
      "\n",
      "2020-10-13 10:35:55,986 - wandb.wandb_agent - INFO - Running runs: ['aj5xawms']\n",
      "2020-10-13 10:35:56,540\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
      "== Status ==\n",
      "Memory usage on this node: 11.7/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/80 CPUs, 0/3 GPUs, 0.0/557.18 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+----------------------------------+----------+-------+\n",
      "| Trial name                       | status   | loc   |\n",
      "|----------------------------------+----------+-------|\n",
      "| RandomMasked_jss_env_e13d6_00000 | RUNNING  |       |\n",
      "+----------------------------------+----------+-------+\n",
      "\n",
      "\n",
      "2020-10-13 10:35:59,308\tERROR trial_runner.py:567 -- Trial RandomMasked_jss_env_e13d6_00000: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/trial_runner.py\", line 515, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/ray_trial_executor.py\", line 488, in fetch_result\n",
      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1428, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError: \u001b[36mray::RandomMasked.train()\u001b[39m (pid=17518, ip=172.17.0.4)\n",
      "  File \"python/ray/_raylet.pyx\", line 445, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 479, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 483, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer_template.py\", line 101, in __init__\n",
      "    Trainer.__init__(self, config, env, logger_creator)\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\", line 476, in __init__\n",
      "    super().__init__(config, logger_creator)\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/trainable.py\", line 249, in __init__\n",
      "    self.setup(copy.deepcopy(self.config))\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\", line 577, in setup\n",
      "    self.config = Trainer.merge_trainer_configs(self._default_config,\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\", line 1045, in merge_trainer_configs\n",
      "    return deep_update(config1, config2, _allow_unknown_configs,\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/utils/util.py\", line 208, in deep_update\n",
      "    raise Exception(\"Unknown config parameter `{}` \".format(k))\n",
      "Exception: Unknown config parameter `instance_path`\n",
      "== Status ==\n",
      "Memory usage on this node: 11.8/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.18 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1 (1 ERROR)\n",
      "+----------------------------------+----------+-------+\n",
      "| Trial name                       | status   | loc   |\n",
      "|----------------------------------+----------+-------|\n",
      "| RandomMasked_jss_env_e13d6_00000 | ERROR    |       |\n",
      "+----------------------------------+----------+-------+\n",
      "Number of errored trials: 1\n",
      "+----------------------------------+--------------+--------------------------------------------------------------------------------------------+\n",
      "| Trial name                       |   # failures | error file                                                                                 |\n",
      "|----------------------------------+--------------+--------------------------------------------------------------------------------------------|\n",
      "| RandomMasked_jss_env_e13d6_00000 |            1 | /root/ray_results/ppo-jss/RandomMasked_jss_env_e13d6_00000_0_2020-10-13_10-35-57/error.txt |\n",
      "+----------------------------------+--------------+--------------------------------------------------------------------------------------------+\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"random_loop.py\", line 66, in <module>\n",
      "    rand_func()\n",
      "  File \"random_loop.py\", line 48, in rand_func\n",
      "    analysis = tune.run(RandomMaskedTrainer, config=config, stop=stop, name=\"ppo-jss\")\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/tune.py\", line 427, in run\n",
      "    raise TuneError(\"Trials did not complete\", incomplete_trials)\n",
      "ray.tune.error.TuneError: ('Trials did not complete', [RandomMasked_jss_env_e13d6_00000])\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 17280\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 1.  Press ctrl-c to abort syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201013_103552-aj5xawms/logs/debug.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201013_103552-aj5xawms/logs/debug-internal.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mfeasible-sweep-1\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/aj5xawms\u001b[0m\n",
      "2020-10-13 10:36:06,420 - wandb.wandb_agent - INFO - Cleaning up finished run: aj5xawms\n",
      "2020-10-13 10:36:06,747 - wandb.wandb_agent - INFO - Agent received command: run\n",
      "2020-10-13 10:36:06,747 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
      "\tinstance_path: /JSS/JSS/env/instances/ta52\n",
      "2020-10-13 10:36:06,749 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python random_loop.py --instance_path=/JSS/JSS/env/instances/ta52\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33matomic-sweep-2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/a1j4vbxx\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/ftxuo7ok\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201013_103608-ftxuo7ok\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
      "\n",
      "2020-10-13 10:36:11,762 - wandb.wandb_agent - INFO - Running runs: ['ftxuo7ok']\n",
      "2020-10-13 10:36:12,289\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
      "== Status ==\n",
      "Memory usage on this node: 11.7/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/80 CPUs, 0/3 GPUs, 0.0/557.18 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+----------------------------------+----------+-------+\n",
      "| Trial name                       | status   | loc   |\n",
      "|----------------------------------+----------+-------|\n",
      "| RandomMasked_jss_env_ea9dc_00000 | RUNNING  |       |\n",
      "+----------------------------------+----------+-------+\n",
      "\n",
      "\n",
      "2020-10-13 10:36:15,021\tERROR trial_runner.py:567 -- Trial RandomMasked_jss_env_ea9dc_00000: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/trial_runner.py\", line 515, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/ray_trial_executor.py\", line 488, in fetch_result\n",
      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1428, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError: \u001b[36mray::RandomMasked.train()\u001b[39m (pid=19144, ip=172.17.0.4)\n",
      "  File \"python/ray/_raylet.pyx\", line 445, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 479, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 483, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer_template.py\", line 101, in __init__\n",
      "    Trainer.__init__(self, config, env, logger_creator)\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\", line 476, in __init__\n",
      "    super().__init__(config, logger_creator)\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/trainable.py\", line 249, in __init__\n",
      "    self.setup(copy.deepcopy(self.config))\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\", line 577, in setup\n",
      "    self.config = Trainer.merge_trainer_configs(self._default_config,\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\", line 1045, in merge_trainer_configs\n",
      "    return deep_update(config1, config2, _allow_unknown_configs,\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/utils/util.py\", line 208, in deep_update\n",
      "    raise Exception(\"Unknown config parameter `{}` \".format(k))\n",
      "Exception: Unknown config parameter `instance_path`\n",
      "== Status ==\n",
      "Memory usage on this node: 11.8/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.18 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1 (1 ERROR)\n",
      "+----------------------------------+----------+-------+\n",
      "| Trial name                       | status   | loc   |\n",
      "|----------------------------------+----------+-------|\n",
      "| RandomMasked_jss_env_ea9dc_00000 | ERROR    |       |\n",
      "+----------------------------------+----------+-------+\n",
      "Number of errored trials: 1\n",
      "+----------------------------------+--------------+--------------------------------------------------------------------------------------------+\n",
      "| Trial name                       |   # failures | error file                                                                                 |\n",
      "|----------------------------------+--------------+--------------------------------------------------------------------------------------------|\n",
      "| RandomMasked_jss_env_ea9dc_00000 |            1 | /root/ray_results/ppo-jss/RandomMasked_jss_env_ea9dc_00000_0_2020-10-13_10-36-13/error.txt |\n",
      "+----------------------------------+--------------+--------------------------------------------------------------------------------------------+\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"random_loop.py\", line 66, in <module>\n",
      "    rand_func()\n",
      "  File \"random_loop.py\", line 48, in rand_func\n",
      "    analysis = tune.run(RandomMaskedTrainer, config=config, stop=stop, name=\"ppo-jss\")\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/tune.py\", line 427, in run\n",
      "    raise TuneError(\"Trials did not complete\", incomplete_trials)\n",
      "ray.tune.error.TuneError: ('Trials did not complete', [RandomMasked_jss_env_ea9dc_00000])\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 18883\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 1.  Press ctrl-c to abort syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201013_103608-ftxuo7ok/logs/debug.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201013_103608-ftxuo7ok/logs/debug-internal.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33matomic-sweep-2\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/ftxuo7ok\u001b[0m\n",
      "2020-10-13 10:36:22,210 - wandb.wandb_agent - INFO - Cleaning up finished run: ftxuo7ok\n",
      "2020-10-13 10:36:22,521 - wandb.wandb_agent - INFO - Agent received command: run\n",
      "2020-10-13 10:36:22,522 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
      "\tinstance_path: /JSS/JSS/env/instances/ta53\n",
      "2020-10-13 10:36:22,523 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python random_loop.py --instance_path=/JSS/JSS/env/instances/ta53\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mupbeat-sweep-3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/a1j4vbxx\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/zrrrfeny\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201013_103624-zrrrfeny\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
      "\n",
      "2020-10-13 10:36:27,538 - wandb.wandb_agent - INFO - Running runs: ['zrrrfeny']\n",
      "2020-10-13 10:36:28,071\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
      "== Status ==\n",
      "Memory usage on this node: 11.7/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/80 CPUs, 0/3 GPUs, 0.0/557.18 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+----------------------------------+----------+-------+\n",
      "| Trial name                       | status   | loc   |\n",
      "|----------------------------------+----------+-------|\n",
      "| RandomMasked_jss_env_f4051_00000 | RUNNING  |       |\n",
      "+----------------------------------+----------+-------+\n",
      "\n",
      "\n",
      "2020-10-13 10:36:30,777\tERROR trial_runner.py:567 -- Trial RandomMasked_jss_env_f4051_00000: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/trial_runner.py\", line 515, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/ray_trial_executor.py\", line 488, in fetch_result\n",
      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1428, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError: \u001b[36mray::RandomMasked.train()\u001b[39m (pid=20753, ip=172.17.0.4)\n",
      "  File \"python/ray/_raylet.pyx\", line 445, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 479, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 483, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer_template.py\", line 101, in __init__\n",
      "    Trainer.__init__(self, config, env, logger_creator)\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\", line 476, in __init__\n",
      "    super().__init__(config, logger_creator)\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/trainable.py\", line 249, in __init__\n",
      "    self.setup(copy.deepcopy(self.config))\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\", line 577, in setup\n",
      "    self.config = Trainer.merge_trainer_configs(self._default_config,\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\", line 1045, in merge_trainer_configs\n",
      "    return deep_update(config1, config2, _allow_unknown_configs,\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/utils/util.py\", line 208, in deep_update\n",
      "    raise Exception(\"Unknown config parameter `{}` \".format(k))\n",
      "Exception: Unknown config parameter `instance_path`\n",
      "== Status ==\n",
      "Memory usage on this node: 11.8/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.18 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1 (1 ERROR)\n",
      "+----------------------------------+----------+-------+\n",
      "| Trial name                       | status   | loc   |\n",
      "|----------------------------------+----------+-------|\n",
      "| RandomMasked_jss_env_f4051_00000 | ERROR    |       |\n",
      "+----------------------------------+----------+-------+\n",
      "Number of errored trials: 1\n",
      "+----------------------------------+--------------+--------------------------------------------------------------------------------------------+\n",
      "| Trial name                       |   # failures | error file                                                                                 |\n",
      "|----------------------------------+--------------+--------------------------------------------------------------------------------------------|\n",
      "| RandomMasked_jss_env_f4051_00000 |            1 | /root/ray_results/ppo-jss/RandomMasked_jss_env_f4051_00000_0_2020-10-13_10-36-29/error.txt |\n",
      "+----------------------------------+--------------+--------------------------------------------------------------------------------------------+\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"random_loop.py\", line 66, in <module>\n",
      "    rand_func()\n",
      "  File \"random_loop.py\", line 48, in rand_func\n",
      "    analysis = tune.run(RandomMaskedTrainer, config=config, stop=stop, name=\"ppo-jss\")\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/tune.py\", line 427, in run\n",
      "    raise TuneError(\"Trials did not complete\", incomplete_trials)\n",
      "ray.tune.error.TuneError: ('Trials did not complete', [RandomMasked_jss_env_f4051_00000])\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 20486\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 1.  Press ctrl-c to abort syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201013_103624-zrrrfeny/logs/debug.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201013_103624-zrrrfeny/logs/debug-internal.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mupbeat-sweep-3\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/zrrrfeny\u001b[0m\n",
      "2020-10-13 10:36:37,963 - wandb.wandb_agent - ERROR - Detected 3 failed runs in the first 60 seconds, shutting down.\n",
      "2020-10-13 10:36:37,963 - wandb.wandb_agent - INFO - To disable this check set WANDB_AGENT_DISABLE_FLAPPING=true\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Terminating and syncing runs. Press ctrl-c to kill.\n"
     ]
    }
   ],
   "source": [
    "!wandb agent a1j4vbxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
