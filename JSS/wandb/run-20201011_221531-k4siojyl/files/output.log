2020-10-11 22:15:35,668	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_49eff_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=56577)[0m 2020-10-11 22:15:38,449	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=56514)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56514)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56607)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56607)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56561)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56561)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56497)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56497)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56629)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56629)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56596)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56596)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56510)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56510)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56617)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56617)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56506)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56506)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56578)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56578)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56604)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56604)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56565)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56565)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56613)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56613)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56524)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56524)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56589)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56589)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56621)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56621)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56624)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56624)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56622)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56622)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56575)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56575)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56526)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56526)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56509)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56509)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56513)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56513)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56499)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56499)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56527)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56527)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56612)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56612)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56498)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56498)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56582)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56582)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56591)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56591)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56606)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56606)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56630)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56630)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56594)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56594)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56623)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56623)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56592)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56592)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56609)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56609)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56569)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56569)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56626)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56626)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56601)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56601)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56522)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56522)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56515)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56515)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56567)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56567)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56605)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56605)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56584)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56584)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56564)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56564)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56576)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56576)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56614)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56614)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56562)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56562)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56585)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56585)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56573)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56573)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56570)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56570)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56580)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56580)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56560)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56560)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56616)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56616)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56525)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56525)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56507)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56507)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56501)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56501)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56511)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56511)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56518)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56518)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56559)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56559)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56505)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56505)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56572)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56572)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56531)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56531)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56502)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56502)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56611)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56611)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56566)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56566)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56512)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56512)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56579)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56579)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56574)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56574)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56496)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56496)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56581)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56581)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56571)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56571)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56583)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56583)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56500)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56500)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56516)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56516)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56503)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56503)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56521)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56521)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56568)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56568)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56528)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56528)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56523)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56523)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56532)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56532)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_49eff_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-11_22-16-20
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 2a919c4c23d146cd9d615e33e1191e41
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1813985804716747
        entropy_coeff: 0.0001
        kl: 0.007592482569937904
        model: {}
        policy_loss: -0.012557204434415326
        total_loss: 500.4123942057292
        vf_explained_var: 0.5819632411003113
        vf_loss: 500.42430623372394
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.195348837209306
    gpu_util_percent0: 0.3930232558139535
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.59767441860465
    vram_util_percent0: 0.09143104487174598
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56577
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16712583852204396
    mean_env_wait_ms: 1.1641065321354336
    mean_inference_ms: 5.702690334738166
    mean_raw_obs_processing_ms: 0.4462739721276429
  time_since_restore: 36.65408396720886
  time_this_iter_s: 36.65408396720886
  time_total_s: 36.65408396720886
  timers:
    learn_throughput: 5887.206
    learn_time_ms: 27481.968
    sample_throughput: 17772.67
    sample_time_ms: 9103.416
    update_time_ms: 33.596
  timestamp: 1602454580
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 49eff_00000
  
== Status ==
Memory usage on this node: 27.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_49eff_00000 | RUNNING  | 172.17.0.4:56577 |      1 |          36.6541 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_49eff_00000:
  custom_metrics:
    time_step_max: 4327
    time_step_mean: 3613.1006944444443
    time_step_min: 3315
  date: 2020-10-11_22-16-55
  done: false
  episode_len_mean: 888.496835443038
  episode_reward_max: 263.74747474747426
  episode_reward_mean: 216.75236542641585
  episode_reward_min: 106.77777777777801
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 2a919c4c23d146cd9d615e33e1191e41
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1502158045768738
        entropy_coeff: 0.0001
        kl: 0.008860165563722452
        model: {}
        policy_loss: -0.016520420283389587
        total_loss: 124.11390558878581
        vf_explained_var: 0.8193988800048828
        vf_loss: 124.1296558380127
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.427500000000002
    gpu_util_percent0: 0.309
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7675000000000005
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56577
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16264231856456615
    mean_env_wait_ms: 1.1623793084718383
    mean_inference_ms: 5.4301394766083355
    mean_raw_obs_processing_ms: 0.43310426150854897
  time_since_restore: 71.36180305480957
  time_this_iter_s: 34.70771908760071
  time_total_s: 71.36180305480957
  timers:
    learn_throughput: 5923.094
    learn_time_ms: 27315.456
    sample_throughput: 19526.06
    sample_time_ms: 8285.952
    update_time_ms: 37.823
  timestamp: 1602454615
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 49eff_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_49eff_00000 | RUNNING  | 172.17.0.4:56577 |      2 |          71.3618 | 323584 |  216.752 |              263.747 |              106.778 |            888.497 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_49eff_00000:
  custom_metrics:
    time_step_max: 4327
    time_step_mean: 3611.459641255605
    time_step_min: 3315
  date: 2020-10-11_22-17-29
  done: false
  episode_len_mean: 884.3755274261604
  episode_reward_max: 267.6868686868686
  episode_reward_mean: 217.34707837872372
  episode_reward_min: 106.77777777777801
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 2a919c4c23d146cd9d615e33e1191e41
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.138886998097102
        entropy_coeff: 0.0001
        kl: 0.009768595453351736
        model: {}
        policy_loss: -0.01719727081945166
        total_loss: 45.55108451843262
        vf_explained_var: 0.9217436909675598
        vf_loss: 45.56741841634115
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.346341463414635
    gpu_util_percent0: 0.31560975609756103
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7780487804878056
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56577
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15985456769504905
    mean_env_wait_ms: 1.1631294562406223
    mean_inference_ms: 5.245007055971816
    mean_raw_obs_processing_ms: 0.42459712262728555
  time_since_restore: 105.73389959335327
  time_this_iter_s: 34.3720965385437
  time_total_s: 105.73389959335327
  timers:
    learn_throughput: 5929.425
    learn_time_ms: 27286.29
    sample_throughput: 20534.879
    sample_time_ms: 7878.888
    update_time_ms: 35.322
  timestamp: 1602454649
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 49eff_00000
  
== Status ==
Memory usage on this node: 28.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_49eff_00000 | RUNNING  | 172.17.0.4:56577 |      3 |          105.734 | 485376 |  217.347 |              267.687 |              106.778 |            884.376 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_49eff_00000:
  custom_metrics:
    time_step_max: 4327
    time_step_mean: 3607.3460264900664
    time_step_min: 3315
  date: 2020-10-11_22-18-04
  done: false
  episode_len_mean: 881.3544303797469
  episode_reward_max: 267.6868686868686
  episode_reward_mean: 217.73289860631613
  episode_reward_min: 106.77777777777801
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 2a919c4c23d146cd9d615e33e1191e41
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1215672294298809
        entropy_coeff: 0.0001
        kl: 0.008861550207560262
        model: {}
        policy_loss: -0.017103165465717513
        total_loss: 29.846932252248127
        vf_explained_var: 0.9496901035308838
        vf_loss: 29.863260904947918
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.6175
    gpu_util_percent0: 0.28975
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.785
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56577
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15795293727448234
    mean_env_wait_ms: 1.1637359408180554
    mean_inference_ms: 5.116155358799175
    mean_raw_obs_processing_ms: 0.41843369060783137
  time_since_restore: 140.04236888885498
  time_this_iter_s: 34.30846929550171
  time_total_s: 140.04236888885498
  timers:
    learn_throughput: 5927.613
    learn_time_ms: 27294.628
    sample_throughput: 21183.792
    sample_time_ms: 7637.537
    update_time_ms: 31.53
  timestamp: 1602454684
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 49eff_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_49eff_00000 | RUNNING  | 172.17.0.4:56577 |      4 |          140.042 | 647168 |  217.733 |              267.687 |              106.778 |            881.354 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_49eff_00000:
  custom_metrics:
    time_step_max: 4343
    time_step_mean: 3598.1482939632547
    time_step_min: 3246
  date: 2020-10-11_22-18-38
  done: false
  episode_len_mean: 877.0215189873418
  episode_reward_max: 274.20202020202015
  episode_reward_mean: 219.70719856795787
  episode_reward_min: 106.77777777777801
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 2a919c4c23d146cd9d615e33e1191e41
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0900474389394124
        entropy_coeff: 0.0001
        kl: 0.009456767700612545
        model: {}
        policy_loss: -0.018026052741333842
        total_loss: 26.461381594340008
        vf_explained_var: 0.9565213322639465
        vf_loss: 26.47857077916463
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.6675
    gpu_util_percent0: 0.29475
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7825
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56577
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1565730415281969
    mean_env_wait_ms: 1.1650117761852194
    mean_inference_ms: 5.020974472319719
    mean_raw_obs_processing_ms: 0.413803518740552
  time_since_restore: 174.28469443321228
  time_this_iter_s: 34.2423255443573
  time_total_s: 174.28469443321228
  timers:
    learn_throughput: 5929.789
    learn_time_ms: 27284.612
    sample_throughput: 21590.325
    sample_time_ms: 7493.727
    update_time_ms: 30.046
  timestamp: 1602454718
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 49eff_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_49eff_00000 | RUNNING  | 172.17.0.4:56577 |      5 |          174.285 | 808960 |  219.707 |              274.202 |              106.778 |            877.022 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_49eff_00000:
  custom_metrics:
    time_step_max: 4343
    time_step_mean: 3576.9896907216494
    time_step_min: 3240
  date: 2020-10-11_22-19-12
  done: false
  episode_len_mean: 868.5031963470319
  episode_reward_max: 280.1111111111104
  episode_reward_mean: 223.8771274387711
  episode_reward_min: 106.77777777777801
  episodes_this_iter: 305
  episodes_total: 1095
  experiment_id: 2a919c4c23d146cd9d615e33e1191e41
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0717031757036846
        entropy_coeff: 0.0001
        kl: 0.009037841732303301
        model: {}
        policy_loss: -0.014265036288027963
        total_loss: 29.73210557301839
        vf_explained_var: 0.9637808203697205
        vf_loss: 29.745573838551838
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.7625
    gpu_util_percent0: 0.351
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7725
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56577
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15478272997069867
    mean_env_wait_ms: 1.1684325961828061
    mean_inference_ms: 4.897146357541493
    mean_raw_obs_processing_ms: 0.4079680574261013
  time_since_restore: 208.30559730529785
  time_this_iter_s: 34.02090287208557
  time_total_s: 208.30559730529785
  timers:
    learn_throughput: 5940.048
    learn_time_ms: 27237.49
    sample_throughput: 21859.334
    sample_time_ms: 7401.506
    update_time_ms: 29.759
  timestamp: 1602454752
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 49eff_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_49eff_00000 | RUNNING  | 172.17.0.4:56577 |      6 |          208.306 | 970752 |  223.877 |              280.111 |              106.778 |            868.503 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_49eff_00000:
  custom_metrics:
    time_step_max: 4343
    time_step_mean: 3564.6205501618124
    time_step_min: 3240
  date: 2020-10-11_22-19-46
  done: false
  episode_len_mean: 862.9351265822785
  episode_reward_max: 280.1111111111104
  episode_reward_mean: 225.97177470911635
  episode_reward_min: 106.77777777777801
  episodes_this_iter: 169
  episodes_total: 1264
  experiment_id: 2a919c4c23d146cd9d615e33e1191e41
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0605590244134266
        entropy_coeff: 0.0001
        kl: 0.008275331774105629
        model: {}
        policy_loss: -0.015744596060055
        total_loss: 17.47739330927531
        vf_explained_var: 0.9678491950035095
        vf_loss: 17.492416699727375
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.6675
    gpu_util_percent0: 0.32175000000000004
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.785000000000001
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56577
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15407455637928574
    mean_env_wait_ms: 1.1700922154117916
    mean_inference_ms: 4.847773387793611
    mean_raw_obs_processing_ms: 0.4056801877334394
  time_since_restore: 242.5724995136261
  time_this_iter_s: 34.26690220832825
  time_total_s: 242.5724995136261
  timers:
    learn_throughput: 5943.037
    learn_time_ms: 27223.79
    sample_throughput: 22019.783
    sample_time_ms: 7347.575
    update_time_ms: 31.46
  timestamp: 1602454786
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 49eff_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_49eff_00000 | RUNNING  | 172.17.0.4:56577 |      7 |          242.572 | 1132544 |  225.972 |              280.111 |              106.778 |            862.935 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_49eff_00000:
  custom_metrics:
    time_step_max: 4343
    time_step_mean: 3552.0688665710186
    time_step_min: 3235
  date: 2020-10-11_22-20-21
  done: false
  episode_len_mean: 857.6645569620254
  episode_reward_max: 282.6868686868685
  episode_reward_mean: 227.89474917955917
  episode_reward_min: 106.77777777777801
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 2a919c4c23d146cd9d615e33e1191e41
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0343750417232513
        entropy_coeff: 0.0001
        kl: 0.00911420676857233
        model: {}
        policy_loss: -0.017840288278724376
        total_loss: 15.268435955047607
        vf_explained_var: 0.9698565006256104
        vf_loss: 15.285468260447184
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.517500000000002
    gpu_util_percent0: 0.31174999999999997
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7825
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56577
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15351667810322925
    mean_env_wait_ms: 1.1716421842762905
    mean_inference_ms: 4.808477592952754
    mean_raw_obs_processing_ms: 0.4038087048474989
  time_since_restore: 276.71832299232483
  time_this_iter_s: 34.14582347869873
  time_total_s: 276.71832299232483
  timers:
    learn_throughput: 5944.904
    learn_time_ms: 27215.241
    sample_throughput: 22190.695
    sample_time_ms: 7290.984
    update_time_ms: 32.908
  timestamp: 1602454821
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 49eff_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_49eff_00000 | RUNNING  | 172.17.0.4:56577 |      8 |          276.718 | 1294336 |  227.895 |              282.687 |              106.778 |            857.665 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_49eff_00000:
  custom_metrics:
    time_step_max: 4343
    time_step_mean: 3537.649100257069
    time_step_min: 3162
  date: 2020-10-11_22-20-55
  done: false
  episode_len_mean: 852.9880050505051
  episode_reward_max: 286.929292929293
  episode_reward_mean: 229.9083256810528
  episode_reward_min: 106.77777777777801
  episodes_this_iter: 162
  episodes_total: 1584
  experiment_id: 2a919c4c23d146cd9d615e33e1191e41
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0032838433980942
        entropy_coeff: 0.0001
        kl: 0.00883012815999488
        model: {}
        policy_loss: -0.017697396823981155
        total_loss: 14.626861095428467
        vf_explained_var: 0.9729071259498596
        vf_loss: 14.643775939941406
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.595
    gpu_util_percent0: 0.363
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.775
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56577
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1530153770421335
    mean_env_wait_ms: 1.1732812236598549
    mean_inference_ms: 4.7733714775028515
    mean_raw_obs_processing_ms: 0.4021230341343365
  time_since_restore: 310.95607686042786
  time_this_iter_s: 34.23775386810303
  time_total_s: 310.95607686042786
  timers:
    learn_throughput: 5947.719
    learn_time_ms: 27202.361
    sample_throughput: 22269.293
    sample_time_ms: 7265.251
    update_time_ms: 31.585
  timestamp: 1602454855
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 49eff_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_49eff_00000 | RUNNING  | 172.17.0.4:56577 |      9 |          310.956 | 1456128 |  229.908 |              286.929 |              106.778 |            852.988 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_49eff_00000:
  custom_metrics:
    time_step_max: 4343
    time_step_mean: 3516.3668639053253
    time_step_min: 3162
  date: 2020-10-11_22-21-29
  done: false
  episode_len_mean: 846.0545839957605
  episode_reward_max: 292.2323232323236
  episode_reward_mean: 233.19818213935847
  episode_reward_min: 106.77777777777801
  episodes_this_iter: 303
  episodes_total: 1887
  experiment_id: 2a919c4c23d146cd9d615e33e1191e41
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9796416411797205
        entropy_coeff: 0.0001
        kl: 0.0077074622580160694
        model: {}
        policy_loss: -0.017394189858653892
        total_loss: 19.756762981414795
        vf_explained_var: 0.9740856289863586
        vf_loss: 19.773484388987224
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.4
    gpu_util_percent0: 0.36
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7725
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56577
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1522613009743444
    mean_env_wait_ms: 1.176286511314184
    mean_inference_ms: 4.720648448053445
    mean_raw_obs_processing_ms: 0.39965664667270207
  time_since_restore: 345.0550136566162
  time_this_iter_s: 34.098936796188354
  time_total_s: 345.0550136566162
  timers:
    learn_throughput: 5948.453
    learn_time_ms: 27199.004
    sample_throughput: 22398.046
    sample_time_ms: 7223.487
    update_time_ms: 30.919
  timestamp: 1602454889
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 49eff_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_49eff_00000 | RUNNING  | 172.17.0.4:56577 |     10 |          345.055 | 1617920 |  233.198 |              292.232 |              106.778 |            846.055 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_49eff_00000:
  custom_metrics:
    time_step_max: 4343
    time_step_mean: 3504.8820335636724
    time_step_min: 3123
  date: 2020-10-11_22-22-04
  done: false
  episode_len_mean: 843.085199610516
  episode_reward_max: 292.83838383838395
  episode_reward_mean: 234.8075644468048
  episode_reward_min: 106.77777777777801
  episodes_this_iter: 167
  episodes_total: 2054
  experiment_id: 2a919c4c23d146cd9d615e33e1191e41
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9644764910141627
        entropy_coeff: 0.0001
        kl: 0.008123684480475882
        model: {}
        policy_loss: -0.018922119595420856
        total_loss: 10.082622528076172
        vf_explained_var: 0.9805335402488708
        vf_loss: 10.100828568140665
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.2
    gpu_util_percent0: 0.42073170731707327
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.778048780487805
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56577
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15191591353498549
    mean_env_wait_ms: 1.1776421909064398
    mean_inference_ms: 4.696243960697316
    mean_raw_obs_processing_ms: 0.39855245481171453
  time_since_restore: 379.4364151954651
  time_this_iter_s: 34.38140153884888
  time_total_s: 379.4364151954651
  timers:
    learn_throughput: 5956.38
    learn_time_ms: 27162.808
    sample_throughput: 23038.619
    sample_time_ms: 7022.643
    update_time_ms: 31.646
  timestamp: 1602454924
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 49eff_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_49eff_00000 | RUNNING  | 172.17.0.4:56577 |     11 |          379.436 | 1779712 |  234.808 |              292.838 |              106.778 |            843.085 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_49eff_00000:
  custom_metrics:
    time_step_max: 4343
    time_step_mean: 3497.605769230769
    time_step_min: 3123
  date: 2020-10-11_22-22-38
  done: false
  episode_len_mean: 840.6098553345389
  episode_reward_max: 292.83838383838395
  episode_reward_mean: 235.85854932690364
  episode_reward_min: 106.77777777777801
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 2a919c4c23d146cd9d615e33e1191e41
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9480908066034317
        entropy_coeff: 0.0001
        kl: 0.008173223895331224
        model: {}
        policy_loss: -0.0170200295591106
        total_loss: 13.047847986221313
        vf_explained_var: 0.9752633571624756
        vf_loss: 13.06414540608724
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.54
    gpu_util_percent0: 0.39449999999999996
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7900000000000005
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56577
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1516260611134587
    mean_env_wait_ms: 1.1788336506761772
    mean_inference_ms: 4.6757332027769705
    mean_raw_obs_processing_ms: 0.3975853647555759
  time_since_restore: 413.92365050315857
  time_this_iter_s: 34.48723530769348
  time_total_s: 413.92365050315857
  timers:
    learn_throughput: 5950.145
    learn_time_ms: 27191.269
    sample_throughput: 23203.192
    sample_time_ms: 6972.834
    update_time_ms: 30.393
  timestamp: 1602454958
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 49eff_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_49eff_00000 | RUNNING  | 172.17.0.4:56577 |     12 |          413.924 | 1941504 |  235.859 |              292.838 |              106.778 |             840.61 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_49eff_00000:
  custom_metrics:
    time_step_max: 4343
    time_step_mean: 3488.019417475728
    time_step_min: 3123
  date: 2020-10-11_22-23-13
  done: false
  episode_len_mean: 837.7584480600751
  episode_reward_max: 292.8383838383842
  episode_reward_mean: 237.4883250527805
  episode_reward_min: 106.77777777777801
  episodes_this_iter: 185
  episodes_total: 2397
  experiment_id: 2a919c4c23d146cd9d615e33e1191e41
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9102677057186762
        entropy_coeff: 0.0001
        kl: 0.008197648838783303
        model: {}
        policy_loss: -0.01663444278528914
        total_loss: 13.088514725367228
        vf_explained_var: 0.9783415794372559
        vf_loss: 13.104420264561972
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.134146341463413
    gpu_util_percent0: 0.34731707317073174
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.773170731707317
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56577
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15132518805828632
    mean_env_wait_ms: 1.180212840732506
    mean_inference_ms: 4.654367829576469
    mean_raw_obs_processing_ms: 0.3965614632887215
  time_since_restore: 448.3404221534729
  time_this_iter_s: 34.41677165031433
  time_total_s: 448.3404221534729
  timers:
    learn_throughput: 5947.428
    learn_time_ms: 27203.694
    sample_throughput: 23231.361
    sample_time_ms: 6964.379
    update_time_ms: 29.881
  timestamp: 1602454993
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 49eff_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_49eff_00000 | RUNNING  | 172.17.0.4:56577 |     13 |           448.34 | 2103296 |  237.488 |              292.838 |              106.778 |            837.758 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_49eff_00000:
  custom_metrics:
    time_step_max: 4343
    time_step_mean: 3474.6168611215658
    time_step_min: 3123
  date: 2020-10-11_22-23-47
  done: false
  episode_len_mean: 833.9191806331471
  episode_reward_max: 292.8383838383842
  episode_reward_mean: 239.41549573951795
  episode_reward_min: 106.77777777777801
  episodes_this_iter: 288
  episodes_total: 2685
  experiment_id: 2a919c4c23d146cd9d615e33e1191e41
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8843665222326914
        entropy_coeff: 0.0001
        kl: 0.007982256162601212
        model: {}
        policy_loss: -0.013931292565151429
        total_loss: 15.588904857635498
        vf_explained_var: 0.9774231910705566
        vf_loss: 15.602126359939575
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.7125
    gpu_util_percent0: 0.40199999999999997
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.775
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56577
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1509060268981819
    mean_env_wait_ms: 1.182100104969366
    mean_inference_ms: 4.625174492887011
    mean_raw_obs_processing_ms: 0.39518908621223653
  time_since_restore: 482.61798429489136
  time_this_iter_s: 34.27756214141846
  time_total_s: 482.61798429489136
  timers:
    learn_throughput: 5949.599
    learn_time_ms: 27193.765
    sample_throughput: 23214.258
    sample_time_ms: 6969.51
    update_time_ms: 31.574
  timestamp: 1602455027
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 49eff_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_49eff_00000 | RUNNING  | 172.17.0.4:56577 |     14 |          482.618 | 2265088 |  239.415 |              292.838 |              106.778 |            833.919 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_49eff_00000:
  custom_metrics:
    time_step_max: 4343
    time_step_mean: 3468.19921875
    time_step_min: 3123
  date: 2020-10-11_22-24-22
  done: false
  episode_len_mean: 831.8639240506329
  episode_reward_max: 292.8383838383842
  episode_reward_mean: 240.43838170736893
  episode_reward_min: 106.77777777777801
  episodes_this_iter: 159
  episodes_total: 2844
  experiment_id: 2a919c4c23d146cd9d615e33e1191e41
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.875699852903684
        entropy_coeff: 0.0001
        kl: 0.007928681870301565
        model: {}
        policy_loss: -0.018612359145966668
        total_loss: 9.255796909332275
        vf_explained_var: 0.9811435341835022
        vf_loss: 9.273704290390015
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.435
    gpu_util_percent0: 0.373
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.785000000000001
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56577
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15070675805863692
    mean_env_wait_ms: 1.1830461595997188
    mean_inference_ms: 4.611120164246068
    mean_raw_obs_processing_ms: 0.3945322454806497
  time_since_restore: 516.9852778911591
  time_this_iter_s: 34.3672935962677
  time_total_s: 516.9852778911591
  timers:
    learn_throughput: 5949.702
    learn_time_ms: 27193.297
    sample_throughput: 23174.602
    sample_time_ms: 6981.436
    update_time_ms: 32.263
  timestamp: 1602455062
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 49eff_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_49eff_00000 | RUNNING  | 172.17.0.4:56577 |     15 |          516.985 | 2426880 |  240.438 |              292.838 |              106.778 |            831.864 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_49eff_00000:
  custom_metrics:
    time_step_max: 4343
    time_step_mean: 3461.3579831932775
    time_step_min: 3123
  date: 2020-10-11_22-24-56
  done: false
  episode_len_mean: 829.9144189144189
  episode_reward_max: 292.8383838383842
  episode_reward_mean: 241.53085298539833
  episode_reward_min: 106.77777777777801
  episodes_this_iter: 159
  episodes_total: 3003
  experiment_id: 2a919c4c23d146cd9d615e33e1191e41
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8581066131591797
        entropy_coeff: 0.0001
        kl: 0.008198911518168947
        model: {}
        policy_loss: -0.017007101133155327
        total_loss: 9.833723147710165
        vf_explained_var: 0.978848397731781
        vf_loss: 9.849995930989584
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.04390243902439
    gpu_util_percent0: 0.37
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7829268292682925
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56577
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15052050461793132
    mean_env_wait_ms: 1.1839335331932295
    mean_inference_ms: 4.5981008310966125
    mean_raw_obs_processing_ms: 0.3939071548884782
  time_since_restore: 551.4254515171051
  time_this_iter_s: 34.440173625946045
  time_total_s: 551.4254515171051
  timers:
    learn_throughput: 5945.143
    learn_time_ms: 27214.148
    sample_throughput: 23133.976
    sample_time_ms: 6993.696
    update_time_ms: 33.131
  timestamp: 1602455096
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 49eff_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_49eff_00000 | RUNNING  | 172.17.0.4:56577 |     16 |          551.425 | 2588672 |  241.531 |              292.838 |              106.778 |            829.914 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_49eff_00000:
  custom_metrics:
    time_step_max: 4343
    time_step_mean: 3450.9907947223073
    time_step_min: 3123
  date: 2020-10-11_22-25-31
  done: false
  episode_len_mean: 826.4283541223
  episode_reward_max: 292.8383838383842
  episode_reward_mean: 243.22931782073846
  episode_reward_min: 106.77777777777801
  episodes_this_iter: 284
  episodes_total: 3287
  experiment_id: 2a919c4c23d146cd9d615e33e1191e41
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8231376608212789
        entropy_coeff: 0.0001
        kl: 0.007986484910361469
        model: {}
        policy_loss: -0.013650909706484526
        total_loss: 13.903800328572592
        vf_explained_var: 0.9800006747245789
        vf_loss: 13.91673493385315
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.705000000000002
    gpu_util_percent0: 0.39775
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.78
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56577
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15022397038345278
    mean_env_wait_ms: 1.1854826137811694
    mean_inference_ms: 4.577292995192778
    mean_raw_obs_processing_ms: 0.39291435459253915
  time_since_restore: 585.9386808872223
  time_this_iter_s: 34.51322937011719
  time_total_s: 585.9386808872223
  timers:
    learn_throughput: 5941.021
    learn_time_ms: 27233.031
    sample_throughput: 23116.718
    sample_time_ms: 6998.917
    update_time_ms: 33.435
  timestamp: 1602455131
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 49eff_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_49eff_00000 | RUNNING  | 172.17.0.4:56577 |     17 |          585.939 | 2750464 |  243.229 |              292.838 |              106.778 |            826.428 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_49eff_00000:
  custom_metrics:
    time_step_max: 4343
    time_step_mean: 3443.1882250580047
    time_step_min: 3123
  date: 2020-10-11_22-26-05
  done: true
  episode_len_mean: 824.1786536248561
  episode_reward_max: 297.38383838383874
  episode_reward_mean: 244.41102916390594
  episode_reward_min: 106.77777777777801
  episodes_this_iter: 189
  episodes_total: 3476
  experiment_id: 2a919c4c23d146cd9d615e33e1191e41
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8103283842404684
        entropy_coeff: 0.0001
        kl: 0.007367763435468078
        model: {}
        policy_loss: -0.015943664708174765
        total_loss: 8.758411486943563
        vf_explained_var: 0.9822162985801697
        vf_loss: 8.773699522018433
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.665
    gpu_util_percent0: 0.34475
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7875
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56577
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15004851031632
    mean_env_wait_ms: 1.1864642028911143
    mean_inference_ms: 4.565059649179841
    mean_raw_obs_processing_ms: 0.39235013878699804
  time_since_restore: 620.1015784740448
  time_this_iter_s: 34.16289758682251
  time_total_s: 620.1015784740448
  timers:
    learn_throughput: 5941.191
    learn_time_ms: 27232.249
    sample_throughput: 23109.876
    sample_time_ms: 7000.989
    update_time_ms: 33.008
  timestamp: 1602455165
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 49eff_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_49eff_00000 | TERMINATED |       |     18 |          620.102 | 2912256 |  244.411 |              297.384 |              106.778 |            824.179 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_49eff_00000 | TERMINATED |       |     18 |          620.102 | 2912256 |  244.411 |              297.384 |              106.778 |            824.179 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


