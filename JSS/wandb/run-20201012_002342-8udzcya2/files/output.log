2020-10-12 00:23:46,382	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_31f4e_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=1801)[0m 2020-10-12 00:23:49,133	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=1806)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1806)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1803)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1803)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1820)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1820)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1832)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1832)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1790)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1790)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1791)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1791)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1787)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1787)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1825)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1825)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1813)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1813)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1819)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1819)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1789)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1789)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1766)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1766)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1833)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1833)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1770)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1770)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1707)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1707)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1722)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1722)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1831)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1831)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1716)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1716)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1797)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1797)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1784)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1784)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1769)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1769)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1712)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1712)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1724)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1724)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1816)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1816)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1738)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1738)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1709)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1709)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1748)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1748)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1794)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1794)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1742)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1742)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1777)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1777)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1802)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1802)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1760)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1760)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1780)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1780)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1740)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1740)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1706)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1706)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1798)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1798)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1705)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1705)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1764)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1764)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1717)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1717)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1711)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1711)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1785)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1785)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1782)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1782)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1815)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1815)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1743)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1743)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1804)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1804)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1714)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1714)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1783)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1783)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1734)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1734)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1719)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1719)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1817)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1817)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1781)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1781)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1725)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1725)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1810)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1810)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1718)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1718)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1772)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1772)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1786)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1786)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1828)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1828)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1775)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1775)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1792)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1792)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1727)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1727)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1779)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1779)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1721)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1721)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1747)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1747)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1834)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1834)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1767)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1767)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1708)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1708)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1726)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1726)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1713)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1713)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1728)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1728)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1735)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1735)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1829)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1829)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1846)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1846)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1773)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1773)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1730)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1730)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1811)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1811)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1837)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1837)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1788)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1788)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1710)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1710)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1796)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1796)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_31f4e_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-12_00-24-30
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 262130d2f50c4fb8a06c2e91905acad9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.179647554953893
        entropy_coeff: 0.0005000000000000001
        kl: 0.009386838258554539
        model: {}
        policy_loss: -0.014191241362520183
        total_loss: 500.4114074707031
        vf_explained_var: 0.5819632411003113
        vf_loss: 500.42430623372394
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.572093023255814
    gpu_util_percent0: 0.2797674418604652
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5953488372093014
    vram_util_percent0: 0.09048143882477673
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 1801
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16944662661197635
    mean_env_wait_ms: 1.1674383798842447
    mean_inference_ms: 5.575553079047443
    mean_raw_obs_processing_ms: 0.45128655970998294
  time_since_restore: 36.10845470428467
  time_this_iter_s: 36.10845470428467
  time_total_s: 36.10845470428467
  timers:
    learn_throughput: 5954.46
    learn_time_ms: 27171.563
    sample_throughput: 18342.564
    sample_time_ms: 8820.577
    update_time_ms: 30.008
  timestamp: 1602462270
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 31f4e_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_31f4e_00000 | RUNNING  | 172.17.0.4:1801 |      1 |          36.1085 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_31f4e_00000:
  custom_metrics:
    time_step_max: 4130
    time_step_mean: 3609.2326388888887
    time_step_min: 3352
  date: 2020-10-12_00-25-05
  done: false
  episode_len_mean: 890.876582278481
  episode_reward_max: 262.080808080808
  episode_reward_mean: 217.55021736350832
  episode_reward_min: 133.8989898989894
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 262130d2f50c4fb8a06c2e91905acad9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.143593430519104
        entropy_coeff: 0.0005000000000000001
        kl: 0.01247255791289111
        model: {}
        policy_loss: -0.018173754991342623
        total_loss: 118.8584976196289
        vf_explained_var: 0.8239815831184387
        vf_loss: 118.87474632263184
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.7275
    gpu_util_percent0: 0.2875
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7700000000000005
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 1801
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16467752237083355
    mean_env_wait_ms: 1.1632554710791374
    mean_inference_ms: 5.358277916904617
    mean_raw_obs_processing_ms: 0.43874840470887
  time_since_restore: 70.58802485466003
  time_this_iter_s: 34.479570150375366
  time_total_s: 70.58802485466003
  timers:
    learn_throughput: 5981.705
    learn_time_ms: 27047.806
    sample_throughput: 19841.604
    sample_time_ms: 8154.18
    update_time_ms: 24.347
  timestamp: 1602462305
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 31f4e_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_31f4e_00000 | RUNNING  | 172.17.0.4:1801 |      2 |           70.588 | 323584 |   217.55 |              262.081 |              133.899 |            890.877 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_31f4e_00000:
  custom_metrics:
    time_step_max: 4130
    time_step_mean: 3610.114349775785
    time_step_min: 3352
  date: 2020-10-12_00-25-39
  done: false
  episode_len_mean: 890.0210970464135
  episode_reward_max: 262.080808080808
  episode_reward_mean: 217.8719473213142
  episode_reward_min: 105.11111111111099
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 262130d2f50c4fb8a06c2e91905acad9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1292846898237865
        entropy_coeff: 0.0005000000000000001
        kl: 0.013232750274861852
        model: {}
        policy_loss: -0.018127874597363796
        total_loss: 46.934974352518715
        vf_explained_var: 0.9205439686775208
        vf_loss: 46.951018969217934
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.66
    gpu_util_percent0: 0.319
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.785000000000001
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 1801
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16171153525650436
    mean_env_wait_ms: 1.1614598895227075
    mean_inference_ms: 5.192312894732658
    mean_raw_obs_processing_ms: 0.4297706575743041
  time_since_restore: 104.73665380477905
  time_this_iter_s: 34.14862895011902
  time_total_s: 104.73665380477905
  timers:
    learn_throughput: 5974.83
    learn_time_ms: 27078.928
    sample_throughput: 20882.754
    sample_time_ms: 7747.637
    update_time_ms: 25.19
  timestamp: 1602462339
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 31f4e_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_31f4e_00000 | RUNNING  | 172.17.0.4:1801 |      3 |          104.737 | 485376 |  217.872 |              262.081 |              105.111 |            890.021 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_31f4e_00000:
  custom_metrics:
    time_step_max: 4130
    time_step_mean: 3603.023178807947
    time_step_min: 3352
  date: 2020-10-12_00-26-13
  done: false
  episode_len_mean: 886.5490506329114
  episode_reward_max: 262.080808080808
  episode_reward_mean: 218.8956335506966
  episode_reward_min: 105.11111111111099
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 262130d2f50c4fb8a06c2e91905acad9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1074550847212474
        entropy_coeff: 0.0005000000000000001
        kl: 0.013599486167853078
        model: {}
        policy_loss: -0.02130676802092542
        total_loss: 29.753436247507732
        vf_explained_var: 0.9473784565925598
        vf_loss: 29.772576491038006
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.3125
    gpu_util_percent0: 0.35700000000000004
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7775
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 1801
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15963904634647097
    mean_env_wait_ms: 1.1609786328027203
    mean_inference_ms: 5.072872080284154
    mean_raw_obs_processing_ms: 0.42307345201637775
  time_since_restore: 138.94163751602173
  time_this_iter_s: 34.204983711242676
  time_total_s: 138.94163751602173
  timers:
    learn_throughput: 5960.161
    learn_time_ms: 27145.574
    sample_throughput: 21558.389
    sample_time_ms: 7504.828
    update_time_ms: 26.603
  timestamp: 1602462373
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 31f4e_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_31f4e_00000 | RUNNING  | 172.17.0.4:1801 |      4 |          138.942 | 647168 |  218.896 |              262.081 |              105.111 |            886.549 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_31f4e_00000:
  custom_metrics:
    time_step_max: 4130
    time_step_mean: 3590.712598425197
    time_step_min: 3269
  date: 2020-10-12_00-26-48
  done: false
  episode_len_mean: 881.6164556962025
  episode_reward_max: 270.71717171717165
  episode_reward_mean: 221.02614755146382
  episode_reward_min: 105.11111111111099
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 262130d2f50c4fb8a06c2e91905acad9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0685576498508453
        entropy_coeff: 0.0005000000000000001
        kl: 0.015463131945580244
        model: {}
        policy_loss: -0.021996237492809694
        total_loss: 22.10743300120036
        vf_explained_var: 0.9607601165771484
        vf_loss: 22.12687126795451
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.8625
    gpu_util_percent0: 0.3205
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7849999999999993
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 1801
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.158095392874731
    mean_env_wait_ms: 1.161788709464045
    mean_inference_ms: 4.9827237500273025
    mean_raw_obs_processing_ms: 0.4177980886636828
  time_since_restore: 173.17991495132446
  time_this_iter_s: 34.238277435302734
  time_total_s: 173.17991495132446
  timers:
    learn_throughput: 5949.673
    learn_time_ms: 27193.425
    sample_throughput: 21984.351
    sample_time_ms: 7359.417
    update_time_ms: 26.73
  timestamp: 1602462408
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 31f4e_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_31f4e_00000 | RUNNING  | 172.17.0.4:1801 |      5 |           173.18 | 808960 |  221.026 |              270.717 |              105.111 |            881.616 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_31f4e_00000:
  custom_metrics:
    time_step_max: 4130
    time_step_mean: 3570.133971291866
    time_step_min: 3269
  date: 2020-10-12_00-27-22
  done: false
  episode_len_mean: 873.0428704566635
  episode_reward_max: 277.3838383838381
  episode_reward_mean: 224.4163724853378
  episode_reward_min: 105.11111111111099
  episodes_this_iter: 283
  episodes_total: 1073
  experiment_id: 262130d2f50c4fb8a06c2e91905acad9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0429097910722096
        entropy_coeff: 0.0005000000000000001
        kl: 0.014100355561822653
        model: {}
        policy_loss: -0.02002248940213273
        total_loss: 26.650039196014404
        vf_explained_var: 0.9673227667808533
        vf_loss: 26.667763233184814
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.827499999999997
    gpu_util_percent0: 0.37825
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.78
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 1801
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15616704040060883
    mean_env_wait_ms: 1.1645047467975362
    mean_inference_ms: 4.870991654914009
    mean_raw_obs_processing_ms: 0.4113973281421617
  time_since_restore: 207.40266633033752
  time_this_iter_s: 34.22275137901306
  time_total_s: 207.40266633033752
  timers:
    learn_throughput: 5945.444
    learn_time_ms: 27212.772
    sample_throughput: 22247.083
    sample_time_ms: 7272.504
    update_time_ms: 25.925
  timestamp: 1602462442
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 31f4e_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_31f4e_00000 | RUNNING  | 172.17.0.4:1801 |      6 |          207.403 | 970752 |  224.416 |              277.384 |              105.111 |            873.043 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_31f4e_00000:
  custom_metrics:
    time_step_max: 4130
    time_step_mean: 3561.69498381877
    time_step_min: 3245
  date: 2020-10-12_00-27-56
  done: false
  episode_len_mean: 866.6534810126582
  episode_reward_max: 278.8989898989894
  episode_reward_mean: 226.12305012146763
  episode_reward_min: 105.11111111111099
  episodes_this_iter: 191
  episodes_total: 1264
  experiment_id: 262130d2f50c4fb8a06c2e91905acad9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0464061200618744
        entropy_coeff: 0.0005000000000000001
        kl: 0.012187682480240861
        model: {}
        policy_loss: -0.019194026477634907
        total_loss: 18.816860516866047
        vf_explained_var: 0.9679368138313293
        vf_loss: 18.834139823913574
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.310000000000002
    gpu_util_percent0: 0.30575
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7800000000000002
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 1801
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1552687555466812
    mean_env_wait_ms: 1.166319564023329
    mean_inference_ms: 4.816920407829584
    mean_raw_obs_processing_ms: 0.4084227258671983
  time_since_restore: 241.5872082710266
  time_this_iter_s: 34.18454194068909
  time_total_s: 241.5872082710266
  timers:
    learn_throughput: 5943.431
    learn_time_ms: 27221.989
    sample_throughput: 22441.898
    sample_time_ms: 7209.372
    update_time_ms: 25.857
  timestamp: 1602462476
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 31f4e_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_31f4e_00000 | RUNNING  | 172.17.0.4:1801 |      7 |          241.587 | 1132544 |  226.123 |              278.899 |              105.111 |            866.653 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_31f4e_00000:
  custom_metrics:
    time_step_max: 4130
    time_step_mean: 3550.96843615495
    time_step_min: 3245
  date: 2020-10-12_00-28-30
  done: false
  episode_len_mean: 861.2201125175809
  episode_reward_max: 278.8989898989894
  episode_reward_mean: 228.09378596087438
  episode_reward_min: 105.11111111111099
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 262130d2f50c4fb8a06c2e91905acad9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0158366759618123
        entropy_coeff: 0.0005000000000000001
        kl: 0.013218709810947379
        model: {}
        policy_loss: -0.020021504955366254
        total_loss: 13.703810214996338
        vf_explained_var: 0.9733670353889465
        vf_loss: 13.721696297327677
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.34
    gpu_util_percent0: 0.399
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.785000000000001
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 1801
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15464118013969133
    mean_env_wait_ms: 1.1678708124784798
    mean_inference_ms: 4.779750094743428
    mean_raw_obs_processing_ms: 0.4063286067286126
  time_since_restore: 275.7631936073303
  time_this_iter_s: 34.17598533630371
  time_total_s: 275.7631936073303
  timers:
    learn_throughput: 5942.674
    learn_time_ms: 27225.455
    sample_throughput: 22580.668
    sample_time_ms: 7165.067
    update_time_ms: 25.082
  timestamp: 1602462510
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 31f4e_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_31f4e_00000 | RUNNING  | 172.17.0.4:1801 |      8 |          275.763 | 1294336 |  228.094 |              278.899 |              105.111 |             861.22 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_31f4e_00000:
  custom_metrics:
    time_step_max: 4130
    time_step_mean: 3541.791237113402
    time_step_min: 3229
  date: 2020-10-12_00-29-05
  done: false
  episode_len_mean: 856.6132911392405
  episode_reward_max: 284.050505050505
  episode_reward_mean: 229.55961513872887
  episode_reward_min: 105.11111111111099
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 262130d2f50c4fb8a06c2e91905acad9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9870403110980988
        entropy_coeff: 0.0005000000000000001
        kl: 0.012308246611307064
        model: {}
        policy_loss: -0.01942475066365053
        total_loss: 13.404837052027384
        vf_explained_var: 0.9745244383811951
        vf_loss: 13.422293821970621
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.077500000000004
    gpu_util_percent0: 0.37825000000000003
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.78
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 1801
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15409865076402116
    mean_env_wait_ms: 1.1694543435488134
    mean_inference_ms: 4.747736551566901
    mean_raw_obs_processing_ms: 0.40449835849169524
  time_since_restore: 309.98259234428406
  time_this_iter_s: 34.219398736953735
  time_total_s: 309.98259234428406
  timers:
    learn_throughput: 5942.846
    learn_time_ms: 27224.667
    sample_throughput: 22666.069
    sample_time_ms: 7138.07
    update_time_ms: 25.807
  timestamp: 1602462545
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 31f4e_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_31f4e_00000 | RUNNING  | 172.17.0.4:1801 |      9 |          309.983 | 1456128 |   229.56 |              284.051 |              105.111 |            856.613 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_31f4e_00000:
  custom_metrics:
    time_step_max: 4130
    time_step_mean: 3526.088586956522
    time_step_min: 3213
  date: 2020-10-12_00-29-39
  done: false
  episode_len_mean: 849.7516059957173
  episode_reward_max: 284.050505050505
  episode_reward_mean: 231.95816840784704
  episode_reward_min: 105.11111111111099
  episodes_this_iter: 288
  episodes_total: 1868
  experiment_id: 262130d2f50c4fb8a06c2e91905acad9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9608143419027328
        entropy_coeff: 0.0005000000000000001
        kl: 0.010597323377927145
        model: {}
        policy_loss: -0.017742432594483642
        total_loss: 20.90774122873942
        vf_explained_var: 0.9734821915626526
        vf_loss: 20.92384433746338
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.472500000000004
    gpu_util_percent0: 0.33999999999999997
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.78
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 1801
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15327867013720703
    mean_env_wait_ms: 1.172411400539201
    mean_inference_ms: 4.700741072986394
    mean_raw_obs_processing_ms: 0.40182527619292596
  time_since_restore: 344.5986292362213
  time_this_iter_s: 34.616036891937256
  time_total_s: 344.5986292362213
  timers:
    learn_throughput: 5935.373
    learn_time_ms: 27258.944
    sample_throughput: 22719.126
    sample_time_ms: 7121.401
    update_time_ms: 25.559
  timestamp: 1602462579
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 31f4e_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_31f4e_00000 | RUNNING  | 172.17.0.4:1801 |     10 |          344.599 | 1617920 |  231.958 |              284.051 |              105.111 |            849.752 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_31f4e_00000:
  custom_metrics:
    time_step_max: 4130
    time_step_mean: 3516.6929911154984
    time_step_min: 3213
  date: 2020-10-12_00-30-14
  done: false
  episode_len_mean: 846.5243427458618
  episode_reward_max: 284.050505050505
  episode_reward_mean: 233.19209131234433
  episode_reward_min: 105.11111111111099
  episodes_this_iter: 186
  episodes_total: 2054
  experiment_id: 262130d2f50c4fb8a06c2e91905acad9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9466322610775629
        entropy_coeff: 0.0005000000000000001
        kl: 0.013187641277909279
        model: {}
        policy_loss: -0.02057140596055736
        total_loss: 11.86665932337443
        vf_explained_var: 0.9799923300743103
        vf_loss: 11.885066429773966
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.921951219512195
    gpu_util_percent0: 0.294390243902439
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7853658536585377
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 1801
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15286634604094287
    mean_env_wait_ms: 1.1740759886584133
    mean_inference_ms: 4.6756357147157726
    mean_raw_obs_processing_ms: 0.40046264675084464
  time_since_restore: 379.2124619483948
  time_this_iter_s: 34.61383271217346
  time_total_s: 379.2124619483948
  timers:
    learn_throughput: 5926.527
    learn_time_ms: 27299.63
    sample_throughput: 23336.878
    sample_time_ms: 6932.89
    update_time_ms: 26.565
  timestamp: 1602462614
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 31f4e_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_31f4e_00000 | RUNNING  | 172.17.0.4:1801 |     11 |          379.212 | 1779712 |  233.192 |              284.051 |              105.111 |            846.524 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_31f4e_00000:
  custom_metrics:
    time_step_max: 4130
    time_step_mean: 3508.822344322344
    time_step_min: 3202
  date: 2020-10-12_00-30-49
  done: false
  episode_len_mean: 843.2952079566004
  episode_reward_max: 284.050505050505
  episode_reward_mean: 234.4434032915044
  episode_reward_min: 105.11111111111099
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 262130d2f50c4fb8a06c2e91905acad9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9265244056781133
        entropy_coeff: 0.0005000000000000001
        kl: 0.012395760898167888
        model: {}
        policy_loss: -0.021642743066574138
        total_loss: 10.03646445274353
        vf_explained_var: 0.9796914458274841
        vf_loss: 10.05609130859375
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.27
    gpu_util_percent0: 0.327
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7900000000000005
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 1801
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15254628739844178
    mean_env_wait_ms: 1.1753956425817547
    mean_inference_ms: 4.656743263732156
    mean_raw_obs_processing_ms: 0.39938935023612465
  time_since_restore: 413.73945450782776
  time_this_iter_s: 34.52699255943298
  time_total_s: 413.73945450782776
  timers:
    learn_throughput: 5914.728
    learn_time_ms: 27354.091
    sample_throughput: 23513.645
    sample_time_ms: 6880.771
    update_time_ms: 28.773
  timestamp: 1602462649
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 31f4e_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_31f4e_00000 | RUNNING  | 172.17.0.4:1801 |     12 |          413.739 | 1941504 |  234.443 |              284.051 |              105.111 |            843.295 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_31f4e_00000:
  custom_metrics:
    time_step_max: 4130
    time_step_mean: 3500.65888841748
    time_step_min: 3202
  date: 2020-10-12_00-31-23
  done: false
  episode_len_mean: 840.0402515723271
  episode_reward_max: 284.050505050505
  episode_reward_mean: 235.73699256718106
  episode_reward_min: 105.11111111111099
  episodes_this_iter: 173
  episodes_total: 2385
  experiment_id: 262130d2f50c4fb8a06c2e91905acad9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8866900751988093
        entropy_coeff: 0.0005000000000000001
        kl: 0.011962157518913349
        model: {}
        policy_loss: -0.01799912805533192
        total_loss: 12.36307692527771
        vf_explained_var: 0.9787567257881165
        vf_loss: 12.379127422968546
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.241463414634147
    gpu_util_percent0: 0.30902439024390244
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7829268292682934
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 1801
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15222812776926828
    mean_env_wait_ms: 1.176871950134154
    mean_inference_ms: 4.637969648031376
    mean_raw_obs_processing_ms: 0.3982945133842468
  time_since_restore: 448.11132979393005
  time_this_iter_s: 34.371875286102295
  time_total_s: 448.11132979393005
  timers:
    learn_throughput: 5908.998
    learn_time_ms: 27380.615
    sample_throughput: 23534.557
    sample_time_ms: 6874.657
    update_time_ms: 30.038
  timestamp: 1602462683
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 31f4e_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_31f4e_00000 | RUNNING  | 172.17.0.4:1801 |     13 |          448.111 | 2103296 |  235.737 |              284.051 |              105.111 |             840.04 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_31f4e_00000:
  custom_metrics:
    time_step_max: 4130
    time_step_mean: 3488.963074604371
    time_step_min: 3189
  date: 2020-10-12_00-31-58
  done: false
  episode_len_mean: 835.1636838180463
  episode_reward_max: 284.050505050505
  episode_reward_mean: 237.40169028088476
  episode_reward_min: 105.11111111111099
  episodes_this_iter: 297
  episodes_total: 2682
  experiment_id: 262130d2f50c4fb8a06c2e91905acad9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.881892000635465
        entropy_coeff: 0.0005000000000000001
        kl: 0.010719634980584184
        model: {}
        policy_loss: -0.01789320931614687
        total_loss: 15.254487991333008
        vf_explained_var: 0.9796085953712463
        vf_loss: 15.270678043365479
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.3625
    gpu_util_percent0: 0.39925
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7775000000000007
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 1801
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15176237730124684
    mean_env_wait_ms: 1.1792622328582354
    mean_inference_ms: 4.6101923752504055
    mean_raw_obs_processing_ms: 0.3967546832201237
  time_since_restore: 482.49509859085083
  time_this_iter_s: 34.383768796920776
  time_total_s: 482.49509859085083
  timers:
    learn_throughput: 5908.438
    learn_time_ms: 27383.211
    sample_throughput: 23481.353
    sample_time_ms: 6890.233
    update_time_ms: 29.07
  timestamp: 1602462718
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 31f4e_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_31f4e_00000 | RUNNING  | 172.17.0.4:1801 |     14 |          482.495 | 2265088 |  237.402 |              284.051 |              105.111 |            835.164 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_31f4e_00000:
  custom_metrics:
    time_step_max: 4130
    time_step_mean: 3484.205255681818
    time_step_min: 3189
  date: 2020-10-12_00-32-32
  done: false
  episode_len_mean: 833.3132911392405
  episode_reward_max: 284.050505050505
  episode_reward_mean: 238.26922175339882
  episode_reward_min: 105.11111111111099
  episodes_this_iter: 162
  episodes_total: 2844
  experiment_id: 262130d2f50c4fb8a06c2e91905acad9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8567106078068415
        entropy_coeff: 0.0005000000000000001
        kl: 0.012384066125378013
        model: {}
        policy_loss: -0.018370698526268825
        total_loss: 8.730159600575766
        vf_explained_var: 0.9836559891700745
        vf_loss: 8.746481815973917
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.2125
    gpu_util_percent0: 0.3
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7900000000000005
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 1801
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15153947047167568
    mean_env_wait_ms: 1.1804538890798408
    mean_inference_ms: 4.596915465284048
    mean_raw_obs_processing_ms: 0.39601932082594643
  time_since_restore: 516.8373205661774
  time_this_iter_s: 34.34222197532654
  time_total_s: 516.8373205661774
  timers:
    learn_throughput: 5906.316
    learn_time_ms: 27393.05
    sample_throughput: 23482.557
    sample_time_ms: 6889.88
    update_time_ms: 28.989
  timestamp: 1602462752
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 31f4e_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_31f4e_00000 | RUNNING  | 172.17.0.4:1801 |     15 |          516.837 | 2426880 |  238.269 |              284.051 |              105.111 |            833.313 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_31f4e_00000:
  custom_metrics:
    time_step_max: 4130
    time_step_mean: 3479.892064559516
    time_step_min: 3174
  date: 2020-10-12_00-33-07
  done: false
  episode_len_mean: 831.5366422385076
  episode_reward_max: 285.11111111111103
  episode_reward_mean: 238.92720341321262
  episode_reward_min: 105.11111111111099
  episodes_this_iter: 158
  episodes_total: 3002
  experiment_id: 262130d2f50c4fb8a06c2e91905acad9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8413337965806326
        entropy_coeff: 0.0005000000000000001
        kl: 0.011444773680220047
        model: {}
        policy_loss: -0.021845395172325272
        total_loss: 9.239734888076782
        vf_explained_var: 0.9821836352348328
        vf_loss: 9.259711901346842
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.747500000000002
    gpu_util_percent0: 0.26875
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.785
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 1801
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1513382812262425
    mean_env_wait_ms: 1.181542597389898
    mean_inference_ms: 4.584867919974745
    mean_raw_obs_processing_ms: 0.395334768804124
  time_since_restore: 551.2735288143158
  time_this_iter_s: 34.43620824813843
  time_total_s: 551.2735288143158
  timers:
    learn_throughput: 5900.973
    learn_time_ms: 27417.852
    sample_throughput: 23500.456
    sample_time_ms: 6884.632
    update_time_ms: 30.47
  timestamp: 1602462787
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 31f4e_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_31f4e_00000 | RUNNING  | 172.17.0.4:1801 |     16 |          551.274 | 2588672 |  238.927 |              285.111 |              105.111 |            831.537 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_31f4e_00000:
  custom_metrics:
    time_step_max: 4130
    time_step_mean: 3471.5680272108843
    time_step_min: 3174
  date: 2020-10-12_00-33-41
  done: false
  episode_len_mean: 828.4785407725321
  episode_reward_max: 285.11111111111103
  episode_reward_mean: 240.17646421294478
  episode_reward_min: 105.11111111111099
  episodes_this_iter: 260
  episodes_total: 3262
  experiment_id: 262130d2f50c4fb8a06c2e91905acad9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8153345137834549
        entropy_coeff: 0.0005000000000000001
        kl: 0.011123254196718335
        model: {}
        policy_loss: -0.017276848782785237
        total_loss: 14.129539489746094
        vf_explained_var: 0.9802613854408264
        vf_loss: 14.144999742507935
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.597500000000004
    gpu_util_percent0: 0.36725
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.775
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 1801
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15103482578464936
    mean_env_wait_ms: 1.1833468658247237
    mean_inference_ms: 4.5668509002536535
    mean_raw_obs_processing_ms: 0.3943317189498018
  time_since_restore: 585.3237767219543
  time_this_iter_s: 34.05024790763855
  time_total_s: 585.3237767219543
  timers:
    learn_throughput: 5903.152
    learn_time_ms: 27407.729
    sample_throughput: 23518.081
    sample_time_ms: 6879.473
    update_time_ms: 31.448
  timestamp: 1602462821
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 31f4e_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_31f4e_00000 | RUNNING  | 172.17.0.4:1801 |     17 |          585.324 | 2750464 |  240.176 |              285.111 |              105.111 |            828.479 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_31f4e_00000:
  custom_metrics:
    time_step_max: 4130
    time_step_mean: 3464.8854408352668
    time_step_min: 3171
  date: 2020-10-12_00-34-15
  done: true
  episode_len_mean: 826.3947065592636
  episode_reward_max: 285.56565656565664
  episode_reward_mean: 241.16679162162467
  episode_reward_min: 105.11111111111099
  episodes_this_iter: 214
  episodes_total: 3476
  experiment_id: 262130d2f50c4fb8a06c2e91905acad9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8140861590703329
        entropy_coeff: 0.0005000000000000001
        kl: 0.01158733774597446
        model: {}
        policy_loss: -0.02097339394579952
        total_loss: 8.168803294499716
        vf_explained_var: 0.9859420657157898
        vf_loss: 8.187865932782492
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.9075
    gpu_util_percent0: 0.37225
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7925000000000004
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 1801
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15082031490098116
    mean_env_wait_ms: 1.1846652571828515
    mean_inference_ms: 4.553707722225714
    mean_raw_obs_processing_ms: 0.3936132552910897
  time_since_restore: 619.3901443481445
  time_this_iter_s: 34.066367626190186
  time_total_s: 619.3901443481445
  timers:
    learn_throughput: 5906.024
    learn_time_ms: 27394.402
    sample_throughput: 23514.878
    sample_time_ms: 6880.41
    update_time_ms: 31.723
  timestamp: 1602462855
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 31f4e_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_31f4e_00000 | TERMINATED |       |     18 |           619.39 | 2912256 |  241.167 |              285.566 |              105.111 |            826.395 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_31f4e_00000 | TERMINATED |       |     18 |           619.39 | 2912256 |  241.167 |              285.566 |              105.111 |            826.395 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


