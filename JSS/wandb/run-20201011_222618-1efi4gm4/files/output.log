2020-10-11 22:26:22,289	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_cb556_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=76483)[0m 2020-10-11 22:26:24,985	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=76482)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76482)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76405)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76405)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76508)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76508)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76433)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76433)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76477)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76477)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76469)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76469)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76460)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76460)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76411)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76411)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76391)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76391)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76502)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76502)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76448)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76448)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76390)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76390)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76478)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76478)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76496)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76496)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76449)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76449)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76467)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76467)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76492)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76492)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76472)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76472)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76381)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76381)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76389)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76389)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76382)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76382)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76373)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76373)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76408)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76408)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76454)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76454)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76387)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76387)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76466)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76466)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76458)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76458)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76451)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76451)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76375)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76375)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76487)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76487)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76488)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76488)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76402)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76402)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76406)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76406)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76450)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76450)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76445)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76445)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76475)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76475)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76372)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76372)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76380)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76380)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76435)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76435)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76452)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76452)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76439)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76439)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76489)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76489)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76374)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76374)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76379)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76379)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76378)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76378)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76392)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76392)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76412)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76412)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76384)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76384)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76398)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76398)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76446)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76446)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76397)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76397)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76444)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76444)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76431)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76431)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76438)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76438)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76486)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76486)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76443)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76443)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76457)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76457)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76453)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76453)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76399)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76399)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76376)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76376)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76470)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76470)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76471)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76471)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76388)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76388)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76480)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76480)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76394)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76394)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76441)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76441)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76456)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76456)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76491)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76491)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76493)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76493)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76499)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76499)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76473)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76473)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76377)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76377)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76510)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76510)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76501)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76501)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76385)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76385)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76447)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76447)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76418)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76418)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76442)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76442)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76459)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76459)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_cb556_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-11_22-26-57
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 72e30bf5241d4a978bc93780059fd965
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1850829323132832
        entropy_coeff: 0.0001
        kl: 0.004093626630492508
        model: {}
        policy_loss: -0.007868677183675269
        total_loss: 507.0761362711589
        vf_explained_var: 0.540532648563385
        vf_loss: 507.0832926432292
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.323529411764707
    gpu_util_percent0: 0.39529411764705885
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5558823529411767
    vram_util_percent0: 0.08636872262844136
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 76483
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16788368130878523
    mean_env_wait_ms: 1.1679277364101333
    mean_inference_ms: 5.4492530663759124
    mean_raw_obs_processing_ms: 0.44686299777759675
  time_since_restore: 27.417211294174194
  time_this_iter_s: 27.417211294174194
  time_total_s: 27.417211294174194
  timers:
    learn_throughput: 8659.466
    learn_time_ms: 18683.831
    sample_throughput: 18700.298
    sample_time_ms: 8651.841
    update_time_ms: 46.069
  timestamp: 1602455217
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: cb556_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_cb556_00000 | RUNNING  | 172.17.0.4:76483 |      1 |          27.4172 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_cb556_00000:
  custom_metrics:
    time_step_max: 4139
    time_step_mean: 3608.8055555555557
    time_step_min: 3250
  date: 2020-10-11_22-27-24
  done: false
  episode_len_mean: 890.7056962025316
  episode_reward_max: 273.5959595959592
  episode_reward_mean: 217.07793121084234
  episode_reward_min: 138.89898989898958
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 72e30bf5241d4a978bc93780059fd965
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1567376752694447
        entropy_coeff: 0.0001
        kl: 0.0070590757532045245
        model: {}
        policy_loss: -0.010883362002156597
        total_loss: 129.9215234120687
        vf_explained_var: 0.8072310090065002
        vf_loss: 129.93181800842285
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.25
    gpu_util_percent0: 0.3675
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.753125
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 76483
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16390359387453543
    mean_env_wait_ms: 1.16497772562309
    mean_inference_ms: 5.299528508262362
    mean_raw_obs_processing_ms: 0.4369767961883029
  time_since_restore: 53.73591208457947
  time_this_iter_s: 26.318700790405273
  time_total_s: 53.73591208457947
  timers:
    learn_throughput: 8697.541
    learn_time_ms: 18602.04
    sample_throughput: 19780.142
    sample_time_ms: 8179.517
    update_time_ms: 44.749
  timestamp: 1602455244
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: cb556_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_cb556_00000 | RUNNING  | 172.17.0.4:76483 |      2 |          53.7359 | 323584 |  217.078 |              273.596 |              138.899 |            890.706 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_cb556_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3602.798206278027
    time_step_min: 3250
  date: 2020-10-11_22-27-49
  done: false
  episode_len_mean: 886.1392405063291
  episode_reward_max: 273.5959595959592
  episode_reward_mean: 218.34343434343413
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 72e30bf5241d4a978bc93780059fd965
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.143834412097931
        entropy_coeff: 0.0001
        kl: 0.00900065409950912
        model: {}
        policy_loss: -0.012952111646882258
        total_loss: 62.266885121663414
        vf_explained_var: 0.8935738205909729
        vf_loss: 62.279051780700684
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.435483870967747
    gpu_util_percent0: 0.38064516129032255
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.770967741935483
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 76483
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16108652237071855
    mean_env_wait_ms: 1.1646816734007794
    mean_inference_ms: 5.151894600429613
    mean_raw_obs_processing_ms: 0.42866006379687815
  time_since_restore: 79.27923917770386
  time_this_iter_s: 25.54332709312439
  time_total_s: 79.27923917770386
  timers:
    learn_throughput: 8686.967
    learn_time_ms: 18624.683
    sample_throughput: 20962.682
    sample_time_ms: 7718.096
    update_time_ms: 39.028
  timestamp: 1602455269
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: cb556_00000
  
== Status ==
Memory usage on this node: 28.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_cb556_00000 | RUNNING  | 172.17.0.4:76483 |      3 |          79.2792 | 485376 |  218.343 |              273.596 |               137.99 |            886.139 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_cb556_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3596.7533112582782
    time_step_min: 3250
  date: 2020-10-11_22-28-15
  done: false
  episode_len_mean: 882.5870253164557
  episode_reward_max: 273.5959595959592
  episode_reward_mean: 219.16725802327048
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 72e30bf5241d4a978bc93780059fd965
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1256821552912395
        entropy_coeff: 0.0001
        kl: 0.00838832138106227
        model: {}
        policy_loss: -0.013208418832315752
        total_loss: 44.44708792368571
        vf_explained_var: 0.9239999651908875
        vf_loss: 44.45957056681315
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.683333333333334
    gpu_util_percent0: 0.3423333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.769999999999999
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 76483
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15906630879241562
    mean_env_wait_ms: 1.1645719023705734
    mean_inference_ms: 5.03977364700919
    mean_raw_obs_processing_ms: 0.42212708911563546
  time_since_restore: 104.65956211090088
  time_this_iter_s: 25.38032293319702
  time_total_s: 104.65956211090088
  timers:
    learn_throughput: 8684.483
    learn_time_ms: 18630.008
    sample_throughput: 21713.622
    sample_time_ms: 7451.175
    update_time_ms: 38.21
  timestamp: 1602455295
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: cb556_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_cb556_00000 | RUNNING  | 172.17.0.4:76483 |      4 |           104.66 | 647168 |  219.167 |              273.596 |               137.99 |            882.587 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_cb556_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3591.5629921259842
    time_step_min: 3242
  date: 2020-10-11_22-28-40
  done: false
  episode_len_mean: 878.2569620253165
  episode_reward_max: 274.8080808080809
  episode_reward_mean: 220.1586753612068
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 72e30bf5241d4a978bc93780059fd965
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0966354012489319
        entropy_coeff: 0.0001
        kl: 0.008652650052681565
        model: {}
        policy_loss: -0.013121832271281164
        total_loss: 35.068282763163246
        vf_explained_var: 0.9439868927001953
        vf_loss: 35.080649058024086
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.309677419354838
    gpu_util_percent0: 0.38419354838709674
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.770967741935483
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 76483
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15758412380350753
    mean_env_wait_ms: 1.1654900329769302
    mean_inference_ms: 4.953610822247257
    mean_raw_obs_processing_ms: 0.41712834146338557
  time_since_restore: 129.89139199256897
  time_this_iter_s: 25.23182988166809
  time_total_s: 129.89139199256897
  timers:
    learn_throughput: 8698.998
    learn_time_ms: 18598.924
    sample_throughput: 22167.447
    sample_time_ms: 7298.63
    update_time_ms: 34.672
  timestamp: 1602455320
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: cb556_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_cb556_00000 | RUNNING  | 172.17.0.4:76483 |      5 |          129.891 | 808960 |  220.159 |              274.808 |               137.99 |            878.257 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_cb556_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3575.0697674418607
    time_step_min: 3187
  date: 2020-10-11_22-29-05
  done: false
  episode_len_mean: 868.2937443336356
  episode_reward_max: 283.14141414141375
  episode_reward_mean: 223.16600272901252
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 313
  episodes_total: 1103
  experiment_id: 72e30bf5241d4a978bc93780059fd965
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0826950172583263
        entropy_coeff: 0.0001
        kl: 0.008017374784685671
        model: {}
        policy_loss: -0.009852176726174852
        total_loss: 37.77317714691162
        vf_explained_var: 0.9565708637237549
        vf_loss: 37.78233687082926
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.030000000000005
    gpu_util_percent0: 0.3003333333333334
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.766666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 76483
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15563671117673772
    mean_env_wait_ms: 1.168900644689346
    mean_inference_ms: 4.83753679732278
    mean_raw_obs_processing_ms: 0.41080868027999956
  time_since_restore: 155.07761406898499
  time_this_iter_s: 25.186222076416016
  time_total_s: 155.07761406898499
  timers:
    learn_throughput: 8716.252
    learn_time_ms: 18562.106
    sample_throughput: 22464.044
    sample_time_ms: 7202.265
    update_time_ms: 35.637
  timestamp: 1602455345
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: cb556_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_cb556_00000 | RUNNING  | 172.17.0.4:76483 |      6 |          155.078 | 970752 |  223.166 |              283.141 |               137.99 |            868.294 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_cb556_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3561.846278317152
    time_step_min: 3187
  date: 2020-10-11_22-29-31
  done: false
  episode_len_mean: 862.3742088607595
  episode_reward_max: 283.14141414141375
  episode_reward_mean: 225.2731747858328
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 161
  episodes_total: 1264
  experiment_id: 72e30bf5241d4a978bc93780059fd965
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0706466734409332
        entropy_coeff: 0.0001
        kl: 0.007869300238477686
        model: {}
        policy_loss: -0.013351764432930699
        total_loss: 18.482054869333904
        vf_explained_var: 0.9659532904624939
        vf_loss: 18.49472649892171
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.280645161290327
    gpu_util_percent0: 0.3958064516129033
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7806451612903222
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 76483
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15491491663103854
    mean_env_wait_ms: 1.1705345940002487
    mean_inference_ms: 4.794355285172476
    mean_raw_obs_processing_ms: 0.40839931344321956
  time_since_restore: 180.36618041992188
  time_this_iter_s: 25.28856635093689
  time_total_s: 180.36618041992188
  timers:
    learn_throughput: 8716.374
    learn_time_ms: 18561.848
    sample_throughput: 22718.033
    sample_time_ms: 7121.743
    update_time_ms: 35.812
  timestamp: 1602455371
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: cb556_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_cb556_00000 | RUNNING  | 172.17.0.4:76483 |      7 |          180.366 | 1132544 |  225.273 |              283.141 |               137.99 |            862.374 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_cb556_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3551.647776183644
    time_step_min: 3187
  date: 2020-10-11_22-29-56
  done: false
  episode_len_mean: 858.2130801687764
  episode_reward_max: 286.9292929292936
  episode_reward_mean: 227.1781954566763
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 72e30bf5241d4a978bc93780059fd965
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0530053079128265
        entropy_coeff: 0.0001
        kl: 0.007424288894981146
        model: {}
        policy_loss: -0.014031020080437884
        total_loss: 18.28844420115153
        vf_explained_var: 0.9650914669036865
        vf_loss: 18.30183744430542
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.39032258064516
    gpu_util_percent0: 0.32838709677419353
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.780645161290322
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 76483
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15430797346195743
    mean_env_wait_ms: 1.1719205386116904
    mean_inference_ms: 4.757935892776756
    mean_raw_obs_processing_ms: 0.4063113407210735
  time_since_restore: 205.877259016037
  time_this_iter_s: 25.511078596115112
  time_total_s: 205.877259016037
  timers:
    learn_throughput: 8705.848
    learn_time_ms: 18584.29
    sample_throughput: 22889.39
    sample_time_ms: 7068.428
    update_time_ms: 34.348
  timestamp: 1602455396
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: cb556_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_cb556_00000 | RUNNING  | 172.17.0.4:76483 |      8 |          205.877 | 1294336 |  227.178 |              286.929 |               137.99 |            858.213 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_cb556_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3540.2345360824743
    time_step_min: 3187
  date: 2020-10-11_22-30-21
  done: false
  episode_len_mean: 854.4341772151898
  episode_reward_max: 286.9292929292936
  episode_reward_mean: 228.90886715253788
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 72e30bf5241d4a978bc93780059fd965
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0118485788504283
        entropy_coeff: 0.0001
        kl: 0.007579043585186203
        model: {}
        policy_loss: -0.010258643926742176
        total_loss: 15.40296204884847
        vf_explained_var: 0.9705337882041931
        vf_loss: 15.412563880284628
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.263333333333335
    gpu_util_percent0: 0.3676666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.77
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 76483
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15378268330477587
    mean_env_wait_ms: 1.1732586569337242
    mean_inference_ms: 4.726188139611932
    mean_raw_obs_processing_ms: 0.4044277910959929
  time_since_restore: 231.01398348808289
  time_this_iter_s: 25.1367244720459
  time_total_s: 231.01398348808289
  timers:
    learn_throughput: 8717.993
    learn_time_ms: 18558.401
    sample_throughput: 23026.954
    sample_time_ms: 7026.201
    update_time_ms: 35.293
  timestamp: 1602455421
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: cb556_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_cb556_00000 | RUNNING  | 172.17.0.4:76483 |      9 |          231.014 | 1456128 |  228.909 |              286.929 |               137.99 |            854.434 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_cb556_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3518.7373791621912
    time_step_min: 3186
  date: 2020-10-11_22-30-47
  done: false
  episode_len_mean: 847.1243386243386
  episode_reward_max: 286.9292929292936
  episode_reward_mean: 232.65247715247702
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 310
  episodes_total: 1890
  experiment_id: 72e30bf5241d4a978bc93780059fd965
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9885825465122858
        entropy_coeff: 0.0001
        kl: 0.00694818701595068
        model: {}
        policy_loss: -0.011202118165480593
        total_loss: 19.333553791046143
        vf_explained_var: 0.9741263389587402
        vf_loss: 19.344160079956055
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.296774193548387
    gpu_util_percent0: 0.36903225806451617
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.761290322580645
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 76483
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15293919754407126
    mean_env_wait_ms: 1.1760092596580218
    mean_inference_ms: 4.675520294813949
    mean_raw_obs_processing_ms: 0.4014957598679163
  time_since_restore: 256.30957770347595
  time_this_iter_s: 25.295594215393066
  time_total_s: 256.30957770347595
  timers:
    learn_throughput: 8721.891
    learn_time_ms: 18550.105
    sample_throughput: 23120.633
    sample_time_ms: 6997.732
    update_time_ms: 33.949
  timestamp: 1602455447
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: cb556_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_cb556_00000 | RUNNING  | 172.17.0.4:76483 |     10 |           256.31 | 1617920 |  232.652 |              286.929 |               137.99 |            847.124 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_cb556_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3508.0286278381045
    time_step_min: 3186
  date: 2020-10-11_22-31-12
  done: false
  episode_len_mean: 843.8758519961052
  episode_reward_max: 286.9292929292936
  episode_reward_mean: 234.34446214825948
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 164
  episodes_total: 2054
  experiment_id: 72e30bf5241d4a978bc93780059fd965
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9782296568155289
        entropy_coeff: 0.0001
        kl: 0.0074202436953783035
        model: {}
        policy_loss: -0.011524421182305863
        total_loss: 11.349893887837728
        vf_explained_var: 0.9778836369514465
        vf_loss: 11.360774596532186
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.35333333333334
    gpu_util_percent0: 0.358
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.78
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 76483
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15257416751379102
    mean_env_wait_ms: 1.1773124631914709
    mean_inference_ms: 4.653471886051546
    mean_raw_obs_processing_ms: 0.40022726928307334
  time_since_restore: 281.4631359577179
  time_this_iter_s: 25.153558254241943
  time_total_s: 281.4631359577179
  timers:
    learn_throughput: 8734.023
    learn_time_ms: 18524.339
    sample_throughput: 23799.893
    sample_time_ms: 6798.014
    update_time_ms: 31.417
  timestamp: 1602455472
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: cb556_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_cb556_00000 | RUNNING  | 172.17.0.4:76483 |     11 |          281.463 | 1779712 |  234.344 |              286.929 |               137.99 |            843.876 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_cb556_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3497.526098901099
    time_step_min: 3186
  date: 2020-10-11_22-31-37
  done: false
  episode_len_mean: 840.8141952983725
  episode_reward_max: 289.5050505050505
  episode_reward_mean: 236.0104069629385
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 72e30bf5241d4a978bc93780059fd965
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9659954756498337
        entropy_coeff: 0.0001
        kl: 0.00687529263086617
        model: {}
        policy_loss: -0.011743300943635404
        total_loss: 12.973399877548218
        vf_explained_var: 0.9719108939170837
        vf_loss: 12.984552383422852
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.864516129032257
    gpu_util_percent0: 0.38258064516129037
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 76483
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15225594626949235
    mean_env_wait_ms: 1.1784634484964185
    mean_inference_ms: 4.634321062313492
    mean_raw_obs_processing_ms: 0.39908978969026243
  time_since_restore: 306.6985595226288
  time_this_iter_s: 25.23542356491089
  time_total_s: 306.6985595226288
  timers:
    learn_throughput: 8733.055
    learn_time_ms: 18526.392
    sample_throughput: 24194.545
    sample_time_ms: 6687.127
    update_time_ms: 30.671
  timestamp: 1602455497
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: cb556_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_cb556_00000 | RUNNING  | 172.17.0.4:76483 |     12 |          306.699 | 1941504 |   236.01 |              289.505 |               137.99 |            840.814 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_cb556_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3487.3178360101438
    time_step_min: 3170
  date: 2020-10-11_22-32-03
  done: false
  episode_len_mean: 837.5388471177945
  episode_reward_max: 289.5050505050505
  episode_reward_mean: 237.452001215159
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 182
  episodes_total: 2394
  experiment_id: 72e30bf5241d4a978bc93780059fd965
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9220593820015589
        entropy_coeff: 0.0001
        kl: 0.007104225301494201
        model: {}
        policy_loss: -0.013087665856194993
        total_loss: 14.173670689264933
        vf_explained_var: 0.976102352142334
        vf_loss: 14.186140378316244
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.89333333333333
    gpu_util_percent0: 0.37166666666666676
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7666666666666657
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 76483
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15191936081627483
    mean_env_wait_ms: 1.1798696251408876
    mean_inference_ms: 4.614257974104745
    mean_raw_obs_processing_ms: 0.3978902594908314
  time_since_restore: 332.08618450164795
  time_this_iter_s: 25.387624979019165
  time_total_s: 332.08618450164795
  timers:
    learn_throughput: 8740.09
    learn_time_ms: 18511.479
    sample_throughput: 24197.262
    sample_time_ms: 6686.376
    update_time_ms: 30.149
  timestamp: 1602455523
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: cb556_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_cb556_00000 | RUNNING  | 172.17.0.4:76483 |     13 |          332.086 | 2103296 |  237.452 |              289.505 |               137.99 |            837.539 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_cb556_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3473.3540255831454
    time_step_min: 3170
  date: 2020-10-11_22-32-28
  done: false
  episode_len_mean: 833.4810126582279
  episode_reward_max: 289.5050505050505
  episode_reward_mean: 239.5821054927532
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 292
  episodes_total: 2686
  experiment_id: 72e30bf5241d4a978bc93780059fd965
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9201588133970896
        entropy_coeff: 0.0001
        kl: 0.006468101870268583
        model: {}
        policy_loss: -0.012541183774980405
        total_loss: 12.514065821965536
        vf_explained_var: 0.980458676815033
        vf_loss: 12.526052554448446
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.45483870967743
    gpu_util_percent0: 0.3496774193548387
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.764516129032258
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 76483
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15146937906351388
    mean_env_wait_ms: 1.1818544660225188
    mean_inference_ms: 4.586878425758582
    mean_raw_obs_processing_ms: 0.39626516393763483
  time_since_restore: 357.4376184940338
  time_this_iter_s: 25.351433992385864
  time_total_s: 357.4376184940338
  timers:
    learn_throughput: 8743.407
    learn_time_ms: 18504.456
    sample_throughput: 24181.99
    sample_time_ms: 6690.599
    update_time_ms: 29.232
  timestamp: 1602455548
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: cb556_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_cb556_00000 | RUNNING  | 172.17.0.4:76483 |     14 |          357.438 | 2265088 |  239.582 |              289.505 |               137.99 |            833.481 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_cb556_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3466.54296875
    time_step_min: 3170
  date: 2020-10-11_22-32-54
  done: false
  episode_len_mean: 831.3913502109705
  episode_reward_max: 289.5050505050505
  episode_reward_mean: 240.64524996803468
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: 72e30bf5241d4a978bc93780059fd965
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9064158648252487
        entropy_coeff: 0.0001
        kl: 0.00678737946630766
        model: {}
        policy_loss: -0.012710827655003717
        total_loss: 10.679505268732706
        vf_explained_var: 0.9777107238769531
        vf_loss: 10.691628138224283
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.453333333333337
    gpu_util_percent0: 0.4003333333333334
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.776666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 76483
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1512552092133331
    mean_env_wait_ms: 1.1828432384083116
    mean_inference_ms: 4.5738651854161185
    mean_raw_obs_processing_ms: 0.3954877186731981
  time_since_restore: 382.63721203804016
  time_this_iter_s: 25.199593544006348
  time_total_s: 382.63721203804016
  timers:
    learn_throughput: 8749.424
    learn_time_ms: 18491.732
    sample_throughput: 24153.792
    sample_time_ms: 6698.41
    update_time_ms: 30.186
  timestamp: 1602455574
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: cb556_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_cb556_00000 | RUNNING  | 172.17.0.4:76483 |     15 |          382.637 | 2426880 |  240.645 |              289.505 |               137.99 |            831.391 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_cb556_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3459.892737054472
    time_step_min: 3170
  date: 2020-10-11_22-33-19
  done: false
  episode_len_mean: 830.020652898068
  episode_reward_max: 289.5050505050505
  episode_reward_mean: 241.5691289981762
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 158
  episodes_total: 3002
  experiment_id: 72e30bf5241d4a978bc93780059fd965
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8919036090373993
        entropy_coeff: 0.0001
        kl: 0.0065164086408913136
        model: {}
        policy_loss: -0.011898661767190788
        total_loss: 10.162490367889404
        vf_explained_var: 0.9785982966423035
        vf_loss: 10.173826615015665
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.116129032258062
    gpu_util_percent0: 0.34161290322580656
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7870967741935484
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 76483
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15105666020571468
    mean_env_wait_ms: 1.1837514954980843
    mean_inference_ms: 4.561788674665821
    mean_raw_obs_processing_ms: 0.39474864267769744
  time_since_restore: 408.118332862854
  time_this_iter_s: 25.481120824813843
  time_total_s: 408.118332862854
  timers:
    learn_throughput: 8736.701
    learn_time_ms: 18518.661
    sample_throughput: 24149.217
    sample_time_ms: 6699.679
    update_time_ms: 29.879
  timestamp: 1602455599
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: cb556_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_cb556_00000 | RUNNING  | 172.17.0.4:76483 |     16 |          408.118 | 2588672 |  241.569 |              289.505 |               137.99 |            830.021 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_cb556_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3451.432941903585
    time_step_min: 3158
  date: 2020-10-11_22-33-45
  done: false
  episode_len_mean: 827.9087009803922
  episode_reward_max: 289.5050505050505
  episode_reward_mean: 242.70980020796188
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 262
  episodes_total: 3264
  experiment_id: 72e30bf5241d4a978bc93780059fd965
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8572876205046972
        entropy_coeff: 0.0001
        kl: 0.006706862438780566
        model: {}
        policy_loss: -0.011741302907466888
        total_loss: 15.199506441752115
        vf_explained_var: 0.97942715883255
        vf_loss: 15.210662841796875
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.43225806451613
    gpu_util_percent0: 0.4264516129032258
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322577
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 76483
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15076114130051346
    mean_env_wait_ms: 1.1852592706180367
    mean_inference_ms: 4.543808896497725
    mean_raw_obs_processing_ms: 0.39366397203534287
  time_since_restore: 433.3144235610962
  time_this_iter_s: 25.196090698242188
  time_total_s: 433.3144235610962
  timers:
    learn_throughput: 8745.104
    learn_time_ms: 18500.866
    sample_throughput: 24121.032
    sample_time_ms: 6707.507
    update_time_ms: 29.563
  timestamp: 1602455625
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: cb556_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_cb556_00000 | RUNNING  | 172.17.0.4:76483 |     17 |          433.314 | 2750464 |   242.71 |              289.505 |               137.99 |            827.909 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_cb556_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3445.4002320185614
    time_step_min: 3146
  date: 2020-10-11_22-34-10
  done: false
  episode_len_mean: 826.5290563866513
  episode_reward_max: 289.5050505050505
  episode_reward_mean: 243.6558072090292
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 212
  episodes_total: 3476
  experiment_id: 72e30bf5241d4a978bc93780059fd965
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8529605269432068
        entropy_coeff: 0.0001
        kl: 0.005917649987774591
        model: {}
        policy_loss: -0.011277009830034027
        total_loss: 11.547587235768637
        vf_explained_var: 0.9794904589653015
        vf_loss: 11.558358192443848
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.019999999999996
    gpu_util_percent0: 0.301
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7800000000000002
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 76483
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1505471262721069
    mean_env_wait_ms: 1.1862333545325279
    mean_inference_ms: 4.53075594304773
    mean_raw_obs_processing_ms: 0.3928785019936991
  time_since_restore: 458.4218285083771
  time_this_iter_s: 25.107404947280884
  time_total_s: 458.4218285083771
  timers:
    learn_throughput: 8763.185
    learn_time_ms: 18462.694
    sample_throughput: 24130.314
    sample_time_ms: 6704.927
    update_time_ms: 29.126
  timestamp: 1602455650
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: cb556_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_cb556_00000 | RUNNING  | 172.17.0.4:76483 |     18 |          458.422 | 2912256 |  243.656 |              289.505 |               137.99 |            826.529 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_cb556_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3440.769828064337
    time_step_min: 3110
  date: 2020-10-11_22-34-35
  done: false
  episode_len_mean: 825.8247110621904
  episode_reward_max: 294.80808080808083
  episode_reward_mean: 244.29612303552858
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 158
  episodes_total: 3634
  experiment_id: 72e30bf5241d4a978bc93780059fd965
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8457075009743372
        entropy_coeff: 0.0001
        kl: 0.0065199139062315226
        model: {}
        policy_loss: -0.01116289470034341
        total_loss: 10.043978214263916
        vf_explained_var: 0.9801807403564453
        vf_loss: 10.05457361539205
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.183870967741935
    gpu_util_percent0: 0.33967741935483875
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7870967741935484
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 76483
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15040017684221274
    mean_env_wait_ms: 1.186908736828454
    mean_inference_ms: 4.521815194123893
    mean_raw_obs_processing_ms: 0.39233666918423943
  time_since_restore: 483.88720083236694
  time_this_iter_s: 25.465372323989868
  time_total_s: 483.88720083236694
  timers:
    learn_throughput: 8747.1
    learn_time_ms: 18496.644
    sample_throughput: 24132.983
    sample_time_ms: 6704.186
    update_time_ms: 28.265
  timestamp: 1602455675
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: cb556_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_cb556_00000 | RUNNING  | 172.17.0.4:76483 |     19 |          483.887 | 3074048 |  244.296 |              294.808 |               137.99 |            825.825 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_cb556_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3436.3805732484075
    time_step_min: 3110
  date: 2020-10-11_22-35-01
  done: false
  episode_len_mean: 825.2513171759747
  episode_reward_max: 294.80808080808083
  episode_reward_mean: 244.92866228140193
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 162
  episodes_total: 3796
  experiment_id: 72e30bf5241d4a978bc93780059fd965
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8178661465644836
        entropy_coeff: 0.0001
        kl: 0.006614145318356653
        model: {}
        policy_loss: -0.012304873768395433
        total_loss: 9.505411148071289
        vf_explained_var: 0.9820902943611145
        vf_loss: 9.517136255900065
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.98709677419355
    gpu_util_percent0: 0.3974193548387096
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7774193548387096
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 76483
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15025763875504422
    mean_env_wait_ms: 1.1875497634620629
    mean_inference_ms: 4.51321203291126
    mean_raw_obs_processing_ms: 0.39180882309067355
  time_since_restore: 509.27370524406433
  time_this_iter_s: 25.386504411697388
  time_total_s: 509.27370524406433
  timers:
    learn_throughput: 8742.679
    learn_time_ms: 18505.998
    sample_throughput: 24142.12
    sample_time_ms: 6701.648
    update_time_ms: 29.383
  timestamp: 1602455701
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: cb556_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_cb556_00000 | RUNNING  | 172.17.0.4:76483 |     20 |          509.274 | 3235840 |  244.929 |              294.808 |               137.99 |            825.251 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_cb556_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3430.280848963475
    time_step_min: 3110
  date: 2020-10-11_22-35-27
  done: false
  episode_len_mean: 824.5730392156863
  episode_reward_max: 297.6868686868688
  episode_reward_mean: 245.9245023767082
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 284
  episodes_total: 4080
  experiment_id: 72e30bf5241d4a978bc93780059fd965
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7949359466632208
        entropy_coeff: 0.0001
        kl: 0.005695687839761376
        model: {}
        policy_loss: -0.010721294248166183
        total_loss: 15.119903961817423
        vf_explained_var: 0.9795476794242859
        vf_loss: 15.13013505935669
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.032258064516128
    gpu_util_percent0: 0.38483870967741934
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322573
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 76483
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1500280251599869
    mean_env_wait_ms: 1.1885885255829254
    mean_inference_ms: 4.499496548961973
    mean_raw_obs_processing_ms: 0.39097785003072955
  time_since_restore: 534.9051718711853
  time_this_iter_s: 25.63146662712097
  time_total_s: 534.9051718711853
  timers:
    learn_throughput: 8737.592
    learn_time_ms: 18516.772
    sample_throughput: 24037.124
    sample_time_ms: 6730.922
    update_time_ms: 35.496
  timestamp: 1602455727
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: cb556_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_cb556_00000 | RUNNING  | 172.17.0.4:76483 |     21 |          534.905 | 3397632 |  245.925 |              297.687 |               137.99 |            824.573 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_cb556_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3425.592968381312
    time_step_min: 3110
  date: 2020-10-11_22-35-52
  done: false
  episode_len_mean: 824.3506797937177
  episode_reward_max: 297.6868686868688
  episode_reward_mean: 246.62825157339924
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 186
  episodes_total: 4266
  experiment_id: 72e30bf5241d4a978bc93780059fd965
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7829316059748331
        entropy_coeff: 0.0001
        kl: 0.006042617450778683
        model: {}
        policy_loss: -0.012270252065112194
        total_loss: 7.568831443786621
        vf_explained_var: 0.9859895706176758
        vf_loss: 7.580575466156006
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.50666666666667
    gpu_util_percent0: 0.32833333333333337
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7899999999999996
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 76483
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14989834833962512
    mean_env_wait_ms: 1.1891048976423704
    mean_inference_ms: 4.491290748057144
    mean_raw_obs_processing_ms: 0.39050067890507106
  time_since_restore: 560.2034115791321
  time_this_iter_s: 25.298239707946777
  time_total_s: 560.2034115791321
  timers:
    learn_throughput: 8736.333
    learn_time_ms: 18519.441
    sample_throughput: 24020.551
    sample_time_ms: 6735.566
    update_time_ms: 34.244
  timestamp: 1602455752
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: cb556_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_cb556_00000 | RUNNING  | 172.17.0.4:76483 |     22 |          560.203 | 3559424 |  246.628 |              297.687 |               137.99 |            824.351 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_cb556_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3422.125568698817
    time_step_min: 3110
  date: 2020-10-11_22-36-18
  done: false
  episode_len_mean: 823.993444846293
  episode_reward_max: 297.6868686868688
  episode_reward_mean: 247.1778681936909
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 158
  episodes_total: 4424
  experiment_id: 72e30bf5241d4a978bc93780059fd965
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7830241670211157
        entropy_coeff: 0.0001
        kl: 0.005572947518279155
        model: {}
        policy_loss: -0.008857697199952478
        total_loss: 9.253699541091919
        vf_explained_var: 0.9810841679573059
        vf_loss: 9.262078205744425
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.400000000000002
    gpu_util_percent0: 0.3929032258064516
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7806451612903222
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 76483
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14979027414671955
    mean_env_wait_ms: 1.18954268013283
    mean_inference_ms: 4.484746218345733
    mean_raw_obs_processing_ms: 0.3901101387895457
  time_since_restore: 585.5828950405121
  time_this_iter_s: 25.379483461380005
  time_total_s: 585.5828950405121
  timers:
    learn_throughput: 8730.928
    learn_time_ms: 18530.904
    sample_throughput: 24067.98
    sample_time_ms: 6722.293
    update_time_ms: 34.447
  timestamp: 1602455778
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: cb556_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_cb556_00000 | RUNNING  | 172.17.0.4:76483 |     23 |          585.583 | 3721216 |  247.178 |              297.687 |               137.99 |            823.993 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_cb556_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3418.8553266111353
    time_step_min: 3110
  date: 2020-10-11_22-36-43
  done: true
  episode_len_mean: 823.7326797385621
  episode_reward_max: 297.6868686868688
  episode_reward_mean: 247.70248233973717
  episode_reward_min: 137.98989898989845
  episodes_this_iter: 166
  episodes_total: 4590
  experiment_id: 72e30bf5241d4a978bc93780059fd965
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7631906171639761
        entropy_coeff: 0.0001
        kl: 0.005887019874838491
        model: {}
        policy_loss: -0.01170718360420627
        total_loss: 8.404380480448404
        vf_explained_var: 0.9844815135002136
        vf_loss: 8.415575504302979
    num_steps_sampled: 3883008
    num_steps_trained: 3883008
  iterations_since_restore: 24
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.763333333333332
    gpu_util_percent0: 0.34833333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7766666666666664
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 76483
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14968242820676206
    mean_env_wait_ms: 1.1899685438299712
    mean_inference_ms: 4.4782505387612535
    mean_raw_obs_processing_ms: 0.38971632108265275
  time_since_restore: 610.6845602989197
  time_this_iter_s: 25.101665258407593
  time_total_s: 610.6845602989197
  timers:
    learn_throughput: 8741.984
    learn_time_ms: 18507.468
    sample_throughput: 24075.088
    sample_time_ms: 6720.308
    update_time_ms: 33.828
  timestamp: 1602455803
  timesteps_since_restore: 0
  timesteps_total: 3883008
  training_iteration: 24
  trial_id: cb556_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_cb556_00000 | TERMINATED |       |     24 |          610.685 | 3883008 |  247.702 |              297.687 |               137.99 |            823.733 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_cb556_00000 | TERMINATED |       |     24 |          610.685 | 3883008 |  247.702 |              297.687 |               137.99 |            823.733 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


