2020-10-08 19:16:53,846	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8270[39m[22m
== Status ==
Memory usage on this node: 57.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_d41db_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=9918)[0m 2020-10-08 19:16:56,947	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=9909)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9909)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9882)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9882)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9887)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9887)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9852)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9852)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9925)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9925)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9881)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9881)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9880)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9880)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9911)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9911)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9940)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9940)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9800)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9800)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9900)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9900)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9877)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9877)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9907)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9907)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9874)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9874)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9878)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9878)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9794)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9794)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9824)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9824)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9799)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9799)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9813)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9813)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9915)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9915)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9946)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9946)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9892)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9892)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9797)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9797)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9933)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9933)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9913)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9913)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9815)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9815)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9899)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9899)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9902)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9902)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9936)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9936)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9895)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9895)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9927)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9927)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9886)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9886)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9894)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9894)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9930)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9930)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9922)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9922)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9802)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9802)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9796)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9796)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9806)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9806)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9789)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9789)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9790)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9790)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9826)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9826)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9804)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9804)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9809)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9809)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9856)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9856)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9812)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9812)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9801)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9801)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9798)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9798)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9803)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9803)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9876)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9876)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9821)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9821)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9795)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9795)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9906)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9906)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9863)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9863)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9871)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9871)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9864)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9864)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9791)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9791)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9816)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9816)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9793)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9793)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9898)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9898)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9890)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9890)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9883)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9883)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9858)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9858)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9888)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9888)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9805)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9805)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9788)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9788)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9872)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9872)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9850)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9850)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9810)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9810)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9792)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9792)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9875)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9875)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9814)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9814)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9866)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9866)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9865)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9865)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9818)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9818)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9855)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9855)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9854)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9854)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9873)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9873)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9889)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9889)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9848)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9848)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_d41db_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3279.0
  date: 2020-10-08_19-17-38
  done: false
  episode_len_mean: 877.1708860759494
  episode_reward_max: 273.13131313131294
  episode_reward_mean: 224.28870988364636
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: d5215944c49d43f6ad906cada031c0f8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1623869061470031
        entropy_coeff: 0.0
        kl: 0.0047691816231235865
        model: {}
        policy_loss: -0.010880604933481664
        total_loss: 7.694286465644836
        vf_explained_var: 0.7767370939254761
        vf_loss: 7.704213285446167
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.141463414634146
    gpu_util_percent0: 0.4317073170731707
    gpu_util_percent1: 0.00024390243902439024
    gpu_util_percent2: 0.0
    ram_util_percent: 9.507317073170734
    vram_util_percent0: 0.25971130078634336
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9918
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1795138794538893
    mean_env_wait_ms: 1.6523227002672958
    mean_inference_ms: 5.863923296290955
    mean_raw_obs_processing_ms: 0.4810404917383385
  time_since_restore: 34.953869104385376
  time_this_iter_s: 34.953869104385376
  time_total_s: 34.953869104385376
  timers:
    learn_throughput: 6439.143
    learn_time_ms: 25126.326
    sample_throughput: 16582.066
    sample_time_ms: 9757.047
    update_time_ms: 26.087
  timestamp: 1602184658
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: d41db_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 72.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d41db_00000 | RUNNING  | 172.17.0.4:9918 |      1 |          34.9539 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d41db_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3238.0
  date: 2020-10-08_19-18-11
  done: false
  episode_len_mean: 872.2658227848101
  episode_reward_max: 274.272727272727
  episode_reward_mean: 226.31444188722645
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: d5215944c49d43f6ad906cada031c0f8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1339414536952972
        entropy_coeff: 0.0
        kl: 0.007432148605585098
        model: {}
        policy_loss: -0.01348833420779556
        total_loss: 6.213881874084473
        vf_explained_var: 0.9093573689460754
        vf_loss: 6.226627016067505
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.571794871794875
    gpu_util_percent0: 0.4328205128205128
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.756410256410257
    vram_util_percent0: 0.26820268940636255
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9918
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17449796908861598
    mean_env_wait_ms: 1.6497659328310745
    mean_inference_ms: 5.56081637743869
    mean_raw_obs_processing_ms: 0.46717183390061273
  time_since_restore: 68.24755096435547
  time_this_iter_s: 33.29368185997009
  time_total_s: 68.24755096435547
  timers:
    learn_throughput: 6464.37
    learn_time_ms: 25028.27
    sample_throughput: 17942.946
    sample_time_ms: 9017.026
    update_time_ms: 31.343
  timestamp: 1602184691
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: d41db_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d41db_00000 | RUNNING  | 172.17.0.4:9918 |      2 |          68.2476 | 323584 |  226.314 |              274.273 |              115.788 |            872.266 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d41db_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3220.0
  date: 2020-10-08_19-18-44
  done: false
  episode_len_mean: 866.3649789029536
  episode_reward_max: 276.0101010101009
  episode_reward_mean: 226.898734177215
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: d5215944c49d43f6ad906cada031c0f8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1215266346931458
        entropy_coeff: 0.0
        kl: 0.008378646057099103
        model: {}
        policy_loss: -0.015776434121653436
        total_loss: 6.404408288002014
        vf_explained_var: 0.9473223686218262
        vf_loss: 6.419346737861633
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.764102564102558
    gpu_util_percent0: 0.4384615384615385
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.771794871794874
    vram_util_percent0: 0.26820268940636255
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9918
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17113867994923412
    mean_env_wait_ms: 1.6487117295550668
    mean_inference_ms: 5.391266290711525
    mean_raw_obs_processing_ms: 0.4567211413197218
  time_since_restore: 101.77758860588074
  time_this_iter_s: 33.53003764152527
  time_total_s: 101.77758860588074
  timers:
    learn_throughput: 6455.627
    learn_time_ms: 25062.167
    sample_throughput: 18417.655
    sample_time_ms: 8784.615
    update_time_ms: 30.401
  timestamp: 1602184724
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: d41db_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d41db_00000 | RUNNING  | 172.17.0.4:9918 |      3 |          101.778 | 485376 |  226.899 |               276.01 |              115.788 |            866.365 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d41db_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3220.0
  date: 2020-10-08_19-19-18
  done: false
  episode_len_mean: 860.5664556962025
  episode_reward_max: 276.0101010101009
  episode_reward_mean: 227.5887354558239
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: d5215944c49d43f6ad906cada031c0f8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.085555326938629
        entropy_coeff: 0.0
        kl: 0.00998464492149651
        model: {}
        policy_loss: -0.016159064939711244
        total_loss: 6.339247846603394
        vf_explained_var: 0.964798629283905
        vf_loss: 6.354408478736877
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.964102564102568
    gpu_util_percent0: 0.33512820512820507
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.76923076923077
    vram_util_percent0: 0.26820268940636255
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9918
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16868462437635454
    mean_env_wait_ms: 1.6505454290884964
    mean_inference_ms: 5.269089803076265
    mean_raw_obs_processing_ms: 0.4492892096968614
  time_since_restore: 134.78453016281128
  time_this_iter_s: 33.00694155693054
  time_total_s: 134.78453016281128
  timers:
    learn_throughput: 6463.309
    learn_time_ms: 25032.38
    sample_throughput: 18876.788
    sample_time_ms: 8570.949
    update_time_ms: 42.45
  timestamp: 1602184758
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: d41db_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d41db_00000 | RUNNING  | 172.17.0.4:9918 |      4 |          134.785 | 647168 |  227.589 |               276.01 |              115.788 |            860.566 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d41db_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3167.0
  date: 2020-10-08_19-19-50
  done: false
  episode_len_mean: 849.7789815817985
  episode_reward_max: 284.08080808080786
  episode_reward_mean: 227.68372785274178
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 291
  episodes_total: 923
  experiment_id: d5215944c49d43f6ad906cada031c0f8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0468401253223418
        entropy_coeff: 0.0
        kl: 0.008189769648015498
        model: {}
        policy_loss: -0.015242714760825038
        total_loss: 9.053186893463135
        vf_explained_var: 0.9780328869819641
        vf_loss: 9.06761064529419
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.236842105263158
    gpu_util_percent0: 0.3702631578947369
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.763157894736844
    vram_util_percent0: 0.26820268940636255
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9918
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.165820550969195
    mean_env_wait_ms: 1.6566314162872784
    mean_inference_ms: 5.125318609374687
    mean_raw_obs_processing_ms: 0.44077076958548295
  time_since_restore: 167.63154411315918
  time_this_iter_s: 32.8470139503479
  time_total_s: 167.63154411315918
  timers:
    learn_throughput: 6480.451
    learn_time_ms: 24966.163
    sample_throughput: 19103.478
    sample_time_ms: 8469.243
    update_time_ms: 40.557
  timestamp: 1602184790
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: d41db_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d41db_00000 | RUNNING  | 172.17.0.4:9918 |      5 |          167.632 | 808960 |  227.684 |              284.081 |              115.788 |            849.779 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d41db_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3167.0
  date: 2020-10-08_19-20-23
  done: false
  episode_len_mean: 843.5967450271248
  episode_reward_max: 284.08080808080786
  episode_reward_mean: 227.66842932032793
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 183
  episodes_total: 1106
  experiment_id: d5215944c49d43f6ad906cada031c0f8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0427606344223022
        entropy_coeff: 0.0
        kl: 0.00771990823559463
        model: {}
        policy_loss: -0.016434159281197937
        total_loss: 4.810517954826355
        vf_explained_var: 0.9849395751953125
        vf_loss: 4.826180076599121
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.30526315789474
    gpu_util_percent0: 0.3718421052631578
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.771052631578948
    vram_util_percent0: 0.26820268940636255
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9918
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16469036246244484
    mean_env_wait_ms: 1.6606700498861766
    mean_inference_ms: 5.063284404724712
    mean_raw_obs_processing_ms: 0.4373290218410883
  time_since_restore: 200.37469720840454
  time_this_iter_s: 32.74315309524536
  time_total_s: 200.37469720840454
  timers:
    learn_throughput: 6490.315
    learn_time_ms: 24928.218
    sample_throughput: 19313.531
    sample_time_ms: 8377.132
    update_time_ms: 39.977
  timestamp: 1602184823
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: d41db_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d41db_00000 | RUNNING  | 172.17.0.4:9918 |      6 |          200.375 | 970752 |  227.668 |              284.081 |              115.788 |            843.597 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d41db_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3167.0
  date: 2020-10-08_19-20-56
  done: false
  episode_len_mean: 838.5680379746835
  episode_reward_max: 284.08080808080786
  episode_reward_mean: 227.5415068405573
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: d5215944c49d43f6ad906cada031c0f8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0236716270446777
        entropy_coeff: 0.0
        kl: 0.0069445088971406225
        model: {}
        policy_loss: -0.017079158697742968
        total_loss: 4.373168301582337
        vf_explained_var: 0.9883626699447632
        vf_loss: 4.389552903175354
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.110526315789468
    gpu_util_percent0: 0.3584210526315789
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.771052631578948
    vram_util_percent0: 0.26820268940636255
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9918
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16387479146290035
    mean_env_wait_ms: 1.6639109032372625
    mean_inference_ms: 5.01908195116113
    mean_raw_obs_processing_ms: 0.43482627863553186
  time_since_restore: 233.21181321144104
  time_this_iter_s: 32.8371160030365
  time_total_s: 233.21181321144104
  timers:
    learn_throughput: 6505.347
    learn_time_ms: 24870.619
    sample_throughput: 19359.847
    sample_time_ms: 8357.091
    update_time_ms: 37.23
  timestamp: 1602184856
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: d41db_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d41db_00000 | RUNNING  | 172.17.0.4:9918 |      7 |          233.212 | 1132544 |  227.542 |              284.081 |              115.788 |            838.568 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d41db_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3167.0
  date: 2020-10-08_19-21-29
  done: false
  episode_len_mean: 834.457805907173
  episode_reward_max: 284.08080808080786
  episode_reward_mean: 227.74425691514284
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: d5215944c49d43f6ad906cada031c0f8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9871220707893371
        entropy_coeff: 0.0
        kl: 0.006086677452549339
        model: {}
        policy_loss: -0.016842020372860134
        total_loss: 4.770051717758179
        vf_explained_var: 0.9893091320991516
        vf_loss: 4.786285161972046
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.78461538461539
    gpu_util_percent0: 0.43461538461538457
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.76923076923077
    vram_util_percent0: 0.26820268940636255
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9918
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16316914095644602
    mean_env_wait_ms: 1.6670633942521003
    mean_inference_ms: 4.981011273198731
    mean_raw_obs_processing_ms: 0.4326741682963854
  time_since_restore: 266.19651985168457
  time_this_iter_s: 32.98470664024353
  time_total_s: 266.19651985168457
  timers:
    learn_throughput: 6501.456
    learn_time_ms: 24885.504
    sample_throughput: 19487.855
    sample_time_ms: 8302.197
    update_time_ms: 34.888
  timestamp: 1602184889
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: d41db_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d41db_00000 | RUNNING  | 172.17.0.4:9918 |      8 |          266.197 | 1294336 |  227.744 |              284.081 |              115.788 |            834.458 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d41db_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3167.0
  date: 2020-10-08_19-22-02
  done: false
  episode_len_mean: 827.7927461139897
  episode_reward_max: 284.08080808080786
  episode_reward_mean: 228.60797962352356
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 315
  episodes_total: 1737
  experiment_id: d5215944c49d43f6ad906cada031c0f8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9603379964828491
        entropy_coeff: 0.0
        kl: 0.005697819241322577
        model: {}
        policy_loss: -0.015374647197313606
        total_loss: 5.835705876350403
        vf_explained_var: 0.9917343258857727
        vf_loss: 5.850510787963867
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.989473684210523
    gpu_util_percent0: 0.3928947368421053
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.763157894736844
    vram_util_percent0: 0.26820268940636255
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9918
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16205768258120481
    mean_env_wait_ms: 1.6727845916745814
    mean_inference_ms: 4.9205828855374785
    mean_raw_obs_processing_ms: 0.4294476109318349
  time_since_restore: 299.00560688972473
  time_this_iter_s: 32.80908703804016
  time_total_s: 299.00560688972473
  timers:
    learn_throughput: 6505.841
    learn_time_ms: 24868.728
    sample_throughput: 19568.811
    sample_time_ms: 8267.85
    update_time_ms: 33.88
  timestamp: 1602184922
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: d41db_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d41db_00000 | RUNNING  | 172.17.0.4:9918 |      9 |          299.006 | 1456128 |  228.608 |              284.081 |              115.788 |            827.793 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d41db_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3167.0
  date: 2020-10-08_19-22-35
  done: false
  episode_len_mean: 825.1888185654009
  episode_reward_max: 284.08080808080786
  episode_reward_mean: 229.01668584579963
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 159
  episodes_total: 1896
  experiment_id: d5215944c49d43f6ad906cada031c0f8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9395302057266235
        entropy_coeff: 0.0
        kl: 0.005725901760160923
        model: {}
        policy_loss: -0.015155132982181385
        total_loss: 3.7032951951026916
        vf_explained_var: 0.9923890233039856
        vf_loss: 3.717877686023712
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.978947368421046
    gpu_util_percent0: 0.2794736842105263
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.773684210526318
    vram_util_percent0: 0.26820268940636255
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9918
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16160499331665681
    mean_env_wait_ms: 1.675266558830174
    mean_inference_ms: 4.89589623540649
    mean_raw_obs_processing_ms: 0.42812972704111807
  time_since_restore: 331.86645340919495
  time_this_iter_s: 32.860846519470215
  time_total_s: 331.86645340919495
  timers:
    learn_throughput: 6513.263
    learn_time_ms: 24840.39
    sample_throughput: 19585.011
    sample_time_ms: 8261.012
    update_time_ms: 32.662
  timestamp: 1602184955
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: d41db_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d41db_00000 | RUNNING  | 172.17.0.4:9918 |     10 |          331.866 | 1617920 |  229.017 |              284.081 |              115.788 |            825.189 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d41db_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3167.0
  date: 2020-10-08_19-23-08
  done: false
  episode_len_mean: 823.0243427458618
  episode_reward_max: 284.08080808080786
  episode_reward_mean: 229.54907399211186
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: d5215944c49d43f6ad906cada031c0f8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9247192710638046
        entropy_coeff: 0.0
        kl: 0.005742019205354154
        model: {}
        policy_loss: -0.01602785640861839
        total_loss: 3.3244777798652647
        vf_explained_var: 0.993094265460968
        vf_loss: 3.3399314165115355
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.52307692307692
    gpu_util_percent0: 0.48051282051282046
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.76923076923077
    vram_util_percent0: 0.26820268940636255
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9918
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16120713203532253
    mean_env_wait_ms: 1.6776009326820938
    mean_inference_ms: 4.873914714346929
    mean_raw_obs_processing_ms: 0.4269352308713072
  time_since_restore: 364.97143840789795
  time_this_iter_s: 33.104984998703
  time_total_s: 364.97143840789795
  timers:
    learn_throughput: 6521.8
    learn_time_ms: 24807.875
    sample_throughput: 19956.555
    sample_time_ms: 8107.211
    update_time_ms: 32.34
  timestamp: 1602184988
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: d41db_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d41db_00000 | RUNNING  | 172.17.0.4:9918 |     11 |          364.971 | 1779712 |  229.549 |              284.081 |              115.788 |            823.024 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d41db_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3167.0
  date: 2020-10-08_19-23-41
  done: false
  episode_len_mean: 820.8899163364157
  episode_reward_max: 284.08080808080786
  episode_reward_mean: 230.23466278816338
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 217
  episodes_total: 2271
  experiment_id: d5215944c49d43f6ad906cada031c0f8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8901327341794968
        entropy_coeff: 0.0
        kl: 0.005733145796693861
        model: {}
        policy_loss: -0.015184902143664658
        total_loss: 3.778871715068817
        vf_explained_var: 0.9947299957275391
        vf_loss: 3.7934833645820616
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.976315789473688
    gpu_util_percent0: 0.0318421052631579
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.760526315789477
    vram_util_percent0: 0.26820268940636255
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9918
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16071583659501443
    mean_env_wait_ms: 1.6805241995995566
    mean_inference_ms: 4.846949279310241
    mean_raw_obs_processing_ms: 0.42538318747774745
  time_since_restore: 397.9372503757477
  time_this_iter_s: 32.96581196784973
  time_total_s: 397.9372503757477
  timers:
    learn_throughput: 6527.065
    learn_time_ms: 24787.862
    sample_throughput: 19989.049
    sample_time_ms: 8094.032
    update_time_ms: 31.953
  timestamp: 1602185021
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: d41db_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d41db_00000 | RUNNING  | 172.17.0.4:9918 |     12 |          397.937 | 1941504 |  230.235 |              284.081 |              115.788 |             820.89 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d41db_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3167.0
  date: 2020-10-08_19-24-14
  done: false
  episode_len_mean: 818.993670886076
  episode_reward_max: 284.08080808080786
  episode_reward_mean: 231.10896944124784
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 257
  episodes_total: 2528
  experiment_id: d5215944c49d43f6ad906cada031c0f8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8700982570648194
        entropy_coeff: 0.0
        kl: 0.005516815418377519
        model: {}
        policy_loss: -0.014399837283417583
        total_loss: 3.4849750280380247
        vf_explained_var: 0.9939899444580078
        vf_loss: 3.498823142051697
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.871794871794872
    gpu_util_percent0: 0.4574358974358974
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.761538461538464
    vram_util_percent0: 0.26820268940636255
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9918
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1602360842343802
    mean_env_wait_ms: 1.6834862730158446
    mean_inference_ms: 4.820296172810918
    mean_raw_obs_processing_ms: 0.4239446718188371
  time_since_restore: 430.787202835083
  time_this_iter_s: 32.84995245933533
  time_total_s: 430.787202835083
  timers:
    learn_throughput: 6533.468
    learn_time_ms: 24763.572
    sample_throughput: 20098.431
    sample_time_ms: 8049.982
    update_time_ms: 31.013
  timestamp: 1602185054
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: d41db_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d41db_00000 | RUNNING  | 172.17.0.4:9918 |     13 |          430.787 | 2103296 |  231.109 |              284.081 |              115.788 |            818.994 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d41db_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3167.0
  date: 2020-10-08_19-24-47
  done: false
  episode_len_mean: 817.9475055845123
  episode_reward_max: 284.08080808080786
  episode_reward_mean: 231.65144746045704
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 2686
  experiment_id: d5215944c49d43f6ad906cada031c0f8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8588024288415909
        entropy_coeff: 0.0
        kl: 0.005537407263182104
        model: {}
        policy_loss: -0.016135693783871828
        total_loss: 2.58554984331131
        vf_explained_var: 0.9949114918708801
        vf_loss: 2.601131784915924
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.24210526315789
    gpu_util_percent0: 0.022894736842105263
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.776315789473687
    vram_util_percent0: 0.26820268940636255
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9918
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1599715409092958
    mean_env_wait_ms: 1.6851168086215345
    mean_inference_ms: 4.805590847369248
    mean_raw_obs_processing_ms: 0.4231251053978283
  time_since_restore: 463.5489675998688
  time_this_iter_s: 32.76176476478577
  time_total_s: 463.5489675998688
  timers:
    learn_throughput: 6538.217
    learn_time_ms: 24745.585
    sample_throughput: 20101.802
    sample_time_ms: 8048.631
    update_time_ms: 25.076
  timestamp: 1602185087
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: d41db_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d41db_00000 | RUNNING  | 172.17.0.4:9918 |     14 |          463.549 | 2265088 |  231.651 |              284.081 |              115.788 |            817.948 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d41db_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3167.0
  date: 2020-10-08_19-25-20
  done: false
  episode_len_mean: 816.9722222222222
  episode_reward_max: 284.08080808080786
  episode_reward_mean: 232.11303612780398
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: d5215944c49d43f6ad906cada031c0f8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8475103586912155
        entropy_coeff: 0.0
        kl: 0.0052801115904003385
        model: {}
        policy_loss: -0.015429721167311072
        total_loss: 2.7394189834594727
        vf_explained_var: 0.9946831464767456
        vf_loss: 2.754320740699768
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.52307692307692
    gpu_util_percent0: 0.4315384615384615
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.764102564102565
    vram_util_percent0: 0.26820268940636255
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9918
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1597287557974805
    mean_env_wait_ms: 1.6866374183544806
    mean_inference_ms: 4.791978166083945
    mean_raw_obs_processing_ms: 0.42234886752495315
  time_since_restore: 496.2555708885193
  time_this_iter_s: 32.70660328865051
  time_total_s: 496.2555708885193
  timers:
    learn_throughput: 6541.487
    learn_time_ms: 24733.212
    sample_throughput: 20106.768
    sample_time_ms: 8046.644
    update_time_ms: 23.751
  timestamp: 1602185120
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: d41db_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d41db_00000 | RUNNING  | 172.17.0.4:9918 |     15 |          496.256 | 2426880 |  232.113 |              284.081 |              115.788 |            816.972 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d41db_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3167.0
  date: 2020-10-08_19-25-53
  done: false
  episode_len_mean: 815.360291785601
  episode_reward_max: 284.08080808080786
  episode_reward_mean: 232.9663331699487
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 309
  episodes_total: 3153
  experiment_id: d5215944c49d43f6ad906cada031c0f8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8052306085824966
        entropy_coeff: 0.0
        kl: 0.005000332067720592
        model: {}
        policy_loss: -0.012981131742708384
        total_loss: 3.8279479146003723
        vf_explained_var: 0.9948102831840515
        vf_loss: 3.8404290080070496
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.39736842105263
    gpu_util_percent0: 0.0868421052631579
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.773684210526314
    vram_util_percent0: 0.26820268940636255
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9918
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15930453305837258
    mean_env_wait_ms: 1.6893966887689944
    mean_inference_ms: 4.768420168857852
    mean_raw_obs_processing_ms: 0.4210177698005263
  time_since_restore: 529.1011326313019
  time_this_iter_s: 32.84556174278259
  time_total_s: 529.1011326313019
  timers:
    learn_throughput: 6544.535
    learn_time_ms: 24721.697
    sample_throughput: 20051.643
    sample_time_ms: 8068.765
    update_time_ms: 21.861
  timestamp: 1602185153
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: d41db_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d41db_00000 | RUNNING  | 172.17.0.4:9918 |     16 |          529.101 | 2588672 |  232.966 |              284.081 |              115.788 |             815.36 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d41db_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3164.0
  date: 2020-10-08_19-26-26
  done: false
  episode_len_mean: 814.5033152501506
  episode_reward_max: 285.3333333333336
  episode_reward_mean: 233.5270243118344
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 165
  episodes_total: 3318
  experiment_id: d5215944c49d43f6ad906cada031c0f8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7854989558458328
        entropy_coeff: 0.0
        kl: 0.005395125481300056
        model: {}
        policy_loss: -0.015607044706121087
        total_loss: 2.2944273829460142
        vf_explained_var: 0.9953802824020386
        vf_loss: 2.309494876861572
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.274358974358975
    gpu_util_percent0: 0.34871794871794864
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.771794871794874
    vram_util_percent0: 0.26820268940636255
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9918
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15910994373579562
    mean_env_wait_ms: 1.6907817509542857
    mean_inference_ms: 4.757343252770776
    mean_raw_obs_processing_ms: 0.42041740986903064
  time_since_restore: 561.9229936599731
  time_this_iter_s: 32.821861028671265
  time_total_s: 561.9229936599731
  timers:
    learn_throughput: 6542.115
    learn_time_ms: 24730.841
    sample_throughput: 20101.438
    sample_time_ms: 8048.777
    update_time_ms: 23.219
  timestamp: 1602185186
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: d41db_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d41db_00000 | RUNNING  | 172.17.0.4:9918 |     17 |          561.923 | 2750464 |  233.527 |              285.333 |              115.788 |            814.503 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d41db_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3164.0
  date: 2020-10-08_19-27-00
  done: false
  episode_len_mean: 813.8124280782508
  episode_reward_max: 285.3333333333336
  episode_reward_mean: 233.94599039880967
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 3476
  experiment_id: d5215944c49d43f6ad906cada031c0f8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7977687448263169
        entropy_coeff: 0.0
        kl: 0.005210272828117013
        model: {}
        policy_loss: -0.015333612775430083
        total_loss: 2.292774522304535
        vf_explained_var: 0.9950755834579468
        vf_loss: 2.3075870633125306
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.269230769230763
    gpu_util_percent0: 0.35461538461538467
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.771794871794874
    vram_util_percent0: 0.26820268940636255
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9918
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15893254101004012
    mean_env_wait_ms: 1.692015669565979
    mean_inference_ms: 4.7473722515917425
    mean_raw_obs_processing_ms: 0.41986212805600437
  time_since_restore: 595.1026215553284
  time_this_iter_s: 33.179627895355225
  time_total_s: 595.1026215553284
  timers:
    learn_throughput: 6545.553
    learn_time_ms: 24717.849
    sample_throughput: 20025.809
    sample_time_ms: 8079.174
    update_time_ms: 24.677
  timestamp: 1602185220
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: d41db_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d41db_00000 | RUNNING  | 172.17.0.4:9918 |     18 |          595.103 | 2912256 |  233.946 |              285.333 |              115.788 |            813.812 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d41db_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3164.0
  date: 2020-10-08_19-27-33
  done: true
  episode_len_mean: 812.7965639487319
  episode_reward_max: 285.3333333333336
  episode_reward_mean: 234.63312701600125
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 191
  episodes_total: 3667
  experiment_id: d5215944c49d43f6ad906cada031c0f8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7714986503124237
        entropy_coeff: 0.0
        kl: 0.004941698256880045
        model: {}
        policy_loss: -0.014686040277592839
        total_loss: 2.5084762454032896
        vf_explained_var: 0.9957863092422485
        vf_loss: 2.52266811132431
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.386842105263153
    gpu_util_percent0: 0.28210526315789475
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.765789473684212
    vram_util_percent0: 0.26820268940636255
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9918
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15872718137000347
    mean_env_wait_ms: 1.6933976356663185
    mean_inference_ms: 4.735891405902993
    mean_raw_obs_processing_ms: 0.41920483104503703
  time_since_restore: 628.0439858436584
  time_this_iter_s: 32.94136428833008
  time_total_s: 628.0439858436584
  timers:
    learn_throughput: 6540.683
    learn_time_ms: 24736.254
    sample_throughput: 20041.039
    sample_time_ms: 8073.035
    update_time_ms: 24.487
  timestamp: 1602185253
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: d41db_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d41db_00000 | TERMINATED |       |     19 |          628.044 | 3074048 |  234.633 |              285.333 |              115.788 |            812.797 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d41db_00000 | TERMINATED |       |     19 |          628.044 | 3074048 |  234.633 |              285.333 |              115.788 |            812.797 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


