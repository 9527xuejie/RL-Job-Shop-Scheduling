2020-10-10 22:58:40,177	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8266[39m[22m
== Status ==
Memory usage on this node: 32.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_2414c_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=3784)[0m 2020-10-10 22:58:43,111	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=3733)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3733)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3718)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3718)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3793)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3793)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3777)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3777)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3740)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3740)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3775)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3775)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3673)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3673)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3716)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3716)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3652)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3652)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3757)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3757)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3660)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3660)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3661)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3661)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3654)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3654)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3767)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3767)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3731)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3731)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3787)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3787)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3755)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3755)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3772)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3772)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3712)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3712)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3670)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3670)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3684)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3684)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3724)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3724)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3723)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3723)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3655)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3655)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3679)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3679)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3678)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3678)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3667)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3667)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3714)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3714)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3649)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3649)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3658)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3658)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3663)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3663)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3722)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3722)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3648)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3648)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3681)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3681)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3730)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3730)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3662)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3662)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3665)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3665)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3721)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3721)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3729)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3729)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3672)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3672)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3734)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3734)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3752)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3752)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3742)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3742)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3669)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3669)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3770)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3770)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3664)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3664)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3683)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3683)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3754)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3754)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3732)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3732)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3779)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3779)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3764)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3764)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3651)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3651)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3761)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3761)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3768)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3768)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3788)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3788)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3717)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3717)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3774)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3774)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3749)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3749)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3743)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3743)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3656)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3656)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3727)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3727)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3760)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3760)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3713)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3713)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3715)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3715)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3689)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3689)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3686)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3686)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3720)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3720)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3719)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3719)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3741)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3741)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3726)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3726)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3657)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3657)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3687)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3687)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3747)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3747)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3676)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3676)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3736)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3736)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3650)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3650)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3728)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3728)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3725)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3725)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3739)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3739)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_2414c_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-10_22-59-25
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 729a2d32d1aa43ceae8b933135524a1b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.185313642024994
        entropy_coeff: 0.0
        kl: 0.003611819851877434
        model: {}
        policy_loss: -0.0033204275449471815
        total_loss: 660.8494480678013
        vf_explained_var: 0.0902143344283104
        vf_loss: 660.8520377022879
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.188636363636363
    gpu_util_percent0: 0.33113636363636356
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.00022727272727272727
    ram_util_percent: 6.290909090909088
    vram_util_percent0: 0.19252959241480064
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 3784
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.172679034895866
    mean_env_wait_ms: 1.1958571737583275
    mean_inference_ms: 5.752630263208127
    mean_raw_obs_processing_ms: 0.45830834386671865
  time_since_restore: 36.38242816925049
  time_this_iter_s: 36.38242816925049
  time_total_s: 36.38242816925049
  timers:
    learn_throughput: 5975.838
    learn_time_ms: 27074.36
    sample_throughput: 17511.597
    sample_time_ms: 9239.135
    update_time_ms: 23.927
  timestamp: 1602370765
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 2414c_00000
  
== Status ==
Memory usage on this node: 48.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2414c_00000 | RUNNING  | 172.17.0.4:3784 |      1 |          36.3824 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2414c_00000:
  custom_metrics:
    time_step_max: 4134
    time_step_mean: 3615.996527777778
    time_step_min: 3379
  date: 2020-10-10_23-00-00
  done: false
  episode_len_mean: 889.3101265822785
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 218.11072752844885
  episode_reward_min: 139.6565656565651
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 729a2d32d1aa43ceae8b933135524a1b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.1567445141928536
        entropy_coeff: 0.0
        kl: 0.005561558263642448
        model: {}
        policy_loss: -0.005204253913169461
        total_loss: 308.84869166782926
        vf_explained_var: 0.511374294757843
        vf_loss: 308.8533390590123
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.799999999999997
    gpu_util_percent0: 0.3690697674418605
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.467441860465115
    vram_util_percent0: 0.2046572646769432
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 3784
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16796869689856173
    mean_env_wait_ms: 1.1910386283101295
    mean_inference_ms: 5.546991578048319
    mean_raw_obs_processing_ms: 0.44803349412626403
  time_since_restore: 71.53722214698792
  time_this_iter_s: 35.15479397773743
  time_total_s: 71.53722214698792
  timers:
    learn_throughput: 5994.877
    learn_time_ms: 26988.377
    sample_throughput: 18663.739
    sample_time_ms: 8668.788
    update_time_ms: 31.743
  timestamp: 1602370800
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 2414c_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2414c_00000 | RUNNING  | 172.17.0.4:3784 |      2 |          71.5372 | 323584 |  218.111 |              258.596 |              139.657 |             889.31 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2414c_00000:
  custom_metrics:
    time_step_max: 4148
    time_step_mean: 3604.9237668161436
    time_step_min: 3286
  date: 2020-10-10_23-00-34
  done: false
  episode_len_mean: 883.8565400843881
  episode_reward_max: 268.14141414141415
  episode_reward_mean: 219.9842091804115
  episode_reward_min: 137.53535353535372
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 729a2d32d1aa43ceae8b933135524a1b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.1556446211678642
        entropy_coeff: 0.0
        kl: 0.005806051760113665
        model: {}
        policy_loss: -0.005337582805493314
        total_loss: 131.89488547188895
        vf_explained_var: 0.758877694606781
        vf_loss: 131.89964403424943
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.953658536585365
    gpu_util_percent0: 0.38365853658536586
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.49268292682927
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 3784
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1649780829627152
    mean_env_wait_ms: 1.1901939486029072
    mean_inference_ms: 5.380074064659597
    mean_raw_obs_processing_ms: 0.4403248282468679
  time_since_restore: 105.93688201904297
  time_this_iter_s: 34.399659872055054
  time_total_s: 105.93688201904297
  timers:
    learn_throughput: 6005.116
    learn_time_ms: 26942.361
    sample_throughput: 19560.725
    sample_time_ms: 8271.268
    update_time_ms: 28.574
  timestamp: 1602370834
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 2414c_00000
  
== Status ==
Memory usage on this node: 48.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2414c_00000 | RUNNING  | 172.17.0.4:3784 |      3 |          105.937 | 485376 |  219.984 |              268.141 |              137.535 |            883.857 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2414c_00000:
  custom_metrics:
    time_step_max: 4148
    time_step_mean: 3600.1639072847684
    time_step_min: 3286
  date: 2020-10-10_23-01-09
  done: false
  episode_len_mean: 880.2594936708861
  episode_reward_max: 268.14141414141415
  episode_reward_mean: 220.85334356220415
  episode_reward_min: 137.53535353535372
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 729a2d32d1aa43ceae8b933135524a1b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.1445089748927526
        entropy_coeff: 0.0
        kl: 0.006365465366148523
        model: {}
        policy_loss: -0.004952114948537201
        total_loss: 85.22358104160854
        vf_explained_var: 0.84419184923172
        vf_loss: 85.22789764404297
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.307142857142857
    gpu_util_percent0: 0.3538095238095238
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.485714285714285
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 3784
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1629083502326775
    mean_env_wait_ms: 1.1899421347213062
    mean_inference_ms: 5.254678075020549
    mean_raw_obs_processing_ms: 0.4340650984999196
  time_since_restore: 140.48762559890747
  time_this_iter_s: 34.5507435798645
  time_total_s: 140.48762559890747
  timers:
    learn_throughput: 5993.193
    learn_time_ms: 26995.962
    sample_throughput: 20144.906
    sample_time_ms: 8031.41
    update_time_ms: 30.364
  timestamp: 1602370869
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 2414c_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2414c_00000 | RUNNING  | 172.17.0.4:3784 |      4 |          140.488 | 647168 |  220.853 |              268.141 |              137.535 |            880.259 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2414c_00000:
  custom_metrics:
    time_step_max: 4148
    time_step_mean: 3588.3490813648295
    time_step_min: 3165
  date: 2020-10-10_23-01-43
  done: false
  episode_len_mean: 876.6936708860759
  episode_reward_max: 286.4747474747474
  episode_reward_mean: 222.30654647743236
  episode_reward_min: 132.38383838383783
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 729a2d32d1aa43ceae8b933135524a1b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.1123680216925484
        entropy_coeff: 0.0
        kl: 0.00653064061355378
        model: {}
        policy_loss: -0.0034417585578531934
        total_loss: 69.91056878226144
        vf_explained_var: 0.8704271912574768
        vf_loss: 69.91335787091937
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.185365853658535
    gpu_util_percent0: 0.4163414634146341
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.492682926829268
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 3784
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.161346120524221
    mean_env_wait_ms: 1.1908122896425326
    mean_inference_ms: 5.157637478812167
    mean_raw_obs_processing_ms: 0.4291060811114693
  time_since_restore: 174.80012774467468
  time_this_iter_s: 34.31250214576721
  time_total_s: 174.80012774467468
  timers:
    learn_throughput: 6001.02
    learn_time_ms: 26960.75
    sample_throughput: 20461.025
    sample_time_ms: 7907.326
    update_time_ms: 30.542
  timestamp: 1602370903
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 2414c_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2414c_00000 | RUNNING  | 172.17.0.4:3784 |      5 |            174.8 | 808960 |  222.307 |              286.475 |              132.384 |            876.694 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2414c_00000:
  custom_metrics:
    time_step_max: 4217
    time_step_mean: 3575.5148975791435
    time_step_min: 3165
  date: 2020-10-10_23-02-18
  done: false
  episode_len_mean: 868.7205081669691
  episode_reward_max: 286.4747474747474
  episode_reward_mean: 224.24299253881813
  episode_reward_min: 127.08080808080815
  episodes_this_iter: 312
  episodes_total: 1102
  experiment_id: 729a2d32d1aa43ceae8b933135524a1b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.1038210902895247
        entropy_coeff: 0.0
        kl: 0.006877317425927946
        model: {}
        policy_loss: -0.004983438669504332
        total_loss: 81.63377870832171
        vf_explained_var: 0.9036083221435547
        vf_loss: 81.6380729675293
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.37317073170732
    gpu_util_percent0: 0.38951219512195123
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.485365853658536
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 3784
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15923884310893444
    mean_env_wait_ms: 1.1942152972152487
    mean_inference_ms: 5.026574876440941
    mean_raw_obs_processing_ms: 0.422630000648429
  time_since_restore: 208.93123650550842
  time_this_iter_s: 34.13110876083374
  time_total_s: 208.93123650550842
  timers:
    learn_throughput: 6004.298
    learn_time_ms: 26946.033
    sample_throughput: 20780.357
    sample_time_ms: 7785.814
    update_time_ms: 29.823
  timestamp: 1602370938
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 2414c_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2414c_00000 | RUNNING  | 172.17.0.4:3784 |      6 |          208.931 | 970752 |  224.243 |              286.475 |              127.081 |            868.721 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2414c_00000:
  custom_metrics:
    time_step_max: 4217
    time_step_mean: 3572.460355987055
    time_step_min: 3165
  date: 2020-10-10_23-02-52
  done: false
  episode_len_mean: 863.9098101265823
  episode_reward_max: 286.4747474747474
  episode_reward_mean: 224.55851233857544
  episode_reward_min: 127.08080808080815
  episodes_this_iter: 162
  episodes_total: 1264
  experiment_id: 729a2d32d1aa43ceae8b933135524a1b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.105991610458919
        entropy_coeff: 0.0
        kl: 0.007301111772124257
        model: {}
        policy_loss: -0.004700696503277868
        total_loss: 57.614264079502654
        vf_explained_var: 0.9060148000717163
        vf_loss: 57.61823545183454
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.536585365853657
    gpu_util_percent0: 0.34975609756097564
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497560975609756
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 3784
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1584574278294927
    mean_env_wait_ms: 1.1957414228644097
    mean_inference_ms: 4.977885959161953
    mean_raw_obs_processing_ms: 0.4202557114966035
  time_since_restore: 243.42815470695496
  time_this_iter_s: 34.49691820144653
  time_total_s: 243.42815470695496
  timers:
    learn_throughput: 5998.016
    learn_time_ms: 26974.254
    sample_throughput: 20981.388
    sample_time_ms: 7711.215
    update_time_ms: 31.159
  timestamp: 1602370972
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 2414c_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2414c_00000 | RUNNING  | 172.17.0.4:3784 |      7 |          243.428 | 1132544 |  224.559 |              286.475 |              127.081 |             863.91 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2414c_00000:
  custom_metrics:
    time_step_max: 4217
    time_step_mean: 3566.393830703013
    time_step_min: 3165
  date: 2020-10-10_23-03-27
  done: false
  episode_len_mean: 859.2194092827004
  episode_reward_max: 286.4747474747474
  episode_reward_mean: 225.84940118484408
  episode_reward_min: 127.08080808080815
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 729a2d32d1aa43ceae8b933135524a1b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.09130425964083
        entropy_coeff: 0.0
        kl: 0.005992845299520663
        model: {}
        policy_loss: -0.004608599352650344
        total_loss: 43.89360318865095
        vf_explained_var: 0.9200215935707092
        vf_loss: 43.89761216299875
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.109523809523807
    gpu_util_percent0: 0.38047619047619047
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.488095238095238
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 3784
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1577986968603761
    mean_env_wait_ms: 1.197170179067282
    mean_inference_ms: 4.936744177257634
    mean_raw_obs_processing_ms: 0.4182376448587426
  time_since_restore: 278.0255525112152
  time_this_iter_s: 34.597397804260254
  time_total_s: 278.0255525112152
  timers:
    learn_throughput: 5993.385
    learn_time_ms: 26995.094
    sample_throughput: 21112.659
    sample_time_ms: 7663.27
    update_time_ms: 29.829
  timestamp: 1602371007
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 2414c_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2414c_00000 | RUNNING  | 172.17.0.4:3784 |      8 |          278.026 | 1294336 |  225.849 |              286.475 |              127.081 |            859.219 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2414c_00000:
  custom_metrics:
    time_step_max: 4217
    time_step_mean: 3557.009020618557
    time_step_min: 3165
  date: 2020-10-10_23-04-01
  done: false
  episode_len_mean: 854.593670886076
  episode_reward_max: 286.4747474747474
  episode_reward_mean: 227.4031134126069
  episode_reward_min: 127.08080808080815
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 729a2d32d1aa43ceae8b933135524a1b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.0632348826953344
        entropy_coeff: 0.0
        kl: 0.005568870576098561
        model: {}
        policy_loss: -0.003896666474507323
        total_loss: 37.11343955993652
        vf_explained_var: 0.930292010307312
        vf_loss: 37.11677987234933
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.782926829268295
    gpu_util_percent0: 0.3931707317073171
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.49268292682927
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 3784
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15723322414682792
    mean_env_wait_ms: 1.1986082830889446
    mean_inference_ms: 4.900780285048632
    mean_raw_obs_processing_ms: 0.41639820340283806
  time_since_restore: 312.32934498786926
  time_this_iter_s: 34.30379247665405
  time_total_s: 312.32934498786926
  timers:
    learn_throughput: 5994.223
    learn_time_ms: 26991.319
    sample_throughput: 21234.164
    sample_time_ms: 7619.419
    update_time_ms: 28.832
  timestamp: 1602371041
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 2414c_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2414c_00000 | RUNNING  | 172.17.0.4:3784 |      9 |          312.329 | 1456128 |  227.403 |              286.475 |              127.081 |            854.594 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2414c_00000:
  custom_metrics:
    time_step_max: 4217
    time_step_mean: 3539.688269951794
    time_step_min: 3165
  date: 2020-10-10_23-04-36
  done: false
  episode_len_mean: 846.3250659630606
  episode_reward_max: 286.4747474747474
  episode_reward_mean: 229.84062258468575
  episode_reward_min: 127.08080808080815
  episodes_this_iter: 315
  episodes_total: 1895
  experiment_id: 729a2d32d1aa43ceae8b933135524a1b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.0416866881506783
        entropy_coeff: 0.0
        kl: 0.006614009051450661
        model: {}
        policy_loss: -0.004694884942312326
        total_loss: 42.8121155330113
        vf_explained_var: 0.9485732913017273
        vf_loss: 42.81615012032645
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.741463414634147
    gpu_util_percent0: 0.36024390243902443
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.480487804878049
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 3784
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15630992948797587
    mean_env_wait_ms: 1.2018068758174867
    mean_inference_ms: 4.842665147495369
    mean_raw_obs_processing_ms: 0.4135263129098206
  time_since_restore: 346.53855085372925
  time_this_iter_s: 34.209205865859985
  time_total_s: 346.53855085372925
  timers:
    learn_throughput: 5995.905
    learn_time_ms: 26983.748
    sample_throughput: 21346.301
    sample_time_ms: 7579.393
    update_time_ms: 27.919
  timestamp: 1602371076
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 2414c_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2414c_00000 | RUNNING  | 172.17.0.4:3784 |     10 |          346.539 | 1617920 |  229.841 |              286.475 |              127.081 |            846.325 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2414c_00000:
  custom_metrics:
    time_step_max: 4217
    time_step_mean: 3531.332181638697
    time_step_min: 3165
  date: 2020-10-10_23-05-10
  done: false
  episode_len_mean: 843.0306718597858
  episode_reward_max: 286.4747474747474
  episode_reward_mean: 231.07412489058044
  episode_reward_min: 127.08080808080815
  episodes_this_iter: 159
  episodes_total: 2054
  experiment_id: 729a2d32d1aa43ceae8b933135524a1b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.0282801474843706
        entropy_coeff: 0.0
        kl: 0.006507092754223517
        model: {}
        policy_loss: -0.006126677027038697
        total_loss: 25.279328891209193
        vf_explained_var: 0.9543164968490601
        vf_loss: 25.28480475289481
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.62682926829268
    gpu_util_percent0: 0.36390243902439023
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.490243902439025
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 3784
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15593424603051473
    mean_env_wait_ms: 1.2032069225342124
    mean_inference_ms: 4.818739581632676
    mean_raw_obs_processing_ms: 0.41231630126261365
  time_since_restore: 380.84437441825867
  time_this_iter_s: 34.30582356452942
  time_total_s: 380.84437441825867
  timers:
    learn_throughput: 5996.042
    learn_time_ms: 26983.134
    sample_throughput: 21951.123
    sample_time_ms: 7370.557
    update_time_ms: 28.95
  timestamp: 1602371110
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 2414c_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2414c_00000 | RUNNING  | 172.17.0.4:3784 |     11 |          380.844 | 1779712 |  231.074 |              286.475 |              127.081 |            843.031 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2414c_00000:
  custom_metrics:
    time_step_max: 4217
    time_step_mean: 3524.837912087912
    time_step_min: 3165
  date: 2020-10-10_23-05-44
  done: false
  episode_len_mean: 840.3304701627486
  episode_reward_max: 286.4747474747474
  episode_reward_mean: 232.1174539244158
  episode_reward_min: 127.08080808080815
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 729a2d32d1aa43ceae8b933135524a1b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.011575996875763
        entropy_coeff: 0.0
        kl: 0.005952906395707812
        model: {}
        policy_loss: -0.004471184193140029
        total_loss: 22.417439733232772
        vf_explained_var: 0.9571657776832581
        vf_loss: 22.42131519317627
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.154761904761905
    gpu_util_percent0: 0.38047619047619047
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.492857142857143
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 3784
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15560171794464914
    mean_env_wait_ms: 1.2044724117495869
    mean_inference_ms: 4.79729561173938
    mean_raw_obs_processing_ms: 0.4112121002030739
  time_since_restore: 415.29545044898987
  time_this_iter_s: 34.4510760307312
  time_total_s: 415.29545044898987
  timers:
    learn_throughput: 5992.277
    learn_time_ms: 27000.086
    sample_throughput: 22199.235
    sample_time_ms: 7288.179
    update_time_ms: 27.944
  timestamp: 1602371144
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 2414c_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2414c_00000 | RUNNING  | 172.17.0.4:3784 |     12 |          415.295 | 1941504 |  232.117 |              286.475 |              127.081 |             840.33 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2414c_00000:
  custom_metrics:
    time_step_max: 4217
    time_step_mean: 3517.620425531915
    time_step_min: 3165
  date: 2020-10-10_23-06-19
  done: false
  episode_len_mean: 837.9457527333894
  episode_reward_max: 286.4747474747474
  episode_reward_mean: 233.31389164988818
  episode_reward_min: 127.08080808080815
  episodes_this_iter: 166
  episodes_total: 2378
  experiment_id: 729a2d32d1aa43ceae8b933135524a1b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.9658734287534442
        entropy_coeff: 0.0
        kl: 0.006478673911520413
        model: {}
        policy_loss: -0.004363657956543777
        total_loss: 20.615535191127233
        vf_explained_var: 0.9669041633605957
        vf_loss: 20.619250978742325
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.597560975609756
    gpu_util_percent0: 0.38536585365853665
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.490243902439025
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 3784
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15528480644341372
    mean_env_wait_ms: 1.2057566299819258
    mean_inference_ms: 4.776818472985279
    mean_raw_obs_processing_ms: 0.4101437590372594
  time_since_restore: 449.63289642333984
  time_this_iter_s: 34.337445974349976
  time_total_s: 449.63289642333984
  timers:
    learn_throughput: 5990.186
    learn_time_ms: 27009.512
    sample_throughput: 22249.017
    sample_time_ms: 7271.872
    update_time_ms: 28.114
  timestamp: 1602371179
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 2414c_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2414c_00000 | RUNNING  | 172.17.0.4:3784 |     13 |          449.633 | 2103296 |  233.314 |              286.475 |              127.081 |            837.946 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2414c_00000:
  custom_metrics:
    time_step_max: 4217
    time_step_mean: 3502.9860797592173
    time_step_min: 3165
  date: 2020-10-10_23-06-53
  done: false
  episode_len_mean: 833.7278481012659
  episode_reward_max: 286.4747474747474
  episode_reward_mean: 235.46197642846923
  episode_reward_min: 127.08080808080815
  episodes_this_iter: 308
  episodes_total: 2686
  experiment_id: 729a2d32d1aa43ceae8b933135524a1b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.9748452263219016
        entropy_coeff: 0.0
        kl: 0.005704211071133614
        model: {}
        policy_loss: -0.003550159387357001
        total_loss: 23.52777930668422
        vf_explained_var: 0.9669684767723083
        vf_loss: 23.53075885772705
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.56341463414634
    gpu_util_percent0: 0.3617073170731707
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.485365853658536
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 3784
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.154782525931697
    mean_env_wait_ms: 1.2079844651590608
    mean_inference_ms: 4.7444976140910935
    mean_raw_obs_processing_ms: 0.4085160897817709
  time_since_restore: 483.8460280895233
  time_this_iter_s: 34.21313166618347
  time_total_s: 483.8460280895233
  timers:
    learn_throughput: 5996.801
    learn_time_ms: 26979.718
    sample_throughput: 22260.223
    sample_time_ms: 7268.211
    update_time_ms: 26.471
  timestamp: 1602371213
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 2414c_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2414c_00000 | RUNNING  | 172.17.0.4:3784 |     14 |          483.846 | 2265088 |  235.462 |              286.475 |              127.081 |            833.728 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2414c_00000:
  custom_metrics:
    time_step_max: 4217
    time_step_mean: 3495.4115767045455
    time_step_min: 3125
  date: 2020-10-10_23-07-28
  done: false
  episode_len_mean: 831.6325597749649
  episode_reward_max: 292.53535353535295
  episode_reward_mean: 236.60420662319385
  episode_reward_min: 127.08080808080815
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: 729a2d32d1aa43ceae8b933135524a1b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.9558461138180324
        entropy_coeff: 0.0
        kl: 0.005150949382888419
        model: {}
        policy_loss: -0.0041134368636578855
        total_loss: 16.030233315059117
        vf_explained_var: 0.9682015776634216
        vf_loss: 16.033832209450857
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.402439024390244
    gpu_util_percent0: 0.3641463414634146
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4902439024390235
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 3784
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15456147383651841
    mean_env_wait_ms: 1.2090062648951112
    mean_inference_ms: 4.7299907685768385
    mean_raw_obs_processing_ms: 0.40777610789665364
  time_since_restore: 518.0417177677155
  time_this_iter_s: 34.19568967819214
  time_total_s: 518.0417177677155
  timers:
    learn_throughput: 5994.122
    learn_time_ms: 26991.774
    sample_throughput: 22333.01
    sample_time_ms: 7244.523
    update_time_ms: 25.263
  timestamp: 1602371248
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 2414c_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2414c_00000 | RUNNING  | 172.17.0.4:3784 |     15 |          518.042 | 2426880 |  236.604 |              292.535 |              127.081 |            831.633 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2414c_00000:
  custom_metrics:
    time_step_max: 4217
    time_step_mean: 3489.2864828513784
    time_step_min: 3125
  date: 2020-10-10_23-08-02
  done: false
  episode_len_mean: 829.6998667554964
  episode_reward_max: 292.53535353535295
  episode_reward_mean: 237.59420319113846
  episode_reward_min: 127.08080808080815
  episodes_this_iter: 158
  episodes_total: 3002
  experiment_id: 729a2d32d1aa43ceae8b933135524a1b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.9314469609941755
        entropy_coeff: 0.0
        kl: 0.005702521252845015
        model: {}
        policy_loss: -0.0036766595606292996
        total_loss: 15.496587821415492
        vf_explained_var: 0.967986524105072
        vf_loss: 15.499694415501185
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.548780487804876
    gpu_util_percent0: 0.3446341463414634
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.502439024390244
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 3784
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15435404709560285
    mean_env_wait_ms: 1.2099803264618818
    mean_inference_ms: 4.7165442627918175
    mean_raw_obs_processing_ms: 0.40708066569804324
  time_since_restore: 552.0241820812225
  time_this_iter_s: 33.98246431350708
  time_total_s: 552.0241820812225
  timers:
    learn_throughput: 6002.147
    learn_time_ms: 26955.685
    sample_throughput: 22266.219
    sample_time_ms: 7266.254
    update_time_ms: 24.664
  timestamp: 1602371282
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 2414c_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2414c_00000 | RUNNING  | 172.17.0.4:3784 |     16 |          552.024 | 2588672 |  237.594 |              292.535 |              127.081 |              829.7 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2414c_00000:
  custom_metrics:
    time_step_max: 4217
    time_step_mean: 3477.451081987199
    time_step_min: 3125
  date: 2020-10-10_23-08-36
  done: false
  episode_len_mean: 825.854034451496
  episode_reward_max: 292.53535353535295
  episode_reward_mean: 239.3372345394103
  episode_reward_min: 127.08080808080815
  episodes_this_iter: 307
  episodes_total: 3309
  experiment_id: 729a2d32d1aa43ceae8b933135524a1b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.9015395045280457
        entropy_coeff: 0.0
        kl: 0.005383640062063932
        model: {}
        policy_loss: -0.0051800252320910135
        total_loss: 20.57960183279855
        vf_explained_var: 0.9723972678184509
        vf_loss: 20.584243365696498
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.721951219512192
    gpu_util_percent0: 0.3641463414634147
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.482926829268291
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 3784
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15399493610046358
    mean_env_wait_ms: 1.2118838931583744
    mean_inference_ms: 4.693263937388269
    mean_raw_obs_processing_ms: 0.4059071805696856
  time_since_restore: 586.2912633419037
  time_this_iter_s: 34.26708126068115
  time_total_s: 586.2912633419037
  timers:
    learn_throughput: 6007.968
    learn_time_ms: 26929.571
    sample_throughput: 22254.532
    sample_time_ms: 7270.07
    update_time_ms: 22.797
  timestamp: 1602371316
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 2414c_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2414c_00000 | RUNNING  | 172.17.0.4:3784 |     17 |          586.291 | 2750464 |  239.337 |              292.535 |              127.081 |            825.854 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2414c_00000:
  custom_metrics:
    time_step_max: 4217
    time_step_mean: 3471.5681554524363
    time_step_min: 3125
  date: 2020-10-10_23-09-10
  done: true
  episode_len_mean: 823.9470655926352
  episode_reward_max: 292.53535353535295
  episode_reward_mean: 240.16398449396135
  episode_reward_min: 127.08080808080815
  episodes_this_iter: 167
  episodes_total: 3476
  experiment_id: 729a2d32d1aa43ceae8b933135524a1b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.882352637393134
        entropy_coeff: 0.0
        kl: 0.005262456235608884
        model: {}
        policy_loss: -0.0033967578617323723
        total_loss: 13.337545939854213
        vf_explained_var: 0.9748047590255737
        vf_loss: 13.340416499546595
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.60731707317073
    gpu_util_percent0: 0.3397560975609756
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.495121951219512
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 3784
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1538139610988274
    mean_env_wait_ms: 1.2128058997832833
    mean_inference_ms: 4.681889001734243
    mean_raw_obs_processing_ms: 0.40532399792419266
  time_since_restore: 620.5865135192871
  time_this_iter_s: 34.29525017738342
  time_total_s: 620.5865135192871
  timers:
    learn_throughput: 6015.822
    learn_time_ms: 26894.414
    sample_throughput: 22227.976
    sample_time_ms: 7278.755
    update_time_ms: 24.132
  timestamp: 1602371350
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 2414c_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2414c_00000 | TERMINATED |       |     18 |          620.587 | 2912256 |  240.164 |              292.535 |              127.081 |            823.947 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2414c_00000 | TERMINATED |       |     18 |          620.587 | 2912256 |  240.164 |              292.535 |              127.081 |            823.947 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


