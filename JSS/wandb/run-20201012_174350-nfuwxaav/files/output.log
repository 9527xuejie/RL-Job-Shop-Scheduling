2020-10-12 17:43:54,136	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.37 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_7fe9e_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=60624)[0m F1012 17:43:56.378516 60624 60624 service_based_gcs_client.cc:207] Couldn't reconnect to GCS server. The last attempted GCS server address was 172.17.0.4:43145
[2m[36m(pid=60624)[0m *** Check failure stack trace: ***
[2m[36m(pid=60624)[0m     @     0x7f84ab2266ed  google::LogMessage::Fail()
[2m[36m(pid=60624)[0m     @     0x7f84ab22784c  google::LogMessage::SendToLog()
[2m[36m(pid=60624)[0m     @     0x7f84ab2263c9  google::LogMessage::Flush()
[2m[36m(pid=60624)[0m     @     0x7f84ab2265e1  google::LogMessage::~LogMessage()
[2m[36m(pid=60658)[0m F1012 17:43:56.378502 60658 60658 service_based_gcs_client.cc:207] Couldn't reconnect to GCS server. The last attempted GCS server address was 172.17.0.4:43145
[2m[36m(pid=60658)[0m *** Check failure stack trace: ***
[2m[36m(pid=60658)[0m     @     0x7f5adf7cd6ed  google::LogMessage::Fail()
[2m[36m(pid=60658)[0m     @     0x7f5adf7ce84c  google::LogMessage::SendToLog()
[2m[36m(pid=60658)[0m     @     0x7f5adf7cd3c9  google::LogMessage::Flush()
[2m[36m(pid=60658)[0m     @     0x7f5adf7cd5e1  google::LogMessage::~LogMessage()
[2m[36m(pid=60658)[0m     @     0x7f5adf784789  ray::RayLog::~RayLog()
[2m[36m(pid=60661)[0m F1012 17:43:56.378307 60661 60661 service_based_gcs_client.cc:207] Couldn't reconnect to GCS server. The last attempted GCS server address was 172.17.0.4:43145
[2m[36m(pid=60661)[0m *** Check failure stack trace: ***
[2m[36m(pid=60661)[0m     @     0x7f2115d2a6ed  google::LogMessage::Fail()
[2m[36m(pid=60661)[0m     @     0x7f2115d2b84c  google::LogMessage::SendToLog()
[2m[36m(pid=60661)[0m     @     0x7f2115d2a3c9  google::LogMessage::Flush()
[2m[36m(pid=60661)[0m     @     0x7f2115d2a5e1  google::LogMessage::~LogMessage()
[2m[36m(pid=60661)[0m     @     0x7f2115ce1789  ray::RayLog::~RayLog()
[2m[36m(pid=60661)[0m     @     0x7f2115a251ea  ray::gcs::ServiceBasedGcsClient::ReconnectGcsServer()
[2m[36m(pid=60690)[0m F1012 17:43:56.379518 60690 60690 service_based_gcs_client.cc:207] Couldn't reconnect to GCS server. The last attempted GCS server address was 172.17.0.4:43145
[2m[36m(pid=60690)[0m *** Check failure stack trace: ***
[2m[36m(pid=60690)[0m     @     0x7f2dd29376ed  google::LogMessage::Fail()
[2m[36m(pid=60690)[0m     @     0x7f2dd293884c  google::LogMessage::SendToLog()
[2m[36m(pid=60690)[0m     @     0x7f2dd29373c9  google::LogMessage::Flush()
[2m[36m(pid=60690)[0m     @     0x7f2dd29375e1  google::LogMessage::~LogMessage()
[2m[36m(pid=60690)[0m     @     0x7f2dd28ee789  ray::RayLog::~RayLog()
[2m[36m(pid=60714)[0m F1012 17:43:56.379153 60714 60714 service_based_gcs_client.cc:207] Couldn't reconnect to GCS server. The last attempted GCS server address was 172.17.0.4:43145
[2m[36m(pid=60714)[0m *** Check failure stack trace: ***
[2m[36m(pid=60714)[0m     @     0x7ff9ef2816ed  google::LogMessage::Fail()
[2m[36m(pid=60714)[0m     @     0x7ff9ef28284c  google::LogMessage::SendToLog()
[2m[36m(pid=60714)[0m     @     0x7ff9ef2813c9  google::LogMessage::Flush()
[2m[36m(pid=60714)[0m     @     0x7ff9ef2815e1  google::LogMessage::~LogMessage()
[2m[36m(pid=60714)[0m     @     0x7ff9ef238789  ray::RayLog::~RayLog()
[2m[36m(pid=60624)[0m     @     0x7f84ab1dd789  ray::RayLog::~RayLog()
[2m[36m(pid=60624)[0m     @     0x7f84aaf211ea  ray::gcs::ServiceBasedGcsClient::ReconnectGcsServer()
[2m[36m(pid=60624)[0m     @     0x7f84aaf212ef  ray::gcs::ServiceBasedGcsClient::GcsServiceFailureDetected()
[2m[36m(pid=60624)[0m     @     0x7f84aaf21491  ray::gcs::ServiceBasedGcsClient::PeriodicallyCheckGcsServerAddress()
[2m[36m(pid=60624)[0m     @     0x7f84aaf23801  ray::gcs::ServiceBasedGcsClient::Connect()
[2m[36m(pid=60658)[0m     @     0x7f5adf4c81ea  ray::gcs::ServiceBasedGcsClient::ReconnectGcsServer()
[2m[36m(pid=60658)[0m     @     0x7f5adf4c82ef  ray::gcs::ServiceBasedGcsClient::GcsServiceFailureDetected()
[2m[36m(pid=60658)[0m     @     0x7f5adf4c8491  ray::gcs::ServiceBasedGcsClient::PeriodicallyCheckGcsServerAddress()
[2m[36m(pid=60658)[0m     @     0x7f5adf4ca801  ray::gcs::ServiceBasedGcsClient::Connect()
[2m[36m(pid=60661)[0m     @     0x7f2115a252ef  ray::gcs::ServiceBasedGcsClient::GcsServiceFailureDetected()
[2m[36m(pid=60661)[0m     @     0x7f2115a25491  ray::gcs::ServiceBasedGcsClient::PeriodicallyCheckGcsServerAddress()
[2m[36m(pid=60661)[0m     @     0x7f2115a27801  ray::gcs::ServiceBasedGcsClient::Connect()
[2m[36m(pid=60690)[0m     @     0x7f2dd26321ea  ray::gcs::ServiceBasedGcsClient::ReconnectGcsServer()
[2m[36m(pid=60690)[0m     @     0x7f2dd26322ef  ray::gcs::ServiceBasedGcsClient::GcsServiceFailureDetected()
[2m[36m(pid=60690)[0m     @     0x7f2dd2632491  ray::gcs::ServiceBasedGcsClient::PeriodicallyCheckGcsServerAddress()
[2m[36m(pid=60690)[0m     @     0x7f2dd2634801  ray::gcs::ServiceBasedGcsClient::Connect()
[2m[36m(pid=60714)[0m     @     0x7ff9eef7c1ea  ray::gcs::ServiceBasedGcsClient::ReconnectGcsServer()
[2m[36m(pid=60714)[0m     @     0x7ff9eef7c2ef  ray::gcs::ServiceBasedGcsClient::GcsServiceFailureDetected()
[2m[36m(pid=60714)[0m     @     0x7ff9eef7c491  ray::gcs::ServiceBasedGcsClient::PeriodicallyCheckGcsServerAddress()
[2m[36m(pid=60714)[0m     @     0x7ff9eef7e801  ray::gcs::ServiceBasedGcsClient::Connect()
[2m[36m(pid=60624)[0m     @     0x7f84aae327a8  ray::gcs::GlobalStateAccessor::Connect()
[2m[36m(pid=60624)[0m     @     0x7f84aada3a2c  __pyx_pw_3ray_7_raylet_19GlobalStateAccessor_3connect()
[2m[36m(pid=60624)[0m     @     0x559104d9598a  method_vectorcall_NOARGS
[2m[36m(pid=60624)[0m     @     0x559104d25b08  _PyEval_EvalFrameDefault.cold.2792
[2m[36m(pid=60624)[0m     @     0x559104db06a2  _PyEval_EvalCodeWithName
[2m[36m(pid=60624)[0m     @     0x559104db1a20  method_vectorcall
[2m[36m(pid=60624)[0m     @     0x559104d26de6  _PyEval_EvalFrameDefault.cold.2792
[2m[36m(pid=60624)[0m     @     0x559104db0baf  _PyEval_EvalCodeWithName
[2m[36m(pid=60624)[0m     @     0x559104db1643  _PyFunction_Vectorcall.localalias.353
[2m[36m(pid=60624)[0m     @     0x559104d26de6  _PyEval_EvalFrameDefault.cold.2792
[2m[36m(pid=60624)[0m     @     0x559104db06a2  _PyEval_EvalCodeWithName
[2m[36m(pid=60624)[0m     @     0x559104db1454  PyEval_EvalCodeEx
[2m[36m(pid=60624)[0m     @     0x559104e3fbbc  PyEval_EvalCode
[2m[36m(pid=60624)[0m     @     0x559104e3fc64  run_eval_code_obj
[2m[36m(pid=60624)[0m     @     0x559104e71d14  run_mod
[2m[36m(pid=60624)[0m     @     0x559104d3a625  PyRun_FileExFlags
[2m[36m(pid=60624)[0m     @     0x559104d3aa0a  PyRun_SimpleFileExFlags
[2m[36m(pid=60624)[0m     @     0x559104d3b8cf  Py_RunMain.cold.2911
[2m[36m(pid=60658)[0m     @     0x7f5adf3d97a8  ray::gcs::GlobalStateAccessor::Connect()
[2m[36m(pid=60658)[0m     @     0x7f5adf34aa2c  __pyx_pw_3ray_7_raylet_19GlobalStateAccessor_3connect()
[2m[36m(pid=60658)[0m     @     0x55eab84d198a  method_vectorcall_NOARGS
[2m[36m(pid=60658)[0m     @     0x55eab8461b08  _PyEval_EvalFrameDefault.cold.2792
[2m[36m(pid=60658)[0m     @     0x55eab84ec6a2  _PyEval_EvalCodeWithName
[2m[36m(pid=60658)[0m     @     0x55eab84eda20  method_vectorcall
[2m[36m(pid=60658)[0m     @     0x55eab8462de6  _PyEval_EvalFrameDefault.cold.2792
[2m[36m(pid=60658)[0m     @     0x55eab84ecbaf  _PyEval_EvalCodeWithName
[2m[36m(pid=60658)[0m     @     0x55eab84ed643  _PyFunction_Vectorcall.localalias.353
[2m[36m(pid=60658)[0m     @     0x55eab8462de6  _PyEval_EvalFrameDefault.cold.2792
[2m[36m(pid=60658)[0m     @     0x55eab84ec6a2  _PyEval_EvalCodeWithName
[2m[36m(pid=60658)[0m     @     0x55eab84ed454  PyEval_EvalCodeEx
[2m[36m(pid=60658)[0m     @     0x55eab857bbbc  PyEval_EvalCode
[2m[36m(pid=60658)[0m     @     0x55eab857bc64  run_eval_code_obj
[2m[36m(pid=60658)[0m     @     0x55eab85add14  run_mod
[2m[36m(pid=60658)[0m     @     0x55eab8476625  PyRun_FileExFlags
[2m[36m(pid=60658)[0m     @     0x55eab8476a0a  PyRun_SimpleFileExFlags
[2m[36m(pid=60658)[0m     @     0x55eab84778cf  Py_RunMain.cold.2911
[2m[36m(pid=60658)[0m     @     0x55eab85b0829  Py_BytesMain
[2m[36m(pid=60661)[0m     @     0x7f21159367a8  ray::gcs::GlobalStateAccessor::Connect()
[2m[36m(pid=60661)[0m     @     0x7f21158a7a2c  __pyx_pw_3ray_7_raylet_19GlobalStateAccessor_3connect()
[2m[36m(pid=60661)[0m     @     0x55726f4e498a  method_vectorcall_NOARGS
[2m[36m(pid=60661)[0m     @     0x55726f474b08  _PyEval_EvalFrameDefault.cold.2792
[2m[36m(pid=60661)[0m     @     0x55726f4ff6a2  _PyEval_EvalCodeWithName
[2m[36m(pid=60661)[0m     @     0x55726f500a20  method_vectorcall
[2m[36m(pid=60661)[0m     @     0x55726f475de6  _PyEval_EvalFrameDefault.cold.2792
[2m[36m(pid=60661)[0m     @     0x55726f4ffbaf  _PyEval_EvalCodeWithName
[2m[36m(pid=60661)[0m     @     0x55726f500643  _PyFunction_Vectorcall.localalias.353
[2m[36m(pid=60661)[0m     @     0x55726f475de6  _PyEval_EvalFrameDefault.cold.2792
[2m[36m(pid=60661)[0m     @     0x55726f4ff6a2  _PyEval_EvalCodeWithName
[2m[36m(pid=60661)[0m     @     0x55726f500454  PyEval_EvalCodeEx
[2m[36m(pid=60661)[0m     @     0x55726f58ebbc  PyEval_EvalCode
[2m[36m(pid=60661)[0m     @     0x55726f58ec64  run_eval_code_obj
[2m[36m(pid=60661)[0m     @     0x55726f5c0d14  run_mod
[2m[36m(pid=60661)[0m     @     0x55726f489625  PyRun_FileExFlags
[2m[36m(pid=60661)[0m     @     0x55726f489a0a  PyRun_SimpleFileExFlags
[2m[36m(pid=60661)[0m     @     0x55726f48a8cf  Py_RunMain.cold.2911
[2m[36m(pid=60661)[0m     @     0x55726f5c3829  Py_BytesMain
[2m[36m(pid=60690)[0m     @     0x7f2dd25437a8  ray::gcs::GlobalStateAccessor::Connect()
[2m[36m(pid=60690)[0m     @     0x7f2dd24b4a2c  __pyx_pw_3ray_7_raylet_19GlobalStateAccessor_3connect()
[2m[36m(pid=60690)[0m     @     0x56447979798a  method_vectorcall_NOARGS
[2m[36m(pid=60690)[0m     @     0x564479727b08  _PyEval_EvalFrameDefault.cold.2792
[2m[36m(pid=60690)[0m     @     0x5644797b26a2  _PyEval_EvalCodeWithName
[2m[36m(pid=60690)[0m     @     0x5644797b3a20  method_vectorcall
[2m[36m(pid=60690)[0m     @     0x564479728de6  _PyEval_EvalFrameDefault.cold.2792
[2m[36m(pid=60690)[0m     @     0x5644797b2baf  _PyEval_EvalCodeWithName
[2m[36m(pid=60690)[0m     @     0x5644797b3643  _PyFunction_Vectorcall.localalias.353
[2m[36m(pid=60690)[0m     @     0x564479728de6  _PyEval_EvalFrameDefault.cold.2792
[2m[36m(pid=60690)[0m     @     0x5644797b26a2  _PyEval_EvalCodeWithName
[2m[36m(pid=60690)[0m     @     0x5644797b3454  PyEval_EvalCodeEx
[2m[36m(pid=60690)[0m     @     0x564479841bbc  PyEval_EvalCode
[2m[36m(pid=60690)[0m     @     0x564479841c64  run_eval_code_obj
[2m[36m(pid=60690)[0m     @     0x564479873d14  run_mod
[2m[36m(pid=60690)[0m     @     0x56447973c625  PyRun_FileExFlags
[2m[36m(pid=60690)[0m     @     0x56447973ca0a  PyRun_SimpleFileExFlags
[2m[36m(pid=60690)[0m     @     0x56447973d8cf  Py_RunMain.cold.2911
[2m[36m(pid=60690)[0m     @     0x564479876829  Py_BytesMain
[2m[36m(pid=60714)[0m     @     0x7ff9eee8d7a8  ray::gcs::GlobalStateAccessor::Connect()
[2m[36m(pid=60714)[0m     @     0x7ff9eedfea2c  __pyx_pw_3ray_7_raylet_19GlobalStateAccessor_3connect()
[2m[36m(pid=60714)[0m     @     0x5571757ff98a  method_vectorcall_NOARGS
[2m[36m(pid=60714)[0m     @     0x55717578fb08  _PyEval_EvalFrameDefault.cold.2792
[2m[36m(pid=60714)[0m     @     0x55717581a6a2  _PyEval_EvalCodeWithName
[2m[36m(pid=60714)[0m     @     0x55717581ba20  method_vectorcall
[2m[36m(pid=60714)[0m     @     0x557175790de6  _PyEval_EvalFrameDefault.cold.2792
[2m[36m(pid=60714)[0m     @     0x55717581abaf  _PyEval_EvalCodeWithName
[2m[36m(pid=60714)[0m     @     0x55717581b643  _PyFunction_Vectorcall.localalias.353
[2m[36m(pid=60714)[0m     @     0x557175790de6  _PyEval_EvalFrameDefault.cold.2792
[2m[36m(pid=60714)[0m     @     0x55717581a6a2  _PyEval_EvalCodeWithName
[2m[36m(pid=60714)[0m     @     0x55717581b454  PyEval_EvalCodeEx
[2m[36m(pid=60714)[0m     @     0x5571758a9bbc  PyEval_EvalCode
[2m[36m(pid=60714)[0m     @     0x5571758a9c64  run_eval_code_obj
[2m[36m(pid=60714)[0m     @     0x5571758dbd14  run_mod
[2m[36m(pid=60714)[0m     @     0x5571757a4625  PyRun_FileExFlags
[2m[36m(pid=60714)[0m     @     0x5571757a4a0a  PyRun_SimpleFileExFlags
[2m[36m(pid=60714)[0m     @     0x5571757a58cf  Py_RunMain.cold.2911
[2m[36m(pid=60714)[0m     @     0x5571758de829  Py_BytesMain
[2m[36m(pid=60624)[0m     @     0x559104e74829  Py_BytesMain
[2m[36m(pid=60624)[0m     @     0x7f84ac52b840  __libc_start_main
[2m[36m(pid=60624)[0m     @     0x559104e04b33  (unknown)
[2m[36m(pid=60658)[0m     @     0x7f5ae0ad2840  __libc_start_main
[2m[36m(pid=60658)[0m     @     0x55eab8540b33  (unknown)
[2m[36m(pid=60661)[0m     @     0x7f211702f840  __libc_start_main
[2m[36m(pid=60661)[0m     @     0x55726f553b33  (unknown)
[2m[36m(pid=60690)[0m     @     0x7f2dd3c3c840  __libc_start_main
[2m[36m(pid=60690)[0m     @     0x564479806b33  (unknown)
[2m[36m(pid=60714)[0m     @     0x7ff9f0586840  __libc_start_main
[2m[36m(pid=60714)[0m     @     0x55717586eb33  (unknown)
[2m[36m(pid=60752)[0m 2020-10-12 17:43:56,991	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=60739)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60739)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60702)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60702)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60718)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60718)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60716)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60716)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60758)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60758)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60695)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60695)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60755)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60755)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60720)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60720)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60711)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60711)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60735)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60735)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60732)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60732)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60703)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60703)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60745)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60745)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60733)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60733)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60731)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60731)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60682)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60682)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60721)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60721)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60654)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60654)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60712)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60712)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60697)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60697)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60646)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60646)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60747)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60747)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60632)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60632)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60640)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60640)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60649)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60649)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60633)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60633)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60653)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60653)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60694)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60694)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60699)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60699)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60641)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60641)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60635)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60635)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60650)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60650)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60740)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60740)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60652)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60652)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60626)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60626)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60700)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60700)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60625)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60625)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60748)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60748)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60736)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60736)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60643)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60643)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60630)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60630)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60627)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60627)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60636)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60636)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62032)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62032)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62030)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62030)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62034)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62034)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62033)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62033)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60623)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60623)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60708)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60708)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60725)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60725)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60742)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60742)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60738)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60738)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60696)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60696)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60688)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60688)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60709)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60709)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60628)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60628)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60705)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60705)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60707)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60707)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60629)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60629)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60656)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60656)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60698)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60698)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60638)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60638)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60679)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60679)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60681)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60681)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60706)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60706)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60642)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60642)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60665)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60665)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60634)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60634)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62031)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62031)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60704)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60704)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60692)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60692)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60710)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60710)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60701)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60701)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60637)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60637)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60723)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60723)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60644)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60644)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60727)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60727)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60685)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60685)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60744)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60744)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_7fe9e_00000:
  custom_metrics:
    time_step_max: 3691
    time_step_mean: 3418.869230769231
    time_step_min: 3176
  date: 2020-10-12_17-44-30
  done: false
  episode_len_mean: 886.753164556962
  episode_reward_max: 282.343434343434
  episode_reward_mean: 241.94642628819824
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 86b3342f9eeb46c9a6fb2ff43c27e2e3
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1820020775000255
        entropy_coeff: 0.009999999999999998
        kl: 0.007774646393954754
        model: {}
        policy_loss: -0.010018515279322552
        total_loss: 488.3563003540039
        vf_explained_var: 0.49538537859916687
        vf_loss: 488.3765920003255
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.105882352941176
    gpu_util_percent0: 0.33029411764705885
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5970588235294123
    vram_util_percent0: 0.08660505855343122
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60752
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1687276256640188
    mean_env_wait_ms: 1.1586135476781616
    mean_inference_ms: 5.6357870369864385
    mean_raw_obs_processing_ms: 0.45224763022855907
  time_since_restore: 28.597816705703735
  time_this_iter_s: 28.597816705703735
  time_total_s: 28.597816705703735
  timers:
    learn_throughput: 8212.381
    learn_time_ms: 19700.984
    sample_throughput: 18335.574
    sample_time_ms: 8823.94
    update_time_ms: 28.807
  timestamp: 1602524670
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 7fe9e_00000
  
== Status ==
Memory usage on this node: 28.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.37 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7fe9e_00000 | RUNNING  | 172.17.0.4:60752 |      1 |          28.5978 | 161792 |  241.946 |              282.343 |              165.677 |            886.753 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7fe9e_00000:
  custom_metrics:
    time_step_max: 3804
    time_step_mean: 3423.8645833333335
    time_step_min: 3146
  date: 2020-10-12_17-44-58
  done: false
  episode_len_mean: 885.2310126582279
  episode_reward_max: 286.888888888889
  episode_reward_mean: 242.34295486510655
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 86b3342f9eeb46c9a6fb2ff43c27e2e3
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.150316019852956
        entropy_coeff: 0.009999999999999998
        kl: 0.00876023822153608
        model: {}
        policy_loss: -0.010785821524526304
        total_loss: 123.56760342915852
        vf_explained_var: 0.7958800196647644
        vf_loss: 123.58813794453938
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.10625
    gpu_util_percent0: 0.2625
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60752
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16542158511678462
    mean_env_wait_ms: 1.154249304371715
    mean_inference_ms: 5.475489362186884
    mean_raw_obs_processing_ms: 0.4438480663006808
  time_since_restore: 56.345850229263306
  time_this_iter_s: 27.74803352355957
  time_total_s: 56.345850229263306
  timers:
    learn_throughput: 8198.337
    learn_time_ms: 19734.735
    sample_throughput: 19378.075
    sample_time_ms: 8349.23
    update_time_ms: 37.084
  timestamp: 1602524698
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 7fe9e_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.37 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7fe9e_00000 | RUNNING  | 172.17.0.4:60752 |      2 |          56.3459 | 323584 |  242.343 |              286.889 |              165.677 |            885.231 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7fe9e_00000:
  custom_metrics:
    time_step_max: 3865
    time_step_mean: 3421.7825112107626
    time_step_min: 3146
  date: 2020-10-12_17-45-25
  done: false
  episode_len_mean: 879.7510548523206
  episode_reward_max: 286.888888888889
  episode_reward_mean: 243.42993223372952
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 86b3342f9eeb46c9a6fb2ff43c27e2e3
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1413436432679493
        entropy_coeff: 0.009999999999999998
        kl: 0.01218837988562882
        model: {}
        policy_loss: -0.013896720891352743
        total_loss: 50.76286919911703
        vf_explained_var: 0.8870547413825989
        vf_loss: 50.7857411702474
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.729032258064507
    gpu_util_percent0: 0.29903225806451605
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8032258064516133
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60752
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16283621658334593
    mean_env_wait_ms: 1.1529258264961635
    mean_inference_ms: 5.319972592901626
    mean_raw_obs_processing_ms: 0.4361940353454818
  time_since_restore: 83.16830468177795
  time_this_iter_s: 26.82245445251465
  time_total_s: 83.16830468177795
  timers:
    learn_throughput: 8220.033
    learn_time_ms: 19682.645
    sample_throughput: 20346.648
    sample_time_ms: 7951.777
    update_time_ms: 37.397
  timestamp: 1602524725
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 7fe9e_00000
  
== Status ==
Memory usage on this node: 28.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.37 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7fe9e_00000 | RUNNING  | 172.17.0.4:60752 |      3 |          83.1683 | 485376 |   243.43 |              286.889 |              165.677 |            879.751 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7fe9e_00000:
  custom_metrics:
    time_step_max: 3937
    time_step_mean: 3418.023178807947
    time_step_min: 3146
  date: 2020-10-12_17-45-52
  done: false
  episode_len_mean: 873.0901898734177
  episode_reward_max: 286.888888888889
  episode_reward_mean: 244.79069172740037
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 86b3342f9eeb46c9a6fb2ff43c27e2e3
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1202614605426788
        entropy_coeff: 0.009999999999999998
        kl: 0.009905736815805236
        model: {}
        policy_loss: -0.013301973153526584
        total_loss: 43.111274083455406
        vf_explained_var: 0.902519702911377
        vf_loss: 43.13379700978597
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.229032258064517
    gpu_util_percent0: 0.26999999999999996
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.858064516129034
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60752
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16086278287002945
    mean_env_wait_ms: 1.1535561797604585
    mean_inference_ms: 5.198414855802965
    mean_raw_obs_processing_ms: 0.4298711376710661
  time_since_restore: 109.84654498100281
  time_this_iter_s: 26.678240299224854
  time_total_s: 109.84654498100281
  timers:
    learn_throughput: 8232.86
    learn_time_ms: 19651.98
    sample_throughput: 20955.661
    sample_time_ms: 7720.682
    update_time_ms: 39.217
  timestamp: 1602524752
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 7fe9e_00000
  
== Status ==
Memory usage on this node: 28.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.37 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7fe9e_00000 | RUNNING  | 172.17.0.4:60752 |      4 |          109.847 | 647168 |  244.791 |              286.889 |              165.677 |             873.09 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7fe9e_00000:
  custom_metrics:
    time_step_max: 3937
    time_step_mean: 3412.024771838331
    time_step_min: 3058
  date: 2020-10-12_17-46-19
  done: false
  episode_len_mean: 867.3622641509434
  episode_reward_max: 300.2222222222221
  episode_reward_mean: 245.59748427672935
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 163
  episodes_total: 795
  experiment_id: 86b3342f9eeb46c9a6fb2ff43c27e2e3
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0757236381371815
        entropy_coeff: 0.009999999999999998
        kl: 0.009962915442883968
        model: {}
        policy_loss: -0.011633968097157776
        total_loss: 32.291967709859215
        vf_explained_var: 0.9438338279724121
        vf_loss: 32.312366008758545
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.25625
    gpu_util_percent0: 0.35468749999999993
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7875000000000005
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60752
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15931820358739432
    mean_env_wait_ms: 1.1557451251693074
    mean_inference_ms: 5.100634021478796
    mean_raw_obs_processing_ms: 0.42461064000631027
  time_since_restore: 136.891681432724
  time_this_iter_s: 27.04513645172119
  time_total_s: 136.891681432724
  timers:
    learn_throughput: 8222.13
    learn_time_ms: 19677.625
    sample_throughput: 21296.771
    sample_time_ms: 7597.02
    update_time_ms: 52.739
  timestamp: 1602524779
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 7fe9e_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.37 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7fe9e_00000 | RUNNING  | 172.17.0.4:60752 |      5 |          136.892 | 808960 |  245.597 |              300.222 |              165.677 |            867.362 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7fe9e_00000:
  custom_metrics:
    time_step_max: 3937
    time_step_mean: 3398.5018552875695
    time_step_min: 3058
  date: 2020-10-12_17-46-46
  done: false
  episode_len_mean: 856.1925858951175
  episode_reward_max: 300.2222222222221
  episode_reward_mean: 247.89798527773198
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 311
  episodes_total: 1106
  experiment_id: 86b3342f9eeb46c9a6fb2ff43c27e2e3
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0880309740702312
        entropy_coeff: 0.009999999999999998
        kl: 0.009906971051047245
        model: {}
        policy_loss: -0.01418424024207828
        total_loss: 23.68917989730835
        vf_explained_var: 0.960367739200592
        vf_loss: 23.712262630462646
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.626666666666665
    gpu_util_percent0: 0.3593333333333332
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.840000000000001
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60752
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1572573639214457
    mean_env_wait_ms: 1.1599722521548528
    mean_inference_ms: 4.97185939408368
    mean_raw_obs_processing_ms: 0.41778172889520115
  time_since_restore: 163.4590322971344
  time_this_iter_s: 26.5673508644104
  time_total_s: 163.4590322971344
  timers:
    learn_throughput: 8232.086
    learn_time_ms: 19653.828
    sample_throughput: 21600.388
    sample_time_ms: 7490.236
    update_time_ms: 47.751
  timestamp: 1602524806
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 7fe9e_00000
  
== Status ==
Memory usage on this node: 28.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.37 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7fe9e_00000 | RUNNING  | 172.17.0.4:60752 |      6 |          163.459 | 970752 |  247.898 |              300.222 |              165.677 |            856.193 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7fe9e_00000:
  custom_metrics:
    time_step_max: 3937
    time_step_mean: 3392.0606796116504
    time_step_min: 3058
  date: 2020-10-12_17-47-12
  done: false
  episode_len_mean: 852.0949367088608
  episode_reward_max: 300.2222222222221
  episode_reward_mean: 248.93218578186912
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: 86b3342f9eeb46c9a6fb2ff43c27e2e3
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.066784660021464
        entropy_coeff: 0.009999999999999998
        kl: 0.010593781092514595
        model: {}
        policy_loss: -0.013834795313111195
        total_loss: 17.26591380437215
        vf_explained_var: 0.9633823037147522
        vf_loss: 17.288297335306805
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.61935483870968
    gpu_util_percent0: 0.26903225806451614
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8193548387096774
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60752
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1565079725617849
    mean_env_wait_ms: 1.1616496887879515
    mean_inference_ms: 4.92390207095598
    mean_raw_obs_processing_ms: 0.41522618739747913
  time_since_restore: 189.97484588623047
  time_this_iter_s: 26.51581358909607
  time_total_s: 189.97484588623047
  timers:
    learn_throughput: 8244.659
    learn_time_ms: 19623.856
    sample_throughput: 21805.508
    sample_time_ms: 7419.777
    update_time_ms: 43.744
  timestamp: 1602524832
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 7fe9e_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.37 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7fe9e_00000 | RUNNING  | 172.17.0.4:60752 |      7 |          189.975 | 1132544 |  248.932 |              300.222 |              165.677 |            852.095 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7fe9e_00000:
  custom_metrics:
    time_step_max: 3937
    time_step_mean: 3384.1169296987086
    time_step_min: 3058
  date: 2020-10-12_17-47-39
  done: false
  episode_len_mean: 848.985935302391
  episode_reward_max: 300.2222222222221
  episode_reward_mean: 249.96927076673896
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 86b3342f9eeb46c9a6fb2ff43c27e2e3
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0405194958051045
        entropy_coeff: 0.009999999999999998
        kl: 0.00961096266595026
        model: {}
        policy_loss: -0.014498237986117601
        total_loss: 16.290620883305866
        vf_explained_var: 0.9633330702781677
        vf_loss: 16.313602447509766
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.464516129032262
    gpu_util_percent0: 0.29774193548387096
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8612903225806465
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60752
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15585831613237977
    mean_env_wait_ms: 1.1632154230004172
    mean_inference_ms: 4.88184120548181
    mean_raw_obs_processing_ms: 0.412874208859421
  time_since_restore: 216.80199551582336
  time_this_iter_s: 26.827149629592896
  time_total_s: 216.80199551582336
  timers:
    learn_throughput: 8228.11
    learn_time_ms: 19663.326
    sample_throughput: 22040.421
    sample_time_ms: 7340.695
    update_time_ms: 43.411
  timestamp: 1602524859
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 7fe9e_00000
  
== Status ==
Memory usage on this node: 28.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.37 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7fe9e_00000 | RUNNING  | 172.17.0.4:60752 |      8 |          216.802 | 1294336 |  249.969 |              300.222 |              165.677 |            848.986 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7fe9e_00000:
  custom_metrics:
    time_step_max: 3937
    time_step_mean: 3379.7350865939707
    time_step_min: 3058
  date: 2020-10-12_17-48-05
  done: false
  episode_len_mean: 846.3509766855702
  episode_reward_max: 300.2222222222221
  episode_reward_mean: 250.71276087911235
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 165
  episodes_total: 1587
  experiment_id: 86b3342f9eeb46c9a6fb2ff43c27e2e3
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9924418479204178
        entropy_coeff: 0.009999999999999998
        kl: 0.010049515714248022
        model: {}
        policy_loss: -0.012585859900961319
        total_loss: 14.588239034016928
        vf_explained_var: 0.9740464091300964
        vf_loss: 14.608739614486694
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.220000000000006
    gpu_util_percent0: 0.3960000000000001
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8166666666666678
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60752
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1552680750491058
    mean_env_wait_ms: 1.1647672040582082
    mean_inference_ms: 4.843297888846515
    mean_raw_obs_processing_ms: 0.41066848074033535
  time_since_restore: 243.16782093048096
  time_this_iter_s: 26.365825414657593
  time_total_s: 243.16782093048096
  timers:
    learn_throughput: 8233.685
    learn_time_ms: 19650.01
    sample_throughput: 22240.856
    sample_time_ms: 7274.54
    update_time_ms: 41.465
  timestamp: 1602524885
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 7fe9e_00000
  
== Status ==
Memory usage on this node: 28.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.37 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7fe9e_00000 | RUNNING  | 172.17.0.4:60752 |      9 |          243.168 | 1456128 |  250.713 |              300.222 |              165.677 |            846.351 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7fe9e_00000:
  custom_metrics:
    time_step_max: 3937
    time_step_mean: 3369.595607927156
    time_step_min: 3058
  date: 2020-10-12_17-48-32
  done: false
  episode_len_mean: 841.555672823219
  episode_reward_max: 300.2222222222221
  episode_reward_mean: 252.54516137629582
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 308
  episodes_total: 1895
  experiment_id: 86b3342f9eeb46c9a6fb2ff43c27e2e3
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9963159461816152
        entropy_coeff: 0.009999999999999998
        kl: 0.00856743473559618
        model: {}
        policy_loss: -0.013211292010964826
        total_loss: 15.818744023640951
        vf_explained_var: 0.9754418730735779
        vf_loss: 15.8402050336202
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.453333333333333
    gpu_util_percent0: 0.301
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8433333333333346
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60752
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1543642172504592
    mean_env_wait_ms: 1.1674061593571796
    mean_inference_ms: 4.784906670324149
    mean_raw_obs_processing_ms: 0.40735814606283094
  time_since_restore: 269.39147901535034
  time_this_iter_s: 26.223658084869385
  time_total_s: 269.39147901535034
  timers:
    learn_throughput: 8244.763
    learn_time_ms: 19623.609
    sample_throughput: 22398.974
    sample_time_ms: 7223.188
    update_time_ms: 39.317
  timestamp: 1602524912
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 7fe9e_00000
  
== Status ==
Memory usage on this node: 28.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.37 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7fe9e_00000 | RUNNING  | 172.17.0.4:60752 |     10 |          269.391 | 1617920 |  252.545 |              300.222 |              165.677 |            841.556 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7fe9e_00000:
  custom_metrics:
    time_step_max: 3937
    time_step_mean: 3364.7270483711745
    time_step_min: 3058
  date: 2020-10-12_17-48-58
  done: false
  episode_len_mean: 838.7964946445959
  episode_reward_max: 300.2222222222221
  episode_reward_mean: 253.39297551955767
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 159
  episodes_total: 2054
  experiment_id: 86b3342f9eeb46c9a6fb2ff43c27e2e3
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9897495210170746
        entropy_coeff: 0.009999999999999998
        kl: 0.008607143225769201
        model: {}
        policy_loss: -0.015703455739033718
        total_loss: 14.762703895568848
        vf_explained_var: 0.969495952129364
        vf_loss: 14.786583105723063
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.54838709677419
    gpu_util_percent0: 0.28580645161290325
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.864516129032259
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60752
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15397576048692202
    mean_env_wait_ms: 1.168556574449378
    mean_inference_ms: 4.759837610534256
    mean_raw_obs_processing_ms: 0.4059212976277617
  time_since_restore: 295.8297801017761
  time_this_iter_s: 26.43830108642578
  time_total_s: 295.8297801017761
  timers:
    learn_throughput: 8248.835
    learn_time_ms: 19613.922
    sample_throughput: 23061.736
    sample_time_ms: 7015.604
    update_time_ms: 39.064
  timestamp: 1602524938
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 7fe9e_00000
  
== Status ==
Memory usage on this node: 28.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.37 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7fe9e_00000 | RUNNING  | 172.17.0.4:60752 |     11 |           295.83 | 1779712 |  253.393 |              300.222 |              165.677 |            838.796 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7fe9e_00000:
  custom_metrics:
    time_step_max: 3937
    time_step_mean: 3360.828296703297
    time_step_min: 3058
  date: 2020-10-12_17-49-25
  done: false
  episode_len_mean: 836.0809222423146
  episode_reward_max: 300.2222222222221
  episode_reward_mean: 254.04469194659058
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 86b3342f9eeb46c9a6fb2ff43c27e2e3
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9671823730071386
        entropy_coeff: 0.009999999999999998
        kl: 0.009246536763384938
        model: {}
        policy_loss: -0.013299339607935204
        total_loss: 12.791313807169596
        vf_explained_var: 0.9718108177185059
        vf_loss: 12.812435468037924
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.245161290322578
    gpu_util_percent0: 0.34451612903225803
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.864516129032259
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60752
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15362554422840358
    mean_env_wait_ms: 1.1696961732197346
    mean_inference_ms: 4.737175694694978
    mean_raw_obs_processing_ms: 0.4045993169112942
  time_since_restore: 322.3938157558441
  time_this_iter_s: 26.564035654067993
  time_total_s: 322.3938157558441
  timers:
    learn_throughput: 8250.059
    learn_time_ms: 19611.011
    sample_throughput: 23439.818
    sample_time_ms: 6902.443
    update_time_ms: 36.831
  timestamp: 1602524965
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 7fe9e_00000
  
== Status ==
Memory usage on this node: 28.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.37 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7fe9e_00000 | RUNNING  | 172.17.0.4:60752 |     12 |          322.394 | 1941504 |  254.045 |              300.222 |              165.677 |            836.081 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7fe9e_00000:
  custom_metrics:
    time_step_max: 3937
    time_step_mean: 3355.0160427807486
    time_step_min: 3058
  date: 2020-10-12_17-49-51
  done: false
  episode_len_mean: 832.219194794632
  episode_reward_max: 300.2222222222221
  episode_reward_mean: 254.85073590726287
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 247
  episodes_total: 2459
  experiment_id: 86b3342f9eeb46c9a6fb2ff43c27e2e3
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9249537189801534
        entropy_coeff: 0.009999999999999998
        kl: 0.0077892803043747945
        model: {}
        policy_loss: -0.01340778338878105
        total_loss: 15.985984007517496
        vf_explained_var: 0.9758171439170837
        vf_loss: 16.00708317756653
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.91333333333334
    gpu_util_percent0: 0.37966666666666665
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8066666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60752
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15315393874888197
    mean_env_wait_ms: 1.1715912404592808
    mean_inference_ms: 4.706038051917187
    mean_raw_obs_processing_ms: 0.4027603315162653
  time_since_restore: 348.723042011261
  time_this_iter_s: 26.32922625541687
  time_total_s: 348.723042011261
  timers:
    learn_throughput: 8258.075
    learn_time_ms: 19591.975
    sample_throughput: 23540.915
    sample_time_ms: 6872.8
    update_time_ms: 34.993
  timestamp: 1602524991
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 7fe9e_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.37 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7fe9e_00000 | RUNNING  | 172.17.0.4:60752 |     13 |          348.723 | 2103296 |  254.851 |              300.222 |              165.677 |            832.219 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7fe9e_00000:
  custom_metrics:
    time_step_max: 3937
    time_step_mean: 3350.8295711060946
    time_step_min: 3058
  date: 2020-10-12_17-50-18
  done: false
  episode_len_mean: 829.4981384959046
  episode_reward_max: 300.2222222222221
  episode_reward_mean: 255.52762171228287
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 227
  episodes_total: 2686
  experiment_id: 86b3342f9eeb46c9a6fb2ff43c27e2e3
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9350921461979548
        entropy_coeff: 0.009999999999999998
        kl: 0.008452397538349032
        model: {}
        policy_loss: -0.013019873877055943
        total_loss: 11.574453274408976
        vf_explained_var: 0.9792971611022949
        vf_loss: 11.595133622487387
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.249999999999996
    gpu_util_percent0: 0.26266666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8533333333333344
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60752
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15276803710733236
    mean_env_wait_ms: 1.1731406990104671
    mean_inference_ms: 4.681108788991369
    mean_raw_obs_processing_ms: 0.4013568654097053
  time_since_restore: 374.83606004714966
  time_this_iter_s: 26.113018035888672
  time_total_s: 374.83606004714966
  timers:
    learn_throughput: 8268.803
    learn_time_ms: 19566.557
    sample_throughput: 23642.921
    sample_time_ms: 6843.148
    update_time_ms: 32.634
  timestamp: 1602525018
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 7fe9e_00000
  
== Status ==
Memory usage on this node: 28.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.37 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7fe9e_00000 | RUNNING  | 172.17.0.4:60752 |     14 |          374.836 | 2265088 |  255.528 |              300.222 |              165.677 |            829.498 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7fe9e_00000:
  custom_metrics:
    time_step_max: 3937
    time_step_mean: 3348.049715909091
    time_step_min: 3058
  date: 2020-10-12_17-50-44
  done: false
  episode_len_mean: 827.7274964838256
  episode_reward_max: 300.2222222222221
  episode_reward_mean: 256.02556152239686
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: 86b3342f9eeb46c9a6fb2ff43c27e2e3
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9192713797092438
        entropy_coeff: 0.009999999999999998
        kl: 0.009106894411767522
        model: {}
        policy_loss: -0.013783228302296871
        total_loss: 10.940451622009277
        vf_explained_var: 0.9768653512001038
        vf_loss: 10.9616060256958
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.112903225806456
    gpu_util_percent0: 0.3280645161290322
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8612903225806465
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60752
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15253176476673944
    mean_env_wait_ms: 1.1741510565937636
    mean_inference_ms: 4.665546809479448
    mean_raw_obs_processing_ms: 0.4004566665446815
  time_since_restore: 401.3643538951874
  time_this_iter_s: 26.52829384803772
  time_total_s: 401.3643538951874
  timers:
    learn_throughput: 8273.521
    learn_time_ms: 19555.397
    sample_throughput: 23761.676
    sample_time_ms: 6808.947
    update_time_ms: 25.628
  timestamp: 1602525044
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 7fe9e_00000
  
== Status ==
Memory usage on this node: 28.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.37 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7fe9e_00000 | RUNNING  | 172.17.0.4:60752 |     15 |          401.364 | 2426880 |  256.026 |              300.222 |              165.677 |            827.727 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7fe9e_00000:
  custom_metrics:
    time_step_max: 3937
    time_step_mean: 3343.64128256513
    time_step_min: 3058
  date: 2020-10-12_17-51-11
  done: false
  episode_len_mean: 825.0714758438121
  episode_reward_max: 300.2222222222221
  episode_reward_mean: 256.6715433621455
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 178
  episodes_total: 3022
  experiment_id: 86b3342f9eeb46c9a6fb2ff43c27e2e3
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8827571322520574
        entropy_coeff: 0.009999999999999998
        kl: 0.00814120975943903
        model: {}
        policy_loss: -0.012587558206481239
        total_loss: 12.927326361338297
        vf_explained_var: 0.9760591983795166
        vf_loss: 12.947113513946533
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.246666666666666
    gpu_util_percent0: 0.36433333333333334
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.860000000000001
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60752
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15228965879824996
    mean_env_wait_ms: 1.1753883328229353
    mean_inference_ms: 4.649442264699071
    mean_raw_obs_processing_ms: 0.3995244095071105
  time_since_restore: 427.76297426223755
  time_this_iter_s: 26.39862036705017
  time_total_s: 427.76297426223755
  timers:
    learn_throughput: 8274.679
    learn_time_ms: 19552.662
    sample_throughput: 23819.41
    sample_time_ms: 6792.444
    update_time_ms: 27.593
  timestamp: 1602525071
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 7fe9e_00000
  
== Status ==
Memory usage on this node: 28.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.37 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7fe9e_00000 | RUNNING  | 172.17.0.4:60752 |     16 |          427.763 | 2588672 |  256.672 |              300.222 |              165.677 |            825.071 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7fe9e_00000:
  custom_metrics:
    time_step_max: 3937
    time_step_mean: 3337.2978982637833
    time_step_min: 3058
  date: 2020-10-12_17-51-37
  done: false
  episode_len_mean: 821.7674418604652
  episode_reward_max: 300.2222222222221
  episode_reward_mean: 257.5471629615392
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 289
  episodes_total: 3311
  experiment_id: 86b3342f9eeb46c9a6fb2ff43c27e2e3
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8981230109930038
        entropy_coeff: 0.009999999999999998
        kl: 0.006675910709115366
        model: {}
        policy_loss: -0.010721152269979939
        total_loss: 15.721824725468954
        vf_explained_var: 0.9754064679145813
        vf_loss: 15.740192095438639
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.20645161290322
    gpu_util_percent0: 0.2696774193548387
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.854838709677421
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60752
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15193223737316058
    mean_env_wait_ms: 1.1771984041768992
    mean_inference_ms: 4.6259526745640605
    mean_raw_obs_processing_ms: 0.39816718700272746
  time_since_restore: 454.29013538360596
  time_this_iter_s: 26.527161121368408
  time_total_s: 454.29013538360596
  timers:
    learn_throughput: 8265.586
    learn_time_ms: 19574.173
    sample_throughput: 23898.324
    sample_time_ms: 6770.014
    update_time_ms: 29.041
  timestamp: 1602525097
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 7fe9e_00000
  
== Status ==
Memory usage on this node: 28.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.37 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7fe9e_00000 | RUNNING  | 172.17.0.4:60752 |     17 |           454.29 | 2750464 |  257.547 |              300.222 |              165.677 |            821.767 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7fe9e_00000:
  custom_metrics:
    time_step_max: 3937
    time_step_mean: 3333.6977958236657
    time_step_min: 3058
  date: 2020-10-12_17-52-04
  done: false
  episode_len_mean: 819.8593210586881
  episode_reward_max: 300.2222222222221
  episode_reward_mean: 258.10872534319014
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 165
  episodes_total: 3476
  experiment_id: 86b3342f9eeb46c9a6fb2ff43c27e2e3
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8890323291222254
        entropy_coeff: 0.009999999999999998
        kl: 0.008143752192457518
        model: {}
        policy_loss: -0.012578828037173176
        total_loss: 9.946056842803955
        vf_explained_var: 0.9779917597770691
        vf_loss: 9.965896844863892
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.851612903225806
    gpu_util_percent0: 0.2903225806451613
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8612903225806465
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60752
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15174927303689684
    mean_env_wait_ms: 1.1781632196425182
    mean_inference_ms: 4.613960477903548
    mean_raw_obs_processing_ms: 0.3974815537786032
  time_since_restore: 480.6953635215759
  time_this_iter_s: 26.40522813796997
  time_total_s: 480.6953635215759
  timers:
    learn_throughput: 8280.819
    learn_time_ms: 19538.165
    sample_throughput: 23914.348
    sample_time_ms: 6765.478
    update_time_ms: 26.803
  timestamp: 1602525124
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 7fe9e_00000
  
== Status ==
Memory usage on this node: 28.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.37 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7fe9e_00000 | RUNNING  | 172.17.0.4:60752 |     18 |          480.695 | 2912256 |  258.109 |              300.222 |              165.677 |            819.859 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7fe9e_00000:
  custom_metrics:
    time_step_max: 3937
    time_step_mean: 3330.204098587649
    time_step_min: 3058
  date: 2020-10-12_17-52-31
  done: false
  episode_len_mean: 818.1382247870295
  episode_reward_max: 300.2222222222221
  episode_reward_mean: 258.6534429205492
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 163
  episodes_total: 3639
  experiment_id: 86b3342f9eeb46c9a6fb2ff43c27e2e3
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8594749917586645
        entropy_coeff: 0.009999999999999998
        kl: 0.008123672101646662
        model: {}
        policy_loss: -0.012689230468822643
        total_loss: 9.738242149353027
        vf_explained_var: 0.9791495203971863
        vf_loss: 9.757901271184286
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.122580645161285
    gpu_util_percent0: 0.40612903225806446
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.864516129032259
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60752
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15158155974577248
    mean_env_wait_ms: 1.1791276975452851
    mean_inference_ms: 4.60287284522628
    mean_raw_obs_processing_ms: 0.3968342930316022
  time_since_restore: 507.3137490749359
  time_this_iter_s: 26.618385553359985
  time_total_s: 507.3137490749359
  timers:
    learn_throughput: 8273.08
    learn_time_ms: 19556.442
    sample_throughput: 23896.679
    sample_time_ms: 6770.481
    update_time_ms: 26.992
  timestamp: 1602525151
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 7fe9e_00000
  
== Status ==
Memory usage on this node: 28.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.37 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7fe9e_00000 | RUNNING  | 172.17.0.4:60752 |     19 |          507.314 | 3074048 |  258.653 |              300.222 |              165.677 |            818.138 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7fe9e_00000:
  custom_metrics:
    time_step_max: 3937
    time_step_mean: 3325.5270582200565
    time_step_min: 3058
  date: 2020-10-12_17-52-57
  done: false
  episode_len_mean: 815.7147950089127
  episode_reward_max: 300.2222222222221
  episode_reward_mean: 259.36205446365864
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 288
  episodes_total: 3927
  experiment_id: 86b3342f9eeb46c9a6fb2ff43c27e2e3
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8442142953475317
        entropy_coeff: 0.009999999999999998
        kl: 0.00718651603286465
        model: {}
        policy_loss: -0.013559733207027117
        total_loss: 13.628875255584717
        vf_explained_var: 0.9791759848594666
        vf_loss: 13.649439970652262
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.259999999999994
    gpu_util_percent0: 0.298
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.840000000000001
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60752
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15130530717452234
    mean_env_wait_ms: 1.1807591172642447
    mean_inference_ms: 4.585003090295597
    mean_raw_obs_processing_ms: 0.3958053589794689
  time_since_restore: 533.8012187480927
  time_this_iter_s: 26.48746967315674
  time_total_s: 533.8012187480927
  timers:
    learn_throughput: 8265.887
    learn_time_ms: 19573.458
    sample_throughput: 23872.417
    sample_time_ms: 6777.362
    update_time_ms: 29.082
  timestamp: 1602525177
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 7fe9e_00000
  
== Status ==
Memory usage on this node: 28.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.37 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7fe9e_00000 | RUNNING  | 172.17.0.4:60752 |     20 |          533.801 | 3235840 |  259.362 |              300.222 |              165.677 |            815.715 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7fe9e_00000:
  custom_metrics:
    time_step_max: 3937
    time_step_mean: 3322.2073529411764
    time_step_min: 3058
  date: 2020-10-12_17-53-24
  done: false
  episode_len_mean: 814.1764849074975
  episode_reward_max: 300.2222222222221
  episode_reward_mean: 259.8255461135207
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 181
  episodes_total: 4108
  experiment_id: 86b3342f9eeb46c9a6fb2ff43c27e2e3
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8439555168151855
        entropy_coeff: 0.009999999999999998
        kl: 0.007454316946677864
        model: {}
        policy_loss: -0.012060137484998753
        total_loss: 10.92050806681315
        vf_explained_var: 0.9774009585380554
        vf_loss: 10.939516941706339
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.703225806451613
    gpu_util_percent0: 0.3212903225806451
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.854838709677421
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60752
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15115398661480883
    mean_env_wait_ms: 1.1817062422823035
    mean_inference_ms: 4.5747927209064105
    mean_raw_obs_processing_ms: 0.3952367281248191
  time_since_restore: 560.206463098526
  time_this_iter_s: 26.40524435043335
  time_total_s: 560.206463098526
  timers:
    learn_throughput: 8269.144
    learn_time_ms: 19565.748
    sample_throughput: 23858.067
    sample_time_ms: 6781.438
    update_time_ms: 28.409
  timestamp: 1602525204
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: 7fe9e_00000
  
== Status ==
Memory usage on this node: 28.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.37 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7fe9e_00000 | RUNNING  | 172.17.0.4:60752 |     21 |          560.206 | 3397632 |  259.826 |              300.222 |              165.677 |            814.176 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7fe9e_00000:
  custom_metrics:
    time_step_max: 3937
    time_step_mean: 3319.936305732484
    time_step_min: 3058
  date: 2020-10-12_17-53-50
  done: false
  episode_len_mean: 812.9303960628076
  episode_reward_max: 300.2222222222221
  episode_reward_mean: 260.2164698307186
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 159
  episodes_total: 4267
  experiment_id: 86b3342f9eeb46c9a6fb2ff43c27e2e3
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8358242362737656
        entropy_coeff: 0.009999999999999998
        kl: 0.008619646619384488
        model: {}
        policy_loss: -0.014051563426619396
        total_loss: 7.796376387278239
        vf_explained_var: 0.9824905395507812
        vf_loss: 7.8170621792475385
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.686666666666667
    gpu_util_percent0: 0.3466666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8633333333333346
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60752
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15102555298809878
    mean_env_wait_ms: 1.1825114373621954
    mean_inference_ms: 4.56634186533611
    mean_raw_obs_processing_ms: 0.39475274640182445
  time_since_restore: 586.6267325878143
  time_this_iter_s: 26.42026948928833
  time_total_s: 586.6267325878143
  timers:
    learn_throughput: 8277.909
    learn_time_ms: 19545.032
    sample_throughput: 23839.265
    sample_time_ms: 6786.786
    update_time_ms: 28.72
  timestamp: 1602525230
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: 7fe9e_00000
  
== Status ==
Memory usage on this node: 28.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.37 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7fe9e_00000 | RUNNING  | 172.17.0.4:60752 |     22 |          586.627 | 3559424 |  260.216 |              300.222 |              165.677 |             812.93 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7fe9e_00000:
  custom_metrics:
    time_step_max: 3937
    time_step_mean: 3316.5188637372394
    time_step_min: 3058
  date: 2020-10-12_17-54-17
  done: true
  episode_len_mean: 810.9424349360388
  episode_reward_max: 300.2222222222221
  episode_reward_mean: 260.75760471944847
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 267
  episodes_total: 4534
  experiment_id: 86b3342f9eeb46c9a6fb2ff43c27e2e3
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8029479632774988
        entropy_coeff: 0.009999999999999998
        kl: 0.007437431641543905
        model: {}
        policy_loss: -0.01123986296200504
        total_loss: 12.67585309346517
        vf_explained_var: 0.9800798892974854
        vf_loss: 12.693634748458862
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.535483870967738
    gpu_util_percent0: 0.3629032258064516
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.854838709677421
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60752
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15082237771127155
    mean_env_wait_ms: 1.1838749830977424
    mean_inference_ms: 4.553177637173223
    mean_raw_obs_processing_ms: 0.3939961272391806
  time_since_restore: 612.981406211853
  time_this_iter_s: 26.354673624038696
  time_total_s: 612.981406211853
  timers:
    learn_throughput: 8272.269
    learn_time_ms: 19558.359
    sample_throughput: 23882.302
    sample_time_ms: 6774.556
    update_time_ms: 29.86
  timestamp: 1602525257
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: 7fe9e_00000
  
== Status ==
Memory usage on this node: 28.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.37 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7fe9e_00000 | TERMINATED |       |     23 |          612.981 | 3721216 |  260.758 |              300.222 |              165.677 |            810.942 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.37 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7fe9e_00000 | TERMINATED |       |     23 |          612.981 | 3721216 |  260.758 |              300.222 |              165.677 |            810.942 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


