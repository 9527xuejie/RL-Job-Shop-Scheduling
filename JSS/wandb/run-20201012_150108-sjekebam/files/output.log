2020-10-12 15:01:11,975	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_c52d2_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=10782)[0m 2020-10-12 15:01:14,757	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=10766)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10766)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10771)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10771)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10757)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10757)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10804)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10804)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10786)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10786)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10676)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10676)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10677)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10677)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10672)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10672)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10756)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10756)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10752)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10752)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10685)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10685)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10696)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10696)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10792)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10792)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10788)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10788)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10755)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10755)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10777)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10777)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10779)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10779)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10798)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10798)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10773)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10773)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10794)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10794)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10808)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10808)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10780)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10780)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10776)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10776)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10801)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10801)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10728)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10728)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10789)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10789)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10746)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10746)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10733)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10733)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10684)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10684)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10769)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10769)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10682)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10682)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10753)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10753)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10692)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10692)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10754)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10754)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10673)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10673)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10695)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10695)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10748)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10748)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10668)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10668)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10785)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10785)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10683)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10683)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10678)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10678)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10767)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10767)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10689)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10689)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10701)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10701)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10725)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10725)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10734)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10734)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10730)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10730)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10671)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10671)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10699)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10699)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10745)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10745)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10679)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10679)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10686)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10686)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10743)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10743)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10747)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10747)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10784)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10784)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10702)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10702)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10694)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10694)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10764)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10764)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10687)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10687)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10741)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10741)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10738)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10738)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10742)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10742)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10778)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10778)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10739)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10739)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10681)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10681)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10763)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10763)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10669)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10669)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10731)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10731)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10790)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10790)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10740)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10740)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10688)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10688)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10707)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10707)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10675)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10675)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10670)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10670)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10698)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10698)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10744)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10744)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10749)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10749)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10750)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10750)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10703)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10703)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_c52d2_00000:
  custom_metrics:
    time_step_max: 3941
    time_step_mean: 3510.563025210084
    time_step_min: 3241
  date: 2020-10-12_15-01-48
  done: false
  episode_len_mean: 895.2911392405064
  episode_reward_max: 255.28282828282772
  episode_reward_mean: 213.63438179260947
  episode_reward_min: 147.70707070707059
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 278703f5a76a413d80112154e6e1c72f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1733678877353668
        entropy_coeff: 0.0005000000000000001
        kl: 0.004998006935541828
        model: {}
        policy_loss: -0.00916472086282738
        total_loss: 415.6246159871419
        vf_explained_var: 0.5660186409950256
        vf_loss: 415.63336181640625
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.74242424242424
    gpu_util_percent0: 0.2463636363636364
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5727272727272728
    vram_util_percent0: 0.08750757824224535
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 10782
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1663994531493085
    mean_env_wait_ms: 1.163995880593338
    mean_inference_ms: 5.136890585093485
    mean_raw_obs_processing_ms: 0.43364785416106383
  time_since_restore: 28.24773406982422
  time_this_iter_s: 28.24773406982422
  time_total_s: 28.24773406982422
  timers:
    learn_throughput: 8117.471
    learn_time_ms: 19931.33
    sample_throughput: 19646.095
    sample_time_ms: 8235.326
    update_time_ms: 48.368
  timestamp: 1602514908
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: c52d2_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c52d2_00000 | RUNNING  | 172.17.0.4:10782 |      1 |          28.2477 | 161792 |  213.634 |              255.283 |              147.707 |            895.291 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c52d2_00000:
  custom_metrics:
    time_step_max: 4000
    time_step_mean: 3516.126353790614
    time_step_min: 3207
  date: 2020-10-12_15-02-15
  done: false
  episode_len_mean: 894.6867088607595
  episode_reward_max: 258.9191919191918
  episode_reward_mean: 212.48123641478057
  episode_reward_min: 138.7676767676767
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 278703f5a76a413d80112154e6e1c72f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1481354931990306
        entropy_coeff: 0.0005000000000000001
        kl: 0.007063919988771279
        model: {}
        policy_loss: -0.010035032425851872
        total_loss: 99.03858502705891
        vf_explained_var: 0.832775890827179
        vf_loss: 99.04848734537761
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.09375
    gpu_util_percent0: 0.26
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.753125
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 10782
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16306230405235267
    mean_env_wait_ms: 1.1641208216835026
    mean_inference_ms: 5.0647776437704035
    mean_raw_obs_processing_ms: 0.42720688739691076
  time_since_restore: 55.43538427352905
  time_this_iter_s: 27.187650203704834
  time_total_s: 55.43538427352905
  timers:
    learn_throughput: 8220.386
    learn_time_ms: 19681.8
    sample_throughput: 20346.059
    sample_time_ms: 7952.007
    update_time_ms: 43.244
  timestamp: 1602514935
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: c52d2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c52d2_00000 | RUNNING  | 172.17.0.4:10782 |      2 |          55.4354 | 323584 |  212.481 |              258.919 |              138.768 |            894.687 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c52d2_00000:
  custom_metrics:
    time_step_max: 4000
    time_step_mean: 3508.733333333333
    time_step_min: 3207
  date: 2020-10-12_15-02-42
  done: false
  episode_len_mean: 886.3544303797469
  episode_reward_max: 258.9191919191918
  episode_reward_mean: 212.8691343817925
  episode_reward_min: 138.7676767676767
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 278703f5a76a413d80112154e6e1c72f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1320596237977345
        entropy_coeff: 0.0005000000000000001
        kl: 0.009627530816942453
        model: {}
        policy_loss: -0.011608108102033535
        total_loss: 40.9521697362264
        vf_explained_var: 0.9179801344871521
        vf_loss: 40.96338144938151
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.91612903225807
    gpu_util_percent0: 0.32903225806451614
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322573
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 10782
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16061269873669995
    mean_env_wait_ms: 1.1658873032891233
    mean_inference_ms: 4.969580731400424
    mean_raw_obs_processing_ms: 0.4212340241954109
  time_since_restore: 82.25170969963074
  time_this_iter_s: 26.816325426101685
  time_total_s: 82.25170969963074
  timers:
    learn_throughput: 8244.204
    learn_time_ms: 19624.939
    sample_throughput: 21001.419
    sample_time_ms: 7703.86
    update_time_ms: 43.972
  timestamp: 1602514962
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: c52d2_00000
  
== Status ==
Memory usage on this node: 28.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c52d2_00000 | RUNNING  | 172.17.0.4:10782 |      3 |          82.2517 | 485376 |  212.869 |              258.919 |              138.768 |            886.354 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c52d2_00000:
  custom_metrics:
    time_step_max: 4000
    time_step_mean: 3507.1973018549747
    time_step_min: 3207
  date: 2020-10-12_15-03-09
  done: false
  episode_len_mean: 878.8560126582279
  episode_reward_max: 258.9191919191918
  episode_reward_mean: 213.623593530239
  episode_reward_min: 138.7676767676767
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 278703f5a76a413d80112154e6e1c72f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1127084891001384
        entropy_coeff: 0.0005000000000000001
        kl: 0.007927578369465968
        model: {}
        policy_loss: -0.01219729493216922
        total_loss: 31.16670513153076
        vf_explained_var: 0.9360077381134033
        vf_loss: 31.17866579691569
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.26129032258065
    gpu_util_percent0: 0.31516129032258067
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7677419354838704
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 10782
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15879614714809914
    mean_env_wait_ms: 1.168510158899108
    mean_inference_ms: 4.890456013610907
    mean_raw_obs_processing_ms: 0.4162167117018698
  time_since_restore: 108.7154483795166
  time_this_iter_s: 26.463738679885864
  time_total_s: 108.7154483795166
  timers:
    learn_throughput: 8266.561
    learn_time_ms: 19571.863
    sample_throughput: 21514.301
    sample_time_ms: 7520.207
    update_time_ms: 41.916
  timestamp: 1602514989
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: c52d2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c52d2_00000 | RUNNING  | 172.17.0.4:10782 |      4 |          108.715 | 647168 |  213.624 |              258.919 |              138.768 |            878.856 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c52d2_00000:
  custom_metrics:
    time_step_max: 4000
    time_step_mean: 3500.901464713715
    time_step_min: 3207
  date: 2020-10-12_15-03-35
  done: false
  episode_len_mean: 871.9417721518987
  episode_reward_max: 258.9191919191918
  episode_reward_mean: 214.66871244086423
  episode_reward_min: 138.7676767676767
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 278703f5a76a413d80112154e6e1c72f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0736438035964966
        entropy_coeff: 0.0005000000000000001
        kl: 0.008050509185219804
        model: {}
        policy_loss: -0.011381465864057342
        total_loss: 25.45706097284953
        vf_explained_var: 0.9563339352607727
        vf_loss: 25.468174775441486
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.358064516129037
    gpu_util_percent0: 0.35258064516129034
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322577
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 10782
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15741014805311154
    mean_env_wait_ms: 1.1717018485048676
    mean_inference_ms: 4.827768250690935
    mean_raw_obs_processing_ms: 0.41208779363506276
  time_since_restore: 135.2645034790039
  time_this_iter_s: 26.549055099487305
  time_total_s: 135.2645034790039
  timers:
    learn_throughput: 8277.51
    learn_time_ms: 19545.975
    sample_throughput: 21802.553
    sample_time_ms: 7420.782
    update_time_ms: 41.37
  timestamp: 1602515015
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: c52d2_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c52d2_00000 | RUNNING  | 172.17.0.4:10782 |      5 |          135.265 | 808960 |  214.669 |              258.919 |              138.768 |            871.942 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c52d2_00000:
  custom_metrics:
    time_step_max: 4000
    time_step_mean: 3485.6166822867854
    time_step_min: 3203
  date: 2020-10-12_15-04-02
  done: false
  episode_len_mean: 861.7206148282098
  episode_reward_max: 259.5252525252525
  episode_reward_mean: 216.85017443878195
  episode_reward_min: 138.7676767676767
  episodes_this_iter: 316
  episodes_total: 1106
  experiment_id: 278703f5a76a413d80112154e6e1c72f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0657447179158528
        entropy_coeff: 0.0005000000000000001
        kl: 0.008472384458097318
        model: {}
        policy_loss: -0.011950941659354916
        total_loss: 27.248703002929688
        vf_explained_var: 0.9630305171012878
        vf_loss: 27.260340054829914
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.329032258064522
    gpu_util_percent0: 0.28516129032258064
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.770967741935483
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 10782
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15550148974120434
    mean_env_wait_ms: 1.176718841302797
    mean_inference_ms: 4.740526402525625
    mean_raw_obs_processing_ms: 0.40673619170889713
  time_since_restore: 161.7237193584442
  time_this_iter_s: 26.459215879440308
  time_total_s: 161.7237193584442
  timers:
    learn_throughput: 8288.635
    learn_time_ms: 19519.739
    sample_throughput: 22021.651
    sample_time_ms: 7346.952
    update_time_ms: 41.615
  timestamp: 1602515042
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: c52d2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c52d2_00000 | RUNNING  | 172.17.0.4:10782 |      6 |          161.724 | 970752 |   216.85 |              259.525 |              138.768 |            861.721 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c52d2_00000:
  custom_metrics:
    time_step_max: 4000
    time_step_mean: 3476.8171428571427
    time_step_min: 3167
  date: 2020-10-12_15-04-28
  done: false
  episode_len_mean: 857.3180379746835
  episode_reward_max: 265.7373737373735
  episode_reward_mean: 218.20381025444308
  episode_reward_min: 138.7676767676767
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: 278703f5a76a413d80112154e6e1c72f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0459044277668
        entropy_coeff: 0.0005000000000000001
        kl: 0.008025348264103135
        model: {}
        policy_loss: -0.012926413328386843
        total_loss: 15.976893107096354
        vf_explained_var: 0.9690950512886047
        vf_loss: 15.989539941151937
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.71612903225807
    gpu_util_percent0: 0.38870967741935475
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7806451612903222
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 10782
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1548211951439317
    mean_env_wait_ms: 1.1786746000292136
    mean_inference_ms: 4.708676979268536
    mean_raw_obs_processing_ms: 0.4048014708325516
  time_since_restore: 188.32198691368103
  time_this_iter_s: 26.598267555236816
  time_total_s: 188.32198691368103
  timers:
    learn_throughput: 8292.563
    learn_time_ms: 19510.494
    sample_throughput: 22152.93
    sample_time_ms: 7303.413
    update_time_ms: 41.641
  timestamp: 1602515068
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: c52d2_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c52d2_00000 | RUNNING  | 172.17.0.4:10782 |      7 |          188.322 | 1132544 |  218.204 |              265.737 |              138.768 |            857.318 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c52d2_00000:
  custom_metrics:
    time_step_max: 4000
    time_step_mean: 3467.940708604483
    time_step_min: 3167
  date: 2020-10-12_15-04-55
  done: false
  episode_len_mean: 854.1075949367089
  episode_reward_max: 265.7373737373735
  episode_reward_mean: 219.32312577249283
  episode_reward_min: 138.7676767676767
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 278703f5a76a413d80112154e6e1c72f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0292503933111827
        entropy_coeff: 0.0005000000000000001
        kl: 0.007071365291873614
        model: {}
        policy_loss: -0.011622646396669248
        total_loss: 13.951191822687784
        vf_explained_var: 0.9717023372650146
        vf_loss: 13.962621847788492
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.24516129032259
    gpu_util_percent0: 0.32129032258064505
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 10782
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1542318956442207
    mean_env_wait_ms: 1.1802891391168226
    mean_inference_ms: 4.680771648823181
    mean_raw_obs_processing_ms: 0.4030570951500994
  time_since_restore: 214.8034861087799
  time_this_iter_s: 26.481499195098877
  time_total_s: 214.8034861087799
  timers:
    learn_throughput: 8298.834
    learn_time_ms: 19495.75
    sample_throughput: 22269.036
    sample_time_ms: 7265.335
    update_time_ms: 41.695
  timestamp: 1602515095
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: c52d2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c52d2_00000 | RUNNING  | 172.17.0.4:10782 |      8 |          214.803 | 1294336 |  219.323 |              265.737 |              138.768 |            854.108 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c52d2_00000:
  custom_metrics:
    time_step_max: 4000
    time_step_mean: 3458.6658014276445
    time_step_min: 3148
  date: 2020-10-12_15-05-22
  done: false
  episode_len_mean: 850.2822784810127
  episode_reward_max: 267.8585858585858
  episode_reward_mean: 220.54769211098318
  episode_reward_min: 138.7676767676767
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 278703f5a76a413d80112154e6e1c72f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9820772459109625
        entropy_coeff: 0.0005000000000000001
        kl: 0.007025937355744342
        model: {}
        policy_loss: -0.011879481782671064
        total_loss: 16.12793469429016
        vf_explained_var: 0.9705111384391785
        vf_loss: 16.139602581659954
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.737499999999997
    gpu_util_percent0: 0.37093750000000003
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7625
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 10782
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15371688424398572
    mean_env_wait_ms: 1.181972392784228
    mean_inference_ms: 4.656120408140079
    mean_raw_obs_processing_ms: 0.40147316535721955
  time_since_restore: 241.598552942276
  time_this_iter_s: 26.795066833496094
  time_total_s: 241.598552942276
  timers:
    learn_throughput: 8289.309
    learn_time_ms: 19518.153
    sample_throughput: 22358.439
    sample_time_ms: 7236.283
    update_time_ms: 39.957
  timestamp: 1602515122
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: c52d2_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c52d2_00000 | RUNNING  | 172.17.0.4:10782 |      9 |          241.599 | 1456128 |  220.548 |              267.859 |              138.768 |            850.282 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c52d2_00000:
  custom_metrics:
    time_step_max: 4000
    time_step_mean: 3443.0635433494886
    time_step_min: 3108
  date: 2020-10-12_15-05-49
  done: false
  episode_len_mean: 842.329641350211
  episode_reward_max: 273.9191919191924
  episode_reward_mean: 223.18886651323356
  episode_reward_min: 138.7676767676767
  episodes_this_iter: 316
  episodes_total: 1896
  experiment_id: 278703f5a76a413d80112154e6e1c72f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9527567028999329
        entropy_coeff: 0.0005000000000000001
        kl: 0.0066283421668534475
        model: {}
        policy_loss: -0.010255232860799879
        total_loss: 16.848692893981934
        vf_explained_var: 0.9762053489685059
        vf_loss: 16.85876162846883
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.125806451612902
    gpu_util_percent0: 0.3467741935483871
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.770967741935483
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 10782
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15287973378664363
    mean_env_wait_ms: 1.1853585852731747
    mean_inference_ms: 4.615763303312499
    mean_raw_obs_processing_ms: 0.3990078489408098
  time_since_restore: 268.2208135128021
  time_this_iter_s: 26.622260570526123
  time_total_s: 268.2208135128021
  timers:
    learn_throughput: 8286.42
    learn_time_ms: 19524.957
    sample_throughput: 22448.185
    sample_time_ms: 7207.353
    update_time_ms: 39.773
  timestamp: 1602515149
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: c52d2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c52d2_00000 | RUNNING  | 172.17.0.4:10782 |     10 |          268.221 | 1617920 |  223.189 |              273.919 |              138.768 |             842.33 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c52d2_00000:
  custom_metrics:
    time_step_max: 4000
    time_step_mean: 3436.9563275434243
    time_step_min: 3108
  date: 2020-10-12_15-06-15
  done: false
  episode_len_mean: 838.5628042843233
  episode_reward_max: 273.9191919191924
  episode_reward_mean: 224.2034856844983
  episode_reward_min: 138.7676767676767
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: 278703f5a76a413d80112154e6e1c72f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9340264697869619
        entropy_coeff: 0.0005000000000000001
        kl: 0.006637935526669025
        model: {}
        policy_loss: -0.010802200093166903
        total_loss: 11.707856257756552
        vf_explained_var: 0.9762506484985352
        vf_loss: 11.718461910883585
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.1
    gpu_util_percent0: 0.3022580645161291
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7806451612903222
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 10782
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15253429852504466
    mean_env_wait_ms: 1.186851260215755
    mean_inference_ms: 4.599122919244033
    mean_raw_obs_processing_ms: 0.397983620124492
  time_since_restore: 294.8870041370392
  time_this_iter_s: 26.66619062423706
  time_total_s: 294.8870041370392
  timers:
    learn_throughput: 8299.808
    learn_time_ms: 19493.463
    sample_throughput: 22853.422
    sample_time_ms: 7079.552
    update_time_ms: 38.882
  timestamp: 1602515175
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: c52d2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c52d2_00000 | RUNNING  | 172.17.0.4:10782 |     11 |          294.887 | 1779712 |  224.203 |              273.919 |              138.768 |            838.563 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c52d2_00000:
  custom_metrics:
    time_step_max: 4000
    time_step_mean: 3429.441785549931
    time_step_min: 3108
  date: 2020-10-12_15-06-42
  done: false
  episode_len_mean: 835.3019891500904
  episode_reward_max: 283.9191919191916
  episode_reward_mean: 225.35105119915244
  episode_reward_min: 138.7676767676767
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 278703f5a76a413d80112154e6e1c72f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9185261279344559
        entropy_coeff: 0.0005000000000000001
        kl: 0.006282192383271952
        model: {}
        policy_loss: -0.010594809878966771
        total_loss: 11.78148102760315
        vf_explained_var: 0.9733021855354309
        vf_loss: 11.791906754175821
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.122580645161293
    gpu_util_percent0: 0.31741935483870976
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7774193548387096
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 10782
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15222395561913488
    mean_env_wait_ms: 1.1882813265215038
    mean_inference_ms: 4.583989971264347
    mean_raw_obs_processing_ms: 0.3970190279577171
  time_since_restore: 321.51186084747314
  time_this_iter_s: 26.62485671043396
  time_total_s: 321.51186084747314
  timers:
    learn_throughput: 8296.603
    learn_time_ms: 19500.994
    sample_throughput: 23063.757
    sample_time_ms: 7014.989
    update_time_ms: 38.863
  timestamp: 1602515202
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: c52d2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c52d2_00000 | RUNNING  | 172.17.0.4:10782 |     12 |          321.512 | 1941504 |  225.351 |              283.919 |              138.768 |            835.302 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c52d2_00000:
  custom_metrics:
    time_step_max: 4000
    time_step_mean: 3416.010212418301
    time_step_min: 3107
  date: 2020-10-12_15-07-09
  done: false
  episode_len_mean: 830.3470044229996
  episode_reward_max: 283.9191919191916
  episode_reward_mean: 227.07201081989982
  episode_reward_min: 138.7676767676767
  episodes_this_iter: 275
  episodes_total: 2487
  experiment_id: 278703f5a76a413d80112154e6e1c72f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8739954978227615
        entropy_coeff: 0.0005000000000000001
        kl: 0.006836044291655223
        model: {}
        policy_loss: -0.011842325504403561
        total_loss: 15.203980127970377
        vf_explained_var: 0.9774308800697327
        vf_loss: 15.215575774510702
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.55806451612903
    gpu_util_percent0: 0.3251612903225806
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7677419354838704
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 10782
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15175092072124807
    mean_env_wait_ms: 1.190889417605735
    mean_inference_ms: 4.560796638997515
    mean_raw_obs_processing_ms: 0.3955937873233322
  time_since_restore: 348.19422459602356
  time_this_iter_s: 26.682363748550415
  time_total_s: 348.19422459602356
  timers:
    learn_throughput: 8287.373
    learn_time_ms: 19522.712
    sample_throughput: 23185.029
    sample_time_ms: 6978.296
    update_time_ms: 38.503
  timestamp: 1602515229
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: c52d2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c52d2_00000 | RUNNING  | 172.17.0.4:10782 |     13 |          348.194 | 2103296 |  227.072 |              283.919 |              138.768 |            830.347 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c52d2_00000:
  custom_metrics:
    time_step_max: 4000
    time_step_mean: 3407.6898375519454
    time_step_min: 3107
  date: 2020-10-12_15-07-36
  done: false
  episode_len_mean: 827.4717051377513
  episode_reward_max: 283.9191919191916
  episode_reward_mean: 228.25514264010167
  episode_reward_min: 138.7676767676767
  episodes_this_iter: 199
  episodes_total: 2686
  experiment_id: 278703f5a76a413d80112154e6e1c72f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8569933970769247
        entropy_coeff: 0.0005000000000000001
        kl: 0.006308569146009783
        model: {}
        policy_loss: -0.010416376687013932
        total_loss: 10.241653362909952
        vf_explained_var: 0.979211151599884
        vf_loss: 10.251867532730103
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.651612903225804
    gpu_util_percent0: 0.3125806451612903
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.783870967741935
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 10782
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15146266213053308
    mean_env_wait_ms: 1.192463815613075
    mean_inference_ms: 4.546547796853665
    mean_raw_obs_processing_ms: 0.39472310717565473
  time_since_restore: 374.9624752998352
  time_this_iter_s: 26.768250703811646
  time_total_s: 374.9624752998352
  timers:
    learn_throughput: 8268.927
    learn_time_ms: 19566.262
    sample_throughput: 23233.498
    sample_time_ms: 6963.738
    update_time_ms: 38.566
  timestamp: 1602515256
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: c52d2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c52d2_00000 | RUNNING  | 172.17.0.4:10782 |     14 |          374.962 | 2265088 |  228.255 |              283.919 |              138.768 |            827.472 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c52d2_00000:
  custom_metrics:
    time_step_max: 4000
    time_step_mean: 3403.4976827094474
    time_step_min: 3107
  date: 2020-10-12_15-08-02
  done: false
  episode_len_mean: 825.5502812939521
  episode_reward_max: 283.9191919191916
  episode_reward_mean: 228.9589353450113
  episode_reward_min: 138.7676767676767
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: 278703f5a76a413d80112154e6e1c72f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.849844848116239
        entropy_coeff: 0.0005000000000000001
        kl: 0.006415587888720135
        model: {}
        policy_loss: -0.01132429470696176
        total_loss: 10.057613849639893
        vf_explained_var: 0.9778110980987549
        vf_loss: 10.068721373875936
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.37741935483871
    gpu_util_percent0: 0.26999999999999996
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7741935483870965
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 10782
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.151251694931873
    mean_env_wait_ms: 1.1936603529133836
    mean_inference_ms: 4.536136144488529
    mean_raw_obs_processing_ms: 0.3940777293691623
  time_since_restore: 401.59893560409546
  time_this_iter_s: 26.636460304260254
  time_total_s: 401.59893560409546
  timers:
    learn_throughput: 8263.577
    learn_time_ms: 19578.93
    sample_throughput: 23251.36
    sample_time_ms: 6958.389
    update_time_ms: 38.798
  timestamp: 1602515282
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: c52d2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c52d2_00000 | RUNNING  | 172.17.0.4:10782 |     15 |          401.599 | 2426880 |  228.959 |              283.919 |              138.768 |             825.55 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c52d2_00000:
  custom_metrics:
    time_step_max: 4000
    time_step_mean: 3397.2335669002337
    time_step_min: 3107
  date: 2020-10-12_15-08-29
  done: false
  episode_len_mean: 823.1696310935441
  episode_reward_max: 283.9191919191916
  episode_reward_mean: 229.98873118537148
  episode_reward_min: 138.7676767676767
  episodes_this_iter: 192
  episodes_total: 3036
  experiment_id: 278703f5a76a413d80112154e6e1c72f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8184456924597422
        entropy_coeff: 0.0005000000000000001
        kl: 0.006053957312057416
        model: {}
        policy_loss: -0.00969617662485689
        total_loss: 11.97330617904663
        vf_explained_var: 0.977895200252533
        vf_loss: 11.982805728912354
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.816129032258065
    gpu_util_percent0: 0.24741935483870967
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 10782
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15101548953459396
    mean_env_wait_ms: 1.1950955533701821
    mean_inference_ms: 4.5243540035232686
    mean_raw_obs_processing_ms: 0.39333615639034913
  time_since_restore: 428.2090075016022
  time_this_iter_s: 26.610071897506714
  time_total_s: 428.2090075016022
  timers:
    learn_throughput: 8258.937
    learn_time_ms: 19589.93
    sample_throughput: 23240.436
    sample_time_ms: 6961.659
    update_time_ms: 38.382
  timestamp: 1602515309
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: c52d2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c52d2_00000 | RUNNING  | 172.17.0.4:10782 |     16 |          428.209 | 2588672 |  229.989 |              283.919 |              138.768 |             823.17 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c52d2_00000:
  custom_metrics:
    time_step_max: 4000
    time_step_mean: 3386.8481244281793
    time_step_min: 3103
  date: 2020-10-12_15-08-56
  done: false
  episode_len_mean: 820.1711874623267
  episode_reward_max: 283.9191919191916
  episode_reward_mean: 231.59162145871008
  episode_reward_min: 138.7676767676767
  episodes_this_iter: 282
  episodes_total: 3318
  experiment_id: 278703f5a76a413d80112154e6e1c72f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7818726052840551
        entropy_coeff: 0.0005000000000000001
        kl: 0.006080446105139951
        model: {}
        policy_loss: -0.010272806757711805
        total_loss: 11.227606932322184
        vf_explained_var: 0.981134831905365
        vf_loss: 11.237662474314371
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.058064516129033
    gpu_util_percent0: 0.4390322580645161
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7677419354838704
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 10782
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15070610708037377
    mean_env_wait_ms: 1.196983280559447
    mean_inference_ms: 4.509309882051034
    mean_raw_obs_processing_ms: 0.3923966135013807
  time_since_restore: 454.9691250324249
  time_this_iter_s: 26.760117530822754
  time_total_s: 454.9691250324249
  timers:
    learn_throughput: 8256.963
    learn_time_ms: 19594.614
    sample_throughput: 23202.545
    sample_time_ms: 6973.028
    update_time_ms: 38.479
  timestamp: 1602515336
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: c52d2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c52d2_00000 | RUNNING  | 172.17.0.4:10782 |     17 |          454.969 | 2750464 |  231.592 |              283.919 |              138.768 |            820.171 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c52d2_00000:
  custom_metrics:
    time_step_max: 4000
    time_step_mean: 3381.3046261274367
    time_step_min: 3094
  date: 2020-10-12_15-09-23
  done: false
  episode_len_mean: 818.4976985040277
  episode_reward_max: 283.9191919191916
  episode_reward_mean: 232.3974584742709
  episode_reward_min: 138.7676767676767
  episodes_this_iter: 158
  episodes_total: 3476
  experiment_id: 278703f5a76a413d80112154e6e1c72f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7945885012547175
        entropy_coeff: 0.0005000000000000001
        kl: 0.006646261123629908
        model: {}
        policy_loss: -0.008898436247060696
        total_loss: 9.387492338816324
        vf_explained_var: 0.978131115436554
        vf_loss: 9.396123170852661
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.775
    gpu_util_percent0: 0.334375
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.778125
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 10782
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15054884191545131
    mean_env_wait_ms: 1.1979370710333144
    mean_inference_ms: 4.501628573176973
    mean_raw_obs_processing_ms: 0.39190882495732454
  time_since_restore: 481.6522297859192
  time_this_iter_s: 26.683104753494263
  time_total_s: 481.6522297859192
  timers:
    learn_throughput: 8248.681
    learn_time_ms: 19614.287
    sample_throughput: 23204.642
    sample_time_ms: 6972.398
    update_time_ms: 38.432
  timestamp: 1602515363
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: c52d2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c52d2_00000 | RUNNING  | 172.17.0.4:10782 |     18 |          481.652 | 2912256 |  232.397 |              283.919 |              138.768 |            818.498 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c52d2_00000:
  custom_metrics:
    time_step_max: 4000
    time_step_mean: 3375.6286111111112
    time_step_min: 3094
  date: 2020-10-12_15-09-50
  done: false
  episode_len_mean: 816.8419895575707
  episode_reward_max: 283.9191919191916
  episode_reward_mean: 233.2244039737857
  episode_reward_min: 138.7676767676767
  episodes_this_iter: 163
  episodes_total: 3639
  experiment_id: 278703f5a76a413d80112154e6e1c72f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7640985002120336
        entropy_coeff: 0.0005000000000000001
        kl: 0.005924703553318977
        model: {}
        policy_loss: -0.01154794641964448
        total_loss: 9.984641949335733
        vf_explained_var: 0.9783595204353333
        vf_loss: 9.995979229609171
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.63225806451613
    gpu_util_percent0: 0.30096774193548387
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 10782
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15039586512202635
    mean_env_wait_ms: 1.1989127777278936
    mean_inference_ms: 4.49413990783475
    mean_raw_obs_processing_ms: 0.3914308825412922
  time_since_restore: 508.3049101829529
  time_this_iter_s: 26.65268039703369
  time_total_s: 508.3049101829529
  timers:
    learn_throughput: 8249.937
    learn_time_ms: 19611.302
    sample_throughput: 23243.92
    sample_time_ms: 6960.616
    update_time_ms: 39.75
  timestamp: 1602515390
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: c52d2_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c52d2_00000 | RUNNING  | 172.17.0.4:10782 |     19 |          508.305 | 3074048 |  233.224 |              283.919 |              138.768 |            816.842 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c52d2_00000:
  custom_metrics:
    time_step_max: 4000
    time_step_mean: 3366.6026100307063
    time_step_min: 3068
  date: 2020-10-12_15-10-16
  done: false
  episode_len_mean: 814.0339498353179
  episode_reward_max: 286.1919191919192
  episode_reward_mean: 234.70736245147194
  episode_reward_min: 138.7676767676767
  episodes_this_iter: 308
  episodes_total: 3947
  experiment_id: 278703f5a76a413d80112154e6e1c72f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7212709039449692
        entropy_coeff: 0.0005000000000000001
        kl: 0.005585941020399332
        model: {}
        policy_loss: -0.009148939342897696
        total_loss: 11.774536848068237
        vf_explained_var: 0.9819743633270264
        vf_loss: 11.783488035202026
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.89354838709678
    gpu_util_percent0: 0.36
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7677419354838704
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 10782
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15013818086967534
    mean_env_wait_ms: 1.2006187486346673
    mean_inference_ms: 4.481473689832602
    mean_raw_obs_processing_ms: 0.39062112293101947
  time_since_restore: 534.9549059867859
  time_this_iter_s: 26.649995803833008
  time_total_s: 534.9549059867859
  timers:
    learn_throughput: 8260.203
    learn_time_ms: 19586.929
    sample_throughput: 23151.637
    sample_time_ms: 6988.361
    update_time_ms: 37.883
  timestamp: 1602515416
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: c52d2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c52d2_00000 | RUNNING  | 172.17.0.4:10782 |     20 |          534.955 | 3235840 |  234.707 |              286.192 |              138.768 |            814.034 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c52d2_00000:
  custom_metrics:
    time_step_max: 4000
    time_step_mean: 3361.2777095109363
    time_step_min: 3068
  date: 2020-10-12_15-10-43
  done: false
  episode_len_mean: 812.6032132424538
  episode_reward_max: 286.1919191919192
  episode_reward_mean: 235.5290219625663
  episode_reward_min: 138.7676767676767
  episodes_this_iter: 161
  episodes_total: 4108
  experiment_id: 278703f5a76a413d80112154e6e1c72f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7334958960612615
        entropy_coeff: 0.0005000000000000001
        kl: 0.00623501290101558
        model: {}
        policy_loss: -0.012696098769083619
        total_loss: 8.210275928179422
        vf_explained_var: 0.9805936217308044
        vf_loss: 8.222715377807617
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.148387096774197
    gpu_util_percent0: 0.28838709677419355
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7806451612903222
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 10782
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15001274609613216
    mean_env_wait_ms: 1.2014104168203592
    mean_inference_ms: 4.47536467879199
    mean_raw_obs_processing_ms: 0.3902298097490615
  time_since_restore: 561.7725501060486
  time_this_iter_s: 26.817644119262695
  time_total_s: 561.7725501060486
  timers:
    learn_throughput: 8264.502
    learn_time_ms: 19576.739
    sample_throughput: 23070.246
    sample_time_ms: 7013.016
    update_time_ms: 37.783
  timestamp: 1602515443
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: c52d2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c52d2_00000 | RUNNING  | 172.17.0.4:10782 |     21 |          561.773 | 3397632 |  235.529 |              286.192 |              138.768 |            812.603 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c52d2_00000:
  custom_metrics:
    time_step_max: 4000
    time_step_mean: 3355.935888336882
    time_step_min: 2992
  date: 2020-10-12_15-11-10
  done: false
  episode_len_mean: 811.4566338490389
  episode_reward_max: 291.4949494949492
  episode_reward_mean: 236.30717157510412
  episode_reward_min: 138.7676767676767
  episodes_this_iter: 158
  episodes_total: 4266
  experiment_id: 278703f5a76a413d80112154e6e1c72f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7313190599282583
        entropy_coeff: 0.0005000000000000001
        kl: 0.0059486522028843565
        model: {}
        policy_loss: -0.010567928196905996
        total_loss: 8.188967108726501
        vf_explained_var: 0.9800074100494385
        vf_loss: 8.199306011199951
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.812903225806455
    gpu_util_percent0: 0.2893548387096774
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 10782
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14989802765720947
    mean_env_wait_ms: 1.2021612409117175
    mean_inference_ms: 4.469741163385711
    mean_raw_obs_processing_ms: 0.3898606362297102
  time_since_restore: 588.5127539634705
  time_this_iter_s: 26.740203857421875
  time_total_s: 588.5127539634705
  timers:
    learn_throughput: 8258.847
    learn_time_ms: 19590.144
    sample_throughput: 23080.5
    sample_time_ms: 7009.9
    update_time_ms: 37.799
  timestamp: 1602515470
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: c52d2_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c52d2_00000 | RUNNING  | 172.17.0.4:10782 |     22 |          588.513 | 3559424 |  236.307 |              291.495 |              138.768 |            811.457 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c52d2_00000:
  custom_metrics:
    time_step_max: 4000
    time_step_mean: 3346.508729281768
    time_step_min: 2992
  date: 2020-10-12_15-11-37
  done: true
  episode_len_mean: 809.3422436459247
  episode_reward_max: 291.4949494949492
  episode_reward_mean: 237.67161536486694
  episode_reward_min: 138.7676767676767
  episodes_this_iter: 298
  episodes_total: 4564
  experiment_id: 278703f5a76a413d80112154e6e1c72f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.6868849446376165
        entropy_coeff: 0.0005000000000000001
        kl: 0.005426900926977396
        model: {}
        policy_loss: -0.012831605854444206
        total_loss: 10.865561644236246
        vf_explained_var: 0.9829086661338806
        vf_loss: 10.878193855285645
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.741935483870968
    gpu_util_percent0: 0.29806451612903234
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322573
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 10782
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14969546689023083
    mean_env_wait_ms: 1.2035092400508398
    mean_inference_ms: 4.459926158115246
    mean_raw_obs_processing_ms: 0.389229242467895
  time_since_restore: 615.1636734008789
  time_this_iter_s: 26.650919437408447
  time_total_s: 615.1636734008789
  timers:
    learn_throughput: 8263.168
    learn_time_ms: 19579.9
    sample_throughput: 23052.935
    sample_time_ms: 7018.282
    update_time_ms: 37.48
  timestamp: 1602515497
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: c52d2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c52d2_00000 | TERMINATED |       |     23 |          615.164 | 3721216 |  237.672 |              291.495 |              138.768 |            809.342 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c52d2_00000 | TERMINATED |       |     23 |          615.164 | 3721216 |  237.672 |              291.495 |              138.768 |            809.342 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


