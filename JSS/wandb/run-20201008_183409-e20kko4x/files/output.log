2020-10-08 18:34:11,610	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8270[39m[22m
== Status ==
Memory usage on this node: 57.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_dcdda_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=61793)[0m 2020-10-08 18:34:14,734	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=61723)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61723)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61757)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61757)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61767)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61767)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61761)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61761)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61736)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61736)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61772)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61772)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61724)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61724)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61661)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61661)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61779)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61779)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61756)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61756)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61739)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61739)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61799)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61799)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61744)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61744)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61649)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61649)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61683)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61683)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61653)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61653)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61735)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61735)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61742)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61742)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61721)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61721)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61777)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61777)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61655)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61655)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61711)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61711)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61733)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61733)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61720)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61720)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61755)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61755)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61753)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61753)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61787)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61787)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61726)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61726)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61768)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61768)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61725)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61725)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61738)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61738)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61652)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61652)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61647)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61647)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61751)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61751)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61676)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61676)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61658)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61658)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61716)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61716)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61654)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61654)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61790)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61790)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61713)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61713)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61656)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61656)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61680)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61680)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61666)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61666)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61746)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61746)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61671)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61671)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61663)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61663)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61748)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61748)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61722)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61722)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61675)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61675)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61770)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61770)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61660)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61660)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61672)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61672)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61732)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61732)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61715)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61715)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61651)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61651)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61640)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61640)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61731)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61731)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61641)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61641)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61678)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61678)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61657)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61657)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61727)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61727)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61668)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61668)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61783)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61783)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61682)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61682)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61648)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61648)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61729)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61729)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61669)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61669)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61717)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61717)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61734)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61734)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61650)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61650)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61730)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61730)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61728)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61728)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61642)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61642)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61740)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61740)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61718)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61718)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61681)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61681)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61719)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61719)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61775)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61775)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61786)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61786)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_dcdda_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3279.0
  date: 2020-10-08_18-34-46
  done: false
  episode_len_mean: 877.1708860759494
  episode_reward_max: 273.13131313131294
  episode_reward_mean: 224.28870988364636
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: ad5ec0684a53442cb6f894ce7ce81856
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1623869717121125
        entropy_coeff: 0.0
        kl: 0.004495001025497913
        model: {}
        policy_loss: -0.007870184851344674
        total_loss: 8.237782764434815
        vf_explained_var: 0.7536491751670837
        vf_loss: 8.24475393295288
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 37.49677419354839
    gpu_util_percent0: 0.2958064516129032
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0003225806451612903
    ram_util_percent: 9.480645161290324
    vram_util_percent0: 0.2568875040997048
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61793
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.18078452460962371
    mean_env_wait_ms: 1.6651610409488422
    mean_inference_ms: 5.882819285544396
    mean_raw_obs_processing_ms: 0.4849698713584681
  time_since_restore: 26.13601303100586
  time_this_iter_s: 26.13601303100586
  time_total_s: 26.13601303100586
  timers:
    learn_throughput: 9946.958
    learn_time_ms: 16265.476
    sample_throughput: 16580.115
    sample_time_ms: 9758.195
    update_time_ms: 28.376
  timestamp: 1602182086
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: dcdda_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 72.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcdda_00000 | RUNNING  | 172.17.0.4:61793 |      1 |           26.136 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dcdda_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3200.0
  date: 2020-10-08_18-35-11
  done: false
  episode_len_mean: 870.3132911392405
  episode_reward_max: 280.53535353535375
  episode_reward_mean: 226.201828410689
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: ad5ec0684a53442cb6f894ce7ce81856
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.136464351415634
        entropy_coeff: 0.0
        kl: 0.006411744328215718
        model: {}
        policy_loss: -0.0100418918649666
        total_loss: 7.719148564338684
        vf_explained_var: 0.8878858685493469
        vf_loss: 7.728549194335938
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.725
    gpu_util_percent0: 0.30249999999999994
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.739285714285716
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61793
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17537490126714897
    mean_env_wait_ms: 1.6585325432411997
    mean_inference_ms: 5.590765667110439
    mean_raw_obs_processing_ms: 0.4720633820080976
  time_since_restore: 50.66071033477783
  time_this_iter_s: 24.524697303771973
  time_total_s: 50.66071033477783
  timers:
    learn_throughput: 10014.103
    learn_time_ms: 16156.415
    sample_throughput: 17815.915
    sample_time_ms: 9081.319
    update_time_ms: 25.168
  timestamp: 1602182111
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: dcdda_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcdda_00000 | RUNNING  | 172.17.0.4:61793 |      2 |          50.6607 | 323584 |  226.202 |              280.535 |              115.788 |            870.313 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dcdda_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3200.0
  date: 2020-10-08_18-35-36
  done: false
  episode_len_mean: 863.3333333333334
  episode_reward_max: 280.53535353535375
  episode_reward_mean: 228.03993521715023
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: ad5ec0684a53442cb6f894ce7ce81856
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1226667582988739
        entropy_coeff: 0.0
        kl: 0.007708484772592783
        model: {}
        policy_loss: -0.01118325067218393
        total_loss: 7.66869421005249
        vf_explained_var: 0.9342523813247681
        vf_loss: 7.6791064739227295
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.66206896551725
    gpu_util_percent0: 0.18413793103448275
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.751724137931037
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61793
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17191736920995465
    mean_env_wait_ms: 1.6551999286284824
    mean_inference_ms: 5.430723044960598
    mean_raw_obs_processing_ms: 0.46280921609271775
  time_since_restore: 75.37837815284729
  time_this_iter_s: 24.717667818069458
  time_total_s: 75.37837815284729
  timers:
    learn_throughput: 10016.149
    learn_time_ms: 16153.114
    sample_throughput: 18223.167
    sample_time_ms: 8878.369
    update_time_ms: 29.711
  timestamp: 1602182136
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: dcdda_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcdda_00000 | RUNNING  | 172.17.0.4:61793 |      3 |          75.3784 | 485376 |   228.04 |              280.535 |              115.788 |            863.333 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dcdda_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3200.0
  date: 2020-10-08_18-36-00
  done: false
  episode_len_mean: 856.7041139240506
  episode_reward_max: 280.53535353535375
  episode_reward_mean: 229.22762434471278
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: ad5ec0684a53442cb6f894ce7ce81856
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0864292621612548
        entropy_coeff: 0.0
        kl: 0.009485246241092682
        model: {}
        policy_loss: -0.012085625482723118
        total_loss: 7.654739284515381
        vf_explained_var: 0.9551712274551392
        vf_loss: 7.665876269340515
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.13103448275862
    gpu_util_percent0: 0.31862068965517243
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.751724137931037
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61793
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16953975578236694
    mean_env_wait_ms: 1.6557276419563423
    mean_inference_ms: 5.313699603429612
    mean_raw_obs_processing_ms: 0.4558884647506208
  time_since_restore: 99.88074707984924
  time_this_iter_s: 24.502368927001953
  time_total_s: 99.88074707984924
  timers:
    learn_throughput: 10017.312
    learn_time_ms: 16151.238
    sample_throughput: 18537.277
    sample_time_ms: 8727.927
    update_time_ms: 29.892
  timestamp: 1602182160
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: dcdda_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcdda_00000 | RUNNING  | 172.17.0.4:61793 |      4 |          99.8807 | 647168 |  229.228 |              280.535 |              115.788 |            856.704 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dcdda_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3200.0
  date: 2020-10-08_18-36-25
  done: false
  episode_len_mean: 842.3997890295359
  episode_reward_max: 280.53535353535375
  episode_reward_mean: 231.38957081362133
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 316
  episodes_total: 948
  experiment_id: ad5ec0684a53442cb6f894ce7ce81856
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0540016770362854
        entropy_coeff: 0.0
        kl: 0.0074445920297876
        model: {}
        policy_loss: -0.01087031844072044
        total_loss: 9.755606746673584
        vf_explained_var: 0.9746206402778625
        vf_loss: 9.765732479095458
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.48214285714286
    gpu_util_percent0: 0.225
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.750000000000002
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61793
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16658479820874636
    mean_env_wait_ms: 1.6617532278755065
    mean_inference_ms: 5.164509497639284
    mean_raw_obs_processing_ms: 0.44740650165474566
  time_since_restore: 124.38389182090759
  time_this_iter_s: 24.50314474105835
  time_total_s: 124.38389182090759
  timers:
    learn_throughput: 10007.783
    learn_time_ms: 16166.617
    sample_throughput: 18771.058
    sample_time_ms: 8619.227
    update_time_ms: 31.815
  timestamp: 1602182185
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: dcdda_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcdda_00000 | RUNNING  | 172.17.0.4:61793 |      5 |          124.384 | 808960 |   231.39 |              280.535 |              115.788 |              842.4 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dcdda_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3200.0
  date: 2020-10-08_18-36-49
  done: false
  episode_len_mean: 835.6708860759494
  episode_reward_max: 281.4444444444448
  episode_reward_mean: 232.9500246588853
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 1106
  experiment_id: ad5ec0684a53442cb6f894ce7ce81856
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0322220742702484
        entropy_coeff: 0.0
        kl: 0.006681828713044524
        model: {}
        policy_loss: -0.01169363158987835
        total_loss: 4.592606687545777
        vf_explained_var: 0.9835664629936218
        vf_loss: 4.603632020950317
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.69642857142858
    gpu_util_percent0: 0.23249999999999998
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.760714285714286
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61793
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1655446276841814
    mean_env_wait_ms: 1.6647720771647465
    mean_inference_ms: 5.112677250045697
    mean_raw_obs_processing_ms: 0.44448728003597604
  time_since_restore: 148.71809554100037
  time_this_iter_s: 24.334203720092773
  time_total_s: 148.71809554100037
  timers:
    learn_throughput: 10014.867
    learn_time_ms: 16155.182
    sample_throughput: 18942.88
    sample_time_ms: 8541.045
    update_time_ms: 32.188
  timestamp: 1602182209
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: dcdda_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcdda_00000 | RUNNING  | 172.17.0.4:61793 |      6 |          148.718 | 970752 |   232.95 |              281.444 |              115.788 |            835.671 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dcdda_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3200.0
  date: 2020-10-08_18-37-14
  done: false
  episode_len_mean: 830.3037974683544
  episode_reward_max: 281.4444444444448
  episode_reward_mean: 233.88462153177332
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: ad5ec0684a53442cb6f894ce7ce81856
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0072282195091247
        entropy_coeff: 0.0
        kl: 0.0058178078616037965
        model: {}
        policy_loss: -0.01249282828066498
        total_loss: 4.180519866943359
        vf_explained_var: 0.9872654676437378
        vf_loss: 4.192430913448334
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.73571428571428
    gpu_util_percent0: 0.2121428571428572
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.757142857142858
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61793
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16465683695568284
    mean_env_wait_ms: 1.6678832662216618
    mean_inference_ms: 5.067744062050173
    mean_raw_obs_processing_ms: 0.44187952654472945
  time_since_restore: 173.0558145046234
  time_this_iter_s: 24.337718963623047
  time_total_s: 173.0558145046234
  timers:
    learn_throughput: 10011.639
    learn_time_ms: 16160.391
    sample_throughput: 19097.687
    sample_time_ms: 8471.811
    update_time_ms: 32.982
  timestamp: 1602182234
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: dcdda_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcdda_00000 | RUNNING  | 172.17.0.4:61793 |      7 |          173.056 | 1132544 |  233.885 |              281.444 |              115.788 |            830.304 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dcdda_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3200.0
  date: 2020-10-08_18-37-38
  done: false
  episode_len_mean: 825.9184668989546
  episode_reward_max: 281.4444444444448
  episode_reward_mean: 234.47101678808986
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 171
  episodes_total: 1435
  experiment_id: ad5ec0684a53442cb6f894ce7ce81856
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9628604829311371
        entropy_coeff: 0.0
        kl: 0.005152228148654103
        model: {}
        policy_loss: -0.010881587490439415
        total_loss: 4.960894751548767
        vf_explained_var: 0.990268886089325
        vf_loss: 4.971261215209961
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.00714285714285
    gpu_util_percent0: 0.16642857142857143
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.760714285714286
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61793
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1638661765469221
    mean_env_wait_ms: 1.671716585042267
    mean_inference_ms: 5.026187738363911
    mean_raw_obs_processing_ms: 0.4393832629652352
  time_since_restore: 197.39478993415833
  time_this_iter_s: 24.338975429534912
  time_total_s: 197.39478993415833
  timers:
    learn_throughput: 10014.395
    learn_time_ms: 16155.943
    sample_throughput: 19196.506
    sample_time_ms: 8428.2
    update_time_ms: 33.932
  timestamp: 1602182258
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: dcdda_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcdda_00000 | RUNNING  | 172.17.0.4:61793 |      8 |          197.395 | 1294336 |  234.471 |              281.444 |              115.788 |            825.918 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dcdda_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3200.0
  date: 2020-10-08_18-38-03
  done: false
  episode_len_mean: 819.8325661680092
  episode_reward_max: 281.4444444444448
  episode_reward_mean: 235.32423777475552
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 303
  episodes_total: 1738
  experiment_id: ad5ec0684a53442cb6f894ce7ce81856
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9490918070077896
        entropy_coeff: 0.0
        kl: 0.005457967310212553
        model: {}
        policy_loss: -0.010802903934381903
        total_loss: 5.115585064888
        vf_explained_var: 0.9896923303604126
        vf_loss: 5.1258423089981076
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.55
    gpu_util_percent0: 0.17464285714285716
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.750000000000002
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61793
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16270334160314467
    mean_env_wait_ms: 1.6772274914981657
    mean_inference_ms: 4.966097790656017
    mean_raw_obs_processing_ms: 0.4358062498149722
  time_since_restore: 221.81873774528503
  time_this_iter_s: 24.42394781112671
  time_total_s: 221.81873774528503
  timers:
    learn_throughput: 10021.117
    learn_time_ms: 16145.106
    sample_throughput: 19233.184
    sample_time_ms: 8412.128
    update_time_ms: 33.236
  timestamp: 1602182283
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: dcdda_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcdda_00000 | RUNNING  | 172.17.0.4:61793 |      9 |          221.819 | 1456128 |  235.324 |              281.444 |              115.788 |            819.833 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dcdda_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3137.0
  date: 2020-10-08_18-38-27
  done: false
  episode_len_mean: 817.0690928270042
  episode_reward_max: 289.6363636363634
  episode_reward_mean: 235.84218769978258
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 1896
  experiment_id: ad5ec0684a53442cb6f894ce7ce81856
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9128808826208115
        entropy_coeff: 0.0
        kl: 0.004901849571615458
        model: {}
        policy_loss: -0.010996322717983276
        total_loss: 3.614064335823059
        vf_explained_var: 0.9917303323745728
        vf_loss: 3.6245704889297485
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.55714285714286
    gpu_util_percent0: 0.2228571428571429
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.760714285714288
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61793
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1622256710183699
    mean_env_wait_ms: 1.67986075652389
    mean_inference_ms: 4.940581821236069
    mean_raw_obs_processing_ms: 0.4343238376044022
  time_since_restore: 246.24009227752686
  time_this_iter_s: 24.42135453224182
  time_total_s: 246.24009227752686
  timers:
    learn_throughput: 10026.962
    learn_time_ms: 16135.695
    sample_throughput: 19264.241
    sample_time_ms: 8398.566
    update_time_ms: 33.21
  timestamp: 1602182307
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: dcdda_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcdda_00000 | RUNNING  | 172.17.0.4:61793 |     10 |           246.24 | 1617920 |  235.842 |              289.636 |              115.788 |            817.069 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dcdda_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3137.0
  date: 2020-10-08_18-38-51
  done: false
  episode_len_mean: 814.7409931840311
  episode_reward_max: 289.6363636363634
  episode_reward_mean: 236.24852222320573
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: ad5ec0684a53442cb6f894ce7ce81856
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.0e-05
        entropy: 0.8862208992242813
        entropy_coeff: 0.0
        kl: 0.005289160180836916
        model: {}
        policy_loss: -0.011241631518350914
        total_loss: 3.160608196258545
        vf_explained_var: 0.9933274984359741
        vf_loss: 3.1715853810310364
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.47142857142857
    gpu_util_percent0: 0.2596428571428572
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.760714285714286
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61793
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16180041755182845
    mean_env_wait_ms: 1.682446806975943
    mean_inference_ms: 4.917454379652367
    mean_raw_obs_processing_ms: 0.43294138432147117
  time_since_restore: 270.40135622024536
  time_this_iter_s: 24.161263942718506
  time_total_s: 270.40135622024536
  timers:
    learn_throughput: 10035.135
    learn_time_ms: 16122.554
    sample_throughput: 19690.602
    sample_time_ms: 8216.712
    update_time_ms: 33.273
  timestamp: 1602182331
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: dcdda_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcdda_00000 | RUNNING  | 172.17.0.4:61793 |     11 |          270.401 | 1779712 |  236.249 |              289.636 |              115.788 |            814.741 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dcdda_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3137.0
  date: 2020-10-08_18-39-16
  done: false
  episode_len_mean: 811.0118143459915
  episode_reward_max: 289.6363636363634
  episode_reward_mean: 236.42664194689505
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 316
  episodes_total: 2370
  experiment_id: ad5ec0684a53442cb6f894ce7ce81856
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.0e-05
        entropy: 0.8496158272027969
        entropy_coeff: 0.0
        kl: 0.005078033288009464
        model: {}
        policy_loss: -0.008576176781207322
        total_loss: 4.369901871681213
        vf_explained_var: 0.9937219619750977
        vf_loss: 4.378224039077759
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.575
    gpu_util_percent0: 0.14535714285714288
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.75357142857143
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61793
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16107612852949582
    mean_env_wait_ms: 1.6872943710347805
    mean_inference_ms: 4.878148555132336
    mean_raw_obs_processing_ms: 0.4306478792966297
  time_since_restore: 294.8649823665619
  time_this_iter_s: 24.46362614631653
  time_total_s: 294.8649823665619
  timers:
    learn_throughput: 10033.047
    learn_time_ms: 16125.908
    sample_throughput: 19716.513
    sample_time_ms: 8205.914
    update_time_ms: 33.112
  timestamp: 1602182356
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: dcdda_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcdda_00000 | RUNNING  | 172.17.0.4:61793 |     12 |          294.865 | 1941504 |  236.427 |              289.636 |              115.788 |            811.012 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dcdda_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3137.0
  date: 2020-10-08_18-39-40
  done: false
  episode_len_mean: 809.443829113924
  episode_reward_max: 289.6363636363634
  episode_reward_mean: 236.79321697992583
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 2528
  experiment_id: ad5ec0684a53442cb6f894ce7ce81856
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.0e-05
        entropy: 0.8209726393222809
        entropy_coeff: 0.0
        kl: 0.004655330860987306
        model: {}
        policy_loss: -0.010432996577583254
        total_loss: 2.5049042820930483
        vf_explained_var: 0.9947488903999329
        vf_loss: 2.5151045322418213
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.325
    gpu_util_percent0: 0.32821428571428574
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.760714285714286
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61793
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16076409800990835
    mean_env_wait_ms: 1.6894514979024264
    mean_inference_ms: 4.8612299232570955
    mean_raw_obs_processing_ms: 0.42965275833179833
  time_since_restore: 319.242308139801
  time_this_iter_s: 24.377325773239136
  time_total_s: 319.242308139801
  timers:
    learn_throughput: 10031.377
    learn_time_ms: 16128.593
    sample_throughput: 19804.326
    sample_time_ms: 8169.528
    update_time_ms: 32.862
  timestamp: 1602182380
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: dcdda_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcdda_00000 | RUNNING  | 172.17.0.4:61793 |     13 |          319.242 | 2103296 |  236.793 |              289.636 |              115.788 |            809.444 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dcdda_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3137.0
  date: 2020-10-08_18-40-05
  done: false
  episode_len_mean: 808.114668652271
  episode_reward_max: 289.6363636363634
  episode_reward_mean: 237.1535834893988
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 2686
  experiment_id: ad5ec0684a53442cb6f894ce7ce81856
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025000000000000005
        cur_lr: 5.0e-05
        entropy: 0.8185998618602752
        entropy_coeff: 0.0
        kl: 0.005254795262590051
        model: {}
        policy_loss: -0.00981018942547962
        total_loss: 2.632296550273895
        vf_explained_var: 0.994111180305481
        vf_loss: 2.6419753551483156
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.76428571428571
    gpu_util_percent0: 0.28857142857142865
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.757142857142858
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61793
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16047534718922712
    mean_env_wait_ms: 1.6914972838563584
    mean_inference_ms: 4.845612758948077
    mean_raw_obs_processing_ms: 0.4287282867455215
  time_since_restore: 343.4908127784729
  time_this_iter_s: 24.248504638671875
  time_total_s: 343.4908127784729
  timers:
    learn_throughput: 10041.412
    learn_time_ms: 16112.474
    sample_throughput: 19829.865
    sample_time_ms: 8159.006
    update_time_ms: 33.195
  timestamp: 1602182405
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: dcdda_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcdda_00000 | RUNNING  | 172.17.0.4:61793 |     14 |          343.491 | 2265088 |  237.154 |              289.636 |              115.788 |            808.115 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dcdda_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3137.0
  date: 2020-10-08_18-40-29
  done: false
  episode_len_mean: 805.8002004677581
  episode_reward_max: 289.6363636363634
  episode_reward_mean: 237.70762756195435
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 307
  episodes_total: 2993
  experiment_id: ad5ec0684a53442cb6f894ce7ce81856
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025000000000000005
        cur_lr: 5.0e-05
        entropy: 0.7888743937015533
        entropy_coeff: 0.0
        kl: 0.00472110640257597
        model: {}
        policy_loss: -0.008770648681093007
        total_loss: 3.5633772373199464
        vf_explained_var: 0.9948158264160156
        vf_loss: 3.5720299243927003
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.32142857142857
    gpu_util_percent0: 0.26142857142857145
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.750000000000002
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61793
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15997039672796226
    mean_env_wait_ms: 1.6953271827607785
    mean_inference_ms: 4.818786225987087
    mean_raw_obs_processing_ms: 0.4271682195463652
  time_since_restore: 367.73448371887207
  time_this_iter_s: 24.24367094039917
  time_total_s: 367.73448371887207
  timers:
    learn_throughput: 10048.85
    learn_time_ms: 16100.548
    sample_throughput: 19862.819
    sample_time_ms: 8145.47
    update_time_ms: 31.308
  timestamp: 1602182429
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: dcdda_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcdda_00000 | RUNNING  | 172.17.0.4:61793 |     15 |          367.734 | 2426880 |  237.708 |              289.636 |              115.788 |              805.8 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dcdda_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3137.0
  date: 2020-10-08_18-40-54
  done: false
  episode_len_mean: 804.6129746835443
  episode_reward_max: 289.6363636363634
  episode_reward_mean: 237.92562012530365
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 167
  episodes_total: 3160
  experiment_id: ad5ec0684a53442cb6f894ce7ce81856
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.012500000000000002
        cur_lr: 5.0e-05
        entropy: 0.7418307036161422
        entropy_coeff: 0.0
        kl: 0.004754281742498279
        model: {}
        policy_loss: -0.009978909540222958
        total_loss: 2.2573763728141785
        vf_explained_var: 0.9953057169914246
        vf_loss: 2.2672958254814146
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.50344827586207
    gpu_util_percent0: 0.17482758620689653
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.768965517241382
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61793
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15973527722686423
    mean_env_wait_ms: 1.6971265947598355
    mean_inference_ms: 4.80586533890557
    mean_raw_obs_processing_ms: 0.4264126494967999
  time_since_restore: 392.28324365615845
  time_this_iter_s: 24.548759937286377
  time_total_s: 392.28324365615845
  timers:
    learn_throughput: 10047.209
    learn_time_ms: 16103.178
    sample_throughput: 19820.482
    sample_time_ms: 8162.869
    update_time_ms: 29.911
  timestamp: 1602182454
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: dcdda_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcdda_00000 | RUNNING  | 172.17.0.4:61793 |     16 |          392.283 | 2588672 |  237.926 |              289.636 |              115.788 |            804.613 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dcdda_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3137.0
  date: 2020-10-08_18-41-19
  done: false
  episode_len_mean: 803.4626280892104
  episode_reward_max: 289.6363636363634
  episode_reward_mean: 238.3570423950171
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 3318
  experiment_id: ad5ec0684a53442cb6f894ce7ce81856
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.006250000000000001
        cur_lr: 5.0e-05
        entropy: 0.7555918782949448
        entropy_coeff: 0.0
        kl: 0.004798290226608515
        model: {}
        policy_loss: -0.009443993505556136
        total_loss: 2.181638127565384
        vf_explained_var: 0.9948902130126953
        vf_loss: 2.1910521030426025
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.19285714285714
    gpu_util_percent0: 0.29857142857142854
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.757142857142858
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61793
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15953124907989677
    mean_env_wait_ms: 1.698797874526805
    mean_inference_ms: 4.794471701765483
    mean_raw_obs_processing_ms: 0.42574550830651087
  time_since_restore: 416.8221778869629
  time_this_iter_s: 24.538934230804443
  time_total_s: 416.8221778869629
  timers:
    learn_throughput: 10054.479
    learn_time_ms: 16091.536
    sample_throughput: 19743.125
    sample_time_ms: 8194.853
    update_time_ms: 28.461
  timestamp: 1602182479
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: dcdda_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcdda_00000 | RUNNING  | 172.17.0.4:61793 |     17 |          416.822 | 2750464 |  238.357 |              289.636 |              115.788 |            803.463 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dcdda_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3137.0
  date: 2020-10-08_18-41-43
  done: false
  episode_len_mean: 802.2361425339367
  episode_reward_max: 289.6363636363634
  episode_reward_mean: 238.8235951140363
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 218
  episodes_total: 3536
  experiment_id: ad5ec0684a53442cb6f894ce7ce81856
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0031250000000000006
        cur_lr: 5.0e-05
        entropy: 0.7367299377918244
        entropy_coeff: 0.0
        kl: 0.004432362457737327
        model: {}
        policy_loss: -0.00933759540785104
        total_loss: 2.6716785073280334
        vf_explained_var: 0.9955344200134277
        vf_loss: 2.681002306938171
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.425
    gpu_util_percent0: 0.26321428571428573
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.750000000000002
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61793
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15927711982857418
    mean_env_wait_ms: 1.70107844983334
    mean_inference_ms: 4.77981403699115
    mean_raw_obs_processing_ms: 0.4248805681572548
  time_since_restore: 441.13336539268494
  time_this_iter_s: 24.311187505722046
  time_total_s: 441.13336539268494
  timers:
    learn_throughput: 10060.589
    learn_time_ms: 16081.762
    sample_throughput: 19724.676
    sample_time_ms: 8202.518
    update_time_ms: 26.752
  timestamp: 1602182503
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: dcdda_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcdda_00000 | RUNNING  | 172.17.0.4:61793 |     18 |          441.133 | 2912256 |  238.824 |              289.636 |              115.788 |            802.236 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dcdda_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3137.0
  date: 2020-10-08_18-42-08
  done: false
  episode_len_mean: 801.2070147679325
  episode_reward_max: 289.6363636363634
  episode_reward_mean: 239.3128036696075
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 256
  episodes_total: 3792
  experiment_id: ad5ec0684a53442cb6f894ce7ce81856
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0015625000000000003
        cur_lr: 5.0e-05
        entropy: 0.6876504361629486
        entropy_coeff: 0.0
        kl: 0.004603545507416129
        model: {}
        policy_loss: -0.008868791186250747
        total_loss: 2.438988471031189
        vf_explained_var: 0.9951601028442383
        vf_loss: 2.447850060462952
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.42413793103449
    gpu_util_percent0: 0.2989655172413794
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.758620689655174
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61793
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15899406458874613
    mean_env_wait_ms: 1.7033716314387775
    mean_inference_ms: 4.764531539641802
    mean_raw_obs_processing_ms: 0.42398400143993614
  time_since_restore: 465.61732006073
  time_this_iter_s: 24.483954668045044
  time_total_s: 465.61732006073
  timers:
    learn_throughput: 10049.967
    learn_time_ms: 16098.76
    sample_throughput: 19752.512
    sample_time_ms: 8190.958
    update_time_ms: 26.489
  timestamp: 1602182528
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: dcdda_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcdda_00000 | RUNNING  | 172.17.0.4:61793 |     19 |          465.617 | 3074048 |  239.313 |              289.636 |              115.788 |            801.207 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dcdda_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3137.0
  date: 2020-10-08_18-42-32
  done: false
  episode_len_mean: 800.4339240506329
  episode_reward_max: 289.6363636363634
  episode_reward_mean: 239.5999974427823
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 3950
  experiment_id: ad5ec0684a53442cb6f894ce7ce81856
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0007812500000000002
        cur_lr: 5.0e-05
        entropy: 0.6983130633831024
        entropy_coeff: 0.0
        kl: 0.004435630142688751
        model: {}
        policy_loss: -0.008949237986234948
        total_loss: 2.13798269033432
        vf_explained_var: 0.9948981404304504
        vf_loss: 2.1469285130500793
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.675
    gpu_util_percent0: 0.26428571428571423
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.760714285714286
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61793
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15883742739447482
    mean_env_wait_ms: 1.7047029670054115
    mean_inference_ms: 4.755767108083374
    mean_raw_obs_processing_ms: 0.42347200991475986
  time_since_restore: 489.94359731674194
  time_this_iter_s: 24.326277256011963
  time_total_s: 489.94359731674194
  timers:
    learn_throughput: 10043.728
    learn_time_ms: 16108.76
    sample_throughput: 19797.959
    sample_time_ms: 8172.156
    update_time_ms: 25.127
  timestamp: 1602182552
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: dcdda_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcdda_00000 | RUNNING  | 172.17.0.4:61793 |     20 |          489.944 | 3235840 |    239.6 |              289.636 |              115.788 |            800.434 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dcdda_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3137.0
  date: 2020-10-08_18-42-57
  done: false
  episode_len_mean: 799.8516897641624
  episode_reward_max: 289.6363636363634
  episode_reward_mean: 239.88289410025374
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 163
  episodes_total: 4113
  experiment_id: ad5ec0684a53442cb6f894ce7ce81856
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0003906250000000001
        cur_lr: 5.0e-05
        entropy: 0.6947086155414581
        entropy_coeff: 0.0
        kl: 0.004513862566091121
        model: {}
        policy_loss: -0.00980280947405845
        total_loss: 2.178980839252472
        vf_explained_var: 0.9955021739006042
        vf_loss: 2.1887818932533265
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.267857142857146
    gpu_util_percent0: 0.20071428571428576
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.760714285714286
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61793
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15868738304854088
    mean_env_wait_ms: 1.7060889452932537
    mean_inference_ms: 4.7474045679499115
    mean_raw_obs_processing_ms: 0.4229840848016877
  time_since_restore: 514.348482131958
  time_this_iter_s: 24.404884815216064
  time_total_s: 514.348482131958
  timers:
    learn_throughput: 10037.805
    learn_time_ms: 16118.264
    sample_throughput: 19762.689
    sample_time_ms: 8186.74
    update_time_ms: 24.298
  timestamp: 1602182577
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: dcdda_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcdda_00000 | RUNNING  | 172.17.0.4:61793 |     21 |          514.348 | 3397632 |  239.883 |              289.636 |              115.788 |            799.852 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dcdda_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3137.0
  date: 2020-10-08_18-43-21
  done: false
  episode_len_mean: 798.7224231464738
  episode_reward_max: 289.6363636363634
  episode_reward_mean: 240.41196321259616
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 311
  episodes_total: 4424
  experiment_id: ad5ec0684a53442cb6f894ce7ce81856
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.00019531250000000004
        cur_lr: 5.0e-05
        entropy: 0.6459014415740967
        entropy_coeff: 0.0
        kl: 0.00415674785617739
        model: {}
        policy_loss: -0.008441441634204239
        total_loss: 2.86402587890625
        vf_explained_var: 0.9953325390815735
        vf_loss: 2.872466468811035
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.017857142857146
    gpu_util_percent0: 0.25857142857142856
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.757142857142858
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61793
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15841816686777585
    mean_env_wait_ms: 1.7084093083692584
    mean_inference_ms: 4.73236743357015
    mean_raw_obs_processing_ms: 0.4221150134355735
  time_since_restore: 538.7743480205536
  time_this_iter_s: 24.42586588859558
  time_total_s: 538.7743480205536
  timers:
    learn_throughput: 10034.511
    learn_time_ms: 16123.555
    sample_throughput: 19788.651
    sample_time_ms: 8176.0
    update_time_ms: 25.721
  timestamp: 1602182601
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: dcdda_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcdda_00000 | RUNNING  | 172.17.0.4:61793 |     22 |          538.774 | 3559424 |  240.412 |              289.636 |              115.788 |            798.722 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dcdda_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3137.0
  date: 2020-10-08_18-43-46
  done: false
  episode_len_mean: 798.1697948494108
  episode_reward_max: 289.6363636363634
  episode_reward_mean: 240.73618551292063
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 4582
  experiment_id: ad5ec0684a53442cb6f894ce7ce81856
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 9.765625000000002e-05
        cur_lr: 5.0e-05
        entropy: 0.655648934841156
        entropy_coeff: 0.0
        kl: 0.004280474968254566
        model: {}
        policy_loss: -0.010435595375020057
        total_loss: 1.7212722539901733
        vf_explained_var: 0.9959337115287781
        vf_loss: 1.7317074477672576
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.06071428571428
    gpu_util_percent0: 0.20678571428571427
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.771428571428572
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61793
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15829422091025563
    mean_env_wait_ms: 1.7095228823148687
    mean_inference_ms: 4.725427902194311
    mean_raw_obs_processing_ms: 0.4217174096887373
  time_since_restore: 563.2571375370026
  time_this_iter_s: 24.482789516448975
  time_total_s: 563.2571375370026
  timers:
    learn_throughput: 10035.655
    learn_time_ms: 16121.719
    sample_throughput: 19760.028
    sample_time_ms: 8187.843
    update_time_ms: 25.269
  timestamp: 1602182626
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: dcdda_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcdda_00000 | RUNNING  | 172.17.0.4:61793 |     23 |          563.257 | 3721216 |  240.736 |              289.636 |              115.788 |             798.17 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dcdda_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3137.0
  date: 2020-10-08_18-44-11
  done: false
  episode_len_mean: 797.6215189873418
  episode_reward_max: 289.6363636363634
  episode_reward_mean: 241.02339001832675
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 4740
  experiment_id: ad5ec0684a53442cb6f894ce7ce81856
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 4.882812500000001e-05
        cur_lr: 5.0e-05
        entropy: 0.659921470284462
        entropy_coeff: 0.0
        kl: 0.0038709761342033745
        model: {}
        policy_loss: -0.009979837306309492
        total_loss: 1.8656711637973786
        vf_explained_var: 0.9955980181694031
        vf_loss: 1.8756507873535155
    num_steps_sampled: 3883008
    num_steps_trained: 3883008
  iterations_since_restore: 24
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.05357142857143
    gpu_util_percent0: 0.27214285714285713
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.760714285714286
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61793
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15817733418993127
    mean_env_wait_ms: 1.7106152802625918
    mean_inference_ms: 4.718810892427955
    mean_raw_obs_processing_ms: 0.42132789747904764
  time_since_restore: 587.7988812923431
  time_this_iter_s: 24.541743755340576
  time_total_s: 587.7988812923431
  timers:
    learn_throughput: 10034.91
    learn_time_ms: 16122.915
    sample_throughput: 19700.462
    sample_time_ms: 8212.599
    update_time_ms: 25.443
  timestamp: 1602182651
  timesteps_since_restore: 0
  timesteps_total: 3883008
  training_iteration: 24
  trial_id: dcdda_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcdda_00000 | RUNNING  | 172.17.0.4:61793 |     24 |          587.799 | 3883008 |  241.023 |              289.636 |              115.788 |            797.622 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dcdda_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3137.0
  date: 2020-10-08_18-44-35
  done: true
  episode_len_mean: 796.671875
  episode_reward_max: 289.6363636363634
  episode_reward_mean: 241.6990813994374
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 316
  episodes_total: 5056
  experiment_id: ad5ec0684a53442cb6f894ce7ce81856
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 2.4414062500000005e-05
        cur_lr: 5.0e-05
        entropy: 0.6159051269292831
        entropy_coeff: 0.0
        kl: 0.0038445065845735373
        model: {}
        policy_loss: -0.00824204934615409
        total_loss: 2.4778953790664673
        vf_explained_var: 0.9960786700248718
        vf_loss: 2.486137318611145
    num_steps_sampled: 4044800
    num_steps_trained: 4044800
  iterations_since_restore: 25
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.43928571428571
    gpu_util_percent0: 0.2239285714285714
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.753571428571428
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61793
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15796010750154718
    mean_env_wait_ms: 1.712662313228033
    mean_inference_ms: 4.706600345647986
    mean_raw_obs_processing_ms: 0.42062626644684836
  time_since_restore: 612.1513347625732
  time_this_iter_s: 24.352453470230103
  time_total_s: 612.1513347625732
  timers:
    learn_throughput: 10037.471
    learn_time_ms: 16118.801
    sample_throughput: 19668.296
    sample_time_ms: 8226.03
    update_time_ms: 25.344
  timestamp: 1602182675
  timesteps_since_restore: 0
  timesteps_total: 4044800
  training_iteration: 25
  trial_id: dcdda_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcdda_00000 | TERMINATED |       |     25 |          612.151 | 4044800 |  241.699 |              289.636 |              115.788 |            796.672 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcdda_00000 | TERMINATED |       |     25 |          612.151 | 4044800 |  241.699 |              289.636 |              115.788 |            796.672 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


