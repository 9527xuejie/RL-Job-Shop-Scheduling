2020-10-10 18:42:46,957	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8266[39m[22m
== Status ==
Memory usage on this node: 32.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_64d08_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=71840)[0m 2020-10-10 18:42:49,804	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=71834)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71834)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71791)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71791)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71802)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71802)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71776)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71776)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71794)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71794)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71801)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71801)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71814)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71814)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71773)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71773)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71766)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71766)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71822)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71822)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71769)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71769)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71772)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71772)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71813)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71813)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71785)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71785)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71761)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71761)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71819)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71819)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71818)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71818)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71703)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71703)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71779)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71779)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71799)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71799)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71748)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71748)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71710)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71710)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71733)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71733)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71728)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71728)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71709)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71709)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71777)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71777)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71754)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71754)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71800)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71800)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71751)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71751)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71787)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71787)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71784)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71784)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71788)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71788)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71774)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71774)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71724)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71724)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71697)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71697)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71715)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71715)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71805)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71805)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71695)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71695)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71698)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71698)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71694)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71694)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71795)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71795)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71759)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71759)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71722)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71722)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71705)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71705)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71704)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71704)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71809)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71809)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71780)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71780)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71792)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71792)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71693)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71693)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71706)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71706)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71764)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71764)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71738)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71738)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71796)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71796)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71725)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71725)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71696)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71696)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71768)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71768)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71775)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71775)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71736)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71736)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71756)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71756)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71781)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71781)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71832)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71832)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71729)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71729)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71712)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71712)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71700)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71700)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71711)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71711)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71719)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71719)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71701)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71701)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71708)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71708)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71763)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71763)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71717)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71717)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71767)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71767)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71771)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71771)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71778)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71778)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71713)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71713)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71790)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71790)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71749)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71749)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71810)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71810)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71730)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71730)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=71782)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=71782)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_64d08_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-10_18-43-31
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: a78cb9a0a063446d831f079d747c3528
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.1868481125150407
        entropy_coeff: 0.0
        kl: 0.0020665525724845274
        model: {}
        policy_loss: -0.0026865176956302355
        total_loss: 660.8497576032366
        vf_explained_var: 0.0902143344283104
        vf_loss: 660.8520377022879
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.897727272727266
    gpu_util_percent0: 0.3554545454545455
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.284090909090907
    vram_util_percent0: 0.19162393034974204
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 71840
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17691790965575793
    mean_env_wait_ms: 1.2053446933125669
    mean_inference_ms: 6.245076484833281
    mean_raw_obs_processing_ms: 0.479949066100867
  time_since_restore: 36.141244649887085
  time_this_iter_s: 36.141244649887085
  time_total_s: 36.141244649887085
  timers:
    learn_throughput: 6140.777
    learn_time_ms: 26347.156
    sample_throughput: 16663.129
    sample_time_ms: 9709.581
    update_time_ms: 50.35
  timestamp: 1602355411
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 64d08_00000
  
== Status ==
Memory usage on this node: 48.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_64d08_00000 | RUNNING  | 172.17.0.4:71840 |      1 |          36.1412 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_64d08_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3597.4270833333335
    time_step_min: 3269
  date: 2020-10-10_18-44-05
  done: false
  episode_len_mean: 888.6360759493671
  episode_reward_max: 270.71717171717137
  episode_reward_mean: 220.0439841452497
  episode_reward_min: 100.26262626262617
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: a78cb9a0a063446d831f079d747c3528
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.162245750427246
        entropy_coeff: 0.0
        kl: 0.003311335408527936
        model: {}
        policy_loss: -0.003996366456703981
        total_loss: 309.0002681187221
        vf_explained_var: 0.5081067681312561
        vf_loss: 309.0039324079241
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.441463414634146
    gpu_util_percent0: 0.39463414634146343
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.465853658536586
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 71840
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17108067528175308
    mean_env_wait_ms: 1.1985002753449785
    mean_inference_ms: 5.8995270225238725
    mean_raw_obs_processing_ms: 0.463825518391646
  time_since_restore: 70.01687908172607
  time_this_iter_s: 33.87563443183899
  time_total_s: 70.01687908172607
  timers:
    learn_throughput: 6189.037
    learn_time_ms: 26141.707
    sample_throughput: 18413.624
    sample_time_ms: 8786.538
    update_time_ms: 37.436
  timestamp: 1602355445
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 64d08_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_64d08_00000 | RUNNING  | 172.17.0.4:71840 |      2 |          70.0169 | 323584 |  220.044 |              270.717 |              100.263 |            888.636 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_64d08_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3597.791479820628
    time_step_min: 3269
  date: 2020-10-10_18-44-39
  done: false
  episode_len_mean: 884.717299578059
  episode_reward_max: 270.71717171717137
  episode_reward_mean: 220.14819076844367
  episode_reward_min: 100.26262626262617
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: a78cb9a0a063446d831f079d747c3528
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 1.0e-05
        entropy: 1.1578872799873352
        entropy_coeff: 0.0
        kl: 0.003837172457549189
        model: {}
        policy_loss: -0.005166775059089039
        total_loss: 141.13865116664343
        vf_explained_var: 0.7530078291893005
        vf_loss: 141.14362444196428
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.3625
    gpu_util_percent0: 0.39174999999999993
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4875
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 71840
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16744905490231474
    mean_env_wait_ms: 1.1958877395155394
    mean_inference_ms: 5.6579835579006295
    mean_raw_obs_processing_ms: 0.45232935723184997
  time_since_restore: 103.6211040019989
  time_this_iter_s: 33.60422492027283
  time_total_s: 103.6211040019989
  timers:
    learn_throughput: 6178.842
    learn_time_ms: 26184.842
    sample_throughput: 19548.785
    sample_time_ms: 8276.32
    update_time_ms: 33.733
  timestamp: 1602355479
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 64d08_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_64d08_00000 | RUNNING  | 172.17.0.4:71840 |      3 |          103.621 | 485376 |  220.148 |              270.717 |              100.263 |            884.717 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_64d08_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3593.6241721854303
    time_step_min: 3269
  date: 2020-10-10_18-45-12
  done: false
  episode_len_mean: 880.5142405063291
  episode_reward_max: 270.71717171717137
  episode_reward_mean: 220.46017133358885
  episode_reward_min: 100.26262626262617
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: a78cb9a0a063446d831f079d747c3528
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025000000000000005
        cur_lr: 1.0e-05
        entropy: 1.1487685867718287
        entropy_coeff: 0.0
        kl: 0.004773730012987342
        model: {}
        policy_loss: -0.0038177870800219743
        total_loss: 92.32309068952289
        vf_explained_var: 0.8350268602371216
        vf_loss: 92.32678713117328
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.665853658536584
    gpu_util_percent0: 0.3873170731707318
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.485365853658536
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 71840
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16487652746386552
    mean_env_wait_ms: 1.194713601623006
    mean_inference_ms: 5.484984546009456
    mean_raw_obs_processing_ms: 0.44365930501221856
  time_since_restore: 136.91575264930725
  time_this_iter_s: 33.29464864730835
  time_total_s: 136.91575264930725
  timers:
    learn_throughput: 6191.987
    learn_time_ms: 26129.255
    sample_throughput: 20205.813
    sample_time_ms: 8007.201
    update_time_ms: 31.657
  timestamp: 1602355512
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 64d08_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_64d08_00000 | RUNNING  | 172.17.0.4:71840 |      4 |          136.916 | 647168 |   220.46 |              270.717 |              100.263 |            880.514 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_64d08_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3598.8976377952754
    time_step_min: 3254
  date: 2020-10-10_18-45-46
  done: false
  episode_len_mean: 875.8392405063291
  episode_reward_max: 272.9898989898986
  episode_reward_mean: 220.76051655798474
  episode_reward_min: 100.26262626262617
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: a78cb9a0a063446d831f079d747c3528
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.012500000000000002
        cur_lr: 1.0e-05
        entropy: 1.1255904350961958
        entropy_coeff: 0.0
        kl: 0.004058086878753134
        model: {}
        policy_loss: -0.00421006530606454
        total_loss: 72.77077266148159
        vf_explained_var: 0.8785425424575806
        vf_loss: 72.77493068150112
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.2975
    gpu_util_percent0: 0.3835
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4875
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 71840
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1629880321076151
    mean_env_wait_ms: 1.1952559562038467
    mean_inference_ms: 5.35574945931491
    mean_raw_obs_processing_ms: 0.43710355900991194
  time_since_restore: 170.43105244636536
  time_this_iter_s: 33.515299797058105
  time_total_s: 170.43105244636536
  timers:
    learn_throughput: 6188.794
    learn_time_ms: 26142.734
    sample_throughput: 20609.15
    sample_time_ms: 7850.494
    update_time_ms: 32.611
  timestamp: 1602355546
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 64d08_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_64d08_00000 | RUNNING  | 172.17.0.4:71840 |      5 |          170.431 | 808960 |  220.761 |               272.99 |              100.263 |            875.839 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_64d08_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3592.791821561338
    time_step_min: 3254
  date: 2020-10-10_18-46-19
  done: false
  episode_len_mean: 865.7327898550725
  episode_reward_max: 272.9898989898986
  episode_reward_mean: 221.96497584541044
  episode_reward_min: 100.26262626262617
  episodes_this_iter: 314
  episodes_total: 1104
  experiment_id: a78cb9a0a063446d831f079d747c3528
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.006250000000000001
        cur_lr: 1.0e-05
        entropy: 1.1268339582851954
        entropy_coeff: 0.0
        kl: 0.004244935233145952
        model: {}
        policy_loss: -0.004581809636355112
        total_loss: 82.25983047485352
        vf_explained_var: 0.9054819345474243
        vf_loss: 82.26438576834542
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.9225
    gpu_util_percent0: 0.38425000000000004
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.477499999999999
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 71840
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16042916402652724
    mean_env_wait_ms: 1.1982157851566297
    mean_inference_ms: 5.18331842919438
    mean_raw_obs_processing_ms: 0.4285486059575679
  time_since_restore: 203.65542912483215
  time_this_iter_s: 33.2243766784668
  time_total_s: 203.65542912483215
  timers:
    learn_throughput: 6197.475
    learn_time_ms: 26106.117
    sample_throughput: 20890.281
    sample_time_ms: 7744.846
    update_time_ms: 33.044
  timestamp: 1602355579
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 64d08_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_64d08_00000 | RUNNING  | 172.17.0.4:71840 |      6 |          203.655 | 970752 |  221.965 |               272.99 |              100.263 |            865.733 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_64d08_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3587.3923948220063
    time_step_min: 3221
  date: 2020-10-10_18-46-52
  done: false
  episode_len_mean: 861.1653481012659
  episode_reward_max: 277.98989898989885
  episode_reward_mean: 223.0091979925839
  episode_reward_min: 100.26262626262617
  episodes_this_iter: 160
  episodes_total: 1264
  experiment_id: a78cb9a0a063446d831f079d747c3528
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0031250000000000006
        cur_lr: 1.0e-05
        entropy: 1.1327165280069624
        entropy_coeff: 0.0
        kl: 0.00369324443662273
        model: {}
        policy_loss: -0.003911687418751951
        total_loss: 52.55099269321987
        vf_explained_var: 0.9066729545593262
        vf_loss: 52.554892676217214
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.020000000000003
    gpu_util_percent0: 0.41550000000000004
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.49
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 71840
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1595232369206339
    mean_env_wait_ms: 1.199659471984056
    mean_inference_ms: 5.120631437431653
    mean_raw_obs_processing_ms: 0.42549012430058386
  time_since_restore: 236.7153148651123
  time_this_iter_s: 33.05988574028015
  time_total_s: 236.7153148651123
  timers:
    learn_throughput: 6205.782
    learn_time_ms: 26071.169
    sample_throughput: 21153.858
    sample_time_ms: 7648.345
    update_time_ms: 39.31
  timestamp: 1602355612
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 64d08_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_64d08_00000 | RUNNING  | 172.17.0.4:71840 |      7 |          236.715 | 1132544 |  223.009 |               277.99 |              100.263 |            861.165 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_64d08_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3580.0373027259684
    time_step_min: 3221
  date: 2020-10-10_18-47-25
  done: false
  episode_len_mean: 856.9613220815752
  episode_reward_max: 277.98989898989885
  episode_reward_mean: 223.9964838255975
  episode_reward_min: 100.26262626262617
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: a78cb9a0a063446d831f079d747c3528
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0015625000000000003
        cur_lr: 1.0e-05
        entropy: 1.1182438560894556
        entropy_coeff: 0.0
        kl: 0.004204081437949624
        model: {}
        policy_loss: -0.003741336695384234
        total_loss: 47.22164263044085
        vf_explained_var: 0.9124733805656433
        vf_loss: 47.22537858145578
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.225
    gpu_util_percent0: 0.38
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.484999999999999
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 71840
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15875969792484676
    mean_env_wait_ms: 1.201009363342297
    mean_inference_ms: 5.067412277527597
    mean_raw_obs_processing_ms: 0.42285136830438186
  time_since_restore: 269.99145126342773
  time_this_iter_s: 33.27613639831543
  time_total_s: 269.99145126342773
  timers:
    learn_throughput: 6209.744
    learn_time_ms: 26054.537
    sample_throughput: 21291.329
    sample_time_ms: 7598.962
    update_time_ms: 38.915
  timestamp: 1602355645
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 64d08_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_64d08_00000 | RUNNING  | 172.17.0.4:71840 |      8 |          269.991 | 1294336 |  223.996 |               277.99 |              100.263 |            856.961 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_64d08_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3570.9117268041236
    time_step_min: 3221
  date: 2020-10-10_18-47-59
  done: false
  episode_len_mean: 852.843670886076
  episode_reward_max: 277.98989898989885
  episode_reward_mean: 225.14994885564488
  episode_reward_min: 100.26262626262617
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: a78cb9a0a063446d831f079d747c3528
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0007812500000000002
        cur_lr: 1.0e-05
        entropy: 1.0874286379132951
        entropy_coeff: 0.0
        kl: 0.003997047398505467
        model: {}
        policy_loss: -0.00477573781141213
        total_loss: 42.05925069536482
        vf_explained_var: 0.921959400177002
        vf_loss: 42.06402315412249
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.997499999999995
    gpu_util_percent0: 0.41600000000000004
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4875
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 71840
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1580930556448566
    mean_env_wait_ms: 1.2024451410904928
    mean_inference_ms: 5.021354706671507
    mean_raw_obs_processing_ms: 0.4205355797478956
  time_since_restore: 303.34129190444946
  time_this_iter_s: 33.34984064102173
  time_total_s: 303.34129190444946
  timers:
    learn_throughput: 6208.883
    learn_time_ms: 26058.148
    sample_throughput: 21425.005
    sample_time_ms: 7551.55
    update_time_ms: 38.915
  timestamp: 1602355679
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 64d08_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_64d08_00000 | RUNNING  | 172.17.0.4:71840 |      9 |          303.341 | 1456128 |   225.15 |               277.99 |              100.263 |            852.844 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_64d08_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3559.400107123728
    time_step_min: 3221
  date: 2020-10-10_18-48-32
  done: false
  episode_len_mean: 845.7778364116095
  episode_reward_max: 284.50505050505046
  episode_reward_mean: 226.94992137736185
  episode_reward_min: 100.26262626262617
  episodes_this_iter: 315
  episodes_total: 1895
  experiment_id: a78cb9a0a063446d831f079d747c3528
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0003906250000000001
        cur_lr: 1.0e-05
        entropy: 1.0793670756476266
        entropy_coeff: 0.0
        kl: 0.004368711928171771
        model: {}
        policy_loss: -0.002660145559015551
        total_loss: 44.012190682547434
        vf_explained_var: 0.9481062293052673
        vf_loss: 44.01484979901995
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.189999999999998
    gpu_util_percent0: 0.38875000000000004
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.477500000000001
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 71840
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15701447521498313
    mean_env_wait_ms: 1.2054821505338753
    mean_inference_ms: 4.947425010867924
    mean_raw_obs_processing_ms: 0.41691563991278113
  time_since_restore: 336.6092131137848
  time_this_iter_s: 33.26792120933533
  time_total_s: 336.6092131137848
  timers:
    learn_throughput: 6212.269
    learn_time_ms: 26043.946
    sample_throughput: 21508.795
    sample_time_ms: 7522.132
    update_time_ms: 38.828
  timestamp: 1602355712
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 64d08_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_64d08_00000 | RUNNING  | 172.17.0.4:71840 |     10 |          336.609 | 1617920 |   226.95 |              284.505 |              100.263 |            845.778 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_64d08_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3555.192497532083
    time_step_min: 3221
  date: 2020-10-10_18-49-06
  done: false
  episode_len_mean: 842.3627069133398
  episode_reward_max: 284.50505050505046
  episode_reward_mean: 227.68111494693756
  episode_reward_min: 100.26262626262617
  episodes_this_iter: 159
  episodes_total: 2054
  experiment_id: a78cb9a0a063446d831f079d747c3528
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.00019531250000000004
        cur_lr: 1.0e-05
        entropy: 1.0767979962485177
        entropy_coeff: 0.0
        kl: 0.0038785195210948586
        model: {}
        policy_loss: -0.004714956259704195
        total_loss: 29.538367543901717
        vf_explained_var: 0.9471567273139954
        vf_loss: 29.5430816922869
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.215
    gpu_util_percent0: 0.376
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.49
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 71840
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1565684257271368
    mean_env_wait_ms: 1.2069275146377871
    mean_inference_ms: 4.9168917664471286
    mean_raw_obs_processing_ms: 0.4154399643208397
  time_since_restore: 369.7896206378937
  time_this_iter_s: 33.18040752410889
  time_total_s: 369.7896206378937
  timers:
    learn_throughput: 6221.111
    learn_time_ms: 26006.93
    sample_throughput: 22273.97
    sample_time_ms: 7263.725
    update_time_ms: 35.853
  timestamp: 1602355746
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 64d08_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_64d08_00000 | RUNNING  | 172.17.0.4:71840 |     11 |           369.79 | 1779712 |  227.681 |              284.505 |              100.263 |            842.363 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_64d08_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3552.7152014652015
    time_step_min: 3221
  date: 2020-10-10_18-49-39
  done: false
  episode_len_mean: 839.4764918625679
  episode_reward_max: 284.50505050505046
  episode_reward_mean: 228.1197691197689
  episode_reward_min: 100.26262626262617
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: a78cb9a0a063446d831f079d747c3528
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 9.765625000000002e-05
        cur_lr: 1.0e-05
        entropy: 1.0657645208495004
        entropy_coeff: 0.0
        kl: 0.0038083745499274562
        model: {}
        policy_loss: -0.0037083856482890303
        total_loss: 30.084248406546457
        vf_explained_var: 0.9461135268211365
        vf_loss: 30.087956837245397
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.415
    gpu_util_percent0: 0.378
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.494999999999999
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 71840
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1561680884877955
    mean_env_wait_ms: 1.208251299037183
    mean_inference_ms: 4.889378628318127
    mean_raw_obs_processing_ms: 0.4140858313594911
  time_since_restore: 403.18059635162354
  time_this_iter_s: 33.39097571372986
  time_total_s: 403.18059635162354
  timers:
    learn_throughput: 6221.884
    learn_time_ms: 26003.699
    sample_throughput: 22412.789
    sample_time_ms: 7218.736
    update_time_ms: 35.332
  timestamp: 1602355779
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 64d08_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_64d08_00000 | RUNNING  | 172.17.0.4:71840 |     12 |          403.181 | 1941504 |   228.12 |              284.505 |              100.263 |            839.476 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_64d08_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3548.8079191238417
    time_step_min: 3221
  date: 2020-10-10_18-50-12
  done: false
  episode_len_mean: 836.2822647793505
  episode_reward_max: 284.50505050505046
  episode_reward_mean: 228.88574336201296
  episode_reward_min: 100.26262626262617
  episodes_this_iter: 190
  episodes_total: 2402
  experiment_id: a78cb9a0a063446d831f079d747c3528
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 4.882812500000001e-05
        cur_lr: 1.0e-05
        entropy: 1.0286408833095007
        entropy_coeff: 0.0
        kl: 0.0039574265746133664
        model: {}
        policy_loss: -0.0031796586034553392
        total_loss: 29.565215247017996
        vf_explained_var: 0.9584766030311584
        vf_loss: 29.568394933428085
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.985
    gpu_util_percent0: 0.35550000000000004
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4875
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 71840
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15573475968414144
    mean_env_wait_ms: 1.2099219280299947
    mean_inference_ms: 4.859561862989628
    mean_raw_obs_processing_ms: 0.4125910489317703
  time_since_restore: 436.3118953704834
  time_this_iter_s: 33.13129901885986
  time_total_s: 436.3118953704834
  timers:
    learn_throughput: 6229.615
    learn_time_ms: 25971.428
    sample_throughput: 22464.35
    sample_time_ms: 7202.167
    update_time_ms: 35.381
  timestamp: 1602355812
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 64d08_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_64d08_00000 | RUNNING  | 172.17.0.4:71840 |     13 |          436.312 | 2103296 |  228.886 |              284.505 |              100.263 |            836.282 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_64d08_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3541.7336343115126
    time_step_min: 3221
  date: 2020-10-10_18-50-46
  done: false
  episode_len_mean: 831.8585256887566
  episode_reward_max: 284.50505050505046
  episode_reward_mean: 229.96309333092637
  episode_reward_min: 100.26262626262617
  episodes_this_iter: 284
  episodes_total: 2686
  experiment_id: a78cb9a0a063446d831f079d747c3528
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 2.4414062500000005e-05
        cur_lr: 1.0e-05
        entropy: 1.0344858254705156
        entropy_coeff: 0.0
        kl: 0.0040557446191087365
        model: {}
        policy_loss: -0.0023627281105811043
        total_loss: 25.55212947300502
        vf_explained_var: 0.9633784890174866
        vf_loss: 25.55449186052595
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.924390243902437
    gpu_util_percent0: 0.3468292682926829
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.482926829268291
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 71840
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15517960904855224
    mean_env_wait_ms: 1.212242077320535
    mean_inference_ms: 4.8215036626105325
    mean_raw_obs_processing_ms: 0.410718358219615
  time_since_restore: 469.9094715118408
  time_this_iter_s: 33.59757614135742
  time_total_s: 469.9094715118408
  timers:
    learn_throughput: 6222.716
    learn_time_ms: 26000.223
    sample_throughput: 22445.176
    sample_time_ms: 7208.319
    update_time_ms: 35.584
  timestamp: 1602355846
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 64d08_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_64d08_00000 | RUNNING  | 172.17.0.4:71840 |     14 |          469.909 | 2265088 |  229.963 |              284.505 |              100.263 |            831.859 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_64d08_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3537.3132102272725
    time_step_min: 3214
  date: 2020-10-10_18-51-19
  done: false
  episode_len_mean: 829.6990154711674
  episode_reward_max: 284.50505050505046
  episode_reward_mean: 230.63821761923012
  episode_reward_min: 100.26262626262617
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: a78cb9a0a063446d831f079d747c3528
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 1.2207031250000002e-05
        cur_lr: 1.0e-05
        entropy: 1.0220723407609122
        entropy_coeff: 0.0
        kl: 0.003553888710614826
        model: {}
        policy_loss: -0.003685942807351239
        total_loss: 18.393438611711776
        vf_explained_var: 0.9655689597129822
        vf_loss: 18.397124699183873
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.2
    gpu_util_percent0: 0.43249999999999994
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4875
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 71840
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15491114986459947
    mean_env_wait_ms: 1.2134237996604231
    mean_inference_ms: 4.802870924996544
    mean_raw_obs_processing_ms: 0.4097885719892114
  time_since_restore: 503.0952775478363
  time_this_iter_s: 33.18580603599548
  time_total_s: 503.0952775478363
  timers:
    learn_throughput: 6230.317
    learn_time_ms: 25968.504
    sample_throughput: 22452.709
    sample_time_ms: 7205.901
    update_time_ms: 35.511
  timestamp: 1602355879
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 64d08_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_64d08_00000 | RUNNING  | 172.17.0.4:71840 |     15 |          503.095 | 2426880 |  230.638 |              284.505 |              100.263 |            829.699 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_64d08_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3533.1271015467382
    time_step_min: 3173
  date: 2020-10-10_18-51-53
  done: false
  episode_len_mean: 827.5396402398401
  episode_reward_max: 285.2626262626263
  episode_reward_mean: 231.24146865052916
  episode_reward_min: 100.26262626262617
  episodes_this_iter: 158
  episodes_total: 3002
  experiment_id: a78cb9a0a063446d831f079d747c3528
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 6.103515625000001e-06
        cur_lr: 1.0e-05
        entropy: 1.0004522715296065
        entropy_coeff: 0.0
        kl: 0.003660842776298523
        model: {}
        policy_loss: -0.0028768116192493054
        total_loss: 20.27658121926444
        vf_explained_var: 0.9625537991523743
        vf_loss: 20.279457909720286
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.3675
    gpu_util_percent0: 0.36324999999999996
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.5
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 71840
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15466381509861882
    mean_env_wait_ms: 1.2145681249932574
    mean_inference_ms: 4.785592485370031
    mean_raw_obs_processing_ms: 0.4089039107090555
  time_since_restore: 536.4431674480438
  time_this_iter_s: 33.34788990020752
  time_total_s: 536.4431674480438
  timers:
    learn_throughput: 6228.097
    learn_time_ms: 25977.758
    sample_throughput: 22449.6
    sample_time_ms: 7206.899
    update_time_ms: 35.67
  timestamp: 1602355913
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 64d08_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_64d08_00000 | RUNNING  | 172.17.0.4:71840 |     16 |          536.443 | 2588672 |  231.241 |              285.263 |              100.263 |             827.54 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_64d08_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3523.5782912739433
    time_step_min: 3173
  date: 2020-10-10_18-52-26
  done: false
  episode_len_mean: 823.516129032258
  episode_reward_max: 285.2626262626263
  episode_reward_mean: 232.71779294299628
  episode_reward_min: 100.26262626262617
  episodes_this_iter: 315
  episodes_total: 3317
  experiment_id: a78cb9a0a063446d831f079d747c3528
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 3.0517578125000006e-06
        cur_lr: 1.0e-05
        entropy: 0.9845668034894126
        entropy_coeff: 0.0
        kl: 0.0033926062252638595
        model: {}
        policy_loss: -0.0036782972685094656
        total_loss: 22.4258873803275
        vf_explained_var: 0.9709459543228149
        vf_loss: 22.4295654296875
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.975
    gpu_util_percent0: 0.362
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.475
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 71840
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15423247434159806
    mean_env_wait_ms: 1.2168440508415073
    mean_inference_ms: 4.755037859227257
    mean_raw_obs_processing_ms: 0.4073772932877737
  time_since_restore: 569.8150987625122
  time_this_iter_s: 33.371931314468384
  time_total_s: 569.8150987625122
  timers:
    learn_throughput: 6223.991
    learn_time_ms: 25994.897
    sample_throughput: 22391.74
    sample_time_ms: 7225.522
    update_time_ms: 30.258
  timestamp: 1602355946
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 64d08_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_64d08_00000 | RUNNING  | 172.17.0.4:71840 |     17 |          569.815 | 2750464 |  232.718 |              285.263 |              100.263 |            823.516 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_64d08_00000:
  custom_metrics:
    time_step_max: 4394
    time_step_mean: 3517.981438515081
    time_step_min: 3173
  date: 2020-10-10_18-53-00
  done: true
  episode_len_mean: 821.5601265822785
  episode_reward_max: 288.29292929292956
  episode_reward_mean: 233.5129662563493
  episode_reward_min: 100.26262626262617
  episodes_this_iter: 159
  episodes_total: 3476
  experiment_id: a78cb9a0a063446d831f079d747c3528
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 1.5258789062500003e-06
        cur_lr: 1.0e-05
        entropy: 0.9778145934854235
        entropy_coeff: 0.0
        kl: 0.003566629785512175
        model: {}
        policy_loss: -0.003934240315824614
        total_loss: 14.81396518434797
        vf_explained_var: 0.970695972442627
        vf_loss: 14.81789915902274
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.758536585365857
    gpu_util_percent0: 0.35585365853658535
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.495121951219512
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 71840
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15404067541201166
    mean_env_wait_ms: 1.2179154165165824
    mean_inference_ms: 4.7413687363856285
    mean_raw_obs_processing_ms: 0.4066941092509816
  time_since_restore: 603.2645852565765
  time_this_iter_s: 33.44948649406433
  time_total_s: 603.2645852565765
  timers:
    learn_throughput: 6217.896
    learn_time_ms: 26020.378
    sample_throughput: 22417.033
    sample_time_ms: 7217.369
    update_time_ms: 28.814
  timestamp: 1602355980
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 64d08_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_64d08_00000 | TERMINATED |       |     18 |          603.265 | 2912256 |  233.513 |              288.293 |              100.263 |             821.56 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 48.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_64d08_00000 | TERMINATED |       |     18 |          603.265 | 2912256 |  233.513 |              288.293 |              100.263 |             821.56 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


