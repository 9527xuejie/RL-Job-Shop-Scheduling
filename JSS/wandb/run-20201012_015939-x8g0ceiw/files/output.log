2020-10-12 01:59:43,096	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_993c0_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=40791)[0m 2020-10-12 01:59:45,907	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=40793)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40793)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40749)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40749)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40700)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40700)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40751)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40751)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40689)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40689)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40673)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40673)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40667)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40667)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40774)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40774)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40714)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40714)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40729)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40729)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40743)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40743)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40781)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40781)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40664)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40664)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40741)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40741)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40717)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40717)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40719)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40719)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40754)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40754)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40752)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40752)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40771)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40771)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40698)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40698)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40742)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40742)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40739)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40739)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40740)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40740)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40768)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40768)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40690)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40690)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40661)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40661)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40798)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40798)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40663)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40663)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40669)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40669)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40755)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40755)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40778)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40778)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40671)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40671)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40783)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40783)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40761)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40761)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40756)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40756)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40736)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40736)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40715)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40715)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40759)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40759)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40766)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40766)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40773)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40773)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40750)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40750)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40726)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40726)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40659)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40659)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40679)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40679)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40678)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40678)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40665)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40665)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40721)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40721)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40677)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40677)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40685)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40685)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40658)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40658)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40724)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40724)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40782)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40782)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40748)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40748)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40796)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40796)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40660)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40660)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40672)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40672)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40716)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40716)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40767)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40767)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40684)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40684)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40792)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40792)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40697)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40697)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40694)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40694)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40758)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40758)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40674)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40674)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40734)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40734)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40733)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40733)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40681)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40681)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40666)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40666)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40728)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40728)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40662)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40662)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40732)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40732)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40789)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40789)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40725)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40725)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40786)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40786)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40753)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40753)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40675)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40675)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40692)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40692)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40720)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40720)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=40676)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40676)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_993c0_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-12_02-00-26
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 046fb74358ee4ecba5496df9646c7570
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1796465913454692
        entropy_coeff: 0.0001
        kl: 0.00938712681333224
        model: {}
        policy_loss: -0.014201135102969905
        total_loss: 500.41188049316406
        vf_explained_var: 0.5819632411003113
        vf_loss: 500.42430623372394
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.311904761904763
    gpu_util_percent0: 0.41285714285714276
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5952380952380945
    vram_util_percent0: 0.09112277249371378
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 40791
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16598520399648933
    mean_env_wait_ms: 1.1598051606449458
    mean_inference_ms: 5.56695678713293
    mean_raw_obs_processing_ms: 0.4420694166880104
  time_since_restore: 35.72639489173889
  time_this_iter_s: 35.72639489173889
  time_total_s: 35.72639489173889
  timers:
    learn_throughput: 6057.44
    learn_time_ms: 26709.634
    sample_throughput: 18072.766
    sample_time_ms: 8952.255
    update_time_ms: 30.473
  timestamp: 1602468026
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 993c0_00000
  
== Status ==
Memory usage on this node: 27.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_993c0_00000 | RUNNING  | 172.17.0.4:40791 |      1 |          35.7264 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_993c0_00000:
  custom_metrics:
    time_step_max: 4130
    time_step_mean: 3613.7361111111113
    time_step_min: 3376
  date: 2020-10-12_02-01-00
  done: false
  episode_len_mean: 891.376582278481
  episode_reward_max: 266.0202020202022
  episode_reward_mean: 217.58473980309407
  episode_reward_min: 133.8989898989894
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 046fb74358ee4ecba5496df9646c7570
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1458798547585805
        entropy_coeff: 0.0001
        kl: 0.012037907649452487
        model: {}
        policy_loss: -0.0175471538095735
        total_loss: 116.48144276936848
        vf_explained_var: 0.8286274075508118
        vf_loss: 116.49669647216797
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.557499999999997
    gpu_util_percent0: 0.3755
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7675000000000005
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 40791
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16212828567868465
    mean_env_wait_ms: 1.1569677926866901
    mean_inference_ms: 5.358551933366621
    mean_raw_obs_processing_ms: 0.43128784497115513
  time_since_restore: 69.80499148368835
  time_this_iter_s: 34.07859659194946
  time_total_s: 69.80499148368835
  timers:
    learn_throughput: 6096.778
    learn_time_ms: 26537.296
    sample_throughput: 19496.652
    sample_time_ms: 8298.45
    update_time_ms: 25.268
  timestamp: 1602468060
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 993c0_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_993c0_00000 | RUNNING  | 172.17.0.4:40791 |      2 |           69.805 | 323584 |  217.585 |               266.02 |              133.899 |            891.377 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_993c0_00000:
  custom_metrics:
    time_step_max: 4130
    time_step_mean: 3619.3385650224213
    time_step_min: 3376
  date: 2020-10-12_02-01-34
  done: false
  episode_len_mean: 890.6392405063291
  episode_reward_max: 266.0202020202022
  episode_reward_mean: 217.8879299322335
  episode_reward_min: 133.8989898989894
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 046fb74358ee4ecba5496df9646c7570
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1331391334533691
        entropy_coeff: 0.0001
        kl: 0.012271860924859842
        model: {}
        policy_loss: -0.019046661055957276
        total_loss: 45.04107189178467
        vf_explained_var: 0.9210568070411682
        vf_loss: 45.057777404785156
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.233333333333334
    gpu_util_percent0: 0.3474358974358975
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.779487179487181
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 40791
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1596270407179533
    mean_env_wait_ms: 1.1567198300093087
    mean_inference_ms: 5.196336602040185
    mean_raw_obs_processing_ms: 0.4234934969270362
  time_since_restore: 103.4256021976471
  time_this_iter_s: 33.62061071395874
  time_total_s: 103.4256021976471
  timers:
    learn_throughput: 6094.524
    learn_time_ms: 26547.109
    sample_throughput: 20583.163
    sample_time_ms: 7860.405
    update_time_ms: 23.305
  timestamp: 1602468094
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 993c0_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_993c0_00000 | RUNNING  | 172.17.0.4:40791 |      3 |          103.426 | 485376 |  217.888 |               266.02 |              133.899 |            890.639 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_993c0_00000:
  custom_metrics:
    time_step_max: 4130
    time_step_mean: 3616.8708609271525
    time_step_min: 3330
  date: 2020-10-12_02-02-08
  done: false
  episode_len_mean: 889.4066455696203
  episode_reward_max: 266.0202020202022
  episode_reward_mean: 217.95273941951137
  episode_reward_min: 133.8989898989894
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 046fb74358ee4ecba5496df9646c7570
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1113294959068298
        entropy_coeff: 0.0001
        kl: 0.014422132633626461
        model: {}
        policy_loss: -0.019586678051079314
        total_loss: 30.712732632954914
        vf_explained_var: 0.947422206401825
        vf_loss: 30.72954559326172
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.7425
    gpu_util_percent0: 0.45149999999999996
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7775000000000007
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 40791
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15785117983136907
    mean_env_wait_ms: 1.1567419947650412
    mean_inference_ms: 5.077649984564101
    mean_raw_obs_processing_ms: 0.4176249070404465
  time_since_restore: 137.1220829486847
  time_this_iter_s: 33.6964807510376
  time_total_s: 137.1220829486847
  timers:
    learn_throughput: 6086.377
    learn_time_ms: 26582.647
    sample_throughput: 21207.666
    sample_time_ms: 7628.94
    update_time_ms: 23.072
  timestamp: 1602468128
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 993c0_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_993c0_00000 | RUNNING  | 172.17.0.4:40791 |      4 |          137.122 | 647168 |  217.953 |               266.02 |              133.899 |            889.407 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_993c0_00000:
  custom_metrics:
    time_step_max: 4130
    time_step_mean: 3610.5131233595803
    time_step_min: 3330
  date: 2020-10-12_02-02-42
  done: false
  episode_len_mean: 885.5379746835443
  episode_reward_max: 266.0202020202022
  episode_reward_mean: 218.9900907812298
  episode_reward_min: 133.8989898989894
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 046fb74358ee4ecba5496df9646c7570
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0826570689678192
        entropy_coeff: 0.0001
        kl: 0.013772468936319152
        model: {}
        policy_loss: -0.0208830216821904
        total_loss: 23.45069646835327
        vf_explained_var: 0.9586309790611267
        vf_loss: 23.468933423360188
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.327499999999997
    gpu_util_percent0: 0.44125
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7775000000000007
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 40791
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15652045119633812
    mean_env_wait_ms: 1.1577940576213306
    mean_inference_ms: 4.98734302936042
    mean_raw_obs_processing_ms: 0.41303375363273087
  time_since_restore: 171.05976700782776
  time_this_iter_s: 33.937684059143066
  time_total_s: 171.05976700782776
  timers:
    learn_throughput: 6072.772
    learn_time_ms: 26642.197
    sample_throughput: 21615.362
    sample_time_ms: 7485.047
    update_time_ms: 22.864
  timestamp: 1602468162
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 993c0_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_993c0_00000 | RUNNING  | 172.17.0.4:40791 |      5 |           171.06 | 808960 |   218.99 |               266.02 |              133.899 |            885.538 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_993c0_00000:
  custom_metrics:
    time_step_max: 4164
    time_step_mean: 3607.1632850241544
    time_step_min: 3270
  date: 2020-10-12_02-03-16
  done: false
  episode_len_mean: 875.5823142050799
  episode_reward_max: 270.5656565656566
  episode_reward_mean: 219.99665516880927
  episode_reward_min: 133.8989898989894
  episodes_this_iter: 273
  episodes_total: 1063
  experiment_id: 046fb74358ee4ecba5496df9646c7570
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0536836683750153
        entropy_coeff: 0.0001
        kl: 0.013035923630620042
        model: {}
        policy_loss: -0.018688951211515814
        total_loss: 32.94665733973185
        vf_explained_var: 0.9632402062416077
        vf_loss: 32.962843894958496
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.264102564102565
    gpu_util_percent0: 0.316923076923077
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.771794871794873
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 40791
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15489407123613141
    mean_env_wait_ms: 1.161548215143479
    mean_inference_ms: 4.8788693668985195
    mean_raw_obs_processing_ms: 0.40759618083552257
  time_since_restore: 204.89492750167847
  time_this_iter_s: 33.83516049385071
  time_total_s: 204.89492750167847
  timers:
    learn_throughput: 6066.488
    learn_time_ms: 26669.797
    sample_throughput: 21880.363
    sample_time_ms: 7394.393
    update_time_ms: 25.01
  timestamp: 1602468196
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 993c0_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_993c0_00000 | RUNNING  | 172.17.0.4:40791 |      6 |          204.895 | 970752 |  219.997 |              270.566 |              133.899 |            875.582 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_993c0_00000:
  custom_metrics:
    time_step_max: 4164
    time_step_mean: 3597.314724919094
    time_step_min: 3225
  date: 2020-10-12_02-03-50
  done: false
  episode_len_mean: 869.3575949367089
  episode_reward_max: 277.3838383838384
  episode_reward_mean: 221.50003995652713
  episode_reward_min: 133.8989898989894
  episodes_this_iter: 201
  episodes_total: 1264
  experiment_id: 046fb74358ee4ecba5496df9646c7570
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0606599350770314
        entropy_coeff: 0.0001
        kl: 0.011819812391574184
        model: {}
        policy_loss: -0.019723519993325073
        total_loss: 19.43341128031413
        vf_explained_var: 0.9684562087059021
        vf_loss: 19.450876077016193
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.53
    gpu_util_percent0: 0.3825
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.775
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 40791
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15405485219986922
    mean_env_wait_ms: 1.1640157092157823
    mean_inference_ms: 4.821268535666571
    mean_raw_obs_processing_ms: 0.40479445455669233
  time_since_restore: 238.70768356323242
  time_this_iter_s: 33.812756061553955
  time_total_s: 238.70768356323242
  timers:
    learn_throughput: 6061.229
    learn_time_ms: 26692.938
    sample_throughput: 22094.017
    sample_time_ms: 7322.887
    update_time_ms: 24.326
  timestamp: 1602468230
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 993c0_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_993c0_00000 | RUNNING  | 172.17.0.4:40791 |      7 |          238.708 | 1132544 |    221.5 |              277.384 |              133.899 |            869.358 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_993c0_00000:
  custom_metrics:
    time_step_max: 4164
    time_step_mean: 3590.1750358680056
    time_step_min: 3225
  date: 2020-10-12_02-04-24
  done: false
  episode_len_mean: 864.3994374120956
  episode_reward_max: 277.3838383838384
  episode_reward_mean: 222.7022119933511
  episode_reward_min: 133.8989898989894
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 046fb74358ee4ecba5496df9646c7570
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0253396928310394
        entropy_coeff: 0.0001
        kl: 0.012849677121266723
        model: {}
        policy_loss: -0.01999065326526761
        total_loss: 15.222762982050577
        vf_explained_var: 0.9726788997650146
        vf_loss: 15.240286270777384
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.445
    gpu_util_percent0: 0.32125
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7900000000000005
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 40791
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15350529954755365
    mean_env_wait_ms: 1.1658964234653424
    mean_inference_ms: 4.784000436190938
    mean_raw_obs_processing_ms: 0.4029284177916942
  time_since_restore: 272.55171298980713
  time_this_iter_s: 33.84402942657471
  time_total_s: 272.55171298980713
  timers:
    learn_throughput: 6059.601
    learn_time_ms: 26700.108
    sample_throughput: 22238.808
    sample_time_ms: 7275.21
    update_time_ms: 32.988
  timestamp: 1602468264
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 993c0_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_993c0_00000 | RUNNING  | 172.17.0.4:40791 |      8 |          272.552 | 1294336 |  222.702 |              277.384 |              133.899 |            864.399 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_993c0_00000:
  custom_metrics:
    time_step_max: 4164
    time_step_mean: 3582.5708762886597
    time_step_min: 3225
  date: 2020-10-12_02-04-58
  done: false
  episode_len_mean: 860.2322784810127
  episode_reward_max: 277.3838383838384
  episode_reward_mean: 223.96697992584058
  episode_reward_min: 133.8989898989894
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 046fb74358ee4ecba5496df9646c7570
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9872532238562902
        entropy_coeff: 0.0001
        kl: 0.013535311911255121
        model: {}
        policy_loss: -0.021314270289925236
        total_loss: 13.868618488311768
        vf_explained_var: 0.9740790724754333
        vf_loss: 13.887324333190918
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.902564102564103
    gpu_util_percent0: 0.38692307692307687
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7871794871794884
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 40791
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1530351526279255
    mean_env_wait_ms: 1.1677268958507248
    mean_inference_ms: 4.752060527082489
    mean_raw_obs_processing_ms: 0.40130339020270767
  time_since_restore: 306.52362751960754
  time_this_iter_s: 33.971914529800415
  time_total_s: 306.52362751960754
  timers:
    learn_throughput: 6054.592
    learn_time_ms: 26722.196
    sample_throughput: 22334.095
    sample_time_ms: 7244.171
    update_time_ms: 32.369
  timestamp: 1602468298
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 993c0_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_993c0_00000 | RUNNING  | 172.17.0.4:40791 |      9 |          306.524 | 1456128 |  223.967 |              277.384 |              133.899 |            860.232 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_993c0_00000:
  custom_metrics:
    time_step_max: 4269
    time_step_mean: 3566.259197324415
    time_step_min: 3220
  date: 2020-10-12_02-05-31
  done: false
  episode_len_mean: 854.347420417124
  episode_reward_max: 278.14141414141426
  episode_reward_mean: 226.14460743549645
  episode_reward_min: 119.20202020201998
  episodes_this_iter: 242
  episodes_total: 1822
  experiment_id: 046fb74358ee4ecba5496df9646c7570
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9534993668397268
        entropy_coeff: 0.0001
        kl: 0.012596679851412773
        model: {}
        policy_loss: -0.019435644537831347
        total_loss: 21.137900193532307
        vf_explained_var: 0.9720433354377747
        vf_loss: 21.154911994934082
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.655
    gpu_util_percent0: 0.404
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.775
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 40791
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15242667804411553
    mean_env_wait_ms: 1.1705808915332971
    mean_inference_ms: 4.711513930278886
    mean_raw_obs_processing_ms: 0.3992543769430632
  time_since_restore: 340.18675565719604
  time_this_iter_s: 33.6631281375885
  time_total_s: 340.18675565719604
  timers:
    learn_throughput: 6055.765
    learn_time_ms: 26717.021
    sample_throughput: 22434.459
    sample_time_ms: 7211.763
    update_time_ms: 30.975
  timestamp: 1602468331
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 993c0_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_993c0_00000 | RUNNING  | 172.17.0.4:40791 |     10 |          340.187 | 1617920 |  226.145 |              278.141 |              119.202 |            854.347 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_993c0_00000:
  custom_metrics:
    time_step_max: 4269
    time_step_mean: 3554.305034550839
    time_step_min: 3220
  date: 2020-10-12_02-06-06
  done: false
  episode_len_mean: 850.8018500486855
  episode_reward_max: 278.14141414141426
  episode_reward_mean: 227.88559401217617
  episode_reward_min: 119.20202020201998
  episodes_this_iter: 232
  episodes_total: 2054
  experiment_id: 046fb74358ee4ecba5496df9646c7570
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9538102895021439
        entropy_coeff: 0.0001
        kl: 0.01124386404020091
        model: {}
        policy_loss: -0.018309206837633003
        total_loss: 14.170413494110107
        vf_explained_var: 0.9778718948364258
        vf_loss: 14.186569611231485
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.705000000000002
    gpu_util_percent0: 0.34299999999999997
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7775000000000007
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 40791
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15196347324971926
    mean_env_wait_ms: 1.1728574448246203
    mean_inference_ms: 4.678915566109415
    mean_raw_obs_processing_ms: 0.39771751857638493
  time_since_restore: 374.14589071273804
  time_this_iter_s: 33.95913505554199
  time_total_s: 374.14589071273804
  timers:
    learn_throughput: 6051.538
    learn_time_ms: 26735.683
    sample_throughput: 23061.966
    sample_time_ms: 7015.534
    update_time_ms: 29.823
  timestamp: 1602468366
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 993c0_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_993c0_00000 | RUNNING  | 172.17.0.4:40791 |     11 |          374.146 | 1779712 |  227.886 |              278.141 |              119.202 |            850.802 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_993c0_00000:
  custom_metrics:
    time_step_max: 4269
    time_step_mean: 3546.9757326007325
    time_step_min: 3220
  date: 2020-10-12_02-06-40
  done: false
  episode_len_mean: 849.1880650994575
  episode_reward_max: 278.14141414141426
  episode_reward_mean: 228.87268708787684
  episode_reward_min: 119.20202020201998
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 046fb74358ee4ecba5496df9646c7570
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9324918339649836
        entropy_coeff: 0.0001
        kl: 0.011402512667700648
        model: {}
        policy_loss: -0.019873969683734078
        total_loss: 13.73786743481954
        vf_explained_var: 0.9755845665931702
        vf_loss: 13.75555427869161
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.6725
    gpu_util_percent0: 0.3775
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7900000000000005
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 40791
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1516847553866549
    mean_env_wait_ms: 1.1741888454447933
    mean_inference_ms: 4.659864126368432
    mean_raw_obs_processing_ms: 0.3967933299210815
  time_since_restore: 408.06050872802734
  time_this_iter_s: 33.91461801528931
  time_total_s: 408.06050872802734
  timers:
    learn_throughput: 6042.606
    learn_time_ms: 26775.202
    sample_throughput: 23254.826
    sample_time_ms: 6957.352
    update_time_ms: 31.097
  timestamp: 1602468400
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 993c0_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_993c0_00000 | RUNNING  | 172.17.0.4:40791 |     12 |          408.061 | 1941504 |  228.873 |              278.141 |              119.202 |            849.188 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_993c0_00000:
  custom_metrics:
    time_step_max: 4269
    time_step_mean: 3539.3868488471394
    time_step_min: 3220
  date: 2020-10-12_02-07-13
  done: false
  episode_len_mean: 847.4721518987342
  episode_reward_max: 278.14141414141426
  episode_reward_mean: 229.80814473852436
  episode_reward_min: 119.20202020201998
  episodes_this_iter: 158
  episodes_total: 2370
  experiment_id: 046fb74358ee4ecba5496df9646c7570
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9073009143273035
        entropy_coeff: 0.0001
        kl: 0.01222355260203282
        model: {}
        policy_loss: -0.020259643982475
        total_loss: 12.153260072072348
        vf_explained_var: 0.9777944087982178
        vf_loss: 12.171165625254313
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.792307692307695
    gpu_util_percent0: 0.32999999999999996
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.789743589743591
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 40791
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15143568015901512
    mean_env_wait_ms: 1.1753653807897722
    mean_inference_ms: 4.642644557663818
    mean_raw_obs_processing_ms: 0.3959478003619119
  time_since_restore: 441.8463203907013
  time_this_iter_s: 33.78581166267395
  time_total_s: 441.8463203907013
  timers:
    learn_throughput: 6038.567
    learn_time_ms: 26793.11
    sample_throughput: 23261.224
    sample_time_ms: 6955.438
    update_time_ms: 31.229
  timestamp: 1602468433
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 993c0_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_993c0_00000 | RUNNING  | 172.17.0.4:40791 |     13 |          441.846 | 2103296 |  229.808 |              278.141 |              119.202 |            847.472 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_993c0_00000:
  custom_metrics:
    time_step_max: 4269
    time_step_mean: 3530.510101010101
    time_step_min: 3220
  date: 2020-10-12_02-07-48
  done: false
  episode_len_mean: 845.0338201383552
  episode_reward_max: 278.14141414141426
  episode_reward_mean: 231.23309187183122
  episode_reward_min: 119.20202020201998
  episodes_this_iter: 232
  episodes_total: 2602
  experiment_id: 046fb74358ee4ecba5496df9646c7570
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8544954756895701
        entropy_coeff: 0.0001
        kl: 0.011969598398233453
        model: {}
        policy_loss: -0.019318545508819323
        total_loss: 13.585681120554606
        vf_explained_var: 0.9813011288642883
        vf_loss: 13.602691411972046
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.244999999999997
    gpu_util_percent0: 0.3275
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7800000000000002
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 40791
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15110228557502853
    mean_env_wait_ms: 1.1770073403165087
    mean_inference_ms: 4.619913398223607
    mean_raw_obs_processing_ms: 0.3948360332840086
  time_since_restore: 475.9525489807129
  time_this_iter_s: 34.1062285900116
  time_total_s: 475.9525489807129
  timers:
    learn_throughput: 6030.687
    learn_time_ms: 26828.121
    sample_throughput: 23250.017
    sample_time_ms: 6958.791
    update_time_ms: 32.542
  timestamp: 1602468468
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 993c0_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_993c0_00000 | RUNNING  | 172.17.0.4:40791 |     14 |          475.953 | 2265088 |  231.233 |              278.141 |              119.202 |            845.034 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_993c0_00000:
  custom_metrics:
    time_step_max: 4269
    time_step_mean: 3520.900462140064
    time_step_min: 3210
  date: 2020-10-12_02-08-21
  done: false
  episode_len_mean: 843.2618796198522
  episode_reward_max: 279.6565656565665
  episode_reward_mean: 232.61652427122323
  episode_reward_min: 119.20202020201998
  episodes_this_iter: 239
  episodes_total: 2841
  experiment_id: 046fb74358ee4ecba5496df9646c7570
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8502124001582464
        entropy_coeff: 0.0001
        kl: 0.012367788158978025
        model: {}
        policy_loss: -0.01807946579841276
        total_loss: 10.67011292775472
        vf_explained_var: 0.9838699698448181
        vf_loss: 10.68580412864685
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.30769230769231
    gpu_util_percent0: 0.39051282051282055
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7794871794871803
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 40791
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1508299484550508
    mean_env_wait_ms: 1.1784844059567285
    mean_inference_ms: 4.600107282260612
    mean_raw_obs_processing_ms: 0.3938980676673785
  time_since_restore: 509.6140847206116
  time_this_iter_s: 33.66153573989868
  time_total_s: 509.6140847206116
  timers:
    learn_throughput: 6033.323
    learn_time_ms: 26816.399
    sample_throughput: 23280.827
    sample_time_ms: 6949.581
    update_time_ms: 32.432
  timestamp: 1602468501
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 993c0_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_993c0_00000 | RUNNING  | 172.17.0.4:40791 |     15 |          509.614 | 2426880 |  232.617 |              279.657 |              119.202 |            843.262 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_993c0_00000:
  custom_metrics:
    time_step_max: 4269
    time_step_mean: 3515.3073301950235
    time_step_min: 3210
  date: 2020-10-12_02-08-55
  done: false
  episode_len_mean: 842.0446369087275
  episode_reward_max: 286.77777777777754
  episode_reward_mean: 233.41078001870798
  episode_reward_min: 119.20202020201998
  episodes_this_iter: 161
  episodes_total: 3002
  experiment_id: 046fb74358ee4ecba5496df9646c7570
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8373124152421951
        entropy_coeff: 0.0001
        kl: 0.011136741222192844
        model: {}
        policy_loss: -0.018654990126378834
        total_loss: 10.585015296936035
        vf_explained_var: 0.9814069867134094
        vf_loss: 10.601526896158854
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.464102564102564
    gpu_util_percent0: 0.35871794871794876
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.784615384615386
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 40791
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1506532529847062
    mean_env_wait_ms: 1.1793725324321551
    mean_inference_ms: 4.587866150436331
    mean_raw_obs_processing_ms: 0.39331013144285176
  time_since_restore: 543.242110490799
  time_this_iter_s: 33.62802577018738
  time_total_s: 543.242110490799
  timers:
    learn_throughput: 6035.669
    learn_time_ms: 26805.978
    sample_throughput: 23311.755
    sample_time_ms: 6940.361
    update_time_ms: 30.742
  timestamp: 1602468535
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 993c0_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_993c0_00000 | RUNNING  | 172.17.0.4:40791 |     16 |          543.242 | 2588672 |  233.411 |              286.778 |              119.202 |            842.045 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_993c0_00000:
  custom_metrics:
    time_step_max: 4269
    time_step_mean: 3509.844877114587
    time_step_min: 3210
  date: 2020-10-12_02-09-29
  done: false
  episode_len_mean: 840.4739006643467
  episode_reward_max: 286.77777777777754
  episode_reward_mean: 234.1982335215489
  episode_reward_min: 119.20202020201998
  episodes_this_iter: 159
  episodes_total: 3161
  experiment_id: 046fb74358ee4ecba5496df9646c7570
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8174298405647278
        entropy_coeff: 0.0001
        kl: 0.011847644113004208
        model: {}
        policy_loss: -0.018571102409623563
        total_loss: 10.16049631436666
        vf_explained_var: 0.9812217354774475
        vf_loss: 10.176779905954996
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.215384615384615
    gpu_util_percent0: 0.3184615384615385
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.784615384615386
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 40791
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15049445897489333
    mean_env_wait_ms: 1.1802059603698194
    mean_inference_ms: 4.576587099978045
    mean_raw_obs_processing_ms: 0.392760772883943
  time_since_restore: 576.8507742881775
  time_this_iter_s: 33.60866379737854
  time_total_s: 576.8507742881775
  timers:
    learn_throughput: 6038.9
    learn_time_ms: 26791.635
    sample_throughput: 23336.641
    sample_time_ms: 6932.96
    update_time_ms: 32.998
  timestamp: 1602468569
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 993c0_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_993c0_00000 | RUNNING  | 172.17.0.4:40791 |     17 |          576.851 | 2750464 |  234.198 |              286.778 |              119.202 |            840.474 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_993c0_00000:
  custom_metrics:
    time_step_max: 4269
    time_step_mean: 3502.689429928741
    time_step_min: 3199
  date: 2020-10-12_02-10-03
  done: true
  episode_len_mean: 838.4128386336866
  episode_reward_max: 286.77777777777754
  episode_reward_mean: 235.29573116322229
  episode_reward_min: 119.20202020201998
  episodes_this_iter: 235
  episodes_total: 3396
  experiment_id: 046fb74358ee4ecba5496df9646c7570
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7823745260636011
        entropy_coeff: 0.0001
        kl: 0.011435891734436154
        model: {}
        policy_loss: -0.018447599043914426
        total_loss: 11.542823632558187
        vf_explained_var: 0.9840161800384521
        vf_loss: 11.559062163035074
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.96
    gpu_util_percent0: 0.4004999999999999
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7775000000000007
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 40791
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1502767651562069
    mean_env_wait_ms: 1.1814265188346778
    mean_inference_ms: 4.5614251526463505
    mean_raw_obs_processing_ms: 0.3920282230352704
  time_since_restore: 610.5575437545776
  time_this_iter_s: 33.70676946640015
  time_total_s: 610.5575437545776
  timers:
    learn_throughput: 6038.556
    learn_time_ms: 26793.16
    sample_throughput: 23365.901
    sample_time_ms: 6924.278
    update_time_ms: 26.215
  timestamp: 1602468603
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 993c0_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_993c0_00000 | TERMINATED |       |     18 |          610.558 | 2912256 |  235.296 |              286.778 |              119.202 |            838.413 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_993c0_00000 | TERMINATED |       |     18 |          610.558 | 2912256 |  235.296 |              286.778 |              119.202 |            838.413 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


