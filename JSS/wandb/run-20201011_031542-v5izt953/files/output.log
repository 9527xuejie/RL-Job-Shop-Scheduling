2020-10-11 03:15:44,623	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8266[39m[22m
== Status ==
Memory usage on this node: 32.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_0dc04_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=22956)[0m 2020-10-11 03:15:47,589	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=22973)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22973)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22926)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22926)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22935)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22935)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22852)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22852)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22939)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22939)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22905)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22905)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22869)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22869)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22848)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22848)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22896)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22896)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22924)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22924)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22960)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22960)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22971)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22971)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22967)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22967)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22937)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22937)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22952)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22952)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22975)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22975)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22951)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22951)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22908)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22908)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22897)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22897)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22849)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22849)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22846)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22846)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22944)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22944)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22875)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22875)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22837)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22837)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22912)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22912)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22851)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22851)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22947)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22947)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22907)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22907)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22899)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22899)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22957)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22957)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22917)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22917)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22927)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22927)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22834)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22834)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22918)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22918)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22916)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22916)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22925)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22925)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22862)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22862)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22928)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22928)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22954)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22954)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22931)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22931)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22900)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22900)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22840)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22840)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22914)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22914)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22966)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22966)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22836)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22836)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22930)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22930)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22902)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22902)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22853)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22853)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22865)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22865)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22850)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22850)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22910)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22910)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22934)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22934)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22835)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22835)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22923)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22923)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22845)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22845)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22844)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22844)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22864)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22864)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22838)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22838)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22964)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22964)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22841)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22841)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22948)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22948)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22911)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22911)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22933)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22933)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22876)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22876)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22872)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22872)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22855)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22855)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22915)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22915)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22839)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22839)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22857)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22857)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22942)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22942)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22867)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22867)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22859)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22859)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22945)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22945)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22909)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22909)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22904)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22904)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22870)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22870)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22843)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22843)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22903)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22903)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22906)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22906)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_0dc04_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-11_03-16-30
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 1edfe1009e7b4967a981e3872905f242
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.1838255865233285
        entropy_coeff: 0.0
        kl: 0.005123625609225461
        model: {}
        policy_loss: -0.003837728376051278
        total_loss: 660.8492170061384
        vf_explained_var: 0.0902143344283104
        vf_loss: 660.8520377022879
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.89090909090909
    gpu_util_percent0: 0.2518181818181818
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.00022727272727272727
    ram_util_percent: 6.299999999999998
    vram_util_percent0: 0.1927084886251826
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 22956
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16980170320308882
    mean_env_wait_ms: 1.1880714402371033
    mean_inference_ms: 5.713334827004998
    mean_raw_obs_processing_ms: 0.45447362209036246
  time_since_restore: 37.41455316543579
  time_this_iter_s: 37.41455316543579
  time_total_s: 37.41455316543579
  timers:
    learn_throughput: 5750.065
    learn_time_ms: 28137.419
    sample_throughput: 17577.097
    sample_time_ms: 9204.705
    update_time_ms: 31.264
  timestamp: 1602386190
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 0dc04_00000
  
== Status ==
Memory usage on this node: 48.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0dc04_00000 | RUNNING  | 172.17.0.4:22956 |      1 |          37.4146 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0dc04_00000:
  custom_metrics:
    time_step_max: 4080
    time_step_mean: 3594.9305555555557
    time_step_min: 3325
  date: 2020-10-11_03-17-06
  done: false
  episode_len_mean: 889.6518987341772
  episode_reward_max: 262.23232323232264
  episode_reward_mean: 218.7949431019049
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 1edfe1009e7b4967a981e3872905f242
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.1572047642299108
        entropy_coeff: 0.0
        kl: 0.007015603527958904
        model: {}
        policy_loss: -0.0058796150499672096
        total_loss: 312.24219185965404
        vf_explained_var: 0.5080538988113403
        vf_loss: 312.2466561453683
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.33095238095238
    gpu_util_percent0: 0.27999999999999997
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.473809523809523
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 22956
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16542327386489405
    mean_env_wait_ms: 1.1844152574947795
    mean_inference_ms: 5.468043873407652
    mean_raw_obs_processing_ms: 0.44277127468203153
  time_since_restore: 72.74755239486694
  time_this_iter_s: 35.33299922943115
  time_total_s: 72.74755239486694
  timers:
    learn_throughput: 5805.18
    learn_time_ms: 27870.281
    sample_throughput: 19187.893
    sample_time_ms: 8431.984
    update_time_ms: 26.495
  timestamp: 1602386226
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 0dc04_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0dc04_00000 | RUNNING  | 172.17.0.4:22956 |      2 |          72.7476 | 323584 |  218.795 |              262.232 |              145.717 |            889.652 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0dc04_00000:
  custom_metrics:
    time_step_max: 4080
    time_step_mean: 3591.087443946188
    time_step_min: 3291
  date: 2020-10-11_03-17-41
  done: false
  episode_len_mean: 884.1877637130801
  episode_reward_max: 267.3838383838379
  episode_reward_mean: 220.57588543664468
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 1edfe1009e7b4967a981e3872905f242
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.1512408341680254
        entropy_coeff: 0.0
        kl: 0.004928208022777524
        model: {}
        policy_loss: -0.005212505034121152
        total_loss: 124.27872576032367
        vf_explained_var: 0.7686433792114258
        vf_loss: 124.28295298985073
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.63170731707317
    gpu_util_percent0: 0.37097560975609756
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.487804878048781
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 22956
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1628296415353504
    mean_env_wait_ms: 1.1836508306938975
    mean_inference_ms: 5.302416114104748
    mean_raw_obs_processing_ms: 0.43582449570462195
  time_since_restore: 107.90744090080261
  time_this_iter_s: 35.15988850593567
  time_total_s: 107.90744090080261
  timers:
    learn_throughput: 5819.498
    learn_time_ms: 27801.709
    sample_throughput: 19985.954
    sample_time_ms: 8095.285
    update_time_ms: 25.752
  timestamp: 1602386261
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 0dc04_00000
  
== Status ==
Memory usage on this node: 48.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0dc04_00000 | RUNNING  | 172.17.0.4:22956 |      3 |          107.907 | 485376 |  220.576 |              267.384 |              145.717 |            884.188 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0dc04_00000:
  custom_metrics:
    time_step_max: 4080
    time_step_mean: 3589.417218543046
    time_step_min: 3291
  date: 2020-10-11_03-18-16
  done: false
  episode_len_mean: 880.3196202531645
  episode_reward_max: 268.5959595959594
  episode_reward_mean: 221.07102672292524
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 1edfe1009e7b4967a981e3872905f242
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.1345034071377345
        entropy_coeff: 0.0
        kl: 0.00957657037568944
        model: {}
        policy_loss: -0.005718629524510886
        total_loss: 81.81211144583565
        vf_explained_var: 0.8472751975059509
        vf_loss: 81.8168705531529
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.233333333333334
    gpu_util_percent0: 0.3064285714285714
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497619047619047
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 22956
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1610433747079125
    mean_env_wait_ms: 1.1839339965841398
    mean_inference_ms: 5.184102894087632
    mean_raw_obs_processing_ms: 0.4304530306499491
  time_since_restore: 143.31403827667236
  time_this_iter_s: 35.40659737586975
  time_total_s: 143.31403827667236
  timers:
    learn_throughput: 5815.068
    learn_time_ms: 27822.893
    sample_throughput: 20396.423
    sample_time_ms: 7932.371
    update_time_ms: 25.616
  timestamp: 1602386296
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 0dc04_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0dc04_00000 | RUNNING  | 172.17.0.4:22956 |      4 |          143.314 | 647168 |  221.071 |              268.596 |              145.717 |             880.32 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0dc04_00000:
  custom_metrics:
    time_step_max: 4080
    time_step_mean: 3584.766404199475
    time_step_min: 3274
  date: 2020-10-11_03-18-52
  done: false
  episode_len_mean: 876.1075949367089
  episode_reward_max: 279.6565656565653
  episode_reward_mean: 222.0762050888631
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 1edfe1009e7b4967a981e3872905f242
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.105091120515551
        entropy_coeff: 0.0
        kl: 0.008119648854647363
        model: {}
        policy_loss: -0.004397567432273978
        total_loss: 67.3666261945452
        vf_explained_var: 0.8779516816139221
        vf_loss: 67.37020983014789
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.092682926829266
    gpu_util_percent0: 0.2980487804878049
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.490243902439025
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 22956
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1596923763288986
    mean_env_wait_ms: 1.185351246852981
    mean_inference_ms: 5.095410770683593
    mean_raw_obs_processing_ms: 0.42620113820821054
  time_since_restore: 178.46047234535217
  time_this_iter_s: 35.14643406867981
  time_total_s: 178.46047234535217
  timers:
    learn_throughput: 5823.182
    learn_time_ms: 27784.123
    sample_throughput: 20655.11
    sample_time_ms: 7833.026
    update_time_ms: 27.319
  timestamp: 1602386332
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 0dc04_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0dc04_00000 | RUNNING  | 172.17.0.4:22956 |      5 |           178.46 | 808960 |  222.076 |              279.657 |              145.717 |            876.108 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0dc04_00000:
  custom_metrics:
    time_step_max: 4080
    time_step_mean: 3578.910780669145
    time_step_min: 3274
  date: 2020-10-11_03-19-27
  done: false
  episode_len_mean: 867.5280797101449
  episode_reward_max: 279.6565656565653
  episode_reward_mean: 223.80964536671038
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 314
  episodes_total: 1104
  experiment_id: 1edfe1009e7b4967a981e3872905f242
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.0982338615826197
        entropy_coeff: 0.0
        kl: 0.008503314240702562
        model: {}
        policy_loss: -0.004832364016692736
        total_loss: 70.46154349190849
        vf_explained_var: 0.9111862778663635
        vf_loss: 70.46552385602679
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.726190476190474
    gpu_util_percent0: 0.2857142857142857
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.488095238095238
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 22956
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15791164698283808
    mean_env_wait_ms: 1.1893611582813273
    mean_inference_ms: 4.975458654706248
    mean_raw_obs_processing_ms: 0.420589283944223
  time_since_restore: 213.72042441368103
  time_this_iter_s: 35.25995206832886
  time_total_s: 213.72042441368103
  timers:
    learn_throughput: 5827.694
    learn_time_ms: 27762.612
    sample_throughput: 20801.351
    sample_time_ms: 7777.956
    update_time_ms: 29.578
  timestamp: 1602386367
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 0dc04_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0dc04_00000 | RUNNING  | 172.17.0.4:22956 |      6 |           213.72 | 970752 |   223.81 |              279.657 |              145.717 |            867.528 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0dc04_00000:
  custom_metrics:
    time_step_max: 4080
    time_step_mean: 3572.7548543689322
    time_step_min: 3274
  date: 2020-10-11_03-20-02
  done: false
  episode_len_mean: 862.3132911392405
  episode_reward_max: 279.6565656565653
  episode_reward_mean: 224.92315560669974
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 160
  episodes_total: 1264
  experiment_id: 1edfe1009e7b4967a981e3872905f242
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.0894856878689356
        entropy_coeff: 0.0
        kl: 0.010974461611892496
        model: {}
        policy_loss: -0.003228063029902322
        total_loss: 45.71440151759556
        vf_explained_var: 0.911666214466095
        vf_loss: 45.716531208583284
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.557142857142857
    gpu_util_percent0: 0.33809523809523806
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.492857142857143
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 22956
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15725788013216982
    mean_env_wait_ms: 1.191331855929368
    mean_inference_ms: 4.932357228303018
    mean_raw_obs_processing_ms: 0.41859933230663443
  time_since_restore: 249.0735535621643
  time_this_iter_s: 35.353129148483276
  time_total_s: 249.0735535621643
  timers:
    learn_throughput: 5827.915
    learn_time_ms: 27761.56
    sample_throughput: 20930.862
    sample_time_ms: 7729.83
    update_time_ms: 39.676
  timestamp: 1602386402
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 0dc04_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0dc04_00000 | RUNNING  | 172.17.0.4:22956 |      7 |          249.074 | 1132544 |  224.923 |              279.657 |              145.717 |            862.313 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0dc04_00000:
  custom_metrics:
    time_step_max: 4080
    time_step_mean: 3565.4756097560976
    time_step_min: 3274
  date: 2020-10-11_03-20-38
  done: false
  episode_len_mean: 857.1104078762306
  episode_reward_max: 279.6565656565653
  episode_reward_mean: 226.15552145931875
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 1edfe1009e7b4967a981e3872905f242
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.0650211998394556
        entropy_coeff: 0.0
        kl: 0.009266908812735761
        model: {}
        policy_loss: -0.004585698369607728
        total_loss: 40.49679183959961
        vf_explained_var: 0.9189044833183289
        vf_loss: 40.5004517691476
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.339024390243903
    gpu_util_percent0: 0.3148780487804878
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.487804878048781
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 22956
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15669652941420725
    mean_env_wait_ms: 1.1932611805402924
    mean_inference_ms: 4.895377642819281
    mean_raw_obs_processing_ms: 0.4168503412286156
  time_since_restore: 284.60115361213684
  time_this_iter_s: 35.527600049972534
  time_total_s: 284.60115361213684
  timers:
    learn_throughput: 5824.099
    learn_time_ms: 27779.747
    sample_throughput: 20997.08
    sample_time_ms: 7705.452
    update_time_ms: 39.41
  timestamp: 1602386438
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 0dc04_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0dc04_00000 | RUNNING  | 172.17.0.4:22956 |      8 |          284.601 | 1294336 |  226.156 |              279.657 |              145.717 |             857.11 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0dc04_00000:
  custom_metrics:
    time_step_max: 4080
    time_step_mean: 3558.3498711340208
    time_step_min: 3220
  date: 2020-10-11_03-21-13
  done: false
  episode_len_mean: 852.0436708860759
  episode_reward_max: 279.6565656565653
  episode_reward_mean: 227.26780462856394
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 1edfe1009e7b4967a981e3872905f242
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.0094214252063207
        entropy_coeff: 0.0
        kl: 0.009210781460361821
        model: {}
        policy_loss: -0.006029469322779083
        total_loss: 36.66504423958914
        vf_explained_var: 0.9308019280433655
        vf_loss: 36.67015130179269
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.307142857142857
    gpu_util_percent0: 0.28309523809523807
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.490476190476191
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 22956
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1562166852021763
    mean_env_wait_ms: 1.1953551919551808
    mean_inference_ms: 4.863029660881274
    mean_raw_obs_processing_ms: 0.41524640196337936
  time_since_restore: 319.8040885925293
  time_this_iter_s: 35.202934980392456
  time_total_s: 319.8040885925293
  timers:
    learn_throughput: 5826.852
    learn_time_ms: 27766.623
    sample_throughput: 21069.417
    sample_time_ms: 7678.997
    update_time_ms: 37.298
  timestamp: 1602386473
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 0dc04_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0dc04_00000 | RUNNING  | 172.17.0.4:22956 |      9 |          319.804 | 1456128 |  227.268 |              279.657 |              145.717 |            852.044 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0dc04_00000:
  custom_metrics:
    time_step_max: 4080
    time_step_mean: 3545.6504282655246
    time_step_min: 3220
  date: 2020-10-11_03-21-49
  done: false
  episode_len_mean: 842.2162447257384
  episode_reward_max: 279.6565656565653
  episode_reward_mean: 229.38486127093705
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 316
  episodes_total: 1896
  experiment_id: 1edfe1009e7b4967a981e3872905f242
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.0125895398003715
        entropy_coeff: 0.0
        kl: 0.008327819473509277
        model: {}
        policy_loss: -0.004357009458804636
        total_loss: 36.54181889125279
        vf_explained_var: 0.9532211422920227
        vf_loss: 36.545343671526226
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.823809523809523
    gpu_util_percent0: 0.39642857142857146
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.485714285714285
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 22956
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15543499124064247
    mean_env_wait_ms: 1.1997856738677577
    mean_inference_ms: 4.810261446871581
    mean_raw_obs_processing_ms: 0.41272995683494673
  time_since_restore: 355.36015152931213
  time_this_iter_s: 35.55606293678284
  time_total_s: 355.36015152931213
  timers:
    learn_throughput: 5823.728
    learn_time_ms: 27781.517
    sample_throughput: 21120.576
    sample_time_ms: 7660.397
    update_time_ms: 41.717
  timestamp: 1602386509
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 0dc04_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0dc04_00000 | RUNNING  | 172.17.0.4:22956 |     10 |           355.36 | 1617920 |  229.385 |              279.657 |              145.717 |            842.216 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0dc04_00000:
  custom_metrics:
    time_step_max: 4080
    time_step_mean: 3538.908193484699
    time_step_min: 3215
  date: 2020-10-11_03-22-24
  done: false
  episode_len_mean: 837.815481986368
  episode_reward_max: 279.6565656565653
  episode_reward_mean: 230.44172985945121
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: 1edfe1009e7b4967a981e3872905f242
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.0025906605379922
        entropy_coeff: 0.0
        kl: 0.008006592015070575
        model: {}
        policy_loss: -0.004433066376285362
        total_loss: 23.926629066467285
        vf_explained_var: 0.9545801281929016
        vf_loss: 23.930261203220912
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.090243902439024
    gpu_util_percent0: 0.3475609756097561
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.495121951219511
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 22956
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1551135379000783
    mean_env_wait_ms: 1.2017582126496293
    mean_inference_ms: 4.788395864840217
    mean_raw_obs_processing_ms: 0.41166208205559246
  time_since_restore: 390.55320835113525
  time_this_iter_s: 35.19305682182312
  time_total_s: 390.55320835113525
  timers:
    learn_throughput: 5834.935
    learn_time_ms: 27728.158
    sample_throughput: 21602.898
    sample_time_ms: 7489.366
    update_time_ms: 42.589
  timestamp: 1602386544
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 0dc04_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0dc04_00000 | RUNNING  | 172.17.0.4:22956 |     11 |          390.553 | 1779712 |  230.442 |              279.657 |              145.717 |            837.815 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0dc04_00000:
  custom_metrics:
    time_step_max: 4080
    time_step_mean: 3530.5540293040294
    time_step_min: 3215
  date: 2020-10-11_03-22-59
  done: false
  episode_len_mean: 833.5917721518987
  episode_reward_max: 279.6565656565653
  episode_reward_mean: 231.64098946060955
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 1edfe1009e7b4967a981e3872905f242
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.9661155428205218
        entropy_coeff: 0.0
        kl: 0.008635765141142266
        model: {}
        policy_loss: -0.003959545424939799
        total_loss: 21.736254828316824
        vf_explained_var: 0.9547680616378784
        vf_loss: 21.739350863865443
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.90731707317073
    gpu_util_percent0: 0.27512195121951216
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.504878048780488
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 22956
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1548215597102703
    mean_env_wait_ms: 1.2037092759738723
    mean_inference_ms: 4.768544502294656
    mean_raw_obs_processing_ms: 0.41064599665676993
  time_since_restore: 425.7749168872833
  time_this_iter_s: 35.22170853614807
  time_total_s: 425.7749168872833
  timers:
    learn_throughput: 5831.415
    learn_time_ms: 27744.895
    sample_throughput: 21686.87
    sample_time_ms: 7460.367
    update_time_ms: 42.978
  timestamp: 1602386579
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 0dc04_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0dc04_00000 | RUNNING  | 172.17.0.4:22956 |     12 |          425.775 | 1941504 |  231.641 |              279.657 |              145.717 |            833.592 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0dc04_00000:
  custom_metrics:
    time_step_max: 4080
    time_step_mean: 3515.7078831532613
    time_step_min: 3181
  date: 2020-10-11_03-23-34
  done: false
  episode_len_mean: 826.5092995647012
  episode_reward_max: 284.05050505050514
  episode_reward_mean: 233.83429466808948
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 315
  episodes_total: 2527
  experiment_id: 1edfe1009e7b4967a981e3872905f242
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.9296429881027767
        entropy_coeff: 0.0
        kl: 0.007966382362480675
        model: {}
        policy_loss: -0.004952899105514267
        total_loss: 25.18915843963623
        vf_explained_var: 0.9677068591117859
        vf_loss: 25.19331455230713
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.339024390243903
    gpu_util_percent0: 0.2768292682926829
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.490243902439025
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 22956
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1543249069166309
    mean_env_wait_ms: 1.2075536963805287
    mean_inference_ms: 4.734526212722419
    mean_raw_obs_processing_ms: 0.4089152834564709
  time_since_restore: 460.76481318473816
  time_this_iter_s: 34.989896297454834
  time_total_s: 460.76481318473816
  timers:
    learn_throughput: 5831.635
    learn_time_ms: 27743.85
    sample_throughput: 21738.15
    sample_time_ms: 7442.768
    update_time_ms: 43.859
  timestamp: 1602386614
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 0dc04_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0dc04_00000 | RUNNING  | 172.17.0.4:22956 |     13 |          460.765 | 2103296 |  233.834 |              284.051 |              145.717 |            826.509 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0dc04_00000:
  custom_metrics:
    time_step_max: 4080
    time_step_mean: 3508.122648607976
    time_step_min: 3181
  date: 2020-10-11_03-24-10
  done: false
  episode_len_mean: 823.4311243484735
  episode_reward_max: 284.05050505050514
  episode_reward_mean: 234.91243785584794
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 159
  episodes_total: 2686
  experiment_id: 1edfe1009e7b4967a981e3872905f242
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.9134626345975059
        entropy_coeff: 0.0
        kl: 0.009398104356867927
        model: {}
        policy_loss: -0.004814401742935713
        total_loss: 16.088700907570974
        vf_explained_var: 0.9687336683273315
        vf_loss: 16.092575277600968
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.424390243902437
    gpu_util_percent0: 0.38365853658536586
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497560975609756
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 22956
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15410616175828218
    mean_env_wait_ms: 1.209267968127377
    mean_inference_ms: 4.719699621054436
    mean_raw_obs_processing_ms: 0.4081737985941971
  time_since_restore: 496.0957841873169
  time_this_iter_s: 35.330971002578735
  time_total_s: 496.0957841873169
  timers:
    learn_throughput: 5834.149
    learn_time_ms: 27731.893
    sample_throughput: 21726.047
    sample_time_ms: 7446.914
    update_time_ms: 43.072
  timestamp: 1602386650
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 0dc04_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0dc04_00000 | RUNNING  | 172.17.0.4:22956 |     14 |          496.096 | 2265088 |  234.912 |              284.051 |              145.717 |            823.431 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0dc04_00000:
  custom_metrics:
    time_step_max: 4080
    time_step_mean: 3501.4009232954545
    time_step_min: 3181
  date: 2020-10-11_03-24-46
  done: false
  episode_len_mean: 820.5615330520394
  episode_reward_max: 287.23232323232315
  episode_reward_mean: 235.87092443421545
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: 1edfe1009e7b4967a981e3872905f242
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.8881498319762093
        entropy_coeff: 0.0
        kl: 0.00791315667863403
        model: {}
        policy_loss: -0.004214695557103758
        total_loss: 15.485446180616107
        vf_explained_var: 0.9675639271736145
        vf_loss: 15.48886946269444
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.707142857142856
    gpu_util_percent0: 0.24500000000000002
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.502380952380953
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 22956
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1539031346472525
    mean_env_wait_ms: 1.2108754568580902
    mean_inference_ms: 4.706005620589642
    mean_raw_obs_processing_ms: 0.40745444737915776
  time_since_restore: 531.568413734436
  time_this_iter_s: 35.47262954711914
  time_total_s: 531.568413734436
  timers:
    learn_throughput: 5827.748
    learn_time_ms: 27762.353
    sample_throughput: 21728.971
    sample_time_ms: 7445.912
    update_time_ms: 43.741
  timestamp: 1602386686
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 0dc04_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0dc04_00000 | RUNNING  | 172.17.0.4:22956 |     15 |          531.568 | 2426880 |  235.871 |              287.232 |              145.717 |            820.562 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0dc04_00000:
  custom_metrics:
    time_step_max: 4080
    time_step_mean: 3488.435602428891
    time_step_min: 3181
  date: 2020-10-11_03-25-21
  done: false
  episode_len_mean: 815.5793474817865
  episode_reward_max: 287.23232323232315
  episode_reward_mean: 237.7060180519159
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 313
  episodes_total: 3157
  experiment_id: 1edfe1009e7b4967a981e3872905f242
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.8468168250152043
        entropy_coeff: 0.0
        kl: 0.007454350923321077
        model: {}
        policy_loss: -0.004882199462112372
        total_loss: 20.091411318097794
        vf_explained_var: 0.9729297757148743
        vf_loss: 20.095547948564803
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.20731707317073
    gpu_util_percent0: 0.44414634146341475
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.482926829268293
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 22956
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15354654122469283
    mean_env_wait_ms: 1.2139831357812272
    mean_inference_ms: 4.681837317360474
    mean_raw_obs_processing_ms: 0.4061852947150054
  time_since_restore: 566.9930398464203
  time_this_iter_s: 35.42462611198425
  time_total_s: 566.9930398464203
  timers:
    learn_throughput: 5825.36
    learn_time_ms: 27773.736
    sample_throughput: 21716.663
    sample_time_ms: 7450.132
    update_time_ms: 44.675
  timestamp: 1602386721
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 0dc04_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0dc04_00000 | RUNNING  | 172.17.0.4:22956 |     16 |          566.993 | 2588672 |  237.706 |              287.232 |              145.717 |            815.579 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0dc04_00000:
  custom_metrics:
    time_step_max: 4080
    time_step_mean: 3483.193313069909
    time_step_min: 3181
  date: 2020-10-11_03-25-57
  done: true
  episode_len_mean: 813.4544906570223
  episode_reward_max: 287.23232323232315
  episode_reward_mean: 238.50280380660112
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 161
  episodes_total: 3318
  experiment_id: 1edfe1009e7b4967a981e3872905f242
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.8455609466348376
        entropy_coeff: 0.0
        kl: 0.007612316636368632
        model: {}
        policy_loss: -0.003928348072804511
        total_loss: 14.146584510803223
        vf_explained_var: 0.9723100066184998
        vf_loss: 14.149751458849225
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.11904761904762
    gpu_util_percent0: 0.29928571428571427
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4976190476190485
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 22956
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1533850848043274
    mean_env_wait_ms: 1.2154402943717482
    mean_inference_ms: 4.670917595831944
    mean_raw_obs_processing_ms: 0.40561085519542545
  time_since_restore: 602.5003592967987
  time_this_iter_s: 35.50731945037842
  time_total_s: 602.5003592967987
  timers:
    learn_throughput: 5822.233
    learn_time_ms: 27788.652
    sample_throughput: 21695.702
    sample_time_ms: 7457.33
    update_time_ms: 37.388
  timestamp: 1602386757
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 0dc04_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0dc04_00000 | TERMINATED |       |     17 |            602.5 | 2750464 |  238.503 |              287.232 |              145.717 |            813.454 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0dc04_00000 | TERMINATED |       |     17 |            602.5 | 2750464 |  238.503 |              287.232 |              145.717 |            813.454 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


