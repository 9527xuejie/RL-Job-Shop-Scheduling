2020-10-12 07:55:23,655	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_4935d_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=47316)[0m F1012 07:55:25.842725 47316 47316 service_based_gcs_client.cc:207] Couldn't reconnect to GCS server. The last attempted GCS server address was 172.17.0.4:35227
[2m[36m(pid=47316)[0m *** Check failure stack trace: ***
[2m[36m(pid=47316)[0m     @     0x7f050a1296ed  google::LogMessage::Fail()
[2m[36m(pid=47316)[0m     @     0x7f050a12a84c  google::LogMessage::SendToLog()
[2m[36m(pid=47316)[0m     @     0x7f050a1293c9  google::LogMessage::Flush()
[2m[36m(pid=47316)[0m     @     0x7f050a1295e1  google::LogMessage::~LogMessage()
[2m[36m(pid=47316)[0m     @     0x7f050a0e0789  ray::RayLog::~RayLog()
[2m[36m(pid=47316)[0m     @     0x7f0509e241ea  ray::gcs::ServiceBasedGcsClient::ReconnectGcsServer()
[2m[36m(pid=47316)[0m     @     0x7f0509e242ef  ray::gcs::ServiceBasedGcsClient::GcsServiceFailureDetected()
[2m[36m(pid=47316)[0m     @     0x7f0509e24491  ray::gcs::ServiceBasedGcsClient::PeriodicallyCheckGcsServerAddress()
[2m[36m(pid=47316)[0m     @     0x7f0509e26801  ray::gcs::ServiceBasedGcsClient::Connect()
[2m[36m(pid=47316)[0m     @     0x7f0509da7ed6  ray::CoreWorker::CoreWorker()
[2m[36m(pid=47316)[0m     @     0x7f0509dabc14  ray::CoreWorkerProcess::CreateWorker()
[2m[36m(pid=47316)[0m     @     0x7f0509dace82  ray::CoreWorkerProcess::CoreWorkerProcess()
[2m[36m(pid=47316)[0m     @     0x7f0509dad84b  ray::CoreWorkerProcess::Initialize()
[2m[36m(pid=47316)[0m     @     0x7f0509ceb448  __pyx_pw_3ray_7_raylet_10CoreWorker_1__cinit__()
[2m[36m(pid=47316)[0m     @     0x7f0509cecba5  __pyx_tp_new_3ray_7_raylet_CoreWorker()
[2m[36m(pid=47316)[0m     @     0x5624df60137d  _PyObject_MakeTpCall
[2m[36m(pid=47316)[0m     @     0x5624df689d09  _PyEval_EvalFrameDefault
[2m[36m(pid=47316)[0m     @     0x5624df64ebaf  _PyEval_EvalCodeWithName
[2m[36m(pid=47316)[0m     @     0x5624df64f643  _PyFunction_Vectorcall.localalias.353
[2m[36m(pid=47316)[0m     @     0x5624df5c4de6  _PyEval_EvalFrameDefault.cold.2792
[2m[36m(pid=47316)[0m     @     0x5624df64e6a2  _PyEval_EvalCodeWithName
[2m[36m(pid=47316)[0m     @     0x5624df64f454  PyEval_EvalCodeEx
[2m[36m(pid=47316)[0m     @     0x5624df6ddbbc  PyEval_EvalCode
[2m[36m(pid=47316)[0m     @     0x5624df6ddc64  run_eval_code_obj
[2m[36m(pid=47316)[0m     @     0x5624df70fd14  run_mod
[2m[36m(pid=47316)[0m     @     0x5624df5d8625  PyRun_FileExFlags
[2m[36m(pid=47316)[0m     @     0x5624df5d8a0a  PyRun_SimpleFileExFlags
[2m[36m(pid=47316)[0m     @     0x5624df5d98cf  Py_RunMain.cold.2911
[2m[36m(pid=47316)[0m     @     0x5624df712829  Py_BytesMain
[2m[36m(pid=47316)[0m     @     0x7f050b42e840  __libc_start_main
[2m[36m(pid=47316)[0m     @     0x5624df6a2b33  (unknown)
[2m[36m(pid=47416)[0m 2020-10-12 07:55:26,358	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=47424)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47424)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47408)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47408)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47406)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47406)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47390)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47390)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47379)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47379)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47359)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47359)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47415)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47415)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47386)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47386)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47401)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47401)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47313)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47313)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47404)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47404)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47290)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47290)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47301)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47301)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47321)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47321)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47317)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47317)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47354)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47354)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47419)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47419)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47309)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47309)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47388)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47388)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47295)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47295)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47326)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47326)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47399)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47399)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47385)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47385)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47420)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47420)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47362)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47362)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47298)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47298)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47365)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47365)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47394)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47394)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47358)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47358)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47368)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47368)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47396)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47396)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47384)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47384)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47413)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47413)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47289)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47289)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47296)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47296)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47306)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47306)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47374)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47374)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47329)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47329)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47364)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47364)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47299)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47299)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47353)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47353)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47303)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47303)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47375)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47375)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47345)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47345)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47322)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47322)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47293)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47293)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47371)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47371)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47376)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47376)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47287)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47287)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47411)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47411)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47398)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47398)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47304)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47304)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47305)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47305)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47389)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47389)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47369)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47369)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47315)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47315)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47393)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47393)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47357)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47357)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47351)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47351)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47292)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47292)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47325)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47325)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47360)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47360)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47286)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47286)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47347)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47347)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47312)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47312)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47355)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47355)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47300)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47300)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47288)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47288)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47383)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47383)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47291)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47291)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47302)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47302)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47366)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47366)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47372)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47372)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47367)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47367)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47356)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47356)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47361)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47361)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47403)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47403)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47363)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47363)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48709)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48709)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_4935d_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-12_07-55-56
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 6ea347bd390343169770bb0ae7eaccbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1858798464139302
        entropy_coeff: 0.0010000000000000002
        kl: 0.004064181082261105
        model: {}
        policy_loss: -0.006395086013526452
        total_loss: 514.7333170572916
        vf_explained_var: 0.4917435944080353
        vf_loss: 514.7400767008463
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.325
    gpu_util_percent0: 0.2092857142857143
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.521428571428572
    vram_util_percent0: 0.0827847537834419
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47416
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1714163571458129
    mean_env_wait_ms: 1.1807994247771
    mean_inference_ms: 6.147634724696208
    mean_raw_obs_processing_ms: 0.4624706714673703
  time_since_restore: 24.50074791908264
  time_this_iter_s: 24.50074791908264
  time_total_s: 24.50074791908264
  timers:
    learn_throughput: 10802.415
    learn_time_ms: 14977.391
    sample_throughput: 17107.315
    sample_time_ms: 9457.475
    update_time_ms: 31.281
  timestamp: 1602489356
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 4935d_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |      1 |          24.5007 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4935d_00000:
  custom_metrics:
    time_step_max: 4152
    time_step_mean: 3627.0208333333335
    time_step_min: 3371
  date: 2020-10-12_07-56-18
  done: false
  episode_len_mean: 890.1550632911392
  episode_reward_max: 261.3232323232323
  episode_reward_mean: 216.59365809998698
  episode_reward_min: 136.92929292929247
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 6ea347bd390343169770bb0ae7eaccbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1566268702348073
        entropy_coeff: 0.0010000000000000002
        kl: 0.0074133020437632995
        model: {}
        policy_loss: -0.006318914315973719
        total_loss: 150.94015757242838
        vf_explained_var: 0.7832780480384827
        vf_loss: 150.94689814249674
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.403846153846153
    gpu_util_percent0: 0.2919230769230769
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.738461538461538
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47416
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16644640977929873
    mean_env_wait_ms: 1.1752532318633375
    mean_inference_ms: 5.803889831603577
    mean_raw_obs_processing_ms: 0.44867825635494135
  time_since_restore: 46.78164482116699
  time_this_iter_s: 22.28089690208435
  time_total_s: 46.78164482116699
  timers:
    learn_throughput: 10923.565
    learn_time_ms: 14811.282
    sample_throughput: 19007.513
    sample_time_ms: 8512.003
    update_time_ms: 24.435
  timestamp: 1602489378
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 4935d_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |      2 |          46.7816 | 323584 |  216.594 |              261.323 |              136.929 |            890.155 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4935d_00000:
  custom_metrics:
    time_step_max: 4152
    time_step_mean: 3626.109865470852
    time_step_min: 3272
  date: 2020-10-12_07-56-40
  done: false
  episode_len_mean: 884.9831223628692
  episode_reward_max: 270.2626262626259
  episode_reward_mean: 216.85513361462705
  episode_reward_min: 131.47474747474718
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 6ea347bd390343169770bb0ae7eaccbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1470215519269307
        entropy_coeff: 0.0010000000000000002
        kl: 0.00852755201049149
        model: {}
        policy_loss: -0.009047169092809781
        total_loss: 76.8135159810384
        vf_explained_var: 0.8726572394371033
        vf_loss: 76.82285753885905
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.192000000000004
    gpu_util_percent0: 0.3004
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.76
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47416
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16333984937915608
    mean_env_wait_ms: 1.1739520111463604
    mean_inference_ms: 5.565249658448001
    mean_raw_obs_processing_ms: 0.4384964806056524
  time_since_restore: 68.35362577438354
  time_this_iter_s: 21.571980953216553
  time_total_s: 68.35362577438354
  timers:
    learn_throughput: 11013.223
    learn_time_ms: 14690.705
    sample_throughput: 20158.612
    sample_time_ms: 8025.949
    update_time_ms: 22.645
  timestamp: 1602489400
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 4935d_00000
  
== Status ==
Memory usage on this node: 28.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |      3 |          68.3536 | 485376 |  216.855 |              270.263 |              131.475 |            884.983 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4935d_00000:
  custom_metrics:
    time_step_max: 4152
    time_step_mean: 3616.112582781457
    time_step_min: 3272
  date: 2020-10-12_07-57-01
  done: false
  episode_len_mean: 880.873417721519
  episode_reward_max: 270.2626262626259
  episode_reward_mean: 217.44137578314778
  episode_reward_min: 131.47474747474718
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 6ea347bd390343169770bb0ae7eaccbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1285836795965831
        entropy_coeff: 0.0010000000000000002
        kl: 0.00767273692569385
        model: {}
        policy_loss: -0.010500759337446652
        total_loss: 59.14047654469808
        vf_explained_var: 0.8996696472167969
        vf_loss: 59.15133762359619
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.415999999999993
    gpu_util_percent0: 0.2936
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.764
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47416
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16111490150136074
    mean_env_wait_ms: 1.1737004337712953
    mean_inference_ms: 5.3947826177609235
    mean_raw_obs_processing_ms: 0.430652089513709
  time_since_restore: 89.98465132713318
  time_this_iter_s: 21.631025552749634
  time_total_s: 89.98465132713318
  timers:
    learn_throughput: 10998.429
    learn_time_ms: 14710.464
    sample_throughput: 20976.687
    sample_time_ms: 7712.944
    update_time_ms: 25.621
  timestamp: 1602489421
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 4935d_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |      4 |          89.9847 | 647168 |  217.441 |              270.263 |              131.475 |            880.873 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4935d_00000:
  custom_metrics:
    time_step_max: 4152
    time_step_mean: 3609.715223097113
    time_step_min: 3272
  date: 2020-10-12_07-57-23
  done: false
  episode_len_mean: 876.7126582278481
  episode_reward_max: 270.86868686868655
  episode_reward_mean: 219.01483186293294
  episode_reward_min: 131.47474747474718
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 6ea347bd390343169770bb0ae7eaccbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0982058942317963
        entropy_coeff: 0.0010000000000000002
        kl: 0.007201045867986977
        model: {}
        policy_loss: -0.010341917989232266
        total_loss: 42.64804267883301
        vf_explained_var: 0.9292742609977722
        vf_loss: 42.65876293182373
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.268
    gpu_util_percent0: 0.41200000000000003
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.764
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47416
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15946129373348403
    mean_env_wait_ms: 1.1745178858430907
    mean_inference_ms: 5.267336295216427
    mean_raw_obs_processing_ms: 0.42471797495802377
  time_since_restore: 111.63249826431274
  time_this_iter_s: 21.647846937179565
  time_total_s: 111.63249826431274
  timers:
    learn_throughput: 10988.215
    learn_time_ms: 14724.138
    sample_throughput: 21486.438
    sample_time_ms: 7529.959
    update_time_ms: 24.854
  timestamp: 1602489443
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 4935d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |      5 |          111.632 | 808960 |  219.015 |              270.869 |              131.475 |            876.713 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4935d_00000:
  custom_metrics:
    time_step_max: 4188
    time_step_mean: 3587.309412861137
    time_step_min: 3208
  date: 2020-10-12_07-57-45
  done: false
  episode_len_mean: 867.2933696639419
  episode_reward_max: 279.95959595959596
  episode_reward_mean: 222.83136542537073
  episode_reward_min: 131.47474747474718
  episodes_this_iter: 311
  episodes_total: 1101
  experiment_id: 6ea347bd390343169770bb0ae7eaccbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.089649925629298
        entropy_coeff: 0.0010000000000000002
        kl: 0.007361165403078
        model: {}
        policy_loss: -0.009514839436936503
        total_loss: 46.27031675974528
        vf_explained_var: 0.943225085735321
        vf_loss: 46.28018538157145
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.864000000000004
    gpu_util_percent0: 0.3748
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.764
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47416
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15725032607004152
    mean_env_wait_ms: 1.1776184097035538
    mean_inference_ms: 5.098571486930799
    mean_raw_obs_processing_ms: 0.4170828285387513
  time_since_restore: 133.61357593536377
  time_this_iter_s: 21.981077671051025
  time_total_s: 133.61357593536377
  timers:
    learn_throughput: 10942.983
    learn_time_ms: 14784.999
    sample_throughput: 21830.619
    sample_time_ms: 7411.242
    update_time_ms: 23.625
  timestamp: 1602489465
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 4935d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |      6 |          133.614 | 970752 |  222.831 |               279.96 |              131.475 |            867.293 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4935d_00000:
  custom_metrics:
    time_step_max: 4188
    time_step_mean: 3576.204692556634
    time_step_min: 3208
  date: 2020-10-12_07-58-07
  done: false
  episode_len_mean: 863.2911392405064
  episode_reward_max: 279.95959595959596
  episode_reward_mean: 224.62120412990652
  episode_reward_min: 131.47474747474718
  episodes_this_iter: 163
  episodes_total: 1264
  experiment_id: 6ea347bd390343169770bb0ae7eaccbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.078253577152888
        entropy_coeff: 0.0010000000000000002
        kl: 0.00760688950928549
        model: {}
        policy_loss: -0.00808424704397718
        total_loss: 24.090112050374348
        vf_explained_var: 0.9561929702758789
        vf_loss: 24.098513921101887
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.566666666666666
    gpu_util_percent0: 0.29375
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7708333333333335
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47416
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1564654163893213
    mean_env_wait_ms: 1.1790260759751634
    mean_inference_ms: 5.035471631648462
    mean_raw_obs_processing_ms: 0.4142370056618957
  time_since_restore: 155.21138048171997
  time_this_iter_s: 21.5978045463562
  time_total_s: 155.21138048171997
  timers:
    learn_throughput: 10958.033
    learn_time_ms: 14764.693
    sample_throughput: 22056.652
    sample_time_ms: 7335.293
    update_time_ms: 23.414
  timestamp: 1602489487
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 4935d_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |      7 |          155.211 | 1132544 |  224.621 |               279.96 |              131.475 |            863.291 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4935d_00000:
  custom_metrics:
    time_step_max: 4188
    time_step_mean: 3563.761836441894
    time_step_min: 3208
  date: 2020-10-12_07-58-28
  done: false
  episode_len_mean: 859.7215189873418
  episode_reward_max: 279.95959595959596
  episode_reward_mean: 226.28391510037065
  episode_reward_min: 131.47474747474718
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 6ea347bd390343169770bb0ae7eaccbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0665611525376637
        entropy_coeff: 0.0010000000000000002
        kl: 0.007063437098016341
        model: {}
        policy_loss: -0.011236034988542087
        total_loss: 23.269086996714275
        vf_explained_var: 0.9564061164855957
        vf_loss: 23.280683676401775
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.136
    gpu_util_percent0: 0.2932
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.76
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47416
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15580133340075322
    mean_env_wait_ms: 1.180217866621754
    mean_inference_ms: 4.983044491631497
    mean_raw_obs_processing_ms: 0.411793605828682
  time_since_restore: 176.72998452186584
  time_this_iter_s: 21.518604040145874
  time_total_s: 176.72998452186584
  timers:
    learn_throughput: 10960.775
    learn_time_ms: 14761.0
    sample_throughput: 22300.07
    sample_time_ms: 7255.224
    update_time_ms: 25.162
  timestamp: 1602489508
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 4935d_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |      8 |           176.73 | 1294336 |  226.284 |               279.96 |              131.475 |            859.722 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4935d_00000:
  custom_metrics:
    time_step_max: 4188
    time_step_mean: 3554.637886597938
    time_step_min: 3208
  date: 2020-10-12_07-58-50
  done: false
  episode_len_mean: 856.3879746835443
  episode_reward_max: 279.95959595959596
  episode_reward_mean: 227.5292162127604
  episode_reward_min: 131.47474747474718
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 6ea347bd390343169770bb0ae7eaccbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0308950543403625
        entropy_coeff: 0.0010000000000000002
        kl: 0.0075525245629251
        model: {}
        policy_loss: -0.009404902209401675
        total_loss: 19.759908358256023
        vf_explained_var: 0.9632963538169861
        vf_loss: 19.769589106241863
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.592
    gpu_util_percent0: 0.4132
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7640000000000002
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47416
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15522609255515757
    mean_env_wait_ms: 1.1813788429250602
    mean_inference_ms: 4.93757485426149
    mean_raw_obs_processing_ms: 0.4096284903807881
  time_since_restore: 198.41875982284546
  time_this_iter_s: 21.688775300979614
  time_total_s: 198.41875982284546
  timers:
    learn_throughput: 10952.147
    learn_time_ms: 14772.628
    sample_throughput: 22477.809
    sample_time_ms: 7197.855
    update_time_ms: 25.989
  timestamp: 1602489530
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 4935d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |      9 |          198.419 | 1456128 |  227.529 |               279.96 |              131.475 |            856.388 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4935d_00000:
  custom_metrics:
    time_step_max: 4188
    time_step_mean: 3536.35698808234
    time_step_min: 3151
  date: 2020-10-12_07-59-12
  done: false
  episode_len_mean: 849.9642475987193
  episode_reward_max: 288.59595959595976
  episode_reward_mean: 230.30434548257375
  episode_reward_min: 131.47474747474718
  episodes_this_iter: 294
  episodes_total: 1874
  experiment_id: 6ea347bd390343169770bb0ae7eaccbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0002753188212712
        entropy_coeff: 0.0010000000000000002
        kl: 0.007455945403004686
        model: {}
        policy_loss: -0.010204158699101148
        total_loss: 24.197932084401447
        vf_explained_var: 0.9683513641357422
        vf_loss: 24.208391030629475
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.928
    gpu_util_percent0: 0.29960000000000003
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.756
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47416
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15436430506291107
    mean_env_wait_ms: 1.1838305992833973
    mean_inference_ms: 4.868544754944554
    mean_raw_obs_processing_ms: 0.4063909084512901
  time_since_restore: 220.12364220619202
  time_this_iter_s: 21.704882383346558
  time_total_s: 220.12364220619202
  timers:
    learn_throughput: 10949.037
    learn_time_ms: 14776.825
    sample_throughput: 22602.127
    sample_time_ms: 7158.264
    update_time_ms: 26.962
  timestamp: 1602489552
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 4935d_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     10 |          220.124 | 1617920 |  230.304 |              288.596 |              131.475 |            849.964 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4935d_00000:
  custom_metrics:
    time_step_max: 4188
    time_step_mean: 3525.1461006910167
    time_step_min: 3151
  date: 2020-10-12_07-59-34
  done: false
  episode_len_mean: 846.1324245374879
  episode_reward_max: 288.59595959595976
  episode_reward_mean: 232.04503162098086
  episode_reward_min: 131.47474747474718
  episodes_this_iter: 180
  episodes_total: 2054
  experiment_id: 6ea347bd390343169770bb0ae7eaccbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9904046803712845
        entropy_coeff: 0.0010000000000000002
        kl: 0.00673914875369519
        model: {}
        policy_loss: -0.00991532149297806
        total_loss: 13.990095853805542
        vf_explained_var: 0.9738118648529053
        vf_loss: 14.000327746073404
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.933333333333334
    gpu_util_percent0: 0.29000000000000004
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.775
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47416
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15391489145310477
    mean_env_wait_ms: 1.1852050260285005
    mean_inference_ms: 4.834181265578874
    mean_raw_obs_processing_ms: 0.4047779605513047
  time_since_restore: 241.79468941688538
  time_this_iter_s: 21.67104721069336
  time_total_s: 241.79468941688538
  timers:
    learn_throughput: 10963.723
    learn_time_ms: 14757.031
    sample_throughput: 23472.344
    sample_time_ms: 6892.878
    update_time_ms: 27.456
  timestamp: 1602489574
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 4935d_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     11 |          241.795 | 1779712 |  232.045 |              288.596 |              131.475 |            846.132 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4935d_00000:
  custom_metrics:
    time_step_max: 4188
    time_step_mean: 3516.3241758241757
    time_step_min: 3151
  date: 2020-10-12_07-59-56
  done: false
  episode_len_mean: 843.4877938517179
  episode_reward_max: 288.59595959595976
  episode_reward_mean: 233.29224432388978
  episode_reward_min: 131.47474747474718
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 6ea347bd390343169770bb0ae7eaccbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9801873713731766
        entropy_coeff: 0.0010000000000000002
        kl: 0.006010051351040602
        model: {}
        policy_loss: -0.009126228047534823
        total_loss: 15.280177116394043
        vf_explained_var: 0.97007817029953
        vf_loss: 15.289682388305664
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.676923076923075
    gpu_util_percent0: 0.3492307692307693
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7576923076923077
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47416
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15356980009174312
    mean_env_wait_ms: 1.1862927867683948
    mean_inference_ms: 4.807153098875207
    mean_raw_obs_processing_ms: 0.40347536671037615
  time_since_restore: 263.58598041534424
  time_this_iter_s: 21.791290998458862
  time_total_s: 263.58598041534424
  timers:
    learn_throughput: 10959.991
    learn_time_ms: 14762.056
    sample_throughput: 23687.883
    sample_time_ms: 6830.159
    update_time_ms: 27.684
  timestamp: 1602489596
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 4935d_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     12 |          263.586 | 1941504 |  233.292 |              288.596 |              131.475 |            843.488 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4935d_00000:
  custom_metrics:
    time_step_max: 4188
    time_step_mean: 3509.2247334754798
    time_step_min: 3147
  date: 2020-10-12_08-00-17
  done: false
  episode_len_mean: 841.2806573957016
  episode_reward_max: 289.2020202020203
  episode_reward_mean: 234.43851919958107
  episode_reward_min: 131.47474747474718
  episodes_this_iter: 161
  episodes_total: 2373
  experiment_id: 6ea347bd390343169770bb0ae7eaccbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9412872145573298
        entropy_coeff: 0.0010000000000000002
        kl: 0.006324911878133814
        model: {}
        policy_loss: -0.009316468562853212
        total_loss: 15.226327737172445
        vf_explained_var: 0.9722931385040283
        vf_loss: 15.235953092575073
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.983333333333334
    gpu_util_percent0: 0.27166666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7708333333333335
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47416
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15325367165896728
    mean_env_wait_ms: 1.187351681010106
    mean_inference_ms: 4.7823496059783706
    mean_raw_obs_processing_ms: 0.4022524139138643
  time_since_restore: 285.0491192340851
  time_this_iter_s: 21.463138818740845
  time_total_s: 285.0491192340851
  timers:
    learn_throughput: 10948.329
    learn_time_ms: 14777.781
    sample_throughput: 23786.854
    sample_time_ms: 6801.74
    update_time_ms: 29.054
  timestamp: 1602489617
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 4935d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     13 |          285.049 | 2103296 |  234.439 |              289.202 |              131.475 |            841.281 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4935d_00000:
  custom_metrics:
    time_step_max: 4188
    time_step_mean: 3494.709811320755
    time_step_min: 3147
  date: 2020-10-12_08-00-39
  done: false
  episode_len_mean: 837.9985063480209
  episode_reward_max: 289.2020202020203
  episode_reward_mean: 236.4201499686936
  episode_reward_min: 131.47474747474718
  episodes_this_iter: 305
  episodes_total: 2678
  experiment_id: 6ea347bd390343169770bb0ae7eaccbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9193607121706009
        entropy_coeff: 0.0010000000000000002
        kl: 0.005588505533523858
        model: {}
        policy_loss: -0.008722007876106849
        total_loss: 18.580758730570476
        vf_explained_var: 0.9753453135490417
        vf_loss: 18.589841842651367
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.628
    gpu_util_percent0: 0.2636
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.748
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47416
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1527339914723438
    mean_env_wait_ms: 1.1892359688684517
    mean_inference_ms: 4.741593468063049
    mean_raw_obs_processing_ms: 0.40029834826674837
  time_since_restore: 306.7374804019928
  time_this_iter_s: 21.688361167907715
  time_total_s: 306.7374804019928
  timers:
    learn_throughput: 10956.442
    learn_time_ms: 14766.838
    sample_throughput: 23724.753
    sample_time_ms: 6819.544
    update_time_ms: 27.668
  timestamp: 1602489639
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 4935d_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     14 |          306.737 | 2265088 |   236.42 |              289.202 |              131.475 |            837.999 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4935d_00000:
  custom_metrics:
    time_step_max: 4188
    time_step_mean: 3488.3952414772725
    time_step_min: 3147
  date: 2020-10-12_08-01-01
  done: false
  episode_len_mean: 836.292194092827
  episode_reward_max: 289.35353535353516
  episode_reward_mean: 237.4111686485104
  episode_reward_min: 131.47474747474718
  episodes_this_iter: 166
  episodes_total: 2844
  experiment_id: 6ea347bd390343169770bb0ae7eaccbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9131054629882177
        entropy_coeff: 0.0010000000000000002
        kl: 0.005497211551604171
        model: {}
        policy_loss: -0.007378635054919869
        total_loss: 11.72153385480245
        vf_explained_var: 0.9775063991546631
        vf_loss: 11.729275782903036
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.951999999999998
    gpu_util_percent0: 0.30200000000000005
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7720000000000002
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47416
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1524858565651682
    mean_env_wait_ms: 1.1901572464312566
    mean_inference_ms: 4.7225269139524615
    mean_raw_obs_processing_ms: 0.39938440810721976
  time_since_restore: 328.52804470062256
  time_this_iter_s: 21.79056429862976
  time_total_s: 328.52804470062256
  timers:
    learn_throughput: 10963.331
    learn_time_ms: 14757.558
    sample_throughput: 23645.81
    sample_time_ms: 6842.311
    update_time_ms: 27.3
  timestamp: 1602489661
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 4935d_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     15 |          328.528 | 2426880 |  237.411 |              289.354 |              131.475 |            836.292 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4935d_00000:
  custom_metrics:
    time_step_max: 4188
    time_step_mean: 3483.3301950235373
    time_step_min: 3147
  date: 2020-10-12_08-01-23
  done: false
  episode_len_mean: 834.7891405729514
  episode_reward_max: 290.56565656565647
  episode_reward_mean: 238.28404632601823
  episode_reward_min: 131.47474747474718
  episodes_this_iter: 158
  episodes_total: 3002
  experiment_id: 6ea347bd390343169770bb0ae7eaccbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9084820051987966
        entropy_coeff: 0.0010000000000000002
        kl: 0.006018294564758738
        model: {}
        policy_loss: -0.007524173070123652
        total_loss: 12.962319930394491
        vf_explained_var: 0.9735670685768127
        vf_loss: 12.97015110651652
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.04
    gpu_util_percent0: 0.3156
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.76
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47416
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15227382725048905
    mean_env_wait_ms: 1.19098373725698
    mean_inference_ms: 4.705735246407954
    mean_raw_obs_processing_ms: 0.39857025145429437
  time_since_restore: 350.29178285598755
  time_this_iter_s: 21.76373815536499
  time_total_s: 350.29178285598755
  timers:
    learn_throughput: 10974.293
    learn_time_ms: 14742.818
    sample_throughput: 23676.909
    sample_time_ms: 6833.324
    update_time_ms: 29.076
  timestamp: 1602489683
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 4935d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     16 |          350.292 | 2588672 |  238.284 |              290.566 |              131.475 |            834.789 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4935d_00000:
  custom_metrics:
    time_step_max: 4188
    time_step_mean: 3477.5213404995256
    time_step_min: 3147
  date: 2020-10-12_08-01-45
  done: false
  episode_len_mean: 832.9103729238483
  episode_reward_max: 290.56565656565647
  episode_reward_mean: 239.1295626272122
  episode_reward_min: 131.47474747474718
  episodes_this_iter: 189
  episodes_total: 3191
  experiment_id: 6ea347bd390343169770bb0ae7eaccbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8652510742346445
        entropy_coeff: 0.0010000000000000002
        kl: 0.005546345414283375
        model: {}
        policy_loss: -0.009394650240816796
        total_loss: 15.037363767623901
        vf_explained_var: 0.975414514541626
        vf_loss: 15.047069152196249
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.28
    gpu_util_percent0: 0.3452
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.76
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47416
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.152045327822301
    mean_env_wait_ms: 1.1919710779649575
    mean_inference_ms: 4.687307194280671
    mean_raw_obs_processing_ms: 0.39768841070955224
  time_since_restore: 372.28986644744873
  time_this_iter_s: 21.99808359146118
  time_total_s: 372.28986644744873
  timers:
    learn_throughput: 10951.776
    learn_time_ms: 14773.128
    sample_throughput: 23646.205
    sample_time_ms: 6842.197
    update_time_ms: 29.179
  timestamp: 1602489705
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 4935d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     17 |           372.29 | 2750464 |   239.13 |              290.566 |              131.475 |             832.91 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4935d_00000:
  custom_metrics:
    time_step_max: 4188
    time_step_mean: 3470.0330818340103
    time_step_min: 3147
  date: 2020-10-12_08-02-07
  done: false
  episode_len_mean: 830.6729994242947
  episode_reward_max: 290.56565656565647
  episode_reward_mean: 240.3484150660316
  episode_reward_min: 131.47474747474718
  episodes_this_iter: 283
  episodes_total: 3474
  experiment_id: 6ea347bd390343169770bb0ae7eaccbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8562458703915278
        entropy_coeff: 0.0010000000000000002
        kl: 0.0056136711888636155
        model: {}
        policy_loss: -0.008814311237074435
        total_loss: 12.922985871632894
        vf_explained_var: 0.9803910255432129
        vf_loss: 12.932095050811768
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.131999999999998
    gpu_util_percent0: 0.3864
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.752
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47416
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15173502064916347
    mean_env_wait_ms: 1.1933266139357905
    mean_inference_ms: 4.662769914171586
    mean_raw_obs_processing_ms: 0.3964979335973578
  time_since_restore: 394.223580121994
  time_this_iter_s: 21.933713674545288
  time_total_s: 394.223580121994
  timers:
    learn_throughput: 10942.497
    learn_time_ms: 14785.656
    sample_throughput: 23545.734
    sample_time_ms: 6871.393
    update_time_ms: 27.489
  timestamp: 1602489727
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 4935d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     18 |          394.224 | 2912256 |  240.348 |              290.566 |              131.475 |            830.673 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4935d_00000:
  custom_metrics:
    time_step_max: 4188
    time_step_mean: 3465.9986134220744
    time_step_min: 3147
  date: 2020-10-12_08-02-29
  done: false
  episode_len_mean: 829.3965327462851
  episode_reward_max: 290.56565656565647
  episode_reward_mean: 240.93648093482983
  episode_reward_min: 131.47474747474718
  episodes_this_iter: 160
  episodes_total: 3634
  experiment_id: 6ea347bd390343169770bb0ae7eaccbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8458269933859507
        entropy_coeff: 0.0010000000000000002
        kl: 0.005238918277124564
        model: {}
        policy_loss: -0.008863923489116132
        total_loss: 11.462480147679647
        vf_explained_var: 0.9772316813468933
        vf_loss: 11.47166625658671
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.348
    gpu_util_percent0: 0.2864
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.764
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47416
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15157817273439375
    mean_env_wait_ms: 1.194051067524682
    mean_inference_ms: 4.650287496491038
    mean_raw_obs_processing_ms: 0.3958943252438647
  time_since_restore: 415.73195481300354
  time_this_iter_s: 21.50837469100952
  time_total_s: 415.73195481300354
  timers:
    learn_throughput: 10966.22
    learn_time_ms: 14753.671
    sample_throughput: 23498.986
    sample_time_ms: 6885.063
    update_time_ms: 26.453
  timestamp: 1602489749
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 4935d_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     19 |          415.732 | 3074048 |  240.936 |              290.566 |              131.475 |            829.397 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4935d_00000:
  custom_metrics:
    time_step_max: 4188
    time_step_mean: 3461.7851261620185
    time_step_min: 3147
  date: 2020-10-12_08-02-51
  done: false
  episode_len_mean: 828.2813076720274
  episode_reward_max: 290.56565656565647
  episode_reward_mean: 241.56190963151147
  episode_reward_min: 131.47474747474718
  episodes_this_iter: 159
  episodes_total: 3793
  experiment_id: 6ea347bd390343169770bb0ae7eaccbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8354400197664896
        entropy_coeff: 0.0010000000000000002
        kl: 0.006724536186084151
        model: {}
        policy_loss: -0.00911139192370077
        total_loss: 11.11555004119873
        vf_explained_var: 0.9771101474761963
        vf_loss: 11.1248246828715
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.765384615384612
    gpu_util_percent0: 0.42576923076923073
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.765384615384615
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47416
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15143153977037152
    mean_env_wait_ms: 1.19475205207732
    mean_inference_ms: 4.638693538397803
    mean_raw_obs_processing_ms: 0.39532808620572457
  time_since_restore: 437.7973186969757
  time_this_iter_s: 22.065363883972168
  time_total_s: 437.7973186969757
  timers:
    learn_throughput: 10956.318
    learn_time_ms: 14767.004
    sample_throughput: 23424.906
    sample_time_ms: 6906.837
    update_time_ms: 25.358
  timestamp: 1602489771
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 4935d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     20 |          437.797 | 3235840 |  241.562 |              290.566 |              131.475 |            828.281 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4935d_00000:
  custom_metrics:
    time_step_max: 4188
    time_step_mean: 3454.446708074534
    time_step_min: 3147
  date: 2020-10-12_08-03-13
  done: false
  episode_len_mean: 826.1258327165062
  episode_reward_max: 290.56565656565647
  episode_reward_mean: 242.65150393647795
  episode_reward_min: 131.47474747474718
  episodes_this_iter: 260
  episodes_total: 4053
  experiment_id: 6ea347bd390343169770bb0ae7eaccbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8038722376028696
        entropy_coeff: 0.0010000000000000002
        kl: 0.005003524556135138
        model: {}
        policy_loss: -0.007377958051317061
        total_loss: 13.692698876063028
        vf_explained_var: 0.9796187877655029
        vf_loss: 13.700380086898804
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.34
    gpu_util_percent0: 0.42400000000000004
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.752
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47416
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15121696352248112
    mean_env_wait_ms: 1.1958913902831356
    mean_inference_ms: 4.621158716371925
    mean_raw_obs_processing_ms: 0.39449719521269605
  time_since_restore: 459.43015336990356
  time_this_iter_s: 21.632834672927856
  time_total_s: 459.43015336990356
  timers:
    learn_throughput: 10961.455
    learn_time_ms: 14760.085
    sample_throughput: 23418.203
    sample_time_ms: 6908.814
    update_time_ms: 25.193
  timestamp: 1602489793
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: 4935d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     21 |           459.43 | 3397632 |  242.652 |              290.566 |              131.475 |            826.126 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4935d_00000:
  custom_metrics:
    time_step_max: 4188
    time_step_mean: 3448.8378952336006
    time_step_min: 3147
  date: 2020-10-12_08-03-35
  done: false
  episode_len_mean: 824.4301453352086
  episode_reward_max: 290.56565656565647
  episode_reward_mean: 243.4875974939266
  episode_reward_min: 131.47474747474718
  episodes_this_iter: 213
  episodes_total: 4266
  experiment_id: 6ea347bd390343169770bb0ae7eaccbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7977566868066788
        entropy_coeff: 0.0010000000000000002
        kl: 0.005455355780820052
        model: {}
        policy_loss: -0.00767945071614425
        total_loss: 10.277512709299723
        vf_explained_var: 0.9814075827598572
        vf_loss: 10.285443782806396
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.120000000000005
    gpu_util_percent0: 0.3268
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.752
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47416
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15104737207579993
    mean_env_wait_ms: 1.1967581522595114
    mean_inference_ms: 4.608215003769806
    mean_raw_obs_processing_ms: 0.39386805388018364
  time_since_restore: 481.1195831298828
  time_this_iter_s: 21.689429759979248
  time_total_s: 481.1195831298828
  timers:
    learn_throughput: 10962.993
    learn_time_ms: 14758.014
    sample_throughput: 23448.37
    sample_time_ms: 6899.925
    update_time_ms: 25.154
  timestamp: 1602489815
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: 4935d_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     22 |           481.12 | 3559424 |  243.488 |              290.566 |              131.475 |             824.43 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4935d_00000:
  custom_metrics:
    time_step_max: 4188
    time_step_mean: 3444.6345235387766
    time_step_min: 3147
  date: 2020-10-12_08-03-57
  done: false
  episode_len_mean: 823.2205649717514
  episode_reward_max: 290.56565656565647
  episode_reward_mean: 244.06426981681216
  episode_reward_min: 131.47474747474718
  episodes_this_iter: 159
  episodes_total: 4425
  experiment_id: 6ea347bd390343169770bb0ae7eaccbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8060282667477926
        entropy_coeff: 0.0010000000000000002
        kl: 0.005679386241051058
        model: {}
        policy_loss: -0.010035674378741533
        total_loss: 10.034321387608847
        vf_explained_var: 0.978935182094574
        vf_loss: 10.044595638910929
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.368000000000002
    gpu_util_percent0: 0.29960000000000003
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.76
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47416
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15093291820308186
    mean_env_wait_ms: 1.1973932493733186
    mean_inference_ms: 4.599187677452534
    mean_raw_obs_processing_ms: 0.3934317186327627
  time_since_restore: 502.85791778564453
  time_this_iter_s: 21.73833465576172
  time_total_s: 502.85791778564453
  timers:
    learn_throughput: 10957.609
    learn_time_ms: 14765.265
    sample_throughput: 23407.54
    sample_time_ms: 6911.961
    update_time_ms: 23.641
  timestamp: 1602489837
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: 4935d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     23 |          502.858 | 3721216 |  244.064 |              290.566 |              131.475 |            823.221 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4935d_00000:
  custom_metrics:
    time_step_max: 4188
    time_step_mean: 3439.959219088937
    time_step_min: 3147
  date: 2020-10-12_08-04-18
  done: false
  episode_len_mean: 821.3749460974558
  episode_reward_max: 290.56565656565647
  episode_reward_mean: 244.75604035177128
  episode_reward_min: 131.47474747474718
  episodes_this_iter: 213
  episodes_total: 4638
  experiment_id: 6ea347bd390343169770bb0ae7eaccbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7703086733818054
        entropy_coeff: 0.0010000000000000002
        kl: 0.005429171995880703
        model: {}
        policy_loss: -0.007289163496655722
        total_loss: 12.348905007044474
        vf_explained_var: 0.979224681854248
        vf_loss: 12.356421629587809
    num_steps_sampled: 3883008
    num_steps_trained: 3883008
  iterations_since_restore: 24
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.8125
    gpu_util_percent0: 0.43249999999999994
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7541666666666664
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47416
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15079284947059365
    mean_env_wait_ms: 1.1982450189298106
    mean_inference_ms: 4.587776541874426
    mean_raw_obs_processing_ms: 0.3928856835406434
  time_since_restore: 524.5500221252441
  time_this_iter_s: 21.69210433959961
  time_total_s: 524.5500221252441
  timers:
    learn_throughput: 10957.433
    learn_time_ms: 14765.502
    sample_throughput: 23416.047
    sample_time_ms: 6909.45
    update_time_ms: 25.924
  timestamp: 1602489858
  timesteps_since_restore: 0
  timesteps_total: 3883008
  training_iteration: 24
  trial_id: 4935d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     24 |           524.55 | 3883008 |  244.756 |              290.566 |              131.475 |            821.375 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4935d_00000:
  custom_metrics:
    time_step_max: 4188
    time_step_mean: 3434.701314708299
    time_step_min: 3147
  date: 2020-10-12_08-04-41
  done: false
  episode_len_mean: 819.6397058823529
  episode_reward_max: 290.56565656565647
  episode_reward_mean: 245.61130298078825
  episode_reward_min: 131.47474747474718
  episodes_this_iter: 258
  episodes_total: 4896
  experiment_id: 6ea347bd390343169770bb0ae7eaccbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7541884630918503
        entropy_coeff: 0.0010000000000000002
        kl: 0.004939307885554929
        model: {}
        policy_loss: -0.008982530465194335
        total_loss: 9.952500502268473
        vf_explained_var: 0.9837613105773926
        vf_loss: 9.961743275324503
    num_steps_sampled: 4044800
    num_steps_trained: 4044800
  iterations_since_restore: 25
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.99230769230769
    gpu_util_percent0: 0.29961538461538456
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.75
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47416
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15062599456951525
    mean_env_wait_ms: 1.1992428855480324
    mean_inference_ms: 4.575118912763768
    mean_raw_obs_processing_ms: 0.39227961602231826
  time_since_restore: 546.621901512146
  time_this_iter_s: 22.071879386901855
  time_total_s: 546.621901512146
  timers:
    learn_throughput: 10944.955
    learn_time_ms: 14782.336
    sample_throughput: 23415.435
    sample_time_ms: 6909.63
    update_time_ms: 27.731
  timestamp: 1602489881
  timesteps_since_restore: 0
  timesteps_total: 4044800
  training_iteration: 25
  trial_id: 4935d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     25 |          546.622 | 4044800 |  245.611 |              290.566 |              131.475 |             819.64 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4935d_00000:
  custom_metrics:
    time_step_max: 4188
    time_step_mean: 3431.5177008750993
    time_step_min: 3147
  date: 2020-10-12_08-05-02
  done: false
  episode_len_mean: 818.6079905063291
  episode_reward_max: 290.56565656565647
  episode_reward_mean: 246.10366121659632
  episode_reward_min: 131.47474747474718
  episodes_this_iter: 160
  episodes_total: 5056
  experiment_id: 6ea347bd390343169770bb0ae7eaccbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.0e-05
        entropy: 0.7627150317033132
        entropy_coeff: 0.0010000000000000002
        kl: 0.006050152898145218
        model: {}
        policy_loss: -0.009301517896043757
        total_loss: 8.128399848937988
        vf_explained_var: 0.9824613928794861
        vf_loss: 8.138161698977152
    num_steps_sampled: 4206592
    num_steps_trained: 4206592
  iterations_since_restore: 26
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.45416666666667
    gpu_util_percent0: 0.245
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7708333333333335
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47416
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1505320904163101
    mean_env_wait_ms: 1.1998304190756985
    mean_inference_ms: 4.567782822219138
    mean_raw_obs_processing_ms: 0.3919296307204451
  time_since_restore: 568.2212522029877
  time_this_iter_s: 21.599350690841675
  time_total_s: 568.2212522029877
  timers:
    learn_throughput: 10956.324
    learn_time_ms: 14766.997
    sample_throughput: 23417.631
    sample_time_ms: 6908.982
    update_time_ms: 26.463
  timestamp: 1602489902
  timesteps_since_restore: 0
  timesteps_total: 4206592
  training_iteration: 26
  trial_id: 4935d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     26 |          568.221 | 4206592 |  246.104 |              290.566 |              131.475 |            818.608 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4935d_00000:
  custom_metrics:
    time_step_max: 4188
    time_step_mean: 3428.084934665642
    time_step_min: 3147
  date: 2020-10-12_08-05-24
  done: false
  episode_len_mean: 817.4225917431193
  episode_reward_max: 290.56565656565647
  episode_reward_mean: 246.58821008247608
  episode_reward_min: 131.47474747474718
  episodes_this_iter: 176
  episodes_total: 5232
  experiment_id: 6ea347bd390343169770bb0ae7eaccbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.0e-05
        entropy: 0.7432082245747248
        entropy_coeff: 0.0010000000000000002
        kl: 0.005775055265985429
        model: {}
        policy_loss: -0.009028180410192968
        total_loss: 9.281757434209188
        vf_explained_var: 0.982418954372406
        vf_loss: 9.291240135828653
    num_steps_sampled: 4368384
    num_steps_trained: 4368384
  iterations_since_restore: 27
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.484000000000005
    gpu_util_percent0: 0.29919999999999997
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.764
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47416
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15043915088222498
    mean_env_wait_ms: 1.2004804583814097
    mean_inference_ms: 4.56007833511155
    mean_raw_obs_processing_ms: 0.3915655176555837
  time_since_restore: 589.9885222911835
  time_this_iter_s: 21.7672700881958
  time_total_s: 589.9885222911835
  timers:
    learn_throughput: 10958.884
    learn_time_ms: 14763.547
    sample_throughput: 23485.785
    sample_time_ms: 6888.933
    update_time_ms: 26.0
  timestamp: 1602489924
  timesteps_since_restore: 0
  timesteps_total: 4368384
  training_iteration: 27
  trial_id: 4935d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     27 |          589.989 | 4368384 |  246.588 |              290.566 |              131.475 |            817.423 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4935d_00000:
  custom_metrics:
    time_step_max: 4188
    time_step_mean: 3423.254469171835
    time_step_min: 3145
  date: 2020-10-12_08-05-46
  done: true
  episode_len_mean: 815.7878402903812
  episode_reward_max: 290.56565656565647
  episode_reward_mean: 247.24255256741642
  episode_reward_min: 131.47474747474718
  episodes_this_iter: 278
  episodes_total: 5510
  experiment_id: 6ea347bd390343169770bb0ae7eaccbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.0e-05
        entropy: 0.7183508972326914
        entropy_coeff: 0.0010000000000000002
        kl: 0.005954385424653689
        model: {}
        policy_loss: -0.007631552017604311
        total_loss: 10.137248754501343
        vf_explained_var: 0.9847092032432556
        vf_loss: 10.14530062675476
    num_steps_sampled: 4530176
    num_steps_trained: 4530176
  iterations_since_restore: 28
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.072
    gpu_util_percent0: 0.36760000000000004
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.756
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47416
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15029441536490598
    mean_env_wait_ms: 1.2014855944746754
    mean_inference_ms: 4.548813510251206
    mean_raw_obs_processing_ms: 0.39103728768479246
  time_since_restore: 611.7375376224518
  time_this_iter_s: 21.74901533126831
  time_total_s: 611.7375376224518
  timers:
    learn_throughput: 10953.469
    learn_time_ms: 14770.846
    sample_throughput: 23575.025
    sample_time_ms: 6862.856
    update_time_ms: 25.694
  timestamp: 1602489946
  timesteps_since_restore: 0
  timesteps_total: 4530176
  training_iteration: 28
  trial_id: 4935d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4935d_00000 | TERMINATED |       |     28 |          611.738 | 4530176 |  247.243 |              290.566 |              131.475 |            815.788 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4935d_00000 | TERMINATED |       |     28 |          611.738 | 4530176 |  247.243 |              290.566 |              131.475 |            815.788 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


