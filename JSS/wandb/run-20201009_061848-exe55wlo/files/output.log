2020-10-09 06:18:50,788	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8270[39m[22m
== Status ==
Memory usage on this node: 57.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_4d314_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=54085)[0m F1009 06:18:52.978750 54085 54085 service_based_gcs_client.cc:207] Couldn't reconnect to GCS server. The last attempted GCS server address was 172.17.0.4:46451
[2m[36m(pid=54085)[0m *** Check failure stack trace: ***
[2m[36m(pid=54085)[0m     @     0x7f39940836ed  google::LogMessage::Fail()
[2m[36m(pid=54085)[0m     @     0x7f399408484c  google::LogMessage::SendToLog()
[2m[36m(pid=54085)[0m     @     0x7f39940833c9  google::LogMessage::Flush()
[2m[36m(pid=54085)[0m     @     0x7f39940835e1  google::LogMessage::~LogMessage()
[2m[36m(pid=54085)[0m     @     0x7f399403a789  ray::RayLog::~RayLog()
[2m[36m(pid=54085)[0m     @     0x7f3993d7e1ea  ray::gcs::ServiceBasedGcsClient::ReconnectGcsServer()
[2m[36m(pid=54085)[0m     @     0x7f3993d7e2ef  ray::gcs::ServiceBasedGcsClient::GcsServiceFailureDetected()
[2m[36m(pid=54085)[0m     @     0x7f3993d7e491  ray::gcs::ServiceBasedGcsClient::PeriodicallyCheckGcsServerAddress()
[2m[36m(pid=54110)[0m F1009 06:18:52.974747 54110 54110 service_based_gcs_client.cc:207] Couldn't reconnect to GCS server. The last attempted GCS server address was 172.17.0.4:46451
[2m[36m(pid=54110)[0m *** Check failure stack trace: ***
[2m[36m(pid=54110)[0m     @     0x7fb5f58a26ed  google::LogMessage::Fail()
[2m[36m(pid=54110)[0m     @     0x7fb5f58a384c  google::LogMessage::SendToLog()
[2m[36m(pid=54110)[0m     @     0x7fb5f58a23c9  google::LogMessage::Flush()
[2m[36m(pid=54110)[0m     @     0x7fb5f58a25e1  google::LogMessage::~LogMessage()
[2m[36m(pid=54110)[0m     @     0x7fb5f5859789  ray::RayLog::~RayLog()
[2m[36m(pid=54110)[0m     @     0x7fb5f559d1ea  ray::gcs::ServiceBasedGcsClient::ReconnectGcsServer()
[2m[36m(pid=54110)[0m     @     0x7fb5f559d2ef  ray::gcs::ServiceBasedGcsClient::GcsServiceFailureDetected()
[2m[36m(pid=54110)[0m     @     0x7fb5f559d491  ray::gcs::ServiceBasedGcsClient::PeriodicallyCheckGcsServerAddress()
[2m[36m(pid=54110)[0m     @     0x7fb5f559f801  ray::gcs::ServiceBasedGcsClient::Connect()
[2m[36m(pid=54110)[0m     @     0x7fb5f5520ed6  ray::CoreWorker::CoreWorker()
[2m[36m(pid=54110)[0m     @     0x7fb5f5524c14  ray::CoreWorkerProcess::CreateWorker()
[2m[36m(pid=54110)[0m     @     0x7fb5f5525e82  ray::CoreWorkerProcess::CoreWorkerProcess()
[2m[36m(pid=54110)[0m     @     0x7fb5f552684b  ray::CoreWorkerProcess::Initialize()
[2m[36m(pid=54110)[0m     @     0x7fb5f5464448  __pyx_pw_3ray_7_raylet_10CoreWorker_1__cinit__()
[2m[36m(pid=54110)[0m     @     0x7fb5f5465ba5  __pyx_tp_new_3ray_7_raylet_CoreWorker()
[2m[36m(pid=54110)[0m     @     0x56459e3b137d  _PyObject_MakeTpCall
[2m[36m(pid=54085)[0m     @     0x7f3993d80801  ray::gcs::ServiceBasedGcsClient::Connect()
[2m[36m(pid=54085)[0m     @     0x7f3993c8f7a8  ray::gcs::GlobalStateAccessor::Connect()
[2m[36m(pid=54085)[0m     @     0x7f3993c00a2c  __pyx_pw_3ray_7_raylet_19GlobalStateAccessor_3connect()
[2m[36m(pid=54085)[0m     @     0x560fc95a798a  method_vectorcall_NOARGS
[2m[36m(pid=54085)[0m     @     0x560fc9537b08  _PyEval_EvalFrameDefault.cold.2792
[2m[36m(pid=54085)[0m     @     0x560fc95c26a2  _PyEval_EvalCodeWithName
[2m[36m(pid=54085)[0m     @     0x560fc95c3a20  method_vectorcall
[2m[36m(pid=54085)[0m     @     0x560fc9538de6  _PyEval_EvalFrameDefault.cold.2792
[2m[36m(pid=54085)[0m     @     0x560fc95c2baf  _PyEval_EvalCodeWithName
[2m[36m(pid=54085)[0m     @     0x560fc95c3643  _PyFunction_Vectorcall.localalias.353
[2m[36m(pid=54085)[0m     @     0x560fc9538de6  _PyEval_EvalFrameDefault.cold.2792
[2m[36m(pid=54085)[0m     @     0x560fc95c26a2  _PyEval_EvalCodeWithName
[2m[36m(pid=54085)[0m     @     0x560fc95c3454  PyEval_EvalCodeEx
[2m[36m(pid=54085)[0m     @     0x560fc9651bbc  PyEval_EvalCode
[2m[36m(pid=54085)[0m     @     0x560fc9651c64  run_eval_code_obj
[2m[36m(pid=54085)[0m     @     0x560fc9683d14  run_mod
[2m[36m(pid=54085)[0m     @     0x560fc954c625  PyRun_FileExFlags
[2m[36m(pid=54085)[0m     @     0x560fc954ca0a  PyRun_SimpleFileExFlags
[2m[36m(pid=54085)[0m     @     0x560fc954d8cf  Py_RunMain.cold.2911
[2m[36m(pid=54085)[0m     @     0x560fc9686829  Py_BytesMain
[2m[36m(pid=54110)[0m     @     0x56459e439d09  _PyEval_EvalFrameDefault
[2m[36m(pid=54110)[0m     @     0x56459e3febaf  _PyEval_EvalCodeWithName
[2m[36m(pid=54110)[0m     @     0x56459e3ff643  _PyFunction_Vectorcall.localalias.353
[2m[36m(pid=54110)[0m     @     0x56459e374de6  _PyEval_EvalFrameDefault.cold.2792
[2m[36m(pid=54110)[0m     @     0x56459e3fe6a2  _PyEval_EvalCodeWithName
[2m[36m(pid=54110)[0m     @     0x56459e3ff454  PyEval_EvalCodeEx
[2m[36m(pid=54110)[0m     @     0x56459e48dbbc  PyEval_EvalCode
[2m[36m(pid=54110)[0m     @     0x56459e48dc64  run_eval_code_obj
[2m[36m(pid=54110)[0m     @     0x56459e4bfd14  run_mod
[2m[36m(pid=54110)[0m     @     0x56459e388625  PyRun_FileExFlags
[2m[36m(pid=54110)[0m     @     0x56459e388a0a  PyRun_SimpleFileExFlags
[2m[36m(pid=54110)[0m     @     0x56459e3898cf  Py_RunMain.cold.2911
[2m[36m(pid=54110)[0m     @     0x56459e4c2829  Py_BytesMain
[2m[36m(pid=54110)[0m     @     0x7fb5f6ba7840  __libc_start_main
[2m[36m(pid=54085)[0m     @     0x7f3995388840  __libc_start_main
[2m[36m(pid=54085)[0m     @     0x560fc9616b33  (unknown)
[2m[36m(pid=54110)[0m     @     0x56459e452b33  (unknown)
[2m[33m(pid=raylet)[0m E1009 06:18:53.135697 54043 54043 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer
[2m[33m(pid=raylet)[0m E1009 06:18:53.161396 54043 54043 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer
[2m[36m(pid=54226)[0m 2020-10-09 06:18:53,786	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=54188)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54188)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54234)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54234)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54224)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54224)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54192)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54192)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54205)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54205)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54191)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54191)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54230)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54230)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54194)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54194)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54211)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54211)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54171)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54171)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54217)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54217)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54177)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54177)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54198)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54198)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54178)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54178)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54216)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54216)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54222)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54222)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54168)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54168)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54118)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54118)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54120)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54120)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54084)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54084)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54080)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54080)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54105)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54105)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54165)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54165)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55497)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55497)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54087)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54087)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54150)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54150)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54163)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54163)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54176)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54176)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54083)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54083)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54081)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54081)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54082)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54082)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54122)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54122)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54212)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54212)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54175)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54175)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54196)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54196)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54169)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54169)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55498)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55498)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54166)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54166)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54114)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54114)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54164)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54164)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54170)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54170)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54155)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54155)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54160)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54160)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54152)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54152)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54219)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54219)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54153)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54153)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54167)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54167)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54125)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54125)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54090)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54090)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54089)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54089)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54161)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54161)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54100)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54100)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54162)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54162)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54173)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54173)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54207)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54207)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54190)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54190)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54098)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54098)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54109)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54109)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54092)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54092)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54091)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54091)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54088)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54088)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54199)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54199)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54172)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54172)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54094)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54094)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54206)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54206)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54209)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54209)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54116)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54116)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54095)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54095)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54154)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54154)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54232)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54232)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54174)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54174)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54093)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54093)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54115)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54115)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54179)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54179)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54086)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54086)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54187)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54187)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54096)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54096)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54112)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54112)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=54182)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=54182)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_4d314_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3225.0
  date: 2020-10-09_06-20-41
  done: false
  episode_len_mean: 875.496835443038
  episode_reward_max: 284.79797979797996
  episode_reward_mean: 227.93504666922368
  episode_reward_min: 147.0606060606061
  episodes_this_iter: 316
  episodes_total: 316
  experiment_id: d3ccebdf66b8463d9e4f33d5747f3bc7
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999993
        cur_lr: 0.00010000000000000003
        entropy: 1.1603806788408304
        entropy_coeff: 0.0
        kl: 0.009258272904383986
        model: {}
        policy_loss: -0.04042428985968986
        total_loss: 474.5804775576048
        vf_explained_var: 0.5974021553993225
        vf_loss: 474.6190533215487
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.63025210084034
    gpu_util_percent0: 0.3094957983193278
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.912605042016805
    vram_util_percent0: 0.253950875200851
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 54226
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.24679105051434602
    mean_env_wait_ms: 3.267969368195305
    mean_inference_ms: 9.544921488112674
    mean_raw_obs_processing_ms: 0.8670451060310119
  time_since_restore: 102.03125047683716
  time_this_iter_s: 102.03125047683716
  time_total_s: 102.03125047683716
  timers:
    learn_throughput: 3776.415
    learn_time_ms: 85685.499
    sample_throughput: 19890.013
    sample_time_ms: 16268.667
    update_time_ms: 44.297
  timestamp: 1602224441
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 1
  trial_id: 4d314_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 75.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4d314_00000 | RUNNING  | 172.17.0.4:54226 |      1 |          102.031 | 323584 |  227.935 |              284.798 |              147.061 |            875.497 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4d314_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3221.0
  date: 2020-10-09_06-22-21
  done: false
  episode_len_mean: 874.7025316455696
  episode_reward_max: 295.7272727272725
  episode_reward_mean: 228.7688275156628
  episode_reward_min: 131.85858585858597
  episodes_this_iter: 316
  episodes_total: 632
  experiment_id: d3ccebdf66b8463d9e4f33d5747f3bc7
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999993
        cur_lr: 0.00010000000000000003
        entropy: 1.1267667450482333
        entropy_coeff: 0.0
        kl: 0.009360943013165571
        model: {}
        policy_loss: -0.05610145305436623
        total_loss: 116.70945527281943
        vf_explained_var: 0.8676877617835999
        vf_loss: 116.7636852988714
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.34188034188034
    gpu_util_percent0: 0.26692307692307693
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.201709401709403
    vram_util_percent0: 0.25705149229255486
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 54226
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.2411713384007768
    mean_env_wait_ms: 3.2417834458662305
    mean_inference_ms: 9.119561515586396
    mean_raw_obs_processing_ms: 0.8525631310760108
  time_since_restore: 201.95990014076233
  time_this_iter_s: 99.92864966392517
  time_total_s: 201.95990014076233
  timers:
    learn_throughput: 3795.987
    learn_time_ms: 85243.714
    sample_throughput: 20741.742
    sample_time_ms: 15600.618
    update_time_ms: 63.435
  timestamp: 1602224541
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 2
  trial_id: 4d314_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4d314_00000 | RUNNING  | 172.17.0.4:54226 |      2 |           201.96 | 647168 |  228.769 |              295.727 |              131.859 |            874.703 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4d314_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3215.0
  date: 2020-10-09_06-24-00
  done: false
  episode_len_mean: 874.2742616033755
  episode_reward_max: 295.7272727272725
  episode_reward_mean: 229.9563461620422
  episode_reward_min: 131.85858585858597
  episodes_this_iter: 316
  episodes_total: 948
  experiment_id: d3ccebdf66b8463d9e4f33d5747f3bc7
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999993
        cur_lr: 0.00010000000000000003
        entropy: 1.1139566340023959
        entropy_coeff: 0.0
        kl: 0.010212765311044229
        model: {}
        policy_loss: -0.06861230415068095
        total_loss: 16.046789277957963
        vf_explained_var: 0.9762288331985474
        vf_loss: 16.113359004636354
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.724561403508776
    gpu_util_percent0: 0.2889473684210527
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.212280701754388
    vram_util_percent0: 0.25705149229255486
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 54226
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.23785889808114166
    mean_env_wait_ms: 3.2277040140709765
    mean_inference_ms: 8.826277350693172
    mean_raw_obs_processing_ms: 0.8419319370658654
  time_since_restore: 300.4129846096039
  time_this_iter_s: 98.45308446884155
  time_total_s: 300.4129846096039
  timers:
    learn_throughput: 3807.224
    learn_time_ms: 84992.111
    sample_throughput: 21546.609
    sample_time_ms: 15017.862
    update_time_ms: 50.188
  timestamp: 1602224640
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 3
  trial_id: 4d314_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4d314_00000 | RUNNING  | 172.17.0.4:54226 |      3 |          300.413 | 970752 |  229.956 |              295.727 |              131.859 |            874.274 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4d314_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3208.0
  date: 2020-10-09_06-25-38
  done: false
  episode_len_mean: 873.182753164557
  episode_reward_max: 295.7272727272725
  episode_reward_mean: 230.14047915867516
  episode_reward_min: 131.85858585858597
  episodes_this_iter: 316
  episodes_total: 1264
  experiment_id: d3ccebdf66b8463d9e4f33d5747f3bc7
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999993
        cur_lr: 0.00010000000000000003
        entropy: 1.0960045585149452
        entropy_coeff: 0.0
        kl: 0.010585269360225412
        model: {}
        policy_loss: -0.06564856811037546
        total_loss: 7.743644672104075
        vf_explained_var: 0.986351490020752
        vf_loss: 7.807176251954671
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.76347826086956
    gpu_util_percent0: 0.27408695652173914
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.216521739130435
    vram_util_percent0: 0.25705149229255486
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 54226
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.23569041220773973
    mean_env_wait_ms: 3.21873025994404
    mean_inference_ms: 8.61968682315993
    mean_raw_obs_processing_ms: 0.833882715095897
  time_since_restore: 399.0446307659149
  time_this_iter_s: 98.63164615631104
  time_total_s: 399.0446307659149
  timers:
    learn_throughput: 3808.896
    learn_time_ms: 84954.812
    sample_throughput: 22043.905
    sample_time_ms: 14679.069
    update_time_ms: 43.15
  timestamp: 1602224738
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 4
  trial_id: 4d314_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4d314_00000 | RUNNING  | 172.17.0.4:54226 |      4 |          399.045 | 1294336 |   230.14 |              295.727 |              131.859 |            873.183 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4d314_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3208.0
  date: 2020-10-09_06-27-17
  done: false
  episode_len_mean: 872.3272151898734
  episode_reward_max: 295.7272727272725
  episode_reward_mean: 231.14012913949605
  episode_reward_min: 131.85858585858597
  episodes_this_iter: 316
  episodes_total: 1580
  experiment_id: d3ccebdf66b8463d9e4f33d5747f3bc7
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999993
        cur_lr: 0.00010000000000000003
        entropy: 1.0684153580967384
        entropy_coeff: 0.0
        kl: 0.011273086318581165
        model: {}
        policy_loss: -0.06882448070034196
        total_loss: 6.473125958744483
        vf_explained_var: 0.9889390468597412
        vf_loss: 6.539695908751669
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.93565217391304
    gpu_util_percent0: 0.28808695652173916
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.277391304347825
    vram_util_percent0: 0.25705149229255486
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 54226
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.23423909787982405
    mean_env_wait_ms: 3.2138173864313506
    mean_inference_ms: 8.4660530261116
    mean_raw_obs_processing_ms: 0.8272832094418546
  time_since_restore: 497.770117521286
  time_this_iter_s: 98.7254867553711
  time_total_s: 497.770117521286
  timers:
    learn_throughput: 3811.002
    learn_time_ms: 84907.843
    sample_throughput: 22293.901
    sample_time_ms: 14514.463
    update_time_ms: 44.386
  timestamp: 1602224837
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 5
  trial_id: 4d314_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4d314_00000 | RUNNING  | 172.17.0.4:54226 |      5 |           497.77 | 1617920 |   231.14 |              295.727 |              131.859 |            872.327 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4d314_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3169.0
  date: 2020-10-09_06-28-56
  done: false
  episode_len_mean: 869.5410209662716
  episode_reward_max: 295.7272727272725
  episode_reward_mean: 232.73509019087854
  episode_reward_min: 128.66666666666666
  episodes_this_iter: 614
  episodes_total: 2194
  experiment_id: d3ccebdf66b8463d9e4f33d5747f3bc7
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999993
        cur_lr: 0.00010000000000000003
        entropy: 1.0647160342977018
        entropy_coeff: 0.0
        kl: 0.01141775549165433
        model: {}
        policy_loss: -0.06398457538666605
        total_loss: 11.826693715928476
        vf_explained_var: 0.9857082366943359
        vf_loss: 11.88839468171325
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.815789473684216
    gpu_util_percent0: 0.2789473684210526
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.260526315789471
    vram_util_percent0: 0.25705149229255486
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 54226
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.23241270693740035
    mean_env_wait_ms: 3.211772003323006
    mean_inference_ms: 8.264989628354735
    mean_raw_obs_processing_ms: 0.8188204789394448
  time_since_restore: 596.3372256755829
  time_this_iter_s: 98.56710815429688
  time_total_s: 596.3372256755829
  timers:
    learn_throughput: 3812.378
    learn_time_ms: 84877.203
    sample_throughput: 22503.684
    sample_time_ms: 14379.157
    update_time_ms: 44.828
  timestamp: 1602224936
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 6
  trial_id: 4d314_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4d314_00000 | RUNNING  | 172.17.0.4:54226 |      6 |          596.337 | 1941504 |  232.735 |              295.727 |              128.667 |            869.541 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4d314_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3169.0
  date: 2020-10-09_06-30-35
  done: true
  episode_len_mean: 868.585838607595
  episode_reward_max: 295.7272727272725
  episode_reward_mean: 233.1068677279119
  episode_reward_min: 128.66666666666666
  episodes_this_iter: 334
  episodes_total: 2528
  experiment_id: d3ccebdf66b8463d9e4f33d5747f3bc7
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999993
        cur_lr: 0.00010000000000000003
        entropy: 1.0636283385602734
        entropy_coeff: 0.0
        kl: 0.012031362568841705
        model: {}
        policy_loss: -0.07026327988486501
        total_loss: 7.0159314131434956
        vf_explained_var: 0.9884669780731201
        vf_loss: 7.083788419071632
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.63534482758621
    gpu_util_percent0: 0.28068965517241373
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.281896551724136
    vram_util_percent0: 0.25705149229255486
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 54226
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.23167260294214176
    mean_env_wait_ms: 3.210783699166194
    mean_inference_ms: 8.187796685572915
    mean_raw_obs_processing_ms: 0.8158510123325501
  time_since_restore: 695.681051492691
  time_this_iter_s: 99.34382581710815
  time_total_s: 695.681051492691
  timers:
    learn_throughput: 3809.307
    learn_time_ms: 84945.629
    sample_throughput: 22626.871
    sample_time_ms: 14300.873
    update_time_ms: 45.746
  timestamp: 1602225035
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 7
  trial_id: 4d314_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4d314_00000 | TERMINATED |       |      7 |          695.681 | 2265088 |  233.107 |              295.727 |              128.667 |            868.586 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 76.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4d314_00000 | TERMINATED |       |      7 |          695.681 | 2265088 |  233.107 |              295.727 |              128.667 |            868.586 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


