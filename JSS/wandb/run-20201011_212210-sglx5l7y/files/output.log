2020-10-11 21:22:14,238	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_d5bac_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=23290)[0m 2020-10-11 21:22:16,998	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=23280)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23280)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23270)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23270)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23291)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23291)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23236)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23236)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23237)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23237)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23242)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23242)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23264)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23264)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23230)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23230)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23244)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23244)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23281)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23281)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23167)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23167)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23161)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23161)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23164)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23164)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23233)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23233)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23222)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23222)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23220)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23220)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23248)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23248)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23177)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23177)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23166)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23166)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23279)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23279)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23249)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23249)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23226)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23226)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23240)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23240)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23228)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23228)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23255)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23255)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23287)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23287)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23278)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23278)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23160)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23160)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23221)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23221)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23178)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23178)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23232)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23232)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23238)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23238)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23215)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23215)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23241)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23241)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23273)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23273)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23229)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23229)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23174)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23174)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23169)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23169)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23195)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23195)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23163)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23163)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23165)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23165)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23243)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23243)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23187)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23187)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23176)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23176)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23162)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23162)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23239)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23239)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23192)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23192)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23260)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23260)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23217)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23217)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23194)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23194)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23184)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23184)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23180)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23180)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23245)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23245)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23258)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23258)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23265)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23265)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23214)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23214)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23284)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23284)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23189)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23189)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23263)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23263)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23256)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23256)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23259)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23259)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23246)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23246)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23288)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23288)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23170)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23170)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23271)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23271)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23250)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23250)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23197)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23197)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23247)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23247)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23175)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23175)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23262)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23262)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23253)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23253)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23179)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23179)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23199)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23199)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23198)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23198)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23181)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23181)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23188)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23188)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23171)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23171)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23269)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23269)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=23173)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23173)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_d5bac_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-11_21-22-50
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 7a4276d6b89f4451a8904e373fd08ce2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 1.1862196425596874
        entropy_coeff: 0.0005000000000000001
        kl: 0.002938366417462627
        model: {}
        policy_loss: -0.00765510048950091
        total_loss: 507.075932820638
        vf_explained_var: 0.540532648563385
        vf_loss: 507.0832926432292
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.906060606060606
    gpu_util_percent0: 0.3596969696969697
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.563636363636364
    vram_util_percent0: 0.08605156186330344
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 23290
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16273873350656337
    mean_env_wait_ms: 1.1504387568455856
    mean_inference_ms: 5.354319737626654
    mean_raw_obs_processing_ms: 0.42788852692828133
  time_since_restore: 28.059585571289062
  time_this_iter_s: 28.059585571289062
  time_total_s: 28.059585571289062
  timers:
    learn_throughput: 8421.363
    learn_time_ms: 19212.092
    sample_throughput: 18412.15
    sample_time_ms: 8787.241
    update_time_ms: 22.817
  timestamp: 1602451370
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: d5bac_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d5bac_00000 | RUNNING  | 172.17.0.4:23290 |      1 |          28.0596 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d5bac_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3612.75
    time_step_min: 3339
  date: 2020-10-11_21-23-17
  done: false
  episode_len_mean: 890.3512658227849
  episode_reward_max: 276.02020202020174
  episode_reward_mean: 216.86648126837974
  episode_reward_min: 141.47474747474692
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 7a4276d6b89f4451a8904e373fd08ce2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.1595320403575897
        entropy_coeff: 0.0005000000000000001
        kl: 0.006019254292671879
        model: {}
        policy_loss: -0.010815605016735693
        total_loss: 136.92451985677084
        vf_explained_var: 0.7982837557792664
        vf_loss: 136.9350128173828
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.909374999999997
    gpu_util_percent0: 0.28031249999999996
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7593750000000004
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 23290
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15964135732843526
    mean_env_wait_ms: 1.1508605519384167
    mean_inference_ms: 5.21347012692759
    mean_raw_obs_processing_ms: 0.4214499261058109
  time_since_restore: 55.13105535507202
  time_this_iter_s: 27.07146978378296
  time_total_s: 55.13105535507202
  timers:
    learn_throughput: 8403.655
    learn_time_ms: 19252.576
    sample_throughput: 19620.325
    sample_time_ms: 8246.143
    update_time_ms: 22.963
  timestamp: 1602451397
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: d5bac_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d5bac_00000 | RUNNING  | 172.17.0.4:23290 |      2 |          55.1311 | 323584 |  216.866 |               276.02 |              141.475 |            890.351 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d5bac_00000:
  custom_metrics:
    time_step_max: 4093
    time_step_mean: 3606.4618834080716
    time_step_min: 3273
  date: 2020-10-11_21-23-44
  done: false
  episode_len_mean: 887.120253164557
  episode_reward_max: 276.02020202020174
  episode_reward_mean: 218.81268380002533
  episode_reward_min: 141.47474747474692
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 7a4276d6b89f4451a8904e373fd08ce2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.1453038851420085
        entropy_coeff: 0.0005000000000000001
        kl: 0.008091051791173717
        model: {}
        policy_loss: -0.013366925501031801
        total_loss: 63.08787981669108
        vf_explained_var: 0.8877657055854797
        vf_loss: 63.1006072362264
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.619354838709686
    gpu_util_percent0: 0.34774193548387095
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7741935483870965
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 23290
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15753973397590285
    mean_env_wait_ms: 1.1519545010904937
    mean_inference_ms: 5.083241903021454
    mean_raw_obs_processing_ms: 0.41579927330480654
  time_since_restore: 81.61738085746765
  time_this_iter_s: 26.48632550239563
  time_total_s: 81.61738085746765
  timers:
    learn_throughput: 8372.549
    learn_time_ms: 19324.104
    sample_throughput: 20705.679
    sample_time_ms: 7813.895
    update_time_ms: 22.202
  timestamp: 1602451424
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: d5bac_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d5bac_00000 | RUNNING  | 172.17.0.4:23290 |      3 |          81.6174 | 485376 |  218.813 |               276.02 |              141.475 |             887.12 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d5bac_00000:
  custom_metrics:
    time_step_max: 4093
    time_step_mean: 3596.6059602649007
    time_step_min: 3273
  date: 2020-10-11_21-24-10
  done: false
  episode_len_mean: 885.0158227848101
  episode_reward_max: 276.02020202020174
  episode_reward_mean: 220.72148702211973
  episode_reward_min: 141.47474747474692
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 7a4276d6b89f4451a8904e373fd08ce2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.1319942673047383
        entropy_coeff: 0.0005000000000000001
        kl: 0.006940925881887476
        model: {}
        policy_loss: -0.014043506982488907
        total_loss: 43.93977006276449
        vf_explained_var: 0.9202393889427185
        vf_loss: 43.95333735148112
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.34193548387097
    gpu_util_percent0: 0.3525806451612904
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.770967741935483
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 23290
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15603377184331235
    mean_env_wait_ms: 1.1528349585988014
    mean_inference_ms: 4.983349413566234
    mean_raw_obs_processing_ms: 0.41112078855610446
  time_since_restore: 108.0151755809784
  time_this_iter_s: 26.397794723510742
  time_total_s: 108.0151755809784
  timers:
    learn_throughput: 8367.039
    learn_time_ms: 19336.828
    sample_throughput: 21358.118
    sample_time_ms: 7575.199
    update_time_ms: 24.104
  timestamp: 1602451450
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: d5bac_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d5bac_00000 | RUNNING  | 172.17.0.4:23290 |      4 |          108.015 | 647168 |  220.721 |               276.02 |              141.475 |            885.016 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d5bac_00000:
  custom_metrics:
    time_step_max: 4093
    time_step_mean: 3584.8110236220473
    time_step_min: 3168
  date: 2020-10-11_21-24-36
  done: false
  episode_len_mean: 881.4379746835443
  episode_reward_max: 286.02020202020196
  episode_reward_mean: 222.31421813067362
  episode_reward_min: 141.47474747474692
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 7a4276d6b89f4451a8904e373fd08ce2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.1104028125603993
        entropy_coeff: 0.0005000000000000001
        kl: 0.0064051301839451
        model: {}
        policy_loss: -0.0126600128520901
        total_loss: 33.584352811177574
        vf_explained_var: 0.9395277500152588
        vf_loss: 33.59660784403483
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.966666666666672
    gpu_util_percent0: 0.3326666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.769999999999999
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 23290
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15491802188850073
    mean_env_wait_ms: 1.154290242823973
    mean_inference_ms: 4.906301941636999
    mean_raw_obs_processing_ms: 0.40739741158457876
  time_since_restore: 134.3933231830597
  time_this_iter_s: 26.3781476020813
  time_total_s: 134.3933231830597
  timers:
    learn_throughput: 8357.344
    learn_time_ms: 19359.261
    sample_throughput: 21771.193
    sample_time_ms: 7431.471
    update_time_ms: 23.728
  timestamp: 1602451476
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: d5bac_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d5bac_00000 | RUNNING  | 172.17.0.4:23290 |      5 |          134.393 | 808960 |  222.314 |               286.02 |              141.475 |            881.438 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d5bac_00000:
  custom_metrics:
    time_step_max: 4093
    time_step_mean: 3573.3961904761904
    time_step_min: 3168
  date: 2020-10-11_21-25-03
  done: false
  episode_len_mean: 873.39146567718
  episode_reward_max: 286.02020202020196
  episode_reward_mean: 224.10517981297184
  episode_reward_min: 141.47474747474692
  episodes_this_iter: 288
  episodes_total: 1078
  experiment_id: 7a4276d6b89f4451a8904e373fd08ce2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.0952356656392415
        entropy_coeff: 0.0005000000000000001
        kl: 0.006541164281467597
        model: {}
        policy_loss: -0.01200440141838044
        total_loss: 39.066102027893066
        vf_explained_var: 0.9545696377754211
        vf_loss: 39.07767264048258
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.912903225806453
    gpu_util_percent0: 0.3970967741935484
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322573
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 23290
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15355505529526772
    mean_env_wait_ms: 1.158296788936584
    mean_inference_ms: 4.809420358215445
    mean_raw_obs_processing_ms: 0.40288954488613987
  time_since_restore: 160.7421236038208
  time_this_iter_s: 26.34880042076111
  time_total_s: 160.7421236038208
  timers:
    learn_throughput: 8363.543
    learn_time_ms: 19344.913
    sample_throughput: 21989.089
    sample_time_ms: 7357.831
    update_time_ms: 24.941
  timestamp: 1602451503
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: d5bac_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d5bac_00000 | RUNNING  | 172.17.0.4:23290 |      6 |          160.742 | 970752 |  224.105 |               286.02 |              141.475 |            873.391 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d5bac_00000:
  custom_metrics:
    time_step_max: 4093
    time_step_mean: 3563.8802588996764
    time_step_min: 3168
  date: 2020-10-11_21-25-29
  done: false
  episode_len_mean: 869.4098101265823
  episode_reward_max: 286.02020202020196
  episode_reward_mean: 225.42013489323602
  episode_reward_min: 141.47474747474692
  episodes_this_iter: 186
  episodes_total: 1264
  experiment_id: 7a4276d6b89f4451a8904e373fd08ce2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.0986405809720357
        entropy_coeff: 0.0005000000000000001
        kl: 0.006612970260903239
        model: {}
        policy_loss: -0.010144432870826373
        total_loss: 22.189348538716633
        vf_explained_var: 0.9615075588226318
        vf_loss: 22.199050426483154
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.966666666666672
    gpu_util_percent0: 0.31366666666666665
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7866666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 23290
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15289863928861405
    mean_env_wait_ms: 1.1601764747182013
    mean_inference_ms: 4.763834199870914
    mean_raw_obs_processing_ms: 0.40079142506928894
  time_since_restore: 186.96440052986145
  time_this_iter_s: 26.22227692604065
  time_total_s: 186.96440052986145
  timers:
    learn_throughput: 8366.125
    learn_time_ms: 19338.942
    sample_throughput: 22210.677
    sample_time_ms: 7284.425
    update_time_ms: 24.248
  timestamp: 1602451529
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: d5bac_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d5bac_00000 | RUNNING  | 172.17.0.4:23290 |      7 |          186.964 | 1132544 |   225.42 |               286.02 |              141.475 |             869.41 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d5bac_00000:
  custom_metrics:
    time_step_max: 4093
    time_step_mean: 3558.2230989956956
    time_step_min: 3168
  date: 2020-10-11_21-25-55
  done: false
  episode_len_mean: 867.443741209564
  episode_reward_max: 286.02020202020196
  episode_reward_mean: 226.18269189788165
  episode_reward_min: 141.47474747474692
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 7a4276d6b89f4451a8904e373fd08ce2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.080284724632899
        entropy_coeff: 0.0005000000000000001
        kl: 0.006977737958853443
        model: {}
        policy_loss: -0.01468875712210623
        total_loss: 20.493053436279297
        vf_explained_var: 0.9642829895019531
        vf_loss: 20.507236003875732
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.04666666666667
    gpu_util_percent0: 0.42533333333333334
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7833333333333328
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 23290
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1524338684258481
    mean_env_wait_ms: 1.1615906666698967
    mean_inference_ms: 4.731361941502875
    mean_raw_obs_processing_ms: 0.39924232315954034
  time_since_restore: 212.87171840667725
  time_this_iter_s: 25.907317876815796
  time_total_s: 212.87171840667725
  timers:
    learn_throughput: 8387.339
    learn_time_ms: 19290.027
    sample_throughput: 22363.456
    sample_time_ms: 7234.66
    update_time_ms: 23.804
  timestamp: 1602451555
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: d5bac_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d5bac_00000 | RUNNING  | 172.17.0.4:23290 |      8 |          212.872 | 1294336 |  226.183 |               286.02 |              141.475 |            867.444 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d5bac_00000:
  custom_metrics:
    time_step_max: 4093
    time_step_mean: 3550.665592783505
    time_step_min: 3168
  date: 2020-10-11_21-26-21
  done: false
  episode_len_mean: 865.243670886076
  episode_reward_max: 286.02020202020196
  episode_reward_mean: 227.1805395729445
  episode_reward_min: 141.47474747474692
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 7a4276d6b89f4451a8904e373fd08ce2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.0580568710962932
        entropy_coeff: 0.0005000000000000001
        kl: 0.006936726781229178
        model: {}
        policy_loss: -0.012113248774160942
        total_loss: 19.573460578918457
        vf_explained_var: 0.9635744094848633
        vf_loss: 19.585062344868977
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.583870967741934
    gpu_util_percent0: 0.37806451612903225
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 23290
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1520295413682792
    mean_env_wait_ms: 1.1628204898348353
    mean_inference_ms: 4.70285757851624
    mean_raw_obs_processing_ms: 0.397857847240562
  time_since_restore: 238.95092511177063
  time_this_iter_s: 26.079206705093384
  time_total_s: 238.95092511177063
  timers:
    learn_throughput: 8396.422
    learn_time_ms: 19269.16
    sample_throughput: 22484.876
    sample_time_ms: 7195.592
    update_time_ms: 26.343
  timestamp: 1602451581
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: d5bac_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d5bac_00000 | RUNNING  | 172.17.0.4:23290 |      9 |          238.951 | 1456128 |  227.181 |               286.02 |              141.475 |            865.244 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d5bac_00000:
  custom_metrics:
    time_step_max: 4093
    time_step_mean: 3542.463329452852
    time_step_min: 3168
  date: 2020-10-11_21-26-48
  done: false
  episode_len_mean: 862.8625429553265
  episode_reward_max: 286.02020202020196
  episode_reward_mean: 228.42700197854825
  episode_reward_min: 141.47474747474692
  episodes_this_iter: 166
  episodes_total: 1746
  experiment_id: 7a4276d6b89f4451a8904e373fd08ce2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.0198005139827728
        entropy_coeff: 0.0005000000000000001
        kl: 0.006477807532064617
        model: {}
        policy_loss: -0.01256014299481952
        total_loss: 17.12761354446411
        vf_explained_var: 0.9722877144813538
        vf_loss: 17.13971185684204
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.193333333333328
    gpu_util_percent0: 0.32466666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.769999999999999
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 23290
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1516662620828048
    mean_env_wait_ms: 1.1641083387379925
    mean_inference_ms: 4.676618708040838
    mean_raw_obs_processing_ms: 0.396546283891808
  time_since_restore: 265.2068166732788
  time_this_iter_s: 26.25589156150818
  time_total_s: 265.2068166732788
  timers:
    learn_throughput: 8397.125
    learn_time_ms: 19267.548
    sample_throughput: 22574.426
    sample_time_ms: 7167.048
    update_time_ms: 27.555
  timestamp: 1602451608
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: d5bac_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d5bac_00000 | RUNNING  | 172.17.0.4:23290 |     10 |          265.207 | 1617920 |  228.427 |               286.02 |              141.475 |            862.863 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d5bac_00000:
  custom_metrics:
    time_step_max: 4093
    time_step_mean: 3532.713224368499
    time_step_min: 3168
  date: 2020-10-11_21-27-14
  done: false
  episode_len_mean: 858.7401074743527
  episode_reward_max: 286.02020202020196
  episode_reward_mean: 230.19497367421147
  episode_reward_min: 141.47474747474692
  episodes_this_iter: 301
  episodes_total: 2047
  experiment_id: 7a4276d6b89f4451a8904e373fd08ce2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.0060811241467793
        entropy_coeff: 0.0005000000000000001
        kl: 0.006349060762052734
        model: {}
        policy_loss: -0.012282586200550819
        total_loss: 22.84598207473755
        vf_explained_var: 0.9701985716819763
        vf_loss: 22.857815742492676
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.54193548387097
    gpu_util_percent0: 0.37
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7677419354838704
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 23290
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1511130944591234
    mean_env_wait_ms: 1.1661901758324649
    mean_inference_ms: 4.637628953756551
    mean_raw_obs_processing_ms: 0.3946670928003211
  time_since_restore: 291.7560842037201
  time_this_iter_s: 26.549267530441284
  time_total_s: 291.7560842037201
  timers:
    learn_throughput: 8389.909
    learn_time_ms: 19284.118
    sample_throughput: 23127.314
    sample_time_ms: 6995.711
    update_time_ms: 29.158
  timestamp: 1602451634
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: d5bac_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d5bac_00000 | RUNNING  | 172.17.0.4:23290 |     11 |          291.756 | 1779712 |  230.195 |               286.02 |              141.475 |             858.74 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d5bac_00000:
  custom_metrics:
    time_step_max: 4093
    time_step_mean: 3526.6121794871797
    time_step_min: 3168
  date: 2020-10-11_21-27-41
  done: false
  episode_len_mean: 855.6121157323689
  episode_reward_max: 286.02020202020196
  episode_reward_mean: 231.23261091931968
  episode_reward_min: 141.47474747474692
  episodes_this_iter: 165
  episodes_total: 2212
  experiment_id: 7a4276d6b89f4451a8904e373fd08ce2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.9920330742994944
        entropy_coeff: 0.0005000000000000001
        kl: 0.006071586161851883
        model: {}
        policy_loss: -0.01312481742570526
        total_loss: 15.005290508270264
        vf_explained_var: 0.9728094935417175
        vf_loss: 15.018001000086466
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.186666666666667
    gpu_util_percent0: 0.30866666666666664
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7833333333333328
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 23290
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15085838845667104
    mean_env_wait_ms: 1.1672983819067346
    mean_inference_ms: 4.619632856505368
    mean_raw_obs_processing_ms: 0.393791446345098
  time_since_restore: 318.12431955337524
  time_this_iter_s: 26.36823534965515
  time_total_s: 318.12431955337524
  timers:
    learn_throughput: 8395.371
    learn_time_ms: 19271.572
    sample_throughput: 23323.559
    sample_time_ms: 6936.849
    update_time_ms: 29.03
  timestamp: 1602451661
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: d5bac_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d5bac_00000 | RUNNING  | 172.17.0.4:23290 |     12 |          318.124 | 1941504 |  231.233 |               286.02 |              141.475 |            855.612 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d5bac_00000:
  custom_metrics:
    time_step_max: 4093
    time_step_mean: 3519.6033304867633
    time_step_min: 3168
  date: 2020-10-11_21-28-07
  done: false
  episode_len_mean: 852.2881856540084
  episode_reward_max: 286.02020202020196
  episode_reward_mean: 232.42731108553883
  episode_reward_min: 141.47474747474692
  episodes_this_iter: 158
  episodes_total: 2370
  experiment_id: 7a4276d6b89f4451a8904e373fd08ce2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.9818104455868403
        entropy_coeff: 0.0005000000000000001
        kl: 0.005891515562931697
        model: {}
        policy_loss: -0.011727015177408854
        total_loss: 11.77860418955485
        vf_explained_var: 0.9756176471710205
        vf_loss: 11.789938370386759
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.86451612903226
    gpu_util_percent0: 0.3667741935483871
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7677419354838704
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 23290
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1506375667060552
    mean_env_wait_ms: 1.1683623199876199
    mean_inference_ms: 4.604059955924435
    mean_raw_obs_processing_ms: 0.39299787713413
  time_since_restore: 344.7000002861023
  time_this_iter_s: 26.57568073272705
  time_total_s: 344.7000002861023
  timers:
    learn_throughput: 8393.686
    learn_time_ms: 19275.44
    sample_throughput: 23312.907
    sample_time_ms: 6940.018
    update_time_ms: 30.429
  timestamp: 1602451687
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: d5bac_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d5bac_00000 | RUNNING  | 172.17.0.4:23290 |     13 |            344.7 | 2103296 |  232.427 |               286.02 |              141.475 |            852.288 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d5bac_00000:
  custom_metrics:
    time_step_max: 4093
    time_step_mean: 3511.326779394416
    time_step_min: 3168
  date: 2020-10-11_21-28-34
  done: false
  episode_len_mean: 848.0342279268767
  episode_reward_max: 286.02020202020196
  episode_reward_mean: 233.7912615065473
  episode_reward_min: 141.47474747474692
  episodes_this_iter: 201
  episodes_total: 2571
  experiment_id: 7a4276d6b89f4451a8904e373fd08ce2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.9403989066680273
        entropy_coeff: 0.0005000000000000001
        kl: 0.005777106115904947
        model: {}
        policy_loss: -0.011730696933227591
        total_loss: 15.164489984512329
        vf_explained_var: 0.9755457043647766
        vf_loss: 15.17582392692566
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.810000000000006
    gpu_util_percent0: 0.25766666666666665
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7666666666666657
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 23290
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1503821892086604
    mean_env_wait_ms: 1.1698636183925313
    mean_inference_ms: 4.5860966319954946
    mean_raw_obs_processing_ms: 0.3920798260319874
  time_since_restore: 370.8266444206238
  time_this_iter_s: 26.126644134521484
  time_total_s: 370.8266444206238
  timers:
    learn_throughput: 8410.302
    learn_time_ms: 19237.36
    sample_throughput: 23247.105
    sample_time_ms: 6959.662
    update_time_ms: 29.441
  timestamp: 1602451714
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: d5bac_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d5bac_00000 | RUNNING  | 172.17.0.4:23290 |     14 |          370.827 | 2265088 |  233.791 |               286.02 |              141.475 |            848.034 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d5bac_00000:
  custom_metrics:
    time_step_max: 4093
    time_step_mean: 3499.06891651865
    time_step_min: 3168
  date: 2020-10-11_21-29-00
  done: false
  episode_len_mean: 842.5631375307773
  episode_reward_max: 286.02020202020196
  episode_reward_mean: 235.78522829419765
  episode_reward_min: 141.47474747474692
  episodes_this_iter: 272
  episodes_total: 2843
  experiment_id: 7a4276d6b89f4451a8904e373fd08ce2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.9257176419099172
        entropy_coeff: 0.0005000000000000001
        kl: 0.005760084177988271
        model: {}
        policy_loss: -0.010179700759181287
        total_loss: 12.722555796305338
        vf_explained_var: 0.9796773791313171
        vf_loss: 12.73233429590861
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.480645161290322
    gpu_util_percent0: 0.3887096774193548
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.76774193548387
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 23290
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15008770763081375
    mean_env_wait_ms: 1.1718360476076781
    mean_inference_ms: 4.565254400823598
    mean_raw_obs_processing_ms: 0.3910497978179601
  time_since_restore: 396.96961188316345
  time_this_iter_s: 26.142967462539673
  time_total_s: 396.96961188316345
  timers:
    learn_throughput: 8424.138
    learn_time_ms: 19205.764
    sample_throughput: 23227.272
    sample_time_ms: 6965.605
    update_time_ms: 30.342
  timestamp: 1602451740
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: d5bac_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d5bac_00000 | RUNNING  | 172.17.0.4:23290 |     15 |           396.97 | 2426880 |  235.785 |               286.02 |              141.475 |            842.563 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d5bac_00000:
  custom_metrics:
    time_step_max: 4093
    time_step_mean: 3493.2047747141896
    time_step_min: 3168
  date: 2020-10-11_21-29-26
  done: false
  episode_len_mean: 839.4343770819454
  episode_reward_max: 287.38383838383845
  episode_reward_mean: 236.75128029125352
  episode_reward_min: 141.47474747474692
  episodes_this_iter: 159
  episodes_total: 3002
  experiment_id: 7a4276d6b89f4451a8904e373fd08ce2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.9047323117653528
        entropy_coeff: 0.0005000000000000001
        kl: 0.005609542325449486
        model: {}
        policy_loss: -0.012422506920605278
        total_loss: 9.531224568684896
        vf_explained_var: 0.9800539612770081
        vf_loss: 9.54325826962789
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.393333333333327
    gpu_util_percent0: 0.40166666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7766666666666664
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 23290
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14993225630273618
    mean_env_wait_ms: 1.1729480980236335
    mean_inference_ms: 4.554347095494084
    mean_raw_obs_processing_ms: 0.3904950262610489
  time_since_restore: 423.0151116847992
  time_this_iter_s: 26.045499801635742
  time_total_s: 423.0151116847992
  timers:
    learn_throughput: 8431.735
    learn_time_ms: 19188.458
    sample_throughput: 23269.071
    sample_time_ms: 6953.092
    update_time_ms: 29.621
  timestamp: 1602451766
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: d5bac_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d5bac_00000 | RUNNING  | 172.17.0.4:23290 |     16 |          423.015 | 2588672 |  236.751 |              287.384 |              141.475 |            839.434 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d5bac_00000:
  custom_metrics:
    time_step_max: 4093
    time_step_mean: 3486.6876790830947
    time_step_min: 3168
  date: 2020-10-11_21-29-53
  done: false
  episode_len_mean: 836.5194067529189
  episode_reward_max: 289.05050505050554
  episode_reward_mean: 237.65134462326003
  episode_reward_min: 141.47474747474692
  episodes_this_iter: 167
  episodes_total: 3169
  experiment_id: 7a4276d6b89f4451a8904e373fd08ce2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.8869904428720474
        entropy_coeff: 0.0005000000000000001
        kl: 0.00590256170835346
        model: {}
        policy_loss: -0.012220686612029871
        total_loss: 12.015844265619913
        vf_explained_var: 0.9774371981620789
        vf_loss: 12.027623097101847
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.416129032258066
    gpu_util_percent0: 0.26645161290322583
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 23290
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1497775356247428
    mean_env_wait_ms: 1.1741727231113823
    mean_inference_ms: 4.543638412912256
    mean_raw_obs_processing_ms: 0.3899422701549566
  time_since_restore: 449.43839049339294
  time_this_iter_s: 26.42327880859375
  time_total_s: 449.43839049339294
  timers:
    learn_throughput: 8423.871
    learn_time_ms: 19206.372
    sample_throughput: 23263.928
    sample_time_ms: 6954.629
    update_time_ms: 29.544
  timestamp: 1602451793
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: d5bac_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d5bac_00000 | RUNNING  | 172.17.0.4:23290 |     17 |          449.438 | 2750464 |  237.651 |              289.051 |              141.475 |            836.519 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d5bac_00000:
  custom_metrics:
    time_step_max: 4093
    time_step_mean: 3475.9538193435956
    time_step_min: 3168
  date: 2020-10-11_21-30-19
  done: false
  episode_len_mean: 831.8804379141458
  episode_reward_max: 289.05050505050554
  episode_reward_mean: 239.30084771657798
  episode_reward_min: 141.47474747474692
  episodes_this_iter: 302
  episodes_total: 3471
  experiment_id: 7a4276d6b89f4451a8904e373fd08ce2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.8613734145959219
        entropy_coeff: 0.0005000000000000001
        kl: 0.005500228144228458
        model: {}
        policy_loss: -0.008684957341756672
        total_loss: 12.450392961502075
        vf_explained_var: 0.9819631576538086
        vf_loss: 12.458683411280314
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.933333333333334
    gpu_util_percent0: 0.264
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.766666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 23290
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1495361743479253
    mean_env_wait_ms: 1.1763029124466713
    mean_inference_ms: 4.526556608107483
    mean_raw_obs_processing_ms: 0.3890935170843277
  time_since_restore: 475.60134959220886
  time_this_iter_s: 26.162959098815918
  time_total_s: 475.60134959220886
  timers:
    learn_throughput: 8417.743
    learn_time_ms: 19220.354
    sample_throughput: 23234.966
    sample_time_ms: 6963.298
    update_time_ms: 31.264
  timestamp: 1602451819
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: d5bac_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d5bac_00000 | RUNNING  | 172.17.0.4:23290 |     18 |          475.601 | 2912256 |  239.301 |              289.051 |              141.475 |             831.88 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d5bac_00000:
  custom_metrics:
    time_step_max: 4093
    time_step_mean: 3469.8990571270106
    time_step_min: 3168
  date: 2020-10-11_21-30-45
  done: false
  episode_len_mean: 829.5132085855806
  episode_reward_max: 290.717171717172
  episode_reward_mean: 240.17615338859144
  episode_reward_min: 141.47474747474692
  episodes_this_iter: 163
  episodes_total: 3634
  experiment_id: 7a4276d6b89f4451a8904e373fd08ce2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.8557841380437216
        entropy_coeff: 0.0005000000000000001
        kl: 0.005109146237373352
        model: {}
        policy_loss: -0.0124406140918533
        total_loss: 10.257715702056885
        vf_explained_var: 0.9785848259925842
        vf_loss: 10.269817670186361
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.951612903225808
    gpu_util_percent0: 0.3245161290322582
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7774193548387096
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 23290
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14941699083442128
    mean_env_wait_ms: 1.1773755836693007
    mean_inference_ms: 4.51812675060455
    mean_raw_obs_processing_ms: 0.38867414860179655
  time_since_restore: 501.91957545280457
  time_this_iter_s: 26.318225860595703
  time_total_s: 501.91957545280457
  timers:
    learn_throughput: 8406.863
    learn_time_ms: 19245.228
    sample_throughput: 23240.862
    sample_time_ms: 6961.532
    update_time_ms: 30.694
  timestamp: 1602451845
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: d5bac_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d5bac_00000 | RUNNING  | 172.17.0.4:23290 |     19 |           501.92 | 3074048 |  240.176 |              290.717 |              141.475 |            829.513 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d5bac_00000:
  custom_metrics:
    time_step_max: 4093
    time_step_mean: 3464.509829968119
    time_step_min: 3151
  date: 2020-10-11_21-31-12
  done: false
  episode_len_mean: 827.6139240506329
  episode_reward_max: 290.717171717172
  episode_reward_mean: 240.9400891829689
  episode_reward_min: 141.47474747474692
  episodes_this_iter: 158
  episodes_total: 3792
  experiment_id: 7a4276d6b89f4451a8904e373fd08ce2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.8485396752754847
        entropy_coeff: 0.0005000000000000001
        kl: 0.005326827056705952
        model: {}
        policy_loss: -0.01081282598352118
        total_loss: 10.115727345148722
        vf_explained_var: 0.9786780476570129
        vf_loss: 10.126165310541788
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.996774193548386
    gpu_util_percent0: 0.36999999999999994
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7806451612903222
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 23290
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14930924280371694
    mean_env_wait_ms: 1.1783981554901215
    mean_inference_ms: 4.510496004680461
    mean_raw_obs_processing_ms: 0.3882841351463296
  time_since_restore: 528.1148862838745
  time_this_iter_s: 26.195310831069946
  time_total_s: 528.1148862838745
  timers:
    learn_throughput: 8409.535
    learn_time_ms: 19239.113
    sample_throughput: 23238.178
    sample_time_ms: 6962.336
    update_time_ms: 28.948
  timestamp: 1602451872
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: d5bac_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d5bac_00000 | RUNNING  | 172.17.0.4:23290 |     20 |          528.115 | 3235840 |   240.94 |              290.717 |              141.475 |            827.614 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d5bac_00000:
  custom_metrics:
    time_step_max: 4093
    time_step_mean: 3456.2480906627247
    time_step_min: 3151
  date: 2020-10-11_21-31-38
  done: false
  episode_len_mean: 824.1524345485686
  episode_reward_max: 290.717171717172
  episode_reward_mean: 242.2186805663683
  episode_reward_min: 141.47474747474692
  episodes_this_iter: 295
  episodes_total: 4087
  experiment_id: 7a4276d6b89f4451a8904e373fd08ce2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.8198323100805283
        entropy_coeff: 0.0005000000000000001
        kl: 0.005284009268507361
        model: {}
        policy_loss: -0.010979137286388626
        total_loss: 12.991329431533813
        vf_explained_var: 0.9810224175453186
        vf_loss: 13.001925786336264
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.926666666666673
    gpu_util_percent0: 0.34600000000000003
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.77
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 23290
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14912939489028548
    mean_env_wait_ms: 1.1803424608843711
    mean_inference_ms: 4.497584999309875
    mean_raw_obs_processing_ms: 0.3876398524748072
  time_since_restore: 554.2695167064667
  time_this_iter_s: 26.154630422592163
  time_total_s: 554.2695167064667
  timers:
    learn_throughput: 8417.153
    learn_time_ms: 19221.702
    sample_throughput: 23309.642
    sample_time_ms: 6940.99
    update_time_ms: 27.067
  timestamp: 1602451898
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: d5bac_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d5bac_00000 | RUNNING  | 172.17.0.4:23290 |     21 |           554.27 | 3397632 |  242.219 |              290.717 |              141.475 |            824.152 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d5bac_00000:
  custom_metrics:
    time_step_max: 4093
    time_step_mean: 3451.4233128834358
    time_step_min: 3151
  date: 2020-10-11_21-32-04
  done: false
  episode_len_mean: 822.272386310361
  episode_reward_max: 290.717171717172
  episode_reward_mean: 243.01262981431756
  episode_reward_min: 141.47474747474692
  episodes_this_iter: 179
  episodes_total: 4266
  experiment_id: 7a4276d6b89f4451a8904e373fd08ce2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.810077985127767
        entropy_coeff: 0.0005000000000000001
        kl: 0.005661281989887357
        model: {}
        policy_loss: -0.01100225054930585
        total_loss: 7.782910744349162
        vf_explained_var: 0.983664333820343
        vf_loss: 7.793468912442525
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.69032258064517
    gpu_util_percent0: 0.30096774193548387
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7806451612903222
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 23290
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14902470743149224
    mean_env_wait_ms: 1.1813835399076322
    mean_inference_ms: 4.490306279632789
    mean_raw_obs_processing_ms: 0.3872856419308175
  time_since_restore: 580.6158504486084
  time_this_iter_s: 26.346333742141724
  time_total_s: 580.6158504486084
  timers:
    learn_throughput: 8413.439
    learn_time_ms: 19230.185
    sample_throughput: 23351.802
    sample_time_ms: 6928.459
    update_time_ms: 28.899
  timestamp: 1602451924
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: d5bac_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d5bac_00000 | RUNNING  | 172.17.0.4:23290 |     22 |          580.616 | 3559424 |  243.013 |              290.717 |              141.475 |            822.272 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d5bac_00000:
  custom_metrics:
    time_step_max: 4093
    time_step_mean: 3446.563466787989
    time_step_min: 3151
  date: 2020-10-11_21-32-31
  done: true
  episode_len_mean: 820.6634267631104
  episode_reward_max: 290.717171717172
  episode_reward_mean: 243.68281367015538
  episode_reward_min: 141.47474747474692
  episodes_this_iter: 158
  episodes_total: 4424
  experiment_id: 7a4276d6b89f4451a8904e373fd08ce2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.8058549016714096
        entropy_coeff: 0.0005000000000000001
        kl: 0.0058052534780775504
        model: {}
        policy_loss: -0.010756375937489793
        total_loss: 7.906662344932556
        vf_explained_var: 0.981970489025116
        vf_loss: 7.916950941085815
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.169999999999998
    gpu_util_percent0: 0.2783333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.773333333333333
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 23290
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1489401423202264
    mean_env_wait_ms: 1.182308398490393
    mean_inference_ms: 4.4843526377622736
    mean_raw_obs_processing_ms: 0.38698835423091277
  time_since_restore: 606.7101347446442
  time_this_iter_s: 26.094284296035767
  time_total_s: 606.7101347446442
  timers:
    learn_throughput: 8433.353
    learn_time_ms: 19184.778
    sample_throughput: 23360.564
    sample_time_ms: 6925.86
    update_time_ms: 27.701
  timestamp: 1602451951
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: d5bac_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d5bac_00000 | TERMINATED |       |     23 |           606.71 | 3721216 |  243.683 |              290.717 |              141.475 |            820.663 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d5bac_00000 | TERMINATED |       |     23 |           606.71 | 3721216 |  243.683 |              290.717 |              141.475 |            820.663 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


