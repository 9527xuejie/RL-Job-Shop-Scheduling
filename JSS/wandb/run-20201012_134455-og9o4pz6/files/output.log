2020-10-12 13:44:59,509	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_1fc35_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=76199)[0m 2020-10-12 13:45:02,289	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=76207)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76207)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76233)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76233)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76212)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76212)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76238)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76238)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76187)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76187)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76246)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76246)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76210)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76210)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76228)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76228)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76178)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76178)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76243)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76243)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76127)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76127)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76188)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76188)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76196)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76196)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76250)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76250)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76208)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76208)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76205)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76205)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76237)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76237)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76227)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76227)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76190)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76190)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76193)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76193)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76239)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76239)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76151)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76151)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76138)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76138)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76120)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76120)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76191)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76191)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76114)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76114)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76153)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76153)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76131)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76131)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76126)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76126)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76216)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76216)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76176)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76176)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76194)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76194)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76123)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76123)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76197)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76197)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76200)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76200)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76192)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76192)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76119)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76119)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76217)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76217)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76173)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76173)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76125)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76125)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76140)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76140)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76240)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76240)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76132)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76132)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76165)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76165)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76179)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76179)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76235)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76235)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76223)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76223)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76150)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76150)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76155)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76155)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76112)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76112)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76169)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76169)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76215)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76215)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76130)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76130)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76220)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76220)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76167)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76167)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76141)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76141)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76128)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76128)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76209)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76209)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76145)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76145)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76171)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76171)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76115)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76115)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76221)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76221)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76148)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76148)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76185)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76185)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76121)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76121)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76134)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76134)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76181)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76181)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76124)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76124)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76184)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76184)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76129)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76129)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76116)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76116)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76146)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76146)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76211)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76211)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76225)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76225)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76189)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76189)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76229)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76229)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76118)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76118)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76198)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76198)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=76113)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=76113)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_1fc35_00000:
  custom_metrics:
    time_step_max: 4503
    time_step_mean: 3771.2241379310344
    time_step_min: 3428
  date: 2020-10-12_13-45-36
  done: false
  episode_len_mean: 902.7784810126582
  episode_reward_max: 270.95959595959573
  episode_reward_mean: 218.82112261859064
  episode_reward_min: 107.32323232323165
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 985103c329064696b5f4d20c8e91b85f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1591068506240845
        entropy_coeff: 0.0005000000000000001
        kl: 0.007260716947106023
        model: {}
        policy_loss: -0.010324562744547924
        total_loss: 463.3190383911133
        vf_explained_var: 0.5503719449043274
        vf_loss: 463.32850392659503
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.91470588235294
    gpu_util_percent0: 0.28705882352941176
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5647058823529414
    vram_util_percent0: 0.08659058900700328
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 76199
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17135926623814043
    mean_env_wait_ms: 1.1781435404415668
    mean_inference_ms: 6.036368164246228
    mean_raw_obs_processing_ms: 0.4654708060264293
  time_since_restore: 29.076536893844604
  time_this_iter_s: 29.076536893844604
  time_total_s: 29.076536893844604
  timers:
    learn_throughput: 8226.333
    learn_time_ms: 19667.571
    sample_throughput: 17319.473
    sample_time_ms: 9341.624
    update_time_ms: 30.375
  timestamp: 1602510336
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 1fc35_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1fc35_00000 | RUNNING  | 172.17.0.4:76199 |      1 |          29.0765 | 161792 |  218.821 |               270.96 |              107.323 |            902.778 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1fc35_00000:
  custom_metrics:
    time_step_max: 4503
    time_step_mean: 3761.8430656934306
    time_step_min: 3428
  date: 2020-10-12_13-46-04
  done: false
  episode_len_mean: 900.7721518987341
  episode_reward_max: 270.95959595959573
  episode_reward_mean: 222.14582534202754
  episode_reward_min: 107.32323232323165
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 985103c329064696b5f4d20c8e91b85f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1368693312009175
        entropy_coeff: 0.0005000000000000001
        kl: 0.007597699644975364
        model: {}
        policy_loss: -0.009582230050000362
        total_loss: 110.95142936706543
        vf_explained_var: 0.8132712841033936
        vf_loss: 110.96006329854329
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.003225806451614
    gpu_util_percent0: 0.3616129032258065
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7548387096774185
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 76199
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16618378856984684
    mean_env_wait_ms: 1.172185422930544
    mean_inference_ms: 5.715741348094712
    mean_raw_obs_processing_ms: 0.45029336758407995
  time_since_restore: 56.23753309249878
  time_this_iter_s: 27.160996198654175
  time_total_s: 56.23753309249878
  timers:
    learn_throughput: 8270.169
    learn_time_ms: 19563.324
    sample_throughput: 19086.368
    sample_time_ms: 8476.835
    update_time_ms: 34.592
  timestamp: 1602510364
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 1fc35_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1fc35_00000 | RUNNING  | 172.17.0.4:76199 |      2 |          56.2375 | 323584 |  222.146 |               270.96 |              107.323 |            900.772 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1fc35_00000:
  custom_metrics:
    time_step_max: 4503
    time_step_mean: 3733.6828703703704
    time_step_min: 3386
  date: 2020-10-12_13-46-30
  done: false
  episode_len_mean: 896.1877637130801
  episode_reward_max: 276.5656565656565
  episode_reward_mean: 225.29248177982322
  episode_reward_min: 107.32323232323165
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 985103c329064696b5f4d20c8e91b85f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1199778020381927
        entropy_coeff: 0.0005000000000000001
        kl: 0.012722314645846685
        model: {}
        policy_loss: -0.01465485196483011
        total_loss: 51.23185475667318
        vf_explained_var: 0.8873279690742493
        vf_loss: 51.244523684183754
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.11935483870968
    gpu_util_percent0: 0.33999999999999997
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7677419354838704
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 76199
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1629498300831477
    mean_env_wait_ms: 1.1701312714395695
    mean_inference_ms: 5.493721321208827
    mean_raw_obs_processing_ms: 0.4398655324154261
  time_since_restore: 82.83275580406189
  time_this_iter_s: 26.59522271156311
  time_total_s: 82.83275580406189
  timers:
    learn_throughput: 8295.963
    learn_time_ms: 19502.499
    sample_throughput: 20142.95
    sample_time_ms: 8032.19
    update_time_ms: 29.956
  timestamp: 1602510390
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 1fc35_00000
  
== Status ==
Memory usage on this node: 28.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1fc35_00000 | RUNNING  | 172.17.0.4:76199 |      3 |          82.8328 | 485376 |  225.292 |              276.566 |              107.323 |            896.188 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1fc35_00000:
  custom_metrics:
    time_step_max: 4503
    time_step_mean: 3726.013559322034
    time_step_min: 3386
  date: 2020-10-12_13-46-57
  done: false
  episode_len_mean: 893.4857594936709
  episode_reward_max: 276.5656565656565
  episode_reward_mean: 226.09361015215413
  episode_reward_min: 107.32323232323165
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 985103c329064696b5f4d20c8e91b85f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1056925356388092
        entropy_coeff: 0.0005000000000000001
        kl: 0.011531006079167128
        model: {}
        policy_loss: -0.013364489073865116
        total_loss: 38.18108940124512
        vf_explained_var: 0.924144446849823
        vf_loss: 38.19269975026449
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.351612903225806
    gpu_util_percent0: 0.36548387096774193
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7677419354838704
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 76199
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16070976704347667
    mean_env_wait_ms: 1.1695333886643837
    mean_inference_ms: 5.335713725540599
    mean_raw_obs_processing_ms: 0.4322252780683615
  time_since_restore: 109.29961323738098
  time_this_iter_s: 26.466857433319092
  time_total_s: 109.29961323738098
  timers:
    learn_throughput: 8311.824
    learn_time_ms: 19465.282
    sample_throughput: 20782.615
    sample_time_ms: 7784.968
    update_time_ms: 28.042
  timestamp: 1602510417
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 1fc35_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1fc35_00000 | RUNNING  | 172.17.0.4:76199 |      4 |            109.3 | 647168 |  226.094 |              276.566 |              107.323 |            893.486 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1fc35_00000:
  custom_metrics:
    time_step_max: 4503
    time_step_mean: 3719.9358288770054
    time_step_min: 3386
  date: 2020-10-12_13-47-23
  done: false
  episode_len_mean: 889.479746835443
  episode_reward_max: 276.5656565656565
  episode_reward_mean: 227.57006776626994
  episode_reward_min: 107.32323232323165
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 985103c329064696b5f4d20c8e91b85f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0768516063690186
        entropy_coeff: 0.0005000000000000001
        kl: 0.011141597215707103
        model: {}
        policy_loss: -0.01277905593936642
        total_loss: 29.333818753560383
        vf_explained_var: 0.938424825668335
        vf_loss: 29.34490903218587
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.219354838709677
    gpu_util_percent0: 0.3770967741935484
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.770967741935483
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 76199
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15904742490981302
    mean_env_wait_ms: 1.1699222536536802
    mean_inference_ms: 5.216856471194651
    mean_raw_obs_processing_ms: 0.4262689356909916
  time_since_restore: 135.72907185554504
  time_this_iter_s: 26.429458618164062
  time_total_s: 135.72907185554504
  timers:
    learn_throughput: 8326.002
    learn_time_ms: 19432.135
    sample_throughput: 21190.418
    sample_time_ms: 7635.149
    update_time_ms: 29.773
  timestamp: 1602510443
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 1fc35_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1fc35_00000 | RUNNING  | 172.17.0.4:76199 |      5 |          135.729 | 808960 |   227.57 |              276.566 |              107.323 |             889.48 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1fc35_00000:
  custom_metrics:
    time_step_max: 4503
    time_step_mean: 3704.022869022869
    time_step_min: 3352
  date: 2020-10-12_13-47-50
  done: false
  episode_len_mean: 882.0617529880478
  episode_reward_max: 281.717171717172
  episode_reward_mean: 229.62116181737665
  episode_reward_min: 107.32323232323165
  episodes_this_iter: 214
  episodes_total: 1004
  experiment_id: 985103c329064696b5f4d20c8e91b85f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0329695641994476
        entropy_coeff: 0.0005000000000000001
        kl: 0.011061328075205287
        model: {}
        policy_loss: -0.01258952941376871
        total_loss: 33.870903174082436
        vf_explained_var: 0.9514450430870056
        vf_loss: 33.88179794947306
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.75
    gpu_util_percent0: 0.2883333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7599999999999993
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 76199
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1573753066623186
    mean_env_wait_ms: 1.1717366126042281
    mean_inference_ms: 5.098731254263053
    mean_raw_obs_processing_ms: 0.4202475039259693
  time_since_restore: 162.23428010940552
  time_this_iter_s: 26.505208253860474
  time_total_s: 162.23428010940552
  timers:
    learn_throughput: 8325.101
    learn_time_ms: 19434.239
    sample_throughput: 21493.94
    sample_time_ms: 7527.331
    update_time_ms: 28.145
  timestamp: 1602510470
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 1fc35_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1fc35_00000 | RUNNING  | 172.17.0.4:76199 |      6 |          162.234 | 970752 |  229.621 |              281.717 |              107.323 |            882.062 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1fc35_00000:
  custom_metrics:
    time_step_max: 4503
    time_step_mean: 3686.078559738134
    time_step_min: 3264
  date: 2020-10-12_13-48-16
  done: false
  episode_len_mean: 872.9818037974684
  episode_reward_max: 295.0505050505051
  episode_reward_mean: 232.19389304436748
  episode_reward_min: 107.32323232323165
  episodes_this_iter: 260
  episodes_total: 1264
  experiment_id: 985103c329064696b5f4d20c8e91b85f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0448143283526103
        entropy_coeff: 0.0005000000000000001
        kl: 0.010054788862665495
        model: {}
        policy_loss: -0.013010791968554258
        total_loss: 22.180086135864258
        vf_explained_var: 0.9610714912414551
        vf_loss: 22.191608270009358
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.23225806451613
    gpu_util_percent0: 0.35677419354838713
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322577
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 76199
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15591196072084593
    mean_env_wait_ms: 1.1735926506350092
    mean_inference_ms: 4.994701230232948
    mean_raw_obs_processing_ms: 0.4149592390576975
  time_since_restore: 188.64129257202148
  time_this_iter_s: 26.407012462615967
  time_total_s: 188.64129257202148
  timers:
    learn_throughput: 8329.757
    learn_time_ms: 19423.375
    sample_throughput: 21721.272
    sample_time_ms: 7448.551
    update_time_ms: 26.829
  timestamp: 1602510496
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 1fc35_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1fc35_00000 | RUNNING  | 172.17.0.4:76199 |      7 |          188.641 | 1132544 |  232.194 |              295.051 |              107.323 |            872.982 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1fc35_00000:
  custom_metrics:
    time_step_max: 4503
    time_step_mean: 3674.076811594203
    time_step_min: 3264
  date: 2020-10-12_13-48-43
  done: false
  episode_len_mean: 867.28129395218
  episode_reward_max: 295.0505050505051
  episode_reward_mean: 233.72011251758062
  episode_reward_min: 107.32323232323165
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 985103c329064696b5f4d20c8e91b85f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0238245328267415
        entropy_coeff: 0.0005000000000000001
        kl: 0.010049917735159397
        model: {}
        policy_loss: -0.013329911239755651
        total_loss: 18.37956190109253
        vf_explained_var: 0.9616202712059021
        vf_loss: 18.391393661499023
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.893548387096775
    gpu_util_percent0: 0.3074193548387097
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7774193548387096
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 76199
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15521705612365316
    mean_env_wait_ms: 1.1750031767412605
    mean_inference_ms: 4.945642295201693
    mean_raw_obs_processing_ms: 0.4124600550306779
  time_since_restore: 215.09026837348938
  time_this_iter_s: 26.448975801467896
  time_total_s: 215.09026837348938
  timers:
    learn_throughput: 8326.892
    learn_time_ms: 19430.059
    sample_throughput: 21933.359
    sample_time_ms: 7376.526
    update_time_ms: 28.08
  timestamp: 1602510523
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 1fc35_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1fc35_00000 | RUNNING  | 172.17.0.4:76199 |      8 |           215.09 | 1294336 |   233.72 |              295.051 |              107.323 |            867.281 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1fc35_00000:
  custom_metrics:
    time_step_max: 4503
    time_step_mean: 3665.0344603381013
    time_step_min: 3264
  date: 2020-10-12_13-49-10
  done: false
  episode_len_mean: 861.8481012658228
  episode_reward_max: 295.0505050505051
  episode_reward_mean: 235.08560286408363
  episode_reward_min: 107.32323232323165
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 985103c329064696b5f4d20c8e91b85f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9940209239721298
        entropy_coeff: 0.0005000000000000001
        kl: 0.010795349953696132
        model: {}
        policy_loss: -0.014916640526886718
        total_loss: 18.37829812367757
        vf_explained_var: 0.9607771039009094
        vf_loss: 18.391552289326984
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.2
    gpu_util_percent0: 0.21838709677419357
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7806451612903227
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 76199
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1546158546890702
    mean_env_wait_ms: 1.1765423502930503
    mean_inference_ms: 4.902999990694045
    mean_raw_obs_processing_ms: 0.4102509078909061
  time_since_restore: 241.87047266960144
  time_this_iter_s: 26.78020429611206
  time_total_s: 241.87047266960144
  timers:
    learn_throughput: 8314.533
    learn_time_ms: 19458.94
    sample_throughput: 22058.13
    sample_time_ms: 7334.801
    update_time_ms: 29.338
  timestamp: 1602510550
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 1fc35_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1fc35_00000 | RUNNING  | 172.17.0.4:76199 |      9 |           241.87 | 1456128 |  235.086 |              295.051 |              107.323 |            861.848 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1fc35_00000:
  custom_metrics:
    time_step_max: 4503
    time_step_mean: 3648.92575928009
    time_step_min: 3264
  date: 2020-10-12_13-49-36
  done: false
  episode_len_mean: 854.9516483516484
  episode_reward_max: 295.0505050505051
  episode_reward_mean: 237.57148407148384
  episode_reward_min: 107.32323232323165
  episodes_this_iter: 240
  episodes_total: 1820
  experiment_id: 985103c329064696b5f4d20c8e91b85f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9356724520524343
        entropy_coeff: 0.0005000000000000001
        kl: 0.008661989743510881
        model: {}
        policy_loss: -0.013316753747252127
        total_loss: 21.960830847422283
        vf_explained_var: 0.967780351638794
        vf_loss: 21.972882588704426
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.503225806451614
    gpu_util_percent0: 0.2832258064516129
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322573
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 76199
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15384691804264547
    mean_env_wait_ms: 1.1792330033685834
    mean_inference_ms: 4.848666343712428
    mean_raw_obs_processing_ms: 0.4074641927081311
  time_since_restore: 268.33571577072144
  time_this_iter_s: 26.465243101119995
  time_total_s: 268.33571577072144
  timers:
    learn_throughput: 8312.348
    learn_time_ms: 19464.056
    sample_throughput: 22201.28
    sample_time_ms: 7287.508
    update_time_ms: 29.613
  timestamp: 1602510576
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 1fc35_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1fc35_00000 | RUNNING  | 172.17.0.4:76199 |     10 |          268.336 | 1617920 |  237.571 |              295.051 |              107.323 |            854.952 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1fc35_00000:
  custom_metrics:
    time_step_max: 4503
    time_step_mean: 3636.4314115308152
    time_step_min: 3264
  date: 2020-10-12_13-50-03
  done: false
  episode_len_mean: 848.9464459591042
  episode_reward_max: 295.0505050505051
  episode_reward_mean: 239.53930738740843
  episode_reward_min: 107.32323232323165
  episodes_this_iter: 234
  episodes_total: 2054
  experiment_id: 985103c329064696b5f4d20c8e91b85f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9489046484231949
        entropy_coeff: 0.0005000000000000001
        kl: 0.008599809215714535
        model: {}
        policy_loss: -0.013064989160435895
        total_loss: 14.519462823867798
        vf_explained_var: 0.9734243750572205
        vf_loss: 14.53128202756246
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.580000000000002
    gpu_util_percent0: 0.29500000000000004
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7666666666666657
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 76199
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1532429397620251
    mean_env_wait_ms: 1.1812514288345761
    mean_inference_ms: 4.805163509332853
    mean_raw_obs_processing_ms: 0.40518839329491935
  time_since_restore: 295.0157382488251
  time_this_iter_s: 26.680022478103638
  time_total_s: 295.0157382488251
  timers:
    learn_throughput: 8314.212
    learn_time_ms: 19459.691
    sample_throughput: 22951.272
    sample_time_ms: 7049.37
    update_time_ms: 30.891
  timestamp: 1602510603
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 1fc35_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1fc35_00000 | RUNNING  | 172.17.0.4:76199 |     11 |          295.016 | 1779712 |  239.539 |              295.051 |              107.323 |            848.946 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1fc35_00000:
  custom_metrics:
    time_step_max: 4503
    time_step_mean: 3627.040092165899
    time_step_min: 3264
  date: 2020-10-12_13-50-29
  done: false
  episode_len_mean: 845.245931283906
  episode_reward_max: 295.0505050505051
  episode_reward_mean: 240.83917840246932
  episode_reward_min: 107.32323232323165
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 985103c329064696b5f4d20c8e91b85f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9330548693736395
        entropy_coeff: 0.0005000000000000001
        kl: 0.009426808217540383
        model: {}
        policy_loss: -0.014281418814789504
        total_loss: 12.847650210062662
        vf_explained_var: 0.9719789028167725
        vf_loss: 12.860512812932333
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.135483870967743
    gpu_util_percent0: 0.30225806451612913
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 76199
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15288509723525073
    mean_env_wait_ms: 1.182667899781507
    mean_inference_ms: 4.7797303519830825
    mean_raw_obs_processing_ms: 0.4038580453972876
  time_since_restore: 321.46472692489624
  time_this_iter_s: 26.448988676071167
  time_total_s: 321.46472692489624
  timers:
    learn_throughput: 8315.108
    learn_time_ms: 19457.593
    sample_throughput: 23174.245
    sample_time_ms: 6981.543
    update_time_ms: 29.084
  timestamp: 1602510629
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 1fc35_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1fc35_00000 | RUNNING  | 172.17.0.4:76199 |     12 |          321.465 | 1941504 |  240.839 |              295.051 |              107.323 |            845.246 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1fc35_00000:
  custom_metrics:
    time_step_max: 4503
    time_step_mean: 3619.2574002574
    time_step_min: 3264
  date: 2020-10-12_13-50-56
  done: false
  episode_len_mean: 841.9490096923726
  episode_reward_max: 295.0505050505051
  episode_reward_mean: 242.0688554316871
  episode_reward_min: 107.32323232323165
  episodes_this_iter: 161
  episodes_total: 2373
  experiment_id: 985103c329064696b5f4d20c8e91b85f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8950163871049881
        entropy_coeff: 0.0005000000000000001
        kl: 0.008340420434251428
        model: {}
        policy_loss: -0.01250617066398263
        total_loss: 12.865858236948648
        vf_explained_var: 0.9739401936531067
        vf_loss: 12.877143700917562
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.603225806451615
    gpu_util_percent0: 0.2980645161290323
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.770967741935483
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 76199
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15255744828568177
    mean_env_wait_ms: 1.1841304667261991
    mean_inference_ms: 4.756426509326553
    mean_raw_obs_processing_ms: 0.4026287111521009
  time_since_restore: 347.98672246932983
  time_this_iter_s: 26.521995544433594
  time_total_s: 347.98672246932983
  timers:
    learn_throughput: 8310.257
    learn_time_ms: 19468.952
    sample_throughput: 23238.205
    sample_time_ms: 6962.328
    update_time_ms: 29.314
  timestamp: 1602510656
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 1fc35_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1fc35_00000 | RUNNING  | 172.17.0.4:76199 |     13 |          347.987 | 2103296 |  242.069 |              295.051 |              107.323 |            841.949 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1fc35_00000:
  custom_metrics:
    time_step_max: 4503
    time_step_mean: 3605.1953065859198
    time_step_min: 3264
  date: 2020-10-12_13-51-23
  done: false
  episode_len_mean: 835.6669150521609
  episode_reward_max: 300.3535353535352
  episode_reward_mean: 244.3068727513584
  episode_reward_min: 107.32323232323165
  episodes_this_iter: 311
  episodes_total: 2684
  experiment_id: 985103c329064696b5f4d20c8e91b85f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.874556784828504
        entropy_coeff: 0.0005000000000000001
        kl: 0.007318046099195878
        model: {}
        policy_loss: -0.0105582057231004
        total_loss: 17.12002642949422
        vf_explained_var: 0.9753594994544983
        vf_loss: 17.129558563232422
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.961290322580645
    gpu_util_percent0: 0.3061290322580646
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.76774193548387
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 76199
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15199993119182673
    mean_env_wait_ms: 1.1868402652559058
    mean_inference_ms: 4.717374336595038
    mean_raw_obs_processing_ms: 0.4006057900707982
  time_since_restore: 374.5324194431305
  time_this_iter_s: 26.54569697380066
  time_total_s: 374.5324194431305
  timers:
    learn_throughput: 8314.069
    learn_time_ms: 19460.025
    sample_throughput: 23211.979
    sample_time_ms: 6970.194
    update_time_ms: 36.488
  timestamp: 1602510683
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 1fc35_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1fc35_00000 | RUNNING  | 172.17.0.4:76199 |     14 |          374.532 | 2265088 |  244.307 |              300.354 |              107.323 |            835.667 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1fc35_00000:
  custom_metrics:
    time_step_max: 4503
    time_step_mean: 3598.9760885082082
    time_step_min: 3264
  date: 2020-10-12_13-51-49
  done: false
  episode_len_mean: 832.6744022503516
  episode_reward_max: 300.3535353535352
  episode_reward_mean: 245.22610066913848
  episode_reward_min: 107.32323232323165
  episodes_this_iter: 160
  episodes_total: 2844
  experiment_id: 985103c329064696b5f4d20c8e91b85f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8708053181568781
        entropy_coeff: 0.0005000000000000001
        kl: 0.007612888895285626
        model: {}
        policy_loss: -0.011600103268089393
        total_loss: 13.31410257021586
        vf_explained_var: 0.972301721572876
        vf_loss: 13.324615875879923
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.686666666666667
    gpu_util_percent0: 0.29733333333333334
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7833333333333328
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 76199
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15175077909438567
    mean_env_wait_ms: 1.1881027973355018
    mean_inference_ms: 4.699920797442407
    mean_raw_obs_processing_ms: 0.3996871353148927
  time_since_restore: 400.9707350730896
  time_this_iter_s: 26.438315629959106
  time_total_s: 400.9707350730896
  timers:
    learn_throughput: 8310.863
    learn_time_ms: 19467.533
    sample_throughput: 23230.108
    sample_time_ms: 6964.754
    update_time_ms: 35.553
  timestamp: 1602510709
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 1fc35_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1fc35_00000 | RUNNING  | 172.17.0.4:76199 |     15 |          400.971 | 2426880 |  245.226 |              300.354 |              107.323 |            832.674 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1fc35_00000:
  custom_metrics:
    time_step_max: 4503
    time_step_mean: 3591.3371621621623
    time_step_min: 3264
  date: 2020-10-12_13-52-16
  done: false
  episode_len_mean: 829.8937375083278
  episode_reward_max: 300.3535353535352
  episode_reward_mean: 246.23542217646133
  episode_reward_min: 107.32323232323165
  episodes_this_iter: 158
  episodes_total: 3002
  experiment_id: 985103c329064696b5f4d20c8e91b85f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8487290839354197
        entropy_coeff: 0.0005000000000000001
        kl: 0.009258047522356113
        model: {}
        policy_loss: -0.0130252216088896
        total_loss: 10.494753440221151
        vf_explained_var: 0.9762668609619141
        vf_loss: 10.506351073582968
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.21612903225807
    gpu_util_percent0: 0.3638709677419355
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7838709677419353
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 76199
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1515237705157873
    mean_env_wait_ms: 1.1893528135689986
    mean_inference_ms: 4.683991776671071
    mean_raw_obs_processing_ms: 0.39883635060057526
  time_since_restore: 427.52488255500793
  time_this_iter_s: 26.554147481918335
  time_total_s: 427.52488255500793
  timers:
    learn_throughput: 8307.864
    learn_time_ms: 19474.561
    sample_throughput: 23242.963
    sample_time_ms: 6960.902
    update_time_ms: 36.966
  timestamp: 1602510736
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 1fc35_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1fc35_00000 | RUNNING  | 172.17.0.4:76199 |     16 |          427.525 | 2588672 |  246.235 |              300.354 |              107.323 |            829.894 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1fc35_00000:
  custom_metrics:
    time_step_max: 4503
    time_step_mean: 3579.4921803127877
    time_step_min: 3255
  date: 2020-10-12_13-52-43
  done: false
  episode_len_mean: 825.2612776264002
  episode_reward_max: 300.3535353535352
  episode_reward_mean: 247.95901797264182
  episode_reward_min: 107.32323232323165
  episodes_this_iter: 301
  episodes_total: 3303
  experiment_id: 985103c329064696b5f4d20c8e91b85f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8091975698868433
        entropy_coeff: 0.0005000000000000001
        kl: 0.007185644702985883
        model: {}
        policy_loss: -0.010285617575088205
        total_loss: 15.45983068148295
        vf_explained_var: 0.9778881669044495
        vf_loss: 15.469083627065023
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.0
    gpu_util_percent0: 0.3370967741935484
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7580645161290316
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 76199
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15115002791367826
    mean_env_wait_ms: 1.1917215775769314
    mean_inference_ms: 4.657221123250723
    mean_raw_obs_processing_ms: 0.3974369437338945
  time_since_restore: 454.0848345756531
  time_this_iter_s: 26.55995202064514
  time_total_s: 454.0848345756531
  timers:
    learn_throughput: 8307.956
    learn_time_ms: 19474.346
    sample_throughput: 23209.911
    sample_time_ms: 6970.815
    update_time_ms: 39.31
  timestamp: 1602510763
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 1fc35_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1fc35_00000 | RUNNING  | 172.17.0.4:76199 |     17 |          454.085 | 2750464 |  247.959 |              300.354 |              107.323 |            825.261 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1fc35_00000:
  custom_metrics:
    time_step_max: 4503
    time_step_mean: 3573.141817122889
    time_step_min: 3242
  date: 2020-10-12_13-53-10
  done: false
  episode_len_mean: 822.909666283084
  episode_reward_max: 300.3535353535352
  episode_reward_mean: 248.85703990422041
  episode_reward_min: 107.32323232323165
  episodes_this_iter: 173
  episodes_total: 3476
  experiment_id: 985103c329064696b5f4d20c8e91b85f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8145886361598969
        entropy_coeff: 0.0005000000000000001
        kl: 0.0075280776945874095
        model: {}
        policy_loss: -0.010826747709264358
        total_loss: 11.83052404721578
        vf_explained_var: 0.9753438830375671
        vf_loss: 11.840252240498861
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.977419354838712
    gpu_util_percent0: 0.3258064516129032
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7806451612903222
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 76199
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15094818072367466
    mean_env_wait_ms: 1.1928576879828128
    mean_inference_ms: 4.643204685728231
    mean_raw_obs_processing_ms: 0.39669418908992443
  time_since_restore: 481.0176429748535
  time_this_iter_s: 26.93280839920044
  time_total_s: 481.0176429748535
  timers:
    learn_throughput: 8303.812
    learn_time_ms: 19484.064
    sample_throughput: 23086.962
    sample_time_ms: 7007.938
    update_time_ms: 39.671
  timestamp: 1602510790
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 1fc35_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1fc35_00000 | RUNNING  | 172.17.0.4:76199 |     18 |          481.018 | 2912256 |  248.857 |              300.354 |              107.323 |             822.91 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1fc35_00000:
  custom_metrics:
    time_step_max: 4503
    time_step_mean: 3567.797048997773
    time_step_min: 3217
  date: 2020-10-12_13-53-36
  done: false
  episode_len_mean: 820.6920748486516
  episode_reward_max: 302.171717171717
  episode_reward_mean: 249.649160843437
  episode_reward_min: 107.32323232323165
  episodes_this_iter: 158
  episodes_total: 3634
  experiment_id: 985103c329064696b5f4d20c8e91b85f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7923821012179056
        entropy_coeff: 0.0005000000000000001
        kl: 0.00808877288363874
        model: {}
        policy_loss: -0.013099419719461972
        total_loss: 10.289549430211386
        vf_explained_var: 0.9767322540283203
        vf_loss: 10.301427364349365
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.161290322580644
    gpu_util_percent0: 0.31258064516129036
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7677419354838704
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 76199
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15078171753032404
    mean_env_wait_ms: 1.1939246176560676
    mean_inference_ms: 4.631445800744197
    mean_raw_obs_processing_ms: 0.39606376771489277
  time_since_restore: 507.481201171875
  time_this_iter_s: 26.463558197021484
  time_total_s: 507.481201171875
  timers:
    learn_throughput: 8315.509
    learn_time_ms: 19456.657
    sample_throughput: 23105.389
    sample_time_ms: 7002.349
    update_time_ms: 39.854
  timestamp: 1602510816
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 1fc35_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1fc35_00000 | RUNNING  | 172.17.0.4:76199 |     19 |          507.481 | 3074048 |  249.649 |              302.172 |              107.323 |            820.692 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1fc35_00000:
  custom_metrics:
    time_step_max: 4503
    time_step_mean: 3558.4255154639177
    time_step_min: 3217
  date: 2020-10-12_13-54-03
  done: false
  episode_len_mean: 816.9673635900051
  episode_reward_max: 302.171717171717
  episode_reward_mean: 250.90883336166343
  episode_reward_min: 107.32323232323165
  episodes_this_iter: 288
  episodes_total: 3922
  experiment_id: 985103c329064696b5f4d20c8e91b85f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.75344517827034
        entropy_coeff: 0.0005000000000000001
        kl: 0.0067164797413473325
        model: {}
        policy_loss: -0.010622997457782427
        total_loss: 17.49881712595622
        vf_explained_var: 0.9746193289756775
        vf_loss: 17.50847355524699
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.077419354838714
    gpu_util_percent0: 0.3351612903225807
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322577
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 76199
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15051214556534087
    mean_env_wait_ms: 1.195944772748082
    mean_inference_ms: 4.612215058870887
    mean_raw_obs_processing_ms: 0.39505482168178874
  time_since_restore: 533.810601234436
  time_this_iter_s: 26.329400062561035
  time_total_s: 533.810601234436
  timers:
    learn_throughput: 8326.437
    learn_time_ms: 19431.119
    sample_throughput: 23064.264
    sample_time_ms: 7014.835
    update_time_ms: 39.235
  timestamp: 1602510843
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 1fc35_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1fc35_00000 | RUNNING  | 172.17.0.4:76199 |     20 |          533.811 | 3235840 |  250.909 |              302.172 |              107.323 |            816.967 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1fc35_00000:
  custom_metrics:
    time_step_max: 4503
    time_step_mean: 3553.112395474668
    time_step_min: 3217
  date: 2020-10-12_13-54-30
  done: false
  episode_len_mean: 814.7395326192794
  episode_reward_max: 302.171717171717
  episode_reward_mean: 251.69603778780981
  episode_reward_min: 107.32323232323165
  episodes_this_iter: 186
  episodes_total: 4108
  experiment_id: 985103c329064696b5f4d20c8e91b85f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7660313298304876
        entropy_coeff: 0.0005000000000000001
        kl: 0.007230627117678523
        model: {}
        policy_loss: -0.013739645374395574
        total_loss: 9.73851235707601
        vf_explained_var: 0.9799140095710754
        vf_loss: 9.7511887550354
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.99677419354838
    gpu_util_percent0: 0.35870967741935483
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7806451612903222
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 76199
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15034329990151918
    mean_env_wait_ms: 1.1970053972373533
    mean_inference_ms: 4.600556431040194
    mean_raw_obs_processing_ms: 0.39442936545410706
  time_since_restore: 560.3510069847107
  time_this_iter_s: 26.540405750274658
  time_total_s: 560.3510069847107
  timers:
    learn_throughput: 8335.67
    learn_time_ms: 19409.597
    sample_throughput: 23042.356
    sample_time_ms: 7021.504
    update_time_ms: 39.022
  timestamp: 1602510870
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: 1fc35_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1fc35_00000 | RUNNING  | 172.17.0.4:76199 |     21 |          560.351 | 3397632 |  251.696 |              302.172 |              107.323 |             814.74 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1fc35_00000:
  custom_metrics:
    time_step_max: 4503
    time_step_mean: 3548.4055397727275
    time_step_min: 3178
  date: 2020-10-12_13-54-56
  done: false
  episode_len_mean: 812.9364744491327
  episode_reward_max: 308.0808080808081
  episode_reward_mean: 252.40364261461298
  episode_reward_min: 107.32323232323165
  episodes_this_iter: 158
  episodes_total: 4266
  experiment_id: 985103c329064696b5f4d20c8e91b85f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.750475729505221
        entropy_coeff: 0.0005000000000000001
        kl: 0.008350916400862237
        model: {}
        policy_loss: -0.010536311772132953
        total_loss: 11.030436754226685
        vf_explained_var: 0.9748828411102295
        vf_loss: 11.03967833518982
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.20967741935484
    gpu_util_percent0: 0.29032258064516137
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.777419354838709
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 76199
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15021340827719915
    mean_env_wait_ms: 1.197952994925246
    mean_inference_ms: 4.591439892805338
    mean_raw_obs_processing_ms: 0.3939417492177612
  time_since_restore: 586.8087751865387
  time_this_iter_s: 26.457768201828003
  time_total_s: 586.8087751865387
  timers:
    learn_throughput: 8339.97
    learn_time_ms: 19399.589
    sample_throughput: 23016.993
    sample_time_ms: 7029.241
    update_time_ms: 40.68
  timestamp: 1602510896
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: 1fc35_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1fc35_00000 | RUNNING  | 172.17.0.4:76199 |     22 |          586.809 | 3559424 |  252.404 |              308.081 |              107.323 |            812.936 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1fc35_00000:
  custom_metrics:
    time_step_max: 4503
    time_step_mean: 3539.924047829938
    time_step_min: 3178
  date: 2020-10-12_13-55-23
  done: true
  episode_len_mean: 809.7896007020623
  episode_reward_max: 308.0808080808081
  episode_reward_mean: 253.66778801618634
  episode_reward_min: 107.32323232323165
  episodes_this_iter: 292
  episodes_total: 4558
  experiment_id: 985103c329064696b5f4d20c8e91b85f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7034900238116583
        entropy_coeff: 0.0005000000000000001
        kl: 0.007229706350093086
        model: {}
        policy_loss: -0.012437420101681104
        total_loss: 14.059581915537516
        vf_explained_var: 0.9788525700569153
        vf_loss: 14.070924838383993
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.193548387096776
    gpu_util_percent0: 0.30870967741935484
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7741935483870965
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 76199
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14999419980760334
    mean_env_wait_ms: 1.1997350682168955
    mean_inference_ms: 4.576015062720443
    mean_raw_obs_processing_ms: 0.3931310685502461
  time_since_restore: 613.5425126552582
  time_this_iter_s: 26.733737468719482
  time_total_s: 613.5425126552582
  timers:
    learn_throughput: 8342.85
    learn_time_ms: 19392.894
    sample_throughput: 22929.545
    sample_time_ms: 7056.049
    update_time_ms: 40.607
  timestamp: 1602510923
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: 1fc35_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1fc35_00000 | TERMINATED |       |     23 |          613.543 | 3721216 |  253.668 |              308.081 |              107.323 |             809.79 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1fc35_00000 | TERMINATED |       |     23 |          613.543 | 3721216 |  253.668 |              308.081 |              107.323 |             809.79 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


