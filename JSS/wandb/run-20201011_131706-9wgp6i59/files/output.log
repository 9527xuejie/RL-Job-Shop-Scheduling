2020-10-11 13:17:10,781	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_12c77_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=18363)[0m 2020-10-11 13:17:13,680	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=18321)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18321)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18246)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18246)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18244)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18244)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18313)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18313)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18357)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18357)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18302)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18302)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18338)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18338)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18351)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18351)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18343)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18343)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18274)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18274)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18352)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18352)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18294)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18294)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18369)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18369)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18258)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18258)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18271)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18271)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18329)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18329)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18252)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18252)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18342)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18342)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18298)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18298)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18253)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18253)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18266)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18266)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18320)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18320)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18340)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18340)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18254)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18254)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18347)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18347)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18362)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18362)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18332)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18332)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18328)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18328)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18319)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18319)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18306)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18306)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18346)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18346)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18257)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18257)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18359)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18359)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18262)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18262)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18325)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18325)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18265)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18265)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18247)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18247)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18275)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18275)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18267)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18267)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18333)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18333)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18350)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18350)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18255)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18255)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18364)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18364)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18269)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18269)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18374)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18374)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18291)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18291)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18280)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18280)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18272)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18272)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18345)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18345)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18327)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18327)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18268)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18268)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18251)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18251)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18264)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18264)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18278)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18278)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18300)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18300)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18249)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18249)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18367)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18367)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18335)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18335)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18355)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18355)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18315)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18315)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18242)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18242)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18311)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18311)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18293)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18293)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18259)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18259)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18323)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18323)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18314)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18314)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18339)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18339)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18354)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18354)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18243)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18243)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18256)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18256)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18245)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18245)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18371)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18371)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18324)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18324)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18326)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18326)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18299)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18299)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18304)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18304)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18322)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18322)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18330)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18330)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18260)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18260)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_12c77_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-11_13-17-50
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: eceadde4c614499bacaa06e529b83d59
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.1841148257255554
        entropy_coeff: 0.0001
        kl: 0.004917999496683478
        model: {}
        policy_loss: -0.010679529746994376
        total_loss: 505.8379760742188
        vf_explained_var: 0.542610764503479
        vf_loss: 505.84778747558596
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.478378378378384
    gpu_util_percent0: 0.2624324324324324
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5729729729729724
    vram_util_percent0: 0.0910777126749577
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 18363
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17433065807204734
    mean_env_wait_ms: 1.1855553918210175
    mean_inference_ms: 5.984090962281893
    mean_raw_obs_processing_ms: 0.46326246553087136
  time_since_restore: 31.639983892440796
  time_this_iter_s: 31.639983892440796
  time_total_s: 31.639983892440796
  timers:
    learn_throughput: 7256.763
    learn_time_ms: 22295.341
    sample_throughput: 17456.976
    sample_time_ms: 9268.043
    update_time_ms: 41.77
  timestamp: 1602422270
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 12c77_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_12c77_00000 | RUNNING  | 172.17.0.4:18363 |      1 |            31.64 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_12c77_00000:
  custom_metrics:
    time_step_max: 4264
    time_step_mean: 3617.4166666666665
    time_step_min: 3282
  date: 2020-10-11_13-18-20
  done: false
  episode_len_mean: 889.9462025316456
  episode_reward_max: 268.74747474747466
  episode_reward_mean: 217.02710650811898
  episode_reward_min: 119.95959595959577
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: eceadde4c614499bacaa06e529b83d59
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.1527080178260802
        entropy_coeff: 0.0001
        kl: 0.006816077511757612
        model: {}
        policy_loss: -0.012106262380257249
        total_loss: 132.2905502319336
        vf_explained_var: 0.8015682101249695
        vf_loss: 132.30208740234374
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.982857142857142
    gpu_util_percent0: 0.31514285714285717
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7542857142857144
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 18363
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1692451303679984
    mean_env_wait_ms: 1.1781020416692767
    mean_inference_ms: 5.708517515283157
    mean_raw_obs_processing_ms: 0.4508108276572619
  time_since_restore: 61.41343927383423
  time_this_iter_s: 29.773455381393433
  time_total_s: 61.41343927383423
  timers:
    learn_throughput: 7314.691
    learn_time_ms: 22118.774
    sample_throughput: 19023.917
    sample_time_ms: 8504.663
    update_time_ms: 41.97
  timestamp: 1602422300
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 12c77_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_12c77_00000 | RUNNING  | 172.17.0.4:18363 |      2 |          61.4134 | 323584 |  217.027 |              268.747 |               119.96 |            889.946 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_12c77_00000:
  custom_metrics:
    time_step_max: 4264
    time_step_mean: 3616.6614349775787
    time_step_min: 3282
  date: 2020-10-11_13-18-50
  done: false
  episode_len_mean: 884.951476793249
  episode_reward_max: 268.74747474747466
  episode_reward_mean: 217.58234241145615
  episode_reward_min: 119.95959595959577
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: eceadde4c614499bacaa06e529b83d59
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.139493715763092
        entropy_coeff: 0.0001
        kl: 0.009640024416148663
        model: {}
        policy_loss: -0.013698664214462041
        total_loss: 61.53116455078125
        vf_explained_var: 0.8929950594902039
        vf_loss: 61.54401397705078
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.454285714285714
    gpu_util_percent0: 0.3508571428571428
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7685714285714287
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 18363
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16585894155450284
    mean_env_wait_ms: 1.1753435842071551
    mean_inference_ms: 5.500309635320118
    mean_raw_obs_processing_ms: 0.44181825209067643
  time_since_restore: 90.87421369552612
  time_this_iter_s: 29.460774421691895
  time_total_s: 90.87421369552612
  timers:
    learn_throughput: 7303.824
    learn_time_ms: 22151.685
    sample_throughput: 20077.693
    sample_time_ms: 8058.296
    update_time_ms: 39.002
  timestamp: 1602422330
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 12c77_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_12c77_00000 | RUNNING  | 172.17.0.4:18363 |      3 |          90.8742 | 485376 |  217.582 |              268.747 |               119.96 |            884.951 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_12c77_00000:
  custom_metrics:
    time_step_max: 4264
    time_step_mean: 3608.6258278145697
    time_step_min: 3217
  date: 2020-10-11_13-19-19
  done: false
  episode_len_mean: 881.7689873417721
  episode_reward_max: 278.5959595959589
  episode_reward_mean: 219.19602672292524
  episode_reward_min: 119.95959595959577
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: eceadde4c614499bacaa06e529b83d59
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.1232908010482787
        entropy_coeff: 0.0001
        kl: 0.008994864206761122
        model: {}
        policy_loss: -0.014683684846386314
        total_loss: 43.65212631225586
        vf_explained_var: 0.9194347262382507
        vf_loss: 43.66602249145508
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.473529411764705
    gpu_util_percent0: 0.29352941176470587
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7764705882352945
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 18363
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1634558191429539
    mean_env_wait_ms: 1.1742598895232204
    mean_inference_ms: 5.349000569558883
    mean_raw_obs_processing_ms: 0.4348139236400328
  time_since_restore: 120.01840400695801
  time_this_iter_s: 29.144190311431885
  time_total_s: 120.01840400695801
  timers:
    learn_throughput: 7327.329
    learn_time_ms: 22080.625
    sample_throughput: 20635.517
    sample_time_ms: 7840.463
    update_time_ms: 37.503
  timestamp: 1602422359
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 12c77_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_12c77_00000 | RUNNING  | 172.17.0.4:18363 |      4 |          120.018 | 647168 |  219.196 |              278.596 |               119.96 |            881.769 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_12c77_00000:
  custom_metrics:
    time_step_max: 4264
    time_step_mean: 3599.246719160105
    time_step_min: 3217
  date: 2020-10-11_13-19-47
  done: false
  episode_len_mean: 878.1721518987342
  episode_reward_max: 278.5959595959589
  episode_reward_mean: 220.83320547244577
  episode_reward_min: 119.95959595959577
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: eceadde4c614499bacaa06e529b83d59
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.0947289705276488
        entropy_coeff: 0.0001
        kl: 0.00860484605655074
        model: {}
        policy_loss: -0.015152098797261714
        total_loss: 30.289466094970702
        vf_explained_var: 0.9471577405929565
        vf_loss: 30.30386734008789
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.94545454545454
    gpu_util_percent0: 0.4493939393939394
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.775757575757576
    vram_util_percent0: 0.10897015414890128
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 18363
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16166310994678645
    mean_env_wait_ms: 1.1738538751722747
    mean_inference_ms: 5.233890185949283
    mean_raw_obs_processing_ms: 0.42908613537998497
  time_since_restore: 148.5655128955841
  time_this_iter_s: 28.5471088886261
  time_total_s: 148.5655128955841
  timers:
    learn_throughput: 7364.209
    learn_time_ms: 21970.045
    sample_throughput: 21116.654
    sample_time_ms: 7661.82
    update_time_ms: 34.012
  timestamp: 1602422387
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 12c77_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_12c77_00000 | RUNNING  | 172.17.0.4:18363 |      5 |          148.566 | 808960 |  220.833 |              278.596 |               119.96 |            878.172 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_12c77_00000:
  custom_metrics:
    time_step_max: 4264
    time_step_mean: 3572.980318650422
    time_step_min: 3176
  date: 2020-10-11_13-20-17
  done: false
  episode_len_mean: 870.0584474885844
  episode_reward_max: 284.80808080808083
  episode_reward_mean: 224.50311332503094
  episode_reward_min: 119.95959595959577
  episodes_this_iter: 305
  episodes_total: 1095
  experiment_id: eceadde4c614499bacaa06e529b83d59
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.0759007573127746
        entropy_coeff: 0.0001
        kl: 0.008370665367692709
        model: {}
        policy_loss: -0.01382834855467081
        total_loss: 32.52159156799316
        vf_explained_var: 0.9592925906181335
        vf_loss: 32.53469066619873
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.225714285714286
    gpu_util_percent0: 0.29000000000000004
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7685714285714287
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 18363
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1592891265714289
    mean_env_wait_ms: 1.1754853490811812
    mean_inference_ms: 5.08267827092954
    mean_raw_obs_processing_ms: 0.4217346419300896
  time_since_restore: 177.89227652549744
  time_this_iter_s: 29.32676362991333
  time_total_s: 177.89227652549744
  timers:
    learn_throughput: 7358.98
    learn_time_ms: 21985.655
    sample_throughput: 21340.345
    sample_time_ms: 7581.508
    update_time_ms: 34.168
  timestamp: 1602422417
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 12c77_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_12c77_00000 | RUNNING  | 172.17.0.4:18363 |      6 |          177.892 | 970752 |  224.503 |              284.808 |               119.96 |            870.058 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_12c77_00000:
  custom_metrics:
    time_step_max: 4264
    time_step_mean: 3562.7888349514565
    time_step_min: 3176
  date: 2020-10-11_13-20-46
  done: false
  episode_len_mean: 865.2650316455696
  episode_reward_max: 284.80808080808083
  episode_reward_mean: 226.04777202403767
  episode_reward_min: 119.95959595959577
  episodes_this_iter: 169
  episodes_total: 1264
  experiment_id: eceadde4c614499bacaa06e529b83d59
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.0651807546615601
        entropy_coeff: 0.0001
        kl: 0.008109573926776647
        model: {}
        policy_loss: -0.014530989015474916
        total_loss: 20.533876609802245
        vf_explained_var: 0.9642189145088196
        vf_loss: 20.547703170776366
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.13235294117647
    gpu_util_percent0: 0.3723529411764706
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7882352941176474
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 18363
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1583522866263687
    mean_env_wait_ms: 1.1762804470594392
    mean_inference_ms: 5.022957324082675
    mean_raw_obs_processing_ms: 0.41875026569759105
  time_since_restore: 206.91372156143188
  time_this_iter_s: 29.02144503593445
  time_total_s: 206.91372156143188
  timers:
    learn_throughput: 7374.536
    learn_time_ms: 21939.278
    sample_throughput: 21491.43
    sample_time_ms: 7528.21
    update_time_ms: 43.783
  timestamp: 1602422446
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 12c77_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_12c77_00000 | RUNNING  | 172.17.0.4:18363 |      7 |          206.914 | 1132544 |  226.048 |              284.808 |               119.96 |            865.265 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_12c77_00000:
  custom_metrics:
    time_step_max: 4264
    time_step_mean: 3554.24175035868
    time_step_min: 3176
  date: 2020-10-11_13-21-15
  done: false
  episode_len_mean: 861.1947960618846
  episode_reward_max: 284.80808080808083
  episode_reward_mean: 227.48772535481376
  episode_reward_min: 119.95959595959577
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: eceadde4c614499bacaa06e529b83d59
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.0406574487686158
        entropy_coeff: 0.0001
        kl: 0.008543166937306524
        model: {}
        policy_loss: -0.01388885620981455
        total_loss: 19.90455379486084
        vf_explained_var: 0.9641757011413574
        vf_loss: 19.917692184448242
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.666666666666668
    gpu_util_percent0: 0.4196969696969697
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.775757575757576
    vram_util_percent0: 0.10897015414890128
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 18363
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15759740314646986
    mean_env_wait_ms: 1.177112629236795
    mean_inference_ms: 4.97495633375644
    mean_raw_obs_processing_ms: 0.41630101929696295
  time_since_restore: 235.7926926612854
  time_this_iter_s: 28.878971099853516
  time_total_s: 235.7926926612854
  timers:
    learn_throughput: 7382.229
    learn_time_ms: 21916.415
    sample_throughput: 21670.216
    sample_time_ms: 7466.1
    update_time_ms: 42.647
  timestamp: 1602422475
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 12c77_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_12c77_00000 | RUNNING  | 172.17.0.4:18363 |      8 |          235.793 | 1294336 |  227.488 |              284.808 |               119.96 |            861.195 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_12c77_00000:
  custom_metrics:
    time_step_max: 4264
    time_step_mean: 3545.873067010309
    time_step_min: 3176
  date: 2020-10-11_13-21-44
  done: false
  episode_len_mean: 857.8462025316455
  episode_reward_max: 284.80808080808083
  episode_reward_mean: 228.75351617440208
  episode_reward_min: 119.95959595959577
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: eceadde4c614499bacaa06e529b83d59
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.0099902987480163
        entropy_coeff: 0.0001
        kl: 0.00771885197609663
        model: {}
        policy_loss: -0.014868383202701807
        total_loss: 16.671735191345213
        vf_explained_var: 0.969342052936554
        vf_loss: 16.68593273162842
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.202941176470592
    gpu_util_percent0: 0.40088235294117647
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.770588235294118
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 18363
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15693666341507084
    mean_env_wait_ms: 1.17790947443985
    mean_inference_ms: 4.932952508087572
    mean_raw_obs_processing_ms: 0.41408454252644855
  time_since_restore: 264.59907126426697
  time_this_iter_s: 28.806378602981567
  time_total_s: 264.59907126426697
  timers:
    learn_throughput: 7391.553
    learn_time_ms: 21888.771
    sample_throughput: 21799.687
    sample_time_ms: 7421.758
    update_time_ms: 40.255
  timestamp: 1602422504
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 12c77_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_12c77_00000 | RUNNING  | 172.17.0.4:18363 |      9 |          264.599 | 1456128 |  228.754 |              284.808 |               119.96 |            857.846 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_12c77_00000:
  custom_metrics:
    time_step_max: 4264
    time_step_mean: 3531.832136940917
    time_step_min: 3159
  date: 2020-10-11_13-22-13
  done: false
  episode_len_mean: 852.9891245241979
  episode_reward_max: 287.3838383838387
  episode_reward_mean: 231.01979007036087
  episode_reward_min: 119.95959595959577
  episodes_this_iter: 259
  episodes_total: 1839
  experiment_id: eceadde4c614499bacaa06e529b83d59
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.9737480700016021
        entropy_coeff: 0.0001
        kl: 0.00783180040307343
        model: {}
        policy_loss: -0.013539057364687324
        total_loss: 23.508492088317873
        vf_explained_var: 0.9699012637138367
        vf_loss: 23.521345710754396
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.652941176470588
    gpu_util_percent0: 0.37941176470588234
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.761764705882353
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 18363
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15605845272793564
    mean_env_wait_ms: 1.1794098445234171
    mean_inference_ms: 4.875686842386676
    mean_raw_obs_processing_ms: 0.4110722427424983
  time_since_restore: 293.52161478996277
  time_this_iter_s: 28.9225435256958
  time_total_s: 293.52161478996277
  timers:
    learn_throughput: 7398.252
    learn_time_ms: 21868.948
    sample_throughput: 21883.68
    sample_time_ms: 7393.272
    update_time_ms: 40.287
  timestamp: 1602422533
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 12c77_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_12c77_00000 | RUNNING  | 172.17.0.4:18363 |     10 |          293.522 | 1617920 |   231.02 |              287.384 |               119.96 |            852.989 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_12c77_00000:
  custom_metrics:
    time_step_max: 4264
    time_step_mean: 3523.1377097729514
    time_step_min: 3159
  date: 2020-10-11_13-22-42
  done: false
  episode_len_mean: 849.1124634858812
  episode_reward_max: 287.3838383838387
  episode_reward_mean: 232.63088037138655
  episode_reward_min: 119.95959595959577
  episodes_this_iter: 215
  episodes_total: 2054
  experiment_id: eceadde4c614499bacaa06e529b83d59
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.9689526498317719
        entropy_coeff: 0.0001
        kl: 0.0073252371046692135
        model: {}
        policy_loss: -0.013649152778089046
        total_loss: 17.32485408782959
        vf_explained_var: 0.9711908102035522
        vf_loss: 17.337867546081544
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.27352941176471
    gpu_util_percent0: 0.3247058823529412
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7764705882352945
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 18363
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15542671688249482
    mean_env_wait_ms: 1.1803767767898579
    mean_inference_ms: 4.836288198581999
    mean_raw_obs_processing_ms: 0.4089657002838733
  time_since_restore: 322.6734263896942
  time_this_iter_s: 29.151811599731445
  time_total_s: 322.6734263896942
  timers:
    learn_throughput: 7410.657
    learn_time_ms: 21832.344
    sample_throughput: 22535.912
    sample_time_ms: 7179.297
    update_time_ms: 40.146
  timestamp: 1602422562
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 12c77_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_12c77_00000 | RUNNING  | 172.17.0.4:18363 |     11 |          322.673 | 1779712 |  232.631 |              287.384 |               119.96 |            849.112 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_12c77_00000:
  custom_metrics:
    time_step_max: 4264
    time_step_mean: 3514.3374542124543
    time_step_min: 3159
  date: 2020-10-11_13-23-11
  done: false
  episode_len_mean: 846.121609403255
  episode_reward_max: 287.3838383838387
  episode_reward_mean: 233.92289531846478
  episode_reward_min: 119.95959595959577
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: eceadde4c614499bacaa06e529b83d59
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.9541051328182221
        entropy_coeff: 0.0001
        kl: 0.007601859327405691
        model: {}
        policy_loss: -0.014244027761742472
        total_loss: 14.842232513427735
        vf_explained_var: 0.9712217450141907
        vf_loss: 14.855811882019044
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.279411764705884
    gpu_util_percent0: 0.3029411764705883
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7794117647058822
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 18363
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15503267306927881
    mean_env_wait_ms: 1.1811250390553576
    mean_inference_ms: 4.810916733974038
    mean_raw_obs_processing_ms: 0.40759315773460847
  time_since_restore: 351.69016909599304
  time_this_iter_s: 29.016742706298828
  time_total_s: 351.69016909599304
  timers:
    learn_throughput: 7412.763
    learn_time_ms: 21826.139
    sample_throughput: 22763.972
    sample_time_ms: 7107.371
    update_time_ms: 39.791
  timestamp: 1602422591
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 12c77_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_12c77_00000 | RUNNING  | 172.17.0.4:18363 |     12 |           351.69 | 1941504 |  233.923 |              287.384 |               119.96 |            846.122 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_12c77_00000:
  custom_metrics:
    time_step_max: 4264
    time_step_mean: 3507.3275053304906
    time_step_min: 3159
  date: 2020-10-11_13-23-40
  done: false
  episode_len_mean: 843.1411715128529
  episode_reward_max: 287.3838383838387
  episode_reward_mean: 235.12043315583128
  episode_reward_min: 119.95959595959577
  episodes_this_iter: 161
  episodes_total: 2373
  experiment_id: eceadde4c614499bacaa06e529b83d59
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.9289745569229126
        entropy_coeff: 0.0001
        kl: 0.007398022385314107
        model: {}
        policy_loss: -0.014882047101855278
        total_loss: 14.037666606903077
        vf_explained_var: 0.9735888242721558
        vf_loss: 14.051901912689209
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.5030303030303
    gpu_util_percent0: 0.30393939393939395
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7787878787878793
    vram_util_percent0: 0.10897015414890128
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 18363
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15466598139677337
    mean_env_wait_ms: 1.1819145168046754
    mean_inference_ms: 4.7873292783707075
    mean_raw_obs_processing_ms: 0.4062895820077555
  time_since_restore: 380.3843684196472
  time_this_iter_s: 28.694199323654175
  time_total_s: 380.3843684196472
  timers:
    learn_throughput: 7427.848
    learn_time_ms: 21781.814
    sample_throughput: 22872.51
    sample_time_ms: 7073.644
    update_time_ms: 40.302
  timestamp: 1602422620
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 12c77_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_12c77_00000 | RUNNING  | 172.17.0.4:18363 |     13 |          380.384 | 2103296 |   235.12 |              287.384 |               119.96 |            843.141 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_12c77_00000:
  custom_metrics:
    time_step_max: 4264
    time_step_mean: 3494.4560938682816
    time_step_min: 3157
  date: 2020-10-11_13-24-09
  done: false
  episode_len_mean: 838.3681647940075
  episode_reward_max: 287.6868686868685
  episode_reward_mean: 237.1203609124956
  episode_reward_min: 119.95959595959577
  episodes_this_iter: 297
  episodes_total: 2670
  experiment_id: eceadde4c614499bacaa06e529b83d59
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.9042334794998169
        entropy_coeff: 0.0001
        kl: 0.007176685938611626
        model: {}
        policy_loss: -0.01298322482034564
        total_loss: 18.53554630279541
        vf_explained_var: 0.9748600721359253
        vf_loss: 18.547901725769044
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.661764705882355
    gpu_util_percent0: 0.4173529411764706
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.764705882352941
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 18363
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15408475574239403
    mean_env_wait_ms: 1.1835002166301518
    mean_inference_ms: 4.749652075857732
    mean_raw_obs_processing_ms: 0.40425681041426936
  time_since_restore: 409.27216053009033
  time_this_iter_s: 28.887792110443115
  time_total_s: 409.27216053009033
  timers:
    learn_throughput: 7431.056
    learn_time_ms: 21772.411
    sample_throughput: 22930.808
    sample_time_ms: 7055.661
    update_time_ms: 41.113
  timestamp: 1602422649
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 12c77_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_12c77_00000 | RUNNING  | 172.17.0.4:18363 |     14 |          409.272 | 2265088 |   237.12 |              287.687 |               119.96 |            838.368 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_12c77_00000:
  custom_metrics:
    time_step_max: 4264
    time_step_mean: 3488.01171875
    time_step_min: 3157
  date: 2020-10-11_13-24-38
  done: false
  episode_len_mean: 836.1722925457103
  episode_reward_max: 291.777777777778
  episode_reward_mean: 238.0940523377231
  episode_reward_min: 119.95959595959577
  episodes_this_iter: 174
  episodes_total: 2844
  experiment_id: eceadde4c614499bacaa06e529b83d59
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.8849878549575806
        entropy_coeff: 0.0001
        kl: 0.006577923148870468
        model: {}
        policy_loss: -0.01324602598324418
        total_loss: 13.78815574645996
        vf_explained_var: 0.9754125475883484
        vf_loss: 13.800832366943359
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.54705882352941
    gpu_util_percent0: 0.41794117647058826
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7882352941176474
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 18363
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15377996188409107
    mean_env_wait_ms: 1.1842903136132747
    mean_inference_ms: 4.730353959106829
    mean_raw_obs_processing_ms: 0.40323125344437094
  time_since_restore: 438.30161213874817
  time_this_iter_s: 29.029451608657837
  time_total_s: 438.30161213874817
  timers:
    learn_throughput: 7414.632
    learn_time_ms: 21820.638
    sample_throughput: 22939.932
    sample_time_ms: 7052.854
    update_time_ms: 43.229
  timestamp: 1602422678
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 12c77_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_12c77_00000 | RUNNING  | 172.17.0.4:18363 |     15 |          438.302 | 2426880 |  238.094 |              291.778 |               119.96 |            836.172 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_12c77_00000:
  custom_metrics:
    time_step_max: 4264
    time_step_mean: 3482.3352387357095
    time_step_min: 3157
  date: 2020-10-11_13-25-07
  done: false
  episode_len_mean: 834.288474350433
  episode_reward_max: 291.777777777778
  episode_reward_mean: 238.9443132187967
  episode_reward_min: 119.95959595959577
  episodes_this_iter: 158
  episodes_total: 3002
  experiment_id: eceadde4c614499bacaa06e529b83d59
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.8710641145706177
        entropy_coeff: 0.0001
        kl: 0.006570755923166871
        model: {}
        policy_loss: -0.01373581833904609
        total_loss: 12.521038341522218
        vf_explained_var: 0.9755568504333496
        vf_loss: 12.534204292297364
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.7764705882353
    gpu_util_percent0: 0.36617647058823527
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7823529411764705
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 18363
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15352860784389183
    mean_env_wait_ms: 1.1849886922495934
    mean_inference_ms: 4.714236247540747
    mean_raw_obs_processing_ms: 0.402357764824815
  time_since_restore: 467.1512773036957
  time_this_iter_s: 28.84966516494751
  time_total_s: 467.1512773036957
  timers:
    learn_throughput: 7425.914
    learn_time_ms: 21787.487
    sample_throughput: 22994.621
    sample_time_ms: 7036.08
    update_time_ms: 44.507
  timestamp: 1602422707
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 12c77_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_12c77_00000 | RUNNING  | 172.17.0.4:18363 |     16 |          467.151 | 2588672 |  238.944 |              291.778 |               119.96 |            834.288 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_12c77_00000:
  custom_metrics:
    time_step_max: 4264
    time_step_mean: 3475.0545569221067
    time_step_min: 3157
  date: 2020-10-11_13-25-36
  done: false
  episode_len_mean: 832.2644576430134
  episode_reward_max: 291.777777777778
  episode_reward_mean: 240.09685476206255
  episode_reward_min: 119.95959595959577
  episodes_this_iter: 197
  episodes_total: 3199
  experiment_id: eceadde4c614499bacaa06e529b83d59
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.8405522584915162
        entropy_coeff: 0.0001
        kl: 0.006990063795819878
        model: {}
        policy_loss: -0.013194853393360972
        total_loss: 13.419609355926514
        vf_explained_var: 0.9782096743583679
        vf_loss: 13.43218936920166
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.54705882352941
    gpu_util_percent0: 0.45499999999999996
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.770588235294117
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 18363
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1532569564012331
    mean_env_wait_ms: 1.1858971059646564
    mean_inference_ms: 4.695905468606748
    mean_raw_obs_processing_ms: 0.4013392521898061
  time_since_restore: 496.32785177230835
  time_this_iter_s: 29.17657446861267
  time_total_s: 496.32785177230835
  timers:
    learn_throughput: 7413.826
    learn_time_ms: 21823.009
    sample_throughput: 23065.371
    sample_time_ms: 7014.498
    update_time_ms: 37.693
  timestamp: 1602422736
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 12c77_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_12c77_00000 | RUNNING  | 172.17.0.4:18363 |     17 |          496.328 | 2750464 |  240.097 |              291.778 |               119.96 |            832.264 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_12c77_00000:
  custom_metrics:
    time_step_max: 4264
    time_step_mean: 3466.5212085996513
    time_step_min: 3157
  date: 2020-10-11_13-26-05
  done: false
  episode_len_mean: 830.2054755043227
  episode_reward_max: 291.777777777778
  episode_reward_mean: 241.34467149885006
  episode_reward_min: 119.95959595959577
  episodes_this_iter: 271
  episodes_total: 3470
  experiment_id: eceadde4c614499bacaa06e529b83d59
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.8385762095451355
        entropy_coeff: 0.0001
        kl: 0.006472347024828196
        model: {}
        policy_loss: -0.012117055349517614
        total_loss: 14.5984956741333
        vf_explained_var: 0.978177547454834
        vf_loss: 14.6100492477417
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.224242424242426
    gpu_util_percent0: 0.4433333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7666666666666666
    vram_util_percent0: 0.10897015414890128
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 18363
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15288525433882294
    mean_env_wait_ms: 1.1869722333784194
    mean_inference_ms: 4.67288564394071
    mean_raw_obs_processing_ms: 0.4001169607660545
  time_since_restore: 525.0385384559631
  time_this_iter_s: 28.710686683654785
  time_total_s: 525.0385384559631
  timers:
    learn_throughput: 7411.783
    learn_time_ms: 21829.026
    sample_throughput: 23143.9
    sample_time_ms: 6990.697
    update_time_ms: 38.257
  timestamp: 1602422765
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 12c77_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_12c77_00000 | RUNNING  | 172.17.0.4:18363 |     18 |          525.039 | 2912256 |  241.345 |              291.778 |               119.96 |            830.205 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_12c77_00000:
  custom_metrics:
    time_step_max: 4264
    time_step_mean: 3461.2457016084304
    time_step_min: 3148
  date: 2020-10-11_13-26-34
  done: false
  episode_len_mean: 829.0487066593286
  episode_reward_max: 291.777777777778
  episode_reward_mean: 242.10728362324392
  episode_reward_min: 119.95959595959577
  episodes_this_iter: 164
  episodes_total: 3634
  experiment_id: eceadde4c614499bacaa06e529b83d59
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.8289688408374787
        entropy_coeff: 0.0001
        kl: 0.006461284589022398
        model: {}
        policy_loss: -0.014005647134035825
        total_loss: 9.973568439483643
        vf_explained_var: 0.980167031288147
        vf_loss: 9.987010669708251
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.464705882352945
    gpu_util_percent0: 0.34823529411764703
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7794117647058822
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 18363
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1526908402456695
    mean_env_wait_ms: 1.1875626907965304
    mean_inference_ms: 4.660349008882228
    mean_raw_obs_processing_ms: 0.39944277347908147
  time_since_restore: 553.8710780143738
  time_this_iter_s: 28.832539558410645
  time_total_s: 553.8710780143738
  timers:
    learn_throughput: 7405.131
    learn_time_ms: 21848.635
    sample_throughput: 23235.35
    sample_time_ms: 6963.183
    update_time_ms: 46.622
  timestamp: 1602422794
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 12c77_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_12c77_00000 | RUNNING  | 172.17.0.4:18363 |     19 |          553.871 | 3074048 |  242.107 |              291.778 |               119.96 |            829.049 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_12c77_00000:
  custom_metrics:
    time_step_max: 4264
    time_step_mean: 3457.132837407014
    time_step_min: 3148
  date: 2020-10-11_13-27-03
  done: false
  episode_len_mean: 828.0261075949367
  episode_reward_max: 291.9292929292927
  episode_reward_mean: 242.7260660401482
  episode_reward_min: 119.95959595959577
  episodes_this_iter: 158
  episodes_total: 3792
  experiment_id: eceadde4c614499bacaa06e529b83d59
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.8085484802722931
        entropy_coeff: 0.0001
        kl: 0.006762820947915316
        model: {}
        policy_loss: -0.013417985104024411
        total_loss: 10.215676021575927
        vf_explained_var: 0.9797428250312805
        vf_loss: 10.228498649597167
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.13939393939394
    gpu_util_percent0: 0.36939393939393944
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.781818181818182
    vram_util_percent0: 0.10897015414890128
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 18363
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15251381176127068
    mean_env_wait_ms: 1.188115764363652
    mean_inference_ms: 4.648951471105508
    mean_raw_obs_processing_ms: 0.3988166022410984
  time_since_restore: 582.733978509903
  time_this_iter_s: 28.862900495529175
  time_total_s: 582.733978509903
  timers:
    learn_throughput: 7395.196
    learn_time_ms: 21877.987
    sample_throughput: 23350.592
    sample_time_ms: 6928.818
    update_time_ms: 44.81
  timestamp: 1602422823
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 12c77_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_12c77_00000 | RUNNING  | 172.17.0.4:18363 |     20 |          582.734 | 3235840 |  242.726 |              291.929 |               119.96 |            828.026 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_12c77_00000:
  custom_metrics:
    time_step_max: 4264
    time_step_mean: 3449.796576531878
    time_step_min: 3102
  date: 2020-10-11_13-27-32
  done: true
  episode_len_mean: 826.1335304262134
  episode_reward_max: 296.0202020202016
  episode_reward_mean: 243.79704659305537
  episode_reward_min: 119.95959595959577
  episodes_this_iter: 267
  episodes_total: 4059
  experiment_id: eceadde4c614499bacaa06e529b83d59
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.7875589549541473
        entropy_coeff: 0.0001
        kl: 0.00667554372921586
        model: {}
        policy_loss: -0.012445284612476825
        total_loss: 16.451650047302245
        vf_explained_var: 0.9765976071357727
        vf_loss: 16.463505935668945
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.832352941176474
    gpu_util_percent0: 0.3041176470588235
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7735294117647062
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 18363
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15224418895546757
    mean_env_wait_ms: 1.189077471151772
    mean_inference_ms: 4.631297113347543
    mean_raw_obs_processing_ms: 0.3978542443643884
  time_since_restore: 611.4248576164246
  time_this_iter_s: 28.690879106521606
  time_total_s: 611.4248576164246
  timers:
    learn_throughput: 7399.934
    learn_time_ms: 21863.98
    sample_throughput: 23461.184
    sample_time_ms: 6896.157
    update_time_ms: 44.509
  timestamp: 1602422852
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: 12c77_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_12c77_00000 | TERMINATED |       |     21 |          611.425 | 3397632 |  243.797 |               296.02 |               119.96 |            826.134 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_12c77_00000 | TERMINATED |       |     21 |          611.425 | 3397632 |  243.797 |               296.02 |               119.96 |            826.134 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


