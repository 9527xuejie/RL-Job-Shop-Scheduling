2020-10-12 08:06:00,257	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_c49f7_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=79399)[0m 2020-10-12 08:06:02,983	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=79350)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79350)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79344)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79344)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79333)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79333)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79345)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79345)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79351)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79351)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79355)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79355)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79349)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79349)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79276)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79276)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79279)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79279)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79357)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79357)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79390)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79390)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79379)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79379)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79268)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79268)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79381)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79381)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79377)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79377)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79371)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79371)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79285)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79285)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79363)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79363)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79327)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79327)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79348)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79348)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79294)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79294)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79332)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79332)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79341)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79341)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79273)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79273)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79394)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79394)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79340)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79340)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79384)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79384)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79289)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79289)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79354)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79354)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79360)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79360)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79386)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79386)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79388)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79388)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79343)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79343)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79378)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79378)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79292)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79292)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79364)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79364)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79281)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79281)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79353)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79353)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79339)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79339)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79277)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79277)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79275)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79275)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79287)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79287)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79270)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79270)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79282)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79282)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79280)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79280)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79269)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79269)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79266)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79266)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79370)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79370)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79271)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79271)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79283)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79283)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79265)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79265)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79347)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79347)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79335)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79335)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79361)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79361)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79303)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79303)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79330)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79330)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79337)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79337)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79358)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79358)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79368)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79368)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79295)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79295)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79267)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79267)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79329)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79329)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79299)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79299)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79305)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79305)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79331)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79331)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79346)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79346)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79382)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79382)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79342)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79342)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79334)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79334)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79264)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79264)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79297)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79297)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79300)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79300)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79278)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79278)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79338)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79338)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79391)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79391)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79336)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79336)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79359)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79359)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79304)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79304)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79383)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79383)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_c49f7_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-12_08-06-36
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.185120274623235
        entropy_coeff: 0.0010000000000000002
        kl: 0.004055787847998242
        model: {}
        policy_loss: -0.007851610066912448
        total_loss: 507.07507578531903
        vf_explained_var: 0.540532648563385
        vf_loss: 507.0832926432292
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.89090909090909
    gpu_util_percent0: 0.38969696969696965
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.566666666666667
    vram_util_percent0: 0.08750757824224535
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79399
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1671859768298939
    mean_env_wait_ms: 1.1685175894218744
    mean_inference_ms: 5.542697244015841
    mean_raw_obs_processing_ms: 0.4403039149643279
  time_since_restore: 27.98508620262146
  time_this_iter_s: 27.98508620262146
  time_total_s: 27.98508620262146
  timers:
    learn_throughput: 8511.254
    learn_time_ms: 19009.184
    sample_throughput: 18188.236
    sample_time_ms: 8895.42
    update_time_ms: 25.517
  timestamp: 1602489996
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: c49f7_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |      1 |          27.9851 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c49f7_00000:
  custom_metrics:
    time_step_max: 4139
    time_step_mean: 3615.2916666666665
    time_step_min: 3250
  date: 2020-10-12_08-07-03
  done: false
  episode_len_mean: 890.9303797468355
  episode_reward_max: 273.5959595959592
  episode_reward_mean: 217.42123769338934
  episode_reward_min: 138.89898989898958
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.15665665268898
        entropy_coeff: 0.0010000000000000002
        kl: 0.007565491638767223
        model: {}
        policy_loss: -0.010795095736587731
        total_loss: 126.37152163187663
        vf_explained_var: 0.8081408143043518
        vf_loss: 126.38271840413411
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.083870967741937
    gpu_util_percent0: 0.3458064516129033
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7580645161290316
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79399
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1630873611830732
    mean_env_wait_ms: 1.1651816796611996
    mean_inference_ms: 5.320372510974211
    mean_raw_obs_processing_ms: 0.4290420705682716
  time_since_restore: 54.57611012458801
  time_this_iter_s: 26.591023921966553
  time_total_s: 54.57611012458801
  timers:
    learn_throughput: 8492.107
    learn_time_ms: 19052.045
    sample_throughput: 19867.256
    sample_time_ms: 8143.651
    update_time_ms: 40.696
  timestamp: 1602490023
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: c49f7_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |      2 |          54.5761 | 323584 |  217.421 |              273.596 |              138.899 |             890.93 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c49f7_00000:
  custom_metrics:
    time_step_max: 4139
    time_step_mean: 3613.952914798206
    time_step_min: 3250
  date: 2020-10-12_08-07-29
  done: false
  episode_len_mean: 886.1983122362869
  episode_reward_max: 273.5959595959592
  episode_reward_mean: 218.40800409154815
  episode_reward_min: 138.89898989898958
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1415385901927948
        entropy_coeff: 0.0010000000000000002
        kl: 0.00994268455542624
        model: {}
        policy_loss: -0.012222195859067142
        total_loss: 64.50122865041097
        vf_explained_var: 0.8894491195678711
        vf_loss: 64.51359748840332
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.9
    gpu_util_percent0: 0.34400000000000003
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.78
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79399
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16056376792462443
    mean_env_wait_ms: 1.1654815807931842
    mean_inference_ms: 5.160581395537171
    mean_raw_obs_processing_ms: 0.4210465552605851
  time_since_restore: 80.85679578781128
  time_this_iter_s: 26.280685663223267
  time_total_s: 80.85679578781128
  timers:
    learn_throughput: 8489.867
    learn_time_ms: 19057.072
    sample_throughput: 20738.298
    sample_time_ms: 7801.605
    update_time_ms: 40.121
  timestamp: 1602490049
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: c49f7_00000
  
== Status ==
Memory usage on this node: 28.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |      3 |          80.8568 | 485376 |  218.408 |              273.596 |              138.899 |            886.198 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c49f7_00000:
  custom_metrics:
    time_step_max: 4139
    time_step_mean: 3600.026490066225
    time_step_min: 3250
  date: 2020-10-12_08-07-55
  done: false
  episode_len_mean: 881.0632911392405
  episode_reward_max: 273.5959595959592
  episode_reward_mean: 220.77398989898967
  episode_reward_min: 138.89898989898958
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1262759864330292
        entropy_coeff: 0.0010000000000000002
        kl: 0.007932808017358184
        model: {}
        policy_loss: -0.010753356424781183
        total_loss: 40.0422420501709
        vf_explained_var: 0.9258741736412048
        vf_loss: 40.05332660675049
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.79666666666667
    gpu_util_percent0: 0.36266666666666664
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.773333333333333
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79399
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15881682262783847
    mean_env_wait_ms: 1.1667191329418642
    mean_inference_ms: 5.0460795669711525
    mean_raw_obs_processing_ms: 0.4151562783082309
  time_since_restore: 106.90822958946228
  time_this_iter_s: 26.051433801651
  time_total_s: 106.90822958946228
  timers:
    learn_throughput: 8480.346
    learn_time_ms: 19078.466
    sample_throughput: 21401.448
    sample_time_ms: 7559.862
    update_time_ms: 35.028
  timestamp: 1602490075
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: c49f7_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |      4 |          106.908 | 647168 |  220.774 |              273.596 |              138.899 |            881.063 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c49f7_00000:
  custom_metrics:
    time_step_max: 4139
    time_step_mean: 3586.272965879265
    time_step_min: 3250
  date: 2020-10-12_08-08-21
  done: false
  episode_len_mean: 876.5278481012658
  episode_reward_max: 274.35353535353505
  episode_reward_mean: 223.04858713719454
  episode_reward_min: 138.89898989898958
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0917210976282756
        entropy_coeff: 0.0010000000000000002
        kl: 0.008220920106396079
        model: {}
        policy_loss: -0.013464094430673867
        total_loss: 28.93033440907796
        vf_explained_var: 0.9479137063026428
        vf_loss: 28.944067160288494
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.173333333333332
    gpu_util_percent0: 0.33833333333333343
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.769999999999999
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79399
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15751531511699007
    mean_env_wait_ms: 1.1684766662620152
    mean_inference_ms: 4.95970615273041
    mean_raw_obs_processing_ms: 0.4106852566028239
  time_since_restore: 132.92763376235962
  time_this_iter_s: 26.01940417289734
  time_total_s: 132.92763376235962
  timers:
    learn_throughput: 8474.744
    learn_time_ms: 19091.079
    sample_throughput: 21836.933
    sample_time_ms: 7409.099
    update_time_ms: 32.404
  timestamp: 1602490101
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: c49f7_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |      5 |          132.928 | 808960 |  223.049 |              274.354 |              138.899 |            876.528 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c49f7_00000:
  custom_metrics:
    time_step_max: 4139
    time_step_mean: 3562.720930232558
    time_step_min: 3236
  date: 2020-10-12_08-08-47
  done: false
  episode_len_mean: 866.970988213962
  episode_reward_max: 275.7171717171718
  episode_reward_mean: 226.50675384854873
  episode_reward_min: 138.89898989898958
  episodes_this_iter: 313
  episodes_total: 1103
  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0828292568524678
        entropy_coeff: 0.0010000000000000002
        kl: 0.007986097635390857
        model: {}
        policy_loss: -0.01176670480829974
        total_loss: 28.82416566212972
        vf_explained_var: 0.9627106189727783
        vf_loss: 28.836217085520428
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.993103448275857
    gpu_util_percent0: 0.34206896551724136
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7689655172413787
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79399
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1557423331251979
    mean_env_wait_ms: 1.1728611992308515
    mean_inference_ms: 4.843886786218583
    mean_raw_obs_processing_ms: 0.40510099711437697
  time_since_restore: 158.39731907844543
  time_this_iter_s: 25.469685316085815
  time_total_s: 158.39731907844543
  timers:
    learn_throughput: 8511.93
    learn_time_ms: 19007.676
    sample_throughput: 22135.621
    sample_time_ms: 7309.124
    update_time_ms: 29.98
  timestamp: 1602490127
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: c49f7_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |      6 |          158.397 | 970752 |  226.507 |              275.717 |              138.899 |            866.971 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c49f7_00000:
  custom_metrics:
    time_step_max: 4139
    time_step_mean: 3553.5307443365696
    time_step_min: 3236
  date: 2020-10-12_08-09-13
  done: false
  episode_len_mean: 863.0727848101266
  episode_reward_max: 275.7171717171718
  episode_reward_mean: 227.83155127221562
  episode_reward_min: 138.89898989898958
  episodes_this_iter: 161
  episodes_total: 1264
  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.071872740983963
        entropy_coeff: 0.0010000000000000002
        kl: 0.00846466759685427
        model: {}
        policy_loss: -0.013406029562853897
        total_loss: 19.26950518290202
        vf_explained_var: 0.9649848341941833
        vf_loss: 19.28313668568929
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.403225806451612
    gpu_util_percent0: 0.44258064516129036
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.780645161290322
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79399
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15508125173145895
    mean_env_wait_ms: 1.1746607097364452
    mean_inference_ms: 4.801153989323884
    mean_raw_obs_processing_ms: 0.4030365619774304
  time_since_restore: 184.4202537536621
  time_this_iter_s: 26.022934675216675
  time_total_s: 184.4202537536621
  timers:
    learn_throughput: 8507.604
    learn_time_ms: 19017.34
    sample_throughput: 22352.663
    sample_time_ms: 7238.153
    update_time_ms: 36.921
  timestamp: 1602490153
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: c49f7_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |      7 |           184.42 | 1132544 |  227.832 |              275.717 |              138.899 |            863.073 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c49f7_00000:
  custom_metrics:
    time_step_max: 4139
    time_step_mean: 3545.019368723099
    time_step_min: 3236
  date: 2020-10-12_08-09-39
  done: false
  episode_len_mean: 860.4458509142054
  episode_reward_max: 275.7171717171718
  episode_reward_mean: 229.1102800153431
  episode_reward_min: 138.89898989898958
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0527766644954681
        entropy_coeff: 0.0010000000000000002
        kl: 0.007615982904098928
        model: {}
        policy_loss: -0.012027044120865563
        total_loss: 16.963534673055012
        vf_explained_var: 0.9683038592338562
        vf_loss: 16.975852966308594
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.863333333333333
    gpu_util_percent0: 0.2586666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.776666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79399
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15452219062147216
    mean_env_wait_ms: 1.1761659446759791
    mean_inference_ms: 4.765321018664555
    mean_raw_obs_processing_ms: 0.4012817864251415
  time_since_restore: 210.67793703079224
  time_this_iter_s: 26.257683277130127
  time_total_s: 210.67793703079224
  timers:
    learn_throughput: 8505.771
    learn_time_ms: 19021.438
    sample_throughput: 22391.774
    sample_time_ms: 7225.511
    update_time_ms: 34.921
  timestamp: 1602490179
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: c49f7_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |      8 |          210.678 | 1294336 |   229.11 |              275.717 |              138.899 |            860.446 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c49f7_00000:
  custom_metrics:
    time_step_max: 4139
    time_step_mean: 3536.619201030928
    time_step_min: 3236
  date: 2020-10-12_08-10-05
  done: false
  episode_len_mean: 857.7284810126582
  episode_reward_max: 281.92929292929284
  episode_reward_mean: 230.51368111494673
  episode_reward_min: 138.89898989898958
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0236333707968395
        entropy_coeff: 0.0010000000000000002
        kl: 0.008085604213799039
        model: {}
        policy_loss: -0.011290598209598102
        total_loss: 15.170008023579916
        vf_explained_var: 0.970684289932251
        vf_loss: 15.18151330947876
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.749999999999996
    gpu_util_percent0: 0.251
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7733333333333334
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79399
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1540308837771974
    mean_env_wait_ms: 1.1774970942409586
    mean_inference_ms: 4.734334782954239
    mean_raw_obs_processing_ms: 0.3997390670523251
  time_since_restore: 236.742493391037
  time_this_iter_s: 26.06455636024475
  time_total_s: 236.742493391037
  timers:
    learn_throughput: 8505.518
    learn_time_ms: 19022.004
    sample_throughput: 22482.023
    sample_time_ms: 7196.506
    update_time_ms: 33.142
  timestamp: 1602490205
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: c49f7_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |      9 |          236.742 | 1456128 |  230.514 |              281.929 |              138.899 |            857.728 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c49f7_00000:
  custom_metrics:
    time_step_max: 4139
    time_step_mean: 3519.6370656370655
    time_step_min: 3150
  date: 2020-10-12_08-10-31
  done: false
  episode_len_mean: 852.4513851167843
  episode_reward_max: 288.74747474747466
  episode_reward_mean: 233.1354885081119
  episode_reward_min: 138.89898989898958
  episodes_this_iter: 261
  episodes_total: 1841
  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9897792836030325
        entropy_coeff: 0.0010000000000000002
        kl: 0.008098231783757607
        model: {}
        policy_loss: -0.010045850300230086
        total_loss: 20.74252223968506
        vf_explained_var: 0.9716846346855164
        vf_loss: 20.752748171488445
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.766666666666666
    gpu_util_percent0: 0.28366666666666673
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7633333333333328
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79399
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15336646876524834
    mean_env_wait_ms: 1.179771053805273
    mean_inference_ms: 4.691936826434794
    mean_raw_obs_processing_ms: 0.39762402378600903
  time_since_restore: 262.79794573783875
  time_this_iter_s: 26.055452346801758
  time_total_s: 262.79794573783875
  timers:
    learn_throughput: 8506.736
    learn_time_ms: 19019.281
    sample_throughput: 22547.752
    sample_time_ms: 7175.527
    update_time_ms: 31.912
  timestamp: 1602490231
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: c49f7_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |     10 |          262.798 | 1617920 |  233.135 |              288.747 |              138.899 |            852.451 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c49f7_00000:
  custom_metrics:
    time_step_max: 4139
    time_step_mean: 3509.591806515301
    time_step_min: 3150
  date: 2020-10-12_08-10-58
  done: false
  episode_len_mean: 848.2750730282376
  episode_reward_max: 288.74747474747466
  episode_reward_mean: 234.99839682118142
  episode_reward_min: 138.89898989898958
  episodes_this_iter: 213
  episodes_total: 2054
  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9871509124835333
        entropy_coeff: 0.0010000000000000002
        kl: 0.007209118106402457
        model: {}
        policy_loss: -0.012315249536186457
        total_loss: 13.081322272618612
        vf_explained_var: 0.9765751957893372
        vf_loss: 13.09390377998352
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.37741935483871
    gpu_util_percent0: 0.4119354838709678
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79399
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15291547541255573
    mean_env_wait_ms: 1.1813891282293203
    mean_inference_ms: 4.663419804013761
    mean_raw_obs_processing_ms: 0.39626592689167284
  time_since_restore: 288.9913504123688
  time_this_iter_s: 26.19340467453003
  time_total_s: 288.9913504123688
  timers:
    learn_throughput: 8502.356
    learn_time_ms: 19029.079
    sample_throughput: 23156.003
    sample_time_ms: 6987.043
    update_time_ms: 31.229
  timestamp: 1602490258
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: c49f7_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |     11 |          288.991 | 1779712 |  234.998 |              288.747 |              138.899 |            848.275 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c49f7_00000:
  custom_metrics:
    time_step_max: 4139
    time_step_mean: 3500.4253663003665
    time_step_min: 3150
  date: 2020-10-12_08-11-24
  done: false
  episode_len_mean: 845.25226039783
  episode_reward_max: 288.74747474747466
  episode_reward_mean: 236.21548669333458
  episode_reward_min: 138.89898989898958
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9684580465157827
        entropy_coeff: 0.0010000000000000002
        kl: 0.0071360117290169
        model: {}
        policy_loss: -0.011122295356472023
        total_loss: 14.169920762379965
        vf_explained_var: 0.9724215865135193
        vf_loss: 14.181298096974691
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.079999999999995
    gpu_util_percent0: 0.25166666666666665
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7766666666666664
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79399
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15262288825471745
    mean_env_wait_ms: 1.1825289172355695
    mean_inference_ms: 4.645050441375069
    mean_raw_obs_processing_ms: 0.39535490470579415
  time_since_restore: 315.16404151916504
  time_this_iter_s: 26.172691106796265
  time_total_s: 315.16404151916504
  timers:
    learn_throughput: 8504.47
    learn_time_ms: 19024.348
    sample_throughput: 23270.287
    sample_time_ms: 6952.729
    update_time_ms: 27.675
  timestamp: 1602490284
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: c49f7_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |     12 |          315.164 | 1941504 |  236.215 |              288.747 |              138.899 |            845.252 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c49f7_00000:
  custom_metrics:
    time_step_max: 4139
    time_step_mean: 3492.3398720682303
    time_step_min: 3150
  date: 2020-10-12_08-11-50
  done: false
  episode_len_mean: 842.0539401601349
  episode_reward_max: 288.74747474747466
  episode_reward_mean: 237.38396608308096
  episode_reward_min: 138.89898989898958
  episodes_this_iter: 161
  episodes_total: 2373
  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9432903180519739
        entropy_coeff: 0.0010000000000000002
        kl: 0.0064480928316091495
        model: {}
        policy_loss: -0.010764235218327181
        total_loss: 13.248364766438803
        vf_explained_var: 0.9748766422271729
        vf_loss: 13.259427547454834
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.170000000000005
    gpu_util_percent0: 0.3536666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.773333333333333
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79399
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15235432334814986
    mean_env_wait_ms: 1.1837337370144503
    mean_inference_ms: 4.628123902236818
    mean_raw_obs_processing_ms: 0.39449204277665234
  time_since_restore: 341.18098974227905
  time_this_iter_s: 26.016948223114014
  time_total_s: 341.18098974227905
  timers:
    learn_throughput: 8501.095
    learn_time_ms: 19031.901
    sample_throughput: 23383.904
    sample_time_ms: 6918.947
    update_time_ms: 27.753
  timestamp: 1602490310
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: c49f7_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |     13 |          341.181 | 2103296 |  237.384 |              288.747 |              138.899 |            842.054 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c49f7_00000:
  custom_metrics:
    time_step_max: 4139
    time_step_mean: 3480.9777358490564
    time_step_min: 3150
  date: 2020-10-12_08-12-16
  done: false
  episode_len_mean: 837.1299477221808
  episode_reward_max: 288.74747474747466
  episode_reward_mean: 239.0731927188236
  episode_reward_min: 138.89898989898958
  episodes_this_iter: 305
  episodes_total: 2678
  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9245238403479258
        entropy_coeff: 0.0010000000000000002
        kl: 0.006356651700722675
        model: {}
        policy_loss: -0.0093736828227217
        total_loss: 16.56673304239909
        vf_explained_var: 0.977961540222168
        vf_loss: 16.576395829518635
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.896666666666665
    gpu_util_percent0: 0.29466666666666674
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7633333333333328
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79399
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15190957765651997
    mean_env_wait_ms: 1.1859752986928445
    mean_inference_ms: 4.600343130214659
    mean_raw_obs_processing_ms: 0.3931069726348402
  time_since_restore: 367.24762058258057
  time_this_iter_s: 26.066630840301514
  time_total_s: 367.24762058258057
  timers:
    learn_throughput: 8501.73
    learn_time_ms: 19030.48
    sample_throughput: 23378.515
    sample_time_ms: 6920.542
    update_time_ms: 29.402
  timestamp: 1602490336
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: c49f7_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |     14 |          367.248 | 2265088 |  239.073 |              288.747 |              138.899 |             837.13 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c49f7_00000:
  custom_metrics:
    time_step_max: 4139
    time_step_mean: 3474.9868607954545
    time_step_min: 3150
  date: 2020-10-12_08-12-43
  done: false
  episode_len_mean: 834.7232770745429
  episode_reward_max: 288.74747474747466
  episode_reward_mean: 239.94718279844844
  episode_reward_min: 138.89898989898958
  episodes_this_iter: 166
  episodes_total: 2844
  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.906185562411944
        entropy_coeff: 0.0010000000000000002
        kl: 0.006180410894254844
        model: {}
        policy_loss: -0.012563393373663226
        total_loss: 10.936929861704508
        vf_explained_var: 0.979099452495575
        vf_loss: 10.949781576792398
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.083870967741934
    gpu_util_percent0: 0.3635483870967742
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.783870967741935
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79399
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15170192871649035
    mean_env_wait_ms: 1.187075900566473
    mean_inference_ms: 4.587271974323672
    mean_raw_obs_processing_ms: 0.3924657739112036
  time_since_restore: 393.44245624542236
  time_this_iter_s: 26.194835662841797
  time_total_s: 393.44245624542236
  timers:
    learn_throughput: 8500.238
    learn_time_ms: 19033.821
    sample_throughput: 23336.365
    sample_time_ms: 6933.042
    update_time_ms: 29.449
  timestamp: 1602490363
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: c49f7_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |     15 |          393.442 | 2426880 |  239.947 |              288.747 |              138.899 |            834.723 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c49f7_00000:
  custom_metrics:
    time_step_max: 4139
    time_step_mean: 3469.194351042367
    time_step_min: 3150
  date: 2020-10-12_08-13-09
  done: false
  episode_len_mean: 832.4070619586942
  episode_reward_max: 291.6262626262627
  episode_reward_mean: 240.8477412364819
  episode_reward_min: 138.89898989898958
  episodes_this_iter: 158
  episodes_total: 3002
  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8940609991550446
        entropy_coeff: 0.0010000000000000002
        kl: 0.007062381831929088
        model: {}
        policy_loss: -0.01240032100273917
        total_loss: 9.784063498179117
        vf_explained_var: 0.9792147278785706
        vf_loss: 9.796651442845663
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.439999999999998
    gpu_util_percent0: 0.2953333333333334
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7899999999999996
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79399
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15151935101577735
    mean_env_wait_ms: 1.1880832907069834
    mean_inference_ms: 4.5757290796410865
    mean_raw_obs_processing_ms: 0.39187675467872235
  time_since_restore: 419.5664372444153
  time_this_iter_s: 26.12398099899292
  time_total_s: 419.5664372444153
  timers:
    learn_throughput: 8475.187
    learn_time_ms: 19090.079
    sample_throughput: 23315.951
    sample_time_ms: 6939.112
    update_time_ms: 31.854
  timestamp: 1602490389
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: c49f7_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |     16 |          419.566 | 2588672 |  240.848 |              291.626 |              138.899 |            832.407 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c49f7_00000:
  custom_metrics:
    time_step_max: 4139
    time_step_mean: 3461.9522776572667
    time_step_min: 3146
  date: 2020-10-12_08-13-35
  done: false
  episode_len_mean: 829.152380952381
  episode_reward_max: 291.6262626262627
  episode_reward_mean: 241.9287808965227
  episode_reward_min: 138.89898989898958
  episodes_this_iter: 253
  episodes_total: 3255
  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8715203603108724
        entropy_coeff: 0.0010000000000000002
        kl: 0.0068582673169051605
        model: {}
        policy_loss: -0.009826259381952696
        total_loss: 13.900481621424357
        vf_explained_var: 0.9798092246055603
        vf_loss: 13.910493532816568
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.28666666666667
    gpu_util_percent0: 0.256
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.77
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79399
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15125671270769184
    mean_env_wait_ms: 1.1897326970724291
    mean_inference_ms: 4.559082586406331
    mean_raw_obs_processing_ms: 0.391031531764309
  time_since_restore: 445.54023838043213
  time_this_iter_s: 25.973801136016846
  time_total_s: 445.54023838043213
  timers:
    learn_throughput: 8471.862
    learn_time_ms: 19097.573
    sample_throughput: 23339.019
    sample_time_ms: 6932.254
    update_time_ms: 26.287
  timestamp: 1602490415
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: c49f7_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |     17 |           445.54 | 2750464 |  241.929 |              291.626 |              138.899 |            829.152 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c49f7_00000:
  custom_metrics:
    time_step_max: 4139
    time_step_mean: 3456.317865429234
    time_step_min: 3120
  date: 2020-10-12_08-14-01
  done: false
  episode_len_mean: 826.6527617951668
  episode_reward_max: 293.29292929292956
  episode_reward_mean: 242.82325847659547
  episode_reward_min: 138.89898989898958
  episodes_this_iter: 221
  episodes_total: 3476
  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8578323672215143
        entropy_coeff: 0.0010000000000000002
        kl: 0.0062772125626603765
        model: {}
        policy_loss: -0.011194397937894488
        total_loss: 11.216416676839193
        vf_explained_var: 0.9811086058616638
        vf_loss: 11.2278413772583
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.15
    gpu_util_percent0: 0.275
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7666666666666657
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79399
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15105210665216098
    mean_env_wait_ms: 1.1910411370697684
    mean_inference_ms: 4.546026524305814
    mean_raw_obs_processing_ms: 0.3904015773843836
  time_since_restore: 471.62775897979736
  time_this_iter_s: 26.087520599365234
  time_total_s: 471.62775897979736
  timers:
    learn_throughput: 8466.865
    learn_time_ms: 19108.844
    sample_throughput: 23450.467
    sample_time_ms: 6899.308
    update_time_ms: 28.072
  timestamp: 1602490441
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: c49f7_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |     18 |          471.628 | 2912256 |  242.823 |              293.293 |              138.899 |            826.653 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c49f7_00000:
  custom_metrics:
    time_step_max: 4139
    time_step_mean: 3451.5252357182476
    time_step_min: 3120
  date: 2020-10-12_08-14-27
  done: false
  episode_len_mean: 825.2999449642267
  episode_reward_max: 293.29292929292956
  episode_reward_mean: 243.52266195249118
  episode_reward_min: 138.89898989898958
  episodes_this_iter: 158
  episodes_total: 3634
  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8522786746422449
        entropy_coeff: 0.0010000000000000002
        kl: 0.006254845376436909
        model: {}
        policy_loss: -0.012950713620133078
        total_loss: 9.356015682220459
        vf_explained_var: 0.9807977080345154
        vf_loss: 9.369193077087402
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.18709677419354
    gpu_util_percent0: 0.3722580645161291
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7741935483870965
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79399
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15091926952523643
    mean_env_wait_ms: 1.1919120175490399
    mean_inference_ms: 4.537482004930605
    mean_raw_obs_processing_ms: 0.38997728772240287
  time_since_restore: 497.7250077724457
  time_this_iter_s: 26.097248792648315
  time_total_s: 497.7250077724457
  timers:
    learn_throughput: 8461.979
    learn_time_ms: 19119.877
    sample_throughput: 23489.436
    sample_time_ms: 6887.862
    update_time_ms: 30.171
  timestamp: 1602490467
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: c49f7_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |     19 |          497.725 | 3074048 |  243.523 |              293.293 |              138.899 |              825.3 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c49f7_00000:
  custom_metrics:
    time_step_max: 4139
    time_step_mean: 3446.582144743793
    time_step_min: 3120
  date: 2020-10-12_08-14-54
  done: false
  episode_len_mean: 823.849764027268
  episode_reward_max: 293.29292929292956
  episode_reward_mean: 244.2001530777093
  episode_reward_min: 138.89898989898958
  episodes_this_iter: 180
  episodes_total: 3814
  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8286279241243998
        entropy_coeff: 0.0010000000000000002
        kl: 0.006430626187163095
        model: {}
        policy_loss: -0.012222413827354709
        total_loss: 9.228648900985718
        vf_explained_var: 0.9839107990264893
        vf_loss: 9.2410569190979
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.133333333333333
    gpu_util_percent0: 0.3453333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.78
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79399
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15077733023374773
    mean_env_wait_ms: 1.1928851969603187
    mean_inference_ms: 4.528347029744211
    mean_raw_obs_processing_ms: 0.3895120865590016
  time_since_restore: 523.7741742134094
  time_this_iter_s: 26.049166440963745
  time_total_s: 523.7741742134094
  timers:
    learn_throughput: 8456.501
    learn_time_ms: 19132.264
    sample_throughput: 23545.959
    sample_time_ms: 6871.328
    update_time_ms: 32.795
  timestamp: 1602490494
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: c49f7_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |     20 |          523.774 | 3235840 |    244.2 |              293.293 |              138.899 |             823.85 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c49f7_00000:
  custom_metrics:
    time_step_max: 4139
    time_step_mean: 3438.918773006135
    time_step_min: 3120
  date: 2020-10-12_08-15-20
  done: false
  episode_len_mean: 821.5028028271996
  episode_reward_max: 293.29292929292956
  episode_reward_mean: 245.33389709919064
  episode_reward_min: 138.89898989898958
  episodes_this_iter: 289
  episodes_total: 4103
  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8048954059680303
        entropy_coeff: 0.0010000000000000002
        kl: 0.005603969019527237
        model: {}
        policy_loss: -0.013911528105381876
        total_loss: 11.3087530930837
        vf_explained_var: 0.9836416244506836
        vf_loss: 11.322909275690714
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.470000000000006
    gpu_util_percent0: 0.2516666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.766666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79399
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1505739045388427
    mean_env_wait_ms: 1.1943338077267522
    mean_inference_ms: 4.515047112702623
    mean_raw_obs_processing_ms: 0.38885284610818543
  time_since_restore: 549.8376796245575
  time_this_iter_s: 26.06350541114807
  time_total_s: 549.8376796245575
  timers:
    learn_throughput: 8455.134
    learn_time_ms: 19135.356
    sample_throughput: 23614.521
    sample_time_ms: 6851.378
    update_time_ms: 35.316
  timestamp: 1602490520
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: c49f7_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |     21 |          549.838 | 3397632 |  245.334 |              293.293 |              138.899 |            821.503 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c49f7_00000:
  custom_metrics:
    time_step_max: 4139
    time_step_mean: 3434.6906559697973
    time_step_min: 3120
  date: 2020-10-12_08-15-46
  done: false
  episode_len_mean: 820.2461322081575
  episode_reward_max: 293.29292929292956
  episode_reward_mean: 245.97136626461509
  episode_reward_min: 138.89898989898958
  episodes_this_iter: 163
  episodes_total: 4266
  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7969592610994974
        entropy_coeff: 0.0010000000000000002
        kl: 0.006330874321671824
        model: {}
        policy_loss: -0.011175491047955196
        total_loss: 6.920762340227763
        vf_explained_var: 0.986197292804718
        vf_loss: 6.932101647059123
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.106451612903232
    gpu_util_percent0: 0.3683870967741936
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.783870967741935
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79399
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15046625659796298
    mean_env_wait_ms: 1.1950829782948686
    mean_inference_ms: 4.508158694182665
    mean_raw_obs_processing_ms: 0.3885170657875346
  time_since_restore: 576.0177464485168
  time_this_iter_s: 26.18006682395935
  time_total_s: 576.0177464485168
  timers:
    learn_throughput: 8446.374
    learn_time_ms: 19155.203
    sample_throughput: 23696.753
    sample_time_ms: 6827.602
    update_time_ms: 38.423
  timestamp: 1602490546
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: c49f7_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |     22 |          576.018 | 3559424 |  245.971 |              293.293 |              138.899 |            820.246 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c49f7_00000:
  custom_metrics:
    time_step_max: 4139
    time_step_mean: 3430.9893206089523
    time_step_min: 3120
  date: 2020-10-12_08-16-12
  done: true
  episode_len_mean: 818.8347256717092
  episode_reward_max: 293.29292929292956
  episode_reward_mean: 246.54997479878926
  episode_reward_min: 138.89898989898958
  episodes_this_iter: 163
  episodes_total: 4429
  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7878765910863876
        entropy_coeff: 0.0010000000000000002
        kl: 0.005924326988557975
        model: {}
        policy_loss: -0.012837671786352681
        total_loss: 8.265578190485636
        vf_explained_var: 0.9834974408149719
        vf_loss: 8.278611381848654
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.970000000000002
    gpu_util_percent0: 0.30333333333333334
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.776666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 79399
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15036522832821625
    mean_env_wait_ms: 1.1958362960216486
    mean_inference_ms: 4.5016834026606345
    mean_raw_obs_processing_ms: 0.3881896853970501
  time_since_restore: 602.1439270973206
  time_this_iter_s: 26.12618064880371
  time_total_s: 602.1439270973206
  timers:
    learn_throughput: 8446.113
    learn_time_ms: 19155.793
    sample_throughput: 23657.57
    sample_time_ms: 6838.91
    update_time_ms: 36.492
  timestamp: 1602490572
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: c49f7_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c49f7_00000 | TERMINATED |       |     23 |          602.144 | 3721216 |   246.55 |              293.293 |              138.899 |            818.835 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


[2m[36m(pid=79336)[0m 2020-10-12 08:16:13,040	ERROR worker.py:372 -- SystemExit was raised from the worker
[2m[36m(pid=79336)[0m Traceback (most recent call last):
[2m[36m(pid=79336)[0m   File "python/ray/_raylet.pyx", line 553, in ray._raylet.task_execution_handler
[2m[36m(pid=79336)[0m   File "python/ray/_raylet.pyx", line 440, in ray._raylet.execute_task
[2m[36m(pid=79336)[0m   File "python/ray/_raylet.pyx", line 479, in ray._raylet.execute_task
[2m[36m(pid=79336)[0m   File "python/ray/_raylet.pyx", line 483, in ray._raylet.execute_task
[2m[36m(pid=79336)[0m   File "python/ray/_raylet.pyx", line 484, in ray._raylet.execute_task
[2m[36m(pid=79336)[0m   File "python/ray/_raylet.pyx", line 438, in ray._raylet.execute_task.function_executor
[2m[36m(pid=79336)[0m   File "/root/miniconda3/lib/python3.8/site-packages/ray/function_manager.py", line 553, in actor_method_executor
[2m[36m(pid=79336)[0m     return method(actor, *args, **kwargs)
[2m[36m(pid=79336)[0m   File "/root/miniconda3/lib/python3.8/site-packages/ray/actor.py", line 929, in __ray_terminate__
[2m[36m(pid=79336)[0m     ray.actor.exit_actor()
[2m[36m(pid=79336)[0m   File "/root/miniconda3/lib/python3.8/site-packages/ray/actor.py", line 991, in exit_actor
[2m[36m(pid=79336)[0m     ray.state.state.disconnect()
[2m[36m(pid=79336)[0m   File "/root/miniconda3/lib/python3.8/site-packages/ray/state.py", line 61, in disconnect
[2m[36m(pid=79336)[0m     self.global_state_accessor = None
[2m[36m(pid=79336)[0m   File "/root/miniconda3/lib/python3.8/site-packages/ray/worker.py", line 369, in sigterm_handler
[2m[36m(pid=79336)[0m     sys.exit(1)
[2m[36m(pid=79336)[0m SystemExit: 1
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c49f7_00000 | TERMINATED |       |     23 |          602.144 | 3721216 |   246.55 |              293.293 |              138.899 |            818.835 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


2020-10-12 08:16:13,085	WARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffffd8f83c3801000000.
