2020-10-11 21:54:13,213	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_4d85b_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=9065)[0m 2020-10-11 21:54:15,943	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=9034)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9034)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9058)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9058)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9049)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9049)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9038)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9038)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9032)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9032)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9052)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9052)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9029)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9029)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9037)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9037)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9077)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9077)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8969)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8969)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9050)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9050)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8954)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8954)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8966)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8966)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9062)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9062)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9022)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9022)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9035)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9035)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9012)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9012)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9078)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9078)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9047)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9047)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8962)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8962)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8965)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8965)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9081)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9081)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8979)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8979)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9036)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9036)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9067)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9067)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8967)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8967)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8958)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8958)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8961)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8961)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8980)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8980)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8985)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8985)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9015)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9015)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9017)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9017)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9030)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9030)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9044)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9044)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9064)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9064)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9025)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9025)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9091)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9091)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9039)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9039)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9043)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9043)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9031)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9031)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8984)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8984)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9024)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9024)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8952)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8952)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9033)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9033)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9074)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9074)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9021)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9021)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9055)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9055)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9073)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9073)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8973)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8973)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9086)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9086)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9020)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9020)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8971)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8971)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8957)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8957)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8978)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8978)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9027)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9027)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8968)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8968)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8960)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8960)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8976)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8976)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8956)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8956)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8991)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8991)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8972)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8972)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9045)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9045)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9041)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9041)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8982)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8982)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9048)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9048)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8963)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8963)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8953)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8953)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9068)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9068)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9026)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9026)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9054)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9054)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9066)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9066)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8988)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8988)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8974)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8974)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9013)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9013)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8970)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8970)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9028)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9028)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9014)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9014)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8955)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8955)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9070)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9070)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_4d85b_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-11_21-54-49
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 3b7db5a386254126a6d74c41efb577bc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1826288898785908
        entropy_coeff: 0.0001
        kl: 0.006605606526136398
        model: {}
        policy_loss: -0.008133154866906503
        total_loss: 507.0757141113281
        vf_explained_var: 0.540532648563385
        vf_loss: 507.0832926432292
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.279999999999998
    gpu_util_percent0: 0.3311428571428571
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5571428571428574
    vram_util_percent0: 0.08674741132924146
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9065
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16843113276501356
    mean_env_wait_ms: 1.172792844545624
    mean_inference_ms: 5.627921240754465
    mean_raw_obs_processing_ms: 0.44346441049272534
  time_since_restore: 28.492735862731934
  time_this_iter_s: 28.492735862731934
  time_total_s: 28.492735862731934
  timers:
    learn_throughput: 8266.731
    learn_time_ms: 19571.46
    sample_throughput: 18290.322
    sample_time_ms: 8845.771
    update_time_ms: 38.574
  timestamp: 1602453289
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 4d85b_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4d85b_00000 | RUNNING  | 172.17.0.4:9065 |      1 |          28.4927 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4d85b_00000:
  custom_metrics:
    time_step_max: 4093
    time_step_mean: 3630.565972222222
    time_step_min: 3379
  date: 2020-10-11_21-55-16
  done: false
  episode_len_mean: 889.243670886076
  episode_reward_max: 265.8686868686868
  episode_reward_mean: 216.45412990666136
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 3b7db5a386254126a6d74c41efb577bc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1498342156410217
        entropy_coeff: 0.0001
        kl: 0.008340244957556328
        model: {}
        policy_loss: -0.010777105800419426
        total_loss: 134.15000661214194
        vf_explained_var: 0.8063929080963135
        vf_loss: 134.1600596110026
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.836363636363636
    gpu_util_percent0: 0.3139393939393939
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7545454545454544
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9065
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1648720181795703
    mean_env_wait_ms: 1.1701669931308605
    mean_inference_ms: 5.455961219969186
    mean_raw_obs_processing_ms: 0.436085714000661
  time_since_restore: 55.45789098739624
  time_this_iter_s: 26.965155124664307
  time_total_s: 55.45789098739624
  timers:
    learn_throughput: 8363.186
    learn_time_ms: 19345.738
    sample_throughput: 19487.753
    sample_time_ms: 8302.24
    update_time_ms: 36.435
  timestamp: 1602453316
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 4d85b_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4d85b_00000 | RUNNING  | 172.17.0.4:9065 |      2 |          55.4579 | 323584 |  216.454 |              265.869 |              145.717 |            889.244 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4d85b_00000:
  custom_metrics:
    time_step_max: 4238
    time_step_mean: 3615.616591928251
    time_step_min: 3231
  date: 2020-10-11_21-55-43
  done: false
  episode_len_mean: 884.3818565400844
  episode_reward_max: 276.4747474747471
  episode_reward_mean: 218.35749904104316
  episode_reward_min: 123.89898989899017
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 3b7db5a386254126a6d74c41efb577bc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.140662560860316
        entropy_coeff: 0.0001
        kl: 0.007816510701862475
        model: {}
        policy_loss: -0.012634696050857505
        total_loss: 58.20880444844564
        vf_explained_var: 0.8970012664794922
        vf_loss: 58.220771153767906
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.3375
    gpu_util_percent0: 0.2821875
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.771875
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9065
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16226227398023083
    mean_env_wait_ms: 1.1699682863055991
    mean_inference_ms: 5.2994280308171655
    mean_raw_obs_processing_ms: 0.4291197492589992
  time_since_restore: 82.30184245109558
  time_this_iter_s: 26.84395146369934
  time_total_s: 82.30184245109558
  timers:
    learn_throughput: 8336.094
    learn_time_ms: 19408.611
    sample_throughput: 20378.578
    sample_time_ms: 7939.318
    update_time_ms: 37.121
  timestamp: 1602453343
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 4d85b_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4d85b_00000 | RUNNING  | 172.17.0.4:9065 |      3 |          82.3018 | 485376 |  218.357 |              276.475 |              123.899 |            884.382 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4d85b_00000:
  custom_metrics:
    time_step_max: 4238
    time_step_mean: 3603.3923841059604
    time_step_min: 3231
  date: 2020-10-11_21-56-10
  done: false
  episode_len_mean: 878.2389240506329
  episode_reward_max: 276.4747474747471
  episode_reward_mean: 219.5203938115329
  episode_reward_min: 123.89898989899017
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 3b7db5a386254126a6d74c41efb577bc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1210756500562031
        entropy_coeff: 0.0001
        kl: 0.007468378248934944
        model: {}
        policy_loss: -0.010714383349598696
        total_loss: 49.60937182108561
        vf_explained_var: 0.9099206924438477
        vf_loss: 49.619452158610024
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.718181818181815
    gpu_util_percent0: 0.3627272727272727
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.775757575757576
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9065
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1603527325582571
    mean_env_wait_ms: 1.1707350000544596
    mean_inference_ms: 5.180624513021066
    mean_raw_obs_processing_ms: 0.4235229444747762
  time_since_restore: 108.9041805267334
  time_this_iter_s: 26.602338075637817
  time_total_s: 108.9041805267334
  timers:
    learn_throughput: 8335.026
    learn_time_ms: 19411.097
    sample_throughput: 20928.399
    sample_time_ms: 7730.74
    update_time_ms: 35.301
  timestamp: 1602453370
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 4d85b_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4d85b_00000 | RUNNING  | 172.17.0.4:9065 |      4 |          108.904 | 647168 |   219.52 |              276.475 |              123.899 |            878.239 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4d85b_00000:
  custom_metrics:
    time_step_max: 4238
    time_step_mean: 3594.112565445026
    time_step_min: 3231
  date: 2020-10-11_21-56-37
  done: false
  episode_len_mean: 871.4015151515151
  episode_reward_max: 276.4747474747471
  episode_reward_mean: 221.3748852157941
  episode_reward_min: 123.89898989899017
  episodes_this_iter: 160
  episodes_total: 792
  experiment_id: 3b7db5a386254126a6d74c41efb577bc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0789608558019002
        entropy_coeff: 0.0001
        kl: 0.007944820681586862
        model: {}
        policy_loss: -0.012698741629719734
        total_loss: 32.02072207132975
        vf_explained_var: 0.947960376739502
        vf_loss: 32.03273391723633
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.25625
    gpu_util_percent0: 0.3975
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7625
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9065
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15889581444880485
    mean_env_wait_ms: 1.1731980863844662
    mean_inference_ms: 5.08777934115526
    mean_raw_obs_processing_ms: 0.41891970864415484
  time_since_restore: 135.48096370697021
  time_this_iter_s: 26.576783180236816
  time_total_s: 135.48096370697021
  timers:
    learn_throughput: 8340.998
    learn_time_ms: 19397.199
    sample_throughput: 21257.817
    sample_time_ms: 7610.941
    update_time_ms: 36.387
  timestamp: 1602453397
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 4d85b_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4d85b_00000 | RUNNING  | 172.17.0.4:9065 |      5 |          135.481 | 808960 |  221.375 |              276.475 |              123.899 |            871.402 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4d85b_00000:
  custom_metrics:
    time_step_max: 4238
    time_step_mean: 3571.225417439703
    time_step_min: 3228
  date: 2020-10-11_21-57-03
  done: false
  episode_len_mean: 859.4764918625679
  episode_reward_max: 276.92929292929284
  episode_reward_mean: 224.73095329424427
  episode_reward_min: 123.89898989899017
  episodes_this_iter: 314
  episodes_total: 1106
  experiment_id: 3b7db5a386254126a6d74c41efb577bc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.087694565455119
        entropy_coeff: 0.0001
        kl: 0.00748877099249512
        model: {}
        policy_loss: -0.01142723800148815
        total_loss: 33.36412652333578
        vf_explained_var: 0.9561591148376465
        vf_loss: 33.37491385142008
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.125
    gpu_util_percent0: 0.3834375
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7593750000000004
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9065
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1569201560942559
    mean_env_wait_ms: 1.177687941784653
    mean_inference_ms: 4.962567986798472
    mean_raw_obs_processing_ms: 0.4130816570363779
  time_since_restore: 161.8045952320099
  time_this_iter_s: 26.323631525039673
  time_total_s: 161.8045952320099
  timers:
    learn_throughput: 8346.118
    learn_time_ms: 19385.301
    sample_throughput: 21585.322
    sample_time_ms: 7495.464
    update_time_ms: 35.258
  timestamp: 1602453423
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 4d85b_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4d85b_00000 | RUNNING  | 172.17.0.4:9065 |      6 |          161.805 | 970752 |  224.731 |              276.929 |              123.899 |            859.476 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4d85b_00000:
  custom_metrics:
    time_step_max: 4238
    time_step_mean: 3564.1375404530745
    time_step_min: 3228
  date: 2020-10-11_21-57-29
  done: false
  episode_len_mean: 854.8860759493671
  episode_reward_max: 276.92929292929284
  episode_reward_mean: 226.07725994118383
  episode_reward_min: 123.89898989899017
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: 3b7db5a386254126a6d74c41efb577bc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0702723165353139
        entropy_coeff: 0.0001
        kl: 0.007788429541202883
        model: {}
        policy_loss: -0.012478182072906444
        total_loss: 20.580538272857666
        vf_explained_var: 0.9625504016876221
        vf_loss: 20.592344125111897
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.221874999999997
    gpu_util_percent0: 0.405
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.778125
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9065
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15619465857995316
    mean_env_wait_ms: 1.179614802225528
    mean_inference_ms: 4.916642670212762
    mean_raw_obs_processing_ms: 0.4109401829411092
  time_since_restore: 188.12089014053345
  time_this_iter_s: 26.31629490852356
  time_total_s: 188.12089014053345
  timers:
    learn_throughput: 8354.474
    learn_time_ms: 19365.911
    sample_throughput: 21795.69
    sample_time_ms: 7423.119
    update_time_ms: 33.574
  timestamp: 1602453449
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 4d85b_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4d85b_00000 | RUNNING  | 172.17.0.4:9065 |      7 |          188.121 | 1132544 |  226.077 |              276.929 |              123.899 |            854.886 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4d85b_00000:
  custom_metrics:
    time_step_max: 4238
    time_step_mean: 3551.5473457675753
    time_step_min: 3228
  date: 2020-10-11_21-57-56
  done: false
  episode_len_mean: 850.1497890295359
  episode_reward_max: 277.38383838383834
  episode_reward_mean: 227.8487192601115
  episode_reward_min: 123.89898989899017
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 3b7db5a386254126a6d74c41efb577bc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.053050567706426
        entropy_coeff: 0.0001
        kl: 0.007634645056289931
        model: {}
        policy_loss: -0.011983794150485968
        total_loss: 16.494932492574055
        vf_explained_var: 0.9668369889259338
        vf_loss: 16.50625769297282
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.174999999999997
    gpu_util_percent0: 0.38093750000000004
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.78125
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9065
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1555639154627882
    mean_env_wait_ms: 1.1813595475588137
    mean_inference_ms: 4.876678936754308
    mean_raw_obs_processing_ms: 0.4089953199762691
  time_since_restore: 214.53294467926025
  time_this_iter_s: 26.412054538726807
  time_total_s: 214.53294467926025
  timers:
    learn_throughput: 8354.641
    learn_time_ms: 19365.525
    sample_throughput: 21960.85
    sample_time_ms: 7367.292
    update_time_ms: 31.954
  timestamp: 1602453476
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 4d85b_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4d85b_00000 | RUNNING  | 172.17.0.4:9065 |      8 |          214.533 | 1294336 |  227.849 |              277.384 |              123.899 |             850.15 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4d85b_00000:
  custom_metrics:
    time_step_max: 4238
    time_step_mean: 3536.6401515151515
    time_step_min: 3206
  date: 2020-10-11_21-58-22
  done: false
  episode_len_mean: 844.3045905707196
  episode_reward_max: 286.32323232323296
  episode_reward_mean: 230.21845000877244
  episode_reward_min: 123.89898989899017
  episodes_this_iter: 190
  episodes_total: 1612
  experiment_id: 3b7db5a386254126a6d74c41efb577bc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0085338652133942
        entropy_coeff: 0.0001
        kl: 0.0065708860056474805
        model: {}
        policy_loss: -0.014436486856235812
        total_loss: 17.618113199869793
        vf_explained_var: 0.9724234938621521
        vf_loss: 17.631993770599365
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.834375
    gpu_util_percent0: 0.3503125
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.765625
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9065
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1548975562399466
    mean_env_wait_ms: 1.183800933521458
    mean_inference_ms: 4.834604277023613
    mean_raw_obs_processing_ms: 0.40691107500715146
  time_since_restore: 240.9148006439209
  time_this_iter_s: 26.381855964660645
  time_total_s: 240.9148006439209
  timers:
    learn_throughput: 8354.866
    learn_time_ms: 19365.002
    sample_throughput: 22122.49
    sample_time_ms: 7313.463
    update_time_ms: 37.686
  timestamp: 1602453502
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 4d85b_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4d85b_00000 | RUNNING  | 172.17.0.4:9065 |      9 |          240.915 | 1456128 |  230.218 |              286.323 |              123.899 |            844.305 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4d85b_00000:
  custom_metrics:
    time_step_max: 4238
    time_step_mean: 3518.543897216274
    time_step_min: 3189
  date: 2020-10-11_21-58-49
  done: false
  episode_len_mean: 837.087552742616
  episode_reward_max: 286.32323232323296
  episode_reward_mean: 232.94362933128744
  episode_reward_min: 123.89898989899017
  episodes_this_iter: 284
  episodes_total: 1896
  experiment_id: 3b7db5a386254126a6d74c41efb577bc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0087656676769257
        entropy_coeff: 0.0001
        kl: 0.0072033210114265485
        model: {}
        policy_loss: -0.01137208194025637
        total_loss: 15.296247164408365
        vf_explained_var: 0.9753820896148682
        vf_loss: 15.307000001271566
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.493548387096777
    gpu_util_percent0: 0.317741935483871
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9065
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15410013693176433
    mean_env_wait_ms: 1.1867297951603983
    mean_inference_ms: 4.78418960809956
    mean_raw_obs_processing_ms: 0.40437840691843296
  time_since_restore: 267.10374450683594
  time_this_iter_s: 26.18894386291504
  time_total_s: 267.10374450683594
  timers:
    learn_throughput: 8364.784
    learn_time_ms: 19342.043
    sample_throughput: 22231.335
    sample_time_ms: 7277.656
    update_time_ms: 37.575
  timestamp: 1602453529
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 4d85b_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4d85b_00000 | RUNNING  | 172.17.0.4:9065 |     10 |          267.104 | 1617920 |  232.944 |              286.323 |              123.899 |            837.088 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4d85b_00000:
  custom_metrics:
    time_step_max: 4238
    time_step_mean: 3509.876110562685
    time_step_min: 3189
  date: 2020-10-11_21-59-15
  done: false
  episode_len_mean: 834.6898734177215
  episode_reward_max: 286.32323232323296
  episode_reward_mean: 234.1199187591592
  episode_reward_min: 123.89898989899017
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: 3b7db5a386254126a6d74c41efb577bc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0014224549134572
        entropy_coeff: 0.0001
        kl: 0.006601741653867066
        model: {}
        policy_loss: -0.010757336252330182
        total_loss: 15.426527818044027
        vf_explained_var: 0.9704136848449707
        vf_loss: 15.436724742253622
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.7
    gpu_util_percent0: 0.30437499999999995
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.78125
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9065
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15372183298048026
    mean_env_wait_ms: 1.1881082892789137
    mean_inference_ms: 4.7605020500042
    mean_raw_obs_processing_ms: 0.40317529812751074
  time_since_restore: 293.54571437835693
  time_this_iter_s: 26.441969871520996
  time_total_s: 293.54571437835693
  timers:
    learn_throughput: 8379.277
    learn_time_ms: 19308.586
    sample_throughput: 22776.472
    sample_time_ms: 7103.471
    update_time_ms: 38.08
  timestamp: 1602453555
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 4d85b_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4d85b_00000 | RUNNING  | 172.17.0.4:9065 |     11 |          293.546 | 1779712 |   234.12 |              286.323 |              123.899 |             834.69 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4d85b_00000:
  custom_metrics:
    time_step_max: 4238
    time_step_mean: 3501.592032967033
    time_step_min: 3189
  date: 2020-10-11_21-59-42
  done: false
  episode_len_mean: 832.503616636528
  episode_reward_max: 286.32323232323296
  episode_reward_mean: 235.39496228103815
  episode_reward_min: 123.89898989899017
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 3b7db5a386254126a6d74c41efb577bc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9823817213376363
        entropy_coeff: 0.0001
        kl: 0.007344200547474126
        model: {}
        policy_loss: -0.01289298344636336
        total_loss: 12.10560917854309
        vf_explained_var: 0.9749732613563538
        vf_loss: 12.117865880330404
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.421212121212125
    gpu_util_percent0: 0.3527272727272727
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.772727272727273
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9065
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1533776556303542
    mean_env_wait_ms: 1.1893195501543898
    mean_inference_ms: 4.739042787362285
    mean_raw_obs_processing_ms: 0.40204116484227836
  time_since_restore: 320.2156071662903
  time_this_iter_s: 26.66989278793335
  time_total_s: 320.2156071662903
  timers:
    learn_throughput: 8365.895
    learn_time_ms: 19339.474
    sample_throughput: 22971.08
    sample_time_ms: 7043.291
    update_time_ms: 37.788
  timestamp: 1602453582
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 4d85b_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4d85b_00000 | RUNNING  | 172.17.0.4:9065 |     12 |          320.216 | 1941504 |  235.395 |              286.323 |              123.899 |            832.504 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4d85b_00000:
  custom_metrics:
    time_step_max: 4238
    time_step_mean: 3489.5200811359027
    time_step_min: 3189
  date: 2020-10-11_22-00-08
  done: false
  episode_len_mean: 829.5832330525471
  episode_reward_max: 286.32323232323296
  episode_reward_mean: 237.16121503847125
  episode_reward_min: 123.89898989899017
  episodes_this_iter: 281
  episodes_total: 2493
  experiment_id: 3b7db5a386254126a6d74c41efb577bc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.946636974811554
        entropy_coeff: 0.0001
        kl: 0.006418439947689573
        model: {}
        policy_loss: -0.009843386030600717
        total_loss: 17.84938955307007
        vf_explained_var: 0.9763081669807434
        vf_loss: 17.85868565241496
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.9375
    gpu_util_percent0: 0.408125
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7593750000000004
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9065
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15285069653377292
    mean_env_wait_ms: 1.1913399894286867
    mean_inference_ms: 4.705866742284013
    mean_raw_obs_processing_ms: 0.40030207509513144
  time_since_restore: 346.6218571662903
  time_this_iter_s: 26.40625
  time_total_s: 346.6218571662903
  timers:
    learn_throughput: 8378.819
    learn_time_ms: 19309.642
    sample_throughput: 23017.228
    sample_time_ms: 7029.17
    update_time_ms: 38.089
  timestamp: 1602453608
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 4d85b_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4d85b_00000 | RUNNING  | 172.17.0.4:9065 |     13 |          346.622 | 2103296 |  237.161 |              286.323 |              123.899 |            829.583 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4d85b_00000:
  custom_metrics:
    time_step_max: 4238
    time_step_mean: 3481.2114371708053
    time_step_min: 3189
  date: 2020-10-11_22-00-35
  done: false
  episode_len_mean: 828.1757259865972
  episode_reward_max: 286.32323232323296
  episode_reward_mean: 238.34189249155736
  episode_reward_min: 123.89898989899017
  episodes_this_iter: 193
  episodes_total: 2686
  experiment_id: 3b7db5a386254126a6d74c41efb577bc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.940344825387001
        entropy_coeff: 0.0001
        kl: 0.006452915763172011
        model: {}
        policy_loss: -0.01173625075413535
        total_loss: 13.316154638926188
        vf_explained_var: 0.9755885004997253
        vf_loss: 13.3273397286733
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.778125
    gpu_util_percent0: 0.369375
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.78125
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9065
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15253252857838467
    mean_env_wait_ms: 1.1925173790133377
    mean_inference_ms: 4.686214494182761
    mean_raw_obs_processing_ms: 0.3992764967008785
  time_since_restore: 373.10155272483826
  time_this_iter_s: 26.479695558547974
  time_total_s: 373.10155272483826
  timers:
    learn_throughput: 8380.413
    learn_time_ms: 19305.97
    sample_throughput: 23051.712
    sample_time_ms: 7018.655
    update_time_ms: 39.299
  timestamp: 1602453635
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 4d85b_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4d85b_00000 | RUNNING  | 172.17.0.4:9065 |     14 |          373.102 | 2265088 |  238.342 |              286.323 |              123.899 |            828.176 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4d85b_00000:
  custom_metrics:
    time_step_max: 4238
    time_step_mean: 3475.3053977272725
    time_step_min: 3158
  date: 2020-10-11_22-01-01
  done: false
  episode_len_mean: 826.8966244725739
  episode_reward_max: 287.5353535353531
  episode_reward_mean: 239.22642032135695
  episode_reward_min: 123.89898989899017
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: 3b7db5a386254126a6d74c41efb577bc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9390554924805959
        entropy_coeff: 0.0001
        kl: 0.007465235888957977
        model: {}
        policy_loss: -0.011200093928588709
        total_loss: 11.77927311261495
        vf_explained_var: 0.9756131172180176
        vf_loss: 11.789820750554403
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.86875
    gpu_util_percent0: 0.3971875
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.76875
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9065
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15230112445250815
    mean_env_wait_ms: 1.1933956996140875
    mean_inference_ms: 4.67148596176675
    mean_raw_obs_processing_ms: 0.398492617564084
  time_since_restore: 399.3029990196228
  time_this_iter_s: 26.201446294784546
  time_total_s: 399.3029990196228
  timers:
    learn_throughput: 8387.732
    learn_time_ms: 19289.124
    sample_throughput: 23117.624
    sample_time_ms: 6998.643
    update_time_ms: 39.079
  timestamp: 1602453661
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 4d85b_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4d85b_00000 | RUNNING  | 172.17.0.4:9065 |     15 |          399.303 | 2426880 |  239.226 |              287.535 |              123.899 |            826.897 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4d85b_00000:
  custom_metrics:
    time_step_max: 4238
    time_step_mean: 3470.052702249077
    time_step_min: 3158
  date: 2020-10-11_22-01-28
  done: false
  episode_len_mean: 825.7748586631194
  episode_reward_max: 287.5353535353531
  episode_reward_mean: 239.9778866147339
  episode_reward_min: 123.89898989899017
  episodes_this_iter: 163
  episodes_total: 3007
  experiment_id: 3b7db5a386254126a6d74c41efb577bc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9171208888292313
        entropy_coeff: 0.0001
        kl: 0.007122147246263921
        model: {}
        policy_loss: -0.011705448530847207
        total_loss: 13.658289035161337
        vf_explained_var: 0.9754629135131836
        vf_loss: 13.669373830159506
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.89677419354838
    gpu_util_percent0: 0.30193548387096786
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.780645161290323
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9065
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15208395234599975
    mean_env_wait_ms: 1.1942505412137265
    mean_inference_ms: 4.657376643680474
    mean_raw_obs_processing_ms: 0.3977416028954337
  time_since_restore: 425.2928762435913
  time_this_iter_s: 25.989877223968506
  time_total_s: 425.2928762435913
  timers:
    learn_throughput: 8403.94
    learn_time_ms: 19251.922
    sample_throughput: 23105.729
    sample_time_ms: 7002.246
    update_time_ms: 38.41
  timestamp: 1602453688
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 4d85b_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4d85b_00000 | RUNNING  | 172.17.0.4:9065 |     16 |          425.293 | 2588672 |  239.978 |              287.535 |              123.899 |            825.775 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4d85b_00000:
  custom_metrics:
    time_step_max: 4238
    time_step_mean: 3460.584601339014
    time_step_min: 3119
  date: 2020-10-11_22-01-54
  done: false
  episode_len_mean: 823.156910078455
  episode_reward_max: 293.44444444444446
  episode_reward_mean: 241.35139567064726
  episode_reward_min: 123.89898989899017
  episodes_this_iter: 307
  episodes_total: 3314
  experiment_id: 3b7db5a386254126a6d74c41efb577bc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8919271181027094
        entropy_coeff: 0.0001
        kl: 0.006586392410099506
        model: {}
        policy_loss: -0.010813367223211875
        total_loss: 14.648676792780558
        vf_explained_var: 0.9796624183654785
        vf_loss: 14.658920685450235
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.703125
    gpu_util_percent0: 0.38375000000000004
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7593750000000004
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9065
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1517074148258516
    mean_env_wait_ms: 1.1957316172498837
    mean_inference_ms: 4.633506344226159
    mean_raw_obs_processing_ms: 0.3965032410795351
  time_since_restore: 451.49702620506287
  time_this_iter_s: 26.204149961471558
  time_total_s: 451.49702620506287
  timers:
    learn_throughput: 8407.826
    learn_time_ms: 19243.024
    sample_throughput: 23120.496
    sample_time_ms: 6997.774
    update_time_ms: 39.921
  timestamp: 1602453714
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 4d85b_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4d85b_00000 | RUNNING  | 172.17.0.4:9065 |     17 |          451.497 | 2750464 |  241.351 |              293.444 |              123.899 |            823.157 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4d85b_00000:
  custom_metrics:
    time_step_max: 4238
    time_step_mean: 3455.5896171693735
    time_step_min: 3119
  date: 2020-10-11_22-02-21
  done: false
  episode_len_mean: 821.6622554660529
  episode_reward_max: 293.44444444444446
  episode_reward_mean: 242.09501807487993
  episode_reward_min: 123.89898989899017
  episodes_this_iter: 162
  episodes_total: 3476
  experiment_id: 3b7db5a386254126a6d74c41efb577bc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8782035609086355
        entropy_coeff: 0.0001
        kl: 0.006207475205883384
        model: {}
        policy_loss: -0.010211489231248075
        total_loss: 9.70069408416748
        vf_explained_var: 0.9806513786315918
        vf_loss: 9.71037244796753
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.271875
    gpu_util_percent0: 0.35968749999999994
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7843750000000003
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9065
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15153310122824504
    mean_env_wait_ms: 1.1964969154156075
    mean_inference_ms: 4.622434653715201
    mean_raw_obs_processing_ms: 0.39592054739133975
  time_since_restore: 478.06035113334656
  time_this_iter_s: 26.56332492828369
  time_total_s: 478.06035113334656
  timers:
    learn_throughput: 8402.667
    learn_time_ms: 19254.838
    sample_throughput: 23122.751
    sample_time_ms: 6997.091
    update_time_ms: 41.976
  timestamp: 1602453741
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 4d85b_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4d85b_00000 | RUNNING  | 172.17.0.4:9065 |     18 |           478.06 | 2912256 |  242.095 |              293.444 |              123.899 |            821.662 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4d85b_00000:
  custom_metrics:
    time_step_max: 4238
    time_step_mean: 3450.6012201885746
    time_step_min: 3119
  date: 2020-10-11_22-02-47
  done: false
  episode_len_mean: 820.2047330764997
  episode_reward_max: 293.44444444444446
  episode_reward_mean: 242.8543942451482
  episode_reward_min: 123.89898989899017
  episodes_this_iter: 158
  episodes_total: 3634
  experiment_id: 3b7db5a386254126a6d74c41efb577bc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8788556853930155
        entropy_coeff: 0.0001
        kl: 0.006201032005871336
        model: {}
        policy_loss: -0.01086453337726804
        total_loss: 9.22006924947103
        vf_explained_var: 0.9803513884544373
        vf_loss: 9.230401515960693
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.090625
    gpu_util_percent0: 0.36875
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7750000000000004
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9065
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15137277705746774
    mean_env_wait_ms: 1.1971666356919368
    mean_inference_ms: 4.612144671441917
    mean_raw_obs_processing_ms: 0.3953701652767176
  time_since_restore: 504.48411989212036
  time_this_iter_s: 26.423768758773804
  time_total_s: 504.48411989212036
  timers:
    learn_throughput: 8397.125
    learn_time_ms: 19267.546
    sample_throughput: 23134.214
    sample_time_ms: 6993.624
    update_time_ms: 35.809
  timestamp: 1602453767
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 4d85b_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4d85b_00000 | RUNNING  | 172.17.0.4:9065 |     19 |          504.484 | 3074048 |  242.854 |              293.444 |              123.899 |            820.205 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4d85b_00000:
  custom_metrics:
    time_step_max: 4238
    time_step_mean: 3443.493664339281
    time_step_min: 3119
  date: 2020-10-11_22-03-14
  done: false
  episode_len_mean: 818.2955070603338
  episode_reward_max: 293.44444444444446
  episode_reward_mean: 243.95936256013272
  episode_reward_min: 123.89898989899017
  episodes_this_iter: 261
  episodes_total: 3895
  experiment_id: 3b7db5a386254126a6d74c41efb577bc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.840090791384379
        entropy_coeff: 0.0001
        kl: 0.006405085092410445
        model: {}
        policy_loss: -0.011209893137371788
        total_loss: 14.292994181315104
        vf_explained_var: 0.97933030128479
        vf_loss: 14.30364759763082
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.753125
    gpu_util_percent0: 0.3609375
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.765625
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9065
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1511286665295618
    mean_env_wait_ms: 1.1982526364010837
    mean_inference_ms: 4.596405898733402
    mean_raw_obs_processing_ms: 0.394526120186733
  time_since_restore: 530.8371512889862
  time_this_iter_s: 26.353031396865845
  time_total_s: 530.8371512889862
  timers:
    learn_throughput: 8383.824
    learn_time_ms: 19298.115
    sample_throughput: 23179.721
    sample_time_ms: 6979.894
    update_time_ms: 34.842
  timestamp: 1602453794
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 4d85b_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4d85b_00000 | RUNNING  | 172.17.0.4:9065 |     20 |          530.837 | 3235840 |  243.959 |              293.444 |              123.899 |            818.296 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4d85b_00000:
  custom_metrics:
    time_step_max: 4238
    time_step_mean: 3438.406862745098
    time_step_min: 3119
  date: 2020-10-11_22-03-40
  done: false
  episode_len_mean: 816.9084712755599
  episode_reward_max: 293.44444444444446
  episode_reward_mean: 244.80948236011523
  episode_reward_min: 123.89898989899017
  episodes_this_iter: 213
  episodes_total: 4108
  experiment_id: 3b7db5a386254126a6d74c41efb577bc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8291916946570078
        entropy_coeff: 0.0001
        kl: 0.005608345187890033
        model: {}
        policy_loss: -0.010217425607455274
        total_loss: 10.493353366851807
        vf_explained_var: 0.9807274341583252
        vf_loss: 10.503093401590982
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.828125
    gpu_util_percent0: 0.40249999999999997
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.765625
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9065
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1509505912262014
    mean_env_wait_ms: 1.1990303330387262
    mean_inference_ms: 4.58486205923688
    mean_raw_obs_processing_ms: 0.3939142838726058
  time_since_restore: 557.0353231430054
  time_this_iter_s: 26.198171854019165
  time_total_s: 557.0353231430054
  timers:
    learn_throughput: 8384.3
    learn_time_ms: 19297.019
    sample_throughput: 23260.745
    sample_time_ms: 6955.581
    update_time_ms: 35.38
  timestamp: 1602453820
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: 4d85b_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4d85b_00000 | RUNNING  | 172.17.0.4:9065 |     21 |          557.035 | 3397632 |  244.809 |              293.444 |              123.899 |            816.908 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4d85b_00000:
  custom_metrics:
    time_step_max: 4238
    time_step_mean: 3434.036809815951
    time_step_min: 3119
  date: 2020-10-11_22-04-07
  done: false
  episode_len_mean: 816.0492264416315
  episode_reward_max: 293.44444444444446
  episode_reward_mean: 245.43275227663412
  episode_reward_min: 123.89898989899017
  episodes_this_iter: 158
  episodes_total: 4266
  experiment_id: 3b7db5a386254126a6d74c41efb577bc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8219243437051773
        entropy_coeff: 0.0001
        kl: 0.006758933925690751
        model: {}
        policy_loss: -0.012021305990250161
        total_loss: 7.464851975440979
        vf_explained_var: 0.9836471080780029
        vf_loss: 7.476279536883037
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.9375
    gpu_util_percent0: 0.398125
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7750000000000004
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9065
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1508264292194256
    mean_env_wait_ms: 1.1995719647958607
    mean_inference_ms: 4.5767743386482405
    mean_raw_obs_processing_ms: 0.39348058930815355
  time_since_restore: 583.4468765258789
  time_this_iter_s: 26.411553382873535
  time_total_s: 583.4468765258789
  timers:
    learn_throughput: 8386.784
    learn_time_ms: 19291.305
    sample_throughput: 23355.249
    sample_time_ms: 6927.436
    update_time_ms: 40.908
  timestamp: 1602453847
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: 4d85b_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4d85b_00000 | RUNNING  | 172.17.0.4:9065 |     22 |          583.447 | 3559424 |  245.433 |              293.444 |              123.899 |            816.049 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4d85b_00000:
  custom_metrics:
    time_step_max: 4238
    time_step_mean: 3429.6405332128334
    time_step_min: 3119
  date: 2020-10-11_22-04-33
  done: true
  episode_len_mean: 815.1385271665919
  episode_reward_max: 293.44444444444446
  episode_reward_mean: 246.12351399037522
  episode_reward_min: 123.89898989899017
  episodes_this_iter: 188
  episodes_total: 4454
  experiment_id: 3b7db5a386254126a6d74c41efb577bc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7969813942909241
        entropy_coeff: 0.0001
        kl: 0.006014809866125385
        model: {}
        policy_loss: -0.010011067841939317
        total_loss: 9.508941650390625
        vf_explained_var: 0.9833442568778992
        vf_loss: 9.518430471420288
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.775
    gpu_util_percent0: 0.37843750000000004
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.771875
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9065
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1506843374308563
    mean_env_wait_ms: 1.2002235839067126
    mean_inference_ms: 4.567648809683982
    mean_raw_obs_processing_ms: 0.3929857235301855
  time_since_restore: 609.8866877555847
  time_this_iter_s: 26.43981122970581
  time_total_s: 609.8866877555847
  timers:
    learn_throughput: 8380.273
    learn_time_ms: 19306.293
    sample_throughput: 23400.69
    sample_time_ms: 6913.984
    update_time_ms: 41.626
  timestamp: 1602453873
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: 4d85b_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4d85b_00000 | TERMINATED |       |     23 |          609.887 | 3721216 |  246.124 |              293.444 |              123.899 |            815.139 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4d85b_00000 | TERMINATED |       |     23 |          609.887 | 3721216 |  246.124 |              293.444 |              123.899 |            815.139 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


