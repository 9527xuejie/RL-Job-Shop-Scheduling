2020-10-10 19:46:36,217	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8266[39m[22m
== Status ==
Memory usage on this node: 32.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_4f402_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=35305)[0m 2020-10-10 19:46:39,197	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=35288)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35288)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35306)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35306)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35216)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35216)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35231)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35231)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35316)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35316)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35333)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35333)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35299)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35299)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35356)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35356)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35311)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35311)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35328)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35328)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35321)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35321)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35249)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35249)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35237)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35237)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35279)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35279)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35242)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35242)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35218)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35218)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35226)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35226)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35342)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35342)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35338)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35338)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35340)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35340)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35301)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35301)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35324)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35324)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35290)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35290)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35239)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35239)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35292)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35292)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35287)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35287)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35309)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35309)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35307)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35307)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35230)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35230)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35243)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35243)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35351)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35351)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35246)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35246)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35222)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35222)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35283)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35283)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35344)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35344)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35271)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35271)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35329)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35329)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35318)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35318)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35220)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35220)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35289)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35289)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35254)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35254)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35325)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35325)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35302)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35302)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35217)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35217)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35303)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35303)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35335)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35335)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35269)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35269)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35219)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35219)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35323)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35323)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35215)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35215)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35277)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35277)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35313)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35313)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35268)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35268)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35276)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35276)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35320)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35320)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35221)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35221)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35244)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35244)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35256)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35256)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35233)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35233)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35255)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35255)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35312)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35312)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35298)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35298)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35297)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35297)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35229)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35229)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35225)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35225)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35235)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35235)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35247)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35247)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35214)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35214)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35294)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35294)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35308)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35308)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35273)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35273)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35295)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35295)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35270)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35270)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35232)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35232)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35227)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35227)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35291)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35291)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35281)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35281)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35224)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35224)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35296)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35296)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_4f402_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-10_19-47-22
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 5a1c611f9a8f41d9b90a58b4f60541f6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.1844405276434762
        entropy_coeff: 0.00010000000000000002
        kl: 0.00450187675388796
        model: {}
        policy_loss: -0.003833682299175832
        total_loss: 16.360500471932546
        vf_explained_var: 0.5462602972984314
        vf_loss: 16.36355229786464
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.997727272727275
    gpu_util_percent0: 0.3297727272727273
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.00022727272727272727
    ram_util_percent: 6.299999999999998
    vram_util_percent0: 0.1927084886251826
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 35305
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17209739072634214
    mean_env_wait_ms: 1.1949021892070624
    mean_inference_ms: 5.817169467399576
    mean_raw_obs_processing_ms: 0.46088293475403985
  time_since_restore: 37.31314778327942
  time_this_iter_s: 37.31314778327942
  time_total_s: 37.31314778327942
  timers:
    learn_throughput: 5798.847
    learn_time_ms: 27900.717
    sample_throughput: 17330.895
    sample_time_ms: 9335.467
    update_time_ms: 46.933
  timestamp: 1602359242
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 4f402_00000
  
== Status ==
Memory usage on this node: 48.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4f402_00000 | RUNNING  | 172.17.0.4:35305 |      1 |          37.3131 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4f402_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3606.2083333333335
    time_step_min: 3318
  date: 2020-10-10_19-47-57
  done: false
  episode_len_mean: 882.3069620253165
  episode_reward_max: 263.2929292929288
  episode_reward_mean: 219.5870412990664
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 5a1c611f9a8f41d9b90a58b4f60541f6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.1549177169799805
        entropy_coeff: 0.00010000000000000002
        kl: 0.007260173160050597
        model: {}
        policy_loss: -0.006629330757797496
        total_loss: 11.106062684740339
        vf_explained_var: 0.8100948333740234
        vf_loss: 11.11208166394915
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.228571428571428
    gpu_util_percent0: 0.2680952380952381
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.476190476190476
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 35305
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1682123639295691
    mean_env_wait_ms: 1.1942165105202454
    mean_inference_ms: 5.592418698812984
    mean_raw_obs_processing_ms: 0.45029927917888307
  time_since_restore: 73.0585834980011
  time_this_iter_s: 35.74543571472168
  time_total_s: 73.0585834980011
  timers:
    learn_throughput: 5814.051
    learn_time_ms: 27827.76
    sample_throughput: 18798.389
    sample_time_ms: 8606.695
    update_time_ms: 47.361
  timestamp: 1602359277
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 4f402_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4f402_00000 | RUNNING  | 172.17.0.4:35305 |      2 |          73.0586 | 323584 |  219.587 |              263.293 |              145.717 |            882.307 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4f402_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3603.0
    time_step_min: 3318
  date: 2020-10-10_19-48-33
  done: false
  episode_len_mean: 872.3333333333334
  episode_reward_max: 263.2929292929288
  episode_reward_mean: 220.0116992711927
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 5a1c611f9a8f41d9b90a58b4f60541f6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.1361016205378942
        entropy_coeff: 0.00010000000000000002
        kl: 0.007536961896611112
        model: {}
        policy_loss: -0.006087135149365557
        total_loss: 13.80557748249599
        vf_explained_var: 0.8750059008598328
        vf_loss: 13.811024257114955
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.44146341463415
    gpu_util_percent0: 0.2858536585365854
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.485365853658536
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 35305
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16547862129557162
    mean_env_wait_ms: 1.1962034888930053
    mean_inference_ms: 5.419575987464295
    mean_raw_obs_processing_ms: 0.44241954344139345
  time_since_restore: 108.27449870109558
  time_this_iter_s: 35.21591520309448
  time_total_s: 108.27449870109558
  timers:
    learn_throughput: 5823.172
    learn_time_ms: 27784.168
    sample_throughput: 19699.168
    sample_time_ms: 8213.139
    update_time_ms: 46.872
  timestamp: 1602359313
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 4f402_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4f402_00000 | RUNNING  | 172.17.0.4:35305 |      3 |          108.274 | 485376 |  220.012 |              263.293 |              145.717 |            872.333 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4f402_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3603.2168874172185
    time_step_min: 3306
  date: 2020-10-10_19-49-08
  done: false
  episode_len_mean: 863.5569620253165
  episode_reward_max: 268.8989898989898
  episode_reward_mean: 220.69967075821486
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 5a1c611f9a8f41d9b90a58b4f60541f6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.111703566142491
        entropy_coeff: 0.00010000000000000002
        kl: 0.0051890909339168245
        model: {}
        policy_loss: -0.005507978461017566
        total_loss: 15.462928227015905
        vf_explained_var: 0.9078155755996704
        vf_loss: 15.468028681618827
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.714285714285715
    gpu_util_percent0: 0.3180952380952381
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.480952380952381
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 35305
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16350226174495958
    mean_env_wait_ms: 1.1994268380737714
    mean_inference_ms: 5.2896633305349825
    mean_raw_obs_processing_ms: 0.43608620969502826
  time_since_restore: 143.52754402160645
  time_this_iter_s: 35.253045320510864
  time_total_s: 143.52754402160645
  timers:
    learn_throughput: 5824.519
    learn_time_ms: 27777.745
    sample_throughput: 20239.61
    sample_time_ms: 7993.83
    update_time_ms: 60.628
  timestamp: 1602359348
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 4f402_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4f402_00000 | RUNNING  | 172.17.0.4:35305 |      4 |          143.528 | 647168 |    220.7 |              268.899 |              145.717 |            863.557 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4f402_00000:
  custom_metrics:
    time_step_max: 4375
    time_step_mean: 3596.6338983050846
    time_step_min: 3292
  date: 2020-10-10_19-49-43
  done: false
  episode_len_mean: 850.1982475355969
  episode_reward_max: 271.6262626262622
  episode_reward_mean: 221.18167435582532
  episode_reward_min: 103.14141414141451
  episodes_this_iter: 281
  episodes_total: 913
  experiment_id: 5a1c611f9a8f41d9b90a58b4f60541f6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.0776924320629664
        entropy_coeff: 0.00010000000000000002
        kl: 0.004998633737808892
        model: {}
        policy_loss: -0.005351239806198497
        total_loss: 21.01375756944929
        vf_explained_var: 0.9443046450614929
        vf_loss: 21.018716948372976
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.70731707317073
    gpu_util_percent0: 0.3453658536585366
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.485365853658536
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 35305
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16110318362648177
    mean_env_wait_ms: 1.2066244203908971
    mean_inference_ms: 5.135756215593548
    mean_raw_obs_processing_ms: 0.42860600111970976
  time_since_restore: 178.74155640602112
  time_this_iter_s: 35.21401238441467
  time_total_s: 178.74155640602112
  timers:
    learn_throughput: 5820.399
    learn_time_ms: 27797.405
    sample_throughput: 20623.097
    sample_time_ms: 7845.184
    update_time_ms: 55.53
  timestamp: 1602359383
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 4f402_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4f402_00000 | RUNNING  | 172.17.0.4:35305 |      5 |          178.742 | 808960 |  221.182 |              271.626 |              103.141 |            850.198 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4f402_00000:
  custom_metrics:
    time_step_max: 4375
    time_step_mean: 3593.134508348794
    time_step_min: 3292
  date: 2020-10-10_19-50-19
  done: false
  episode_len_mean: 843.0443037974684
  episode_reward_max: 271.6262626262622
  episode_reward_mean: 221.83339726377687
  episode_reward_min: 103.14141414141451
  episodes_this_iter: 193
  episodes_total: 1106
  experiment_id: 5a1c611f9a8f41d9b90a58b4f60541f6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 1.0e-05
        entropy: 1.0651060683386666
        entropy_coeff: 0.00010000000000000002
        kl: 0.005975143185683659
        model: {}
        policy_loss: -0.005401402171368578
        total_loss: 14.320593425205775
        vf_explained_var: 0.9532895088195801
        vf_loss: 14.325802394321986
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.87073170731707
    gpu_util_percent0: 0.38853658536585367
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.49268292682927
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 35305
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15999083294611488
    mean_env_wait_ms: 1.210685451314638
    mean_inference_ms: 5.06079540751679
    mean_raw_obs_processing_ms: 0.4249359487255209
  time_since_restore: 214.07609462738037
  time_this_iter_s: 35.33453822135925
  time_total_s: 214.07609462738037
  timers:
    learn_throughput: 5810.038
    learn_time_ms: 27846.979
    sample_throughput: 20931.076
    sample_time_ms: 7729.751
    update_time_ms: 52.565
  timestamp: 1602359419
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 4f402_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4f402_00000 | RUNNING  | 172.17.0.4:35305 |      6 |          214.076 | 970752 |  221.833 |              271.626 |              103.141 |            843.044 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4f402_00000:
  custom_metrics:
    time_step_max: 4375
    time_step_mean: 3591.3535598705503
    time_step_min: 3292
  date: 2020-10-10_19-50-54
  done: false
  episode_len_mean: 837.871835443038
  episode_reward_max: 271.6262626262622
  episode_reward_mean: 222.1268380002556
  episode_reward_min: 103.14141414141451
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: 5a1c611f9a8f41d9b90a58b4f60541f6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 1.0e-05
        entropy: 1.0384036472865514
        entropy_coeff: 0.00010000000000000002
        kl: 0.005473977620048183
        model: {}
        policy_loss: -0.00510025314620829
        total_loss: 11.523357118879046
        vf_explained_var: 0.9680077433586121
        vf_loss: 11.528287206377302
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.71707317073171
    gpu_util_percent0: 0.2529268292682927
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497560975609756
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 35305
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15920298609459327
    mean_env_wait_ms: 1.213468444705722
    mean_inference_ms: 5.009740130328474
    mean_raw_obs_processing_ms: 0.4223286249444365
  time_since_restore: 249.3124554157257
  time_this_iter_s: 35.23636078834534
  time_total_s: 249.3124554157257
  timers:
    learn_throughput: 5807.647
    learn_time_ms: 27858.441
    sample_throughput: 21133.652
    sample_time_ms: 7655.658
    update_time_ms: 50.763
  timestamp: 1602359454
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 4f402_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4f402_00000 | RUNNING  | 172.17.0.4:35305 |      7 |          249.312 | 1132544 |  222.127 |              271.626 |              103.141 |            837.872 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4f402_00000:
  custom_metrics:
    time_step_max: 4375
    time_step_mean: 3588.058106169297
    time_step_min: 3292
  date: 2020-10-10_19-51-29
  done: false
  episode_len_mean: 833.8143459915611
  episode_reward_max: 271.6262626262622
  episode_reward_mean: 222.55591782806962
  episode_reward_min: 103.14141414141451
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 5a1c611f9a8f41d9b90a58b4f60541f6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 1.0e-05
        entropy: 0.9847303799220494
        entropy_coeff: 0.00010000000000000002
        kl: 0.00582355257522847
        model: {}
        policy_loss: -0.0038613010120960617
        total_loss: 10.33654158455985
        vf_explained_var: 0.9773072600364685
        vf_loss: 10.340210437774658
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.61951219512195
    gpu_util_percent0: 0.32439024390243903
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.482926829268291
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 35305
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15851453069307472
    mean_env_wait_ms: 1.2161380083402893
    mean_inference_ms: 4.9655947236803915
    mean_raw_obs_processing_ms: 0.4200083994279323
  time_since_restore: 284.3622386455536
  time_this_iter_s: 35.04978322982788
  time_total_s: 284.3622386455536
  timers:
    learn_throughput: 5808.658
    learn_time_ms: 27853.594
    sample_throughput: 21342.79
    sample_time_ms: 7580.639
    update_time_ms: 49.384
  timestamp: 1602359489
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 4f402_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4f402_00000 | RUNNING  | 172.17.0.4:35305 |      8 |          284.362 | 1294336 |  222.556 |              271.626 |              103.141 |            833.814 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4f402_00000:
  custom_metrics:
    time_step_max: 4375
    time_step_mean: 3585.9397660818713
    time_step_min: 3271
  date: 2020-10-10_19-52-05
  done: false
  episode_len_mean: 827.445914844649
  episode_reward_max: 271.6262626262622
  episode_reward_mean: 222.8265276470109
  episode_reward_min: 103.14141414141451
  episodes_this_iter: 316
  episodes_total: 1738
  experiment_id: 5a1c611f9a8f41d9b90a58b4f60541f6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 1.0e-05
        entropy: 0.9512407396520887
        entropy_coeff: 0.00010000000000000002
        kl: 0.005011184407132012
        model: {}
        policy_loss: -0.004135578881167541
        total_loss: 11.581351143973214
        vf_explained_var: 0.9846581816673279
        vf_loss: 11.585331508091517
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.778048780487808
    gpu_util_percent0: 0.28707317073170735
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.485365853658536
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 35305
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15741417717074582
    mean_env_wait_ms: 1.2210776472116387
    mean_inference_ms: 4.895224309800188
    mean_raw_obs_processing_ms: 0.41636660376791285
  time_since_restore: 319.6344983577728
  time_this_iter_s: 35.27225971221924
  time_total_s: 319.6344983577728
  timers:
    learn_throughput: 5810.951
    learn_time_ms: 27842.601
    sample_throughput: 21391.138
    sample_time_ms: 7563.506
    update_time_ms: 47.87
  timestamp: 1602359525
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 4f402_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4f402_00000 | RUNNING  | 172.17.0.4:35305 |      9 |          319.634 | 1456128 |  222.827 |              271.626 |              103.141 |            827.446 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4f402_00000:
  custom_metrics:
    time_step_max: 4375
    time_step_mean: 3585.144539614561
    time_step_min: 3271
  date: 2020-10-10_19-52-40
  done: false
  episode_len_mean: 824.6424050632911
  episode_reward_max: 271.6262626262622
  episode_reward_mean: 223.10841004986565
  episode_reward_min: 103.14141414141451
  episodes_this_iter: 158
  episodes_total: 1896
  experiment_id: 5a1c611f9a8f41d9b90a58b4f60541f6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 1.0e-05
        entropy: 0.903679370880127
        entropy_coeff: 0.00010000000000000002
        kl: 0.005083478255463498
        model: {}
        policy_loss: -0.005555871874094009
        total_loss: 6.27986877305167
        vf_explained_var: 0.9885939359664917
        vf_loss: 6.285260881696429
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.31463414634146
    gpu_util_percent0: 0.25219512195121957
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.5
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 35305
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15696288547273926
    mean_env_wait_ms: 1.223140016834793
    mean_inference_ms: 4.866671308587601
    mean_raw_obs_processing_ms: 0.41485406317130064
  time_since_restore: 354.794974565506
  time_this_iter_s: 35.160476207733154
  time_total_s: 354.794974565506
  timers:
    learn_throughput: 5810.841
    learn_time_ms: 27843.128
    sample_throughput: 21488.285
    sample_time_ms: 7529.312
    update_time_ms: 46.453
  timestamp: 1602359560
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 4f402_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4f402_00000 | RUNNING  | 172.17.0.4:35305 |     10 |          354.795 | 1617920 |  223.108 |              271.626 |              103.141 |            824.642 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4f402_00000:
  custom_metrics:
    time_step_max: 4375
    time_step_mean: 3584.2418558736426
    time_step_min: 3271
  date: 2020-10-10_19-53-15
  done: false
  episode_len_mean: 822.1041869522883
  episode_reward_max: 271.6262626262622
  episode_reward_mean: 223.167527268793
  episode_reward_min: 103.14141414141451
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: 5a1c611f9a8f41d9b90a58b4f60541f6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 1.0e-05
        entropy: 0.8770352176257542
        entropy_coeff: 0.00010000000000000002
        kl: 0.004642816027626395
        model: {}
        policy_loss: -0.0041667830316457965
        total_loss: 5.360162700925555
        vf_explained_var: 0.990423321723938
        vf_loss: 5.364185128893171
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.297560975609755
    gpu_util_percent0: 0.33999999999999997
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.504878048780488
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 35305
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15655085700593804
    mean_env_wait_ms: 1.2251114627991513
    mean_inference_ms: 4.840874418846674
    mean_raw_obs_processing_ms: 0.4134513938946145
  time_since_restore: 389.9850583076477
  time_this_iter_s: 35.190083742141724
  time_total_s: 389.9850583076477
  timers:
    learn_throughput: 5810.972
    learn_time_ms: 27842.501
    sample_throughput: 22120.789
    sample_time_ms: 7314.025
    update_time_ms: 47.197
  timestamp: 1602359595
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 4f402_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4f402_00000 | RUNNING  | 172.17.0.4:35305 |     11 |          389.985 | 1779712 |  223.168 |              271.626 |              103.141 |            822.104 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4f402_00000:
  custom_metrics:
    time_step_max: 4375
    time_step_mean: 3580.304442508711
    time_step_min: 3271
  date: 2020-10-10_19-53-50
  done: false
  episode_len_mean: 818.4845094664372
  episode_reward_max: 271.6262626262622
  episode_reward_mean: 223.7586884333872
  episode_reward_min: 103.14141414141451
  episodes_this_iter: 270
  episodes_total: 2324
  experiment_id: 5a1c611f9a8f41d9b90a58b4f60541f6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025000000000000005
        cur_lr: 1.0e-05
        entropy: 0.8499501432691302
        entropy_coeff: 0.00010000000000000002
        kl: 0.0039250446716323495
        model: {}
        policy_loss: -0.003141307197178581
        total_loss: 6.678173473903111
        vf_explained_var: 0.9921883344650269
        vf_loss: 6.681301389421735
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.4975
    gpu_util_percent0: 0.28600000000000003
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4875
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 35305
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15593140386185694
    mean_env_wait_ms: 1.2284046306047725
    mean_inference_ms: 4.80254383838877
    mean_raw_obs_processing_ms: 0.41135147417074286
  time_since_restore: 425.1372616291046
  time_this_iter_s: 35.15220332145691
  time_total_s: 425.1372616291046
  timers:
    learn_throughput: 5812.993
    learn_time_ms: 27832.824
    sample_throughput: 22261.381
    sample_time_ms: 7267.833
    update_time_ms: 44.65
  timestamp: 1602359630
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 4f402_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4f402_00000 | RUNNING  | 172.17.0.4:35305 |     12 |          425.137 | 1941504 |  223.759 |              271.626 |              103.141 |            818.485 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4f402_00000:
  custom_metrics:
    time_step_max: 4375
    time_step_mean: 3577.8524
    time_step_min: 3271
  date: 2020-10-10_19-54-26
  done: false
  episode_len_mean: 816.3136867088608
  episode_reward_max: 271.6262626262622
  episode_reward_mean: 224.12044895154074
  episode_reward_min: 103.14141414141451
  episodes_this_iter: 204
  episodes_total: 2528
  experiment_id: 5a1c611f9a8f41d9b90a58b4f60541f6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.012500000000000002
        cur_lr: 1.0e-05
        entropy: 0.7978586511952537
        entropy_coeff: 0.00010000000000000002
        kl: 0.004508724070287177
        model: {}
        policy_loss: -0.0033749911318799214
        total_loss: 4.979239872523716
        vf_explained_var: 0.9923165440559387
        vf_loss: 4.98263829095023
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.429268292682927
    gpu_util_percent0: 0.2919512195121951
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.5
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 35305
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15554594636691535
    mean_env_wait_ms: 1.2307223790129758
    mean_inference_ms: 4.77770012306439
    mean_raw_obs_processing_ms: 0.4100763805424611
  time_since_restore: 460.19656586647034
  time_this_iter_s: 35.05930423736572
  time_total_s: 460.19656586647034
  timers:
    learn_throughput: 5811.437
    learn_time_ms: 27840.276
    sample_throughput: 22336.737
    sample_time_ms: 7243.314
    update_time_ms: 45.233
  timestamp: 1602359666
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 4f402_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4f402_00000 | RUNNING  | 172.17.0.4:35305 |     13 |          460.197 | 2103296 |   224.12 |              271.626 |              103.141 |            816.314 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4f402_00000:
  custom_metrics:
    time_step_max: 4375
    time_step_mean: 3574.17870579383
    time_step_min: 3271
  date: 2020-10-10_19-55-01
  done: false
  episode_len_mean: 814.8503350707372
  episode_reward_max: 271.6262626262622
  episode_reward_mean: 224.62774054769582
  episode_reward_min: 103.14141414141451
  episodes_this_iter: 158
  episodes_total: 2686
  experiment_id: 5a1c611f9a8f41d9b90a58b4f60541f6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.006250000000000001
        cur_lr: 1.0e-05
        entropy: 0.7848586525235858
        entropy_coeff: 0.00010000000000000002
        kl: 0.003479861787387303
        model: {}
        policy_loss: -0.004132017193894301
        total_loss: 3.9738671609333585
        vf_explained_var: 0.9932460784912109
        vf_loss: 3.978055851800101
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.882926829268293
    gpu_util_percent0: 0.24634146341463417
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497560975609756
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 35305
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15526829126001518
    mean_env_wait_ms: 1.2322710183734538
    mean_inference_ms: 4.760221483973688
    mean_raw_obs_processing_ms: 0.4091419351418629
  time_since_restore: 495.4019365310669
  time_this_iter_s: 35.20537066459656
  time_total_s: 495.4019365310669
  timers:
    learn_throughput: 5809.708
    learn_time_ms: 27848.559
    sample_throughput: 22354.461
    sample_time_ms: 7237.571
    update_time_ms: 37.826
  timestamp: 1602359701
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 4f402_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4f402_00000 | RUNNING  | 172.17.0.4:35305 |     14 |          495.402 | 2265088 |  224.628 |              271.626 |              103.141 |             814.85 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4f402_00000:
  custom_metrics:
    time_step_max: 4375
    time_step_mean: 3571.2622253720765
    time_step_min: 3271
  date: 2020-10-10_19-55-36
  done: false
  episode_len_mean: 813.3575438596491
  episode_reward_max: 271.6262626262622
  episode_reward_mean: 225.14742158426367
  episode_reward_min: 103.14141414141451
  episodes_this_iter: 164
  episodes_total: 2850
  experiment_id: 5a1c611f9a8f41d9b90a58b4f60541f6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0031250000000000006
        cur_lr: 1.0e-05
        entropy: 0.7732630031449454
        entropy_coeff: 0.00010000000000000002
        kl: 0.0036668263242713045
        model: {}
        policy_loss: -0.004144275781332648
        total_loss: 3.7875431265149797
        vf_explained_var: 0.994385302066803
        vf_loss: 3.7917531728744507
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.490243902439026
    gpu_util_percent0: 0.34902439024390247
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.495121951219511
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 35305
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1550041497277761
    mean_env_wait_ms: 1.2338677209405213
    mean_inference_ms: 4.743491769720777
    mean_raw_obs_processing_ms: 0.4082382162612623
  time_since_restore: 530.5053539276123
  time_this_iter_s: 35.10341739654541
  time_total_s: 530.5053539276123
  timers:
    learn_throughput: 5814.322
    learn_time_ms: 27826.459
    sample_throughput: 22329.706
    sample_time_ms: 7245.595
    update_time_ms: 37.853
  timestamp: 1602359736
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 4f402_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4f402_00000 | RUNNING  | 172.17.0.4:35305 |     15 |          530.505 | 2426880 |  225.147 |              271.626 |              103.141 |            813.358 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4f402_00000:
  custom_metrics:
    time_step_max: 4375
    time_step_mean: 3563.324712643678
    time_step_min: 3271
  date: 2020-10-10_19-56-11
  done: false
  episode_len_mean: 810.9879746835443
  episode_reward_max: 271.6262626262622
  episode_reward_mean: 226.14817478583302
  episode_reward_min: 103.14141414141451
  episodes_this_iter: 310
  episodes_total: 3160
  experiment_id: 5a1c611f9a8f41d9b90a58b4f60541f6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0015625000000000003
        cur_lr: 1.0e-05
        entropy: 0.732566352401461
        entropy_coeff: 0.00010000000000000002
        kl: 0.003373253857716918
        model: {}
        policy_loss: -0.0027686280331441332
        total_loss: 4.445261989321027
        vf_explained_var: 0.9941410422325134
        vf_loss: 4.448098659515381
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.692682926829267
    gpu_util_percent0: 0.2921951219512195
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.485365853658536
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 35305
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1545633921328727
    mean_env_wait_ms: 1.2366622044011406
    mean_inference_ms: 4.715375555074117
    mean_raw_obs_processing_ms: 0.40673277319556667
  time_since_restore: 565.7107894420624
  time_this_iter_s: 35.20543551445007
  time_total_s: 565.7107894420624
  timers:
    learn_throughput: 5821.855
    learn_time_ms: 27790.453
    sample_throughput: 22260.23
    sample_time_ms: 7268.209
    update_time_ms: 37.046
  timestamp: 1602359771
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 4f402_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4f402_00000 | RUNNING  | 172.17.0.4:35305 |     16 |          565.711 | 2588672 |  226.148 |              271.626 |              103.141 |            810.988 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4f402_00000:
  custom_metrics:
    time_step_max: 4375
    time_step_mean: 3559.9559270516716
    time_step_min: 3271
  date: 2020-10-10_19-56-47
  done: true
  episode_len_mean: 810.086196503918
  episode_reward_max: 271.6262626262622
  episode_reward_mean: 226.552833945239
  episode_reward_min: 103.14141414141451
  episodes_this_iter: 158
  episodes_total: 3318
  experiment_id: 5a1c611f9a8f41d9b90a58b4f60541f6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0007812500000000002
        cur_lr: 1.0e-05
        entropy: 0.7026125277791705
        entropy_coeff: 0.00010000000000000002
        kl: 0.0033043736891288844
        model: {}
        policy_loss: -0.004545528217152294
        total_loss: 3.0183547905513217
        vf_explained_var: 0.9947816133499146
        vf_loss: 3.022968019757952
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.778048780487808
    gpu_util_percent0: 0.27585365853658533
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.492682926829268
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 35305
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15436450461869106
    mean_env_wait_ms: 1.237921699481053
    mean_inference_ms: 4.702660438065607
    mean_raw_obs_processing_ms: 0.4060564506428273
  time_since_restore: 600.8053297996521
  time_this_iter_s: 35.09454035758972
  time_total_s: 600.8053297996521
  timers:
    learn_throughput: 5824.214
    learn_time_ms: 27779.198
    sample_throughput: 22270.152
    sample_time_ms: 7264.971
    update_time_ms: 36.91
  timestamp: 1602359807
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 4f402_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4f402_00000 | TERMINATED |       |     17 |          600.805 | 2750464 |  226.553 |              271.626 |              103.141 |            810.086 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4f402_00000 | TERMINATED |       |     17 |          600.805 | 2750464 |  226.553 |              271.626 |              103.141 |            810.086 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


