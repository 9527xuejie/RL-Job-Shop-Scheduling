2020-10-11 11:44:34,497	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_22e7e_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=21893)[0m 2020-10-11 11:44:37,217	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=21919)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21919)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21898)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21898)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21879)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21879)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21915)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21915)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21911)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21911)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21903)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21903)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21892)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21892)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21837)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21837)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21895)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21895)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21882)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21882)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21913)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21913)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21904)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21904)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21853)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21853)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21876)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21876)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21877)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21877)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21889)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21889)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21814)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21814)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21883)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21883)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21909)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21909)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21897)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21897)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21917)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21917)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21815)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21815)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21827)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21827)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21901)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21901)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21812)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21812)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21906)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21906)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21891)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21891)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21908)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21908)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21819)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21819)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21910)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21910)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21907)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21907)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21817)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21817)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21890)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21890)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21822)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21822)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21811)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21811)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21925)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21925)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21813)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21813)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21937)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21937)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21818)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21818)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21923)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21923)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21830)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21830)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21831)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21831)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21886)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21886)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21881)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21881)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21940)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21940)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21896)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21896)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21828)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21828)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21905)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21905)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21836)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21836)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21824)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21824)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21888)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21888)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21900)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21900)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21930)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21930)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21932)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21932)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21825)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21825)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21816)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21816)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21847)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21847)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21899)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21899)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21839)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21839)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21902)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21902)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21875)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21875)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21854)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21854)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21829)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21829)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21841)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21841)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21885)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21885)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21933)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21933)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21873)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21873)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21821)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21821)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21887)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21887)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21926)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21926)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21826)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21826)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21880)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21880)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21845)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21845)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21856)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21856)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21850)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21850)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21929)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21929)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21848)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21848)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21894)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21894)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21878)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21878)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_22e7e_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.267942583732
    time_step_min: 3363
  date: 2020-10-11_11-45-19
  done: false
  episode_len_mean: 889.379746835443
  episode_reward_max: 261.32323232323233
  episode_reward_mean: 217.15624600434705
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 237
  episodes_total: 237
  experiment_id: 84f55d03837049678ee3f548fd31feed
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 0.00010000000000000002
        entropy: 1.1515328645706178
        entropy_coeff: 0.00010000000000000002
        kl: 0.010727026065190633
        model: {}
        policy_loss: -0.02324618815133969
        total_loss: -0.02121593654155731
        vf_explained_var: 0.0041161575354635715
        vf_loss: 0.0
    num_steps_sampled: 210783
    num_steps_trained: 210783
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.288636363636364
    gpu_util_percent0: 0.2252272727272727
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5636363636363626
    vram_util_percent0: 0.07299710784459884
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 21893
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16648777601686732
    mean_env_wait_ms: 1.172007982092815
    mean_inference_ms: 5.605068870778583
    mean_raw_obs_processing_ms: 0.42467628377691685
  time_since_restore: 37.207940340042114
  time_this_iter_s: 37.207940340042114
  time_total_s: 37.207940340042114
  timers:
    learn_throughput: 9291.256
    learn_time_ms: 22686.169
    sample_throughput: 14599.192
    sample_time_ms: 14437.991
    update_time_ms: 40.941
  timestamp: 1602416719
  timesteps_since_restore: 0
  timesteps_total: 210783
  training_iteration: 1
  trial_id: 22e7e_00000
  
== Status ==
Memory usage on this node: 27.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |      1 |          37.2079 | 210783 |  217.156 |              261.323 |              145.717 |             889.38 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_22e7e_00000:
  custom_metrics:
    time_step_max: 4191
    time_step_mean: 3621.2399103139014
    time_step_min: 3316
  date: 2020-10-11_11-45-49
  done: false
  episode_len_mean: 890.4978902953586
  episode_reward_max: 265.2626262626267
  episode_reward_mean: 217.21218514256464
  episode_reward_min: 131.02020202020205
  episodes_this_iter: 237
  episodes_total: 474
  experiment_id: 84f55d03837049678ee3f548fd31feed
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 0.00010000000000000002
        entropy: 1.1433068990707398
        entropy_coeff: 0.00010000000000000002
        kl: 0.01189851804325978
        model: {}
        policy_loss: -0.02315738166992863
        total_loss: -0.02089200944950183
        vf_explained_var: 0.004307313822209835
        vf_loss: 0.0
    num_steps_sampled: 422096
    num_steps_trained: 422096
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.04571428571429
    gpu_util_percent0: 0.27942857142857147
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.851428571428572
    vram_util_percent0: 0.0879796654640866
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 21893
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16371548482521198
    mean_env_wait_ms: 1.1686532604347295
    mean_inference_ms: 5.420568834611119
    mean_raw_obs_processing_ms: 0.4220212101908426
  time_since_restore: 66.73374390602112
  time_this_iter_s: 29.525803565979004
  time_total_s: 66.73374390602112
  timers:
    learn_throughput: 9293.709
    learn_time_ms: 22708.694
    sample_throughput: 20029.689
    sample_time_ms: 10536.759
    update_time_ms: 64.624
  timestamp: 1602416749
  timesteps_since_restore: 0
  timesteps_total: 422096
  training_iteration: 2
  trial_id: 22e7e_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |      2 |          66.7337 | 422096 |  217.212 |              265.263 |               131.02 |            890.498 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_22e7e_00000:
  custom_metrics:
    time_step_max: 4191
    time_step_mean: 3612.7730600292825
    time_step_min: 3316
  date: 2020-10-11_11-46-23
  done: false
  episode_len_mean: 888.9957805907173
  episode_reward_max: 265.2626262626267
  episode_reward_mean: 219.07969995311745
  episode_reward_min: 131.02020202020205
  episodes_this_iter: 237
  episodes_total: 711
  experiment_id: 84f55d03837049678ee3f548fd31feed
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 0.00010000000000000002
        entropy: 1.1310136556625365
        entropy_coeff: 0.00010000000000000002
        kl: 0.010968415128688017
        model: {}
        policy_loss: -0.026474943245799902
        total_loss: -0.024394361876572172
        vf_explained_var: 0.0043815732933580875
        vf_loss: 0.0
    num_steps_sampled: 632076
    num_steps_trained: 632076
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.284615384615392
    gpu_util_percent0: 0.2474358974358974
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8717948717948727
    vram_util_percent0: 0.08797966546408661
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 21893
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16112216399976034
    mean_env_wait_ms: 1.165414661820334
    mean_inference_ms: 5.249603295063079
    mean_raw_obs_processing_ms: 0.41388107167270655
  time_since_restore: 101.0947494506836
  time_this_iter_s: 34.361005544662476
  time_total_s: 101.0947494506836
  timers:
    learn_throughput: 9336.421
    learn_time_ms: 22566.678
    sample_throughput: 19127.495
    sample_time_ms: 11015.138
    update_time_ms: 54.743
  timestamp: 1602416783
  timesteps_since_restore: 0
  timesteps_total: 632076
  training_iteration: 3
  trial_id: 22e7e_00000
  
== Status ==
Memory usage on this node: 28.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |      3 |          101.095 | 632076 |   219.08 |              265.263 |               131.02 |            888.996 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_22e7e_00000:
  custom_metrics:
    time_step_max: 4191
    time_step_mean: 3606.198913043478
    time_step_min: 3275
  date: 2020-10-11_11-46-53
  done: false
  episode_len_mean: 889.0622362869199
  episode_reward_max: 272.38383838383766
  episode_reward_mean: 220.0991241529214
  episode_reward_min: 131.02020202020205
  episodes_this_iter: 237
  episodes_total: 948
  experiment_id: 84f55d03837049678ee3f548fd31feed
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 0.00010000000000000002
        entropy: 1.1246707757314047
        entropy_coeff: 0.00010000000000000002
        kl: 0.012073339087267716
        model: {}
        policy_loss: -0.027101184924443564
        total_loss: -0.024798984949787457
        vf_explained_var: 0.0042299311608076096
        vf_loss: 0.0
    num_steps_sampled: 842831
    num_steps_trained: 842831
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.19428571428571
    gpu_util_percent0: 0.28
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.882857142857143
    vram_util_percent0: 0.0879796654640866
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 21893
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1594245792140959
    mean_env_wait_ms: 1.1635538804000238
    mean_inference_ms: 5.137971799065908
    mean_raw_obs_processing_ms: 0.40978856844149203
  time_since_restore: 130.50831294059753
  time_this_iter_s: 29.41356348991394
  time_total_s: 130.50831294059753
  timers:
    learn_throughput: 9324.53
    learn_time_ms: 22597.143
    sample_throughput: 21248.889
    sample_time_ms: 9916.177
    update_time_ms: 52.503
  timestamp: 1602416813
  timesteps_since_restore: 0
  timesteps_total: 842831
  training_iteration: 4
  trial_id: 22e7e_00000
  
== Status ==
Memory usage on this node: 28.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |      4 |          130.508 | 842831 |  220.099 |              272.384 |               131.02 |            889.062 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_22e7e_00000:
  custom_metrics:
    time_step_max: 4191
    time_step_mean: 3600.3318928262747
    time_step_min: 3275
  date: 2020-10-11_11-47-27
  done: false
  episode_len_mean: 887.8329113924051
  episode_reward_max: 274.65656565656576
  episode_reward_mean: 220.93338447768807
  episode_reward_min: 129.5050505050504
  episodes_this_iter: 237
  episodes_total: 1185
  experiment_id: 84f55d03837049678ee3f548fd31feed
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 0.00010000000000000002
        entropy: 1.1125795602798463
        entropy_coeff: 0.00010000000000000002
        kl: 0.011277629248797893
        model: {}
        policy_loss: -0.02982374553879102
        total_loss: -0.027679476700723172
        vf_explained_var: 0.004315233323723078
        vf_loss: 0.0
    num_steps_sampled: 1052082
    num_steps_trained: 1052082
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.494871794871795
    gpu_util_percent0: 0.26461538461538464
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.86923076923077
    vram_util_percent0: 0.08797966546408661
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 21893
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15798279899678966
    mean_env_wait_ms: 1.161820158517753
    mean_inference_ms: 5.045335862584878
    mean_raw_obs_processing_ms: 0.4053292285015951
  time_since_restore: 164.11815762519836
  time_this_iter_s: 33.60984468460083
  time_total_s: 164.11815762519836
  timers:
    learn_throughput: 9337.496
    learn_time_ms: 22534.565
    sample_throughput: 20668.109
    sample_time_ms: 10180.728
    update_time_ms: 47.822
  timestamp: 1602416847
  timesteps_since_restore: 0
  timesteps_total: 1052082
  training_iteration: 5
  trial_id: 22e7e_00000
  
== Status ==
Memory usage on this node: 28.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |      5 |          164.118 | 1052082 |  220.933 |              274.657 |              129.505 |            887.833 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_22e7e_00000:
  custom_metrics:
    time_step_max: 4191
    time_step_mean: 3593.0911047345767
    time_step_min: 3275
  date: 2020-10-11_11-47-56
  done: false
  episode_len_mean: 886.5386779184248
  episode_reward_max: 274.65656565656576
  episode_reward_mean: 221.70511017346442
  episode_reward_min: 129.5050505050504
  episodes_this_iter: 237
  episodes_total: 1422
  experiment_id: 84f55d03837049678ee3f548fd31feed
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 0.00010000000000000002
        entropy: 1.1075134913126627
        entropy_coeff: 0.00010000000000000002
        kl: 0.012626525262991588
        model: {}
        policy_loss: -0.029389831672112145
        total_loss: -0.02697527843217055
        vf_explained_var: 0.0045168716460466385
        vf_loss: 0.0
    num_steps_sampled: 1260658
    num_steps_trained: 1260658
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.840000000000003
    gpu_util_percent0: 0.29114285714285715
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8885714285714292
    vram_util_percent0: 0.0879796654640866
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 21893
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15687991735644435
    mean_env_wait_ms: 1.1606285217815193
    mean_inference_ms: 4.975068831532567
    mean_raw_obs_processing_ms: 0.40238811926569734
  time_since_restore: 193.20886325836182
  time_this_iter_s: 29.090705633163452
  time_total_s: 193.20886325836182
  timers:
    learn_throughput: 9324.379
    learn_time_ms: 22533.369
    sample_throughput: 21975.909
    sample_time_ms: 9560.909
    update_time_ms: 46.818
  timestamp: 1602416876
  timesteps_since_restore: 0
  timesteps_total: 1260658
  training_iteration: 6
  trial_id: 22e7e_00000
  
== Status ==
Memory usage on this node: 28.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |      6 |          193.209 | 1260658 |  221.705 |              274.657 |              129.505 |            886.539 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_22e7e_00000:
  custom_metrics:
    time_step_max: 4191
    time_step_mean: 3591.814837522992
    time_step_min: 3247
  date: 2020-10-11_11-48-30
  done: false
  episode_len_mean: 885.746835443038
  episode_reward_max: 274.65656565656576
  episode_reward_mean: 222.2184411931245
  episode_reward_min: 129.5050505050504
  episodes_this_iter: 237
  episodes_total: 1659
  experiment_id: 84f55d03837049678ee3f548fd31feed
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 0.00010000000000000002
        entropy: 1.0938406944274903
        entropy_coeff: 0.00010000000000000002
        kl: 0.011840906552970409
        model: {}
        policy_loss: -0.032349477522075176
        total_loss: -0.030090681153039138
        vf_explained_var: 0.004780403804033995
        vf_loss: 0.0
    num_steps_sampled: 1469454
    num_steps_trained: 1469454
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.6325
    gpu_util_percent0: 0.24625
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.88
    vram_util_percent0: 0.08797966546408659
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 21893
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15593363019005474
    mean_env_wait_ms: 1.159485525524178
    mean_inference_ms: 4.915902748379981
    mean_raw_obs_processing_ms: 0.3994958671193922
  time_since_restore: 227.4704246520996
  time_this_iter_s: 34.26156139373779
  time_total_s: 227.4704246520996
  timers:
    learn_throughput: 9297.743
    learn_time_ms: 22577.737
    sample_throughput: 21395.999
    sample_time_ms: 9811.274
    update_time_ms: 46.483
  timestamp: 1602416910
  timesteps_since_restore: 0
  timesteps_total: 1469454
  training_iteration: 7
  trial_id: 22e7e_00000
  
== Status ==
Memory usage on this node: 28.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |      7 |           227.47 | 1469454 |  222.218 |              274.657 |              129.505 |            885.747 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_22e7e_00000:
  custom_metrics:
    time_step_max: 4191
    time_step_mean: 3588.4202355460384
    time_step_min: 3247
  date: 2020-10-11_11-48-59
  done: false
  episode_len_mean: 884.915611814346
  episode_reward_max: 274.65656565656576
  episode_reward_mean: 222.8558048842857
  episode_reward_min: 129.5050505050504
  episodes_this_iter: 237
  episodes_total: 1896
  experiment_id: 84f55d03837049678ee3f548fd31feed
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 0.00010000000000000002
        entropy: 1.0879791339238485
        entropy_coeff: 0.00010000000000000002
        kl: 0.013443161174654961
        model: {}
        policy_loss: -0.032103987659017244
        total_loss: -0.029524152725934984
        vf_explained_var: 0.004608952905982733
        vf_loss: 0.0
    num_steps_sampled: 1677800
    num_steps_trained: 1677800
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.242424242424242
    gpu_util_percent0: 0.2706060606060606
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.884848484848485
    vram_util_percent0: 0.08797966546408659
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 21893
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15516089886252904
    mean_env_wait_ms: 1.1585878747820224
    mean_inference_ms: 4.867907119534596
    mean_raw_obs_processing_ms: 0.39737886686803015
  time_since_restore: 255.9719376564026
  time_this_iter_s: 28.50151300430298
  time_total_s: 255.9719376564026
  timers:
    learn_throughput: 9322.664
    learn_time_ms: 22496.253
    sample_throughput: 22327.089
    sample_time_ms: 9393.298
    update_time_ms: 45.451
  timestamp: 1602416939
  timesteps_since_restore: 0
  timesteps_total: 1677800
  training_iteration: 8
  trial_id: 22e7e_00000
  
== Status ==
Memory usage on this node: 28.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |      8 |          255.972 | 1677800 |  222.856 |              274.657 |              129.505 |            884.916 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_22e7e_00000:
  custom_metrics:
    time_step_max: 4191
    time_step_mean: 3586.915914489311
    time_step_min: 3247
  date: 2020-10-11_11-49-32
  done: false
  episode_len_mean: 884.29676511955
  episode_reward_max: 274.65656565656576
  episode_reward_mean: 222.9680205713959
  episode_reward_min: 129.5050505050504
  episodes_this_iter: 237
  episodes_total: 2133
  experiment_id: 84f55d03837049678ee3f548fd31feed
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 0.00010000000000000002
        entropy: 1.0769737402598063
        entropy_coeff: 0.00010000000000000002
        kl: 0.01233778204768896
        model: {}
        policy_loss: -0.03488614509503047
        total_loss: -0.0325262863188982
        vf_explained_var: 0.00442349910736084
        vf_loss: 0.0
    num_steps_sampled: 1886205
    num_steps_trained: 1886205
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.876923076923084
    gpu_util_percent0: 0.22282051282051277
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.882051282051283
    vram_util_percent0: 0.08797966546408661
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 21893
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1544875213558879
    mean_env_wait_ms: 1.1577098829011632
    mean_inference_ms: 4.8263615190470395
    mean_raw_obs_processing_ms: 0.3953101185725302
  time_since_restore: 289.6378767490387
  time_this_iter_s: 33.66593909263611
  time_total_s: 289.6378767490387
  timers:
    learn_throughput: 9319.587
    learn_time_ms: 22487.942
    sample_throughput: 21862.84
    sample_time_ms: 9586.053
    update_time_ms: 44.77
  timestamp: 1602416972
  timesteps_since_restore: 0
  timesteps_total: 1886205
  training_iteration: 9
  trial_id: 22e7e_00000
  
== Status ==
Memory usage on this node: 28.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |      9 |          289.638 | 1886205 |  222.968 |              274.657 |              129.505 |            884.297 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_22e7e_00000:
  custom_metrics:
    time_step_max: 4191
    time_step_mean: 3585.0764304013665
    time_step_min: 3247
  date: 2020-10-11_11-50-02
  done: false
  episode_len_mean: 884.3721518987342
  episode_reward_max: 274.65656565656576
  episode_reward_mean: 222.96387929932214
  episode_reward_min: 129.5050505050504
  episodes_this_iter: 237
  episodes_total: 2370
  experiment_id: 84f55d03837049678ee3f548fd31feed
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 0.00010000000000000002
        entropy: 1.0696190357208253
        entropy_coeff: 0.00010000000000000002
        kl: 0.013751295581459998
        model: {}
        policy_loss: -0.03426021374762058
        total_loss: -0.031616917625069615
        vf_explained_var: 0.00452190637588501
        vf_loss: 0.0
    num_steps_sampled: 2095962
    num_steps_trained: 2095962
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.197142857142858
    gpu_util_percent0: 0.29114285714285715
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8885714285714292
    vram_util_percent0: 0.0879796654640866
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 21893
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15392038983954964
    mean_env_wait_ms: 1.1569633633981062
    mean_inference_ms: 4.791379278619612
    mean_raw_obs_processing_ms: 0.3937311631719402
  time_since_restore: 318.9559681415558
  time_this_iter_s: 29.31809139251709
  time_total_s: 318.9559681415558
  timers:
    learn_throughput: 9323.01
    learn_time_ms: 22481.602
    sample_throughput: 22522.558
    sample_time_ms: 9306.056
    update_time_ms: 44.808
  timestamp: 1602417002
  timesteps_since_restore: 0
  timesteps_total: 2095962
  training_iteration: 10
  trial_id: 22e7e_00000
  
== Status ==
Memory usage on this node: 28.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |     10 |          318.956 | 2095962 |  222.964 |              274.657 |              129.505 |            884.372 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_22e7e_00000:
  custom_metrics:
    time_step_max: 4241
    time_step_mean: 3585.993796044979
    time_step_min: 3247
  date: 2020-10-11_11-50-35
  done: false
  episode_len_mean: 884.6283084004604
  episode_reward_max: 274.65656565656576
  episode_reward_mean: 222.9485766758492
  episode_reward_min: 123.44444444444436
  episodes_this_iter: 237
  episodes_total: 2607
  experiment_id: 84f55d03837049678ee3f548fd31feed
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 0.00010000000000000002
        entropy: 1.057764212290446
        entropy_coeff: 0.00010000000000000002
        kl: 0.01220239649216334
        model: {}
        policy_loss: -0.03655547251303991
        total_loss: -0.03422076975305875
        vf_explained_var: 0.004498771857470274
        vf_loss: 0.0
    num_steps_sampled: 2306226
    num_steps_trained: 2306226
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.079487179487177
    gpu_util_percent0: 0.2520512820512821
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8769230769230782
    vram_util_percent0: 0.08797966546408661
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 21893
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15341774730576713
    mean_env_wait_ms: 1.1562202430781439
    mean_inference_ms: 4.760572667303618
    mean_raw_obs_processing_ms: 0.39219741805542485
  time_since_restore: 352.508731842041
  time_this_iter_s: 33.55276370048523
  time_total_s: 352.508731842041
  timers:
    learn_throughput: 9336.916
    learn_time_ms: 22442.561
    sample_throughput: 23337.157
    sample_time_ms: 8978.999
    update_time_ms: 43.492
  timestamp: 1602417035
  timesteps_since_restore: 0
  timesteps_total: 2306226
  training_iteration: 11
  trial_id: 22e7e_00000
  
== Status ==
Memory usage on this node: 28.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |     11 |          352.509 | 2306226 |  222.949 |              274.657 |              123.444 |            884.628 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_22e7e_00000:
  custom_metrics:
    time_step_max: 4241
    time_step_mean: 3585.416903409091
    time_step_min: 3247
  date: 2020-10-11_11-51-05
  done: false
  episode_len_mean: 884.5847398030942
  episode_reward_max: 274.65656565656576
  episode_reward_mean: 222.99155052636047
  episode_reward_min: 123.44444444444436
  episodes_this_iter: 237
  episodes_total: 2844
  experiment_id: 84f55d03837049678ee3f548fd31feed
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 0.00010000000000000002
        entropy: 1.0487373749415079
        entropy_coeff: 0.00010000000000000002
        kl: 0.013711805579562981
        model: {}
        policy_loss: -0.03558352831751108
        total_loss: -0.03294604104012251
        vf_explained_var: 0.004443577956408262
        vf_loss: 0.0
    num_steps_sampled: 2515759
    num_steps_trained: 2515759
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.88529411764706
    gpu_util_percent0: 0.27764705882352947
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8852941176470597
    vram_util_percent0: 0.0879796654640866
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 21893
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1529802643731159
    mean_env_wait_ms: 1.1555617141401107
    mean_inference_ms: 4.733817050752962
    mean_raw_obs_processing_ms: 0.39096315453997343
  time_since_restore: 381.7114312648773
  time_this_iter_s: 29.202699422836304
  time_total_s: 381.7114312648773
  timers:
    learn_throughput: 9356.622
    learn_time_ms: 22376.27
    sample_throughput: 23221.036
    sample_time_ms: 9016.234
    update_time_ms: 38.55
  timestamp: 1602417065
  timesteps_since_restore: 0
  timesteps_total: 2515759
  training_iteration: 12
  trial_id: 22e7e_00000
  
== Status ==
Memory usage on this node: 28.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |     12 |          381.711 | 2515759 |  222.992 |              274.657 |              123.444 |            884.585 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_22e7e_00000:
  custom_metrics:
    time_step_max: 4241
    time_step_mean: 3583.670160497871
    time_step_min: 3247
  date: 2020-10-11_11-51-38
  done: false
  episode_len_mean: 883.5699448231094
  episode_reward_max: 274.65656565656576
  episode_reward_mean: 223.30827259941165
  episode_reward_min: 123.44444444444436
  episodes_this_iter: 237
  episodes_total: 3081
  experiment_id: 84f55d03837049678ee3f548fd31feed
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 0.00010000000000000002
        entropy: 1.037754726409912
        entropy_coeff: 0.00010000000000000002
        kl: 0.012784661290546258
        model: {}
        policy_loss: -0.03867535578707854
        total_loss: -0.0362221988538901
        vf_explained_var: 0.004530946258455515
        vf_loss: 0.0
    num_steps_sampled: 2722279
    num_steps_trained: 2722279
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.40769230769231
    gpu_util_percent0: 0.23179487179487177
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8743589743589757
    vram_util_percent0: 0.08797966546408661
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 21893
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15258750220895162
    mean_env_wait_ms: 1.1550136761051824
    mean_inference_ms: 4.70990938387223
    mean_raw_obs_processing_ms: 0.3897614970753449
  time_since_restore: 415.17905950546265
  time_this_iter_s: 33.46762824058533
  time_total_s: 415.17905950546265
  timers:
    learn_throughput: 9342.752
    learn_time_ms: 22372.456
    sample_throughput: 23405.862
    sample_time_ms: 8930.254
    update_time_ms: 39.067
  timestamp: 1602417098
  timesteps_since_restore: 0
  timesteps_total: 2722279
  training_iteration: 13
  trial_id: 22e7e_00000
  
== Status ==
Memory usage on this node: 28.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |     13 |          415.179 | 2722279 |  223.308 |              274.657 |              123.444 |             883.57 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_22e7e_00000:
  custom_metrics:
    time_step_max: 4241
    time_step_mean: 3581.2051671732524
    time_step_min: 3247
  date: 2020-10-11_11-52-07
  done: false
  episode_len_mean: 882.2272453285111
  episode_reward_max: 274.65656565656576
  episode_reward_mean: 223.52833031946935
  episode_reward_min: 123.44444444444436
  episodes_this_iter: 237
  episodes_total: 3318
  experiment_id: 84f55d03837049678ee3f548fd31feed
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 0.00010000000000000002
        entropy: 1.031781538327535
        entropy_coeff: 0.00010000000000000002
        kl: 0.014422734640538693
        model: {}
        policy_loss: -0.038801763827602066
        total_loss: -0.03602039503554503
        vf_explained_var: 0.004225671291351318
        vf_loss: 0.0
    num_steps_sampled: 2927230
    num_steps_trained: 2927230
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.302941176470586
    gpu_util_percent0: 0.26676470588235296
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8911764705882357
    vram_util_percent0: 0.0879796654640866
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 21893
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15223626672918422
    mean_env_wait_ms: 1.1545856441162181
    mean_inference_ms: 4.688645556180501
    mean_raw_obs_processing_ms: 0.38876734649354316
  time_since_restore: 443.92309951782227
  time_this_iter_s: 28.74404001235962
  time_total_s: 443.92309951782227
  timers:
    learn_throughput: 9349.416
    learn_time_ms: 22294.429
    sample_throughput: 23308.931
    sample_time_ms: 8942.491
    update_time_ms: 37.278
  timestamp: 1602417127
  timesteps_since_restore: 0
  timesteps_total: 2927230
  training_iteration: 14
  trial_id: 22e7e_00000
  
== Status ==
Memory usage on this node: 28.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |     14 |          443.923 | 2927230 |  223.528 |              274.657 |              123.444 |            882.227 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_22e7e_00000:
  custom_metrics:
    time_step_max: 4241
    time_step_mean: 3579.850014176354
    time_step_min: 3247
  date: 2020-10-11_11-52-40
  done: false
  episode_len_mean: 881.0486638537271
  episode_reward_max: 274.65656565656576
  episode_reward_mean: 223.70937220304288
  episode_reward_min: 123.44444444444436
  episodes_this_iter: 237
  episodes_total: 3555
  experiment_id: 84f55d03837049678ee3f548fd31feed
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 0.00010000000000000002
        entropy: 1.0202627897262573
        entropy_coeff: 0.00010000000000000002
        kl: 0.01260025588174661
        model: {}
        policy_loss: -0.03989621177315712
        total_loss: -0.03747818768024445
        vf_explained_var: 0.0042155226692557335
        vf_loss: 0.0
    num_steps_sampled: 3132128
    num_steps_trained: 3132128
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.925641025641028
    gpu_util_percent0: 0.26538461538461544
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.874358974358975
    vram_util_percent0: 0.08797966546408661
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 21893
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15191691646680128
    mean_env_wait_ms: 1.1542151412118906
    mean_inference_ms: 4.669274829623884
    mean_raw_obs_processing_ms: 0.38778296009932195
  time_since_restore: 477.0645468235016
  time_this_iter_s: 33.14144730567932
  time_total_s: 477.0645468235016
  timers:
    learn_throughput: 9341.245
    learn_time_ms: 22267.332
    sample_throughput: 23333.802
    sample_time_ms: 8914.304
    update_time_ms: 38.076
  timestamp: 1602417160
  timesteps_since_restore: 0
  timesteps_total: 3132128
  training_iteration: 15
  trial_id: 22e7e_00000
  
== Status ==
Memory usage on this node: 28.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |     15 |          477.065 | 3132128 |  223.709 |              274.657 |              123.444 |            881.049 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_22e7e_00000:
  custom_metrics:
    time_step_max: 4241
    time_step_mean: 3577.9782146652497
    time_step_min: 3247
  date: 2020-10-11_11-53-09
  done: false
  episode_len_mean: 879.95305907173
  episode_reward_max: 274.65656565656576
  episode_reward_mean: 223.97786408387654
  episode_reward_min: 123.44444444444436
  episodes_this_iter: 237
  episodes_total: 3792
  experiment_id: 84f55d03837049678ee3f548fd31feed
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 0.00010000000000000002
        entropy: 1.0082921346028646
        entropy_coeff: 0.00010000000000000002
        kl: 0.014132832487424215
        model: {}
        policy_loss: -0.03908525543908278
        total_loss: -0.03635951802134514
        vf_explained_var: 0.0040289959870278835
        vf_loss: 0.0
    num_steps_sampled: 3336782
    num_steps_trained: 3336782
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.542424242424243
    gpu_util_percent0: 0.2412121212121212
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.881818181818182
    vram_util_percent0: 0.08797966546408659
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 21893
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15162673205272575
    mean_env_wait_ms: 1.1539161632482724
    mean_inference_ms: 4.651769602705972
    mean_raw_obs_processing_ms: 0.38694791347460933
  time_since_restore: 505.45633029937744
  time_this_iter_s: 28.391783475875854
  time_total_s: 505.45633029937744
  timers:
    learn_throughput: 9360.179
    learn_time_ms: 22180.389
    sample_throughput: 23253.448
    sample_time_ms: 8928.241
    update_time_ms: 37.841
  timestamp: 1602417189
  timesteps_since_restore: 0
  timesteps_total: 3336782
  training_iteration: 16
  trial_id: 22e7e_00000
  
== Status ==
Memory usage on this node: 28.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |     16 |          505.456 | 3336782 |  223.978 |              274.657 |              123.444 |            879.953 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_22e7e_00000:
  custom_metrics:
    time_step_max: 4241
    time_step_mean: 3575.7503124218947
    time_step_min: 3247
  date: 2020-10-11_11-53-42
  done: false
  episode_len_mean: 878.3544303797469
  episode_reward_max: 274.65656565656576
  episode_reward_mean: 224.32612047504063
  episode_reward_min: 123.44444444444436
  episodes_this_iter: 237
  episodes_total: 4029
  experiment_id: 84f55d03837049678ee3f548fd31feed
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 0.00010000000000000002
        entropy: 0.9905219038327535
        entropy_coeff: 0.00010000000000000002
        kl: 0.012447120373447735
        model: {}
        policy_loss: -0.040780336658159895
        total_loss: -0.03838996427754561
        vf_explained_var: 0.004459810443222523
        vf_loss: 0.0
    num_steps_sampled: 3538890
    num_steps_trained: 3538890
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.444736842105247
    gpu_util_percent0: 0.23631578947368423
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8815789473684217
    vram_util_percent0: 0.08854067770278436
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 21893
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15135937917121595
    mean_env_wait_ms: 1.153707712687943
    mean_inference_ms: 4.635683081493371
    mean_raw_obs_processing_ms: 0.3861319659741516
  time_since_restore: 537.8191299438477
  time_this_iter_s: 32.362799644470215
  time_total_s: 537.8191299438477
  timers:
    learn_throughput: 9389.236
    learn_time_ms: 22040.515
    sample_throughput: 23315.521
    sample_time_ms: 8875.787
    update_time_ms: 38.941
  timestamp: 1602417222
  timesteps_since_restore: 0
  timesteps_total: 3538890
  training_iteration: 17
  trial_id: 22e7e_00000
  
== Status ==
Memory usage on this node: 28.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |     17 |          537.819 | 3538890 |  224.326 |              274.657 |              123.444 |            878.354 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_22e7e_00000:
  custom_metrics:
    time_step_max: 4493
    time_step_mean: 3575.6833411986786
    time_step_min: 3226
  date: 2020-10-11_11-54-10
  done: false
  episode_len_mean: 877.0180496952648
  episode_reward_max: 277.23232323232315
  episode_reward_mean: 224.28740286124236
  episode_reward_min: 85.26262626262591
  episodes_this_iter: 237
  episodes_total: 4266
  experiment_id: 84f55d03837049678ee3f548fd31feed
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 0.00010000000000000002
        entropy: 0.9774724404017131
        entropy_coeff: 0.00010000000000000002
        kl: 0.014146901729206244
        model: {}
        policy_loss: -0.03988467852274577
        total_loss: -0.03715304508805275
        vf_explained_var: 0.004186526872217655
        vf_loss: 0.0
    num_steps_sampled: 3741359
    num_steps_trained: 3741359
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.02727272727273
    gpu_util_percent0: 0.29666666666666663
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.881818181818182
    vram_util_percent0: 0.08879960642833716
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 21893
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1511129665760311
    mean_env_wait_ms: 1.1535582536116709
    mean_inference_ms: 4.6209747339090015
    mean_raw_obs_processing_ms: 0.3854260879618885
  time_since_restore: 566.2206976413727
  time_this_iter_s: 28.401567697525024
  time_total_s: 566.2206976413727
  timers:
    learn_throughput: 9379.571
    learn_time_ms: 22000.569
    sample_throughput: 23171.728
    sample_time_ms: 8905.503
    update_time_ms: 39.081
  timestamp: 1602417250
  timesteps_since_restore: 0
  timesteps_total: 3741359
  training_iteration: 18
  trial_id: 22e7e_00000
  
== Status ==
Memory usage on this node: 28.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |     18 |          566.221 | 3741359 |  224.287 |              277.232 |              85.2626 |            877.018 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_22e7e_00000:
  custom_metrics:
    time_step_max: 4493
    time_step_mean: 3576.516648044693
    time_step_min: 3226
  date: 2020-10-11_11-54-43
  done: false
  episode_len_mean: 875.4774594714635
  episode_reward_max: 277.23232323232315
  episode_reward_mean: 224.30696707245656
  episode_reward_min: 85.26262626262591
  episodes_this_iter: 237
  episodes_total: 4503
  experiment_id: 84f55d03837049678ee3f548fd31feed
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 0.00010000000000000002
        entropy: 0.9596413969993591
        entropy_coeff: 0.00010000000000000002
        kl: 0.012607416386405628
        model: {}
        policy_loss: -0.041707259913285576
        total_loss: -0.039281741032997766
        vf_explained_var: 0.004265586379915476
        vf_loss: 0.0
    num_steps_sampled: 3942275
    num_steps_trained: 3942275
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.307894736842105
    gpu_util_percent0: 0.23526315789473687
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8789473684210534
    vram_util_percent0: 0.08879960642833716
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 21893
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15088223990719662
    mean_env_wait_ms: 1.1534698963592904
    mean_inference_ms: 4.607334057130936
    mean_raw_obs_processing_ms: 0.3847355330367429
  time_since_restore: 598.7950792312622
  time_this_iter_s: 32.574381589889526
  time_total_s: 598.7950792312622
  timers:
    learn_throughput: 9372.684
    learn_time_ms: 21936.833
    sample_throughput: 23204.865
    sample_time_ms: 8860.513
    update_time_ms: 39.379
  timestamp: 1602417283
  timesteps_since_restore: 0
  timesteps_total: 3942275
  training_iteration: 19
  trial_id: 22e7e_00000
  
== Status ==
Memory usage on this node: 28.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |     19 |          598.795 | 3942275 |  224.307 |              277.232 |              85.2626 |            875.477 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_22e7e_00000:
  custom_metrics:
    time_step_max: 4493
    time_step_mean: 3576.162351443124
    time_step_min: 3226
  date: 2020-10-11_11-55-11
  done: true
  episode_len_mean: 874.2567510548523
  episode_reward_max: 277.23232323232315
  episode_reward_mean: 224.31393044367707
  episode_reward_min: 85.26262626262591
  episodes_this_iter: 237
  episodes_total: 4740
  experiment_id: 84f55d03837049678ee3f548fd31feed
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 0.00010000000000000002
        entropy: 0.9481419285138448
        entropy_coeff: 0.00010000000000000002
        kl: 0.014482068829238415
        model: {}
        policy_loss: -0.039214026927947995
        total_loss: -0.03641242695351442
        vf_explained_var: 0.0043367864564061165
        vf_loss: 0.0
    num_steps_sampled: 4143977
    num_steps_trained: 4143977
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.25882352941177
    gpu_util_percent0: 0.28382352941176475
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.870588235294118
    vram_util_percent0: 0.08879960642833716
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 21893
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15066801098261368
    mean_env_wait_ms: 1.1534095476745612
    mean_inference_ms: 4.594729781957195
    mean_raw_obs_processing_ms: 0.38413356668145165
  time_since_restore: 626.9753849506378
  time_this_iter_s: 28.18030571937561
  time_total_s: 626.9753849506378
  timers:
    learn_throughput: 9385.705
    learn_time_ms: 21820.576
    sample_throughput: 23107.018
    sample_time_ms: 8863.173
    update_time_ms: 37.45
  timestamp: 1602417311
  timesteps_since_restore: 0
  timesteps_total: 4143977
  training_iteration: 20
  trial_id: 22e7e_00000
  
== Status ==
Memory usage on this node: 28.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_22e7e_00000 | TERMINATED |       |     20 |          626.975 | 4143977 |  224.314 |              277.232 |              85.2626 |            874.257 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_22e7e_00000 | TERMINATED |       |     20 |          626.975 | 4143977 |  224.314 |              277.232 |              85.2626 |            874.257 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


