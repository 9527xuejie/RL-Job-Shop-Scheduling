2020-10-11 11:55:26,506	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_a7863_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=44179)[0m 2020-10-11 11:55:29,202	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=44167)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44167)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44113)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44113)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44152)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44152)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44164)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44164)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44154)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44154)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44137)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44137)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44144)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44144)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44130)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44130)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44044)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44044)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44159)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44159)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44114)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44114)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44046)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44046)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44045)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44045)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44102)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44102)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44142)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44142)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44145)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44145)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44116)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44116)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44119)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44119)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44139)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44139)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44173)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44173)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44165)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44165)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44157)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44157)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44063)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44063)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44133)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44133)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44052)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44052)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44080)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44080)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44071)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44071)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44122)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44122)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44106)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44106)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44171)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44171)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44050)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44050)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44048)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44048)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44053)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44053)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44117)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44117)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44121)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44121)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44041)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44041)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44074)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44074)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44104)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44104)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44101)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44101)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44109)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44109)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44058)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44058)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44078)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44078)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44072)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44072)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44115)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44115)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44120)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44120)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44057)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44057)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44140)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44140)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44169)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44169)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44123)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44123)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44126)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44126)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44150)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44150)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44059)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44059)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44062)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44062)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44069)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44069)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44060)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44060)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44049)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44049)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44054)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44054)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44100)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44100)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44125)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44125)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44042)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44042)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44127)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44127)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44040)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44040)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44043)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44043)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44129)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44129)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44051)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44051)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44077)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44077)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44135)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44135)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44111)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44111)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44061)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44061)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44148)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44148)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44131)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44131)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44055)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44055)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44143)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44143)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44118)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44118)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44107)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44107)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44112)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44112)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44066)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44066)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44156)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44156)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44178)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44178)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_a7863_00000:
  custom_metrics:
    time_step_max: 4030
    time_step_mean: 3583.3056768558954
    time_step_min: 3263
  date: 2020-10-11_11-56-20
  done: false
  episode_len_mean: 888.3607594936709
  episode_reward_max: 278.74747474747426
  episode_reward_mean: 221.509269914333
  episode_reward_min: 128.4444444444439
  episodes_this_iter: 316
  episodes_total: 316
  experiment_id: 4edd8c230375465cb0cfd8b8cad86c2d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 1.1498889724413555
        entropy_coeff: 0.0001
        kl: 0.011335016034233073
        model: {}
        policy_loss: -0.023215793664955225
        total_loss: -0.02106377975724172
        vf_explained_var: 0.004248450044542551
        vf_loss: 0.0
    num_steps_sampled: 280722
    num_steps_trained: 280722
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.034545454545455
    gpu_util_percent0: 0.2714545454545455
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.6727272727272737
    vram_util_percent0: 0.06951161334565732
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 44179
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1850455764296597
    mean_env_wait_ms: 1.6345806157514586
    mean_inference_ms: 5.489245068106794
    mean_raw_obs_processing_ms: 0.5145279632159141
  time_since_restore: 46.30164980888367
  time_this_iter_s: 46.30164980888367
  time_total_s: 46.30164980888367
  timers:
    learn_throughput: 9169.182
    learn_time_ms: 30615.816
    sample_throughput: 17982.282
    sample_time_ms: 15611.033
    update_time_ms: 43.374
  timestamp: 1602417380
  timesteps_since_restore: 0
  timesteps_total: 280722
  training_iteration: 1
  trial_id: a7863_00000
  
== Status ==
Memory usage on this node: 29.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a7863_00000 | RUNNING  | 172.17.0.4:44179 |      1 |          46.3016 | 280722 |  221.509 |              278.747 |              128.444 |            888.361 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a7863_00000:
  custom_metrics:
    time_step_max: 4101
    time_step_mean: 3603.748623853211
    time_step_min: 3263
  date: 2020-10-11_11-56-58
  done: false
  episode_len_mean: 888.5395569620254
  episode_reward_max: 278.74747474747426
  episode_reward_mean: 219.77595576013275
  episode_reward_min: 128.4444444444439
  episodes_this_iter: 316
  episodes_total: 632
  experiment_id: 4edd8c230375465cb0cfd8b8cad86c2d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 1.1453350683053334
        entropy_coeff: 0.0001
        kl: 0.011886718644139668
        model: {}
        policy_loss: -0.022168729240850855
        total_loss: -0.01990591855913711
        vf_explained_var: 0.0040741912089288235
        vf_loss: 0.0
    num_steps_sampled: 561557
    num_steps_trained: 561557
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.58
    gpu_util_percent0: 0.2866666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.075555555555554
    vram_util_percent0: 0.08027222040013123
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 44179
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.18290251589096432
    mean_env_wait_ms: 1.6364947535024328
    mean_inference_ms: 5.2985479191377545
    mean_raw_obs_processing_ms: 0.5149596544375026
  time_since_restore: 83.94077706336975
  time_this_iter_s: 37.639127254486084
  time_total_s: 83.94077706336975
  timers:
    learn_throughput: 9208.084
    learn_time_ms: 30492.609
    sample_throughput: 24737.194
    sample_time_ms: 11350.459
    update_time_ms: 69.95
  timestamp: 1602417418
  timesteps_since_restore: 0
  timesteps_total: 561557
  training_iteration: 2
  trial_id: a7863_00000
  
== Status ==
Memory usage on this node: 30.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a7863_00000 | RUNNING  | 172.17.0.4:44179 |      2 |          83.9408 | 561557 |  219.776 |              278.747 |              128.444 |             888.54 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a7863_00000:
  custom_metrics:
    time_step_max: 4101
    time_step_mean: 3606.842044134727
    time_step_min: 3263
  date: 2020-10-11_11-57-36
  done: false
  episode_len_mean: 886.9483122362869
  episode_reward_max: 278.74747474747426
  episode_reward_mean: 219.88895281933233
  episode_reward_min: 128.4444444444439
  episodes_this_iter: 316
  episodes_total: 948
  experiment_id: 4edd8c230375465cb0cfd8b8cad86c2d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 1.137641355395317
        entropy_coeff: 0.0001
        kl: 0.011534631601534784
        model: {}
        policy_loss: -0.024592714238679036
        total_loss: -0.02239955239807993
        vf_explained_var: 0.004056716803461313
        vf_loss: 0.0
    num_steps_sampled: 840827
    num_steps_trained: 840827
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.897727272727273
    gpu_util_percent0: 0.28818181818181815
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.093181818181818
    vram_util_percent0: 0.08027222040013121
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 44179
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.18135088547015082
    mean_env_wait_ms: 1.6367931106358595
    mean_inference_ms: 5.164214978272677
    mean_raw_obs_processing_ms: 0.5141169991422323
  time_since_restore: 121.53825998306274
  time_this_iter_s: 37.59748291969299
  time_total_s: 121.53825998306274
  timers:
    learn_throughput: 9189.836
    learn_time_ms: 30498.44
    sample_throughput: 28315.706
    sample_time_ms: 9898.24
    update_time_ms: 52.945
  timestamp: 1602417456
  timesteps_since_restore: 0
  timesteps_total: 840827
  training_iteration: 3
  trial_id: a7863_00000
  
== Status ==
Memory usage on this node: 30.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a7863_00000 | RUNNING  | 172.17.0.4:44179 |      3 |          121.538 | 840827 |  219.889 |              278.747 |              128.444 |            886.948 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a7863_00000:
  custom_metrics:
    time_step_max: 4160
    time_step_mean: 3601.833474936279
    time_step_min: 3263
  date: 2020-10-11_11-58-19
  done: false
  episode_len_mean: 887.1408227848101
  episode_reward_max: 278.74747474747426
  episode_reward_mean: 220.29247378851787
  episode_reward_min: 124.80808080808065
  episodes_this_iter: 316
  episodes_total: 1264
  experiment_id: 4edd8c230375465cb0cfd8b8cad86c2d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 1.1203653862078984
        entropy_coeff: 0.0001
        kl: 0.010973249096423388
        model: {}
        policy_loss: -0.03036655376975735
        total_loss: -0.028283940434145432
        vf_explained_var: 0.004029279109090567
        vf_loss: 0.0
    num_steps_sampled: 1121346
    num_steps_trained: 1121346
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.041176470588233
    gpu_util_percent0: 0.23823529411764702
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.099999999999999
    vram_util_percent0: 0.0802722204001312
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 44179
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17996506470235132
    mean_env_wait_ms: 1.635602059522103
    mean_inference_ms: 5.047362666044733
    mean_raw_obs_processing_ms: 0.5090124430096958
  time_since_restore: 164.9662103652954
  time_this_iter_s: 43.427950382232666
  time_total_s: 164.9662103652954
  timers:
    learn_throughput: 9170.835
    learn_time_ms: 30568.262
    sample_throughput: 26541.764
    sample_time_ms: 10562.09
    update_time_ms: 46.098
  timestamp: 1602417499
  timesteps_since_restore: 0
  timesteps_total: 1121346
  training_iteration: 4
  trial_id: a7863_00000
  
== Status ==
Memory usage on this node: 30.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a7863_00000 | RUNNING  | 172.17.0.4:44179 |      4 |          164.966 | 1121346 |  220.292 |              278.747 |              124.808 |            887.141 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a7863_00000:
  custom_metrics:
    time_step_max: 4160
    time_step_mean: 3602.5679839249833
    time_step_min: 3263
  date: 2020-10-11_11-58-57
  done: false
  episode_len_mean: 886.823417721519
  episode_reward_max: 278.74747474747426
  episode_reward_mean: 220.4628564122233
  episode_reward_min: 124.80808080808065
  episodes_this_iter: 316
  episodes_total: 1580
  experiment_id: 4edd8c230375465cb0cfd8b8cad86c2d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 1.1207567701737087
        entropy_coeff: 0.0001
        kl: 0.012464039997818569
        model: {}
        policy_loss: -0.028533178808478016
        total_loss: -0.026152446788425248
        vf_explained_var: 0.0040006861090660095
        vf_loss: 0.0
    num_steps_sampled: 1401181
    num_steps_trained: 1401181
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.902272727272727
    gpu_util_percent0: 0.30113636363636365
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.111363636363635
    vram_util_percent0: 0.08027222040013121
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 44179
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17896383302840074
    mean_env_wait_ms: 1.6350190478699875
    mean_inference_ms: 4.964221066545625
    mean_raw_obs_processing_ms: 0.5061447750001521
  time_since_restore: 202.75674152374268
  time_this_iter_s: 37.790531158447266
  time_total_s: 202.75674152374268
  timers:
    learn_throughput: 9167.956
    learn_time_ms: 30566.922
    sample_throughput: 28416.145
    sample_time_ms: 9861.866
    update_time_ms: 45.846
  timestamp: 1602417537
  timesteps_since_restore: 0
  timesteps_total: 1401181
  training_iteration: 5
  trial_id: a7863_00000
  
== Status ==
Memory usage on this node: 30.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a7863_00000 | RUNNING  | 172.17.0.4:44179 |      5 |          202.757 | 1401181 |  220.463 |              278.747 |              124.808 |            886.823 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a7863_00000:
  custom_metrics:
    time_step_max: 4160
    time_step_mean: 3601.0978441127695
    time_step_min: 3263
  date: 2020-10-11_11-59-35
  done: false
  episode_len_mean: 886.2916666666666
  episode_reward_max: 278.74747474747426
  episode_reward_mean: 220.40846758726482
  episode_reward_min: 124.80808080808048
  episodes_this_iter: 316
  episodes_total: 1896
  experiment_id: 4edd8c230375465cb0cfd8b8cad86c2d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 1.1137165029843648
        entropy_coeff: 0.0001
        kl: 0.012430400781643888
        model: {}
        policy_loss: -0.02917195561652382
        total_loss: -0.0267972470416377
        vf_explained_var: 0.0038985435385257006
        vf_loss: 0.0
    num_steps_sampled: 1680409
    num_steps_trained: 1680409
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.397826086956524
    gpu_util_percent0: 0.3254347826086956
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.097826086956521
    vram_util_percent0: 0.08027222040013123
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 44179
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17819279339593588
    mean_env_wait_ms: 1.6347406486892524
    mean_inference_ms: 4.9006176255791685
    mean_raw_obs_processing_ms: 0.5043547185293912
  time_since_restore: 240.989196062088
  time_this_iter_s: 38.23245453834534
  time_total_s: 240.989196062088
  timers:
    learn_throughput: 9142.204
    learn_time_ms: 30634.646
    sample_throughput: 29764.438
    sample_time_ms: 9409.49
    update_time_ms: 44.075
  timestamp: 1602417575
  timesteps_since_restore: 0
  timesteps_total: 1680409
  training_iteration: 6
  trial_id: a7863_00000
  
== Status ==
Memory usage on this node: 30.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a7863_00000 | RUNNING  | 172.17.0.4:44179 |      6 |          240.989 | 1680409 |  220.408 |              278.747 |              124.808 |            886.292 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a7863_00000:
  custom_metrics:
    time_step_max: 4160
    time_step_mean: 3597.1651764705884
    time_step_min: 3263
  date: 2020-10-11_12-00-18
  done: false
  episode_len_mean: 885.2793851717902
  episode_reward_max: 278.74747474747426
  episode_reward_mean: 220.5339424991322
  episode_reward_min: 113.74747474747444
  episodes_this_iter: 316
  episodes_total: 2212
  experiment_id: 4edd8c230375465cb0cfd8b8cad86c2d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 9.999999999999998e-05
        entropy: 1.1002877328706824
        entropy_coeff: 9.999999999999998e-05
        kl: 0.011325264592533526
        model: {}
        policy_loss: -0.0335009365706988
        total_loss: -0.031345912822238774
        vf_explained_var: 0.004416672978550196
        vf_loss: 0.0
    num_steps_sampled: 1958238
    num_steps_trained: 1958238
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.717999999999996
    gpu_util_percent0: 0.2668
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.1
    vram_util_percent0: 0.0802722204001312
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 44179
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17755901687885098
    mean_env_wait_ms: 1.6345007099975517
    mean_inference_ms: 4.846980159516488
    mean_raw_obs_processing_ms: 0.501987014030854
  time_since_restore: 283.8285620212555
  time_this_iter_s: 42.83936595916748
  time_total_s: 283.8285620212555
  timers:
    learn_throughput: 9143.769
    learn_time_ms: 30594.416
    sample_throughput: 28443.563
    sample_time_ms: 9835.206
    update_time_ms: 40.913
  timestamp: 1602417618
  timesteps_since_restore: 0
  timesteps_total: 1958238
  training_iteration: 7
  trial_id: a7863_00000
  
== Status ==
Memory usage on this node: 30.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a7863_00000 | RUNNING  | 172.17.0.4:44179 |      7 |          283.829 | 1958238 |  220.534 |              278.747 |              113.747 |            885.279 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a7863_00000:
  custom_metrics:
    time_step_max: 4160
    time_step_mean: 3598.7140516181894
    time_step_min: 3263
  date: 2020-10-11_12-00-56
  done: false
  episode_len_mean: 884.4426424050633
  episode_reward_max: 278.74747474747426
  episode_reward_mean: 220.35858186293294
  episode_reward_min: 113.74747474747444
  episodes_this_iter: 316
  episodes_total: 2528
  experiment_id: 4edd8c230375465cb0cfd8b8cad86c2d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 9.999999999999998e-05
        entropy: 1.096877756326095
        entropy_coeff: 9.999999999999998e-05
        kl: 0.013676803640049437
        model: {}
        policy_loss: -0.03535164293387662
        total_loss: -0.03272597078719865
        vf_explained_var: 0.004257147666066885
        vf_loss: 0.0
    num_steps_sampled: 2235871
    num_steps_trained: 2235871
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.831818181818182
    gpu_util_percent0: 0.32431818181818184
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.104545454545454
    vram_util_percent0: 0.08027222040013121
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 44179
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17704713608540304
    mean_env_wait_ms: 1.6344888227484144
    mean_inference_ms: 4.803596154650865
    mean_raw_obs_processing_ms: 0.5003498748897143
  time_since_restore: 321.2174234390259
  time_this_iter_s: 37.388861417770386
  time_total_s: 321.2174234390259
  timers:
    learn_throughput: 9157.908
    learn_time_ms: 30518.312
    sample_throughput: 29360.764
    sample_time_ms: 9518.958
    update_time_ms: 38.595
  timestamp: 1602417656
  timesteps_since_restore: 0
  timesteps_total: 2235871
  training_iteration: 8
  trial_id: a7863_00000
  
== Status ==
Memory usage on this node: 30.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a7863_00000 | RUNNING  | 172.17.0.4:44179 |      8 |          321.217 | 2235871 |  220.359 |              278.747 |              113.747 |            884.443 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a7863_00000:
  custom_metrics:
    time_step_max: 4160
    time_step_mean: 3597.656510700036
    time_step_min: 3263
  date: 2020-10-11_12-01-33
  done: false
  episode_len_mean: 883.0225035161744
  episode_reward_max: 278.74747474747426
  episode_reward_mean: 220.68462046626584
  episode_reward_min: 113.74747474747444
  episodes_this_iter: 316
  episodes_total: 2844
  experiment_id: 4edd8c230375465cb0cfd8b8cad86c2d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 9.999999999999998e-05
        entropy: 1.0881383056225984
        entropy_coeff: 9.999999999999998e-05
        kl: 0.013585189438384512
        model: {}
        policy_loss: -0.03852763828700003
        total_loss: -0.035919415238110916
        vf_explained_var: 0.004540689755231142
        vf_loss: 0.0
    num_steps_sampled: 2511316
    num_steps_trained: 2511316
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.75227272727273
    gpu_util_percent0: 0.2977272727272728
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.106818181818181
    vram_util_percent0: 0.08027222040013121
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 44179
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1766138932899392
    mean_env_wait_ms: 1.634674117929501
    mean_inference_ms: 4.76731635971916
    mean_raw_obs_processing_ms: 0.49918007428137373
  time_since_restore: 358.6906907558441
  time_this_iter_s: 37.47326731681824
  time_total_s: 358.6906907558441
  timers:
    learn_throughput: 9150.076
    learn_time_ms: 30495.388
    sample_throughput: 30182.062
    sample_time_ms: 9245.064
    update_time_ms: 37.106
  timestamp: 1602417693
  timesteps_since_restore: 0
  timesteps_total: 2511316
  training_iteration: 9
  trial_id: a7863_00000
  
== Status ==
Memory usage on this node: 30.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a7863_00000 | RUNNING  | 172.17.0.4:44179 |      9 |          358.691 | 2511316 |  220.685 |              278.747 |              113.747 |            883.023 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a7863_00000:
  custom_metrics:
    time_step_max: 4215
    time_step_mean: 3595.9176700292874
    time_step_min: 3255
  date: 2020-10-11_12-02-16
  done: false
  episode_len_mean: 881.9107594936709
  episode_reward_max: 278.74747474747426
  episode_reward_mean: 221.00126262626245
  episode_reward_min: 113.74747474747444
  episodes_this_iter: 316
  episodes_total: 3160
  experiment_id: 4edd8c230375465cb0cfd8b8cad86c2d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 9.999999999999998e-05
        entropy: 1.0710049815799878
        entropy_coeff: 9.999999999999998e-05
        kl: 0.012879531061195808
        model: {}
        policy_loss: -0.04008249347300633
        total_loss: -0.037613687874830284
        vf_explained_var: 0.004218658898025751
        vf_loss: 0.0
    num_steps_sampled: 2786838
    num_steps_trained: 2786838
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.368
    gpu_util_percent0: 0.269
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.155999999999999
    vram_util_percent0: 0.0802722204001312
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 44179
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17623708404107602
    mean_env_wait_ms: 1.6348585510257612
    mean_inference_ms: 4.735462499354929
    mean_raw_obs_processing_ms: 0.497773293456692
  time_since_restore: 401.416556596756
  time_this_iter_s: 42.725865840911865
  time_total_s: 401.416556596756
  timers:
    learn_throughput: 9134.744
    learn_time_ms: 30508.114
    sample_throughput: 29272.763
    sample_time_ms: 9520.242
    update_time_ms: 35.492
  timestamp: 1602417736
  timesteps_since_restore: 0
  timesteps_total: 2786838
  training_iteration: 10
  trial_id: a7863_00000
  
== Status ==
Memory usage on this node: 30.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a7863_00000 | RUNNING  | 172.17.0.4:44179 |     10 |          401.417 | 2786838 |  221.001 |              278.747 |              113.747 |            881.911 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a7863_00000:
  custom_metrics:
    time_step_max: 4277
    time_step_mean: 3597.9442313366776
    time_step_min: 3255
  date: 2020-10-11_12-02-54
  done: false
  episode_len_mean: 881.8322784810126
  episode_reward_max: 278.74747474747426
  episode_reward_mean: 221.01004579744492
  episode_reward_min: 113.74747474747444
  episodes_this_iter: 316
  episodes_total: 3476
  experiment_id: 4edd8c230375465cb0cfd8b8cad86c2d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 9.999999999999998e-05
        entropy: 1.0614151177198992
        entropy_coeff: 9.999999999999998e-05
        kl: 0.014598483422204205
        model: {}
        policy_loss: -0.03986798469787058
        total_loss: -0.037054427939912545
        vf_explained_var: 0.00464921398088336
        vf_loss: 0.0
    num_steps_sampled: 3065249
    num_steps_trained: 3065249
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.67954545454546
    gpu_util_percent0: 0.2990909090909091
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.118181818181816
    vram_util_percent0: 0.08027222040013121
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 44179
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1759128481241497
    mean_env_wait_ms: 1.6349725954603482
    mean_inference_ms: 4.708035359948134
    mean_raw_obs_processing_ms: 0.49670862692783685
  time_since_restore: 438.9541721343994
  time_this_iter_s: 37.53761553764343
  time_total_s: 438.9541721343994
  timers:
    learn_throughput: 9141.009
    learn_time_ms: 30461.921
    sample_throughput: 32056.087
    sample_time_ms: 8686.422
    update_time_ms: 33.186
  timestamp: 1602417774
  timesteps_since_restore: 0
  timesteps_total: 3065249
  training_iteration: 11
  trial_id: a7863_00000
  
== Status ==
Memory usage on this node: 30.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a7863_00000 | RUNNING  | 172.17.0.4:44179 |     11 |          438.954 | 3065249 |   221.01 |              278.747 |              113.747 |            881.832 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a7863_00000:
  custom_metrics:
    time_step_max: 4277
    time_step_mean: 3598.570310391363
    time_step_min: 3255
  date: 2020-10-11_12-03-32
  done: false
  episode_len_mean: 881.9841772151899
  episode_reward_max: 280.7171717171717
  episode_reward_mean: 220.9960682777137
  episode_reward_min: 113.74747474747444
  episodes_this_iter: 316
  episodes_total: 3792
  experiment_id: 4edd8c230375465cb0cfd8b8cad86c2d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 1.050734743475914
        entropy_coeff: 0.0001
        kl: 0.014976095058955252
        model: {}
        policy_loss: -0.03998108487576246
        total_loss: -0.037090940323347844
        vf_explained_var: 0.004644361790269613
        vf_loss: 0.0
    num_steps_sampled: 3344484
    num_steps_trained: 3344484
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.486666666666668
    gpu_util_percent0: 0.3002222222222223
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.1
    vram_util_percent0: 0.08027222040013123
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 44179
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17562744223374796
    mean_env_wait_ms: 1.6350209431082054
    mean_inference_ms: 4.684033724789287
    mean_raw_obs_processing_ms: 0.4958815130032957
  time_since_restore: 477.21140122413635
  time_this_iter_s: 38.25722908973694
  time_total_s: 477.21140122413635
  timers:
    learn_throughput: 9121.507
    learn_time_ms: 30509.51
    sample_throughput: 31961.597
    sample_time_ms: 8707.096
    update_time_ms: 26.986
  timestamp: 1602417812
  timesteps_since_restore: 0
  timesteps_total: 3344484
  training_iteration: 12
  trial_id: a7863_00000
  
== Status ==
Memory usage on this node: 30.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a7863_00000 | RUNNING  | 172.17.0.4:44179 |     12 |          477.211 | 3344484 |  220.996 |              280.717 |              113.747 |            881.984 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a7863_00000:
  custom_metrics:
    time_step_max: 4277
    time_step_mean: 3597.3193235513554
    time_step_min: 3255
  date: 2020-10-11_12-04-14
  done: false
  episode_len_mean: 881.5009737098345
  episode_reward_max: 280.7171717171717
  episode_reward_mean: 221.10606552378684
  episode_reward_min: 113.74747474747444
  episodes_this_iter: 316
  episodes_total: 4108
  experiment_id: 4edd8c230375465cb0cfd8b8cad86c2d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 9.999999999999998e-05
        entropy: 1.0383973173473193
        entropy_coeff: 9.999999999999998e-05
        kl: 0.012736773928222448
        model: {}
        policy_loss: -0.04211038043317587
        total_loss: -0.039666864859021225
        vf_explained_var: 0.0047072614543139935
        vf_loss: 0.0
    num_steps_sampled: 3621206
    num_steps_trained: 3621206
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.322448979591837
    gpu_util_percent0: 0.25612244897959185
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.106122448979591
    vram_util_percent0: 0.08027222040013121
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 44179
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17536456076894563
    mean_env_wait_ms: 1.6349960887856891
    mean_inference_ms: 4.66228642078222
    mean_raw_obs_processing_ms: 0.49493808415453816
  time_since_restore: 518.9900712966919
  time_this_iter_s: 41.77867007255554
  time_total_s: 518.9900712966919
  timers:
    learn_throughput: 9131.167
    learn_time_ms: 30449.329
    sample_throughput: 30313.772
    sample_time_ms: 9171.999
    update_time_ms: 27.334
  timestamp: 1602417854
  timesteps_since_restore: 0
  timesteps_total: 3621206
  training_iteration: 13
  trial_id: a7863_00000
  
== Status ==
Memory usage on this node: 30.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a7863_00000 | RUNNING  | 172.17.0.4:44179 |     13 |           518.99 | 3621206 |  221.106 |              280.717 |              113.747 |            881.501 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a7863_00000:
  custom_metrics:
    time_step_max: 4321
    time_step_mean: 3597.7521328106986
    time_step_min: 3255
  date: 2020-10-11_12-04-52
  done: false
  episode_len_mean: 881.2936256781194
  episode_reward_max: 280.7171717171717
  episode_reward_mean: 221.04218952636654
  episode_reward_min: 111.32323232323223
  episodes_this_iter: 316
  episodes_total: 4424
  experiment_id: 4edd8c230375465cb0cfd8b8cad86c2d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 9.999999999999998e-05
        entropy: 1.027512068333833
        entropy_coeff: 9.999999999999998e-05
        kl: 0.01544172843189343
        model: {}
        policy_loss: -0.04238511306112227
        total_loss: -0.03939951850992182
        vf_explained_var: 0.004803115967661142
        vf_loss: 0.0
    num_steps_sampled: 3898843
    num_steps_trained: 3898843
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.724999999999998
    gpu_util_percent0: 0.28863636363636364
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.161363636363635
    vram_util_percent0: 0.08027222040013121
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 44179
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1751304929882504
    mean_env_wait_ms: 1.6349970026484835
    mean_inference_ms: 4.642984068991798
    mean_raw_obs_processing_ms: 0.4941914924419409
  time_since_restore: 556.6893372535706
  time_this_iter_s: 37.69926595687866
  time_total_s: 556.6893372535706
  timers:
    learn_throughput: 9132.229
    learn_time_ms: 30414.227
    sample_throughput: 32191.866
    sample_time_ms: 8627.946
    update_time_ms: 28.222
  timestamp: 1602417892
  timesteps_since_restore: 0
  timesteps_total: 3898843
  training_iteration: 14
  trial_id: a7863_00000
  
== Status ==
Memory usage on this node: 30.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a7863_00000 | RUNNING  | 172.17.0.4:44179 |     14 |          556.689 | 3898843 |  221.042 |              280.717 |              111.323 |            881.294 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a7863_00000:
  custom_metrics:
    time_step_max: 4321
    time_step_mean: 3594.7418869546527
    time_step_min: 3253
  date: 2020-10-11_12-05-30
  done: false
  episode_len_mean: 880.5643459915611
  episode_reward_max: 280.7171717171717
  episode_reward_mean: 221.48219537143572
  episode_reward_min: 111.32323232323223
  episodes_this_iter: 316
  episodes_total: 4740
  experiment_id: 4edd8c230375465cb0cfd8b8cad86c2d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 9.999999999999998e-05
        entropy: 1.0142047197922417
        entropy_coeff: 9.999999999999998e-05
        kl: 0.014221929418651955
        model: {}
        policy_loss: -0.0444475347581117
        total_loss: -0.04170456982177237
        vf_explained_var: 0.004765121731907129
        vf_loss: 0.0
    num_steps_sampled: 4173875
    num_steps_trained: 4173875
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 17.822222222222223
    gpu_util_percent0: 0.29511111111111116
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.159999999999998
    vram_util_percent0: 0.08027222040013123
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 44179
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17491832227246704
    mean_env_wait_ms: 1.6350363873996365
    mean_inference_ms: 4.625660054493231
    mean_raw_obs_processing_ms: 0.49358376954629585
  time_since_restore: 594.6191325187683
  time_this_iter_s: 37.929795265197754
  time_total_s: 594.6191325187683
  timers:
    learn_throughput: 9119.693
    learn_time_ms: 30403.368
    sample_throughput: 32047.921
    sample_time_ms: 8651.712
    update_time_ms: 32.297
  timestamp: 1602417930
  timesteps_since_restore: 0
  timesteps_total: 4173875
  training_iteration: 15
  trial_id: a7863_00000
  
== Status ==
Memory usage on this node: 30.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a7863_00000 | RUNNING  | 172.17.0.4:44179 |     15 |          594.619 | 4173875 |  221.482 |              280.717 |              111.323 |            880.564 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a7863_00000:
  custom_metrics:
    time_step_max: 4321
    time_step_mean: 3592.152747031596
    time_step_min: 3253
  date: 2020-10-11_12-06-12
  done: true
  episode_len_mean: 878.9845727848101
  episode_reward_max: 280.7171717171717
  episode_reward_mean: 221.9670818149851
  episode_reward_min: 111.32323232323223
  episodes_this_iter: 316
  episodes_total: 5056
  experiment_id: 4edd8c230375465cb0cfd8b8cad86c2d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 9.999999999999998e-05
        entropy: 1.0028439604717752
        entropy_coeff: 9.999999999999998e-05
        kl: 0.013268229997028475
        model: {}
        policy_loss: -0.047741330998099366
        total_loss: -0.04518796819383684
        vf_explained_var: 0.00488576153293252
        vf_loss: 0.0
    num_steps_sampled: 4444146
    num_steps_trained: 4444146
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.287500000000005
    gpu_util_percent0: 0.28729166666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.145833333333333
    vram_util_percent0: 0.08051136984803761
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 44179
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17472513275150073
    mean_env_wait_ms: 1.6351745504105002
    mean_inference_ms: 4.6098440361146436
    mean_raw_obs_processing_ms: 0.4928995541379432
  time_since_restore: 636.0357065200806
  time_this_iter_s: 41.416574001312256
  time_total_s: 636.0357065200806
  timers:
    learn_throughput: 9127.445
    learn_time_ms: 30279.415
    sample_throughput: 30390.588
    sample_time_ms: 9094.056
    update_time_ms: 31.128
  timestamp: 1602417972
  timesteps_since_restore: 0
  timesteps_total: 4444146
  training_iteration: 16
  trial_id: a7863_00000
  
== Status ==
Memory usage on this node: 30.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a7863_00000 | TERMINATED |       |     16 |          636.036 | 4444146 |  221.967 |              280.717 |              111.323 |            878.985 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 30.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a7863_00000 | TERMINATED |       |     16 |          636.036 | 4444146 |  221.967 |              280.717 |              111.323 |            878.985 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


