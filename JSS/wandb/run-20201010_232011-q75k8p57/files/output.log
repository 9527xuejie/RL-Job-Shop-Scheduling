2020-10-10 23:20:13,817	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8266[39m[22m
== Status ==
Memory usage on this node: 32.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_27243_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=44520)[0m 2020-10-10 23:20:16,714	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=44567)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44567)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44526)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44526)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44537)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44537)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44531)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44531)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44580)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44580)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44521)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44521)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44547)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44547)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44560)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44560)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44543)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44543)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44517)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44517)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44510)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44510)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44507)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44507)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44536)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44536)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44522)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44522)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44554)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44554)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44573)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44573)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44555)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44555)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44541)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44541)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44505)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44505)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44467)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44467)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44523)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44523)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44525)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44525)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44549)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44549)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44441)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44441)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44453)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44453)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44516)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44516)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44498)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44498)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44528)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44528)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44461)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44461)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44450)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44450)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44463)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44463)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44449)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44449)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44512)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44512)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44539)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44539)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44457)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44457)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44530)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44530)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44534)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44534)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44508)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44508)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44442)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44442)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44544)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44544)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44480)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44480)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44452)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44452)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44440)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44440)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44474)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44474)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44444)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44444)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44470)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44470)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44455)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44455)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44445)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44445)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44437)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44437)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44506)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44506)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44439)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44439)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44443)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44443)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44477)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44477)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44438)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44438)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44476)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44476)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44456)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44456)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44514)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44514)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44551)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44551)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44472)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44472)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44503)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44503)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44511)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44511)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44447)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44447)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44519)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44519)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44561)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44561)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44481)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44481)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44451)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44451)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44465)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44465)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44497)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44497)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44502)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44502)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44515)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44515)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44527)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44527)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44454)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44454)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44518)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44518)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44577)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44577)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44532)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44532)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44513)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44513)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44563)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44563)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44542)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44542)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44509)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44509)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_27243_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-10_23-20-55
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: a50f5902f76d4f358602d6c33ce7a896
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.1814181889806474
        entropy_coeff: 0.00010000000000000002
        kl: 0.008058699247028147
        model: {}
        policy_loss: -0.011834041363597083
        total_loss: 9.508658136640276
        vf_explained_var: 0.7608073353767395
        vf_loss: 9.518998350415911
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.555
    gpu_util_percent0: 0.27199999999999996
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.00025
    ram_util_percent: 6.279999999999999
    vram_util_percent0: 0.19141521810429646
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 44520
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1769520847029655
    mean_env_wait_ms: 1.2134490936175657
    mean_inference_ms: 5.775687667314342
    mean_raw_obs_processing_ms: 0.47279050814660106
  time_since_restore: 32.68213748931885
  time_this_iter_s: 32.68213748931885
  time_total_s: 32.68213748931885
  timers:
    learn_throughput: 6874.956
    learn_time_ms: 23533.531
    sample_throughput: 17804.718
    sample_time_ms: 9087.03
    update_time_ms: 29.206
  timestamp: 1602372055
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: '27243_00000'
  
== Status ==
Memory usage on this node: 48.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_27243_00000 | RUNNING  | 172.17.0.4:44520 |      1 |          32.6821 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_27243_00000:
  custom_metrics:
    time_step_max: 4092
    time_step_mean: 3630.4166666666665
    time_step_min: 3372
  date: 2020-10-10_23-21-26
  done: false
  episode_len_mean: 879.3924050632911
  episode_reward_max: 266.62626262626185
  episode_reward_mean: 216.3122043216978
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: a50f5902f76d4f358602d6c33ce7a896
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.1466203246797835
        entropy_coeff: 0.00010000000000000002
        kl: 0.009412247754101242
        model: {}
        policy_loss: -0.012529907868676153
        total_loss: 8.185578175953456
        vf_explained_var: 0.8994110822677612
        vf_loss: 8.196340424673897
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.29473684210526
    gpu_util_percent0: 0.37631578947368427
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.463157894736843
    vram_util_percent0: 0.2046572646769433
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 44520
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17159578973126538
    mean_env_wait_ms: 1.207932296300403
    mean_inference_ms: 5.573039120384144
    mean_raw_obs_processing_ms: 0.46146961580991175
  time_since_restore: 64.07417821884155
  time_this_iter_s: 31.392040729522705
  time_total_s: 64.07417821884155
  timers:
    learn_throughput: 6917.95
    learn_time_ms: 23387.274
    sample_throughput: 18851.938
    sample_time_ms: 8582.248
    update_time_ms: 28.235
  timestamp: 1602372086
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: '27243_00000'
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_27243_00000 | RUNNING  | 172.17.0.4:44520 |      2 |          64.0742 | 323584 |  216.312 |              266.626 |              145.717 |            879.392 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_27243_00000:
  custom_metrics:
    time_step_max: 4399
    time_step_mean: 3632.6121076233185
    time_step_min: 3326
  date: 2020-10-10_23-21-57
  done: false
  episode_len_mean: 870.6097046413502
  episode_reward_max: 269.95959595959573
  episode_reward_mean: 216.38684311469103
  episode_reward_min: 99.5050505050503
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: a50f5902f76d4f358602d6c33ce7a896
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.1296213013785226
        entropy_coeff: 0.00010000000000000002
        kl: 0.009471796452999115
        model: {}
        policy_loss: -0.01417204539757222
        total_loss: 8.689759867531913
        vf_explained_var: 0.9386926889419556
        vf_loss: 8.702150549207415
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.127027027027022
    gpu_util_percent0: 0.29324324324324325
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.489189189189188
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 44520
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1680369717332136
    mean_env_wait_ms: 1.2075769597170145
    mean_inference_ms: 5.401755590677079
    mean_raw_obs_processing_ms: 0.4517933270418922
  time_since_restore: 95.12773752212524
  time_this_iter_s: 31.05355930328369
  time_total_s: 95.12773752212524
  timers:
    learn_throughput: 6916.383
    learn_time_ms: 23392.573
    sample_throughput: 19614.889
    sample_time_ms: 8248.428
    update_time_ms: 26.405
  timestamp: 1602372117
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: '27243_00000'
  
== Status ==
Memory usage on this node: 48.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_27243_00000 | RUNNING  | 172.17.0.4:44520 |      3 |          95.1277 | 485376 |  216.387 |               269.96 |              99.5051 |             870.61 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_27243_00000:
  custom_metrics:
    time_step_max: 4496
    time_step_mean: 3625.975165562914
    time_step_min: 3326
  date: 2020-10-10_23-22-28
  done: false
  episode_len_mean: 862.7816455696203
  episode_reward_max: 272.8383838383833
  episode_reward_mean: 216.51046861015197
  episode_reward_min: 84.80808080808093
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: a50f5902f76d4f358602d6c33ce7a896
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.100591846874782
        entropy_coeff: 0.00010000000000000002
        kl: 0.008723151271364518
        model: {}
        policy_loss: -0.016127982842070714
        total_loss: 9.307762554713658
        vf_explained_var: 0.955302894115448
        vf_loss: 9.322255747658867
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.254054054054055
    gpu_util_percent0: 0.30675675675675673
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4837837837837835
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 44520
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16548465524733674
    mean_env_wait_ms: 1.2089662106976746
    mean_inference_ms: 5.271764122418489
    mean_raw_obs_processing_ms: 0.44379582742409823
  time_since_restore: 125.78074359893799
  time_this_iter_s: 30.653006076812744
  time_total_s: 125.78074359893799
  timers:
    learn_throughput: 6915.324
    learn_time_ms: 23396.155
    sample_throughput: 20270.907
    sample_time_ms: 7981.488
    update_time_ms: 24.285
  timestamp: 1602372148
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: '27243_00000'
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_27243_00000 | RUNNING  | 172.17.0.4:44520 |      4 |          125.781 | 647168 |   216.51 |              272.838 |              84.8081 |            862.782 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_27243_00000:
  custom_metrics:
    time_step_max: 4496
    time_step_mean: 3618.752821670429
    time_step_min: 3249
  date: 2020-10-10_23-22-59
  done: false
  episode_len_mean: 850.9277899343545
  episode_reward_max: 276.77777777777743
  episode_reward_mean: 217.64658621223157
  episode_reward_min: 84.80808080808093
  episodes_this_iter: 282
  episodes_total: 914
  experiment_id: a50f5902f76d4f358602d6c33ce7a896
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.0662224803652083
        entropy_coeff: 0.00010000000000000002
        kl: 0.008210398689178484
        model: {}
        policy_loss: -0.01547312134893478
        total_loss: 11.592007296425956
        vf_explained_var: 0.9746409058570862
        vf_loss: 11.605944905962263
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.127027027027026
    gpu_util_percent0: 0.3983783783783784
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.472972972972973
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 44520
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16252008388746308
    mean_env_wait_ms: 1.2135175826008844
    mean_inference_ms: 5.116674715103965
    mean_raw_obs_processing_ms: 0.43424292996641606
  time_since_restore: 156.38569688796997
  time_this_iter_s: 30.604953289031982
  time_total_s: 156.38569688796997
  timers:
    learn_throughput: 6915.64
    learn_time_ms: 23395.089
    sample_throughput: 20710.314
    sample_time_ms: 7812.146
    update_time_ms: 24.44
  timestamp: 1602372179
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: '27243_00000'
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_27243_00000 | RUNNING  | 172.17.0.4:44520 |      5 |          156.386 | 808960 |  217.647 |              276.778 |              84.8081 |            850.928 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_27243_00000:
  custom_metrics:
    time_step_max: 4496
    time_step_mean: 3612.5296846011133
    time_step_min: 3249
  date: 2020-10-10_23-23-29
  done: false
  episode_len_mean: 844.6428571428571
  episode_reward_max: 276.77777777777743
  episode_reward_mean: 218.18621111659075
  episode_reward_min: 84.80808080808093
  episodes_this_iter: 192
  episodes_total: 1106
  experiment_id: a50f5902f76d4f358602d6c33ce7a896
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.0576676641191756
        entropy_coeff: 0.00010000000000000002
        kl: 0.008711957239678927
        model: {}
        policy_loss: -0.014978249099970396
        total_loss: 6.752422196524484
        vf_explained_var: 0.9817423224449158
        vf_loss: 6.76576372555324
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.53333333333333
    gpu_util_percent0: 0.3286111111111111
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497222222222223
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 44520
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16118019389009797
    mean_env_wait_ms: 1.2163924218825644
    mean_inference_ms: 5.043165907236846
    mean_raw_obs_processing_ms: 0.4299396535723284
  time_since_restore: 187.047194480896
  time_this_iter_s: 30.661497592926025
  time_total_s: 187.047194480896
  timers:
    learn_throughput: 6908.506
    learn_time_ms: 23419.247
    sample_throughput: 21060.662
    sample_time_ms: 7682.19
    update_time_ms: 27.106
  timestamp: 1602372209
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: '27243_00000'
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_27243_00000 | RUNNING  | 172.17.0.4:44520 |      6 |          187.047 | 970752 |  218.186 |              276.778 |              84.8081 |            844.643 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_27243_00000:
  custom_metrics:
    time_step_max: 4496
    time_step_mean: 3605.5663430420714
    time_step_min: 3249
  date: 2020-10-10_23-24-00
  done: false
  episode_len_mean: 840.7492088607595
  episode_reward_max: 276.77777777777743
  episode_reward_mean: 219.30618686868675
  episode_reward_min: 84.80808080808093
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: a50f5902f76d4f358602d6c33ce7a896
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.024488968508584
        entropy_coeff: 0.00010000000000000002
        kl: 0.00858380984781044
        model: {}
        policy_loss: -0.01661467881474112
        total_loss: 5.1999035222189764
        vf_explained_var: 0.9872078895568848
        vf_loss: 5.214903933661325
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.337837837837835
    gpu_util_percent0: 0.26918918918918916
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.5
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 44520
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16027063525343357
    mean_env_wait_ms: 1.2184136262490566
    mean_inference_ms: 4.992743688239396
    mean_raw_obs_processing_ms: 0.4269308553038387
  time_since_restore: 217.69655776023865
  time_this_iter_s: 30.64936327934265
  time_total_s: 217.69655776023865
  timers:
    learn_throughput: 6904.878
    learn_time_ms: 23431.55
    sample_throughput: 21303.839
    sample_time_ms: 7594.5
    update_time_ms: 26.639
  timestamp: 1602372240
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: '27243_00000'
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_27243_00000 | RUNNING  | 172.17.0.4:44520 |      7 |          217.697 | 1132544 |  219.306 |              276.778 |              84.8081 |            840.749 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_27243_00000:
  custom_metrics:
    time_step_max: 4496
    time_step_mean: 3603.56456241033
    time_step_min: 3249
  date: 2020-10-10_23-24-31
  done: false
  episode_len_mean: 837.7911392405064
  episode_reward_max: 276.77777777777743
  episode_reward_mean: 219.6787282103737
  episode_reward_min: 84.80808080808093
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: a50f5902f76d4f358602d6c33ce7a896
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9780584233147758
        entropy_coeff: 0.00010000000000000002
        kl: 0.009321027701454503
        model: {}
        policy_loss: -0.016798221306609257
        total_loss: 5.0234671660832
        vf_explained_var: 0.9892960786819458
        vf_loss: 5.038499048777989
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.42105263157895
    gpu_util_percent0: 0.3463157894736842
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.484210526315789
    vram_util_percent0: 0.2046572646769433
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 44520
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1594847728599047
    mean_env_wait_ms: 1.220269959200302
    mean_inference_ms: 4.948918406005269
    mean_raw_obs_processing_ms: 0.42427331503827664
  time_since_restore: 248.9314832687378
  time_this_iter_s: 31.234925508499146
  time_total_s: 248.9314832687378
  timers:
    learn_throughput: 6886.843
    learn_time_ms: 23492.912
    sample_throughput: 21440.798
    sample_time_ms: 7545.988
    update_time_ms: 29.723
  timestamp: 1602372271
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: '27243_00000'
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_27243_00000 | RUNNING  | 172.17.0.4:44520 |      8 |          248.931 | 1294336 |  219.679 |              276.778 |              84.8081 |            837.791 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_27243_00000:
  custom_metrics:
    time_step_max: 4496
    time_step_mean: 3601.349560117302
    time_step_min: 3249
  date: 2020-10-10_23-25-02
  done: false
  episode_len_mean: 832.5129832660127
  episode_reward_max: 276.77777777777743
  episode_reward_mean: 219.9161435474187
  episode_reward_min: 84.80808080808093
  episodes_this_iter: 311
  episodes_total: 1733
  experiment_id: a50f5902f76d4f358602d6c33ce7a896
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9424576376165662
        entropy_coeff: 0.00010000000000000002
        kl: 0.007233036548963615
        model: {}
        policy_loss: -0.012824220682627388
        total_loss: 7.276455879211426
        vf_explained_var: 0.9910178780555725
        vf_loss: 7.2879277638026645
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.608108108108105
    gpu_util_percent0: 0.4224324324324325
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.478378378378378
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 44520
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1582534018467392
    mean_env_wait_ms: 1.223731929501236
    mean_inference_ms: 4.880089138677339
    mean_raw_obs_processing_ms: 0.4201461695948023
  time_since_restore: 279.6598138809204
  time_this_iter_s: 30.728330612182617
  time_total_s: 279.6598138809204
  timers:
    learn_throughput: 6888.17
    learn_time_ms: 23488.387
    sample_throughput: 21571.32
    sample_time_ms: 7500.329
    update_time_ms: 29.003
  timestamp: 1602372302
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: '27243_00000'
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_27243_00000 | RUNNING  | 172.17.0.4:44520 |      9 |           279.66 | 1456128 |  219.916 |              276.778 |              84.8081 |            832.513 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_27243_00000:
  custom_metrics:
    time_step_max: 4496
    time_step_mean: 3600.661670235546
    time_step_min: 3249
  date: 2020-10-10_23-25-33
  done: false
  episode_len_mean: 831.0305907172996
  episode_reward_max: 276.77777777777743
  episode_reward_mean: 219.8440416826492
  episode_reward_min: 84.80808080808093
  episodes_this_iter: 163
  episodes_total: 1896
  experiment_id: a50f5902f76d4f358602d6c33ce7a896
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9045255184173584
        entropy_coeff: 0.00010000000000000002
        kl: 0.008566284352647406
        model: {}
        policy_loss: -0.014111827493512205
        total_loss: 3.80642831325531
        vf_explained_var: 0.9935538172721863
        vf_loss: 3.818917308534895
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.48378378378378
    gpu_util_percent0: 0.3994594594594595
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.491891891891892
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 44520
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1577404982424179
    mean_env_wait_ms: 1.2253594652989745
    mean_inference_ms: 4.850831617613433
    mean_raw_obs_processing_ms: 0.41840843278994705
  time_since_restore: 310.45616340637207
  time_this_iter_s: 30.79634952545166
  time_total_s: 310.45616340637207
  timers:
    learn_throughput: 6887.596
    learn_time_ms: 23490.343
    sample_throughput: 21656.624
    sample_time_ms: 7470.786
    update_time_ms: 28.885
  timestamp: 1602372333
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: '27243_00000'
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_27243_00000 | RUNNING  | 172.17.0.4:44520 |     10 |          310.456 | 1617920 |  219.844 |              276.778 |              84.8081 |            831.031 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_27243_00000:
  custom_metrics:
    time_step_max: 4496
    time_step_mean: 3599.7171767028626
    time_step_min: 3249
  date: 2020-10-10_23-26-03
  done: false
  episode_len_mean: 829.0194741966894
  episode_reward_max: 276.77777777777743
  episode_reward_mean: 220.12261859097296
  episode_reward_min: 84.80808080808093
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: a50f5902f76d4f358602d6c33ce7a896
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.8824434067521777
        entropy_coeff: 0.00010000000000000002
        kl: 0.007425651120554123
        model: {}
        policy_loss: -0.013141711152067208
        total_loss: 3.499799983842032
        vf_explained_var: 0.9939977526664734
        vf_loss: 3.51154477255685
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.205555555555556
    gpu_util_percent0: 0.36999999999999994
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497222222222222
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 44520
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15728892452792081
    mean_env_wait_ms: 1.2267829626019706
    mean_inference_ms: 4.825311096190653
    mean_raw_obs_processing_ms: 0.41686606986309926
  time_since_restore: 340.8146963119507
  time_this_iter_s: 30.358532905578613
  time_total_s: 340.8146963119507
  timers:
    learn_throughput: 6898.108
    learn_time_ms: 23454.547
    sample_throughput: 22246.144
    sample_time_ms: 7272.811
    update_time_ms: 27.941
  timestamp: 1602372363
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: '27243_00000'
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_27243_00000 | RUNNING  | 172.17.0.4:44520 |     11 |          340.815 | 1779712 |  220.123 |              276.778 |              84.8081 |            829.019 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_27243_00000:
  custom_metrics:
    time_step_max: 4496
    time_step_mean: 3595.400091449474
    time_step_min: 3249
  date: 2020-10-10_23-26-35
  done: false
  episode_len_mean: 827.2785553047404
  episode_reward_max: 276.77777777777743
  episode_reward_mean: 220.898784686595
  episode_reward_min: 84.80808080808093
  episodes_this_iter: 161
  episodes_total: 2215
  experiment_id: a50f5902f76d4f358602d6c33ce7a896
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.8539374683584485
        entropy_coeff: 0.00010000000000000002
        kl: 0.0073639389925769395
        model: {}
        policy_loss: -0.016352855168016895
        total_loss: 3.0050249780927385
        vf_explained_var: 0.9953217506408691
        vf_loss: 3.019990393093654
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.876315789473683
    gpu_util_percent0: 0.30473684210526314
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.502631578947369
    vram_util_percent0: 0.2046572646769433
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 44520
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1568804543135601
    mean_env_wait_ms: 1.228239604280847
    mean_inference_ms: 4.801916558500201
    mean_raw_obs_processing_ms: 0.4154279159461015
  time_since_restore: 371.8401143550873
  time_this_iter_s: 31.025418043136597
  time_total_s: 371.8401143550873
  timers:
    learn_throughput: 6884.061
    learn_time_ms: 23502.407
    sample_throughput: 22527.814
    sample_time_ms: 7181.878
    update_time_ms: 27.323
  timestamp: 1602372395
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: '27243_00000'
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_27243_00000 | RUNNING  | 172.17.0.4:44520 |     12 |           371.84 | 1941504 |  220.899 |              276.778 |              84.8081 |            827.279 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_27243_00000:
  custom_metrics:
    time_step_max: 4496
    time_step_mean: 3591.797118847539
    time_step_min: 3249
  date: 2020-10-10_23-27-05
  done: false
  episode_len_mean: 824.8694103680253
  episode_reward_max: 276.77777777777743
  episode_reward_mean: 221.73430785896156
  episode_reward_min: 84.80808080808093
  episodes_this_iter: 312
  episodes_total: 2527
  experiment_id: a50f5902f76d4f358602d6c33ce7a896
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.8253284607614789
        entropy_coeff: 0.00010000000000000002
        kl: 0.007188748967434678
        model: {}
        policy_loss: -0.012911614729091525
        total_loss: 4.2987938949040005
        vf_explained_var: 0.9948042631149292
        vf_loss: 4.310350213732038
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.005555555555556
    gpu_util_percent0: 0.3069444444444444
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.488888888888889
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 44520
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15619991234544808
    mean_env_wait_ms: 1.2307058722274795
    mean_inference_ms: 4.762680054336012
    mean_raw_obs_processing_ms: 0.41306819369082864
  time_since_restore: 402.5529582500458
  time_this_iter_s: 30.712843894958496
  time_total_s: 402.5529582500458
  timers:
    learn_throughput: 6881.72
    learn_time_ms: 23510.402
    sample_throughput: 22664.703
    sample_time_ms: 7138.501
    update_time_ms: 27.383
  timestamp: 1602372425
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: '27243_00000'
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_27243_00000 | RUNNING  | 172.17.0.4:44520 |     13 |          402.553 | 2103296 |  221.734 |              276.778 |              84.8081 |            824.869 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_27243_00000:
  custom_metrics:
    time_step_max: 4496
    time_step_mean: 3587.9401805869074
    time_step_min: 3249
  date: 2020-10-10_23-27-37
  done: false
  episode_len_mean: 823.4404318689501
  episode_reward_max: 276.77777777777743
  episode_reward_mean: 222.36443361387512
  episode_reward_min: 84.80808080808093
  episodes_this_iter: 159
  episodes_total: 2686
  experiment_id: a50f5902f76d4f358602d6c33ce7a896
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.7909964152744838
        entropy_coeff: 0.00010000000000000002
        kl: 0.008063946118844407
        model: {}
        policy_loss: -0.013182396634614893
        total_loss: 2.5994922603879655
        vf_explained_var: 0.995347797870636
        vf_loss: 2.6111408982958113
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.194594594594594
    gpu_util_percent0: 0.3540540540540541
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497297297297296
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 44520
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15589893271738312
    mean_env_wait_ms: 1.2318956878340759
    mean_inference_ms: 4.745472892347983
    mean_raw_obs_processing_ms: 0.41203659908405443
  time_since_restore: 433.5457193851471
  time_this_iter_s: 30.99276113510132
  time_total_s: 433.5457193851471
  timers:
    learn_throughput: 6868.728
    learn_time_ms: 23554.87
    sample_throughput: 22703.901
    sample_time_ms: 7126.176
    update_time_ms: 28.191
  timestamp: 1602372457
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: '27243_00000'
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_27243_00000 | RUNNING  | 172.17.0.4:44520 |     14 |          433.546 | 2265088 |  222.364 |              276.778 |              84.8081 |             823.44 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_27243_00000:
  custom_metrics:
    time_step_max: 4496
    time_step_mean: 3582.7485795454545
    time_step_min: 3249
  date: 2020-10-10_23-28-08
  done: false
  episode_len_mean: 821.7784810126582
  episode_reward_max: 276.77777777777743
  episode_reward_mean: 223.12948045859434
  episode_reward_min: 84.80808080808093
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: a50f5902f76d4f358602d6c33ce7a896
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.7787308820656368
        entropy_coeff: 0.00010000000000000002
        kl: 0.0067940978333354
        model: {}
        policy_loss: -0.015173679525365255
        total_loss: 2.49174097606114
        vf_explained_var: 0.9951062202453613
        vf_loss: 2.5056337288447788
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.043243243243243
    gpu_util_percent0: 0.3189189189189189
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.499999999999999
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 44520
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1556264494794761
    mean_env_wait_ms: 1.2330044744162811
    mean_inference_ms: 4.729745195951593
    mean_raw_obs_processing_ms: 0.41108993422796036
  time_since_restore: 464.42763900756836
  time_this_iter_s: 30.881919622421265
  time_total_s: 464.42763900756836
  timers:
    learn_throughput: 6869.281
    learn_time_ms: 23552.976
    sample_throughput: 22612.326
    sample_time_ms: 7155.036
    update_time_ms: 28.382
  timestamp: 1602372488
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: '27243_00000'
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_27243_00000 | RUNNING  | 172.17.0.4:44520 |     15 |          464.428 | 2426880 |  223.129 |              276.778 |              84.8081 |            821.778 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_27243_00000:
  custom_metrics:
    time_step_max: 4496
    time_step_mean: 3574.396478643626
    time_step_min: 3249
  date: 2020-10-10_23-28-38
  done: false
  episode_len_mean: 819.0953150242326
  episode_reward_max: 276.77777777777743
  episode_reward_mean: 224.41149785414726
  episode_reward_min: 84.80808080808093
  episodes_this_iter: 251
  episodes_total: 3095
  experiment_id: a50f5902f76d4f358602d6c33ce7a896
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.7511502036026546
        entropy_coeff: 0.00010000000000000002
        kl: 0.006446583595659051
        model: {}
        policy_loss: -0.01326805230512816
        total_loss: 3.177613377571106
        vf_explained_var: 0.9954571723937988
        vf_loss: 3.189667293003627
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.2027027027027
    gpu_util_percent0: 0.2913513513513514
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.489189189189188
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 44520
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15523560977201042
    mean_env_wait_ms: 1.2347535833536043
    mean_inference_ms: 4.707418807310509
    mean_raw_obs_processing_ms: 0.4097391074154726
  time_since_restore: 495.09252285957336
  time_this_iter_s: 30.664883852005005
  time_total_s: 495.09252285957336
  timers:
    learn_throughput: 6871.837
    learn_time_ms: 23544.214
    sample_throughput: 22581.931
    sample_time_ms: 7164.666
    update_time_ms: 26.648
  timestamp: 1602372518
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: '27243_00000'
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_27243_00000 | RUNNING  | 172.17.0.4:44520 |     16 |          495.093 | 2588672 |  224.411 |              276.778 |              84.8081 |            819.095 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_27243_00000:
  custom_metrics:
    time_step_max: 4496
    time_step_mean: 3567.6100303951366
    time_step_min: 3249
  date: 2020-10-10_23-29-09
  done: false
  episode_len_mean: 817.0910186859554
  episode_reward_max: 276.77777777777743
  episode_reward_mean: 225.4717701426562
  episode_reward_min: 84.80808080808093
  episodes_this_iter: 223
  episodes_total: 3318
  experiment_id: a50f5902f76d4f358602d6c33ce7a896
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.7043397724628448
        entropy_coeff: 0.00010000000000000002
        kl: 0.006422875149707709
        model: {}
        policy_loss: -0.012735356851148285
        total_loss: 2.456866604941232
        vf_explained_var: 0.9955493807792664
        vf_loss: 2.4683878251484463
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.575675675675676
    gpu_util_percent0: 0.33999999999999997
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.486486486486487
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 44520
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15492667130657653
    mean_env_wait_ms: 1.236235104589452
    mean_inference_ms: 4.689444802001544
    mean_raw_obs_processing_ms: 0.40869119657458264
  time_since_restore: 525.7577075958252
  time_this_iter_s: 30.66518473625183
  time_total_s: 525.7577075958252
  timers:
    learn_throughput: 6872.601
    learn_time_ms: 23541.597
    sample_throughput: 22572.968
    sample_time_ms: 7167.511
    update_time_ms: 26.814
  timestamp: 1602372549
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: '27243_00000'
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_27243_00000 | RUNNING  | 172.17.0.4:44520 |     17 |          525.758 | 2750464 |  225.472 |              276.778 |              84.8081 |            817.091 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_27243_00000:
  custom_metrics:
    time_step_max: 4496
    time_step_mean: 3563.057134570766
    time_step_min: 3249
  date: 2020-10-10_23-29-40
  done: false
  episode_len_mean: 815.7891254315305
  episode_reward_max: 276.77777777777743
  episode_reward_mean: 226.14172798177398
  episode_reward_min: 84.80808080808093
  episodes_this_iter: 158
  episodes_total: 3476
  experiment_id: a50f5902f76d4f358602d6c33ce7a896
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.7089364698954991
        entropy_coeff: 0.00010000000000000002
        kl: 0.0068205374492598435
        model: {}
        policy_loss: -0.013545157396168048
        total_loss: 2.1912212797573636
        vf_explained_var: 0.9954132437705994
        vf_loss: 2.203473278454372
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.256756756756758
    gpu_util_percent0: 0.3172972972972973
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.491891891891891
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 44520
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15472707931488147
    mean_env_wait_ms: 1.2372040990348878
    mean_inference_ms: 4.677881537959234
    mean_raw_obs_processing_ms: 0.40800306028979955
  time_since_restore: 556.5247323513031
  time_this_iter_s: 30.767024755477905
  time_total_s: 556.5247323513031
  timers:
    learn_throughput: 6885.061
    learn_time_ms: 23498.994
    sample_throughput: 22578.746
    sample_time_ms: 7165.677
    update_time_ms: 24.079
  timestamp: 1602372580
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: '27243_00000'
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_27243_00000 | RUNNING  | 172.17.0.4:44520 |     18 |          556.525 | 2912256 |  226.142 |              276.778 |              84.8081 |            815.789 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_27243_00000:
  custom_metrics:
    time_step_max: 4496
    time_step_mean: 3557.8346196251377
    time_step_min: 3227
  date: 2020-10-10_23-30-11
  done: false
  episode_len_mean: 814.4280634573304
  episode_reward_max: 277.080808080808
  episode_reward_mean: 226.9429690780894
  episode_reward_min: 84.80808080808093
  episodes_this_iter: 180
  episodes_total: 3656
  experiment_id: a50f5902f76d4f358602d6c33ce7a896
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.6905673657144819
        entropy_coeff: 0.00010000000000000002
        kl: 0.006543563778645226
        model: {}
        policy_loss: -0.013121655277375664
        total_loss: 2.229641156537192
        vf_explained_var: 0.9960497617721558
        vf_loss: 2.2415232147489275
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.345945945945946
    gpu_util_percent0: 0.3989189189189189
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.486486486486487
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 44520
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1545081464212452
    mean_env_wait_ms: 1.2383397785487527
    mean_inference_ms: 4.665620665457443
    mean_raw_obs_processing_ms: 0.40725547048421357
  time_since_restore: 587.2444398403168
  time_this_iter_s: 30.719707489013672
  time_total_s: 587.2444398403168
  timers:
    learn_throughput: 6884.997
    learn_time_ms: 23499.212
    sample_throughput: 22573.925
    sample_time_ms: 7167.207
    update_time_ms: 26.858
  timestamp: 1602372611
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: '27243_00000'
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_27243_00000 | RUNNING  | 172.17.0.4:44520 |     19 |          587.244 | 3074048 |  226.943 |              277.081 |              84.8081 |            814.428 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_27243_00000:
  custom_metrics:
    time_step_max: 4496
    time_step_mean: 3549.530086690464
    time_step_min: 3227
  date: 2020-10-10_23-30-42
  done: true
  episode_len_mean: 812.340253164557
  episode_reward_max: 277.080808080808
  episode_reward_mean: 228.19039764735962
  episode_reward_min: 84.80808080808093
  episodes_this_iter: 294
  episodes_total: 3950
  experiment_id: a50f5902f76d4f358602d6c33ce7a896
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.6446034737995693
        entropy_coeff: 0.00010000000000000002
        kl: 0.005680264040295567
        model: {}
        policy_loss: -0.01089689524997084
        total_loss: 2.534832034792219
        vf_explained_var: 0.99610435962677
        vf_loss: 2.5446572984967912
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.608108108108105
    gpu_util_percent0: 0.37702702702702706
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4837837837837835
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 44520
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1542030362900688
    mean_env_wait_ms: 1.240011649235467
    mean_inference_ms: 4.647393651352083
    mean_raw_obs_processing_ms: 0.40619316594767546
  time_since_restore: 618.2245578765869
  time_this_iter_s: 30.98011803627014
  time_total_s: 618.2245578765869
  timers:
    learn_throughput: 6879.321
    learn_time_ms: 23518.602
    sample_throughput: 22589.299
    sample_time_ms: 7162.329
    update_time_ms: 27.696
  timestamp: 1602372642
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: '27243_00000'
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_27243_00000 | TERMINATED |       |     20 |          618.225 | 3235840 |   228.19 |              277.081 |              84.8081 |             812.34 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_27243_00000 | TERMINATED |       |     20 |          618.225 | 3235840 |   228.19 |              277.081 |              84.8081 |             812.34 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


