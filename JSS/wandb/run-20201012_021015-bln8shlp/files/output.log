2020-10-12 02:10:19,251	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_146c2_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=60644)[0m 2020-10-12 02:10:22,050	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=60624)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60624)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60652)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60652)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60642)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60642)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60551)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60551)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60649)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60649)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60626)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60626)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60613)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60613)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60616)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60616)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60622)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60622)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60617)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60617)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60601)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60601)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60623)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60623)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60633)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60633)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60610)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60610)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60647)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60647)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60643)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60643)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60608)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60608)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60630)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60630)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60635)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60635)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60591)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60591)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60531)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60531)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60564)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60564)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60552)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60552)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60538)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60538)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60546)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60546)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60562)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60562)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60565)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60565)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60598)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60598)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60583)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60583)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60588)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60588)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60620)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60620)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60557)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60557)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60602)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60602)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60580)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60580)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60540)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60540)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60636)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60636)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60597)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60597)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60555)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60555)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60628)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60628)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60607)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60607)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60655)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60655)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60544)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60544)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60605)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60605)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60536)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60536)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60530)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60530)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60525)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60525)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60528)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60528)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60611)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60611)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60579)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60579)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60545)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60545)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60543)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60543)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60650)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60650)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60532)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60532)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60625)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60625)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60637)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60637)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60586)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60586)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60640)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60640)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60638)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60638)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60594)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60594)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60600)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60600)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60542)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60542)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60535)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60535)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60549)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60549)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60606)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60606)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60529)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60529)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60615)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60615)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60659)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60659)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60527)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60527)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60539)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60539)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60599)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60599)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60595)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60595)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60609)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60609)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60603)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60603)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60541)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60541)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60604)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60604)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60568)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60568)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60534)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60534)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60526)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60526)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60559)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60559)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_146c2_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-12_02-10-56
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: d30e2e5956b043c486c44cd02ec01306
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 1.1844614346822102
        entropy_coeff: 0.0001
        kl: 0.004735834586123626
        model: {}
        policy_loss: -0.008792587546243643
        total_loss: 507.0758056640625
        vf_explained_var: 0.540532648563385
        vf_loss: 507.0832926432292
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.002941176470586
    gpu_util_percent0: 0.2738235294117647
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5647058823529414
    vram_util_percent0: 0.08636872262844136
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60644
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1672601272898642
    mean_env_wait_ms: 1.1594100703645467
    mean_inference_ms: 5.930146378990897
    mean_raw_obs_processing_ms: 0.45240712850393444
  time_since_restore: 29.4014413356781
  time_this_iter_s: 29.4014413356781
  time_total_s: 29.4014413356781
  timers:
    learn_throughput: 8183.942
    learn_time_ms: 19769.446
    sample_throughput: 16953.462
    sample_time_ms: 9543.301
    update_time_ms: 49.872
  timestamp: 1602468656
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 146c2_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_146c2_00000 | RUNNING  | 172.17.0.4:60644 |      1 |          29.4014 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_146c2_00000:
  custom_metrics:
    time_step_max: 4218
    time_step_mean: 3635.8958333333335
    time_step_min: 3332
  date: 2020-10-12_02-11-24
  done: false
  episode_len_mean: 891.496835443038
  episode_reward_max: 261.1717171717164
  episode_reward_mean: 215.46880194348526
  episode_reward_min: 126.92929292929256
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: d30e2e5956b043c486c44cd02ec01306
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.1502267320950825
        entropy_coeff: 0.0001
        kl: 0.011658771817261973
        model: {}
        policy_loss: -0.013879568936924139
        total_loss: 141.35505803426108
        vf_explained_var: 0.7968039512634277
        vf_loss: 141.36730321248373
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.675
    gpu_util_percent0: 0.29500000000000004
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.75625
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60644
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16318632072717415
    mean_env_wait_ms: 1.1572585681109366
    mean_inference_ms: 5.650348701730182
    mean_raw_obs_processing_ms: 0.4399276876371608
  time_since_restore: 56.53422665596008
  time_this_iter_s: 27.132785320281982
  time_total_s: 56.53422665596008
  timers:
    learn_throughput: 8266.025
    learn_time_ms: 19573.132
    sample_throughput: 18788.096
    sample_time_ms: 8611.41
    update_time_ms: 37.562
  timestamp: 1602468684
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 146c2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_146c2_00000 | RUNNING  | 172.17.0.4:60644 |      2 |          56.5342 | 323584 |  215.469 |              261.172 |              126.929 |            891.497 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_146c2_00000:
  custom_metrics:
    time_step_max: 4218
    time_step_mean: 3622.5695067264573
    time_step_min: 3323
  date: 2020-10-12_02-11-50
  done: false
  episode_len_mean: 887.5168776371308
  episode_reward_max: 262.98989898989885
  episode_reward_mean: 217.53950901419236
  episode_reward_min: 126.92929292929256
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: d30e2e5956b043c486c44cd02ec01306
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.1320263644059498
        entropy_coeff: 0.0001
        kl: 0.01445982496564587
        model: {}
        policy_loss: -0.014428126902203076
        total_loss: 59.98652489980062
        vf_explained_var: 0.8932930827140808
        vf_loss: 59.99889723459879
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.758064516129036
    gpu_util_percent0: 0.2603225806451613
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60644
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16042023733980246
    mean_env_wait_ms: 1.157520479131336
    mean_inference_ms: 5.43836192070473
    mean_raw_obs_processing_ms: 0.43063072868009994
  time_since_restore: 83.12755060195923
  time_this_iter_s: 26.593323945999146
  time_total_s: 83.12755060195923
  timers:
    learn_throughput: 8273.309
    learn_time_ms: 19555.901
    sample_throughput: 20058.483
    sample_time_ms: 8066.014
    update_time_ms: 39.006
  timestamp: 1602468710
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 146c2_00000
  
== Status ==
Memory usage on this node: 28.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_146c2_00000 | RUNNING  | 172.17.0.4:60644 |      3 |          83.1276 | 485376 |   217.54 |               262.99 |              126.929 |            887.517 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_146c2_00000:
  custom_metrics:
    time_step_max: 4295
    time_step_mean: 3614.1970198675494
    time_step_min: 3300
  date: 2020-10-12_02-12-17
  done: false
  episode_len_mean: 884.9256329113924
  episode_reward_max: 270.262626262626
  episode_reward_mean: 217.95513681114926
  episode_reward_min: 115.26262626262647
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: d30e2e5956b043c486c44cd02ec01306
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.1104607582092285
        entropy_coeff: 0.0001
        kl: 0.01223536611845096
        model: {}
        policy_loss: -0.01330539236854141
        total_loss: 46.831126848856606
        vf_explained_var: 0.9221466183662415
        vf_loss: 46.84270636240641
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.719354838709684
    gpu_util_percent0: 0.2990322580645161
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60644
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15849986296549154
    mean_env_wait_ms: 1.1583249552369865
    mean_inference_ms: 5.285051769807684
    mean_raw_obs_processing_ms: 0.42381441957484056
  time_since_restore: 109.39862775802612
  time_this_iter_s: 26.271077156066895
  time_total_s: 109.39862775802612
  timers:
    learn_throughput: 8297.765
    learn_time_ms: 19498.262
    sample_throughput: 20866.464
    sample_time_ms: 7753.685
    update_time_ms: 35.797
  timestamp: 1602468737
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 146c2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_146c2_00000 | RUNNING  | 172.17.0.4:60644 |      4 |          109.399 | 647168 |  217.955 |              270.263 |              115.263 |            884.926 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_146c2_00000:
  custom_metrics:
    time_step_max: 4295
    time_step_mean: 3603.8818897637793
    time_step_min: 3286
  date: 2020-10-12_02-12-43
  done: false
  episode_len_mean: 880.5240506329114
  episode_reward_max: 270.262626262626
  episode_reward_mean: 219.84241145633527
  episode_reward_min: 115.26262626262647
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: d30e2e5956b043c486c44cd02ec01306
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.072835902372996
        entropy_coeff: 0.0001
        kl: 0.012925840681418777
        model: {}
        policy_loss: -0.012078958873947462
        total_loss: 34.39954789479574
        vf_explained_var: 0.9414775967597961
        vf_loss: 34.4097957611084
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.450000000000003
    gpu_util_percent0: 0.3553333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7766666666666664
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60644
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1570783832686888
    mean_env_wait_ms: 1.159723176243744
    mean_inference_ms: 5.170152941112843
    mean_raw_obs_processing_ms: 0.41854910158797504
  time_since_restore: 135.51491570472717
  time_this_iter_s: 26.11628794670105
  time_total_s: 135.51491570472717
  timers:
    learn_throughput: 8315.458
    learn_time_ms: 19456.776
    sample_throughput: 21416.813
    sample_time_ms: 7554.439
    update_time_ms: 32.877
  timestamp: 1602468763
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 146c2_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_146c2_00000 | RUNNING  | 172.17.0.4:60644 |      5 |          135.515 | 808960 |  219.842 |              270.263 |              115.263 |            880.524 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_146c2_00000:
  custom_metrics:
    time_step_max: 4295
    time_step_mean: 3577.832863849765
    time_step_min: 3276
  date: 2020-10-12_02-13-10
  done: false
  episode_len_mean: 870.7063129002745
  episode_reward_max: 270.262626262626
  episode_reward_mean: 223.77589250233328
  episode_reward_min: 115.26262626262647
  episodes_this_iter: 303
  episodes_total: 1093
  experiment_id: d30e2e5956b043c486c44cd02ec01306
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.0378763775030773
        entropy_coeff: 0.0001
        kl: 0.011559847431878248
        model: {}
        policy_loss: -0.012860311753077744
        total_loss: 34.24993324279785
        vf_explained_var: 0.9584688544273376
        vf_loss: 34.261163075764976
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.264516129032263
    gpu_util_percent0: 0.2641935483870968
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7774193548387096
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60644
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15523984795111936
    mean_env_wait_ms: 1.1636400515629985
    mean_inference_ms: 5.021183685876437
    mean_raw_obs_processing_ms: 0.41187937713771566
  time_since_restore: 162.2004005908966
  time_this_iter_s: 26.685484886169434
  time_total_s: 162.2004005908966
  timers:
    learn_throughput: 8287.478
    learn_time_ms: 19522.465
    sample_throughput: 21808.487
    sample_time_ms: 7418.763
    update_time_ms: 34.315
  timestamp: 1602468790
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 146c2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_146c2_00000 | RUNNING  | 172.17.0.4:60644 |      6 |            162.2 | 970752 |  223.776 |              270.263 |              115.263 |            870.706 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_146c2_00000:
  custom_metrics:
    time_step_max: 4295
    time_step_mean: 3569.126213592233
    time_step_min: 3276
  date: 2020-10-12_02-13-36
  done: false
  episode_len_mean: 865.6724683544304
  episode_reward_max: 275.5656565656565
  episode_reward_mean: 225.55307025955736
  episode_reward_min: 115.26262626262647
  episodes_this_iter: 171
  episodes_total: 1264
  experiment_id: d30e2e5956b043c486c44cd02ec01306
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.0382561683654785
        entropy_coeff: 0.0001
        kl: 0.011133922729641199
        model: {}
        policy_loss: -0.01344414249372979
        total_loss: 19.70721451441447
        vf_explained_var: 0.9654671549797058
        vf_loss: 19.71909252802531
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.632258064516133
    gpu_util_percent0: 0.40032258064516135
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.783870967741935
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60644
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15447542376175352
    mean_env_wait_ms: 1.1654024180886404
    mean_inference_ms: 4.959976869344187
    mean_raw_obs_processing_ms: 0.409110219931808
  time_since_restore: 188.58098244667053
  time_this_iter_s: 26.380581855773926
  time_total_s: 188.58098244667053
  timers:
    learn_throughput: 8286.012
    learn_time_ms: 19525.918
    sample_throughput: 22094.433
    sample_time_ms: 7322.75
    update_time_ms: 34.817
  timestamp: 1602468816
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 146c2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_146c2_00000 | RUNNING  | 172.17.0.4:60644 |      7 |          188.581 | 1132544 |  225.553 |              275.566 |              115.263 |            865.672 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_146c2_00000:
  custom_metrics:
    time_step_max: 4295
    time_step_mean: 3561.2173601147774
    time_step_min: 3260
  date: 2020-10-12_02-14-02
  done: false
  episode_len_mean: 860.7348804500704
  episode_reward_max: 275.5656565656565
  episode_reward_mean: 226.92204747900934
  episode_reward_min: 115.26262626262647
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: d30e2e5956b043c486c44cd02ec01306
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.0090472251176834
        entropy_coeff: 0.0001
        kl: 0.012448439452176293
        model: {}
        policy_loss: -0.015845766485047836
        total_loss: 19.221986452738445
        vf_explained_var: 0.9653785824775696
        vf_loss: 19.23606554667155
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.493333333333336
    gpu_util_percent0: 0.36166666666666664
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.773333333333333
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60644
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1538862200390092
    mean_env_wait_ms: 1.167184217960951
    mean_inference_ms: 4.91234966207984
    mean_raw_obs_processing_ms: 0.40693254317208055
  time_since_restore: 214.80506801605225
  time_this_iter_s: 26.224085569381714
  time_total_s: 214.80506801605225
  timers:
    learn_throughput: 8294.192
    learn_time_ms: 19506.662
    sample_throughput: 22307.543
    sample_time_ms: 7252.793
    update_time_ms: 35.494
  timestamp: 1602468842
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 146c2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_146c2_00000 | RUNNING  | 172.17.0.4:60644 |      8 |          214.805 | 1294336 |  226.922 |              275.566 |              115.263 |            860.735 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_146c2_00000:
  custom_metrics:
    time_step_max: 4295
    time_step_mean: 3548.993556701031
    time_step_min: 3209
  date: 2020-10-12_02-14-29
  done: false
  episode_len_mean: 855.3487341772152
  episode_reward_max: 282.0808080808081
  episode_reward_mean: 228.80942334739782
  episode_reward_min: 115.26262626262647
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: d30e2e5956b043c486c44cd02ec01306
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.9647120783726374
        entropy_coeff: 0.0001
        kl: 0.010298040928319097
        model: {}
        policy_loss: -0.012920954449024672
        total_loss: 17.32411829630534
        vf_explained_var: 0.9668757915496826
        vf_loss: 17.335590680440266
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.6
    gpu_util_percent0: 0.2335483870967742
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.77741935483871
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60644
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15337815736055616
    mean_env_wait_ms: 1.1690614475305148
    mean_inference_ms: 4.871053309394144
    mean_raw_obs_processing_ms: 0.4049840787204929
  time_since_restore: 241.3633689880371
  time_this_iter_s: 26.558300971984863
  time_total_s: 241.3633689880371
  timers:
    learn_throughput: 8291.421
    learn_time_ms: 19513.182
    sample_throughput: 22423.992
    sample_time_ms: 7215.129
    update_time_ms: 34.558
  timestamp: 1602468869
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 146c2_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_146c2_00000 | RUNNING  | 172.17.0.4:60644 |      9 |          241.363 | 1456128 |  228.809 |              282.081 |              115.263 |            855.349 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_146c2_00000:
  custom_metrics:
    time_step_max: 4295
    time_step_mean: 3525.6134048257372
    time_step_min: 3209
  date: 2020-10-12_02-14-56
  done: false
  episode_len_mean: 846.0338087691495
  episode_reward_max: 282.0808080808081
  episode_reward_mean: 232.20583009172532
  episode_reward_min: 115.26262626262647
  episodes_this_iter: 313
  episodes_total: 1893
  experiment_id: d30e2e5956b043c486c44cd02ec01306
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.9314587016900381
        entropy_coeff: 0.0001
        kl: 0.010108804795891047
        model: {}
        policy_loss: -0.012150359825075915
        total_loss: 24.34405740102132
        vf_explained_var: 0.9678792357444763
        vf_loss: 24.354784329732258
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.03870967741935
    gpu_util_percent0: 0.32612903225806456
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60644
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1525692577486115
    mean_env_wait_ms: 1.1728423143101858
    mean_inference_ms: 4.805335735004261
    mean_raw_obs_processing_ms: 0.40196959656912046
  time_since_restore: 267.93771386146545
  time_this_iter_s: 26.574344873428345
  time_total_s: 267.93771386146545
  timers:
    learn_throughput: 8287.961
    learn_time_ms: 19521.328
    sample_throughput: 22522.932
    sample_time_ms: 7183.434
    update_time_ms: 33.769
  timestamp: 1602468896
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 146c2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_146c2_00000 | RUNNING  | 172.17.0.4:60644 |     10 |          267.938 | 1617920 |  232.206 |              282.081 |              115.263 |            846.034 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_146c2_00000:
  custom_metrics:
    time_step_max: 4295
    time_step_mean: 3514.4664363277393
    time_step_min: 3209
  date: 2020-10-12_02-15-22
  done: false
  episode_len_mean: 841.7346640701071
  episode_reward_max: 282.38383838383817
  episode_reward_mean: 233.82109311223223
  episode_reward_min: 115.26262626262647
  episodes_this_iter: 161
  episodes_total: 2054
  experiment_id: d30e2e5956b043c486c44cd02ec01306
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.9258037606875101
        entropy_coeff: 0.0001
        kl: 0.00963647182409962
        model: {}
        policy_loss: -0.01267018613483136
        total_loss: 13.569735685984293
        vf_explained_var: 0.9725965857505798
        vf_loss: 13.581052859624227
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.55161290322581
    gpu_util_percent0: 0.334516129032258
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.783870967741935
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60644
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15222944788489154
    mean_env_wait_ms: 1.1746636693711738
    mean_inference_ms: 4.777601225458767
    mean_raw_obs_processing_ms: 0.4006893472656482
  time_since_restore: 294.4817020893097
  time_this_iter_s: 26.54398822784424
  time_total_s: 294.4817020893097
  timers:
    learn_throughput: 8294.48
    learn_time_ms: 19505.986
    sample_throughput: 23405.047
    sample_time_ms: 6912.697
    update_time_ms: 32.662
  timestamp: 1602468922
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 146c2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_146c2_00000 | RUNNING  | 172.17.0.4:60644 |     11 |          294.482 | 1779712 |  233.821 |              282.384 |              115.263 |            841.735 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_146c2_00000:
  custom_metrics:
    time_step_max: 4295
    time_step_mean: 3504.022435897436
    time_step_min: 3174
  date: 2020-10-12_02-15-49
  done: false
  episode_len_mean: 837.8083182640145
  episode_reward_max: 285.11111111111074
  episode_reward_mean: 235.47558313697542
  episode_reward_min: 115.26262626262647
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: d30e2e5956b043c486c44cd02ec01306
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.9085799405972163
        entropy_coeff: 0.0001
        kl: 0.010157734621316195
        model: {}
        policy_loss: -0.012682633377456417
        total_loss: 11.956995407740274
        vf_explained_var: 0.9731258749961853
        vf_loss: 11.96824542681376
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.719354838709684
    gpu_util_percent0: 0.25161290322580643
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7903225806451615
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60644
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15192482794585374
    mean_env_wait_ms: 1.1763949923054975
    mean_inference_ms: 4.752971462720278
    mean_raw_obs_processing_ms: 0.39953825711330254
  time_since_restore: 321.0990364551544
  time_this_iter_s: 26.617334365844727
  time_total_s: 321.0990364551544
  timers:
    learn_throughput: 8284.455
    learn_time_ms: 19529.588
    sample_throughput: 23672.079
    sample_time_ms: 6834.719
    update_time_ms: 34.212
  timestamp: 1602468949
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 146c2_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_146c2_00000 | RUNNING  | 172.17.0.4:60644 |     12 |          321.099 | 1941504 |  235.476 |              285.111 |              115.263 |            837.808 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_146c2_00000:
  custom_metrics:
    time_step_max: 4295
    time_step_mean: 3492.1470833333333
    time_step_min: 3166
  date: 2020-10-12_02-16-15
  done: false
  episode_len_mean: 834.1523887973641
  episode_reward_max: 290.41414141414094
  episode_reward_mean: 237.20087198176148
  episode_reward_min: 115.26262626262647
  episodes_this_iter: 216
  episodes_total: 2428
  experiment_id: d30e2e5956b043c486c44cd02ec01306
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.8549998650948206
        entropy_coeff: 0.0001
        kl: 0.00961435578453044
        model: {}
        policy_loss: -0.012839811815259358
        total_loss: 15.972579876581827
        vf_explained_var: 0.9757623076438904
        vf_loss: 15.984062830607096
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.10967741935484
    gpu_util_percent0: 0.2651612903225807
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.76774193548387
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60644
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.151552246622199
    mean_env_wait_ms: 1.178628950496882
    mean_inference_ms: 4.722769927713237
    mean_raw_obs_processing_ms: 0.3981153981403365
  time_since_restore: 347.42165350914
  time_this_iter_s: 26.322617053985596
  time_total_s: 347.42165350914
  timers:
    learn_throughput: 8286.165
    learn_time_ms: 19525.558
    sample_throughput: 23751.824
    sample_time_ms: 6811.771
    update_time_ms: 34.073
  timestamp: 1602468975
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 146c2_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_146c2_00000 | RUNNING  | 172.17.0.4:60644 |     13 |          347.422 | 2103296 |  237.201 |              290.414 |              115.263 |            834.152 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_146c2_00000:
  custom_metrics:
    time_step_max: 4295
    time_step_mean: 3480.7513167795337
    time_step_min: 3166
  date: 2020-10-12_02-16-42
  done: false
  episode_len_mean: 830.9601638123604
  episode_reward_max: 291.17171717171783
  episode_reward_mean: 238.96515790819575
  episode_reward_min: 115.26262626262647
  episodes_this_iter: 258
  episodes_total: 2686
  experiment_id: d30e2e5956b043c486c44cd02ec01306
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.8657606591780981
        entropy_coeff: 0.0001
        kl: 0.010076358215883374
        model: {}
        policy_loss: -0.010343260189983994
        total_loss: 15.516786336898804
        vf_explained_var: 0.9741950035095215
        vf_loss: 15.525704781214396
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.012903225806458
    gpu_util_percent0: 0.3212903225806451
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7580645161290316
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60644
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15117197869213123
    mean_env_wait_ms: 1.1809974082136458
    mean_inference_ms: 4.6923060124445595
    mean_raw_obs_processing_ms: 0.39672541753766544
  time_since_restore: 373.76759576797485
  time_this_iter_s: 26.34594225883484
  time_total_s: 373.76759576797485
  timers:
    learn_throughput: 8280.574
    learn_time_ms: 19538.741
    sample_throughput: 23755.784
    sample_time_ms: 6810.636
    update_time_ms: 33.548
  timestamp: 1602469002
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 146c2_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_146c2_00000 | RUNNING  | 172.17.0.4:60644 |     14 |          373.768 | 2265088 |  238.965 |              291.172 |              115.263 |             830.96 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_146c2_00000:
  custom_metrics:
    time_step_max: 4295
    time_step_mean: 3473.05078125
    time_step_min: 3165
  date: 2020-10-12_02-17-08
  done: false
  episode_len_mean: 828.782700421941
  episode_reward_max: 291.17171717171783
  episode_reward_mean: 240.15767378425593
  episode_reward_min: 115.26262626262647
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: d30e2e5956b043c486c44cd02ec01306
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.8448365579048792
        entropy_coeff: 0.0001
        kl: 0.009399475374569496
        model: {}
        policy_loss: -0.012901390844490379
        total_loss: 11.107781171798706
        vf_explained_var: 0.9757277965545654
        vf_loss: 11.119357109069824
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.18666666666667
    gpu_util_percent0: 0.41233333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.786666666666667
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60644
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15096595054591466
    mean_env_wait_ms: 1.182297091806122
    mean_inference_ms: 4.67558493804877
    mean_raw_obs_processing_ms: 0.3959472486691119
  time_since_restore: 400.01290464401245
  time_this_iter_s: 26.245308876037598
  time_total_s: 400.01290464401245
  timers:
    learn_throughput: 8276.962
    learn_time_ms: 19547.269
    sample_throughput: 23754.727
    sample_time_ms: 6810.939
    update_time_ms: 36.169
  timestamp: 1602469028
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 146c2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_146c2_00000 | RUNNING  | 172.17.0.4:60644 |     15 |          400.013 | 2426880 |  240.158 |              291.172 |              115.263 |            828.783 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_146c2_00000:
  custom_metrics:
    time_step_max: 4295
    time_step_mean: 3467.120255290561
    time_step_min: 3165
  date: 2020-10-12_02-17-35
  done: false
  episode_len_mean: 827.3803660565724
  episode_reward_max: 291.17171717171783
  episode_reward_mean: 241.03628632413978
  episode_reward_min: 115.26262626262647
  episodes_this_iter: 161
  episodes_total: 3005
  experiment_id: d30e2e5956b043c486c44cd02ec01306
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.8009412189324697
        entropy_coeff: 0.0001
        kl: 0.011113404373948773
        model: {}
        policy_loss: -0.013381268101511523
        total_loss: 11.18182643254598
        vf_explained_var: 0.9785330295562744
        vf_loss: 11.193621238072714
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.06774193548388
    gpu_util_percent0: 0.34354838709677415
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.77741935483871
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60644
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15077466575020448
    mean_env_wait_ms: 1.183539512434361
    mean_inference_ms: 4.659795095705708
    mean_raw_obs_processing_ms: 0.395207712840331
  time_since_restore: 426.50918436050415
  time_this_iter_s: 26.4962797164917
  time_total_s: 426.50918436050415
  timers:
    learn_throughput: 8288.431
    learn_time_ms: 19520.22
    sample_throughput: 23725.648
    sample_time_ms: 6819.287
    update_time_ms: 34.182
  timestamp: 1602469055
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 146c2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_146c2_00000 | RUNNING  | 172.17.0.4:60644 |     16 |          426.509 | 2588672 |  241.036 |              291.172 |              115.263 |             827.38 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_146c2_00000:
  custom_metrics:
    time_step_max: 4295
    time_step_mean: 3456.4442066646284
    time_step_min: 3157
  date: 2020-10-12_02-18-01
  done: false
  episode_len_mean: 825.2437102152168
  episode_reward_max: 291.17171717171783
  episode_reward_mean: 242.57815805830342
  episode_reward_min: 115.26262626262647
  episodes_this_iter: 294
  episodes_total: 3299
  experiment_id: d30e2e5956b043c486c44cd02ec01306
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.7736713290214539
        entropy_coeff: 0.0001
        kl: 0.00988006180462738
        model: {}
        policy_loss: -0.01114709935306261
        total_loss: 13.325625658035278
        vf_explained_var: 0.9815632700920105
        vf_loss: 13.335367679595947
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.735483870967744
    gpu_util_percent0: 0.24419354838709678
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322577
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60644
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15046049752850654
    mean_env_wait_ms: 1.18554337307757
    mean_inference_ms: 4.63411155200557
    mean_raw_obs_processing_ms: 0.39401373675338947
  time_since_restore: 452.8773555755615
  time_this_iter_s: 26.368171215057373
  time_total_s: 452.8773555755615
  timers:
    learn_throughput: 8288.066
    learn_time_ms: 19521.079
    sample_throughput: 23731.385
    sample_time_ms: 6817.638
    update_time_ms: 32.544
  timestamp: 1602469081
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 146c2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_146c2_00000 | RUNNING  | 172.17.0.4:60644 |     17 |          452.877 | 2750464 |  242.578 |              291.172 |              115.263 |            825.244 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_146c2_00000:
  custom_metrics:
    time_step_max: 4295
    time_step_mean: 3449.2091067285382
    time_step_min: 3118
  date: 2020-10-12_02-18-28
  done: false
  episode_len_mean: 824.1539125431531
  episode_reward_max: 293.59595959595976
  episode_reward_mean: 243.60498250630576
  episode_reward_min: 115.26262626262647
  episodes_this_iter: 177
  episodes_total: 3476
  experiment_id: d30e2e5956b043c486c44cd02ec01306
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.7757501304149628
        entropy_coeff: 0.0001
        kl: 0.009357167485480508
        model: {}
        policy_loss: -0.01302718681593736
        total_loss: 9.470188776652018
        vf_explained_var: 0.9816890358924866
        vf_loss: 9.481890042622885
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.350000000000005
    gpu_util_percent0: 0.38266666666666665
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7799999999999994
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60644
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15029756788761747
    mean_env_wait_ms: 1.186637144406458
    mean_inference_ms: 4.620508218030654
    mean_raw_obs_processing_ms: 0.39338923622838856
  time_since_restore: 479.0531806945801
  time_this_iter_s: 26.175825119018555
  time_total_s: 479.0531806945801
  timers:
    learn_throughput: 8289.207
    learn_time_ms: 19518.393
    sample_throughput: 23738.73
    sample_time_ms: 6815.529
    update_time_ms: 30.85
  timestamp: 1602469108
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 146c2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_146c2_00000 | RUNNING  | 172.17.0.4:60644 |     18 |          479.053 | 2912256 |  243.605 |              293.596 |              115.263 |            824.154 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_146c2_00000:
  custom_metrics:
    time_step_max: 4295
    time_step_mean: 3444.390183028286
    time_step_min: 3118
  date: 2020-10-12_02-18-54
  done: false
  episode_len_mean: 823.100440286186
  episode_reward_max: 293.59595959595976
  episode_reward_mean: 244.27419211376272
  episode_reward_min: 115.26262626262647
  episodes_this_iter: 158
  episodes_total: 3634
  experiment_id: d30e2e5956b043c486c44cd02ec01306
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.7627355009317398
        entropy_coeff: 0.0001
        kl: 0.010477939698224267
        model: {}
        policy_loss: -0.011835232008403787
        total_loss: 9.512979825337728
        vf_explained_var: 0.9801586270332336
        vf_loss: 9.523319641749064
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.051612903225806
    gpu_util_percent0: 0.38677419354838705
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.777419354838709
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60644
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15016005003982755
    mean_env_wait_ms: 1.1875250237847887
    mean_inference_ms: 4.609096078945515
    mean_raw_obs_processing_ms: 0.3928582080582894
  time_since_restore: 505.45203709602356
  time_this_iter_s: 26.39885640144348
  time_total_s: 505.45203709602356
  timers:
    learn_throughput: 8290.283
    learn_time_ms: 19515.861
    sample_throughput: 23789.499
    sample_time_ms: 6800.984
    update_time_ms: 30.659
  timestamp: 1602469134
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 146c2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_146c2_00000 | RUNNING  | 172.17.0.4:60644 |     19 |          505.452 | 3074048 |  244.274 |              293.596 |              115.263 |              823.1 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_146c2_00000:
  custom_metrics:
    time_step_max: 4295
    time_step_mean: 3439.200787401575
    time_step_min: 3118
  date: 2020-10-12_02-19-21
  done: false
  episode_len_mean: 821.588066701407
  episode_reward_max: 293.59595959595976
  episode_reward_mean: 245.1153352177322
  episode_reward_min: 115.26262626262647
  episodes_this_iter: 204
  episodes_total: 3838
  experiment_id: d30e2e5956b043c486c44cd02ec01306
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.7133812109629313
        entropy_coeff: 0.0001
        kl: 0.009887449520950517
        model: {}
        policy_loss: -0.009300516840691367
        total_loss: 11.988829771677652
        vf_explained_var: 0.9805106520652771
        vf_loss: 11.996718406677246
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.529032258064518
    gpu_util_percent0: 0.38419354838709674
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.774193548387097
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60644
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14999574449579614
    mean_env_wait_ms: 1.1886322594073564
    mean_inference_ms: 4.595529113677109
    mean_raw_obs_processing_ms: 0.3922246706335287
  time_since_restore: 531.7980897426605
  time_this_iter_s: 26.346052646636963
  time_total_s: 531.7980897426605
  timers:
    learn_throughput: 8298.668
    learn_time_ms: 19496.142
    sample_throughput: 23803.715
    sample_time_ms: 6796.922
    update_time_ms: 30.932
  timestamp: 1602469161
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 146c2_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_146c2_00000 | RUNNING  | 172.17.0.4:60644 |     20 |          531.798 | 3235840 |  245.115 |              293.596 |              115.263 |            821.588 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_146c2_00000:
  custom_metrics:
    time_step_max: 4295
    time_step_mean: 3432.8288796273596
    time_step_min: 3118
  date: 2020-10-12_02-19-47
  done: false
  episode_len_mean: 820.081081081081
  episode_reward_max: 293.59595959595976
  episode_reward_mean: 246.10047885723552
  episode_reward_min: 115.26262626262647
  episodes_this_iter: 269
  episodes_total: 4107
  experiment_id: d30e2e5956b043c486c44cd02ec01306
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.710876872142156
        entropy_coeff: 0.0001
        kl: 0.007914676913060248
        model: {}
        policy_loss: -0.009737972012468768
        total_loss: 11.620576937993368
        vf_explained_var: 0.9819566607475281
        vf_loss: 11.62919839223226
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.1741935483871
    gpu_util_percent0: 0.2890322580645161
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60644
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14979717984585145
    mean_env_wait_ms: 1.1899416910417362
    mean_inference_ms: 4.579111794246008
    mean_raw_obs_processing_ms: 0.3914653020639298
  time_since_restore: 558.2689447402954
  time_this_iter_s: 26.470854997634888
  time_total_s: 558.2689447402954
  timers:
    learn_throughput: 8299.127
    learn_time_ms: 19495.062
    sample_throughput: 23844.902
    sample_time_ms: 6785.182
    update_time_ms: 29.132
  timestamp: 1602469187
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: 146c2_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_146c2_00000 | RUNNING  | 172.17.0.4:60644 |     21 |          558.269 | 3397632 |    246.1 |              293.596 |              115.263 |            820.081 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_146c2_00000:
  custom_metrics:
    time_step_max: 4295
    time_step_mean: 3429.799433695139
    time_step_min: 3118
  date: 2020-10-12_02-20-14
  done: false
  episode_len_mean: 819.3743553680263
  episode_reward_max: 293.59595959595976
  episode_reward_mean: 246.54574578414227
  episode_reward_min: 115.26262626262647
  episodes_this_iter: 159
  episodes_total: 4266
  experiment_id: d30e2e5956b043c486c44cd02ec01306
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.7184644093116125
        entropy_coeff: 0.0001
        kl: 0.008766092592850327
        model: {}
        policy_loss: -0.009706505225040019
        total_loss: 8.822493155797323
        vf_explained_var: 0.9822456240653992
        vf_loss: 8.83095637957255
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.858064516129033
    gpu_util_percent0: 0.3851612903225806
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.783870967741935
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60644
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14968998048779159
    mean_env_wait_ms: 1.1906525219151578
    mean_inference_ms: 4.570234777279137
    mean_raw_obs_processing_ms: 0.3910556314581215
  time_since_restore: 584.6503286361694
  time_this_iter_s: 26.381383895874023
  time_total_s: 584.6503286361694
  timers:
    learn_throughput: 8308.245
    learn_time_ms: 19473.668
    sample_throughput: 23850.714
    sample_time_ms: 6783.529
    update_time_ms: 28.562
  timestamp: 1602469214
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: 146c2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_146c2_00000 | RUNNING  | 172.17.0.4:60644 |     22 |           584.65 | 3559424 |  246.546 |              293.596 |              115.263 |            819.374 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_146c2_00000:
  custom_metrics:
    time_step_max: 4295
    time_step_mean: 3427.1550352352806
    time_step_min: 3118
  date: 2020-10-12_02-20-40
  done: true
  episode_len_mean: 818.8735035012423
  episode_reward_max: 293.59595959595976
  episode_reward_mean: 246.94596062271677
  episode_reward_min: 115.26262626262647
  episodes_this_iter: 161
  episodes_total: 4427
  experiment_id: d30e2e5956b043c486c44cd02ec01306
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.6874566276868185
        entropy_coeff: 0.0001
        kl: 0.010289868727947274
        model: {}
        policy_loss: -0.01128913953046625
        total_loss: 8.743628740310669
        vf_explained_var: 0.98284512758255
        vf_loss: 8.753443082173666
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.96774193548388
    gpu_util_percent0: 0.27322580645161293
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.787096774193548
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60644
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14958727966959817
    mean_env_wait_ms: 1.1913394912402813
    mean_inference_ms: 4.561720277145701
    mean_raw_obs_processing_ms: 0.39066026644114016
  time_since_restore: 611.1387591362
  time_this_iter_s: 26.488430500030518
  time_total_s: 611.1387591362
  timers:
    learn_throughput: 8302.421
    learn_time_ms: 19487.328
    sample_throughput: 23841.819
    sample_time_ms: 6786.059
    update_time_ms: 28.061
  timestamp: 1602469240
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: 146c2_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_146c2_00000 | TERMINATED |       |     23 |          611.139 | 3721216 |  246.946 |              293.596 |              115.263 |            818.874 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_146c2_00000 | TERMINATED |       |     23 |          611.139 | 3721216 |  246.946 |              293.596 |              115.263 |            818.874 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


