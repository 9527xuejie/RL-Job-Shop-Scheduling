2020-10-11 21:11:17,121	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_4e0d3_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=2390)[0m 2020-10-11 21:11:19,861	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=2299)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2299)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2315)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2315)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2313)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2313)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2310)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2310)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2300)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2300)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2330)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2330)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2435)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2435)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2426)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2426)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2421)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2421)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2425)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2425)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2436)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2436)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2442)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2442)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2383)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2383)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2388)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2388)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2411)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2411)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2404)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2404)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2329)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2329)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2334)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2334)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2305)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2305)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2400)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2400)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2424)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2424)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2379)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2379)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2370)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2370)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2354)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2354)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2415)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2415)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2372)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2372)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2423)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2423)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2427)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2427)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2309)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2309)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2307)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2307)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2355)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2355)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2381)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2381)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2296)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2296)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2306)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2306)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2369)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2369)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2311)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2311)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2325)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2325)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2359)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2359)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2302)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2302)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2389)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2389)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2335)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2335)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2391)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2391)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2316)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2316)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2380)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2380)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2399)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2399)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2297)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2297)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2356)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2356)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2318)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2318)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2385)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2385)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2418)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2418)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2373)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2373)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2314)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2314)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2430)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2430)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2386)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2386)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2317)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2317)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2396)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2396)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2397)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2397)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2395)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2395)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2363)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2363)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2382)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2382)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2321)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2321)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2304)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2304)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2301)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2301)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2367)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2367)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2353)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2353)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2410)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2410)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2368)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2368)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2392)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2392)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2412)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2412)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2407)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2407)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2327)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2327)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2374)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2374)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2394)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2394)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2303)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2303)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2366)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2366)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2319)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2319)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2384)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2384)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2320)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2320)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2298)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2298)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_4e0d3_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-11_21-12-00
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: bb40daaea7b24087b28e042faef756ce
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1834782163302104
        entropy_coeff: 0.0005000000000000001
        kl: 0.005450233196218808
        model: {}
        policy_loss: -0.012348305531001339
        total_loss: 500.4124577840169
        vf_explained_var: 0.5819632411003113
        vf_loss: 500.42430623372394
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.15952380952381
    gpu_util_percent0: 0.3147619047619048
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5880952380952373
    vram_util_percent0: 0.08979915350856645
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2390
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17118135401038853
    mean_env_wait_ms: 1.1786042455170913
    mean_inference_ms: 5.931247147044564
    mean_raw_obs_processing_ms: 0.45872927080079623
  time_since_restore: 35.601897954940796
  time_this_iter_s: 35.601897954940796
  time_total_s: 35.601897954940796
  timers:
    learn_throughput: 6153.016
    learn_time_ms: 26294.747
    sample_throughput: 17548.067
    sample_time_ms: 9219.933
    update_time_ms: 48.196
  timestamp: 1602450720
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 4e0d3_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4e0d3_00000 | RUNNING  | 172.17.0.4:2390 |      1 |          35.6019 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4e0d3_00000:
  custom_metrics:
    time_step_max: 4215
    time_step_mean: 3627.2569444444443
    time_step_min: 3265
  date: 2020-10-11_21-12-34
  done: false
  episode_len_mean: 889.7816455696203
  episode_reward_max: 271.3232323232321
  episode_reward_mean: 215.7435430251884
  episode_reward_min: 127.38383838383837
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: bb40daaea7b24087b28e042faef756ce
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1532205839951832
        entropy_coeff: 0.0005000000000000001
        kl: 0.00651532089492927
        model: {}
        policy_loss: -0.014753414473185936
        total_loss: 122.24552790323894
        vf_explained_var: 0.8262148499488831
        vf_loss: 122.25955390930176
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.189999999999998
    gpu_util_percent0: 0.4154999999999999
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7650000000000006
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2390
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1663033800390727
    mean_env_wait_ms: 1.1731501176828507
    mean_inference_ms: 5.644243109665905
    mean_raw_obs_processing_ms: 0.4458257825989053
  time_since_restore: 69.29539632797241
  time_this_iter_s: 33.693498373031616
  time_total_s: 69.29539632797241
  timers:
    learn_throughput: 6180.882
    learn_time_ms: 26176.2
    sample_throughput: 19282.535
    sample_time_ms: 8390.598
    update_time_ms: 38.825
  timestamp: 1602450754
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 4e0d3_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4e0d3_00000 | RUNNING  | 172.17.0.4:2390 |      2 |          69.2954 | 323584 |  215.744 |              271.323 |              127.384 |            889.782 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4e0d3_00000:
  custom_metrics:
    time_step_max: 4215
    time_step_mean: 3620.8677130044844
    time_step_min: 3265
  date: 2020-10-11_21-13-07
  done: false
  episode_len_mean: 887.8333333333334
  episode_reward_max: 271.3232323232321
  episode_reward_mean: 217.12172356476134
  episode_reward_min: 124.2020202020202
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: bb40daaea7b24087b28e042faef756ce
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1451842188835144
        entropy_coeff: 0.0005000000000000001
        kl: 0.007286908105015755
        model: {}
        policy_loss: -0.014900553832073152
        total_loss: 49.43164857228597
        vf_explained_var: 0.9139183163642883
        vf_loss: 49.44566345214844
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.594871794871796
    gpu_util_percent0: 0.3179487179487181
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.779487179487181
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2390
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1632367946842115
    mean_env_wait_ms: 1.1705491767214522
    mean_inference_ms: 5.437767367842325
    mean_raw_obs_processing_ms: 0.43660112432807324
  time_since_restore: 102.65822386741638
  time_this_iter_s: 33.36282753944397
  time_total_s: 102.65822386741638
  timers:
    learn_throughput: 6188.191
    learn_time_ms: 26145.281
    sample_throughput: 20250.827
    sample_time_ms: 7989.402
    update_time_ms: 40.841
  timestamp: 1602450787
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 4e0d3_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4e0d3_00000 | RUNNING  | 172.17.0.4:2390 |      3 |          102.658 | 485376 |  217.122 |              271.323 |              124.202 |            887.833 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4e0d3_00000:
  custom_metrics:
    time_step_max: 4215
    time_step_mean: 3619.958609271523
    time_step_min: 3265
  date: 2020-10-11_21-13-41
  done: false
  episode_len_mean: 887.3338607594936
  episode_reward_max: 271.3232323232321
  episode_reward_mean: 217.7432073903591
  episode_reward_min: 124.2020202020202
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: bb40daaea7b24087b28e042faef756ce
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1234834392865498
        entropy_coeff: 0.0005000000000000001
        kl: 0.00805987739780297
        model: {}
        policy_loss: -0.018223056142839294
        total_loss: 30.2487309773763
        vf_explained_var: 0.9477844834327698
        vf_loss: 30.26590347290039
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.082051282051278
    gpu_util_percent0: 0.47692307692307695
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7769230769230786
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2390
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16103655968317182
    mean_env_wait_ms: 1.1686517146923199
    mean_inference_ms: 5.28806928329759
    mean_raw_obs_processing_ms: 0.4294440452294954
  time_since_restore: 135.9769332408905
  time_this_iter_s: 33.31870937347412
  time_total_s: 135.9769332408905
  timers:
    learn_throughput: 6181.04
    learn_time_ms: 26175.532
    sample_throughput: 20921.5
    sample_time_ms: 7733.289
    update_time_ms: 39.544
  timestamp: 1602450821
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 4e0d3_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4e0d3_00000 | RUNNING  | 172.17.0.4:2390 |      4 |          135.977 | 647168 |  217.743 |              271.323 |              124.202 |            887.334 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4e0d3_00000:
  custom_metrics:
    time_step_max: 4215
    time_step_mean: 3610.6246719160104
    time_step_min: 3265
  date: 2020-10-11_21-14-14
  done: false
  episode_len_mean: 886.0367088607595
  episode_reward_max: 271.3232323232321
  episode_reward_mean: 219.32841068917003
  episode_reward_min: 124.2020202020202
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: bb40daaea7b24087b28e042faef756ce
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.100940187772115
        entropy_coeff: 0.0005000000000000001
        kl: 0.008441201954459151
        model: {}
        policy_loss: -0.01878263708204031
        total_loss: 21.739087263743084
        vf_explained_var: 0.9610204696655273
        vf_loss: 21.756731510162354
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.900000000000002
    gpu_util_percent0: 0.4125641025641026
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7769230769230786
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2390
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15940612338721055
    mean_env_wait_ms: 1.1675757165036136
    mean_inference_ms: 5.175922484119961
    mean_raw_obs_processing_ms: 0.42384521417205373
  time_since_restore: 169.10606598854065
  time_this_iter_s: 33.12913274765015
  time_total_s: 169.10606598854065
  timers:
    learn_throughput: 6181.305
    learn_time_ms: 26174.41
    sample_throughput: 21399.852
    sample_time_ms: 7560.426
    update_time_ms: 39.346
  timestamp: 1602450854
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 4e0d3_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4e0d3_00000 | RUNNING  | 172.17.0.4:2390 |      5 |          169.106 | 808960 |  219.328 |              271.323 |              124.202 |            886.037 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4e0d3_00000:
  custom_metrics:
    time_step_max: 4215
    time_step_mean: 3603.0840932117526
    time_step_min: 3265
  date: 2020-10-11_21-14-47
  done: false
  episode_len_mean: 881.0512315270936
  episode_reward_max: 271.3232323232321
  episode_reward_mean: 220.69701945563997
  episode_reward_min: 124.2020202020202
  episodes_this_iter: 225
  episodes_total: 1015
  experiment_id: bb40daaea7b24087b28e042faef756ce
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.076224555571874
        entropy_coeff: 0.0005000000000000001
        kl: 0.007460776677665611
        model: {}
        policy_loss: -0.016307687774921458
        total_loss: 27.543621222178142
        vf_explained_var: 0.9671977162361145
        vf_loss: 27.558974742889404
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.769230769230774
    gpu_util_percent0: 0.46051282051282055
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7692307692307705
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2390
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1577070660300381
    mean_env_wait_ms: 1.1681990029730591
    mean_inference_ms: 5.058644647695779
    mean_raw_obs_processing_ms: 0.41801270575458466
  time_since_restore: 202.02227687835693
  time_this_iter_s: 32.916210889816284
  time_total_s: 202.02227687835693
  timers:
    learn_throughput: 6190.649
    learn_time_ms: 26134.899
    sample_throughput: 21717.564
    sample_time_ms: 7449.823
    update_time_ms: 38.384
  timestamp: 1602450887
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 4e0d3_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4e0d3_00000 | RUNNING  | 172.17.0.4:2390 |      6 |          202.022 | 970752 |  220.697 |              271.323 |              124.202 |            881.051 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4e0d3_00000:
  custom_metrics:
    time_step_max: 4215
    time_step_mean: 3590.42071197411
    time_step_min: 3240
  date: 2020-10-11_21-15-20
  done: false
  episode_len_mean: 874.9580696202531
  episode_reward_max: 275.111111111111
  episode_reward_mean: 222.4549210459019
  episode_reward_min: 114.80808080808109
  episodes_this_iter: 249
  episodes_total: 1264
  experiment_id: bb40daaea7b24087b28e042faef756ce
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.093416005373001
        entropy_coeff: 0.0005000000000000001
        kl: 0.00687856285367161
        model: {}
        policy_loss: -0.015096418074487397
        total_loss: 24.571438630421955
        vf_explained_var: 0.9645304083824158
        vf_loss: 24.585705757141113
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.133333333333333
    gpu_util_percent0: 0.3166666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.774358974358976
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2390
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15633001713068923
    mean_env_wait_ms: 1.168949958188231
    mean_inference_ms: 4.96688572917076
    mean_raw_obs_processing_ms: 0.4133745127485802
  time_since_restore: 235.00784134864807
  time_this_iter_s: 32.98556447029114
  time_total_s: 235.00784134864807
  timers:
    learn_throughput: 6198.005
    learn_time_ms: 26103.882
    sample_throughput: 21945.881
    sample_time_ms: 7372.317
    update_time_ms: 46.263
  timestamp: 1602450920
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 4e0d3_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4e0d3_00000 | RUNNING  | 172.17.0.4:2390 |      7 |          235.008 | 1132544 |  222.455 |              275.111 |              114.808 |            874.958 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4e0d3_00000:
  custom_metrics:
    time_step_max: 4215
    time_step_mean: 3580.045193687231
    time_step_min: 3240
  date: 2020-10-11_21-15-53
  done: false
  episode_len_mean: 870.4261603375527
  episode_reward_max: 275.111111111111
  episode_reward_mean: 224.1207219878104
  episode_reward_min: 114.80808080808109
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: bb40daaea7b24087b28e042faef756ce
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0746860106786091
        entropy_coeff: 0.0005000000000000001
        kl: 0.007217892251598339
        model: {}
        policy_loss: -0.01697918912395835
        total_loss: 15.271596829096476
        vf_explained_var: 0.9722073078155518
        vf_loss: 15.287669658660889
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.22368421052632
    gpu_util_percent0: 0.37815789473684214
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.792105263157896
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2390
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15564405033304246
    mean_env_wait_ms: 1.1697164570126461
    mean_inference_ms: 4.920305483532206
    mean_raw_obs_processing_ms: 0.41101655772612666
  time_since_restore: 268.08834886550903
  time_this_iter_s: 33.08050751686096
  time_total_s: 268.08834886550903
  timers:
    learn_throughput: 6195.83
    learn_time_ms: 26113.048
    sample_throughput: 22149.568
    sample_time_ms: 7304.522
    update_time_ms: 43.282
  timestamp: 1602450953
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 4e0d3_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4e0d3_00000 | RUNNING  | 172.17.0.4:2390 |      8 |          268.088 | 1294336 |  224.121 |              275.111 |              114.808 |            870.426 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4e0d3_00000:
  custom_metrics:
    time_step_max: 4215
    time_step_mean: 3571.490979381443
    time_step_min: 3240
  date: 2020-10-11_21-16-26
  done: false
  episode_len_mean: 865.8310126582278
  episode_reward_max: 275.111111111111
  episode_reward_mean: 225.52202403784665
  episode_reward_min: 114.80808080808109
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: bb40daaea7b24087b28e042faef756ce
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0543301304181416
        entropy_coeff: 0.0005000000000000001
        kl: 0.00745489871284614
        model: {}
        policy_loss: -0.01722554819813619
        total_loss: 14.631956020991007
        vf_explained_var: 0.9727703928947449
        vf_loss: 14.64821751912435
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.76923076923077
    gpu_util_percent0: 0.33615384615384614
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7820512820512837
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2390
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15504989799044774
    mean_env_wait_ms: 1.1706097424738302
    mean_inference_ms: 4.879743494498178
    mean_raw_obs_processing_ms: 0.4089020805322228
  time_since_restore: 300.85775089263916
  time_this_iter_s: 32.76940202713013
  time_total_s: 300.85775089263916
  timers:
    learn_throughput: 6204.55
    learn_time_ms: 26076.347
    sample_throughput: 22310.484
    sample_time_ms: 7251.837
    update_time_ms: 49.906
  timestamp: 1602450986
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 4e0d3_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4e0d3_00000 | RUNNING  | 172.17.0.4:2390 |      9 |          300.858 | 1456128 |  225.522 |              275.111 |              114.808 |            865.831 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4e0d3_00000:
  custom_metrics:
    time_step_max: 4215
    time_step_mean: 3559.12795389049
    time_step_min: 3214
  date: 2020-10-11_21-16-59
  done: false
  episode_len_mean: 860.9398752127056
  episode_reward_max: 281.32323232323233
  episode_reward_mean: 227.49049198737214
  episode_reward_min: 114.80808080808109
  episodes_this_iter: 183
  episodes_total: 1763
  experiment_id: bb40daaea7b24087b28e042faef756ce
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0162923336029053
        entropy_coeff: 0.0005000000000000001
        kl: 0.007199493198034664
        model: {}
        policy_loss: -0.017276054092993338
        total_loss: 17.092223167419434
        vf_explained_var: 0.9744090437889099
        vf_loss: 17.10856819152832
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.233333333333334
    gpu_util_percent0: 0.3802564102564103
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7743589743589756
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2390
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1544513430873049
    mean_env_wait_ms: 1.171940001610024
    mean_inference_ms: 4.838594423716003
    mean_raw_obs_processing_ms: 0.4067198509076306
  time_since_restore: 333.9221203327179
  time_this_iter_s: 33.064369440078735
  time_total_s: 333.9221203327179
  timers:
    learn_throughput: 6202.998
    learn_time_ms: 26082.872
    sample_throughput: 22443.527
    sample_time_ms: 7208.849
    update_time_ms: 50.066
  timestamp: 1602451019
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 4e0d3_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4e0d3_00000 | RUNNING  | 172.17.0.4:2390 |     10 |          333.922 | 1617920 |   227.49 |              281.323 |              114.808 |             860.94 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4e0d3_00000:
  custom_metrics:
    time_step_max: 4215
    time_step_mean: 3541.0365432098765
    time_step_min: 3189
  date: 2020-10-11_21-17-33
  done: false
  episode_len_mean: 854.2016561130054
  episode_reward_max: 286.02020202020174
  episode_reward_mean: 230.1733260515529
  episode_reward_min: 114.80808080808109
  episodes_this_iter: 290
  episodes_total: 2053
  experiment_id: bb40daaea7b24087b28e042faef756ce
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0203609863917034
        entropy_coeff: 0.0005000000000000001
        kl: 0.007031675234126548
        model: {}
        policy_loss: -0.015606618457240984
        total_loss: 17.252197265625
        vf_explained_var: 0.9748867154121399
        vf_loss: 17.266907215118408
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.912820512820506
    gpu_util_percent0: 0.34717948717948716
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.771794871794873
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2390
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1536726680328088
    mean_env_wait_ms: 1.1739607078496694
    mean_inference_ms: 4.786009161972564
    mean_raw_obs_processing_ms: 0.40397271370698284
  time_since_restore: 367.3825452327728
  time_this_iter_s: 33.46042490005493
  time_total_s: 367.3825452327728
  timers:
    learn_throughput: 6203.798
    learn_time_ms: 26079.506
    sample_throughput: 23126.739
    sample_time_ms: 6995.885
    update_time_ms: 48.985
  timestamp: 1602451053
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 4e0d3_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4e0d3_00000 | RUNNING  | 172.17.0.4:2390 |     11 |          367.383 | 1779712 |  230.173 |               286.02 |              114.808 |            854.202 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4e0d3_00000:
  custom_metrics:
    time_step_max: 4215
    time_step_mean: 3530.9496336996335
    time_step_min: 3189
  date: 2020-10-11_21-18-06
  done: false
  episode_len_mean: 851.1541591320072
  episode_reward_max: 286.02020202020174
  episode_reward_mean: 231.51933895921223
  episode_reward_min: 114.80808080808109
  episodes_this_iter: 159
  episodes_total: 2212
  experiment_id: bb40daaea7b24087b28e042faef756ce
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0036945939064026
        entropy_coeff: 0.0005000000000000001
        kl: 0.006985259979652862
        model: {}
        policy_loss: -0.019222625220815342
        total_loss: 10.966131846110025
        vf_explained_var: 0.9790888428688049
        vf_loss: 10.984459320704142
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.62820512820513
    gpu_util_percent0: 0.3894871794871794
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7820512820512837
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2390
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15331806662210512
    mean_env_wait_ms: 1.174970966092855
    mean_inference_ms: 4.761678248936953
    mean_raw_obs_processing_ms: 0.4026853975805055
  time_since_restore: 400.9347970485687
  time_this_iter_s: 33.5522518157959
  time_total_s: 400.9347970485687
  timers:
    learn_throughput: 6199.537
    learn_time_ms: 26097.432
    sample_throughput: 23238.418
    sample_time_ms: 6962.264
    update_time_ms: 49.747
  timestamp: 1602451086
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 4e0d3_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4e0d3_00000 | RUNNING  | 172.17.0.4:2390 |     12 |          400.935 | 1941504 |  231.519 |               286.02 |              114.808 |            851.154 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4e0d3_00000:
  custom_metrics:
    time_step_max: 4215
    time_step_mean: 3523.6319385140905
    time_step_min: 3187
  date: 2020-10-11_21-18-40
  done: false
  episode_len_mean: 848.3793248945148
  episode_reward_max: 290.1111111111111
  episode_reward_mean: 232.63546861015203
  episode_reward_min: 114.80808080808109
  episodes_this_iter: 158
  episodes_total: 2370
  experiment_id: bb40daaea7b24087b28e042faef756ce
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.978306328256925
        entropy_coeff: 0.0005000000000000001
        kl: 0.007045298969993989
        model: {}
        policy_loss: -0.015602520977457365
        total_loss: 11.583065032958984
        vf_explained_var: 0.9771708846092224
        vf_loss: 11.597747484842936
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.887179487179488
    gpu_util_percent0: 0.3371794871794872
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7820512820512837
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2390
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15299626029240684
    mean_env_wait_ms: 1.1759545287317261
    mean_inference_ms: 4.739655178578946
    mean_raw_obs_processing_ms: 0.40150315048926494
  time_since_restore: 434.028032541275
  time_this_iter_s: 33.0932354927063
  time_total_s: 434.028032541275
  timers:
    learn_throughput: 6199.561
    learn_time_ms: 26097.333
    sample_throughput: 23327.28
    sample_time_ms: 6935.742
    update_time_ms: 48.662
  timestamp: 1602451120
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 4e0d3_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4e0d3_00000 | RUNNING  | 172.17.0.4:2390 |     13 |          434.028 | 2103296 |  232.635 |              290.111 |              114.808 |            848.379 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4e0d3_00000:
  custom_metrics:
    time_step_max: 4215
    time_step_mean: 3513.942255169723
    time_step_min: 3187
  date: 2020-10-11_21-19-13
  done: false
  episode_len_mean: 845.4839830181397
  episode_reward_max: 290.1111111111111
  episode_reward_mean: 234.1447707487845
  episode_reward_min: 114.80808080808109
  episodes_this_iter: 221
  episodes_total: 2591
  experiment_id: bb40daaea7b24087b28e042faef756ce
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9443453152974447
        entropy_coeff: 0.0005000000000000001
        kl: 0.0069051772976915044
        model: {}
        policy_loss: -0.01734935666900128
        total_loss: 12.825620969136557
        vf_explained_var: 0.9817320704460144
        vf_loss: 12.842061599095663
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.92051282051282
    gpu_util_percent0: 0.32384615384615384
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.771794871794873
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2390
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1526029037310122
    mean_env_wait_ms: 1.1773721365996777
    mean_inference_ms: 4.712068471214295
    mean_raw_obs_processing_ms: 0.400044797583596
  time_since_restore: 467.1130690574646
  time_this_iter_s: 33.085036516189575
  time_total_s: 467.1130690574646
  timers:
    learn_throughput: 6204.976
    learn_time_ms: 26074.555
    sample_throughput: 23330.081
    sample_time_ms: 6934.91
    update_time_ms: 48.625
  timestamp: 1602451153
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 4e0d3_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4e0d3_00000 | RUNNING  | 172.17.0.4:2390 |     14 |          467.113 | 2265088 |  234.145 |              290.111 |              114.808 |            845.484 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4e0d3_00000:
  custom_metrics:
    time_step_max: 4215
    time_step_mean: 3504.7882770870337
    time_step_min: 3187
  date: 2020-10-11_21-19-46
  done: false
  episode_len_mean: 843.1241646148435
  episode_reward_max: 290.1111111111111
  episode_reward_mean: 235.56576315387414
  episode_reward_min: 114.80808080808109
  episodes_this_iter: 252
  episodes_total: 2843
  experiment_id: bb40daaea7b24087b28e042faef756ce
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9510692656040192
        entropy_coeff: 0.0005000000000000001
        kl: 0.0065308528719469905
        model: {}
        policy_loss: -0.0151393340170074
        total_loss: 10.94356632232666
        vf_explained_var: 0.9831051826477051
        vf_loss: 10.95787501335144
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.297368421052635
    gpu_util_percent0: 0.40026315789473677
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.776315789473685
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2390
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15219649191012313
    mean_env_wait_ms: 1.1786318472713437
    mean_inference_ms: 4.684996201420214
    mean_raw_obs_processing_ms: 0.39861966296227497
  time_since_restore: 499.88459610939026
  time_this_iter_s: 32.77152705192566
  time_total_s: 499.88459610939026
  timers:
    learn_throughput: 6213.471
    learn_time_ms: 26038.91
    sample_throughput: 23325.773
    sample_time_ms: 6936.19
    update_time_ms: 46.707
  timestamp: 1602451186
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 4e0d3_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4e0d3_00000 | RUNNING  | 172.17.0.4:2390 |     15 |          499.885 | 2426880 |  235.566 |              290.111 |              114.808 |            843.124 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4e0d3_00000:
  custom_metrics:
    time_step_max: 4215
    time_step_mean: 3499.098520511096
    time_step_min: 3187
  date: 2020-10-11_21-20-19
  done: false
  episode_len_mean: 841.4287141905396
  episode_reward_max: 290.1111111111111
  episode_reward_mean: 236.4645522513609
  episode_reward_min: 114.80808080808109
  episodes_this_iter: 159
  episodes_total: 3002
  experiment_id: bb40daaea7b24087b28e042faef756ce
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9330631593863169
        entropy_coeff: 0.0005000000000000001
        kl: 0.0071928702139606076
        model: {}
        policy_loss: -0.018368869825887185
        total_loss: 9.227545579274496
        vf_explained_var: 0.9822835326194763
        vf_loss: 9.244942506154379
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.451282051282053
    gpu_util_percent0: 0.3817948717948718
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7820512820512837
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2390
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15197570175343136
    mean_env_wait_ms: 1.1794237719123415
    mean_inference_ms: 4.669755506000374
    mean_raw_obs_processing_ms: 0.3978231917945697
  time_since_restore: 532.9027814865112
  time_this_iter_s: 33.01818537712097
  time_total_s: 532.9027814865112
  timers:
    learn_throughput: 6212.884
    learn_time_ms: 26041.367
    sample_throughput: 23308.965
    sample_time_ms: 6941.192
    update_time_ms: 47.352
  timestamp: 1602451219
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 4e0d3_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4e0d3_00000 | RUNNING  | 172.17.0.4:2390 |     16 |          532.903 | 2588672 |  236.465 |              290.111 |              114.808 |            841.429 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4e0d3_00000:
  custom_metrics:
    time_step_max: 4215
    time_step_mean: 3493.5842911877394
    time_step_min: 3187
  date: 2020-10-11_21-20-52
  done: false
  episode_len_mean: 839.576582278481
  episode_reward_max: 290.1111111111111
  episode_reward_mean: 237.306834164429
  episode_reward_min: 114.80808080808109
  episodes_this_iter: 158
  episodes_total: 3160
  experiment_id: bb40daaea7b24087b28e042faef756ce
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9116851836442947
        entropy_coeff: 0.0005000000000000001
        kl: 0.006816590709301333
        model: {}
        policy_loss: -0.017743770265951753
        total_loss: 8.511868317921957
        vf_explained_var: 0.9828870296478271
        vf_loss: 8.528704722722372
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.99736842105263
    gpu_util_percent0: 0.4515789473684211
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7842105263157904
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2390
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15177228066003093
    mean_env_wait_ms: 1.180184174022614
    mean_inference_ms: 4.655634129096994
    mean_raw_obs_processing_ms: 0.3970760047500777
  time_since_restore: 565.779746055603
  time_this_iter_s: 32.8769645690918
  time_total_s: 565.779746055603
  timers:
    learn_throughput: 6214.021
    learn_time_ms: 26036.602
    sample_throughput: 23314.271
    sample_time_ms: 6939.612
    update_time_ms: 41.954
  timestamp: 1602451252
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 4e0d3_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4e0d3_00000 | RUNNING  | 172.17.0.4:2390 |     17 |           565.78 | 2750464 |  237.307 |              290.111 |              114.808 |            839.577 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4e0d3_00000:
  custom_metrics:
    time_step_max: 4215
    time_step_mean: 3484.3188918361334
    time_step_min: 3164
  date: 2020-10-11_21-21-25
  done: false
  episode_len_mean: 836.879859690149
  episode_reward_max: 290.1111111111111
  episode_reward_mean: 238.66429864266743
  episode_reward_min: 114.80808080808109
  episodes_this_iter: 261
  episodes_total: 3421
  experiment_id: bb40daaea7b24087b28e042faef756ce
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8799512734015783
        entropy_coeff: 0.0005000000000000001
        kl: 0.00669806570901225
        model: {}
        policy_loss: -0.016116968162047367
        total_loss: 11.224719365437826
        vf_explained_var: 0.984184205532074
        vf_loss: 11.239936908086142
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.843589743589746
    gpu_util_percent0: 0.4776923076923076
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.771794871794873
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2390
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15147744499620833
    mean_env_wait_ms: 1.1814476052384753
    mean_inference_ms: 4.634558823060062
    mean_raw_obs_processing_ms: 0.3959795588753821
  time_since_restore: 598.469691991806
  time_this_iter_s: 32.689945936203
  time_total_s: 598.469691991806
  timers:
    learn_throughput: 6224.434
    learn_time_ms: 25993.044
    sample_throughput: 23307.112
    sample_time_ms: 6941.744
    update_time_ms: 43.596
  timestamp: 1602451285
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 4e0d3_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4e0d3_00000 | RUNNING  | 172.17.0.4:2390 |     18 |           598.47 | 2912256 |  238.664 |              290.111 |              114.808 |             836.88 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4e0d3_00000:
  custom_metrics:
    time_step_max: 4215
    time_step_mean: 3477.0257903494175
    time_step_min: 3164
  date: 2020-10-11_21-21-58
  done: true
  episode_len_mean: 835.062740781508
  episode_reward_max: 290.1111111111111
  episode_reward_mean: 239.63792854244136
  episode_reward_min: 114.80808080808109
  episodes_this_iter: 213
  episodes_total: 3634
  experiment_id: bb40daaea7b24087b28e042faef756ce
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8765399307012558
        entropy_coeff: 0.0005000000000000001
        kl: 0.006519439009328683
        model: {}
        policy_loss: -0.016516351684307057
        total_loss: 8.11694081624349
        vf_explained_var: 0.9860876202583313
        vf_loss: 8.132591565450033
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.810256410256407
    gpu_util_percent0: 0.418974358974359
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7743589743589756
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2390
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15124417535660867
    mean_env_wait_ms: 1.1823381606087513
    mean_inference_ms: 4.619093261989014
    mean_raw_obs_processing_ms: 0.39516660540308013
  time_since_restore: 631.5619533061981
  time_this_iter_s: 33.09226131439209
  time_total_s: 631.5619533061981
  timers:
    learn_throughput: 6221.133
    learn_time_ms: 26006.837
    sample_throughput: 23225.65
    sample_time_ms: 6966.091
    update_time_ms: 37.179
  timestamp: 1602451318
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 4e0d3_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4e0d3_00000 | TERMINATED |       |     19 |          631.562 | 3074048 |  239.638 |              290.111 |              114.808 |            835.063 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4e0d3_00000 | TERMINATED |       |     19 |          631.562 | 3074048 |  239.638 |              290.111 |              114.808 |            835.063 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


