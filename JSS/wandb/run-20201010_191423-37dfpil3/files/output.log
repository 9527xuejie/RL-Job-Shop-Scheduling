2020-10-10 19:14:25,350	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8266[39m[22m
== Status ==
Memory usage on this node: 32.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_d05a3_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=53557)[0m 2020-10-10 19:14:28,340	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=53414)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53414)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53507)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53507)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53411)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53411)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53434)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53434)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53419)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53419)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53427)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53427)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53535)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53535)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53526)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53526)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53512)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53512)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53490)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53490)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53547)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53547)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53415)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53415)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53424)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53424)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53412)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53412)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53442)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53442)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53436)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53436)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53520)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53520)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53497)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53497)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53508)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53508)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53549)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53549)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53509)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53509)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53426)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53426)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53494)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53494)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53466)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53466)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53479)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53479)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53453)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53453)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53418)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53418)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53522)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53522)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53480)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53480)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53493)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53493)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53423)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53423)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53514)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53514)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53529)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53529)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53504)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53504)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53551)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53551)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53517)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53517)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53501)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53501)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53495)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53495)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53541)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53541)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53421)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53421)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53473)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53473)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53498)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53498)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53491)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53491)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53492)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53492)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53543)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53543)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53417)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53417)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53446)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53446)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53437)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53437)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53450)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53450)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53425)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53425)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53532)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53532)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53472)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53472)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53413)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53413)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53499)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53499)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53496)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53496)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53511)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53511)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53483)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53483)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53486)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53486)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53505)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53505)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53428)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53428)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53444)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53444)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53489)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53489)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53416)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53416)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53524)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53524)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53451)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53451)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53431)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53431)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53474)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53474)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53468)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53468)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53454)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53454)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53470)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53470)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53488)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53488)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53485)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53485)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53440)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53440)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53475)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53475)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53487)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53487)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53429)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53429)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53447)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53447)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53500)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53500)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53516)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53516)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_d05a3_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-10_19-15-11
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 90ee05a92d64410d9ca45cc29b0d3a12
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.1838872517858232
        entropy_coeff: 0.00010000000000000002
        kl: 0.005071878599535141
        model: {}
        policy_loss: -0.010430979448886189
        total_loss: 9.354604721069336
        vf_explained_var: 0.7688503861427307
        vf_loss: 9.364139488765172
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.318181818181824
    gpu_util_percent0: 0.4229545454545455
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.00022727272727272727
    ram_util_percent: 6.295454545454543
    vram_util_percent0: 0.1927084886251826
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 53557
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16958863251589817
    mean_env_wait_ms: 1.1978660817866194
    mean_inference_ms: 6.043269362630725
    mean_raw_obs_processing_ms: 0.46018875760404954
  time_since_restore: 37.894644021987915
  time_this_iter_s: 37.894644021987915
  time_total_s: 37.894644021987915
  timers:
    learn_throughput: 5763.464
    learn_time_ms: 28072.006
    sample_throughput: 16589.586
    sample_time_ms: 9752.625
    update_time_ms: 24.003
  timestamp: 1602357311
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: d05a3_00000
  
== Status ==
Memory usage on this node: 48.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d05a3_00000 | RUNNING  | 172.17.0.4:53557 |      1 |          37.8946 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d05a3_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3607.2638888888887
    time_step_min: 3346
  date: 2020-10-10_19-15-47
  done: false
  episode_len_mean: 885.1455696202531
  episode_reward_max: 265.56565656565635
  episode_reward_mean: 218.57869837616656
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 90ee05a92d64410d9ca45cc29b0d3a12
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.1548707059451513
        entropy_coeff: 0.00010000000000000002
        kl: 0.006195763691461512
        model: {}
        policy_loss: -0.013239473736445819
        total_loss: 7.16602407182966
        vf_explained_var: 0.9064614176750183
        vf_loss: 7.178139890943255
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.51190476190476
    gpu_util_percent0: 0.2692857142857143
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.473809523809525
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 53557
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1657161523496913
    mean_env_wait_ms: 1.1952132838168137
    mean_inference_ms: 5.74624193146175
    mean_raw_obs_processing_ms: 0.4501763788322658
  time_since_restore: 73.39492559432983
  time_this_iter_s: 35.50028157234192
  time_total_s: 73.39492559432983
  timers:
    learn_throughput: 5814.722
    learn_time_ms: 27824.544
    sample_throughput: 18392.829
    sample_time_ms: 8796.472
    update_time_ms: 30.1
  timestamp: 1602357347
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: d05a3_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d05a3_00000 | RUNNING  | 172.17.0.4:53557 |      2 |          73.3949 | 323584 |  218.579 |              265.566 |              145.717 |            885.146 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d05a3_00000:
  custom_metrics:
    time_step_max: 4104
    time_step_mean: 3610.5044843049327
    time_step_min: 3282
  date: 2020-10-10_19-16-23
  done: false
  episode_len_mean: 878.2383966244726
  episode_reward_max: 274.05050505050457
  episode_reward_mean: 218.78327579593383
  episode_reward_min: 144.20202020202007
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 90ee05a92d64410d9ca45cc29b0d3a12
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.1422560470444816
        entropy_coeff: 0.00010000000000000002
        kl: 0.006820661614515952
        model: {}
        policy_loss: -0.015991192976278917
        total_loss: 7.054318768637521
        vf_explained_var: 0.947256863117218
        vf_loss: 7.069060257502964
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.69761904761905
    gpu_util_percent0: 0.24238095238095236
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.490476190476191
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 53557
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16339416814616697
    mean_env_wait_ms: 1.1954913562254077
    mean_inference_ms: 5.546202147639198
    mean_raw_obs_processing_ms: 0.4433541764598823
  time_since_restore: 109.01514720916748
  time_this_iter_s: 35.62022161483765
  time_total_s: 109.01514720916748
  timers:
    learn_throughput: 5802.063
    learn_time_ms: 27885.254
    sample_throughput: 19319.947
    sample_time_ms: 8374.35
    update_time_ms: 31.493
  timestamp: 1602357383
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: d05a3_00000
  
== Status ==
Memory usage on this node: 48.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d05a3_00000 | RUNNING  | 172.17.0.4:53557 |      3 |          109.015 | 485376 |  218.783 |              274.051 |              144.202 |            878.238 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d05a3_00000:
  custom_metrics:
    time_step_max: 4104
    time_step_mean: 3611.019867549669
    time_step_min: 3282
  date: 2020-10-10_19-16-58
  done: false
  episode_len_mean: 870.618670886076
  episode_reward_max: 274.05050505050457
  episode_reward_mean: 219.2420566423729
  episode_reward_min: 144.20202020202007
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 90ee05a92d64410d9ca45cc29b0d3a12
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.1182554364204407
        entropy_coeff: 0.00010000000000000002
        kl: 0.006509668426588178
        model: {}
        policy_loss: -0.015292617459116238
        total_loss: 7.162050553730556
        vf_explained_var: 0.9640932679176331
        vf_loss: 7.176153114863804
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.295238095238094
    gpu_util_percent0: 0.2909523809523809
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4833333333333325
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 53557
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16170666867921793
    mean_env_wait_ms: 1.197023103902059
    mean_inference_ms: 5.403042671598118
    mean_raw_obs_processing_ms: 0.43781975620732927
  time_since_restore: 144.2099893093109
  time_this_iter_s: 35.19484210014343
  time_total_s: 144.2099893093109
  timers:
    learn_throughput: 5813.217
    learn_time_ms: 27831.751
    sample_throughput: 19872.683
    sample_time_ms: 8141.427
    update_time_ms: 31.334
  timestamp: 1602357418
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: d05a3_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d05a3_00000 | RUNNING  | 172.17.0.4:53557 |      4 |           144.21 | 647168 |  219.242 |              274.051 |              144.202 |            870.619 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d05a3_00000:
  custom_metrics:
    time_step_max: 4104
    time_step_mean: 3599.418901660281
    time_step_min: 3259
  date: 2020-10-10_19-17-34
  done: false
  episode_len_mean: 863.580764488286
  episode_reward_max: 274.95959595959556
  episode_reward_mean: 220.91221711566948
  episode_reward_min: 144.20202020202007
  episodes_this_iter: 179
  episodes_total: 811
  experiment_id: 90ee05a92d64410d9ca45cc29b0d3a12
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.0754015786307198
        entropy_coeff: 0.00010000000000000002
        kl: 0.006495783404846277
        model: {}
        policy_loss: -0.016075572381461307
        total_loss: 7.292695726667132
        vf_explained_var: 0.9794178009033203
        vf_loss: 7.307579619543893
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.676190476190477
    gpu_util_percent0: 0.29190476190476194
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.471428571428571
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 53557
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16032556546521626
    mean_env_wait_ms: 1.2003607835496457
    mean_inference_ms: 5.283310284140977
    mean_raw_obs_processing_ms: 0.43285840354095184
  time_since_restore: 179.69830131530762
  time_this_iter_s: 35.488312005996704
  time_total_s: 179.69830131530762
  timers:
    learn_throughput: 5811.824
    learn_time_ms: 27838.422
    sample_throughput: 20171.184
    sample_time_ms: 8020.947
    update_time_ms: 32.05
  timestamp: 1602357454
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: d05a3_00000
  
== Status ==
Memory usage on this node: 48.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d05a3_00000 | RUNNING  | 172.17.0.4:53557 |      5 |          179.698 | 808960 |  220.912 |               274.96 |              144.202 |            863.581 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d05a3_00000:
  custom_metrics:
    time_step_max: 4104
    time_step_mean: 3590.3469387755104
    time_step_min: 3259
  date: 2020-10-10_19-18-09
  done: false
  episode_len_mean: 852.367992766727
  episode_reward_max: 274.95959595959556
  episode_reward_mean: 222.5741227829834
  episode_reward_min: 144.20202020202007
  episodes_this_iter: 295
  episodes_total: 1106
  experiment_id: 90ee05a92d64410d9ca45cc29b0d3a12
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.0877249496323722
        entropy_coeff: 0.00010000000000000002
        kl: 0.005908718665263483
        model: {}
        policy_loss: -0.016181309845705982
        total_loss: 7.1009932245527
        vf_explained_var: 0.9822722673416138
        vf_loss: 7.116101673671177
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.511904761904766
    gpu_util_percent0: 0.254047619047619
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4785714285714295
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 53557
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15877900077372825
    mean_env_wait_ms: 1.2043910438360663
    mean_inference_ms: 5.150198983116002
    mean_raw_obs_processing_ms: 0.42722793323856817
  time_since_restore: 215.45382523536682
  time_this_iter_s: 35.755523920059204
  time_total_s: 215.45382523536682
  timers:
    learn_throughput: 5804.207
    learn_time_ms: 27874.953
    sample_throughput: 20350.875
    sample_time_ms: 7950.125
    update_time_ms: 34.965
  timestamp: 1602357489
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: d05a3_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d05a3_00000 | RUNNING  | 172.17.0.4:53557 |      6 |          215.454 | 970752 |  222.574 |               274.96 |              144.202 |            852.368 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d05a3_00000:
  custom_metrics:
    time_step_max: 4104
    time_step_mean: 3582.8082524271845
    time_step_min: 3259
  date: 2020-10-10_19-18-45
  done: false
  episode_len_mean: 847.2721518987341
  episode_reward_max: 274.95959595959556
  episode_reward_mean: 223.71331191663455
  episode_reward_min: 144.20202020202007
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: 90ee05a92d64410d9ca45cc29b0d3a12
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.0583925928388322
        entropy_coeff: 0.00010000000000000002
        kl: 0.005369872919150761
        model: {}
        policy_loss: -0.0174571085122547
        total_loss: 4.853351695196969
        vf_explained_var: 0.9864832758903503
        vf_loss: 4.869840656008039
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.761904761904763
    gpu_util_percent0: 0.4107142857142857
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.492857142857144
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 53557
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15815790874476446
    mean_env_wait_ms: 1.2064785809803198
    mean_inference_ms: 5.097258432153899
    mean_raw_obs_processing_ms: 0.4250453786729249
  time_since_restore: 251.12998151779175
  time_this_iter_s: 35.67615628242493
  time_total_s: 251.12998151779175
  timers:
    learn_throughput: 5797.411
    learn_time_ms: 27907.631
    sample_throughput: 20519.098
    sample_time_ms: 7884.947
    update_time_ms: 33.562
  timestamp: 1602357525
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: d05a3_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d05a3_00000 | RUNNING  | 172.17.0.4:53557 |      7 |           251.13 | 1132544 |  223.713 |               274.96 |              144.202 |            847.272 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d05a3_00000:
  custom_metrics:
    time_step_max: 4107
    time_step_mean: 3578.87087517934
    time_step_min: 3259
  date: 2020-10-10_19-19-21
  done: false
  episode_len_mean: 843.4050632911392
  episode_reward_max: 274.95959595959556
  episode_reward_mean: 224.30633337595353
  episode_reward_min: 143.7474747474743
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 90ee05a92d64410d9ca45cc29b0d3a12
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.0332801342010498
        entropy_coeff: 0.00010000000000000002
        kl: 0.005426396948418447
        model: {}
        policy_loss: -0.017011869212313156
        total_loss: 4.640614611761911
        vf_explained_var: 0.9885374903678894
        vf_loss: 4.656644378389631
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.953658536585365
    gpu_util_percent0: 0.31609756097560976
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.495121951219512
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 53557
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15761629127786858
    mean_env_wait_ms: 1.2083913933669914
    mean_inference_ms: 5.050995244105578
    mean_raw_obs_processing_ms: 0.42302847390852366
  time_since_restore: 286.61641478538513
  time_this_iter_s: 35.486433267593384
  time_total_s: 286.61641478538513
  timers:
    learn_throughput: 5800.078
    learn_time_ms: 27894.796
    sample_throughput: 20609.472
    sample_time_ms: 7850.371
    update_time_ms: 32.139
  timestamp: 1602357561
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: d05a3_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d05a3_00000 | RUNNING  | 172.17.0.4:53557 |      8 |          286.616 | 1294336 |  224.306 |               274.96 |              143.747 |            843.405 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d05a3_00000:
  custom_metrics:
    time_step_max: 4107
    time_step_mean: 3572.7251213592235
    time_step_min: 3226
  date: 2020-10-10_19-19-56
  done: false
  episode_len_mean: 837.6628878281623
  episode_reward_max: 277.2323232323232
  episode_reward_mean: 225.5417902172078
  episode_reward_min: 143.7474747474743
  episodes_this_iter: 254
  episodes_total: 1676
  experiment_id: 90ee05a92d64410d9ca45cc29b0d3a12
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9961065096514565
        entropy_coeff: 0.00010000000000000002
        kl: 0.005175028096086213
        model: {}
        policy_loss: -0.0160046588363392
        total_loss: 5.571982792445591
        vf_explained_var: 0.9917523264884949
        vf_loss: 5.5870521068573
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.076190476190476
    gpu_util_percent0: 0.37857142857142856
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.480952380952381
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 53557
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1568715795445671
    mean_env_wait_ms: 1.2115847270071842
    mean_inference_ms: 4.989741905384254
    mean_raw_obs_processing_ms: 0.42032086885857795
  time_since_restore: 321.9553189277649
  time_this_iter_s: 35.33890414237976
  time_total_s: 321.9553189277649
  timers:
    learn_throughput: 5802.587
    learn_time_ms: 27882.736
    sample_throughput: 20719.199
    sample_time_ms: 7808.796
    update_time_ms: 30.857
  timestamp: 1602357596
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: d05a3_00000
  
== Status ==
Memory usage on this node: 48.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d05a3_00000 | RUNNING  | 172.17.0.4:53557 |      9 |          321.955 | 1456128 |  225.542 |              277.232 |              143.747 |            837.663 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d05a3_00000:
  custom_metrics:
    time_step_max: 4107
    time_step_mean: 3564.454496788009
    time_step_min: 3226
  date: 2020-10-10_19-20-31
  done: false
  episode_len_mean: 833.5369198312236
  episode_reward_max: 277.2323232323232
  episode_reward_mean: 226.42647998977105
  episode_reward_min: 143.7474747474743
  episodes_this_iter: 220
  episodes_total: 1896
  experiment_id: 90ee05a92d64410d9ca45cc29b0d3a12
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9841503926685878
        entropy_coeff: 0.00010000000000000002
        kl: 0.005434343059148107
        model: {}
        policy_loss: -0.015601897978090815
        total_loss: 3.690278206552778
        vf_explained_var: 0.9925454258918762
        vf_loss: 3.70489171573094
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.024390243902438
    gpu_util_percent0: 0.26951219512195124
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497560975609756
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 53557
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1563430803694936
    mean_env_wait_ms: 1.214076479525709
    mean_inference_ms: 4.946047133507295
    mean_raw_obs_processing_ms: 0.4183103444140136
  time_since_restore: 357.16904735565186
  time_this_iter_s: 35.21372842788696
  time_total_s: 357.16904735565186
  timers:
    learn_throughput: 5802.753
    learn_time_ms: 27881.938
    sample_throughput: 20867.361
    sample_time_ms: 7753.352
    update_time_ms: 30.515
  timestamp: 1602357631
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: d05a3_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d05a3_00000 | RUNNING  | 172.17.0.4:53557 |     10 |          357.169 | 1617920 |  226.426 |              277.232 |              143.747 |            833.537 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d05a3_00000:
  custom_metrics:
    time_step_max: 4107
    time_step_mean: 3561.357847976308
    time_step_min: 3226
  date: 2020-10-10_19-21-07
  done: false
  episode_len_mean: 831.2297955209348
  episode_reward_max: 277.2323232323232
  episode_reward_mean: 226.89890137991395
  episode_reward_min: 143.7474747474743
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: 90ee05a92d64410d9ca45cc29b0d3a12
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9651176163128444
        entropy_coeff: 0.00010000000000000002
        kl: 0.005137938806521041
        model: {}
        policy_loss: -0.015540925885683723
        total_loss: 3.2578467641557967
        vf_explained_var: 0.9935242533683777
        vf_loss: 3.272456611905779
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.414285714285715
    gpu_util_percent0: 0.3526190476190476
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.488095238095238
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 53557
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1560072702539822
    mean_env_wait_ms: 1.2156824374750992
    mean_inference_ms: 4.9185708268699475
    mean_raw_obs_processing_ms: 0.4170494178422433
  time_since_restore: 392.43550515174866
  time_this_iter_s: 35.2664577960968
  time_total_s: 392.43550515174866
  timers:
    learn_throughput: 5808.512
    learn_time_ms: 27854.294
    sample_throughput: 21545.655
    sample_time_ms: 7509.264
    update_time_ms: 37.925
  timestamp: 1602357667
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: d05a3_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d05a3_00000 | RUNNING  | 172.17.0.4:53557 |     11 |          392.436 | 1779712 |  226.899 |              277.232 |              143.747 |             831.23 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d05a3_00000:
  custom_metrics:
    time_step_max: 4107
    time_step_mean: 3558.151556776557
    time_step_min: 3226
  date: 2020-10-10_19-21-42
  done: false
  episode_len_mean: 829.3648282097649
  episode_reward_max: 277.2323232323232
  episode_reward_mean: 227.3069848576177
  episode_reward_min: 143.7474747474743
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 90ee05a92d64410d9ca45cc29b0d3a12
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9373102188110352
        entropy_coeff: 0.00010000000000000002
        kl: 0.004949947519760046
        model: {}
        policy_loss: -0.014971735937121724
        total_loss: 3.6270849193845476
        vf_explained_var: 0.9933972954750061
        vf_loss: 3.641160454068865
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.68536585365854
    gpu_util_percent0: 0.42707317073170736
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.487804878048781
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 53557
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15569653244938436
    mean_env_wait_ms: 1.2172081044075298
    mean_inference_ms: 4.893439177104255
    mean_raw_obs_processing_ms: 0.4158456279124628
  time_since_restore: 427.5985598564148
  time_this_iter_s: 35.16305470466614
  time_total_s: 427.5985598564148
  timers:
    learn_throughput: 5800.689
    learn_time_ms: 27891.861
    sample_throughput: 21751.401
    sample_time_ms: 7438.234
    update_time_ms: 36.618
  timestamp: 1602357702
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: d05a3_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d05a3_00000 | RUNNING  | 172.17.0.4:53557 |     12 |          427.599 | 1941504 |  227.307 |              277.232 |              143.747 |            829.365 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d05a3_00000:
  custom_metrics:
    time_step_max: 4107
    time_step_mean: 3551.90192153723
    time_step_min: 3226
  date: 2020-10-10_19-22-17
  done: false
  episode_len_mean: 826.5997624703087
  episode_reward_max: 277.2323232323232
  episode_reward_mean: 228.21255308428698
  episode_reward_min: 137.98989898989896
  episodes_this_iter: 314
  episodes_total: 2526
  experiment_id: 90ee05a92d64410d9ca45cc29b0d3a12
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 0.912399845463889
        entropy_coeff: 0.00010000000000000002
        kl: 0.0055714185748781475
        model: {}
        policy_loss: -0.01422621579175549
        total_loss: 4.061985203198025
        vf_explained_var: 0.9948520064353943
        vf_loss: 4.075745480401175
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.614634146341462
    gpu_util_percent0: 0.29731707317073175
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.482926829268291
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 53557
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15516756682337043
    mean_env_wait_ms: 1.219996659122186
    mean_inference_ms: 4.850583090103307
    mean_raw_obs_processing_ms: 0.4138339675630658
  time_since_restore: 462.8056643009186
  time_this_iter_s: 35.207104444503784
  time_total_s: 462.8056643009186
  timers:
    learn_throughput: 5804.946
    learn_time_ms: 27871.404
    sample_throughput: 21816.307
    sample_time_ms: 7416.104
    update_time_ms: 37.062
  timestamp: 1602357737
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: d05a3_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d05a3_00000 | RUNNING  | 172.17.0.4:53557 |     13 |          462.806 | 2103296 |  228.213 |              277.232 |               137.99 |              826.6 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d05a3_00000:
  custom_metrics:
    time_step_max: 4107
    time_step_mean: 3549.2814145974417
    time_step_min: 3226
  date: 2020-10-10_19-22-53
  done: false
  episode_len_mean: 825.3510796723752
  episode_reward_max: 279.8080808080807
  episode_reward_mean: 228.6450356130177
  episode_reward_min: 137.98989898989896
  episodes_this_iter: 160
  episodes_total: 2686
  experiment_id: 90ee05a92d64410d9ca45cc29b0d3a12
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 0.8836630795683179
        entropy_coeff: 0.00010000000000000002
        kl: 0.005679994987856064
        model: {}
        policy_loss: -0.016235323157161474
        total_loss: 2.4924423354012624
        vf_explained_var: 0.9954519867897034
        vf_loss: 2.508198090962001
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.524390243902438
    gpu_util_percent0: 0.29878048780487804
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.487804878048781
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 53557
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15492577985879388
    mean_env_wait_ms: 1.2212199883645927
    mean_inference_ms: 4.831396859032213
    mean_raw_obs_processing_ms: 0.41291801693031976
  time_since_restore: 498.0196259021759
  time_this_iter_s: 35.213961601257324
  time_total_s: 498.0196259021759
  timers:
    learn_throughput: 5804.992
    learn_time_ms: 27871.186
    sample_throughput: 21809.639
    sample_time_ms: 7418.371
    update_time_ms: 36.189
  timestamp: 1602357773
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: d05a3_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d05a3_00000 | RUNNING  | 172.17.0.4:53557 |     14 |           498.02 | 2265088 |  228.645 |              279.808 |               137.99 |            825.351 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d05a3_00000:
  custom_metrics:
    time_step_max: 4107
    time_step_mean: 3546.064630681818
    time_step_min: 3226
  date: 2020-10-10_19-23-28
  done: false
  episode_len_mean: 824.0597749648383
  episode_reward_max: 279.8080808080807
  episode_reward_mean: 229.15018326727184
  episode_reward_min: 137.98989898989896
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: 90ee05a92d64410d9ca45cc29b0d3a12
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 0.8742737003735134
        entropy_coeff: 0.00010000000000000002
        kl: 0.00575702594194029
        model: {}
        policy_loss: -0.01515349023975432
        total_loss: 2.457223687853132
        vf_explained_var: 0.995241641998291
        vf_loss: 2.4718888316835677
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.666666666666668
    gpu_util_percent0: 0.4028571428571428
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.492857142857143
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 53557
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15470402484725707
    mean_env_wait_ms: 1.222379634431672
    mean_inference_ms: 4.8138945982066215
    mean_raw_obs_processing_ms: 0.4120703185633156
  time_since_restore: 533.2857520580292
  time_this_iter_s: 35.26612615585327
  time_total_s: 533.2857520580292
  timers:
    learn_throughput: 5808.914
    learn_time_ms: 27852.366
    sample_throughput: 21818.97
    sample_time_ms: 7415.199
    update_time_ms: 35.024
  timestamp: 1602357808
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: d05a3_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d05a3_00000 | RUNNING  | 172.17.0.4:53557 |     15 |          533.286 | 2426880 |   229.15 |              279.808 |               137.99 |             824.06 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d05a3_00000:
  custom_metrics:
    time_step_max: 4107
    time_step_mean: 3542.356690023357
    time_step_min: 3226
  date: 2020-10-10_19-24-03
  done: false
  episode_len_mean: 822.4899173553719
  episode_reward_max: 279.8080808080807
  episode_reward_mean: 229.6916771015944
  episode_reward_min: 137.98989898989896
  episodes_this_iter: 181
  episodes_total: 3025
  experiment_id: 90ee05a92d64410d9ca45cc29b0d3a12
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 0.8485489359923771
        entropy_coeff: 0.00010000000000000002
        kl: 0.00556503186401512
        model: {}
        policy_loss: -0.015178897429515408
        total_loss: 2.5661660773413524
        vf_explained_var: 0.9960997700691223
        vf_loss: 2.580873336110796
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.117073170731707
    gpu_util_percent0: 0.40926829268292686
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.495121951219511
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 53557
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15446233346700247
    mean_env_wait_ms: 1.2237582080869809
    mean_inference_ms: 4.7953242628846775
    mean_raw_obs_processing_ms: 0.41117606898537795
  time_since_restore: 568.5645973682404
  time_this_iter_s: 35.27884531021118
  time_total_s: 568.5645973682404
  timers:
    learn_throughput: 5813.003
    learn_time_ms: 27832.773
    sample_throughput: 21898.333
    sample_time_ms: 7388.325
    update_time_ms: 33.224
  timestamp: 1602357843
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: d05a3_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d05a3_00000 | RUNNING  | 172.17.0.4:53557 |     16 |          568.565 | 2588672 |  229.692 |              279.808 |               137.99 |             822.49 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d05a3_00000:
  custom_metrics:
    time_step_max: 4107
    time_step_mean: 3535.7231003039515
    time_step_min: 3226
  date: 2020-10-10_19-24-39
  done: true
  episode_len_mean: 820.287221217601
  episode_reward_max: 279.8080808080807
  episode_reward_mean: 230.61648126837997
  episode_reward_min: 137.98989898989896
  episodes_this_iter: 293
  episodes_total: 3318
  experiment_id: 90ee05a92d64410d9ca45cc29b0d3a12
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 0.8094796964100429
        entropy_coeff: 0.00010000000000000002
        kl: 0.004871468891256622
        model: {}
        policy_loss: -0.013787372270599008
        total_loss: 2.6264642477035522
        vf_explained_var: 0.9959844350814819
        vf_loss: 2.639845405306135
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.964285714285715
    gpu_util_percent0: 0.3038095238095238
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4833333333333325
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 53557
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15413359294263296
    mean_env_wait_ms: 1.2257307942639675
    mean_inference_ms: 4.768709639726048
    mean_raw_obs_processing_ms: 0.4098648043551044
  time_since_restore: 603.9449138641357
  time_this_iter_s: 35.380316495895386
  time_total_s: 603.9449138641357
  timers:
    learn_throughput: 5820.542
    learn_time_ms: 27796.723
    sample_throughput: 21883.088
    sample_time_ms: 7393.472
    update_time_ms: 33.03
  timestamp: 1602357879
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: d05a3_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d05a3_00000 | TERMINATED |       |     17 |          603.945 | 2750464 |  230.616 |              279.808 |               137.99 |            820.287 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d05a3_00000 | TERMINATED |       |     17 |          603.945 | 2750464 |  230.616 |              279.808 |               137.99 |            820.287 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


