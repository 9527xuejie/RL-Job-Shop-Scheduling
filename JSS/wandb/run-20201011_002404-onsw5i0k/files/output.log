2020-10-11 00:24:06,474	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8266[39m[22m
== Status ==
Memory usage on this node: 32.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_13916_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=8195)[0m 2020-10-11 00:24:09,431	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=8068)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8068)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8145)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8145)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8155)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8155)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8186)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8186)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8153)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8153)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8150)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8150)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8146)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8146)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8131)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8131)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8147)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8147)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8072)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8072)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8183)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8183)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8075)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8075)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8134)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8134)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8149)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8149)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8138)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8138)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8135)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8135)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8159)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8159)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8142)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8142)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8060)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8060)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8083)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8083)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8136)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8136)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8079)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8079)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8193)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8193)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8169)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8169)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8063)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8063)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8168)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8168)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8077)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8077)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8144)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8144)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8151)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8151)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8165)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8165)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8065)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8065)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8190)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8190)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8157)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8157)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8059)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8059)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8120)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8120)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8070)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8070)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8064)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8064)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8071)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8071)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8066)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8066)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8069)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8069)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8139)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8139)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8129)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8129)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8125)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8125)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8160)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8160)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8090)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8090)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8087)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8087)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8088)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8088)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8173)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8173)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8085)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8085)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8100)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8100)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8074)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8074)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8130)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8130)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8076)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8076)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8062)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8062)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8162)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8162)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8132)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8132)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8127)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8127)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8096)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8096)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8156)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8156)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8184)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8184)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8094)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8094)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8061)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8061)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8178)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8178)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8119)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8119)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8182)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8182)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8181)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8181)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8081)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8081)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8141)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8141)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8124)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8124)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8171)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8171)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8102)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8102)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8140)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8140)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8133)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8133)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8122)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8122)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8163)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8163)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8093)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8093)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8175)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8175)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8137)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8137)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8097)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8097)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_13916_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-11_00-24-47
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 90a115d7cae042ef9ccd55edbdc29f97
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.184123158454895
        entropy_coeff: 0.00010000000000000002
        kl: 0.005288227195186275
        model: {}
        policy_loss: -0.012782024435832031
        total_loss: 499.5481218610491
        vf_explained_var: 0.5819914937019348
        vf_loss: 499.55997358049666
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.91578947368421
    gpu_util_percent0: 0.31868421052631574
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0002631578947368421
    ram_util_percent: 6.284210526315791
    vram_util_percent0: 0.19103761371286532
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 8195
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17123418150216055
    mean_env_wait_ms: 1.195723238312267
    mean_inference_ms: 5.584140261149252
    mean_raw_obs_processing_ms: 0.45459950180030156
  time_since_restore: 31.794280290603638
  time_this_iter_s: 31.794280290603638
  time_total_s: 31.794280290603638
  timers:
    learn_throughput: 7095.51
    learn_time_ms: 22802.026
    sample_throughput: 18226.14
    sample_time_ms: 8876.921
    update_time_ms: 27.797
  timestamp: 1602375887
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: '13916_00000'
  
== Status ==
Memory usage on this node: 48.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13916_00000 | RUNNING  | 172.17.0.4:8195 |      1 |          31.7943 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13916_00000:
  custom_metrics:
    time_step_max: 4211
    time_step_mean: 3629.0868055555557
    time_step_min: 3196
  date: 2020-10-11_00-25-17
  done: false
  episode_len_mean: 889.2310126582279
  episode_reward_max: 281.77777777777743
  episode_reward_mean: 216.47187060478177
  episode_reward_min: 127.98989898989866
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 90a115d7cae042ef9ccd55edbdc29f97
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.15291542666299
        entropy_coeff: 0.00010000000000000002
        kl: 0.006545456259378365
        model: {}
        policy_loss: -0.01308327228096979
        total_loss: 124.30941826956612
        vf_explained_var: 0.8194022178649902
        vf_loss: 124.32130868094308
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.22222222222222
    gpu_util_percent0: 0.32944444444444443
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.466666666666667
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 8195
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16660096360131033
    mean_env_wait_ms: 1.1897364833771278
    mean_inference_ms: 5.379191390333466
    mean_raw_obs_processing_ms: 0.4446500899186085
  time_since_restore: 62.34434676170349
  time_this_iter_s: 30.550066471099854
  time_total_s: 62.34434676170349
  timers:
    learn_throughput: 7133.942
    learn_time_ms: 22679.187
    sample_throughput: 19282.003
    sample_time_ms: 8390.829
    update_time_ms: 34.543
  timestamp: 1602375917
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: '13916_00000'
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13916_00000 | RUNNING  | 172.17.0.4:8195 |      2 |          62.3443 | 323584 |  216.472 |              281.778 |               127.99 |            889.231 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13916_00000:
  custom_metrics:
    time_step_max: 4211
    time_step_mean: 3624.127802690583
    time_step_min: 3196
  date: 2020-10-11_00-25-48
  done: false
  episode_len_mean: 886.3354430379746
  episode_reward_max: 281.77777777777743
  episode_reward_mean: 217.70349060222455
  episode_reward_min: 127.98989898989866
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 90a115d7cae042ef9ccd55edbdc29f97
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.1455024310520716
        entropy_coeff: 0.00010000000000000002
        kl: 0.007958663827074426
        model: {}
        policy_loss: -0.016551869131425128
        total_loss: 45.75190108163016
        vf_explained_var: 0.9211584329605103
        vf_loss: 45.766976492745535
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.997142857142858
    gpu_util_percent0: 0.2868571428571428
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.485714285714285
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 8195
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16381593764099395
    mean_env_wait_ms: 1.1878022762021698
    mean_inference_ms: 5.227336640923147
    mean_raw_obs_processing_ms: 0.437310658310284
  time_since_restore: 92.59895324707031
  time_this_iter_s: 30.25460648536682
  time_total_s: 92.59895324707031
  timers:
    learn_throughput: 7131.347
    learn_time_ms: 22687.44
    sample_throughput: 20028.493
    sample_time_ms: 8078.091
    update_time_ms: 36.5
  timestamp: 1602375948
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: '13916_00000'
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13916_00000 | RUNNING  | 172.17.0.4:8195 |      3 |           92.599 | 485376 |  217.703 |              281.778 |               127.99 |            886.335 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13916_00000:
  custom_metrics:
    time_step_max: 4211
    time_step_mean: 3613.541390728477
    time_step_min: 3196
  date: 2020-10-11_00-26-18
  done: false
  episode_len_mean: 884.0348101265823
  episode_reward_max: 281.77777777777743
  episode_reward_mean: 218.97211034394562
  episode_reward_min: 127.98989898989866
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 90a115d7cae042ef9ccd55edbdc29f97
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.1310375758579798
        entropy_coeff: 0.00010000000000000002
        kl: 0.007558988906177027
        model: {}
        policy_loss: -0.017002199543640018
        total_loss: 32.32759639195034
        vf_explained_var: 0.9433412551879883
        vf_loss: 32.34319932120187
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.622857142857136
    gpu_util_percent0: 0.3748571428571429
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.491428571428571
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 8195
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16186831888995795
    mean_env_wait_ms: 1.1869980960226312
    mean_inference_ms: 5.117912603206433
    mean_raw_obs_processing_ms: 0.4316735668994933
  time_since_restore: 122.67958641052246
  time_this_iter_s: 30.08063316345215
  time_total_s: 122.67958641052246
  timers:
    learn_throughput: 7133.102
    learn_time_ms: 22681.858
    sample_throughput: 20497.018
    sample_time_ms: 7893.441
    update_time_ms: 34.063
  timestamp: 1602375978
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: '13916_00000'
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13916_00000 | RUNNING  | 172.17.0.4:8195 |      4 |           122.68 | 647168 |  218.972 |              281.778 |               127.99 |            884.035 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13916_00000:
  custom_metrics:
    time_step_max: 4211
    time_step_mean: 3599.3700787401576
    time_step_min: 3196
  date: 2020-10-11_00-26-47
  done: false
  episode_len_mean: 880.8392405063291
  episode_reward_max: 281.77777777777743
  episode_reward_mean: 220.5882879427181
  episode_reward_min: 127.98989898989866
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 90a115d7cae042ef9ccd55edbdc29f97
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.105880149773189
        entropy_coeff: 0.00010000000000000002
        kl: 0.008024138963914343
        model: {}
        policy_loss: -0.017010629210355028
        total_loss: 23.298068591526576
        vf_explained_var: 0.9591283798217773
        vf_loss: 23.31358460017613
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.61714285714286
    gpu_util_percent0: 0.32628571428571435
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.48
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 8195
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1604512370872804
    mean_env_wait_ms: 1.1870251248031474
    mean_inference_ms: 5.035023714021065
    mean_raw_obs_processing_ms: 0.42706871685870723
  time_since_restore: 152.1474211215973
  time_this_iter_s: 29.46783471107483
  time_total_s: 152.1474211215973
  timers:
    learn_throughput: 7170.563
    learn_time_ms: 22563.36
    sample_throughput: 20852.339
    sample_time_ms: 7758.938
    update_time_ms: 48.597
  timestamp: 1602376007
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: '13916_00000'
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13916_00000 | RUNNING  | 172.17.0.4:8195 |      5 |          152.147 | 808960 |  220.588 |              281.778 |               127.99 |            880.839 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13916_00000:
  custom_metrics:
    time_step_max: 4211
    time_step_mean: 3589.2368168744006
    time_step_min: 3196
  date: 2020-10-11_00-27-17
  done: false
  episode_len_mean: 873.8375350140057
  episode_reward_max: 281.77777777777743
  episode_reward_mean: 222.76411170528797
  episode_reward_min: 127.98989898989866
  episodes_this_iter: 281
  episodes_total: 1071
  experiment_id: 90a115d7cae042ef9ccd55edbdc29f97
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.0920478701591492
        entropy_coeff: 0.00010000000000000002
        kl: 0.007303245864542467
        model: {}
        policy_loss: -0.016171092483481125
        total_loss: 26.838384764535085
        vf_explained_var: 0.9679027199745178
        vf_loss: 26.853204454694474
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.905714285714286
    gpu_util_percent0: 0.31714285714285706
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.474285714285714
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 8195
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15859049810920395
    mean_env_wait_ms: 1.188794504900874
    mean_inference_ms: 4.931042962025283
    mean_raw_obs_processing_ms: 0.4212355197370307
  time_since_restore: 182.21254515647888
  time_this_iter_s: 30.065124034881592
  time_total_s: 182.21254515647888
  timers:
    learn_throughput: 7163.554
    learn_time_ms: 22585.438
    sample_throughput: 21070.166
    sample_time_ms: 7678.725
    update_time_ms: 46.023
  timestamp: 1602376037
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: '13916_00000'
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13916_00000 | RUNNING  | 172.17.0.4:8195 |      6 |          182.213 | 970752 |  222.764 |              281.778 |               127.99 |            873.838 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13916_00000:
  custom_metrics:
    time_step_max: 4211
    time_step_mean: 3582.23786407767
    time_step_min: 3196
  date: 2020-10-11_00-27-48
  done: false
  episode_len_mean: 870.1787974683544
  episode_reward_max: 281.77777777777743
  episode_reward_mean: 224.02952787367326
  episode_reward_min: 127.98989898989866
  episodes_this_iter: 193
  episodes_total: 1264
  experiment_id: 90a115d7cae042ef9ccd55edbdc29f97
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.1011959314346313
        entropy_coeff: 0.00010000000000000002
        kl: 0.007233736371355397
        model: {}
        policy_loss: -0.015470324217208795
        total_loss: 18.43860081263951
        vf_explained_var: 0.96905517578125
        vf_loss: 18.452734810965403
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.834285714285713
    gpu_util_percent0: 0.3208571428571429
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497142857142857
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 8195
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15773843266889886
    mean_env_wait_ms: 1.190040436509453
    mean_inference_ms: 4.88040475158492
    mean_raw_obs_processing_ms: 0.4185630087649625
  time_since_restore: 212.54080414772034
  time_this_iter_s: 30.328258991241455
  time_total_s: 212.54080414772034
  timers:
    learn_throughput: 7150.04
    learn_time_ms: 22628.126
    sample_throughput: 21201.677
    sample_time_ms: 7631.094
    update_time_ms: 45.874
  timestamp: 1602376068
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: '13916_00000'
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13916_00000 | RUNNING  | 172.17.0.4:8195 |      7 |          212.541 | 1132544 |   224.03 |              281.778 |               127.99 |            870.179 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13916_00000:
  custom_metrics:
    time_step_max: 4211
    time_step_mean: 3577.050932568149
    time_step_min: 3196
  date: 2020-10-11_00-28-18
  done: false
  episode_len_mean: 868.1990154711674
  episode_reward_max: 281.77777777777743
  episode_reward_mean: 224.60467544644746
  episode_reward_min: 127.98989898989866
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 90a115d7cae042ef9ccd55edbdc29f97
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.0803832582065038
        entropy_coeff: 0.00010000000000000002
        kl: 0.007583368303520339
        model: {}
        policy_loss: -0.016576535035190836
        total_loss: 16.651049818311417
        vf_explained_var: 0.9722217917442322
        vf_loss: 16.666217803955078
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.944444444444446
    gpu_util_percent0: 0.34222222222222226
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.488888888888889
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 8195
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1571319731911824
    mean_env_wait_ms: 1.1909029914889953
    mean_inference_ms: 4.845406889133061
    mean_raw_obs_processing_ms: 0.4166294302578157
  time_since_restore: 242.89952993392944
  time_this_iter_s: 30.358725786209106
  time_total_s: 242.89952993392944
  timers:
    learn_throughput: 7145.739
    learn_time_ms: 22641.744
    sample_throughput: 21234.717
    sample_time_ms: 7619.221
    update_time_ms: 44.355
  timestamp: 1602376098
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: '13916_00000'
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13916_00000 | RUNNING  | 172.17.0.4:8195 |      8 |            242.9 | 1294336 |  224.605 |              281.778 |               127.99 |            868.199 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13916_00000:
  custom_metrics:
    time_step_max: 4211
    time_step_mean: 3571.27706185567
    time_step_min: 3196
  date: 2020-10-11_00-28-48
  done: false
  episode_len_mean: 866.5981012658228
  episode_reward_max: 281.77777777777743
  episode_reward_mean: 225.47887098836452
  episode_reward_min: 127.98989898989866
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 90a115d7cae042ef9ccd55edbdc29f97
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.060730048588344
        entropy_coeff: 0.00010000000000000002
        kl: 0.007342381702203836
        model: {}
        policy_loss: -0.017237438886825527
        total_loss: 16.26710523877825
        vf_explained_var: 0.9711273312568665
        vf_loss: 16.28297996520996
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.034285714285716
    gpu_util_percent0: 0.34314285714285714
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497142857142857
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 8195
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15660012571119386
    mean_env_wait_ms: 1.1916351438236379
    mean_inference_ms: 4.814872767933895
    mean_raw_obs_processing_ms: 0.41491146494083064
  time_since_restore: 273.04462909698486
  time_this_iter_s: 30.14509916305542
  time_total_s: 273.04462909698486
  timers:
    learn_throughput: 7144.438
    learn_time_ms: 22645.868
    sample_throughput: 21329.847
    sample_time_ms: 7585.24
    update_time_ms: 42.245
  timestamp: 1602376128
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: '13916_00000'
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13916_00000 | RUNNING  | 172.17.0.4:8195 |      9 |          273.045 | 1456128 |  225.479 |              281.778 |               127.99 |            866.598 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13916_00000:
  custom_metrics:
    time_step_max: 4211
    time_step_mean: 3563.3666472980826
    time_step_min: 3196
  date: 2020-10-11_00-29-19
  done: false
  episode_len_mean: 863.7833047455689
  episode_reward_max: 281.77777777777743
  episode_reward_mean: 226.84474245023114
  episode_reward_min: 127.98989898989866
  episodes_this_iter: 169
  episodes_total: 1749
  experiment_id: 90a115d7cae042ef9ccd55edbdc29f97
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.024056817804064
        entropy_coeff: 0.00010000000000000002
        kl: 0.007914221047290735
        model: {}
        policy_loss: -0.01720719558319875
        total_loss: 15.68863821029663
        vf_explained_var: 0.9744613766670227
        vf_loss: 15.70436464037214
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.314285714285717
    gpu_util_percent0: 0.3568571428571429
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.491428571428571
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 8195
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15610449952715444
    mean_env_wait_ms: 1.192540874721063
    mean_inference_ms: 4.786169843136342
    mean_raw_obs_processing_ms: 0.4132217769334354
  time_since_restore: 303.2809352874756
  time_this_iter_s: 30.236306190490723
  time_total_s: 303.2809352874756
  timers:
    learn_throughput: 7139.438
    learn_time_ms: 22661.729
    sample_throughput: 21395.214
    sample_time_ms: 7562.065
    update_time_ms: 40.278
  timestamp: 1602376159
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: '13916_00000'
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13916_00000 | RUNNING  | 172.17.0.4:8195 |     10 |          303.281 | 1617920 |  226.845 |              281.778 |               127.99 |            863.783 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13916_00000:
  custom_metrics:
    time_step_max: 4211
    time_step_mean: 3547.201684836472
    time_step_min: 3196
  date: 2020-10-11_00-29-49
  done: false
  episode_len_mean: 858.1730205278592
  episode_reward_max: 284.35353535353585
  episode_reward_mean: 229.3084362688467
  episode_reward_min: 127.98989898989866
  episodes_this_iter: 297
  episodes_total: 2046
  experiment_id: 90a115d7cae042ef9ccd55edbdc29f97
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.0186220577784948
        entropy_coeff: 0.00010000000000000002
        kl: 0.007204257184639573
        model: {}
        policy_loss: -0.015155769709963351
        total_loss: 18.25770514351981
        vf_explained_var: 0.9756985306739807
        vf_loss: 18.271521704537527
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.568571428571428
    gpu_util_percent0: 0.33514285714285713
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4714285714285715
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 8195
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15537958955499973
    mean_env_wait_ms: 1.1941547339172105
    mean_inference_ms: 4.744957632301373
    mean_raw_obs_processing_ms: 0.4108534829487936
  time_since_restore: 333.14472126960754
  time_this_iter_s: 29.863785982131958
  time_total_s: 333.14472126960754
  timers:
    learn_throughput: 7146.469
    learn_time_ms: 22639.432
    sample_throughput: 21882.669
    sample_time_ms: 7393.614
    update_time_ms: 40.304
  timestamp: 1602376189
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: '13916_00000'
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13916_00000 | RUNNING  | 172.17.0.4:8195 |     11 |          333.145 | 1779712 |  229.308 |              284.354 |               127.99 |            858.173 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13916_00000:
  custom_metrics:
    time_step_max: 4211
    time_step_mean: 3538.635531135531
    time_step_min: 3196
  date: 2020-10-11_00-30-19
  done: false
  episode_len_mean: 855.6573236889693
  episode_reward_max: 284.35353535353585
  episode_reward_mean: 230.63346850055694
  episode_reward_min: 127.98989898989866
  episodes_this_iter: 166
  episodes_total: 2212
  experiment_id: 90a115d7cae042ef9ccd55edbdc29f97
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.0039416807038444
        entropy_coeff: 0.00010000000000000002
        kl: 0.007015820093719023
        model: {}
        policy_loss: -0.014375619423974837
        total_loss: 10.579041412898473
        vf_explained_var: 0.9804452657699585
        vf_loss: 10.59211472102574
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.385714285714286
    gpu_util_percent0: 0.2977142857142857
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.485714285714286
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 8195
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1550472278082564
    mean_env_wait_ms: 1.1950356926222319
    mean_inference_ms: 4.725575743820769
    mean_raw_obs_processing_ms: 0.4097670273714969
  time_since_restore: 363.1275074481964
  time_this_iter_s: 29.982786178588867
  time_total_s: 363.1275074481964
  timers:
    learn_throughput: 7146.084
    learn_time_ms: 22640.653
    sample_throughput: 22051.507
    sample_time_ms: 7337.004
    update_time_ms: 38.555
  timestamp: 1602376219
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: '13916_00000'
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13916_00000 | RUNNING  | 172.17.0.4:8195 |     12 |          363.128 | 1941504 |  230.633 |              284.354 |               127.99 |            855.657 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13916_00000:
  custom_metrics:
    time_step_max: 4211
    time_step_mean: 3530.675064047822
    time_step_min: 3196
  date: 2020-10-11_00-30-49
  done: false
  episode_len_mean: 853.1822784810126
  episode_reward_max: 285.2626262626264
  episode_reward_mean: 231.76013297532273
  episode_reward_min: 127.98989898989866
  episodes_this_iter: 158
  episodes_total: 2370
  experiment_id: 90a115d7cae042ef9ccd55edbdc29f97
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9916257815701621
        entropy_coeff: 0.00010000000000000002
        kl: 0.007168289174192718
        model: {}
        policy_loss: -0.017465933824756315
        total_loss: 11.533691610608782
        vf_explained_var: 0.9775316119194031
        vf_loss: 11.549822739192418
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.994285714285716
    gpu_util_percent0: 0.30942857142857144
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.494285714285714
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 8195
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15476094824681155
    mean_env_wait_ms: 1.1958237822838043
    mean_inference_ms: 4.70882726901844
    mean_raw_obs_processing_ms: 0.4088029345515253
  time_since_restore: 392.96140241622925
  time_this_iter_s: 29.833894968032837
  time_total_s: 392.96140241622925
  timers:
    learn_throughput: 7152.453
    learn_time_ms: 22620.492
    sample_throughput: 22111.4
    sample_time_ms: 7317.131
    update_time_ms: 36.445
  timestamp: 1602376249
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: '13916_00000'
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13916_00000 | RUNNING  | 172.17.0.4:8195 |     13 |          392.961 | 2103296 |   231.76 |              285.263 |               127.99 |            853.182 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13916_00000:
  custom_metrics:
    time_step_max: 4211
    time_step_mean: 3523.2339158061955
    time_step_min: 3196
  date: 2020-10-11_00-31-19
  done: false
  episode_len_mean: 850.3813825608798
  episode_reward_max: 285.2626262626264
  episode_reward_mean: 232.87319780681906
  episode_reward_min: 127.98989898989866
  episodes_this_iter: 176
  episodes_total: 2546
  experiment_id: 90a115d7cae042ef9ccd55edbdc29f97
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9537116757461003
        entropy_coeff: 0.00010000000000000002
        kl: 0.007702718023210764
        model: {}
        policy_loss: -0.016937840996044024
        total_loss: 12.503281388963972
        vf_explained_var: 0.9794794321060181
        vf_loss: 12.518774236951556
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.63714285714286
    gpu_util_percent0: 0.30742857142857144
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.488571428571428
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 8195
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15447601429770505
    mean_env_wait_ms: 1.1967214586647195
    mean_inference_ms: 4.69188610151001
    mean_raw_obs_processing_ms: 0.4077997493567545
  time_since_restore: 422.97682523727417
  time_this_iter_s: 30.015422821044922
  time_total_s: 422.97682523727417
  timers:
    learn_throughput: 7153.831
    learn_time_ms: 22616.135
    sample_throughput: 22117.519
    sample_time_ms: 7315.106
    update_time_ms: 35.935
  timestamp: 1602376279
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: '13916_00000'
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13916_00000 | RUNNING  | 172.17.0.4:8195 |     14 |          422.977 | 2265088 |  232.873 |              285.263 |               127.99 |            850.381 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13916_00000:
  custom_metrics:
    time_step_max: 4211
    time_step_mean: 3510.1135231316725
    time_step_min: 3172
  date: 2020-10-11_00-31-49
  done: false
  episode_len_mean: 846.3178294573644
  episode_reward_max: 285.41414141414094
  episode_reward_mean: 234.86050782668107
  episode_reward_min: 127.98989898989866
  episodes_this_iter: 292
  episodes_total: 2838
  experiment_id: 90a115d7cae042ef9ccd55edbdc29f97
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9489475573812213
        entropy_coeff: 0.00010000000000000002
        kl: 0.006831914685400469
        model: {}
        policy_loss: -0.017053499884371246
        total_loss: 12.697332041604179
        vf_explained_var: 0.9821307063102722
        vf_loss: 12.713113921029228
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.905714285714286
    gpu_util_percent0: 0.3314285714285714
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.477142857142857
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 8195
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1540633564700207
    mean_env_wait_ms: 1.198167414399392
    mean_inference_ms: 4.66756245810159
    mean_raw_obs_processing_ms: 0.40637382652088444
  time_since_restore: 453.3337826728821
  time_this_iter_s: 30.35695743560791
  time_total_s: 453.3337826728821
  timers:
    learn_throughput: 7126.403
    learn_time_ms: 22703.178
    sample_throughput: 22089.447
    sample_time_ms: 7324.403
    update_time_ms: 27.59
  timestamp: 1602376309
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: '13916_00000'
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13916_00000 | RUNNING  | 172.17.0.4:8195 |     15 |          453.334 | 2426880 |  234.861 |              285.414 |               127.99 |            846.318 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13916_00000:
  custom_metrics:
    time_step_max: 4211
    time_step_mean: 3502.9636852723606
    time_step_min: 3136
  date: 2020-10-11_00-32-20
  done: false
  episode_len_mean: 843.9976682211859
  episode_reward_max: 290.8686868686866
  episode_reward_mean: 235.82866304618457
  episode_reward_min: 127.98989898989866
  episodes_this_iter: 164
  episodes_total: 3002
  experiment_id: 90a115d7cae042ef9ccd55edbdc29f97
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9329651381288256
        entropy_coeff: 0.00010000000000000002
        kl: 0.007104239193722606
        model: {}
        policy_loss: -0.018808537428932532
        total_loss: 8.723822321210589
        vf_explained_var: 0.9832069277763367
        vf_loss: 8.741303103310722
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.86111111111111
    gpu_util_percent0: 0.3652777777777778
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.491666666666666
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 8195
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1538646922401394
    mean_env_wait_ms: 1.1989378656480072
    mean_inference_ms: 4.655478422261229
    mean_raw_obs_processing_ms: 0.4056701962816727
  time_since_restore: 483.4134030342102
  time_this_iter_s: 30.079620361328125
  time_total_s: 483.4134030342102
  timers:
    learn_throughput: 7126.643
    learn_time_ms: 22702.415
    sample_throughput: 22101.595
    sample_time_ms: 7320.377
    update_time_ms: 32.915
  timestamp: 1602376340
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: '13916_00000'
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13916_00000 | RUNNING  | 172.17.0.4:8195 |     16 |          483.413 | 2588672 |  235.829 |              290.869 |               127.99 |            843.998 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13916_00000:
  custom_metrics:
    time_step_max: 4211
    time_step_mean: 3497.2075351213284
    time_step_min: 3136
  date: 2020-10-11_00-32-50
  done: false
  episode_len_mean: 841.8196202531645
  episode_reward_max: 290.8686868686866
  episode_reward_mean: 236.71007543792345
  episode_reward_min: 127.98989898989866
  episodes_this_iter: 158
  episodes_total: 3160
  experiment_id: 90a115d7cae042ef9ccd55edbdc29f97
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9155626978193011
        entropy_coeff: 0.00010000000000000002
        kl: 0.007030365290120244
        model: {}
        policy_loss: -0.01700310848121132
        total_loss: 10.904598644801549
        vf_explained_var: 0.9779341816902161
        vf_loss: 10.920287609100342
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.565714285714286
    gpu_util_percent0: 0.29428571428571426
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.5
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 8195
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15368441453082132
    mean_env_wait_ms: 1.1996812387986502
    mean_inference_ms: 4.644684439912164
    mean_raw_obs_processing_ms: 0.40503234323440224
  time_since_restore: 513.452586889267
  time_this_iter_s: 30.039183855056763
  time_total_s: 513.452586889267
  timers:
    learn_throughput: 7134.219
    learn_time_ms: 22678.305
    sample_throughput: 22111.624
    sample_time_ms: 7317.057
    update_time_ms: 30.458
  timestamp: 1602376370
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: '13916_00000'
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13916_00000 | RUNNING  | 172.17.0.4:8195 |     17 |          513.453 | 2750464 |   236.71 |              290.869 |               127.99 |             841.82 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13916_00000:
  custom_metrics:
    time_step_max: 4211
    time_step_mean: 3489.5173539009197
    time_step_min: 3136
  date: 2020-10-11_00-33-20
  done: false
  episode_len_mean: 838.7884671962341
  episode_reward_max: 291.4747474747474
  episode_reward_mean: 237.91581302878734
  episode_reward_min: 127.98989898989866
  episodes_this_iter: 239
  episodes_total: 3399
  experiment_id: 90a115d7cae042ef9ccd55edbdc29f97
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.8869052273886544
        entropy_coeff: 0.00010000000000000002
        kl: 0.0068834822824490926
        model: {}
        policy_loss: -0.01520132414797055
        total_loss: 14.657113007136754
        vf_explained_var: 0.9783468842506409
        vf_loss: 14.671026911054339
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.240000000000002
    gpu_util_percent0: 0.3337142857142857
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.474285714285714
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 8195
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15343009071334865
    mean_env_wait_ms: 1.2008251807868418
    mean_inference_ms: 4.629460569387292
    mean_raw_obs_processing_ms: 0.4041012870921116
  time_since_restore: 543.7048799991608
  time_this_iter_s: 30.2522931098938
  time_total_s: 543.7048799991608
  timers:
    learn_throughput: 7131.364
    learn_time_ms: 22687.385
    sample_throughput: 22177.49
    sample_time_ms: 7295.325
    update_time_ms: 31.344
  timestamp: 1602376400
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: '13916_00000'
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13916_00000 | RUNNING  | 172.17.0.4:8195 |     18 |          543.705 | 2912256 |  237.916 |              291.475 |               127.99 |            838.788 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13916_00000:
  custom_metrics:
    time_step_max: 4211
    time_step_mean: 3481.8696255201107
    time_step_min: 3136
  date: 2020-10-11_00-33-50
  done: false
  episode_len_mean: 836.3773740710157
  episode_reward_max: 291.4747474747474
  episode_reward_mean: 239.02393881006589
  episode_reward_min: 127.98989898989866
  episodes_this_iter: 234
  episodes_total: 3633
  experiment_id: 90a115d7cae042ef9ccd55edbdc29f97
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.882507209266935
        entropy_coeff: 0.00010000000000000002
        kl: 0.00652917694034321
        model: {}
        policy_loss: -0.017236768455144817
        total_loss: 9.16027035032
        vf_explained_var: 0.984801173210144
        vf_loss: 9.176289422171456
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.880000000000003
    gpu_util_percent0: 0.2848571428571428
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.485714285714286
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 8195
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1532178375716811
    mean_env_wait_ms: 1.2019325515989088
    mean_inference_ms: 4.616733249805333
    mean_raw_obs_processing_ms: 0.40338935857118274
  time_since_restore: 573.4712765216827
  time_this_iter_s: 29.766396522521973
  time_total_s: 573.4712765216827
  timers:
    learn_throughput: 7135.946
    learn_time_ms: 22672.819
    sample_throughput: 22232.353
    sample_time_ms: 7277.322
    update_time_ms: 32.483
  timestamp: 1602376430
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: '13916_00000'
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13916_00000 | RUNNING  | 172.17.0.4:8195 |     19 |          573.471 | 3074048 |  239.024 |              291.475 |               127.99 |            836.377 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13916_00000:
  custom_metrics:
    time_step_max: 4211
    time_step_mean: 3476.4282678002123
    time_step_min: 3134
  date: 2020-10-11_00-34-21
  done: true
  episode_len_mean: 834.824894514768
  episode_reward_max: 291.4747474747474
  episode_reward_mean: 239.86030398925962
  episode_reward_min: 127.98989898989866
  episodes_this_iter: 159
  episodes_total: 3792
  experiment_id: 90a115d7cae042ef9ccd55edbdc29f97
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.8674141424042838
        entropy_coeff: 0.00010000000000000002
        kl: 0.007427827588149479
        model: {}
        policy_loss: -0.01721697155153379
        total_loss: 7.904539142336164
        vf_explained_var: 0.9836692214012146
        vf_loss: 7.920357329504831
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.347222222222218
    gpu_util_percent0: 0.31138888888888894
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497222222222222
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 8195
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15307667713289694
    mean_env_wait_ms: 1.20260771800417
    mean_inference_ms: 4.608595696380417
    mean_raw_obs_processing_ms: 0.4029184590154806
  time_since_restore: 603.8444395065308
  time_this_iter_s: 30.373162984848022
  time_total_s: 603.8444395065308
  timers:
    learn_throughput: 7136.803
    learn_time_ms: 22670.095
    sample_throughput: 22184.861
    sample_time_ms: 7292.901
    update_time_ms: 32.353
  timestamp: 1602376461
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: '13916_00000'
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13916_00000 | TERMINATED |       |     20 |          603.844 | 3235840 |   239.86 |              291.475 |               127.99 |            834.825 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13916_00000 | TERMINATED |       |     20 |          603.844 | 3235840 |   239.86 |              291.475 |               127.99 |            834.825 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


