2020-10-10 17:49:49,532	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8266[39m[22m
== Status ==
Memory usage on this node: 32.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_feec8_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=49783)[0m 2020-10-10 17:49:52,443	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=49756)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49756)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49745)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49745)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49796)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49796)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49735)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49735)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49777)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49777)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49758)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49758)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49791)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49791)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49800)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49800)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49797)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49797)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49751)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49751)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49792)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49792)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49749)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49749)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49747)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49747)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49740)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49740)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49781)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49781)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49794)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49794)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49753)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49753)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49665)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49665)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49750)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49750)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49667)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49667)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49696)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49696)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49734)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49734)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49700)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49700)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49675)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49675)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49746)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49746)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49774)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49774)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49678)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49678)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49733)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49733)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49775)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49775)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49682)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49682)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49743)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49743)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49744)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49744)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49683)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49683)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49789)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49789)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49699)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49699)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49730)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49730)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49684)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49684)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49695)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49695)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49674)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49674)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49737)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49737)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49754)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49754)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49741)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49741)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49780)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49780)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49759)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49759)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49704)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49704)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49688)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49688)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49729)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49729)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49690)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49690)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49739)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49739)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49732)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49732)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49692)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49692)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49679)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49679)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49671)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49671)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49686)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49686)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49664)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49664)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49680)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49680)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49668)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49668)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49666)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49666)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49736)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49736)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49760)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49760)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49769)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49769)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49748)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49748)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49672)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49672)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49670)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49670)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49763)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49763)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49693)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49693)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49707)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49707)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49785)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49785)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49731)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49731)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49669)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49669)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49787)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49787)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49738)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49738)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49804)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49804)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49761)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49761)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49676)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49676)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49742)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49742)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49768)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49768)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49702)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49702)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=49773)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49773)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_feec8_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-10_17-50-38
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: cc140dfa738c444ab5f9a69c51a46abc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.1844769716262817
        entropy_coeff: 0.0
        kl: 0.004386315321815866
        model: {}
        policy_loss: -0.0037442029362344848
        total_loss: 13.656439304351807
        vf_explained_var: 0.6189822554588318
        vf_loss: 13.6593063218253
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.259183673469387
    gpu_util_percent0: 0.3791836734693877
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.00020408163265306123
    ram_util_percent: 6.30204081632653
    vram_util_percent0: 0.19392775148760716
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 49783
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17321034249202377
    mean_env_wait_ms: 1.1957466753223274
    mean_inference_ms: 5.714016711502099
    mean_raw_obs_processing_ms: 0.4642137402036596
  time_since_restore: 40.11212372779846
  time_this_iter_s: 40.11212372779846
  time_total_s: 40.11212372779846
  timers:
    learn_throughput: 5216.429
    learn_time_ms: 31015.854
    sample_throughput: 17944.616
    sample_time_ms: 9016.186
    update_time_ms: 37.904
  timestamp: 1602352238
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: feec8_00000
  
== Status ==
Memory usage on this node: 48.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_feec8_00000 | RUNNING  | 172.17.0.4:49783 |      1 |          40.1121 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_feec8_00000:
  custom_metrics:
    time_step_max: 4214
    time_step_mean: 3609.8020833333335
    time_step_min: 3365
  date: 2020-10-10_17-51-17
  done: false
  episode_len_mean: 882.1772151898734
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 218.86542641605914
  episode_reward_min: 127.53535353535342
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: cc140dfa738c444ab5f9a69c51a46abc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.1535696046692985
        entropy_coeff: 0.0
        kl: 0.007110523259533303
        model: {}
        policy_loss: -0.005326326786806541
        total_loss: 10.858229500906807
        vf_explained_var: 0.8324812054634094
        vf_loss: 10.86284487588065
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.79148936170213
    gpu_util_percent0: 0.4187234042553191
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.474468085106382
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267445
    vram_util_percent2: 0.0009075233687267445
  pid: 49783
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16832858414835866
    mean_env_wait_ms: 1.1929298492221805
    mean_inference_ms: 5.501319352166409
    mean_raw_obs_processing_ms: 0.4512414769656579
  time_since_restore: 78.88926482200623
  time_this_iter_s: 38.777141094207764
  time_total_s: 78.88926482200623
  timers:
    learn_throughput: 5237.587
    learn_time_ms: 30890.559
    sample_throughput: 19116.045
    sample_time_ms: 8463.675
    update_time_ms: 41.289
  timestamp: 1602352277
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: feec8_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_feec8_00000 | RUNNING  | 172.17.0.4:49783 |      2 |          78.8893 | 323584 |  218.865 |              258.596 |              127.535 |            882.177 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_feec8_00000:
  custom_metrics:
    time_step_max: 4214
    time_step_mean: 3605.6121076233185
    time_step_min: 3358
  date: 2020-10-10_17-51-55
  done: false
  episode_len_mean: 871.9810126582279
  episode_reward_max: 267.98989898989936
  episode_reward_mean: 220.35468610152134
  episode_reward_min: 127.53535353535342
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: cc140dfa738c444ab5f9a69c51a46abc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.1374446153640747
        entropy_coeff: 0.0
        kl: 0.008115017054868596
        model: {}
        policy_loss: -0.0056598213413963094
        total_loss: 12.499453817095075
        vf_explained_var: 0.8891684412956238
        vf_loss: 12.504301820482526
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.210869565217394
    gpu_util_percent0: 0.35152173913043483
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.489130434782608
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 49783
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16529467319312996
    mean_env_wait_ms: 1.1938071139498858
    mean_inference_ms: 5.337748408468797
    mean_raw_obs_processing_ms: 0.4419648858617768
  time_since_restore: 117.23322868347168
  time_this_iter_s: 38.343963861465454
  time_total_s: 117.23322868347168
  timers:
    learn_throughput: 5250.438
    learn_time_ms: 30814.951
    sample_throughput: 19806.315
    sample_time_ms: 8168.708
    update_time_ms: 39.896
  timestamp: 1602352315
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: feec8_00000
  
== Status ==
Memory usage on this node: 48.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_feec8_00000 | RUNNING  | 172.17.0.4:49783 |      3 |          117.233 | 485376 |  220.355 |               267.99 |              127.535 |            871.981 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_feec8_00000:
  custom_metrics:
    time_step_max: 4214
    time_step_mean: 3599.5860927152316
    time_step_min: 3307
  date: 2020-10-10_17-52-34
  done: false
  episode_len_mean: 863.9620253164557
  episode_reward_max: 267.98989898989936
  episode_reward_mean: 221.21079465541473
  episode_reward_min: 127.53535353535342
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: cc140dfa738c444ab5f9a69c51a46abc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.1081778832844325
        entropy_coeff: 0.0
        kl: 0.005774352034287793
        model: {}
        policy_loss: -0.005334485530121518
        total_loss: 14.174989019121442
        vf_explained_var: 0.9168268442153931
        vf_loss: 14.179745946611677
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.070212765957447
    gpu_util_percent0: 0.35148936170212763
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.487234042553191
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267445
    vram_util_percent2: 0.0009075233687267445
  pid: 49783
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16312817225924214
    mean_env_wait_ms: 1.1963829147903453
    mean_inference_ms: 5.216009559398922
    mean_raw_obs_processing_ms: 0.4349450296374658
  time_since_restore: 155.6952748298645
  time_this_iter_s: 38.46204614639282
  time_total_s: 155.6952748298645
  timers:
    learn_throughput: 5239.78
    learn_time_ms: 30877.635
    sample_throughput: 20374.123
    sample_time_ms: 7941.053
    update_time_ms: 52.756
  timestamp: 1602352354
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: feec8_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_feec8_00000 | RUNNING  | 172.17.0.4:49783 |      4 |          155.695 | 647168 |  221.211 |               267.99 |              127.535 |            863.962 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_feec8_00000:
  custom_metrics:
    time_step_max: 4282
    time_step_mean: 3593.9785310734464
    time_step_min: 3286
  date: 2020-10-10_17-53-12
  done: false
  episode_len_mean: 850.7677984665936
  episode_reward_max: 281.62626262626304
  episode_reward_mean: 221.2274774027237
  episode_reward_min: 117.23232323232313
  episodes_this_iter: 281
  episodes_total: 913
  experiment_id: cc140dfa738c444ab5f9a69c51a46abc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.0742692947387695
        entropy_coeff: 0.0
        kl: 0.005315700346337897
        model: {}
        policy_loss: -0.0047804775728894
        total_loss: 19.71224239894322
        vf_explained_var: 0.9491860270500183
        vf_loss: 19.716491154262
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.50869565217391
    gpu_util_percent0: 0.3502173913043478
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.482608695652175
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 49783
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16065180305501253
    mean_env_wait_ms: 1.2030824246202103
    mean_inference_ms: 5.0716058295587345
    mean_raw_obs_processing_ms: 0.42690064775398856
  time_since_restore: 194.14684653282166
  time_this_iter_s: 38.45157170295715
  time_total_s: 194.14684653282166
  timers:
    learn_throughput: 5236.419
    learn_time_ms: 30897.451
    sample_throughput: 20662.975
    sample_time_ms: 7830.044
    update_time_ms: 50.014
  timestamp: 1602352392
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: feec8_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_feec8_00000 | RUNNING  | 172.17.0.4:49783 |      5 |          194.147 | 808960 |  221.227 |              281.626 |              117.232 |            850.768 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_feec8_00000:
  custom_metrics:
    time_step_max: 4282
    time_step_mean: 3592.4415584415583
    time_step_min: 3286
  date: 2020-10-10_17-53-50
  done: false
  episode_len_mean: 843.5849909584086
  episode_reward_max: 281.62626262626304
  episode_reward_mean: 221.48433704129894
  episode_reward_min: 106.77777777777766
  episodes_this_iter: 193
  episodes_total: 1106
  experiment_id: cc140dfa738c444ab5f9a69c51a46abc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.065455905028752
        entropy_coeff: 0.0
        kl: 0.004622354970446655
        model: {}
        policy_loss: -0.005600613949354738
        total_loss: 13.345600060054235
        vf_explained_var: 0.9576212763786316
        vf_loss: 13.350738865988594
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.985106382978724
    gpu_util_percent0: 0.4102127659574468
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.491489361702128
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267445
    vram_util_percent2: 0.0009075233687267445
  pid: 49783
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1594271860420813
    mean_env_wait_ms: 1.2065911587931442
    mean_inference_ms: 5.001270902247341
    mean_raw_obs_processing_ms: 0.42308257037042596
  time_since_restore: 232.398619890213
  time_this_iter_s: 38.25177335739136
  time_total_s: 232.398619890213
  timers:
    learn_throughput: 5242.001
    learn_time_ms: 30864.548
    sample_throughput: 20846.373
    sample_time_ms: 7761.158
    update_time_ms: 55.427
  timestamp: 1602352430
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: feec8_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_feec8_00000 | RUNNING  | 172.17.0.4:49783 |      6 |          232.399 | 970752 |  221.484 |              281.626 |              106.778 |            843.585 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_feec8_00000:
  custom_metrics:
    time_step_max: 4282
    time_step_mean: 3588.0558252427186
    time_step_min: 3262
  date: 2020-10-10_17-54-29
  done: false
  episode_len_mean: 838.8924050632911
  episode_reward_max: 281.62626262626304
  episode_reward_mean: 222.03441855261465
  episode_reward_min: 106.77777777777766
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: cc140dfa738c444ab5f9a69c51a46abc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 1.0e-05
        entropy: 1.0288806217057365
        entropy_coeff: 0.0
        kl: 0.006252241287646549
        model: {}
        policy_loss: -0.005688114021073228
        total_loss: 9.47962134225028
        vf_explained_var: 0.9746829271316528
        vf_loss: 9.484997136252266
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.295652173913044
    gpu_util_percent0: 0.35956521739130426
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4913043478260875
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 49783
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1586123491300136
    mean_env_wait_ms: 1.2090445970731105
    mean_inference_ms: 4.9543157812751915
    mean_raw_obs_processing_ms: 0.42049136788326763
  time_since_restore: 270.8129827976227
  time_this_iter_s: 38.41436290740967
  time_total_s: 270.8129827976227
  timers:
    learn_throughput: 5236.171
    learn_time_ms: 30898.913
    sample_throughput: 21054.987
    sample_time_ms: 7684.26
    update_time_ms: 52.556
  timestamp: 1602352469
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: feec8_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_feec8_00000 | RUNNING  | 172.17.0.4:49783 |      7 |          270.813 | 1132544 |  222.034 |              281.626 |              106.778 |            838.892 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_feec8_00000:
  custom_metrics:
    time_step_max: 4282
    time_step_mean: 3584.9727403156385
    time_step_min: 3262
  date: 2020-10-10_17-55-08
  done: false
  episode_len_mean: 835.0386779184248
  episode_reward_max: 281.62626262626304
  episode_reward_mean: 222.58063759962482
  episode_reward_min: 106.77777777777766
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: cc140dfa738c444ab5f9a69c51a46abc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 1.0e-05
        entropy: 0.9802433124610356
        entropy_coeff: 0.0
        kl: 0.005615057257403221
        model: {}
        policy_loss: -0.0047087079645799735
        total_loss: 8.337698698043823
        vf_explained_var: 0.9815921187400818
        vf_loss: 8.342126778193883
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.83404255319149
    gpu_util_percent0: 0.36829787234042544
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4914893617021265
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267445
    vram_util_percent2: 0.0009075233687267445
  pid: 49783
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1579197051343967
    mean_env_wait_ms: 1.2114407956566433
    mean_inference_ms: 4.91366330157681
    mean_raw_obs_processing_ms: 0.4181901326458657
  time_since_restore: 309.3720233440399
  time_this_iter_s: 38.559040546417236
  time_total_s: 309.3720233440399
  timers:
    learn_throughput: 5234.208
    learn_time_ms: 30910.503
    sample_throughput: 21124.039
    sample_time_ms: 7659.141
    update_time_ms: 49.437
  timestamp: 1602352508
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: feec8_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_feec8_00000 | RUNNING  | 172.17.0.4:49783 |      8 |          309.372 | 1294336 |  222.581 |              281.626 |              106.778 |            835.039 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_feec8_00000:
  custom_metrics:
    time_step_max: 4282
    time_step_mean: 3579.6140350877195
    time_step_min: 3262
  date: 2020-10-10_17-55-46
  done: false
  episode_len_mean: 828.3314154200231
  episode_reward_max: 281.62626262626304
  episode_reward_mean: 223.65262521649166
  episode_reward_min: 106.77777777777766
  episodes_this_iter: 316
  episodes_total: 1738
  experiment_id: cc140dfa738c444ab5f9a69c51a46abc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 1.0e-05
        entropy: 0.9392602060522351
        entropy_coeff: 0.0
        kl: 0.005209643293970397
        model: {}
        policy_loss: -0.004235365885376398
        total_loss: 9.747053282601494
        vf_explained_var: 0.9869093298912048
        vf_loss: 9.751028265271868
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.264444444444447
    gpu_util_percent0: 0.40555555555555556
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4799999999999995
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 49783
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15681660574327153
    mean_env_wait_ms: 1.2160546149826599
    mean_inference_ms: 4.8492447851998906
    mean_raw_obs_processing_ms: 0.4146903981759877
  time_since_restore: 347.30982780456543
  time_this_iter_s: 37.93780446052551
  time_total_s: 347.30982780456543
  timers:
    learn_throughput: 5241.254
    learn_time_ms: 30868.949
    sample_throughput: 21224.855
    sample_time_ms: 7622.761
    update_time_ms: 46.072
  timestamp: 1602352546
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: feec8_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_feec8_00000 | RUNNING  | 172.17.0.4:49783 |      9 |           347.31 | 1456128 |  223.653 |              281.626 |              106.778 |            828.331 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_feec8_00000:
  custom_metrics:
    time_step_max: 4282
    time_step_mean: 3578.945931477516
    time_step_min: 3262
  date: 2020-10-10_17-56-24
  done: false
  episode_len_mean: 825.5427215189874
  episode_reward_max: 281.62626262626304
  episode_reward_mean: 224.0806322720879
  episode_reward_min: 106.77777777777766
  episodes_this_iter: 158
  episodes_total: 1896
  experiment_id: cc140dfa738c444ab5f9a69c51a46abc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 1.0e-05
        entropy: 0.8890338625226702
        entropy_coeff: 0.0
        kl: 0.005402878392487764
        model: {}
        policy_loss: -0.004951527570873233
        total_loss: 5.112921612603324
        vf_explained_var: 0.9904587864875793
        vf_loss: 5.117603131702968
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.685106382978724
    gpu_util_percent0: 0.37425531914893617
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.493617021276595
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267445
    vram_util_percent2: 0.0009075233687267445
  pid: 49783
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15637245533695388
    mean_env_wait_ms: 1.2180574456067412
    mean_inference_ms: 4.823135274113834
    mean_raw_obs_processing_ms: 0.41327432424959987
  time_since_restore: 385.5473062992096
  time_this_iter_s: 38.237478494644165
  time_total_s: 385.5473062992096
  timers:
    learn_throughput: 5240.692
    learn_time_ms: 30872.258
    sample_throughput: 21332.499
    sample_time_ms: 7584.297
    update_time_ms: 45.77
  timestamp: 1602352584
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: feec8_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_feec8_00000 | RUNNING  | 172.17.0.4:49783 |     10 |          385.547 | 1617920 |  224.081 |              281.626 |              106.778 |            825.543 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_feec8_00000:
  custom_metrics:
    time_step_max: 4282
    time_step_mean: 3576.7749259624875
    time_step_min: 3262
  date: 2020-10-10_17-57-02
  done: false
  episode_len_mean: 823.6056475170399
  episode_reward_max: 281.62626262626304
  episode_reward_mean: 224.40126188860359
  episode_reward_min: 106.77777777777766
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: cc140dfa738c444ab5f9a69c51a46abc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 1.0e-05
        entropy: 0.8681367039680481
        entropy_coeff: 0.0
        kl: 0.0043278161236750224
        model: {}
        policy_loss: -0.004471761695770381
        total_loss: 4.681305919374738
        vf_explained_var: 0.9914104342460632
        vf_loss: 4.685561350413731
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.92391304347826
    gpu_util_percent0: 0.41
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.495652173913044
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 49783
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15597648906297898
    mean_env_wait_ms: 1.2199062465837633
    mean_inference_ms: 4.79959320856716
    mean_raw_obs_processing_ms: 0.4119747452786441
  time_since_restore: 423.74342823028564
  time_this_iter_s: 38.19612193107605
  time_total_s: 423.74342823028564
  timers:
    learn_throughput: 5245.11
    learn_time_ms: 30846.256
    sample_throughput: 21825.106
    sample_time_ms: 7413.114
    update_time_ms: 43.906
  timestamp: 1602352622
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: feec8_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_feec8_00000 | RUNNING  | 172.17.0.4:49783 |     11 |          423.743 | 1779712 |  224.401 |              281.626 |              106.778 |            823.606 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_feec8_00000:
  custom_metrics:
    time_step_max: 4282
    time_step_mean: 3571.6160714285716
    time_step_min: 3262
  date: 2020-10-10_17-57-41
  done: false
  episode_len_mean: 821.1512345679013
  episode_reward_max: 281.62626262626304
  episode_reward_mean: 224.87067767623319
  episode_reward_min: 106.77777777777766
  episodes_this_iter: 214
  episodes_total: 2268
  experiment_id: cc140dfa738c444ab5f9a69c51a46abc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025000000000000005
        cur_lr: 1.0e-05
        entropy: 0.8356675633362362
        entropy_coeff: 0.0
        kl: 0.004127256538985031
        model: {}
        policy_loss: -0.0038176761175106677
        total_loss: 5.3023556641169955
        vf_explained_var: 0.9932727217674255
        vf_loss: 5.306070191519601
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.01304347826087
    gpu_util_percent0: 0.34608695652173915
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.486956521739131
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 49783
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15551116388768568
    mean_env_wait_ms: 1.222428404636539
    mean_inference_ms: 4.771706386515036
    mean_raw_obs_processing_ms: 0.4104183750354377
  time_since_restore: 462.1881687641144
  time_this_iter_s: 38.444740533828735
  time_total_s: 462.1881687641144
  timers:
    learn_throughput: 5244.628
    learn_time_ms: 30849.09
    sample_throughput: 21931.592
    sample_time_ms: 7377.121
    update_time_ms: 43.648
  timestamp: 1602352661
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: feec8_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_feec8_00000 | RUNNING  | 172.17.0.4:49783 |     12 |          462.188 | 1941504 |  224.871 |              281.626 |              106.778 |            821.151 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_feec8_00000:
  custom_metrics:
    time_step_max: 4282
    time_step_mean: 3566.3432
    time_step_min: 3262
  date: 2020-10-10_17-58-20
  done: false
  episode_len_mean: 818.8144778481013
  episode_reward_max: 281.62626262626304
  episode_reward_mean: 225.55936341260707
  episode_reward_min: 106.77777777777766
  episodes_this_iter: 260
  episodes_total: 2528
  experiment_id: cc140dfa738c444ab5f9a69c51a46abc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.012500000000000002
        cur_lr: 1.0e-05
        entropy: 0.7914616976465497
        entropy_coeff: 0.0
        kl: 0.004030108668043145
        model: {}
        policy_loss: -0.0041341033730922004
        total_loss: 4.8097047465188165
        vf_explained_var: 0.9928188920021057
        vf_loss: 4.813788482121059
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.676595744680856
    gpu_util_percent0: 0.32659574468085106
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.491489361702128
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267445
    vram_util_percent2: 0.0009075233687267445
  pid: 49783
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15500381366227065
    mean_env_wait_ms: 1.2249587231320513
    mean_inference_ms: 4.741975500494673
    mean_raw_obs_processing_ms: 0.40875919518850445
  time_since_restore: 500.9345660209656
  time_this_iter_s: 38.746397256851196
  time_total_s: 500.9345660209656
  timers:
    learn_throughput: 5235.296
    learn_time_ms: 30904.082
    sample_throughput: 21968.358
    sample_time_ms: 7364.774
    update_time_ms: 42.212
  timestamp: 1602352700
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: feec8_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_feec8_00000 | RUNNING  | 172.17.0.4:49783 |     13 |          500.935 | 2103296 |  225.559 |              281.626 |              106.778 |            818.814 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_feec8_00000:
  custom_metrics:
    time_step_max: 4282
    time_step_mean: 3564.5492851768245
    time_step_min: 3262
  date: 2020-10-10_17-58-59
  done: false
  episode_len_mean: 817.7974683544304
  episode_reward_max: 281.62626262626304
  episode_reward_mean: 225.98573598983128
  episode_reward_min: 106.77777777777766
  episodes_this_iter: 158
  episodes_total: 2686
  experiment_id: cc140dfa738c444ab5f9a69c51a46abc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.006250000000000001
        cur_lr: 1.0e-05
        entropy: 0.7754085787705013
        entropy_coeff: 0.0
        kl: 0.0038169645870636615
        model: {}
        policy_loss: -0.0032732371224223505
        total_loss: 3.431881751332964
        vf_explained_var: 0.9941803216934204
        vf_loss: 3.4351310900279453
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.906382978723407
    gpu_util_percent0: 0.32340425531914896
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497872340425531
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267445
    vram_util_percent2: 0.0009075233687267445
  pid: 49783
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15474193565954505
    mean_env_wait_ms: 1.2263565864875416
    mean_inference_ms: 4.72625782702108
    mean_raw_obs_processing_ms: 0.40788527182355444
  time_since_restore: 539.8213477134705
  time_this_iter_s: 38.88678169250488
  time_total_s: 539.8213477134705
  timers:
    learn_throughput: 5231.204
    learn_time_ms: 30928.251
    sample_throughput: 21903.503
    sample_time_ms: 7386.581
    update_time_ms: 36.462
  timestamp: 1602352739
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: feec8_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_feec8_00000 | RUNNING  | 172.17.0.4:49783 |     14 |          539.821 | 2265088 |  225.986 |              281.626 |              106.778 |            817.797 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_feec8_00000:
  custom_metrics:
    time_step_max: 4282
    time_step_mean: 3561.0454545454545
    time_step_min: 3262
  date: 2020-10-10_17-59-37
  done: false
  episode_len_mean: 816.8674402250351
  episode_reward_max: 281.62626262626304
  episode_reward_mean: 226.60596471039506
  episode_reward_min: 106.77777777777766
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: cc140dfa738c444ab5f9a69c51a46abc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0031250000000000006
        cur_lr: 1.0e-05
        entropy: 0.7652191136564527
        entropy_coeff: 0.0
        kl: 0.0035549591328682645
        model: {}
        policy_loss: -0.005285486067545467
        total_loss: 3.142848406519209
        vf_explained_var: 0.9945008158683777
        vf_loss: 3.148122719355992
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.150000000000006
    gpu_util_percent0: 0.32434782608695656
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.50217391304348
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 49783
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1545027991833455
    mean_env_wait_ms: 1.2276705029795332
    mean_inference_ms: 4.711727190953038
    mean_raw_obs_processing_ms: 0.407063657918493
  time_since_restore: 578.2256417274475
  time_this_iter_s: 38.40429401397705
  time_total_s: 578.2256417274475
  timers:
    learn_throughput: 5234.129
    learn_time_ms: 30910.968
    sample_throughput: 21871.262
    sample_time_ms: 7397.47
    update_time_ms: 36.966
  timestamp: 1602352777
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: feec8_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_feec8_00000 | RUNNING  | 172.17.0.4:49783 |     15 |          578.226 | 2426880 |  226.606 |              281.626 |              106.778 |            816.867 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_feec8_00000:
  custom_metrics:
    time_step_max: 4282
    time_step_mean: 3553.810438680756
    time_step_min: 3247
  date: 2020-10-10_18-00-16
  done: true
  episode_len_mean: 815.1520152332592
  episode_reward_max: 281.62626262626304
  episode_reward_mean: 227.59132422286976
  episode_reward_min: 106.77777777777766
  episodes_this_iter: 307
  episodes_total: 3151
  experiment_id: cc140dfa738c444ab5f9a69c51a46abc
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0015625000000000003
        cur_lr: 1.0e-05
        entropy: 0.7329457870551518
        entropy_coeff: 0.0
        kl: 0.003261061667996858
        model: {}
        policy_loss: -0.00348082953964227
        total_loss: 4.279234886169434
        vf_explained_var: 0.9946030378341675
        vf_loss: 4.282710620335171
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.638297872340427
    gpu_util_percent0: 0.4138297872340425
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4851063829787226
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267445
    vram_util_percent2: 0.0009075233687267445
  pid: 49783
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15409039703219335
    mean_env_wait_ms: 1.230042291437554
    mean_inference_ms: 4.686961980093524
    mean_raw_obs_processing_ms: 0.405709941938428
  time_since_restore: 616.8662188053131
  time_this_iter_s: 38.6405770778656
  time_total_s: 616.8662188053131
  timers:
    learn_throughput: 5229.612
    learn_time_ms: 30937.67
    sample_throughput: 21828.03
    sample_time_ms: 7412.121
    update_time_ms: 32.491
  timestamp: 1602352816
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: feec8_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_feec8_00000 | TERMINATED |       |     16 |          616.866 | 2588672 |  227.591 |              281.626 |              106.778 |            815.152 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


[2m[33m(pid=raylet)[0m E1010 18:00:16.512746 49623 49623 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 2: HandleServiceClosed
[2m[33m(pid=raylet)[0m E1010 18:00:16.512982 49623 49623 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 2: HandleServiceClosed
[2m[33m(pid=raylet)[0m E1010 18:00:16.513073 49623 49623 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 2: HandleServiceClosed
[2m[33m(pid=raylet)[0m E1010 18:00:16.513135 49623 49623 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 2: HandleServiceClosed
[2m[33m(pid=raylet)[0m E1010 18:00:16.566051 49623 49623 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 2: HandleServiceClosed
[2m[33m(pid=raylet)[0m E1010 18:00:16.567567 49623 49623 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 2: HandleServiceClosed
== Status ==
Memory usage on this node: 48.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_feec8_00000 | TERMINATED |       |     16 |          616.866 | 2588672 |  227.591 |              281.626 |              106.778 |            815.152 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


[2m[33m(pid=raylet)[0m E1010 18:00:16.572659 49623 49623 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 2: HandleServiceClosed
