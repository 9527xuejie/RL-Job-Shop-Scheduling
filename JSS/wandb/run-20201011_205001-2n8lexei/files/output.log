2020-10-11 20:50:05,155	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_57f23_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=37257)[0m 2020-10-11 20:50:07,972	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=37232)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37232)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37263)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37263)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37237)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37237)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37160)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37160)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37220)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37220)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37238)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37238)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37219)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37219)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37271)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37271)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37178)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37178)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37201)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37201)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37225)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37225)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37223)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37223)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37213)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37213)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37207)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37207)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37241)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37241)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37259)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37259)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37247)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37247)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37261)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37261)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37234)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37234)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37273)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37273)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37210)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37210)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37157)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37157)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37235)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37235)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37251)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37251)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37166)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37166)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37142)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37142)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37200)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37200)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37149)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37149)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37146)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37146)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37182)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37182)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37282)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37282)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37224)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37224)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37215)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37215)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37214)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37214)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37155)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37155)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37197)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37197)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37177)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37177)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37266)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37266)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37242)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37242)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37141)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37141)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37159)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37159)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37205)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37205)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37162)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37162)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37221)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37221)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37140)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37140)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37170)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37170)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37248)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37248)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37158)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37158)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37245)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37245)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37217)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37217)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37161)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37161)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37204)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37204)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37153)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37153)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37176)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37176)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37143)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37143)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37203)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37203)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37236)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37236)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37278)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37278)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37154)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37154)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37250)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37250)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37222)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37222)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37145)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37145)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37173)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37173)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37226)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37226)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37229)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37229)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37230)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37230)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37228)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37228)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37218)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37218)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37233)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37233)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37150)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37150)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37163)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37163)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37268)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37268)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37144)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37144)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37168)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37168)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37152)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37152)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37260)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37260)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37216)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37216)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37147)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37147)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37174)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37174)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_57f23_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-11_20-50-42
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 2c4c9d1a032f4f60b4e49b42a49eb793
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1851047078768413
        entropy_coeff: 0.0005000000000000001
        kl: 0.004071502441850801
        model: {}
        policy_loss: -0.00785889983914482
        total_loss: 507.07567087809247
        vf_explained_var: 0.540532648563385
        vf_loss: 507.0832926432292
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.602941176470587
    gpu_util_percent0: 0.26294117647058823
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5676470588235296
    vram_util_percent0: 0.08659058900700328
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 37257
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16776829819945724
    mean_env_wait_ms: 1.1590575435788
    mean_inference_ms: 5.636969428255295
    mean_raw_obs_processing_ms: 0.44418268713107556
  time_since_restore: 28.716503381729126
  time_this_iter_s: 28.716503381729126
  time_total_s: 28.716503381729126
  timers:
    learn_throughput: 8268.867
    learn_time_ms: 19566.404
    sample_throughput: 17811.996
    sample_time_ms: 9083.317
    update_time_ms: 25.783
  timestamp: 1602449442
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 57f23_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_57f23_00000 | RUNNING  | 172.17.0.4:37257 |      1 |          28.7165 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_57f23_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3614.4305555555557
    time_step_min: 3250
  date: 2020-10-11_20-51-09
  done: false
  episode_len_mean: 890.8607594936709
  episode_reward_max: 273.5959595959592
  episode_reward_mean: 217.6365234624726
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 2c4c9d1a032f4f60b4e49b42a49eb793
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1561074058214824
        entropy_coeff: 0.0005000000000000001
        kl: 0.007923512797181806
        model: {}
        policy_loss: -0.010965243893830726
        total_loss: 127.46906661987305
        vf_explained_var: 0.8076093792915344
        vf_loss: 127.47981770833333
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.793548387096774
    gpu_util_percent0: 0.3754838709677419
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7580645161290316
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 37257
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1641719786222011
    mean_env_wait_ms: 1.1571251717808861
    mean_inference_ms: 5.450378231973181
    mean_raw_obs_processing_ms: 0.4348042526165878
  time_since_restore: 55.82824516296387
  time_this_iter_s: 27.11174178123474
  time_total_s: 55.82824516296387
  timers:
    learn_throughput: 8314.425
    learn_time_ms: 19459.192
    sample_throughput: 19291.922
    sample_time_ms: 8386.515
    update_time_ms: 22.338
  timestamp: 1602449469
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 57f23_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_57f23_00000 | RUNNING  | 172.17.0.4:37257 |      2 |          55.8282 | 323584 |  217.637 |              273.596 |              145.717 |            890.861 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_57f23_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3601.8677130044844
    time_step_min: 3250
  date: 2020-10-11_20-51-35
  done: false
  episode_len_mean: 885.132911392405
  episode_reward_max: 273.5959595959592
  episode_reward_mean: 219.87009333844756
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 2c4c9d1a032f4f60b4e49b42a49eb793
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1456398169199626
        entropy_coeff: 0.0005000000000000001
        kl: 0.008224547879459957
        model: {}
        policy_loss: -0.013529085864623388
        total_loss: 61.275455474853516
        vf_explained_var: 0.8916645646095276
        vf_loss: 61.28873507181803
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.764516129032263
    gpu_util_percent0: 0.4045161290322581
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7774193548387096
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 37257
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16153199701032797
    mean_env_wait_ms: 1.1575292499687186
    mean_inference_ms: 5.28509801236235
    mean_raw_obs_processing_ms: 0.4265118857400026
  time_since_restore: 82.30366969108582
  time_this_iter_s: 26.47542452812195
  time_total_s: 82.30366969108582
  timers:
    learn_throughput: 8340.997
    learn_time_ms: 19397.202
    sample_throughput: 20306.88
    sample_time_ms: 7967.349
    update_time_ms: 21.561
  timestamp: 1602449495
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 57f23_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_57f23_00000 | RUNNING  | 172.17.0.4:37257 |      3 |          82.3037 | 485376 |   219.87 |              273.596 |              145.717 |            885.133 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_57f23_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3596.0099337748343
    time_step_min: 3231
  date: 2020-10-11_20-52-02
  done: false
  episode_len_mean: 878.7689873417721
  episode_reward_max: 276.47474747474763
  episode_reward_mean: 220.6047340493541
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 2c4c9d1a032f4f60b4e49b42a49eb793
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1263898611068726
        entropy_coeff: 0.0005000000000000001
        kl: 0.008100568510902425
        model: {}
        policy_loss: -0.013406771836647144
        total_loss: 47.16934140523275
        vf_explained_var: 0.9198758602142334
        vf_loss: 47.18250052134196
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.280000000000005
    gpu_util_percent0: 0.27033333333333337
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.776666666666667
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 37257
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15963624484748126
    mean_env_wait_ms: 1.1589908530391595
    mean_inference_ms: 5.16074383940212
    mean_raw_obs_processing_ms: 0.42000089194544216
  time_since_restore: 108.65606307983398
  time_this_iter_s: 26.35239338874817
  time_total_s: 108.65606307983398
  timers:
    learn_throughput: 8343.985
    learn_time_ms: 19390.254
    sample_throughput: 21002.803
    sample_time_ms: 7703.353
    update_time_ms: 22.24
  timestamp: 1602449522
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 57f23_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_57f23_00000 | RUNNING  | 172.17.0.4:37257 |      4 |          108.656 | 647168 |  220.605 |              276.475 |              145.717 |            878.769 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_57f23_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3581.6985583224114
    time_step_min: 3204
  date: 2020-10-11_20-52-28
  done: false
  episode_len_mean: 872.4867256637168
  episode_reward_max: 280.5656565656565
  episode_reward_mean: 222.48133675567283
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 159
  episodes_total: 791
  experiment_id: 2c4c9d1a032f4f60b4e49b42a49eb793
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0873714486757915
        entropy_coeff: 0.0005000000000000001
        kl: 0.006956188706681132
        model: {}
        policy_loss: -0.011262792395427823
        total_loss: 34.19948164621989
        vf_explained_var: 0.9459590911865234
        vf_loss: 34.2105925877889
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.303333333333335
    gpu_util_percent0: 0.4106666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.769999999999999
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 37257
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15817950039893686
    mean_env_wait_ms: 1.1613590833916738
    mean_inference_ms: 5.063432853624304
    mean_raw_obs_processing_ms: 0.41486220576747906
  time_since_restore: 135.04889035224915
  time_this_iter_s: 26.39282727241516
  time_total_s: 135.04889035224915
  timers:
    learn_throughput: 8330.201
    learn_time_ms: 19422.341
    sample_throughput: 21546.655
    sample_time_ms: 7508.915
    update_time_ms: 26.246
  timestamp: 1602449548
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 57f23_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_57f23_00000 | RUNNING  | 172.17.0.4:37257 |      5 |          135.049 | 808960 |  222.481 |              280.566 |              145.717 |            872.487 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_57f23_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3564.887755102041
    time_step_min: 3204
  date: 2020-10-11_20-52-55
  done: false
  episode_len_mean: 860.6943942133815
  episode_reward_max: 280.5656565656565
  episode_reward_mean: 225.7112809834327
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 315
  episodes_total: 1106
  experiment_id: 2c4c9d1a032f4f60b4e49b42a49eb793
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0886386533578236
        entropy_coeff: 0.0005000000000000001
        kl: 0.007588425030310948
        model: {}
        policy_loss: -0.01092883839737624
        total_loss: 30.730765342712402
        vf_explained_var: 0.9611188769340515
        vf_loss: 30.741480032602947
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.625806451612906
    gpu_util_percent0: 0.32483870967741935
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.770967741935483
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 37257
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15621525719710777
    mean_env_wait_ms: 1.1668210204516654
    mean_inference_ms: 4.93272834399389
    mean_raw_obs_processing_ms: 0.40834034778017997
  time_since_restore: 161.52393054962158
  time_this_iter_s: 26.475040197372437
  time_total_s: 161.52393054962158
  timers:
    learn_throughput: 8312.905
    learn_time_ms: 19462.752
    sample_throughput: 21937.165
    sample_time_ms: 7375.246
    update_time_ms: 30.484
  timestamp: 1602449575
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 57f23_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_57f23_00000 | RUNNING  | 172.17.0.4:37257 |      6 |          161.524 | 970752 |  225.711 |              280.566 |              145.717 |            860.694 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_57f23_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3552.704692556634
    time_step_min: 3179
  date: 2020-10-11_20-53-21
  done: false
  episode_len_mean: 855.0387658227849
  episode_reward_max: 284.35353535353545
  episode_reward_mean: 227.46978487405684
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: 2c4c9d1a032f4f60b4e49b42a49eb793
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0706470410029094
        entropy_coeff: 0.0005000000000000001
        kl: 0.007387861027382314
        model: {}
        policy_loss: -0.013462736414415607
        total_loss: 19.742233912150066
        vf_explained_var: 0.9632093906402588
        vf_loss: 19.75549300511678
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.756666666666668
    gpu_util_percent0: 0.4333333333333334
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7833333333333328
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 37257
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15550411712357082
    mean_env_wait_ms: 1.1691581697914277
    mean_inference_ms: 4.884967215311216
    mean_raw_obs_processing_ms: 0.4059495908850431
  time_since_restore: 187.9574432373047
  time_this_iter_s: 26.433512687683105
  time_total_s: 187.9574432373047
  timers:
    learn_throughput: 8297.345
    learn_time_ms: 19499.25
    sample_throughput: 22255.226
    sample_time_ms: 7269.843
    update_time_ms: 30.003
  timestamp: 1602449601
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 57f23_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_57f23_00000 | RUNNING  | 172.17.0.4:37257 |      7 |          187.957 | 1132544 |   227.47 |              284.354 |              145.717 |            855.039 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_57f23_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3540.6398852223815
    time_step_min: 3179
  date: 2020-10-11_20-53-47
  done: false
  episode_len_mean: 850.7552742616034
  episode_reward_max: 284.35353535353545
  episode_reward_mean: 229.23441162681647
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 2c4c9d1a032f4f60b4e49b42a49eb793
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0475670397281647
        entropy_coeff: 0.0005000000000000001
        kl: 0.007399068369219701
        model: {}
        policy_loss: -0.009183195322596779
        total_loss: 16.652963479359943
        vf_explained_var: 0.9667003154754639
        vf_loss: 16.661930561065674
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.33666666666667
    gpu_util_percent0: 0.3653333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.783333333333333
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 37257
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1548867606209694
    mean_env_wait_ms: 1.1712627373639917
    mean_inference_ms: 4.843456943180189
    mean_raw_obs_processing_ms: 0.40385329634215633
  time_since_restore: 214.1447422504425
  time_this_iter_s: 26.187299013137817
  time_total_s: 214.1447422504425
  timers:
    learn_throughput: 8301.349
    learn_time_ms: 19489.843
    sample_throughput: 22481.965
    sample_time_ms: 7196.524
    update_time_ms: 29.915
  timestamp: 1602449627
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 57f23_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_57f23_00000 | RUNNING  | 172.17.0.4:37257 |      8 |          214.145 | 1294336 |  229.234 |              284.354 |              145.717 |            850.755 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_57f23_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3526.8721374045804
    time_step_min: 3179
  date: 2020-10-11_20-54-14
  done: false
  episode_len_mean: 845.9875
  episode_reward_max: 285.7171717171716
  episode_reward_mean: 231.28724747474732
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 178
  episodes_total: 1600
  experiment_id: 2c4c9d1a032f4f60b4e49b42a49eb793
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9999773452679316
        entropy_coeff: 0.0005000000000000001
        kl: 0.007928823702968657
        model: {}
        policy_loss: -0.011458211791856835
        total_loss: 16.58501172065735
        vf_explained_var: 0.9729644656181335
        vf_loss: 16.596176783243816
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.57096774193549
    gpu_util_percent0: 0.28903225806451616
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7677419354838704
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 37257
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15428286515965672
    mean_env_wait_ms: 1.1736980224491307
    mean_inference_ms: 4.803458903192215
    mean_raw_obs_processing_ms: 0.40178376287051704
  time_since_restore: 240.7368266582489
  time_this_iter_s: 26.592084407806396
  time_total_s: 240.7368266582489
  timers:
    learn_throughput: 8295.492
    learn_time_ms: 19503.605
    sample_throughput: 22585.993
    sample_time_ms: 7163.378
    update_time_ms: 29.203
  timestamp: 1602449654
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 57f23_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_57f23_00000 | RUNNING  | 172.17.0.4:37257 |      9 |          240.737 | 1456128 |  231.287 |              285.717 |              145.717 |            845.987 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_57f23_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3508.0337259100643
    time_step_min: 3173
  date: 2020-10-11_20-54-41
  done: false
  episode_len_mean: 839.0052742616034
  episode_reward_max: 285.7171717171716
  episode_reward_mean: 234.27066551591852
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 296
  episodes_total: 1896
  experiment_id: 2c4c9d1a032f4f60b4e49b42a49eb793
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9948871235052744
        entropy_coeff: 0.0005000000000000001
        kl: 0.006681857941051324
        model: {}
        policy_loss: -0.011002168253374597
        total_loss: 15.828110535939535
        vf_explained_var: 0.9757750630378723
        vf_loss: 15.838941733042398
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.5
    gpu_util_percent0: 0.36433333333333334
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7633333333333328
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 37257
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15347424025726
    mean_env_wait_ms: 1.177432109263859
    mean_inference_ms: 4.748606379083518
    mean_raw_obs_processing_ms: 0.3990855899241854
  time_since_restore: 267.27121686935425
  time_this_iter_s: 26.534390211105347
  time_total_s: 267.27121686935425
  timers:
    learn_throughput: 8295.686
    learn_time_ms: 19503.149
    sample_throughput: 22650.581
    sample_time_ms: 7142.952
    update_time_ms: 28.461
  timestamp: 1602449681
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 57f23_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_57f23_00000 | RUNNING  | 172.17.0.4:37257 |     10 |          267.271 | 1617920 |  234.271 |              285.717 |              145.717 |            839.005 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_57f23_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3499.19842053307
    time_step_min: 3171
  date: 2020-10-11_20-55-07
  done: false
  episode_len_mean: 835.7263875365142
  episode_reward_max: 294.20202020201987
  episode_reward_mean: 235.87525203347977
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: 2c4c9d1a032f4f60b4e49b42a49eb793
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.975288137793541
        entropy_coeff: 0.0005000000000000001
        kl: 0.007294710182274382
        model: {}
        policy_loss: -0.012727556153549813
        total_loss: 11.962000767389933
        vf_explained_var: 0.9750909805297852
        vf_loss: 11.974486589431763
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.845161290322583
    gpu_util_percent0: 0.227741935483871
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.783870967741935
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 37257
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15311635319026334
    mean_env_wait_ms: 1.1791350381682937
    mean_inference_ms: 4.7244179906768915
    mean_raw_obs_processing_ms: 0.3978720745114414
  time_since_restore: 293.8944375514984
  time_this_iter_s: 26.623220682144165
  time_total_s: 293.8944375514984
  timers:
    learn_throughput: 8296.359
    learn_time_ms: 19501.568
    sample_throughput: 23337.042
    sample_time_ms: 6932.841
    update_time_ms: 29.449
  timestamp: 1602449707
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 57f23_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_57f23_00000 | RUNNING  | 172.17.0.4:37257 |     11 |          293.894 | 1779712 |  235.875 |              294.202 |              145.717 |            835.726 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_57f23_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3490.923534798535
    time_step_min: 3159
  date: 2020-10-11_20-55-34
  done: false
  episode_len_mean: 832.6595840867993
  episode_reward_max: 294.20202020201987
  episode_reward_mean: 237.1319752680511
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 2c4c9d1a032f4f60b4e49b42a49eb793
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9521185209353765
        entropy_coeff: 0.0005000000000000001
        kl: 0.006661186693236232
        model: {}
        policy_loss: -0.013089668517447231
        total_loss: 12.603836615880331
        vf_explained_var: 0.9737562537193298
        vf_loss: 12.61673672993978
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.60967741935484
    gpu_util_percent0: 0.2593548387096774
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.783870967741935
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 37257
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1527884561645553
    mean_env_wait_ms: 1.1807183063273368
    mean_inference_ms: 4.702451833253977
    mean_raw_obs_processing_ms: 0.39674650983115484
  time_since_restore: 320.73373579978943
  time_this_iter_s: 26.839298248291016
  time_total_s: 320.73373579978943
  timers:
    learn_throughput: 8279.132
    learn_time_ms: 19542.146
    sample_throughput: 23570.104
    sample_time_ms: 6864.289
    update_time_ms: 29.633
  timestamp: 1602449734
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 57f23_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_57f23_00000 | RUNNING  | 172.17.0.4:37257 |     12 |          320.734 | 1941504 |  237.132 |              294.202 |              145.717 |             832.66 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_57f23_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3477.030998389694
    time_step_min: 3151
  date: 2020-10-11_20-56-01
  done: false
  episode_len_mean: 827.7671178343949
  episode_reward_max: 294.20202020201987
  episode_reward_mean: 239.24816235604442
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 300
  episodes_total: 2512
  experiment_id: 2c4c9d1a032f4f60b4e49b42a49eb793
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9211943199237188
        entropy_coeff: 0.0005000000000000001
        kl: 0.0069003046955913305
        model: {}
        policy_loss: -0.011187698284629732
        total_loss: 15.527917702992758
        vf_explained_var: 0.9792836308479309
        vf_loss: 15.538876056671143
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.56
    gpu_util_percent0: 0.29933333333333334
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7633333333333328
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 37257
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15224700928612472
    mean_env_wait_ms: 1.1836057320594493
    mean_inference_ms: 4.666493296184004
    mean_raw_obs_processing_ms: 0.3949294968637309
  time_since_restore: 347.1315805912018
  time_this_iter_s: 26.397844791412354
  time_total_s: 347.1315805912018
  timers:
    learn_throughput: 8270.304
    learn_time_ms: 19563.005
    sample_throughput: 23670.862
    sample_time_ms: 6835.07
    update_time_ms: 29.596
  timestamp: 1602449761
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 57f23_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_57f23_00000 | RUNNING  | 172.17.0.4:37257 |     13 |          347.132 | 2103296 |  239.248 |              294.202 |              145.717 |            827.767 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_57f23_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3468.7953348382243
    time_step_min: 3151
  date: 2020-10-11_20-56-27
  done: false
  episode_len_mean: 825.1623231571109
  episode_reward_max: 294.20202020201987
  episode_reward_mean: 240.4743300465563
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 174
  episodes_total: 2686
  experiment_id: 2c4c9d1a032f4f60b4e49b42a49eb793
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9143994450569153
        entropy_coeff: 0.0005000000000000001
        kl: 0.0060155229875817895
        model: {}
        policy_loss: -0.012139652118397256
        total_loss: 10.54153060913086
        vf_explained_var: 0.979185163974762
        vf_loss: 10.553526004155477
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.012903225806454
    gpu_util_percent0: 0.2935483870967742
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.783870967741935
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 37257
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15197445701322412
    mean_env_wait_ms: 1.185070690827907
    mean_inference_ms: 4.6484971520670495
    mean_raw_obs_processing_ms: 0.39404661507322797
  time_since_restore: 373.37467527389526
  time_this_iter_s: 26.24309468269348
  time_total_s: 373.37467527389526
  timers:
    learn_throughput: 8268.071
    learn_time_ms: 19568.288
    sample_throughput: 23751.037
    sample_time_ms: 6811.997
    update_time_ms: 35.476
  timestamp: 1602449787
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 57f23_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_57f23_00000 | RUNNING  | 172.17.0.4:37257 |     14 |          373.375 | 2265088 |  240.474 |              294.202 |              145.717 |            825.162 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_57f23_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3462.4602272727275
    time_step_min: 3131
  date: 2020-10-11_20-56-53
  done: false
  episode_len_mean: 822.9542897327707
  episode_reward_max: 294.20202020201987
  episode_reward_mean: 241.45540851553497
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: 2c4c9d1a032f4f60b4e49b42a49eb793
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9019962549209595
        entropy_coeff: 0.0005000000000000001
        kl: 0.006133316123547654
        model: {}
        policy_loss: -0.012229806568939239
        total_loss: 9.555021127065023
        vf_explained_var: 0.9795403480529785
        vf_loss: 9.567088762919107
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.663333333333338
    gpu_util_percent0: 0.28300000000000003
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.776666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 37257
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15174862561881447
    mean_env_wait_ms: 1.1863092039775454
    mean_inference_ms: 4.6334426972615
    mean_raw_obs_processing_ms: 0.393282314060057
  time_since_restore: 399.53167152404785
  time_this_iter_s: 26.156996250152588
  time_total_s: 399.53167152404785
  timers:
    learn_throughput: 8277.159
    learn_time_ms: 19546.802
    sample_throughput: 23747.621
    sample_time_ms: 6812.977
    update_time_ms: 33.693
  timestamp: 1602449813
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 57f23_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_57f23_00000 | RUNNING  | 172.17.0.4:37257 |     15 |          399.532 | 2426880 |  241.455 |              294.202 |              145.717 |            822.954 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_57f23_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3453.8821989528797
    time_step_min: 3083
  date: 2020-10-11_20-57-20
  done: false
  episode_len_mean: 819.9792477302204
  episode_reward_max: 298.8989898989898
  episode_reward_mean: 242.75903981448718
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 240
  episodes_total: 3084
  experiment_id: 2c4c9d1a032f4f60b4e49b42a49eb793
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8659086326758066
        entropy_coeff: 0.0005000000000000001
        kl: 0.00634678197093308
        model: {}
        policy_loss: -0.012134946203635385
        total_loss: 13.195513248443604
        vf_explained_var: 0.980156421661377
        vf_loss: 13.207446098327637
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.686666666666667
    gpu_util_percent0: 0.28366666666666673
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.766666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 37257
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15144089438905364
    mean_env_wait_ms: 1.1882040214507208
    mean_inference_ms: 4.612706928857857
    mean_raw_obs_processing_ms: 0.39221069322018653
  time_since_restore: 425.9738202095032
  time_this_iter_s: 26.442148685455322
  time_total_s: 425.9738202095032
  timers:
    learn_throughput: 8280.233
    learn_time_ms: 19539.546
    sample_throughput: 23726.502
    sample_time_ms: 6819.041
    update_time_ms: 30.665
  timestamp: 1602449840
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 57f23_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_57f23_00000 | RUNNING  | 172.17.0.4:37257 |     16 |          425.974 | 2588672 |  242.759 |              298.899 |              145.717 |            819.979 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_57f23_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3445.377811550152
    time_step_min: 3083
  date: 2020-10-11_20-57-46
  done: false
  episode_len_mean: 817.4445449065702
  episode_reward_max: 298.8989898989898
  episode_reward_mean: 243.9846110289147
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 234
  episodes_total: 3318
  experiment_id: 2c4c9d1a032f4f60b4e49b42a49eb793
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8606445689996084
        entropy_coeff: 0.0005000000000000001
        kl: 0.005582816433161497
        model: {}
        policy_loss: -0.011729711521184072
        total_loss: 9.780861934026083
        vf_explained_var: 0.9827695488929749
        vf_loss: 9.792463779449463
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.386666666666667
    gpu_util_percent0: 0.3229999999999999
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7633333333333328
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 37257
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1511733753979436
    mean_env_wait_ms: 1.1898060421279049
    mean_inference_ms: 4.5947960129347285
    mean_raw_obs_processing_ms: 0.39134504884948595
  time_since_restore: 452.1008207798004
  time_this_iter_s: 26.12700057029724
  time_total_s: 452.1008207798004
  timers:
    learn_throughput: 8294.661
    learn_time_ms: 19505.558
    sample_throughput: 23716.257
    sample_time_ms: 6821.987
    update_time_ms: 30.489
  timestamp: 1602449866
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 57f23_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_57f23_00000 | RUNNING  | 172.17.0.4:37257 |     17 |          452.101 | 2750464 |  243.985 |              298.899 |              145.717 |            817.445 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_57f23_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3440.181554524362
    time_step_min: 3083
  date: 2020-10-11_20-58-13
  done: false
  episode_len_mean: 815.873417721519
  episode_reward_max: 298.8989898989898
  episode_reward_mean: 244.73267194383405
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 3476
  experiment_id: 2c4c9d1a032f4f60b4e49b42a49eb793
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8570553759733835
        entropy_coeff: 0.0005000000000000001
        kl: 0.00693794801676025
        model: {}
        policy_loss: -0.012595690621916825
        total_loss: 9.302302360534668
        vf_explained_var: 0.9800246357917786
        vf_loss: 9.314632733662924
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.190322580645166
    gpu_util_percent0: 0.2738709677419355
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7774193548387096
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 37257
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.151008419486375
    mean_env_wait_ms: 1.190814079677562
    mean_inference_ms: 4.583731586600891
    mean_raw_obs_processing_ms: 0.390796613625373
  time_since_restore: 478.5561480522156
  time_this_iter_s: 26.45532727241516
  time_total_s: 478.5561480522156
  timers:
    learn_throughput: 8287.606
    learn_time_ms: 19522.163
    sample_throughput: 23681.51
    sample_time_ms: 6831.997
    update_time_ms: 29.642
  timestamp: 1602449893
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 57f23_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_57f23_00000 | RUNNING  | 172.17.0.4:37257 |     18 |          478.556 | 2912256 |  244.733 |              298.899 |              145.717 |            815.873 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_57f23_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3435.160891089109
    time_step_min: 3083
  date: 2020-10-11_20-58-40
  done: false
  episode_len_mean: 814.1853165938865
  episode_reward_max: 298.8989898989898
  episode_reward_mean: 245.55176216311577
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 188
  episodes_total: 3664
  experiment_id: 2c4c9d1a032f4f60b4e49b42a49eb793
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8260929683844248
        entropy_coeff: 0.0005000000000000001
        kl: 0.00627721450291574
        model: {}
        policy_loss: -0.010709817167177485
        total_loss: 11.524338483810425
        vf_explained_var: 0.9801642894744873
        vf_loss: 11.534833749135336
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.787096774193554
    gpu_util_percent0: 0.32516129032258073
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.770967741935483
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 37257
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15082626201248997
    mean_env_wait_ms: 1.1919975103142262
    mean_inference_ms: 4.571369995071208
    mean_raw_obs_processing_ms: 0.3901827134193796
  time_since_restore: 505.1954309940338
  time_this_iter_s: 26.639282941818237
  time_total_s: 505.1954309940338
  timers:
    learn_throughput: 8279.773
    learn_time_ms: 19540.632
    sample_throughput: 23737.023
    sample_time_ms: 6816.019
    update_time_ms: 30.812
  timestamp: 1602449920
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 57f23_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_57f23_00000 | RUNNING  | 172.17.0.4:37257 |     19 |          505.195 | 3074048 |  245.552 |              298.899 |              145.717 |            814.185 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_57f23_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3428.4441611422744
    time_step_min: 3083
  date: 2020-10-11_20-59-06
  done: false
  episode_len_mean: 812.0630379746835
  episode_reward_max: 298.8989898989898
  episode_reward_mean: 246.60976857179378
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 286
  episodes_total: 3950
  experiment_id: 2c4c9d1a032f4f60b4e49b42a49eb793
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8063790599505106
        entropy_coeff: 0.0005000000000000001
        kl: 0.00581474454763035
        model: {}
        policy_loss: -0.010059737542178482
        total_loss: 10.378987232844034
        vf_explained_var: 0.9842923283576965
        vf_loss: 10.388868490854898
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.486666666666668
    gpu_util_percent0: 0.267
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.769999999999999
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 37257
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.150576637512855
    mean_env_wait_ms: 1.1936476445931057
    mean_inference_ms: 4.554557767770224
    mean_raw_obs_processing_ms: 0.3893581543008797
  time_since_restore: 531.4567422866821
  time_this_iter_s: 26.261311292648315
  time_total_s: 531.4567422866821
  timers:
    learn_throughput: 8282.287
    learn_time_ms: 19534.7
    sample_throughput: 23815.747
    sample_time_ms: 6793.488
    update_time_ms: 30.702
  timestamp: 1602449946
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 57f23_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_57f23_00000 | RUNNING  | 172.17.0.4:37257 |     20 |          531.457 | 3235840 |   246.61 |              298.899 |              145.717 |            812.063 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_57f23_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3424.633333333333
    time_step_min: 3083
  date: 2020-10-11_20-59-33
  done: false
  episode_len_mean: 811.1747809152872
  episode_reward_max: 298.8989898989898
  episode_reward_mean: 247.171761431255
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 4108
  experiment_id: 2c4c9d1a032f4f60b4e49b42a49eb793
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8050975054502487
        entropy_coeff: 0.0005000000000000001
        kl: 0.006411496355819206
        model: {}
        policy_loss: -0.0109325938198405
        total_loss: 8.397321462631226
        vf_explained_var: 0.9822394847869873
        vf_loss: 8.408015330632528
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.767741935483873
    gpu_util_percent0: 0.3487096774193549
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.777419354838709
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 37257
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15045094815425328
    mean_env_wait_ms: 1.194472209489626
    mean_inference_ms: 4.546033948380005
    mean_raw_obs_processing_ms: 0.38893762981765684
  time_since_restore: 557.9211881160736
  time_this_iter_s: 26.46444582939148
  time_total_s: 557.9211881160736
  timers:
    learn_throughput: 8279.321
    learn_time_ms: 19541.7
    sample_throughput: 23932.338
    sample_time_ms: 6760.393
    update_time_ms: 29.819
  timestamp: 1602449973
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: 57f23_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_57f23_00000 | RUNNING  | 172.17.0.4:37257 |     21 |          557.921 | 3397632 |  247.172 |              298.899 |              145.717 |            811.175 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_57f23_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3421.5082547169814
    time_step_min: 3083
  date: 2020-10-11_20-59-59
  done: false
  episode_len_mean: 810.3659793814433
  episode_reward_max: 298.8989898989898
  episode_reward_mean: 247.6299262541061
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 160
  episodes_total: 4268
  experiment_id: 2c4c9d1a032f4f60b4e49b42a49eb793
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7943403224150339
        entropy_coeff: 0.0005000000000000001
        kl: 0.006092905105712513
        model: {}
        policy_loss: -0.012508889408006022
        total_loss: 10.069480101267496
        vf_explained_var: 0.9799533486366272
        vf_loss: 10.08177661895752
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.520000000000003
    gpu_util_percent0: 0.31799999999999995
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.78
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 37257
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15033290650736644
    mean_env_wait_ms: 1.1952662098693954
    mean_inference_ms: 4.537854015543671
    mean_raw_obs_processing_ms: 0.388529294279056
  time_since_restore: 584.4980638027191
  time_this_iter_s: 26.576875686645508
  time_total_s: 584.4980638027191
  timers:
    learn_throughput: 8279.067
    learn_time_ms: 19542.3
    sample_throughput: 24037.567
    sample_time_ms: 6730.798
    update_time_ms: 31.271
  timestamp: 1602449999
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: 57f23_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_57f23_00000 | RUNNING  | 172.17.0.4:37257 |     22 |          584.498 | 3559424 |   247.63 |              298.899 |              145.717 |            810.366 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_57f23_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3415.407570422535
    time_step_min: 3083
  date: 2020-10-11_21-00-26
  done: true
  episode_len_mean: 808.5879265091863
  episode_reward_max: 298.8989898989898
  episode_reward_mean: 248.62850287653427
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 304
  episodes_total: 4572
  experiment_id: 2c4c9d1a032f4f60b4e49b42a49eb793
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7644506990909576
        entropy_coeff: 0.0005000000000000001
        kl: 0.005771325357879202
        model: {}
        policy_loss: -0.009549629636846172
        total_loss: 10.615382512410482
        vf_explained_var: 0.9846494197845459
        vf_loss: 10.624737024307251
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.96129032258065
    gpu_util_percent0: 0.3741935483870968
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7741935483870965
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 37257
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1501194363451449
    mean_env_wait_ms: 1.1967178090167394
    mean_inference_ms: 4.5235927595645755
    mean_raw_obs_processing_ms: 0.38782900335570203
  time_since_restore: 610.822046995163
  time_this_iter_s: 26.323983192443848
  time_total_s: 610.822046995163
  timers:
    learn_throughput: 8277.485
    learn_time_ms: 19546.034
    sample_throughput: 24082.955
    sample_time_ms: 6718.112
    update_time_ms: 31.757
  timestamp: 1602450026
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: 57f23_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_57f23_00000 | TERMINATED |       |     23 |          610.822 | 3721216 |  248.629 |              298.899 |              145.717 |            808.588 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_57f23_00000 | TERMINATED |       |     23 |          610.822 | 3721216 |  248.629 |              298.899 |              145.717 |            808.588 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


