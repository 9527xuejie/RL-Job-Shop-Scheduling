2020-11-01 12:15:46,749	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 12.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_f98d0_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=2614)[0m 2020-11-01 12:15:49,495	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=2570)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2570)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2590)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2590)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2557)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2557)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2589)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2589)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2599)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2599)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2591)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2591)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2583)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2583)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2625)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2625)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2573)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2573)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2595)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2595)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2597)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2597)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2587)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2587)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2582)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2582)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2621)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2621)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2600)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2600)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2615)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2615)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2594)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2594)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2527)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2527)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2554)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2554)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2526)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2526)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2560)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2560)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2561)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2561)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2562)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2562)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2511)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2511)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2556)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2556)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2501)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2501)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2553)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2553)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2520)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2520)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2571)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2571)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2612)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2612)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2508)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2508)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2493)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2493)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2565)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2565)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2605)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2605)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2566)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2566)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2506)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2506)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2518)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2518)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2502)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2502)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2503)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2503)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2507)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2507)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2576)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2576)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2567)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2567)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2610)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2610)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2487)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2487)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2603)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2603)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2488)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2488)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2492)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2492)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2497)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2497)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2552)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2552)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2504)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2504)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2563)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2563)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2500)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2500)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2558)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2558)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2555)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2555)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2496)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2496)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2579)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2579)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2564)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2564)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2523)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2523)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2598)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2598)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2524)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2524)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2572)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2572)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2551)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2551)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2505)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2505)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2592)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2592)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2514)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2514)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2498)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2498)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2580)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2580)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2495)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2495)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2568)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2568)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2490)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2490)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2602)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2602)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2569)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2569)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2489)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2489)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2491)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2491)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2559)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2559)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2517)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2517)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2509)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2509)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2596)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2596)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2577)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2577)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_f98d0_00000:
  custom_metrics:
    time_step_max: 1589
    time_step_mean: 1337.9852140077821
    time_step_min: 1155
  date: 2020-11-01_12-16-16
  done: false
  episode_len_mean: 114.43149129447389
  episode_reward_max: 47.39175257731958
  episode_reward_mean: 38.01323583352193
  episode_reward_min: 22.08247422680411
  episodes_this_iter: 1321
  episodes_total: 1321
  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1485573450724285
        entropy_coeff: 0.0005000000000000001
        kl: 0.005282467735620837
        model: {}
        policy_loss: -0.007238074458048989
        total_loss: 63.078263918558754
        vf_explained_var: 0.7385819554328918
        vf_loss: 63.0850191116333
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.44814814814815
    gpu_util_percent0: 0.3718518518518519
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.4370370370370376
    vram_util_percent0: 0.08366130971903357
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2614
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16663877415658362
    mean_env_wait_ms: 0.6660098682308551
    mean_inference_ms: 4.715280418736184
    mean_raw_obs_processing_ms: 0.42943359101439976
  time_since_restore: 21.794464588165283
  time_this_iter_s: 21.794464588165283
  time_total_s: 21.794464588165283
  timers:
    learn_throughput: 11044.835
    learn_time_ms: 14648.658
    sample_throughput: 22922.781
    sample_time_ms: 7058.131
    update_time_ms: 38.538
  timestamp: 1604232976
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: f98d0_00000
  
== Status ==
Memory usage on this node: 26.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |      1 |          21.7945 | 161792 |  38.0132 |              47.3918 |              22.0825 |            114.431 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f98d0_00000:
  custom_metrics:
    time_step_max: 1662
    time_step_mean: 1326.7179115300942
    time_step_min: 1150
  date: 2020-11-01_12-16-37
  done: false
  episode_len_mean: 113.38081603435934
  episode_reward_max: 47.64948453608249
  episode_reward_mean: 38.63342287228155
  episode_reward_min: 21.25773195876288
  episodes_this_iter: 1473
  episodes_total: 2794
  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1314232647418976
        entropy_coeff: 0.0005000000000000001
        kl: 0.009286719684799513
        model: {}
        policy_loss: -0.01014851212191085
        total_loss: 10.35303783416748
        vf_explained_var: 0.901028573513031
        vf_loss: 10.361894766489664
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.084615384615383
    gpu_util_percent0: 0.4496153846153846
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5076923076923077
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2614
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16450090814338433
    mean_env_wait_ms: 0.6642577249066655
    mean_inference_ms: 4.744188369781305
    mean_raw_obs_processing_ms: 0.42877125861262844
  time_since_restore: 43.1419882774353
  time_this_iter_s: 21.34752368927002
  time_total_s: 43.1419882774353
  timers:
    learn_throughput: 11211.024
    learn_time_ms: 14431.51
    sample_throughput: 23059.328
    sample_time_ms: 7016.336
    update_time_ms: 41.882
  timestamp: 1604232997
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: f98d0_00000
  
== Status ==
Memory usage on this node: 26.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |      2 |           43.142 | 323584 |  38.6334 |              47.6495 |              21.2577 |            113.381 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f98d0_00000:
  custom_metrics:
    time_step_max: 1662
    time_step_mean: 1309.3502958579882
    time_step_min: 1150
  date: 2020-11-01_12-16-58
  done: false
  episode_len_mean: 112.32527575686458
  episode_reward_max: 47.64948453608249
  episode_reward_mean: 39.48478286641973
  episode_reward_min: 21.25773195876288
  episodes_this_iter: 1467
  episodes_total: 4261
  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1132993400096893
        entropy_coeff: 0.0005000000000000001
        kl: 0.010391402058303356
        model: {}
        policy_loss: -0.014095689790944258
        total_loss: 6.80802857875824
        vf_explained_var: 0.9351071715354919
        vf_loss: 6.820602655410767
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.832000000000004
    gpu_util_percent0: 0.4172
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5120000000000005
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2614
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16256613873280876
    mean_env_wait_ms: 0.6625184290389695
    mean_inference_ms: 4.69345067144062
    mean_raw_obs_processing_ms: 0.4260658546666288
  time_since_restore: 63.90490484237671
  time_this_iter_s: 20.762916564941406
  time_total_s: 63.90490484237671
  timers:
    learn_throughput: 11227.805
    learn_time_ms: 14409.94
    sample_throughput: 23883.846
    sample_time_ms: 6774.118
    update_time_ms: 41.076
  timestamp: 1604233018
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: f98d0_00000
  
== Status ==
Memory usage on this node: 26.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |      3 |          63.9049 | 485376 |  39.4848 |              47.6495 |              21.2577 |            112.325 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f98d0_00000:
  custom_metrics:
    time_step_max: 1662
    time_step_mean: 1293.2727912706794
    time_step_min: 1150
  date: 2020-11-01_12-17-19
  done: false
  episode_len_mean: 111.25918153200419
  episode_reward_max: 47.649484536082525
  episode_reward_mean: 40.30362789959723
  episode_reward_min: 21.25773195876288
  episodes_this_iter: 1457
  episodes_total: 5718
  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.084079662958781
        entropy_coeff: 0.0005000000000000001
        kl: 0.009383795782923698
        model: {}
        policy_loss: -0.013835826587940877
        total_loss: 4.933180093765259
        vf_explained_var: 0.9529300332069397
        vf_loss: 4.94568133354187
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.936
    gpu_util_percent0: 0.4576
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.508
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2614
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16088212665214047
    mean_env_wait_ms: 0.660815453354488
    mean_inference_ms: 4.632879361030093
    mean_raw_obs_processing_ms: 0.42268288067938126
  time_since_restore: 84.33310127258301
  time_this_iter_s: 20.4281964302063
  time_total_s: 84.33310127258301
  timers:
    learn_throughput: 11238.354
    learn_time_ms: 14396.415
    sample_throughput: 24616.712
    sample_time_ms: 6572.446
    update_time_ms: 38.648
  timestamp: 1604233039
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: f98d0_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |      4 |          84.3331 | 647168 |  40.3036 |              47.6495 |              21.2577 |            111.259 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f98d0_00000:
  custom_metrics:
    time_step_max: 1662
    time_step_mean: 1278.2911882694702
    time_step_min: 1150
  date: 2020-11-01_12-17-39
  done: false
  episode_len_mean: 110.2100481761872
  episode_reward_max: 47.649484536082525
  episode_reward_mean: 41.07122129117859
  episode_reward_min: 21.25773195876288
  episodes_this_iter: 1547
  episodes_total: 7265
  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0668250819047291
        entropy_coeff: 0.0005000000000000001
        kl: 0.008654051227495074
        model: {}
        policy_loss: -0.015438533756726732
        total_loss: 3.750304361184438
        vf_explained_var: 0.9650198817253113
        vf_loss: 3.764545480410258
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.02
    gpu_util_percent0: 0.3504
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5120000000000005
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2614
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1594046299420155
    mean_env_wait_ms: 0.6591918943938871
    mean_inference_ms: 4.572498944569763
    mean_raw_obs_processing_ms: 0.4190994577823986
  time_since_restore: 104.45204615592957
  time_this_iter_s: 20.118944883346558
  time_total_s: 104.45204615592957
  timers:
    learn_throughput: 11259.021
    learn_time_ms: 14369.989
    sample_throughput: 25254.408
    sample_time_ms: 6406.486
    update_time_ms: 37.632
  timestamp: 1604233059
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: f98d0_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |      5 |          104.452 | 808960 |  41.0712 |              47.6495 |              21.2577 |             110.21 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f98d0_00000:
  custom_metrics:
    time_step_max: 1662
    time_step_mean: 1266.0983158852982
    time_step_min: 1150
  date: 2020-11-01_12-18-00
  done: false
  episode_len_mean: 109.32014959202176
  episode_reward_max: 47.649484536082525
  episode_reward_mean: 41.69816035928256
  episode_reward_min: 21.25773195876288
  episodes_this_iter: 1559
  episodes_total: 8824
  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.034409632285436
        entropy_coeff: 0.0005000000000000001
        kl: 0.008218800959487757
        model: {}
        policy_loss: -0.015976834343746305
        total_loss: 3.275542378425598
        vf_explained_var: 0.9698309898376465
        vf_loss: 3.2903926372528076
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.4375
    gpu_util_percent0: 0.43624999999999997
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5208333333333335
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2614
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15817094139921792
    mean_env_wait_ms: 0.6579144407066476
    mean_inference_ms: 4.520312188626085
    mean_raw_obs_processing_ms: 0.41585575516420453
  time_since_restore: 124.74504113197327
  time_this_iter_s: 20.2929949760437
  time_total_s: 124.74504113197327
  timers:
    learn_throughput: 11268.321
    learn_time_ms: 14358.128
    sample_throughput: 25609.299
    sample_time_ms: 6317.705
    update_time_ms: 37.615
  timestamp: 1604233080
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: f98d0_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |      6 |          124.745 | 970752 |  41.6982 |              47.6495 |              21.2577 |             109.32 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f98d0_00000:
  custom_metrics:
    time_step_max: 1662
    time_step_mean: 1255.5475730032877
    time_step_min: 1150
  date: 2020-11-01_12-18-20
  done: false
  episode_len_mean: 108.51175563692426
  episode_reward_max: 47.649484536082525
  episode_reward_mean: 42.23890644960692
  episode_reward_min: 21.25773195876288
  episodes_this_iter: 1554
  episodes_total: 10378
  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9993852277596792
        entropy_coeff: 0.0005000000000000001
        kl: 0.008948890104268989
        model: {}
        policy_loss: -0.011871834401972592
        total_loss: 2.572846511999766
        vf_explained_var: 0.9761440753936768
        vf_loss: 2.5834282437960305
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.36
    gpu_util_percent0: 0.3956
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5120000000000005
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2614
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15713379589800733
    mean_env_wait_ms: 0.6568649191044983
    mean_inference_ms: 4.475812919755018
    mean_raw_obs_processing_ms: 0.4129610571474045
  time_since_restore: 144.9028398990631
  time_this_iter_s: 20.157798767089844
  time_total_s: 144.9028398990631
  timers:
    learn_throughput: 11276.333
    learn_time_ms: 14347.927
    sample_throughput: 25944.994
    sample_time_ms: 6235.962
    update_time_ms: 37.126
  timestamp: 1604233100
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: f98d0_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |      7 |          144.903 | 1132544 |  42.2389 |              47.6495 |              21.2577 |            108.512 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f98d0_00000:
  custom_metrics:
    time_step_max: 1662
    time_step_mean: 1246.681210592686
    time_step_min: 1150
  date: 2020-11-01_12-18-41
  done: false
  episode_len_mean: 107.82323359316068
  episode_reward_max: 47.649484536082525
  episode_reward_mean: 42.700832190594205
  episode_reward_min: 21.25773195876288
  episodes_this_iter: 1553
  episodes_total: 11931
  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9713874608278275
        entropy_coeff: 0.0005000000000000001
        kl: 0.00811462321629127
        model: {}
        policy_loss: -0.013652926543727517
        total_loss: 2.0792956252892814
        vf_explained_var: 0.9808939099311829
        vf_loss: 2.0918113390604653
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.708000000000002
    gpu_util_percent0: 0.412
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.52
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2614
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15626045608420333
    mean_env_wait_ms: 0.6560445478078366
    mean_inference_ms: 4.437668893602004
    mean_raw_obs_processing_ms: 0.41044660220855933
  time_since_restore: 165.08657550811768
  time_this_iter_s: 20.183735609054565
  time_total_s: 165.08657550811768
  timers:
    learn_throughput: 11297.099
    learn_time_ms: 14321.553
    sample_throughput: 26119.381
    sample_time_ms: 6194.327
    update_time_ms: 35.89
  timestamp: 1604233121
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: f98d0_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |      8 |          165.087 | 1294336 |  42.7008 |              47.6495 |              21.2577 |            107.823 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f98d0_00000:
  custom_metrics:
    time_step_max: 1662
    time_step_mean: 1238.4053151213718
    time_step_min: 1150
  date: 2020-11-01_12-19-01
  done: false
  episode_len_mean: 107.21781298585918
  episode_reward_max: 47.649484536082525
  episode_reward_mean: 43.115104119360794
  episode_reward_min: 21.25773195876288
  episodes_this_iter: 1576
  episodes_total: 13507
  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9416759212811788
        entropy_coeff: 0.0005000000000000001
        kl: 0.0077835753715286655
        model: {}
        policy_loss: -0.013627580524674462
        total_loss: 1.650565932194392
        vf_explained_var: 0.9848251938819885
        vf_loss: 1.663107653458913
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.308000000000003
    gpu_util_percent0: 0.392
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.571999999999999
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2614
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15550241078926047
    mean_env_wait_ms: 0.6554019389170324
    mean_inference_ms: 4.404255773765493
    mean_raw_obs_processing_ms: 0.40821271351444455
  time_since_restore: 185.5122389793396
  time_this_iter_s: 20.425663471221924
  time_total_s: 185.5122389793396
  timers:
    learn_throughput: 11288.215
    learn_time_ms: 14332.825
    sample_throughput: 26270.178
    sample_time_ms: 6158.771
    update_time_ms: 34.616
  timestamp: 1604233141
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: f98d0_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |      9 |          185.512 | 1456128 |  43.1151 |              47.6495 |              21.2577 |            107.218 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f98d0_00000:
  custom_metrics:
    time_step_max: 1662
    time_step_mean: 1231.2265303412562
    time_step_min: 1150
  date: 2020-11-01_12-19-22
  done: false
  episode_len_mean: 106.66975758378594
  episode_reward_max: 47.64948453608253
  episode_reward_mean: 43.48257774293858
  episode_reward_min: 21.25773195876288
  episodes_this_iter: 1591
  episodes_total: 15098
  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9080682247877121
        entropy_coeff: 0.0005000000000000001
        kl: 0.007657797929520409
        model: {}
        policy_loss: -0.010565590860399729
        total_loss: 1.296636829773585
        vf_explained_var: 0.988224446773529
        vf_loss: 1.3061249554157257
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.03333333333333
    gpu_util_percent0: 0.4579166666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5749999999999997
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2614
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15484288964237733
    mean_env_wait_ms: 0.6549145589836158
    mean_inference_ms: 4.3750244337617135
    mean_raw_obs_processing_ms: 0.4062248434702486
  time_since_restore: 205.5452425479889
  time_this_iter_s: 20.033003568649292
  time_total_s: 205.5452425479889
  timers:
    learn_throughput: 11294.037
    learn_time_ms: 14325.435
    sample_throughput: 26494.427
    sample_time_ms: 6106.643
    update_time_ms: 33.514
  timestamp: 1604233162
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: f98d0_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     10 |          205.545 | 1617920 |  43.4826 |              47.6495 |              21.2577 |             106.67 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f98d0_00000:
  custom_metrics:
    time_step_max: 1662
    time_step_mean: 1224.8779111644658
    time_step_min: 1150
  date: 2020-11-01_12-19-42
  done: false
  episode_len_mean: 106.19435793004313
  episode_reward_max: 47.64948453608253
  episode_reward_mean: 43.804279931238554
  episode_reward_min: 21.25773195876288
  episodes_this_iter: 1598
  episodes_total: 16696
  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8727221091588339
        entropy_coeff: 0.0005000000000000001
        kl: 0.007556108757853508
        model: {}
        policy_loss: -0.012766734405886382
        total_loss: 1.0635682841142018
        vf_explained_var: 0.9903334975242615
        vf_loss: 1.0752601623535156
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.6375
    gpu_util_percent0: 0.4445833333333334
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.570833333333333
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2614
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1542607271772269
    mean_env_wait_ms: 0.6545202251025621
    mean_inference_ms: 4.349215320409436
    mean_raw_obs_processing_ms: 0.4044561449167446
  time_since_restore: 225.5202054977417
  time_this_iter_s: 19.974962949752808
  time_total_s: 225.5202054977417
  timers:
    learn_throughput: 11330.871
    learn_time_ms: 14278.867
    sample_throughput: 27121.909
    sample_time_ms: 5965.362
    update_time_ms: 33.265
  timestamp: 1604233182
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: f98d0_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     11 |           225.52 | 1779712 |  43.8043 |              47.6495 |              21.2577 |            106.194 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f98d0_00000:
  custom_metrics:
    time_step_max: 1662
    time_step_mean: 1219.3561336254106
    time_step_min: 1150
  date: 2020-11-01_12-20-02
  done: false
  episode_len_mean: 105.77831219938784
  episode_reward_max: 47.64948453608253
  episode_reward_mean: 44.08295937594382
  episode_reward_min: 21.25773195876288
  episodes_this_iter: 1600
  episodes_total: 18296
  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8348831733067831
        entropy_coeff: 0.0005000000000000001
        kl: 0.007376410067081451
        model: {}
        policy_loss: -0.009320069143238166
        total_loss: 0.8637631287177404
        vf_explained_var: 0.99216228723526
        vf_loss: 0.8720253507296244
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.623999999999995
    gpu_util_percent0: 0.364
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5679999999999996
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2614
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15375450185882147
    mean_env_wait_ms: 0.6542416074847509
    mean_inference_ms: 4.326388244632185
    mean_raw_obs_processing_ms: 0.4028915881034749
  time_since_restore: 245.75802636146545
  time_this_iter_s: 20.237820863723755
  time_total_s: 245.75802636146545
  timers:
    learn_throughput: 11325.614
    learn_time_ms: 14285.495
    sample_throughput: 27660.054
    sample_time_ms: 5849.302
    update_time_ms: 30.809
  timestamp: 1604233202
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: f98d0_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     12 |          245.758 | 1941504 |   44.083 |              47.6495 |              21.2577 |            105.778 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f98d0_00000:
  custom_metrics:
    time_step_max: 1662
    time_step_mean: 1214.5580739397603
    time_step_min: 1150
  date: 2020-11-01_12-20-23
  done: false
  episode_len_mean: 105.4173956762192
  episode_reward_max: 47.64948453608254
  episode_reward_mean: 44.32935526840925
  episode_reward_min: 21.25773195876288
  episodes_this_iter: 1594
  episodes_total: 19890
  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7998430083195368
        entropy_coeff: 0.0005000000000000001
        kl: 0.006828729490128656
        model: {}
        policy_loss: -0.011044965135321641
        total_loss: 0.67805515229702
        vf_explained_var: 0.9938119053840637
        vf_loss: 0.6881343126296997
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.831999999999997
    gpu_util_percent0: 0.43200000000000005
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.571999999999999
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2614
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.153302992513867
    mean_env_wait_ms: 0.6540089232561519
    mean_inference_ms: 4.306101213317678
    mean_raw_obs_processing_ms: 0.40148742506884494
  time_since_restore: 266.1050407886505
  time_this_iter_s: 20.34701442718506
  time_total_s: 266.1050407886505
  timers:
    learn_throughput: 11312.078
    learn_time_ms: 14302.589
    sample_throughput: 27960.684
    sample_time_ms: 5786.411
    update_time_ms: 28.901
  timestamp: 1604233223
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: f98d0_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     13 |          266.105 | 2103296 |  44.3294 |              47.6495 |              21.2577 |            105.417 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f98d0_00000:
  custom_metrics:
    time_step_max: 1662
    time_step_mean: 1210.317556539986
    time_step_min: 1150
  date: 2020-11-01_12-20-43
  done: false
  episode_len_mean: 105.1013919277501
  episode_reward_max: 47.64948453608254
  episode_reward_mean: 44.54546357677872
  episode_reward_min: 21.25773195876288
  episodes_this_iter: 1591
  episodes_total: 21481
  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7677376766999563
        entropy_coeff: 0.0005000000000000001
        kl: 0.00645853765308857
        model: {}
        policy_loss: -0.009221890567763088
        total_loss: 0.5704321513573328
        vf_explained_var: 0.9948087334632874
        vf_loss: 0.5787462194760641
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.299999999999997
    gpu_util_percent0: 0.3692
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5679999999999996
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2614
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15289862610010913
    mean_env_wait_ms: 0.6538353499990455
    mean_inference_ms: 4.287840220794161
    mean_raw_obs_processing_ms: 0.40022401934261076
  time_since_restore: 286.03195905685425
  time_this_iter_s: 19.926918268203735
  time_total_s: 286.03195905685425
  timers:
    learn_throughput: 11326.239
    learn_time_ms: 14284.707
    sample_throughput: 28153.263
    sample_time_ms: 5746.83
    update_time_ms: 28.453
  timestamp: 1604233243
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: f98d0_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     14 |          286.032 | 2265088 |  44.5455 |              47.6495 |              21.2577 |            105.101 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f98d0_00000:
  custom_metrics:
    time_step_max: 1662
    time_step_mean: 1206.554523354749
    time_step_min: 1150
  date: 2020-11-01_12-21-04
  done: false
  episode_len_mean: 104.81341019417475
  episode_reward_max: 47.64948453608254
  episode_reward_mean: 44.73924255043826
  episode_reward_min: 21.25773195876288
  episodes_this_iter: 1591
  episodes_total: 23072
  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.733478844165802
        entropy_coeff: 0.0005000000000000001
        kl: 0.00630180553222696
        model: {}
        policy_loss: -0.01086452438418443
        total_loss: 0.44883622725804645
        vf_explained_var: 0.9958701133728027
        vf_loss: 0.4588071381052335
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.691666666666666
    gpu_util_percent0: 0.42
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.570833333333333
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2614
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1525331053770261
    mean_env_wait_ms: 0.6537007767835614
    mean_inference_ms: 4.271271460769205
    mean_raw_obs_processing_ms: 0.39907289277823804
  time_since_restore: 306.18409848213196
  time_this_iter_s: 20.15213942527771
  time_total_s: 306.18409848213196
  timers:
    learn_throughput: 11336.437
    learn_time_ms: 14271.856
    sample_throughput: 28161.1
    sample_time_ms: 5745.23
    update_time_ms: 27.237
  timestamp: 1604233264
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: f98d0_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     15 |          306.184 | 2426880 |  44.7392 |              47.6495 |              21.2577 |            104.813 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f98d0_00000:
  custom_metrics:
    time_step_max: 1662
    time_step_mean: 1203.1918253034055
    time_step_min: 1150
  date: 2020-11-01_12-21-25
  done: false
  episode_len_mean: 104.54650832894256
  episode_reward_max: 47.64948453608254
  episode_reward_mean: 44.91062311529655
  episode_reward_min: 21.25773195876288
  episodes_this_iter: 1601
  episodes_total: 24673
  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7046740502119064
        entropy_coeff: 0.0005000000000000001
        kl: 0.00598089622023205
        model: {}
        policy_loss: -0.010109954212869829
        total_loss: 0.3878796820839246
        vf_explained_var: 0.9964661002159119
        vf_loss: 0.39714578290780383
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.084
    gpu_util_percent0: 0.4572
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.571999999999999
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2614
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15220062387999952
    mean_env_wait_ms: 0.653596423305203
    mean_inference_ms: 4.256089606710892
    mean_raw_obs_processing_ms: 0.3980153671992771
  time_since_restore: 326.27552032470703
  time_this_iter_s: 20.091421842575073
  time_total_s: 326.27552032470703
  timers:
    learn_throughput: 11333.689
    learn_time_ms: 14275.316
    sample_throughput: 28301.321
    sample_time_ms: 5716.765
    update_time_ms: 25.405
  timestamp: 1604233285
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: f98d0_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     16 |          326.276 | 2588672 |  44.9106 |              47.6495 |              21.2577 |            104.547 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f98d0_00000:
  custom_metrics:
    time_step_max: 1662
    time_step_mean: 1200.1823688521467
    time_step_min: 1150
  date: 2020-11-01_12-21-45
  done: false
  episode_len_mean: 104.30184515883583
  episode_reward_max: 47.64948453608254
  episode_reward_mean: 45.06611508661011
  episode_reward_min: 21.25773195876288
  episodes_this_iter: 1612
  episodes_total: 26285
  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.6727208147446314
        entropy_coeff: 0.0005000000000000001
        kl: 0.0061663844001789885
        model: {}
        policy_loss: -0.00950972737094465
        total_loss: 0.2949073016643524
        vf_explained_var: 0.9973233342170715
        vf_loss: 0.3035201082626979
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.068
    gpu_util_percent0: 0.38800000000000007
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5679999999999996
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2614
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15189563586672175
    mean_env_wait_ms: 0.653528700746639
    mean_inference_ms: 4.242058406187237
    mean_raw_obs_processing_ms: 0.3970431055250104
  time_since_restore: 346.44066858291626
  time_this_iter_s: 20.16514825820923
  time_total_s: 346.44066858291626
  timers:
    learn_throughput: 11331.786
    learn_time_ms: 14277.714
    sample_throughput: 28373.21
    sample_time_ms: 5702.28
    update_time_ms: 26.064
  timestamp: 1604233305
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: f98d0_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     17 |          346.441 | 2750464 |  45.0661 |              47.6495 |              21.2577 |            104.302 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f98d0_00000:
  custom_metrics:
    time_step_max: 1662
    time_step_mean: 1197.4265528618562
    time_step_min: 1150
  date: 2020-11-01_12-22-06
  done: false
  episode_len_mean: 104.07865329512894
  episode_reward_max: 47.64948453608255
  episode_reward_mean: 45.20858749593833
  episode_reward_min: 21.25773195876288
  episodes_this_iter: 1635
  episodes_total: 27920
  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.6462279756863912
        entropy_coeff: 0.0005000000000000001
        kl: 0.005753972722838323
        model: {}
        policy_loss: -0.01063174061710015
        total_loss: 0.2318790778517723
        vf_explained_var: 0.997880220413208
        vf_loss: 0.2416831391553084
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.45416666666667
    gpu_util_percent0: 0.44875
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5749999999999997
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2614
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1516142332871325
    mean_env_wait_ms: 0.6534803822249593
    mean_inference_ms: 4.229062941307127
    mean_raw_obs_processing_ms: 0.3961363429731068
  time_since_restore: 366.4673285484314
  time_this_iter_s: 20.026659965515137
  time_total_s: 366.4673285484314
  timers:
    learn_throughput: 11321.995
    learn_time_ms: 14290.061
    sample_throughput: 28529.416
    sample_time_ms: 5671.059
    update_time_ms: 25.131
  timestamp: 1604233326
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: f98d0_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     18 |          366.467 | 2912256 |  45.2086 |              47.6495 |              21.2577 |            104.079 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f98d0_00000:
  custom_metrics:
    time_step_max: 1662
    time_step_mean: 1194.9799281209737
    time_step_min: 1150
  date: 2020-11-01_12-22-27
  done: false
  episode_len_mean: 103.87829326109042
  episode_reward_max: 47.64948453608255
  episode_reward_mean: 45.33514231552049
  episode_reward_min: 21.25773195876288
  episodes_this_iter: 1610
  episodes_total: 29530
  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.6139073818922043
        entropy_coeff: 0.0005000000000000001
        kl: 0.005659738904796541
        model: {}
        policy_loss: -0.009704548533287985
        total_loss: 0.19860607013106346
        vf_explained_var: 0.9981780648231506
        vf_loss: 0.20748562117417654
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.747999999999998
    gpu_util_percent0: 0.39640000000000003
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.571999999999999
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2614
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15135749897686426
    mean_env_wait_ms: 0.6534384087466466
    mean_inference_ms: 4.217280786349381
    mean_raw_obs_processing_ms: 0.3953083892816526
  time_since_restore: 386.6138005256653
  time_this_iter_s: 20.146471977233887
  time_total_s: 386.6138005256653
  timers:
    learn_throughput: 11328.703
    learn_time_ms: 14281.599
    sample_throughput: 28668.019
    sample_time_ms: 5643.641
    update_time_ms: 26.007
  timestamp: 1604233347
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: f98d0_00000
  
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     19 |          386.614 | 3074048 |  45.3351 |              47.6495 |              21.2577 |            103.878 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f98d0_00000:
  custom_metrics:
    time_step_max: 1662
    time_step_mean: 1192.755491943006
    time_step_min: 1150
  date: 2020-11-01_12-22-47
  done: false
  episode_len_mean: 103.69467022199376
  episode_reward_max: 47.64948453608255
  episode_reward_mean: 45.44938246008456
  episode_reward_min: 21.25773195876288
  episodes_this_iter: 1597
  episodes_total: 31127
  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.5885171492894491
        entropy_coeff: 0.0005000000000000001
        kl: 0.00575300360408922
        model: {}
        policy_loss: -0.008459999109618366
        total_loss: 0.1491255114475886
        vf_explained_var: 0.9986266493797302
        vf_loss: 0.15672916546463966
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.32
    gpu_util_percent0: 0.33520000000000005
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5679999999999996
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2614
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15111988887105687
    mean_env_wait_ms: 0.6534000992030266
    mean_inference_ms: 4.206433415272165
    mean_raw_obs_processing_ms: 0.39454176059647716
  time_since_restore: 406.58024430274963
  time_this_iter_s: 19.96644377708435
  time_total_s: 406.58024430274963
  timers:
    learn_throughput: 11334.136
    learn_time_ms: 14274.754
    sample_throughput: 28704.988
    sample_time_ms: 5636.372
    update_time_ms: 26.077
  timestamp: 1604233367
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: f98d0_00000
  
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     20 |           406.58 | 3235840 |  45.4494 |              47.6495 |              21.2577 |            103.695 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f98d0_00000:
  custom_metrics:
    time_step_max: 1662
    time_step_mean: 1190.7317714705164
    time_step_min: 1150
  date: 2020-11-01_12-23-08
  done: false
  episode_len_mean: 103.52679335207137
  episode_reward_max: 47.64948453608255
  episode_reward_mean: 45.553595837989505
  episode_reward_min: 21.25773195876288
  episodes_this_iter: 1605
  episodes_total: 32732
  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.5605561385552088
        entropy_coeff: 0.0005000000000000001
        kl: 0.0051246628087634844
        model: {}
        policy_loss: -0.00707746635695609
        total_loss: 0.12786801221470037
        vf_explained_var: 0.9988241195678711
        vf_loss: 0.13420082504550615
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.108
    gpu_util_percent0: 0.36239999999999994
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5679999999999996
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2614
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1508982454274576
    mean_env_wait_ms: 0.6533685645927871
    mean_inference_ms: 4.196348243483211
    mean_raw_obs_processing_ms: 0.393820825357919
  time_since_restore: 426.77583384513855
  time_this_iter_s: 20.195589542388916
  time_total_s: 426.77583384513855
  timers:
    learn_throughput: 11330.776
    learn_time_ms: 14278.986
    sample_throughput: 28644.617
    sample_time_ms: 5648.251
    update_time_ms: 25.717
  timestamp: 1604233388
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: f98d0_00000
  
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     21 |          426.776 | 3397632 |  45.5536 |              47.6495 |              21.2577 |            103.527 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f98d0_00000:
  custom_metrics:
    time_step_max: 1662
    time_step_mean: 1188.871339064549
    time_step_min: 1150
  date: 2020-11-01_12-23-29
  done: false
  episode_len_mean: 103.37087712148119
  episode_reward_max: 47.64948453608255
  episode_reward_mean: 45.649092584828495
  episode_reward_min: 21.25773195876288
  episodes_this_iter: 1619
  episodes_total: 34351
  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.5297549913326899
        entropy_coeff: 0.0005000000000000001
        kl: 0.005221013678237796
        model: {}
        policy_loss: -0.007347211508507219
        total_loss: 0.11089812219142914
        vf_explained_var: 0.9989762306213379
        vf_loss: 0.11746600580712159
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.358333333333334
    gpu_util_percent0: 0.4533333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.570833333333333
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2614
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15069056354724808
    mean_env_wait_ms: 0.6533427688463339
    mean_inference_ms: 4.1868632869880145
    mean_raw_obs_processing_ms: 0.3931430489205958
  time_since_restore: 447.03629064559937
  time_this_iter_s: 20.260456800460815
  time_total_s: 447.03629064559937
  timers:
    learn_throughput: 11328.702
    learn_time_ms: 14281.601
    sample_throughput: 28676.086
    sample_time_ms: 5642.053
    update_time_ms: 25.502
  timestamp: 1604233409
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: f98d0_00000
  
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     22 |          447.036 | 3559424 |  45.6491 |              47.6495 |              21.2577 |            103.371 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f98d0_00000:
  custom_metrics:
    time_step_max: 1662
    time_step_mean: 1187.1485870048955
    time_step_min: 1150
  date: 2020-11-01_12-23-50
  done: false
  episode_len_mean: 103.22507502500834
  episode_reward_max: 47.64948453608255
  episode_reward_mean: 45.737731878552886
  episode_reward_min: 21.25773195876288
  episodes_this_iter: 1637
  episodes_total: 35988
  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.5043502772847811
        entropy_coeff: 0.0005000000000000001
        kl: 0.0051153005721668405
        model: {}
        policy_loss: -0.007804131872641544
        total_loss: 0.08389338354269664
        vf_explained_var: 0.9992172718048096
        vf_loss: 0.09092663104335467
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.10769230769231
    gpu_util_percent0: 0.4111538461538462
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5692307692307685
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2614
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1504958593946037
    mean_env_wait_ms: 0.6533264567796601
    mean_inference_ms: 4.177979473432433
    mean_raw_obs_processing_ms: 0.39250620871910297
  time_since_restore: 467.43437933921814
  time_this_iter_s: 20.398088693618774
  time_total_s: 467.43437933921814
  timers:
    learn_throughput: 11352.718
    learn_time_ms: 14251.389
    sample_throughput: 28591.581
    sample_time_ms: 5658.729
    update_time_ms: 26.115
  timestamp: 1604233430
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: f98d0_00000
  
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     23 |          467.434 | 3721216 |  45.7377 |              47.6495 |              21.2577 |            103.225 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f98d0_00000:
  custom_metrics:
    time_step_max: 1662
    time_step_mean: 1185.5975664953805
    time_step_min: 1150
  date: 2020-11-01_12-24-11
  done: false
  episode_len_mean: 103.0935496741588
  episode_reward_max: 47.64948453608255
  episode_reward_mean: 45.817267047191805
  episode_reward_min: 21.25773195876288
  episodes_this_iter: 1607
  episodes_total: 37595
  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.477857805788517
        entropy_coeff: 0.0005000000000000001
        kl: 0.005301223369315267
        model: {}
        policy_loss: -0.007187186017593679
        total_loss: 0.0712860906496644
        vf_explained_var: 0.9993272423744202
        vf_loss: 0.07765195891261101
    num_steps_sampled: 3883008
    num_steps_trained: 3883008
  iterations_since_restore: 24
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.808000000000003
    gpu_util_percent0: 0.41159999999999997
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5679999999999996
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2614
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1503165502098337
    mean_env_wait_ms: 0.6533168664023659
    mean_inference_ms: 4.1697739229427855
    mean_raw_obs_processing_ms: 0.39192023267055776
  time_since_restore: 487.5962927341461
  time_this_iter_s: 20.16191339492798
  time_total_s: 487.5962927341461
  timers:
    learn_throughput: 11345.276
    learn_time_ms: 14260.737
    sample_throughput: 28572.718
    sample_time_ms: 5662.465
    update_time_ms: 25.82
  timestamp: 1604233451
  timesteps_since_restore: 0
  timesteps_total: 3883008
  training_iteration: 24
  trial_id: f98d0_00000
  
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     24 |          487.596 | 3883008 |  45.8173 |              47.6495 |              21.2577 |            103.094 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f98d0_00000:
  custom_metrics:
    time_step_max: 1662
    time_step_mean: 1184.1811960574025
    time_step_min: 1150
  date: 2020-11-01_12-24-32
  done: false
  episode_len_mean: 102.9715546711567
  episode_reward_max: 47.64948453608255
  episode_reward_mean: 45.8903373462669
  episode_reward_min: 21.25773195876288
  episodes_this_iter: 1603
  episodes_total: 39198
  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.4582882300019264
        entropy_coeff: 0.0005000000000000001
        kl: 0.004777276888489723
        model: {}
        policy_loss: -0.006818818922814292
        total_loss: 0.06491830727706353
        vf_explained_var: 0.9993811249732971
        vf_loss: 0.07101081249614556
    num_steps_sampled: 4044800
    num_steps_trained: 4044800
  iterations_since_restore: 25
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.5
    gpu_util_percent0: 0.4164
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.571999999999999
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2614
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15014800244823473
    mean_env_wait_ms: 0.6533117275008512
    mean_inference_ms: 4.162086682670796
    mean_raw_obs_processing_ms: 0.3913710326970964
  time_since_restore: 507.939138174057
  time_this_iter_s: 20.34284543991089
  time_total_s: 507.939138174057
  timers:
    learn_throughput: 11324.044
    learn_time_ms: 14287.476
    sample_throughput: 28578.2
    sample_time_ms: 5661.378
    update_time_ms: 26.054
  timestamp: 1604233472
  timesteps_since_restore: 0
  timesteps_total: 4044800
  training_iteration: 25
  trial_id: f98d0_00000
  
2020-11-01 12:24:33,109	WARNING util.py:136 -- The `process_trial` operation took 0.5145235061645508 seconds to complete, which may be a performance bottleneck.
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     25 |          507.939 | 4044800 |  45.8903 |              47.6495 |              21.2577 |            102.972 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f98d0_00000:
  custom_metrics:
    time_step_max: 1662
    time_step_mean: 1182.8508853681267
    time_step_min: 1150
  date: 2020-11-01_12-24-53
  done: false
  episode_len_mean: 102.8577064444989
  episode_reward_max: 47.64948453608255
  episode_reward_mean: 45.95893087655392
  episode_reward_min: 21.25773195876288
  episodes_this_iter: 1612
  episodes_total: 40810
  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.4304437041282654
        entropy_coeff: 0.0005000000000000001
        kl: 0.005302870219262938
        model: {}
        policy_loss: -0.005320634130233278
        total_loss: 0.04602197107548515
        vf_explained_var: 0.9995622038841248
        vf_loss: 0.05102753918617964
    num_steps_sampled: 4206592
    num_steps_trained: 4206592
  iterations_since_restore: 26
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.031999999999996
    gpu_util_percent0: 0.4016
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.571999999999999
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2614
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14998848423358552
    mean_env_wait_ms: 0.6533120076712385
    mean_inference_ms: 4.154808738528033
    mean_raw_obs_processing_ms: 0.39085074710802764
  time_since_restore: 528.287171125412
  time_this_iter_s: 20.34803295135498
  time_total_s: 528.287171125412
  timers:
    learn_throughput: 11314.942
    learn_time_ms: 14298.969
    sample_throughput: 28539.444
    sample_time_ms: 5669.066
    update_time_ms: 26.44
  timestamp: 1604233493
  timesteps_since_restore: 0
  timesteps_total: 4206592
  training_iteration: 26
  trial_id: f98d0_00000
  
2020-11-01 12:24:54,161	WARNING util.py:136 -- The `process_trial` operation took 0.5190365314483643 seconds to complete, which may be a performance bottleneck.
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     26 |          528.287 | 4206592 |  45.9589 |              47.6495 |              21.2577 |            102.858 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f98d0_00000:
  custom_metrics:
    time_step_max: 1662
    time_step_mean: 1181.6014053620693
    time_step_min: 1150
  date: 2020-11-01_12-25-14
  done: false
  episode_len_mean: 102.75047708799623
  episode_reward_max: 47.64948453608255
  episode_reward_mean: 46.02298669108478
  episode_reward_min: 21.25773195876288
  episodes_this_iter: 1635
  episodes_total: 42445
  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.40619519104560214
        entropy_coeff: 0.0005000000000000001
        kl: 0.004850935540162027
        model: {}
        policy_loss: -0.00712713325143947
        total_loss: 0.04109010814378659
        vf_explained_var: 0.9995940327644348
        vf_loss: 0.047935244316856064
    num_steps_sampled: 4368384
    num_steps_trained: 4368384
  iterations_since_restore: 27
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.9
    gpu_util_percent0: 0.4608
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.571999999999999
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2614
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14983678273441456
    mean_env_wait_ms: 0.6533202946066505
    mean_inference_ms: 4.147883359756837
    mean_raw_obs_processing_ms: 0.3903567513935103
  time_since_restore: 548.3913764953613
  time_this_iter_s: 20.10420536994934
  time_total_s: 548.3913764953613
  timers:
    learn_throughput: 11320.7
    learn_time_ms: 14291.696
    sample_throughput: 28538.222
    sample_time_ms: 5669.309
    update_time_ms: 25.152
  timestamp: 1604233514
  timesteps_since_restore: 0
  timesteps_total: 4368384
  training_iteration: 27
  trial_id: f98d0_00000
  
2020-11-01 12:25:14,990	WARNING util.py:136 -- The `process_trial` operation took 0.5334711074829102 seconds to complete, which may be a performance bottleneck.
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     27 |          548.391 | 4368384 |   46.023 |              47.6495 |              21.2577 |             102.75 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f98d0_00000:
  custom_metrics:
    time_step_max: 1662
    time_step_mean: 1180.4515455020326
    time_step_min: 1150
  date: 2020-11-01_12-25-35
  done: false
  episode_len_mean: 102.6508271495677
  episode_reward_max: 47.64948453608255
  episode_reward_mean: 46.08214646909499
  episode_reward_min: 21.25773195876288
  episodes_this_iter: 1622
  episodes_total: 44067
  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.0e-05
        entropy: 0.380776509642601
        entropy_coeff: 0.0005000000000000001
        kl: 0.005104163157132764
        model: {}
        policy_loss: -0.008030562166823074
        total_loss: 0.03263539479424556
        vf_explained_var: 0.9996626377105713
        vf_loss: 0.0406011367837588
    num_steps_sampled: 4530176
    num_steps_trained: 4530176
  iterations_since_restore: 28
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.724
    gpu_util_percent0: 0.3708000000000001
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.571999999999999
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2614
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14969387594042302
    mean_env_wait_ms: 0.6533341674809083
    mean_inference_ms: 4.141387554786562
    mean_raw_obs_processing_ms: 0.3898925942202909
  time_since_restore: 568.5405015945435
  time_this_iter_s: 20.14912509918213
  time_total_s: 568.5405015945435
  timers:
    learn_throughput: 11317.578
    learn_time_ms: 14295.638
    sample_throughput: 28540.327
    sample_time_ms: 5668.891
    update_time_ms: 27.131
  timestamp: 1604233535
  timesteps_since_restore: 0
  timesteps_total: 4530176
  training_iteration: 28
  trial_id: f98d0_00000
  
2020-11-01 12:25:35,895	WARNING util.py:136 -- The `process_trial` operation took 0.5552034378051758 seconds to complete, which may be a performance bottleneck.
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     28 |          568.541 | 4530176 |  46.0821 |              47.6495 |              21.2577 |            102.651 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f98d0_00000:
  custom_metrics:
    time_step_max: 1662
    time_step_mean: 1179.389183503528
    time_step_min: 1150
  date: 2020-11-01_12-25-56
  done: false
  episode_len_mean: 102.55971097000219
  episode_reward_max: 47.64948453608255
  episode_reward_mean: 46.136667351393584
  episode_reward_min: 21.25773195876288
  episodes_this_iter: 1603
  episodes_total: 45670
  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.0e-05
        entropy: 0.3589545438687007
        entropy_coeff: 0.0005000000000000001
        kl: 0.005236083525232971
        model: {}
        policy_loss: -0.005505533023097087
        total_loss: 0.02439635860112806
        vf_explained_var: 0.9997479915618896
        vf_loss: 0.029819565049062174
    num_steps_sampled: 4691968
    num_steps_trained: 4691968
  iterations_since_restore: 29
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.04
    gpu_util_percent0: 0.3832
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.571999999999999
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2614
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14955992403902243
    mean_env_wait_ms: 0.65334881821503
    mean_inference_ms: 4.135306265563136
    mean_raw_obs_processing_ms: 0.3894575857046042
  time_since_restore: 588.7653107643127
  time_this_iter_s: 20.224809169769287
  time_total_s: 588.7653107643127
  timers:
    learn_throughput: 11315.541
    learn_time_ms: 14298.212
    sample_throughput: 28543.882
    sample_time_ms: 5668.185
    update_time_ms: 27.394
  timestamp: 1604233556
  timesteps_since_restore: 0
  timesteps_total: 4691968
  training_iteration: 29
  trial_id: f98d0_00000
  
2020-11-01 12:25:56,904	WARNING util.py:136 -- The `process_trial` operation took 0.5792350769042969 seconds to complete, which may be a performance bottleneck.
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     29 |          588.765 | 4691968 |  46.1367 |              47.6495 |              21.2577 |             102.56 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f98d0_00000:
  custom_metrics:
    time_step_max: 1662
    time_step_mean: 1178.4016808145811
    time_step_min: 1150
  date: 2020-11-01_12-26-17
  done: true
  episode_len_mean: 102.47428873611845
  episode_reward_max: 47.64948453608255
  episode_reward_mean: 46.187587432602626
  episode_reward_min: 21.25773195876288
  episodes_this_iter: 1605
  episodes_total: 47275
  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.0e-05
        entropy: 0.34163280328114826
        entropy_coeff: 0.0005000000000000001
        kl: 0.005014610709622502
        model: {}
        policy_loss: -0.006093008596508298
        total_loss: 0.02250015801594903
        vf_explained_var: 0.9997627139091492
        vf_loss: 0.028513251959035795
    num_steps_sampled: 4853760
    num_steps_trained: 4853760
  iterations_since_restore: 30
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.592000000000002
    gpu_util_percent0: 0.4032
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.571999999999999
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2614
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14943275367352743
    mean_env_wait_ms: 0.6533656820836667
    mean_inference_ms: 4.129545135974801
    mean_raw_obs_processing_ms: 0.38904409500028486
  time_since_restore: 608.9674067497253
  time_this_iter_s: 20.202095985412598
  time_total_s: 608.9674067497253
  timers:
    learn_throughput: 11308.582
    learn_time_ms: 14307.01
    sample_throughput: 28493.852
    sample_time_ms: 5678.137
    update_time_ms: 27.445
  timestamp: 1604233577
  timesteps_since_restore: 0
  timesteps_total: 4853760
  training_iteration: 30
  trial_id: f98d0_00000
  
2020-11-01 12:26:18,072	WARNING util.py:136 -- The `process_trial` operation took 0.6780698299407959 seconds to complete, which may be a performance bottleneck.
== Status ==
Memory usage on this node: 24.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f98d0_00000 | TERMINATED |       |     30 |          608.967 | 4853760 |  46.1876 |              47.6495 |              21.2577 |            102.474 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 24.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f98d0_00000 | TERMINATED |       |     30 |          608.967 | 4853760 |  46.1876 |              47.6495 |              21.2577 |            102.474 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


