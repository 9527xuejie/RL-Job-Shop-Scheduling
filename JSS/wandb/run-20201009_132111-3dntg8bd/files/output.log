2020-10-09 13:21:15,602	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_4fce1_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=25048)[0m 2020-10-09 13:21:18,613	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=24990)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24990)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25038)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25038)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25046)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25046)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25015)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25015)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25011)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25011)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25002)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25002)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25041)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25041)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24943)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24943)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24934)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24934)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24928)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24928)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24942)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24942)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25040)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25040)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25057)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25057)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24958)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24958)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25014)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25014)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25031)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25031)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24995)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24995)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25012)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25012)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25009)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25009)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25005)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25005)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25029)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25029)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24947)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24947)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25028)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25028)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25022)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25022)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24953)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24953)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25043)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25043)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24960)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24960)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25055)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25055)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25052)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25052)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24999)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24999)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25034)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25034)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24932)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24932)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25030)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25030)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24930)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24930)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24988)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24988)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25032)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25032)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25039)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25039)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25001)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25001)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24949)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24949)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24919)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24919)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25036)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25036)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24997)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24997)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25018)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25018)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25007)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25007)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24963)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24963)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24993)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24993)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25013)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25013)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24996)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24996)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25003)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25003)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24920)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24920)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24931)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24931)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24992)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24992)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25058)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25058)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24938)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24938)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24936)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24936)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25024)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25024)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24959)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24959)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24961)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24961)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25027)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25027)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24926)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24926)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25017)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25017)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25006)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25006)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24939)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24939)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24925)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24925)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25045)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25045)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25000)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25000)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24927)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24927)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25004)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25004)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24954)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24954)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25050)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25050)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25008)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25008)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24940)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24940)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24966)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24966)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25020)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25020)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24952)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24952)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25010)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25010)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24933)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24933)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24935)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24935)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=24929)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24929)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_4fce1_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3614.3384615384616
    time_step_min: 3379
  date: 2020-10-09_13-21-55
  done: false
  episode_len_mean: 891.506329113924
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.09308272599387
  episode_reward_min: 136.77777777777735
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 1adf5dec9c0f4909a55616499c30386e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.186342564496127
        entropy_coeff: 0.0
        kl: 0.003734185169874267
        model: {}
        policy_loss: -0.006400093923068859
        total_loss: 504.598671653054
        vf_explained_var: 0.5546019077301025
        vf_loss: 504.6043174050071
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.494594594594595
    gpu_util_percent0: 0.4302702702702702
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.6162162162162157
    vram_util_percent0: 0.09433088385203835
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25048
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15962128140154208
    mean_env_wait_ms: 1.164561955050651
    mean_inference_ms: 4.799142494802307
    mean_raw_obs_processing_ms: 0.4200550802477571
  time_since_restore: 31.01964545249939
  time_this_iter_s: 31.01964545249939
  time_total_s: 31.01964545249939
  timers:
    learn_throughput: 6946.67
    learn_time_ms: 23290.582
    sample_throughput: 21105.018
    sample_time_ms: 7666.044
    update_time_ms: 28.073
  timestamp: 1602249715
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 4fce1_00000
  
== Status ==
Memory usage on this node: 27.9/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4fce1_00000 | RUNNING  | 172.17.0.4:25048 |      1 |          31.0196 | 161792 |  216.093 |              258.596 |              136.778 |            891.506 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4fce1_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.84375
    time_step_min: 3331
  date: 2020-10-09_13-22-25
  done: false
  episode_len_mean: 889.6645569620254
  episode_reward_max: 261.323232323232
  episode_reward_mean: 217.4207582150618
  episode_reward_min: 136.77777777777735
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 1adf5dec9c0f4909a55616499c30386e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.1516491608186201
        entropy_coeff: 0.0
        kl: 0.007062725638124076
        model: {}
        policy_loss: -0.0039830854432445694
        total_loss: 126.55930605801669
        vf_explained_var: 0.8152221441268921
        vf_loss: 126.56258114901456
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.43714285714286
    gpu_util_percent0: 0.29742857142857143
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7857142857142865
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25048
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15786353704619888
    mean_env_wait_ms: 1.1636545602108967
    mean_inference_ms: 4.765319343803612
    mean_raw_obs_processing_ms: 0.41658518582916937
  time_since_restore: 61.643393993377686
  time_this_iter_s: 30.623748540878296
  time_total_s: 61.643393993377686
  timers:
    learn_throughput: 7003.398
    learn_time_ms: 23101.928
    sample_throughput: 21142.838
    sample_time_ms: 7652.331
    update_time_ms: 25.75
  timestamp: 1602249745
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 4fce1_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4fce1_00000 | RUNNING  | 172.17.0.4:25048 |      2 |          61.6434 | 323584 |  217.421 |              261.323 |              136.778 |            889.665 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4fce1_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0
    time_step_min: 3331
  date: 2020-10-09_13-22-56
  done: false
  episode_len_mean: 886.1962025316456
  episode_reward_max: 261.323232323232
  episode_reward_mean: 218.71806674338296
  episode_reward_min: 136.77777777777735
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 1adf5dec9c0f4909a55616499c30386e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.1424578536640515
        entropy_coeff: 0.0
        kl: 0.008548043498938734
        model: {}
        policy_loss: -0.015313899432261347
        total_loss: 60.55732796408913
        vf_explained_var: 0.890821635723114
        vf_loss: 60.57178774746981
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.397142857142857
    gpu_util_percent0: 0.3534285714285714
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8028571428571434
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25048
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15634243258684985
    mean_env_wait_ms: 1.1642296931567626
    mean_inference_ms: 4.713263724635146
    mean_raw_obs_processing_ms: 0.41233202189704504
  time_since_restore: 92.1032304763794
  time_this_iter_s: 30.45983648300171
  time_total_s: 92.1032304763794
  timers:
    learn_throughput: 6982.642
    learn_time_ms: 23170.601
    sample_throughput: 21685.669
    sample_time_ms: 7460.78
    update_time_ms: 24.77
  timestamp: 1602249776
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 4fce1_00000
  
== Status ==
Memory usage on this node: 28.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4fce1_00000 | RUNNING  | 172.17.0.4:25048 |      3 |          92.1032 | 485376 |  218.718 |              261.323 |              136.778 |            886.196 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4fce1_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3600.1208609271525
    time_step_min: 3330
  date: 2020-10-09_13-23-26
  done: false
  episode_len_mean: 881.6376582278481
  episode_reward_max: 264.2020202020198
  episode_reward_mean: 220.91567574478947
  episode_reward_min: 136.77777777777735
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 1adf5dec9c0f4909a55616499c30386e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.1280797611583362
        entropy_coeff: 0.0
        kl: 0.0073576091619377785
        model: {}
        policy_loss: -0.011185637093149126
        total_loss: 38.490605094216086
        vf_explained_var: 0.9280803203582764
        vf_loss: 38.50105459039862
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.962857142857146
    gpu_util_percent0: 0.32
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.814285714285715
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25048
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1551506699377503
    mean_env_wait_ms: 1.1653311690878125
    mean_inference_ms: 4.666669960909577
    mean_raw_obs_processing_ms: 0.40863274384198084
  time_since_restore: 122.11041021347046
  time_this_iter_s: 30.007179737091064
  time_total_s: 122.11041021347046
  timers:
    learn_throughput: 6993.51
    learn_time_ms: 23134.592
    sample_throughput: 22101.771
    sample_time_ms: 7320.318
    update_time_ms: 27.469
  timestamp: 1602249806
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 4fce1_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4fce1_00000 | RUNNING  | 172.17.0.4:25048 |      4 |           122.11 | 647168 |  220.916 |              264.202 |              136.778 |            881.638 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4fce1_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3585.9370078740158
    time_step_min: 3273
  date: 2020-10-09_13-23-56
  done: false
  episode_len_mean: 876.3481012658228
  episode_reward_max: 277.23232323232315
  episode_reward_mean: 222.92373098069285
  episode_reward_min: 136.77777777777735
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 1adf5dec9c0f4909a55616499c30386e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.0957071672786365
        entropy_coeff: 0.0
        kl: 0.007666376969692382
        model: {}
        policy_loss: -0.0036795981313017282
        total_loss: 32.79757967862216
        vf_explained_var: 0.9450544118881226
        vf_loss: 32.80049272017045
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.674285714285716
    gpu_util_percent0: 0.3922857142857143
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8171428571428576
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25048
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15420564824706973
    mean_env_wait_ms: 1.1667695880336457
    mean_inference_ms: 4.627961760022975
    mean_raw_obs_processing_ms: 0.4054777583013631
  time_since_restore: 152.11305713653564
  time_this_iter_s: 30.002646923065186
  time_total_s: 152.11305713653564
  timers:
    learn_throughput: 6996.068
    learn_time_ms: 23126.132
    sample_throughput: 22396.482
    sample_time_ms: 7223.992
    update_time_ms: 26.386
  timestamp: 1602249836
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 4fce1_00000
  
== Status ==
Memory usage on this node: 28.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4fce1_00000 | RUNNING  | 172.17.0.4:25048 |      5 |          152.113 | 808960 |  222.924 |              277.232 |              136.778 |            876.348 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4fce1_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3559.7685873605947
    time_step_min: 3242
  date: 2020-10-09_13-24-26
  done: false
  episode_len_mean: 867.2201086956521
  episode_reward_max: 281.32323232323245
  episode_reward_mean: 226.66976833552903
  episode_reward_min: 136.77777777777735
  episodes_this_iter: 314
  episodes_total: 1104
  experiment_id: 1adf5dec9c0f4909a55616499c30386e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.0836314938285134
        entropy_coeff: 0.0
        kl: 0.007265032396059145
        model: {}
        policy_loss: -0.00521643159233711
        total_loss: 35.21451811356978
        vf_explained_var: 0.9566624164581299
        vf_loss: 35.21900801225142
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.179411764705883
    gpu_util_percent0: 0.26970588235294124
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7970588235294116
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25048
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15291152947432857
    mean_env_wait_ms: 1.170435190247457
    mean_inference_ms: 4.572498411245044
    mean_raw_obs_processing_ms: 0.4013803515378418
  time_since_restore: 181.94769430160522
  time_this_iter_s: 29.83463716506958
  time_total_s: 181.94769430160522
  timers:
    learn_throughput: 7002.05
    learn_time_ms: 23106.377
    sample_throughput: 22641.932
    sample_time_ms: 7145.68
    update_time_ms: 25.411
  timestamp: 1602249866
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 4fce1_00000
  
== Status ==
Memory usage on this node: 28.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4fce1_00000 | RUNNING  | 172.17.0.4:25048 |      6 |          181.948 | 970752 |   226.67 |              281.323 |              136.778 |             867.22 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4fce1_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3548.7661812297733
    time_step_min: 3242
  date: 2020-10-09_13-24-56
  done: false
  episode_len_mean: 862.753164556962
  episode_reward_max: 281.32323232323245
  episode_reward_mean: 227.83526722925436
  episode_reward_min: 136.77777777777735
  episodes_this_iter: 160
  episodes_total: 1264
  experiment_id: 1adf5dec9c0f4909a55616499c30386e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.065663532777266
        entropy_coeff: 0.0
        kl: 0.007907447489825163
        model: {}
        policy_loss: -0.010015583343126556
        total_loss: 22.390480735085227
        vf_explained_var: 0.9611008167266846
        vf_loss: 22.39970554005016
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.77428571428571
    gpu_util_percent0: 0.36457142857142855
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8028571428571434
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25048
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15242969713638432
    mean_env_wait_ms: 1.1720523224285913
    mean_inference_ms: 4.551565012764307
    mean_raw_obs_processing_ms: 0.3998613882610598
  time_since_restore: 212.15917301177979
  time_this_iter_s: 30.21147871017456
  time_total_s: 212.15917301177979
  timers:
    learn_throughput: 6988.093
    learn_time_ms: 23152.526
    sample_throughput: 22847.791
    sample_time_ms: 7081.297
    update_time_ms: 27.216
  timestamp: 1602249896
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 4fce1_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4fce1_00000 | RUNNING  | 172.17.0.4:25048 |      7 |          212.159 | 1132544 |  227.835 |              281.323 |              136.778 |            862.753 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4fce1_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3541.4691535150646
    time_step_min: 3234
  date: 2020-10-09_13-25-26
  done: false
  episode_len_mean: 858.8199718706048
  episode_reward_max: 281.32323232323245
  episode_reward_mean: 229.21810936367885
  episode_reward_min: 136.77777777777735
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 1adf5dec9c0f4909a55616499c30386e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.051892562346025
        entropy_coeff: 0.0
        kl: 0.006317193408242681
        model: {}
        policy_loss: -0.01270514599640261
        total_loss: 18.534130790016867
        vf_explained_var: 0.9658027291297913
        vf_loss: 18.546203786676582
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.947058823529414
    gpu_util_percent0: 0.34294117647058825
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8000000000000007
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25048
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1520169374352084
    mean_env_wait_ms: 1.1734854396843855
    mean_inference_ms: 4.533241965825189
    mean_raw_obs_processing_ms: 0.39849492014976096
  time_since_restore: 242.01730251312256
  time_this_iter_s: 29.858129501342773
  time_total_s: 242.01730251312256
  timers:
    learn_throughput: 6993.784
    learn_time_ms: 23133.685
    sample_throughput: 22968.462
    sample_time_ms: 7044.094
    update_time_ms: 25.898
  timestamp: 1602249926
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 4fce1_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4fce1_00000 | RUNNING  | 172.17.0.4:25048 |      8 |          242.017 | 1294336 |  229.218 |              281.323 |              136.778 |             858.82 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4fce1_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3533.938144329897
    time_step_min: 3234
  date: 2020-10-09_13-25-56
  done: false
  episode_len_mean: 855.7696202531646
  episode_reward_max: 281.32323232323245
  episode_reward_mean: 230.26051655798477
  episode_reward_min: 136.77777777777735
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 1adf5dec9c0f4909a55616499c30386e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.0206010666760532
        entropy_coeff: 0.0
        kl: 0.008004230150783604
        model: {}
        policy_loss: -0.0057261634739750825
        total_loss: 21.60241733897816
        vf_explained_var: 0.9607520699501038
        vf_loss: 21.607343326915394
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.152941176470588
    gpu_util_percent0: 0.3476470588235294
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.855882352941177
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25048
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15165499518045994
    mean_env_wait_ms: 1.1748403061773045
    mean_inference_ms: 4.5169157102426905
    mean_raw_obs_processing_ms: 0.39724171950168063
  time_since_restore: 271.63200545310974
  time_this_iter_s: 29.614702939987183
  time_total_s: 271.63200545310974
  timers:
    learn_throughput: 7004.609
    learn_time_ms: 23097.933
    sample_throughput: 23090.673
    sample_time_ms: 7006.812
    update_time_ms: 28.025
  timestamp: 1602249956
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 4fce1_00000
  
== Status ==
Memory usage on this node: 28.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4fce1_00000 | RUNNING  | 172.17.0.4:25048 |      9 |          271.632 | 1456128 |  230.261 |              281.323 |              136.778 |             855.77 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4fce1_00000:
  custom_metrics:
    time_step_max: 4115
    time_step_mean: 3522.214402618658
    time_step_min: 3234
  date: 2020-10-09_13-26-26
  done: false
  episode_len_mean: 851.3175711982805
  episode_reward_max: 286.171717171717
  episode_reward_mean: 232.2881745992975
  episode_reward_min: 136.77777777777735
  episodes_this_iter: 281
  episodes_total: 1861
  experiment_id: 1adf5dec9c0f4909a55616499c30386e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.9899097897789695
        entropy_coeff: 0.0
        kl: 0.006573941812596538
        model: {}
        policy_loss: -0.008355972822755575
        total_loss: 28.36297572742809
        vf_explained_var: 0.964978814125061
        vf_loss: 28.37067413330078
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.65142857142858
    gpu_util_percent0: 0.3725714285714286
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7885714285714283
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25048
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15113240950752654
    mean_env_wait_ms: 1.1769966668547311
    mean_inference_ms: 4.4929555060549715
    mean_raw_obs_processing_ms: 0.39546727754336025
  time_since_restore: 301.8057014942169
  time_this_iter_s: 30.173696041107178
  time_total_s: 301.8057014942169
  timers:
    learn_throughput: 7008.032
    learn_time_ms: 23086.653
    sample_throughput: 23057.973
    sample_time_ms: 7016.749
    update_time_ms: 28.429
  timestamp: 1602249986
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 4fce1_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4fce1_00000 | RUNNING  | 172.17.0.4:25048 |     10 |          301.806 | 1617920 |  232.288 |              286.172 |              136.778 |            851.318 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4fce1_00000:
  custom_metrics:
    time_step_max: 4115
    time_step_mean: 3512.7275419545904
    time_step_min: 3187
  date: 2020-10-09_13-26-56
  done: false
  episode_len_mean: 848.9342745861733
  episode_reward_max: 286.171717171717
  episode_reward_mean: 233.72136162009565
  episode_reward_min: 136.77777777777735
  episodes_this_iter: 193
  episodes_total: 2054
  experiment_id: 1adf5dec9c0f4909a55616499c30386e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.9792910164052789
        entropy_coeff: 0.0
        kl: 0.006905705879696391
        model: {}
        policy_loss: -0.008842719812698553
        total_loss: 15.649945259094238
        vf_explained_var: 0.9743375182151794
        vf_loss: 15.6580979607322
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.20857142857143
    gpu_util_percent0: 0.3462857142857143
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.805714285714286
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25048
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15082669199639567
    mean_env_wait_ms: 1.1783013909014226
    mean_inference_ms: 4.47921899027593
    mean_raw_obs_processing_ms: 0.3944736647621241
  time_since_restore: 331.8091330528259
  time_this_iter_s: 30.00343155860901
  time_total_s: 331.8091330528259
  timers:
    learn_throughput: 7018.907
    learn_time_ms: 23050.881
    sample_throughput: 23281.1
    sample_time_ms: 6949.5
    update_time_ms: 27.583
  timestamp: 1602250016
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 4fce1_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4fce1_00000 | RUNNING  | 172.17.0.4:25048 |     11 |          331.809 | 1779712 |  233.721 |              286.172 |              136.778 |            848.934 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4fce1_00000:
  custom_metrics:
    time_step_max: 4115
    time_step_mean: 3505.0828754578756
    time_step_min: 3187
  date: 2020-10-09_13-27-26
  done: false
  episode_len_mean: 846.6749547920434
  episode_reward_max: 286.171717171717
  episode_reward_mean: 234.8723994008803
  episode_reward_min: 136.77777777777735
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 1adf5dec9c0f4909a55616499c30386e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.9650880315087058
        entropy_coeff: 0.0
        kl: 0.005957515359940854
        model: {}
        policy_loss: -0.002549712376838381
        total_loss: 12.741229837590998
        vf_explained_var: 0.9765684008598328
        vf_loss: 12.743183742869984
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.947058823529414
    gpu_util_percent0: 0.3511764705882352
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25048
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1506086792078222
    mean_env_wait_ms: 1.179217015466115
    mean_inference_ms: 4.469248908881876
    mean_raw_obs_processing_ms: 0.3937339721341218
  time_since_restore: 361.54867935180664
  time_this_iter_s: 29.739546298980713
  time_total_s: 361.54867935180664
  timers:
    learn_throughput: 7024.73
    learn_time_ms: 23031.776
    sample_throughput: 23517.839
    sample_time_ms: 6879.544
    update_time_ms: 26.967
  timestamp: 1602250046
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 4fce1_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4fce1_00000 | RUNNING  | 172.17.0.4:25048 |     12 |          361.549 | 1941504 |  234.872 |              286.172 |              136.778 |            846.675 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4fce1_00000:
  custom_metrics:
    time_step_max: 4115
    time_step_mean: 3497.9859094790777
    time_step_min: 3159
  date: 2020-10-09_13-27-56
  done: false
  episode_len_mean: 844.6362869198313
  episode_reward_max: 287.3838383838384
  episode_reward_mean: 235.92021480629063
  episode_reward_min: 136.77777777777735
  episodes_this_iter: 158
  episodes_total: 2370
  experiment_id: 1adf5dec9c0f4909a55616499c30386e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.9397648518735712
        entropy_coeff: 0.0
        kl: 0.006702074019069021
        model: {}
        policy_loss: -0.00718664947304536
        total_loss: 12.931520635431463
        vf_explained_var: 0.9757211804389954
        vf_loss: 12.938037005337803
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.49705882352941
    gpu_util_percent0: 0.356764705882353
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8676470588235294
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25048
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15041414051498303
    mean_env_wait_ms: 1.1800898541561036
    mean_inference_ms: 4.460165706245739
    mean_raw_obs_processing_ms: 0.3930421265974292
  time_since_restore: 391.3166902065277
  time_this_iter_s: 29.76801085472107
  time_total_s: 391.3166902065277
  timers:
    learn_throughput: 7038.157
    learn_time_ms: 22987.835
    sample_throughput: 23608.506
    sample_time_ms: 6853.123
    update_time_ms: 26.689
  timestamp: 1602250076
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 4fce1_00000
  
== Status ==
Memory usage on this node: 28.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4fce1_00000 | RUNNING  | 172.17.0.4:25048 |     13 |          391.317 | 2103296 |   235.92 |              287.384 |              136.778 |            844.636 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4fce1_00000:
  custom_metrics:
    time_step_max: 4115
    time_step_mean: 3485.320898363152
    time_step_min: 3159
  date: 2020-10-09_13-28-26
  done: false
  episode_len_mean: 840.9118644067796
  episode_reward_max: 288.1414141414143
  episode_reward_mean: 237.78913428065965
  episode_reward_min: 136.77777777777735
  episodes_this_iter: 285
  episodes_total: 2655
  experiment_id: 1adf5dec9c0f4909a55616499c30386e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.9094517230987549
        entropy_coeff: 0.0
        kl: 0.006454780528491194
        model: {}
        policy_loss: -0.003539222759586251
        total_loss: 17.45256059820002
        vf_explained_var: 0.9767268896102905
        vf_loss: 17.455455086447976
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.905882352941177
    gpu_util_percent0: 0.38941176470588235
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7911764705882356
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25048
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15010489879911332
    mean_env_wait_ms: 1.1817378351331131
    mean_inference_ms: 4.4457686001103
    mean_raw_obs_processing_ms: 0.39196000140069576
  time_since_restore: 420.86385226249695
  time_this_iter_s: 29.54716205596924
  time_total_s: 420.86385226249695
  timers:
    learn_throughput: 7052.124
    learn_time_ms: 22942.307
    sample_throughput: 23608.199
    sample_time_ms: 6853.212
    update_time_ms: 24.828
  timestamp: 1602250106
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 4fce1_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4fce1_00000 | RUNNING  | 172.17.0.4:25048 |     14 |          420.864 | 2265088 |  237.789 |              288.141 |              136.778 |            840.912 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4fce1_00000:
  custom_metrics:
    time_step_max: 4115
    time_step_mean: 3477.7006392045455
    time_step_min: 3159
  date: 2020-10-09_13-28-55
  done: false
  episode_len_mean: 839.0738396624473
  episode_reward_max: 288.1414141414143
  episode_reward_mean: 238.84896432681236
  episode_reward_min: 136.77777777777735
  episodes_this_iter: 189
  episodes_total: 2844
  experiment_id: 1adf5dec9c0f4909a55616499c30386e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.8948863419619474
        entropy_coeff: 0.0
        kl: 0.007415900176221674
        model: {}
        policy_loss: -0.006708539821292189
        total_loss: 13.884615811434658
        vf_explained_var: 0.9757617712020874
        vf_loss: 13.890582951632412
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.208823529411767
    gpu_util_percent0: 0.31823529411764706
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8029411764705885
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25048
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14991804926260102
    mean_env_wait_ms: 1.1826485188427802
    mean_inference_ms: 4.43738947872231
    mean_raw_obs_processing_ms: 0.3913410572931276
  time_since_restore: 450.5514438152313
  time_this_iter_s: 29.687591552734375
  time_total_s: 450.5514438152313
  timers:
    learn_throughput: 7063.69
    learn_time_ms: 22904.741
    sample_throughput: 23591.729
    sample_time_ms: 6857.997
    update_time_ms: 25.833
  timestamp: 1602250135
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 4fce1_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4fce1_00000 | RUNNING  | 172.17.0.4:25048 |     15 |          450.551 | 2426880 |  238.849 |              288.141 |              136.778 |            839.074 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4fce1_00000:
  custom_metrics:
    time_step_max: 4115
    time_step_mean: 3473.2229320780093
    time_step_min: 3155
  date: 2020-10-09_13-29-25
  done: false
  episode_len_mean: 837.9716855429714
  episode_reward_max: 288.1414141414143
  episode_reward_mean: 239.62971487022116
  episode_reward_min: 136.77777777777735
  episodes_this_iter: 158
  episodes_total: 3002
  experiment_id: 1adf5dec9c0f4909a55616499c30386e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.8869339606978677
        entropy_coeff: 0.0
        kl: 0.006313013420863585
        model: {}
        policy_loss: -0.009511776903474873
        total_loss: 10.523137872869318
        vf_explained_var: 0.9796047210693359
        vf_loss: 10.532018314708363
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.562857142857144
    gpu_util_percent0: 0.3400000000000001
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.805714285714286
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25048
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14977653255208567
    mean_env_wait_ms: 1.1833578136182779
    mean_inference_ms: 4.430981537577551
    mean_raw_obs_processing_ms: 0.39085656782845996
  time_since_restore: 480.4291605949402
  time_this_iter_s: 29.877716779708862
  time_total_s: 480.4291605949402
  timers:
    learn_throughput: 7068.77
    learn_time_ms: 22888.281
    sample_throughput: 23553.001
    sample_time_ms: 6869.273
    update_time_ms: 34.316
  timestamp: 1602250165
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 4fce1_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4fce1_00000 | RUNNING  | 172.17.0.4:25048 |     16 |          480.429 | 2588672 |   239.63 |              288.141 |              136.778 |            837.972 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4fce1_00000:
  custom_metrics:
    time_step_max: 4115
    time_step_mean: 3468.1378870092562
    time_step_min: 3155
  date: 2020-10-09_13-29-55
  done: false
  episode_len_mean: 836.9341980385954
  episode_reward_max: 288.1414141414143
  episode_reward_mean: 240.42137924643455
  episode_reward_min: 136.77777777777735
  episodes_this_iter: 159
  episodes_total: 3161
  experiment_id: 1adf5dec9c0f4909a55616499c30386e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.8688194480809298
        entropy_coeff: 0.0
        kl: 0.006577776109969074
        model: {}
        policy_loss: -0.010196327316490087
        total_loss: 10.85499434037642
        vf_explained_var: 0.9794628024101257
        vf_loss: 10.864533077586781
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.223529411764705
    gpu_util_percent0: 0.3867647058823529
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8676470588235294
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25048
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14964453244586096
    mean_env_wait_ms: 1.184020883409756
    mean_inference_ms: 4.424970427884692
    mean_raw_obs_processing_ms: 0.39039694688524923
  time_since_restore: 509.9975724220276
  time_this_iter_s: 29.568411827087402
  time_total_s: 509.9975724220276
  timers:
    learn_throughput: 7091.2
    learn_time_ms: 22815.885
    sample_throughput: 23527.238
    sample_time_ms: 6876.795
    update_time_ms: 34.116
  timestamp: 1602250195
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 4fce1_00000
  
== Status ==
Memory usage on this node: 28.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4fce1_00000 | RUNNING  | 172.17.0.4:25048 |     17 |          509.998 | 2750464 |  240.421 |              288.141 |              136.778 |            836.934 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4fce1_00000:
  custom_metrics:
    time_step_max: 4115
    time_step_mean: 3459.789057928613
    time_step_min: 3155
  date: 2020-10-09_13-30-25
  done: false
  episode_len_mean: 835.5345327916425
  episode_reward_max: 288.1414141414143
  episode_reward_mean: 241.64226712862805
  episode_reward_min: 136.77777777777735
  episodes_this_iter: 285
  episodes_total: 3446
  experiment_id: 1adf5dec9c0f4909a55616499c30386e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.8403011126951738
        entropy_coeff: 0.0
        kl: 0.00648438392884352
        model: {}
        policy_loss: -0.0060077706531790846
        total_loss: 14.848327723416416
        vf_explained_var: 0.9803730249404907
        vf_loss: 14.853686852888627
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.264705882352942
    gpu_util_percent0: 0.3729411764705882
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7941176470588234
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25048
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14942994500015588
    mean_env_wait_ms: 1.1851484214142352
    mean_inference_ms: 4.415181136637125
    mean_raw_obs_processing_ms: 0.38966977314045403
  time_since_restore: 539.7655262947083
  time_this_iter_s: 29.767953872680664
  time_total_s: 539.7655262947083
  timers:
    learn_throughput: 7094.207
    learn_time_ms: 22806.215
    sample_throughput: 23527.493
    sample_time_ms: 6876.721
    update_time_ms: 34.167
  timestamp: 1602250225
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 4fce1_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4fce1_00000 | RUNNING  | 172.17.0.4:25048 |     18 |          539.766 | 2912256 |  241.642 |              288.141 |              136.778 |            835.535 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4fce1_00000:
  custom_metrics:
    time_step_max: 4115
    time_step_mean: 3455.4459234608985
    time_step_min: 3155
  date: 2020-10-09_13-30-55
  done: false
  episode_len_mean: 834.7586681342873
  episode_reward_max: 288.1414141414143
  episode_reward_mean: 242.28485737951885
  episode_reward_min: 136.77777777777735
  episodes_this_iter: 188
  episodes_total: 3634
  experiment_id: 1adf5dec9c0f4909a55616499c30386e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.8228052095933394
        entropy_coeff: 0.0
        kl: 0.006695683664557609
        model: {}
        policy_loss: -0.016326417519435796
        total_loss: 10.381556510925293
        vf_explained_var: 0.9823469519615173
        vf_loss: 10.397213502363725
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.270588235294117
    gpu_util_percent0: 0.36764705882352944
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7970588235294116
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25048
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1493022124649681
    mean_env_wait_ms: 1.185750119687137
    mean_inference_ms: 4.409358725958768
    mean_raw_obs_processing_ms: 0.38925025678072395
  time_since_restore: 569.4602527618408
  time_this_iter_s: 29.69472646713257
  time_total_s: 569.4602527618408
  timers:
    learn_throughput: 7091.976
    learn_time_ms: 22813.387
    sample_throughput: 23527.683
    sample_time_ms: 6876.665
    update_time_ms: 33.887
  timestamp: 1602250255
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 4fce1_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4fce1_00000 | RUNNING  | 172.17.0.4:25048 |     19 |           569.46 | 3074048 |  242.285 |              288.141 |              136.778 |            834.759 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4fce1_00000:
  custom_metrics:
    time_step_max: 4115
    time_step_mean: 3451.871944739639
    time_step_min: 3155
  date: 2020-10-09_13-31-24
  done: false
  episode_len_mean: 834.4280063291139
  episode_reward_max: 288.1414141414143
  episode_reward_mean: 242.83235040276173
  episode_reward_min: 136.77777777777735
  episodes_this_iter: 158
  episodes_total: 3792
  experiment_id: 1adf5dec9c0f4909a55616499c30386e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.8237315307963978
        entropy_coeff: 0.0
        kl: 0.00553253386169672
        model: {}
        policy_loss: -0.006304159040816806
        total_loss: 11.208511265841397
        vf_explained_var: 0.9787155389785767
        vf_loss: 11.214262095364658
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.58529411764706
    gpu_util_percent0: 0.31411764705882356
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8029411764705876
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25048
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.149203970494364
    mean_env_wait_ms: 1.186218866755748
    mean_inference_ms: 4.404793944515224
    mean_raw_obs_processing_ms: 0.3889093709317176
  time_since_restore: 598.7703342437744
  time_this_iter_s: 29.310081481933594
  time_total_s: 598.7703342437744
  timers:
    learn_throughput: 7103.961
    learn_time_ms: 22774.899
    sample_throughput: 23692.682
    sample_time_ms: 6828.775
    update_time_ms: 32.674
  timestamp: 1602250284
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 4fce1_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4fce1_00000 | RUNNING  | 172.17.0.4:25048 |     20 |           598.77 | 3235840 |  242.832 |              288.141 |              136.778 |            834.428 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4fce1_00000:
  custom_metrics:
    time_step_max: 4115
    time_step_mean: 3448.5556971705328
    time_step_min: 3155
  date: 2020-10-09_13-31-54
  done: true
  episode_len_mean: 833.8547203239686
  episode_reward_max: 288.1414141414143
  episode_reward_mean: 243.31252540591942
  episode_reward_min: 136.77777777777735
  episodes_this_iter: 159
  episodes_total: 3951
  experiment_id: 1adf5dec9c0f4909a55616499c30386e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.8039534525437788
        entropy_coeff: 0.0
        kl: 0.006130440795624798
        model: {}
        policy_loss: -0.012929355365816842
        total_loss: 12.15315411307595
        vf_explained_var: 0.9776756167411804
        vf_loss: 12.165470383384012
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.737142857142857
    gpu_util_percent0: 0.344
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8628571428571434
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25048
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14911198103554535
    mean_env_wait_ms: 1.1866669415753546
    mean_inference_ms: 4.400452329901394
    mean_raw_obs_processing_ms: 0.3885787569898792
  time_since_restore: 628.5299572944641
  time_this_iter_s: 29.759623050689697
  time_total_s: 628.5299572944641
  timers:
    learn_throughput: 7103.583
    learn_time_ms: 22776.113
    sample_throughput: 23794.744
    sample_time_ms: 6799.485
    update_time_ms: 34.558
  timestamp: 1602250314
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: 4fce1_00000
  
== Status ==
Memory usage on this node: 28.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4fce1_00000 | TERMINATED |       |     21 |           628.53 | 3397632 |  243.313 |              288.141 |              136.778 |            833.855 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4fce1_00000 | TERMINATED |       |     21 |           628.53 | 3397632 |  243.313 |              288.141 |              136.778 |            833.855 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


