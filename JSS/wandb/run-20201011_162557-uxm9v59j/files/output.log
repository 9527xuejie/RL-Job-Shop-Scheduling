2020-10-11 16:26:01,173	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_742c8_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=61121)[0m 2020-10-11 16:26:04,041	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=61029)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61029)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61043)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61043)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61046)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61046)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61086)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61086)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61030)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61030)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61108)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61108)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61104)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61104)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61129)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61129)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61140)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61140)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61145)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61145)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61115)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61115)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61136)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61136)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61153)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61153)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61015)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61015)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61131)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61131)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61096)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61096)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61134)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61134)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61141)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61141)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61095)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61095)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61025)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61025)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61088)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61088)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61074)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61074)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61149)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61149)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61080)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61080)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61109)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61109)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61119)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61119)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61101)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61101)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61132)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61132)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61035)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61035)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61117)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61117)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61126)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61126)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61106)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61106)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61135)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61135)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61077)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61077)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61100)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61100)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61091)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61091)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61038)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61038)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61026)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61026)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61090)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61090)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61011)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61011)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61013)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61013)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61028)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61028)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61116)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61116)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61016)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61016)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61032)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61032)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61079)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61079)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61123)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61123)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61045)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61045)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61099)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61099)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61031)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61031)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61022)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61022)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61014)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61014)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61112)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61112)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61020)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61020)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61023)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61023)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61018)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61018)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61113)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61113)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61033)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61033)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61081)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61081)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61012)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61012)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61021)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61021)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61110)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61110)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61040)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61040)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61089)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61089)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61087)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61087)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61102)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61102)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61048)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61048)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61128)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61128)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61017)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61017)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61107)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61107)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61094)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61094)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61037)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61037)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61027)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61027)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61071)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61071)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61103)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61103)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61097)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61097)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61039)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61039)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61092)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61092)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=61093)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=61093)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_742c8_00000:
  custom_metrics:
    time_step_max: 4070
    time_step_mean: 3604.8101265822784
    time_step_min: 3251
  date: 2020-10-11_16-26-29
  done: false
  episode_len_mean: 891.0759493670886
  episode_reward_max: 273.4444444444444
  episode_reward_mean: 219.83684950773548
  episode_reward_min: 149.35353535353508
  episodes_this_iter: 79
  episodes_total: 79
  experiment_id: a3fbaca112274408b5a61ebe00de0bbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.1821814060211182
        entropy_coeff: 0.0001
        kl: 0.005178337823599577
        model: {}
        policy_loss: -0.008954001311212777
        total_loss: 598.7196044921875
        vf_explained_var: 0.23389902710914612
        vf_loss: 598.7276489257813
    num_steps_sampled: 80896
    num_steps_trained: 80896
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 37.26521739130435
    gpu_util_percent0: 0.34043478260869564
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.3260869565217397
    vram_util_percent0: 0.08697434654270111
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14098399728490604
    mean_env_wait_ms: 0.6503997359904437
    mean_inference_ms: 6.135537582402172
    mean_raw_obs_processing_ms: 0.3147314418499467
  time_since_restore: 19.96707534790039
  time_this_iter_s: 19.96707534790039
  time_total_s: 19.96707534790039
  timers:
    learn_throughput: 7329.195
    learn_time_ms: 11037.501
    sample_throughput: 9113.969
    sample_time_ms: 8876.046
    update_time_ms: 22.126
  timestamp: 1602433589
  timesteps_since_restore: 0
  timesteps_total: 80896
  training_iteration: 1
  trial_id: 742c8_00000
  
== Status ==
Memory usage on this node: 25.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |      1 |          19.9671 | 80896 |  219.837 |              273.444 |              149.354 |            891.076 |
+-------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_742c8_00000:
  custom_metrics:
    time_step_max: 4070
    time_step_mean: 3613.8734177215188
    time_step_min: 3251
  date: 2020-10-11_16-26-47
  done: false
  episode_len_mean: 890.2088607594936
  episode_reward_max: 273.4444444444444
  episode_reward_mean: 218.46362357754748
  episode_reward_min: 149.35353535353508
  episodes_this_iter: 79
  episodes_total: 158
  experiment_id: a3fbaca112274408b5a61ebe00de0bbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.1610076427459717
        entropy_coeff: 0.0001
        kl: 0.005721182934939862
        model: {}
        policy_loss: -0.010106014460325241
        total_loss: 247.57249755859374
        vf_explained_var: 0.652772068977356
        vf_loss: 247.58157653808593
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.68095238095238
    gpu_util_percent0: 0.24428571428571427
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.4666666666666672
    vram_util_percent0: 0.11634962282715647
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1367699090573646
    mean_env_wait_ms: 0.6473635573763007
    mean_inference_ms: 5.847798019074019
    mean_raw_obs_processing_ms: 0.3044004033168521
  time_since_restore: 37.92630052566528
  time_this_iter_s: 17.959225177764893
  time_total_s: 37.92630052566528
  timers:
    learn_throughput: 7374.544
    learn_time_ms: 10969.627
    sample_throughput: 10255.278
    sample_time_ms: 7888.231
    update_time_ms: 29.399
  timestamp: 1602433607
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 2
  trial_id: 742c8_00000
  
== Status ==
Memory usage on this node: 26.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |      2 |          37.9263 | 161792 |  218.464 |              273.444 |              149.354 |            890.209 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_742c8_00000:
  custom_metrics:
    time_step_max: 4092
    time_step_mean: 3614.9113924050635
    time_step_min: 3251
  date: 2020-10-11_16-27-04
  done: false
  episode_len_mean: 888.590717299578
  episode_reward_max: 273.4444444444444
  episode_reward_mean: 218.30635468610134
  episode_reward_min: 146.02020202020225
  episodes_this_iter: 79
  episodes_total: 237
  experiment_id: a3fbaca112274408b5a61ebe00de0bbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.159032130241394
        entropy_coeff: 0.0001
        kl: 0.0057226565666496755
        model: {}
        policy_loss: -0.01224328400567174
        total_loss: 104.11964721679688
        vf_explained_var: 0.8229959607124329
        vf_loss: 104.13086395263672
    num_steps_sampled: 242688
    num_steps_trained: 242688
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.39
    gpu_util_percent0: 0.35550000000000004
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5
    vram_util_percent0: 0.11634962282715647
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.13413430262435888
    mean_env_wait_ms: 0.645414029757357
    mean_inference_ms: 5.638892347495418
    mean_raw_obs_processing_ms: 0.29784452198874656
  time_since_restore: 55.47215390205383
  time_this_iter_s: 17.54585337638855
  time_total_s: 55.47215390205383
  timers:
    learn_throughput: 7380.249
    learn_time_ms: 10961.147
    sample_throughput: 10878.676
    sample_time_ms: 7436.199
    update_time_ms: 31.95
  timestamp: 1602433624
  timesteps_since_restore: 0
  timesteps_total: 242688
  training_iteration: 3
  trial_id: 742c8_00000
  
== Status ==
Memory usage on this node: 26.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |      3 |          55.4722 | 242688 |  218.306 |              273.444 |               146.02 |            888.591 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_742c8_00000:
  custom_metrics:
    time_step_max: 4092
    time_step_mean: 3604.6075949367087
    time_step_min: 3251
  date: 2020-10-11_16-27-22
  done: false
  episode_len_mean: 886.3354430379746
  episode_reward_max: 273.4444444444444
  episode_reward_mean: 219.86753612070044
  episode_reward_min: 146.02020202020225
  episodes_this_iter: 79
  episodes_total: 316
  experiment_id: a3fbaca112274408b5a61ebe00de0bbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.142055583000183
        entropy_coeff: 0.0001
        kl: 0.006965293735265732
        model: {}
        policy_loss: -0.013879792392253875
        total_loss: 68.49144897460937
        vf_explained_var: 0.8709942698478699
        vf_loss: 68.504052734375
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.025
    gpu_util_percent0: 0.3430000000000001
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5
    vram_util_percent0: 0.11634962282715647
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.13222634804207714
    mean_env_wait_ms: 0.6442073777421974
    mean_inference_ms: 5.483053264492972
    mean_raw_obs_processing_ms: 0.29300762395835384
  time_since_restore: 72.73297452926636
  time_this_iter_s: 17.260820627212524
  time_total_s: 72.73297452926636
  timers:
    learn_throughput: 7378.992
    learn_time_ms: 10963.015
    sample_throughput: 11342.711
    sample_time_ms: 7131.981
    update_time_ms: 33.251
  timestamp: 1602433642
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 4
  trial_id: 742c8_00000
  
== Status ==
Memory usage on this node: 26.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |      4 |           72.733 | 323584 |  219.868 |              273.444 |               146.02 |            886.335 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_742c8_00000:
  custom_metrics:
    time_step_max: 4092
    time_step_mean: 3599.4151898734176
    time_step_min: 3251
  date: 2020-10-11_16-27-39
  done: false
  episode_len_mean: 884.0708860759494
  episode_reward_max: 273.4444444444444
  episode_reward_mean: 220.6542641605931
  episode_reward_min: 146.02020202020225
  episodes_this_iter: 79
  episodes_total: 395
  experiment_id: a3fbaca112274408b5a61ebe00de0bbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.1255623817443847
        entropy_coeff: 0.0001
        kl: 0.006865937076508999
        model: {}
        policy_loss: -0.0142045047134161
        total_loss: 57.66709518432617
        vf_explained_var: 0.8982939720153809
        vf_loss: 57.68003768920899
    num_steps_sampled: 404480
    num_steps_trained: 404480
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.31052631578948
    gpu_util_percent0: 0.3789473684210526
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5
    vram_util_percent0: 0.11634962282715645
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.13073350551274238
    mean_env_wait_ms: 0.6435351135109532
    mean_inference_ms: 5.3628082783487665
    mean_raw_obs_processing_ms: 0.2890854961303385
  time_since_restore: 89.73851156234741
  time_this_iter_s: 17.005537033081055
  time_total_s: 89.73851156234741
  timers:
    learn_throughput: 7381.18
    learn_time_ms: 10959.765
    sample_throughput: 11718.685
    sample_time_ms: 6903.163
    update_time_ms: 33.944
  timestamp: 1602433659
  timesteps_since_restore: 0
  timesteps_total: 404480
  training_iteration: 5
  trial_id: 742c8_00000
  
== Status ==
Memory usage on this node: 26.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |      5 |          89.7385 | 404480 |  220.654 |              273.444 |               146.02 |            884.071 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_742c8_00000:
  custom_metrics:
    time_step_max: 4092
    time_step_mean: 3588.4762808349146
    time_step_min: 3251
  date: 2020-10-11_16-27-56
  done: false
  episode_len_mean: 876.9468690702088
  episode_reward_max: 273.4444444444444
  episode_reward_mean: 222.31167462097235
  episode_reward_min: 146.02020202020225
  episodes_this_iter: 132
  episodes_total: 527
  experiment_id: a3fbaca112274408b5a61ebe00de0bbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.1013608694076538
        entropy_coeff: 0.0001
        kl: 0.006304158177226782
        model: {}
        policy_loss: -0.016743747983127832
        total_loss: 61.22104263305664
        vf_explained_var: 0.9264847636222839
        vf_loss: 61.23663177490234
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.909999999999997
    gpu_util_percent0: 0.29600000000000004
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.4799999999999995
    vram_util_percent0: 0.11634962282715647
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12892989278774483
    mean_env_wait_ms: 0.6439252620955168
    mean_inference_ms: 5.217598169319564
    mean_raw_obs_processing_ms: 0.28441227899644844
  time_since_restore: 107.00913977622986
  time_this_iter_s: 17.270628213882446
  time_total_s: 107.00913977622986
  timers:
    learn_throughput: 7369.101
    learn_time_ms: 10977.729
    sample_throughput: 11940.558
    sample_time_ms: 6774.893
    update_time_ms: 34.153
  timestamp: 1602433676
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 6
  trial_id: 742c8_00000
  
== Status ==
Memory usage on this node: 26.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |      6 |          107.009 | 485376 |  222.312 |              273.444 |               146.02 |            876.947 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_742c8_00000:
  custom_metrics:
    time_step_max: 4092
    time_step_mean: 3579.4794303797466
    time_step_min: 3251
  date: 2020-10-11_16-28-13
  done: false
  episode_len_mean: 872.9651898734177
  episode_reward_max: 273.4444444444444
  episode_reward_mean: 223.67483378084626
  episode_reward_min: 146.02020202020225
  episodes_this_iter: 105
  episodes_total: 632
  experiment_id: a3fbaca112274408b5a61ebe00de0bbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.1148772478103637
        entropy_coeff: 0.0001
        kl: 0.00640232590958476
        model: {}
        policy_loss: -0.01414772029966116
        total_loss: 40.958674621582034
        vf_explained_var: 0.9319775700569153
        vf_loss: 40.97165451049805
    num_steps_sampled: 566272
    num_steps_trained: 566272
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.98
    gpu_util_percent0: 0.263
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.4799999999999995
    vram_util_percent0: 0.11634962282715647
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12790341844197173
    mean_env_wait_ms: 0.6437003581697455
    mean_inference_ms: 5.136787395294866
    mean_raw_obs_processing_ms: 0.28171729219255803
  time_since_restore: 124.0984423160553
  time_this_iter_s: 17.08930253982544
  time_total_s: 124.0984423160553
  timers:
    learn_throughput: 7377.592
    learn_time_ms: 10965.095
    sample_throughput: 12106.989
    sample_time_ms: 6681.761
    update_time_ms: 34.781
  timestamp: 1602433693
  timesteps_since_restore: 0
  timesteps_total: 566272
  training_iteration: 7
  trial_id: 742c8_00000
  
== Status ==
Memory usage on this node: 26.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |      7 |          124.098 | 566272 |  223.675 |              273.444 |               146.02 |            872.965 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_742c8_00000:
  custom_metrics:
    time_step_max: 4092
    time_step_mean: 3571.4486638537273
    time_step_min: 3251
  date: 2020-10-11_16-28-30
  done: false
  episode_len_mean: 869.395218002813
  episode_reward_max: 273.4444444444444
  episode_reward_mean: 224.891616587819
  episode_reward_min: 146.02020202020225
  episodes_this_iter: 79
  episodes_total: 711
  experiment_id: a3fbaca112274408b5a61ebe00de0bbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.0891266345977784
        entropy_coeff: 0.0001
        kl: 0.006864890549331903
        model: {}
        policy_loss: -0.012392168352380394
        total_loss: 29.909460067749023
        vf_explained_var: 0.9454657435417175
        vf_loss: 29.92058868408203
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.326315789473693
    gpu_util_percent0: 0.2757894736842105
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5
    vram_util_percent0: 0.11634962282715645
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12726324582919984
    mean_env_wait_ms: 0.643819807986483
    mean_inference_ms: 5.085353953921927
    mean_raw_obs_processing_ms: 0.28001263883160427
  time_since_restore: 141.00454926490784
  time_this_iter_s: 16.90610694885254
  time_total_s: 141.00454926490784
  timers:
    learn_throughput: 7379.784
    learn_time_ms: 10961.838
    sample_throughput: 12286.631
    sample_time_ms: 6584.067
    update_time_ms: 34.566
  timestamp: 1602433710
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 8
  trial_id: 742c8_00000
  
== Status ==
Memory usage on this node: 26.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |      8 |          141.005 | 647168 |  224.892 |              273.444 |               146.02 |            869.395 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_742c8_00000:
  custom_metrics:
    time_step_max: 4092
    time_step_mean: 3564.345569620253
    time_step_min: 3251
  date: 2020-10-11_16-28-47
  done: false
  episode_len_mean: 866.1582278481013
  episode_reward_max: 273.4444444444444
  episode_reward_mean: 225.96784298683022
  episode_reward_min: 146.02020202020225
  episodes_this_iter: 79
  episodes_total: 790
  experiment_id: a3fbaca112274408b5a61ebe00de0bbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.0771050453186035
        entropy_coeff: 0.0001
        kl: 0.006526902969926596
        model: {}
        policy_loss: -0.0148372957482934
        total_loss: 26.008992385864257
        vf_explained_var: 0.9503160715103149
        vf_loss: 26.0226318359375
    num_steps_sampled: 728064
    num_steps_trained: 728064
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.05263157894737
    gpu_util_percent0: 0.3431578947368421
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5
    vram_util_percent0: 0.11634962282715645
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12670080580046472
    mean_env_wait_ms: 0.6439832765656371
    mean_inference_ms: 5.039983960032047
    mean_raw_obs_processing_ms: 0.2784847809173593
  time_since_restore: 157.93700242042542
  time_this_iter_s: 16.932453155517578
  time_total_s: 157.93700242042542
  timers:
    learn_throughput: 7378.034
    learn_time_ms: 10964.438
    sample_throughput: 12434.892
    sample_time_ms: 6505.565
    update_time_ms: 34.362
  timestamp: 1602433727
  timesteps_since_restore: 0
  timesteps_total: 728064
  training_iteration: 9
  trial_id: 742c8_00000
  
== Status ==
Memory usage on this node: 26.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |      9 |          157.937 | 728064 |  225.968 |              273.444 |               146.02 |            866.158 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_742c8_00000:
  custom_metrics:
    time_step_max: 4092
    time_step_mean: 3557.8855835240274
    time_step_min: 3251
  date: 2020-10-11_16-29-04
  done: false
  episode_len_mean: 862.9096109839817
  episode_reward_max: 273.4444444444444
  episode_reward_mean: 226.94662875898564
  episode_reward_min: 146.02020202020225
  episodes_this_iter: 84
  episodes_total: 874
  experiment_id: a3fbaca112274408b5a61ebe00de0bbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.0427801609039307
        entropy_coeff: 0.0001
        kl: 0.006021166313439607
        model: {}
        policy_loss: -0.010975334793329239
        total_loss: 26.823484039306642
        vf_explained_var: 0.9570068120956421
        vf_loss: 26.833358764648438
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.763157894736842
    gpu_util_percent0: 0.27473684210526317
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.478947368421052
    vram_util_percent0: 0.11634962282715645
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1261609020467685
    mean_env_wait_ms: 0.644256949020595
    mean_inference_ms: 4.997260628493306
    mean_raw_obs_processing_ms: 0.27703591018381557
  time_since_restore: 174.87086534500122
  time_this_iter_s: 16.933862924575806
  time_total_s: 174.87086534500122
  timers:
    learn_throughput: 7374.023
    learn_time_ms: 10970.402
    sample_throughput: 12560.425
    sample_time_ms: 6440.547
    update_time_ms: 32.9
  timestamp: 1602433744
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 10
  trial_id: 742c8_00000
  
== Status ==
Memory usage on this node: 26.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |     10 |          174.871 | 808960 |  226.947 |              273.444 |               146.02 |             862.91 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_742c8_00000:
  custom_metrics:
    time_step_max: 4092
    time_step_mean: 3546.17738791423
    time_step_min: 3229
  date: 2020-10-11_16-29-21
  done: false
  episode_len_mean: 856.958089668616
  episode_reward_max: 276.77777777777794
  episode_reward_mean: 228.72059779077313
  episode_reward_min: 146.02020202020225
  episodes_this_iter: 152
  episodes_total: 1026
  experiment_id: a3fbaca112274408b5a61ebe00de0bbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.047643208503723
        entropy_coeff: 0.0001
        kl: 0.0061458229087293145
        model: {}
        policy_loss: -0.012535271141678095
        total_loss: 28.427783584594728
        vf_explained_var: 0.9625579118728638
        vf_loss: 28.439194107055663
    num_steps_sampled: 889856
    num_steps_trained: 889856
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.94000000000001
    gpu_util_percent0: 0.28300000000000003
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.475
    vram_util_percent0: 0.11634962282715647
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12537372726315876
    mean_env_wait_ms: 0.6449531962595608
    mean_inference_ms: 4.93422262579392
    mean_raw_obs_processing_ms: 0.2749005239350073
  time_since_restore: 191.87603378295898
  time_this_iter_s: 17.005168437957764
  time_total_s: 191.87603378295898
  timers:
    learn_throughput: 7376.233
    learn_time_ms: 10967.116
    sample_throughput: 13164.584
    sample_time_ms: 6144.972
    update_time_ms: 34.87
  timestamp: 1602433761
  timesteps_since_restore: 0
  timesteps_total: 889856
  training_iteration: 11
  trial_id: 742c8_00000
  
== Status ==
Memory usage on this node: 26.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |     11 |          191.876 | 889856 |  228.721 |              276.778 |               146.02 |            856.958 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_742c8_00000:
  custom_metrics:
    time_step_max: 4092
    time_step_mean: 3537.3589511754067
    time_step_min: 3229
  date: 2020-10-11_16-29-38
  done: false
  episode_len_mean: 853.8372513562387
  episode_reward_max: 276.77777777777794
  episode_reward_mean: 230.0567245693827
  episode_reward_min: 146.02020202020225
  episodes_this_iter: 80
  episodes_total: 1106
  experiment_id: a3fbaca112274408b5a61ebe00de0bbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.029042935371399
        entropy_coeff: 0.0001
        kl: 0.006281163450330496
        model: {}
        policy_loss: -0.015307414811104536
        total_loss: 15.060502815246583
        vf_explained_var: 0.9696897268295288
        vf_loss: 15.074656867980957
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.42105263157895
    gpu_util_percent0: 0.4105263157894737
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5
    vram_util_percent0: 0.11634962282715645
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12502306966866958
    mean_env_wait_ms: 0.6452948919573521
    mean_inference_ms: 4.906176534092823
    mean_raw_obs_processing_ms: 0.2739435716455957
  time_since_restore: 208.82465434074402
  time_this_iter_s: 16.948620557785034
  time_total_s: 208.82465434074402
  timers:
    learn_throughput: 7369.215
    learn_time_ms: 10977.56
    sample_throughput: 13389.541
    sample_time_ms: 6041.731
    update_time_ms: 34.692
  timestamp: 1602433778
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 12
  trial_id: 742c8_00000
  
== Status ==
Memory usage on this node: 26.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |     12 |          208.825 | 970752 |  230.057 |              276.778 |               146.02 |            853.837 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_742c8_00000:
  custom_metrics:
    time_step_max: 4092
    time_step_mean: 3530.604219409283
    time_step_min: 3225
  date: 2020-10-11_16-29-55
  done: false
  episode_len_mean: 851.1873417721519
  episode_reward_max: 277.38383838383817
  episode_reward_mean: 231.0801687763712
  episode_reward_min: 146.02020202020225
  episodes_this_iter: 79
  episodes_total: 1185
  experiment_id: a3fbaca112274408b5a61ebe00de0bbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.020499587059021
        entropy_coeff: 0.0001
        kl: 0.0058583361096680164
        model: {}
        policy_loss: -0.014010852668434381
        total_loss: 17.26035079956055
        vf_explained_var: 0.9643712043762207
        vf_loss: 17.273291778564452
    num_steps_sampled: 1051648
    num_steps_trained: 1051648
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.90526315789474
    gpu_util_percent0: 0.27631578947368424
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5
    vram_util_percent0: 0.11634962282715645
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1247077601096726
    mean_env_wait_ms: 0.6456171996062807
    mean_inference_ms: 4.88091950153211
    mean_raw_obs_processing_ms: 0.27306084750810783
  time_since_restore: 225.67816257476807
  time_this_iter_s: 16.853508234024048
  time_total_s: 225.67816257476807
  timers:
    learn_throughput: 7370.749
    learn_time_ms: 10975.276
    sample_throughput: 13537.832
    sample_time_ms: 5975.551
    update_time_ms: 33.247
  timestamp: 1602433795
  timesteps_since_restore: 0
  timesteps_total: 1051648
  training_iteration: 13
  trial_id: 742c8_00000
  
== Status ==
Memory usage on this node: 26.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |     13 |          225.678 | 1051648 |   231.08 |              277.384 |               146.02 |            851.187 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_742c8_00000:
  custom_metrics:
    time_step_max: 4092
    time_step_mean: 3522.7099296325255
    time_step_min: 3184
  date: 2020-10-11_16-30-12
  done: false
  episode_len_mean: 848.0969507427678
  episode_reward_max: 283.59595959595947
  episode_reward_mean: 232.27627328800114
  episode_reward_min: 146.02020202020225
  episodes_this_iter: 94
  episodes_total: 1279
  experiment_id: a3fbaca112274408b5a61ebe00de0bbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 0.988058340549469
        entropy_coeff: 0.0001
        kl: 0.006182871200144291
        model: {}
        policy_loss: -0.014513058867305518
        total_loss: 22.752033996582032
        vf_explained_var: 0.9629007577896118
        vf_loss: 22.76541061401367
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.43500000000001
    gpu_util_percent0: 0.2615
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5
    vram_util_percent0: 0.11634962282715647
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12436254057564351
    mean_env_wait_ms: 0.6461020970423146
    mean_inference_ms: 4.853592419273776
    mean_raw_obs_processing_ms: 0.27210988741028075
  time_since_restore: 242.62031650543213
  time_this_iter_s: 16.942153930664062
  time_total_s: 242.62031650543213
  timers:
    learn_throughput: 7375.065
    learn_time_ms: 10968.852
    sample_throughput: 13597.7
    sample_time_ms: 5949.242
    update_time_ms: 33.29
  timestamp: 1602433812
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 14
  trial_id: 742c8_00000
  
== Status ==
Memory usage on this node: 26.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |     14 |           242.62 | 1132544 |  232.276 |              283.596 |               146.02 |            848.097 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_742c8_00000:
  custom_metrics:
    time_step_max: 4092
    time_step_mean: 3513.834739803094
    time_step_min: 3184
  date: 2020-10-11_16-30-29
  done: false
  episode_len_mean: 843.6962025316456
  episode_reward_max: 283.59595959595947
  episode_reward_mean: 233.62099901973312
  episode_reward_min: 146.02020202020225
  episodes_this_iter: 143
  episodes_total: 1422
  experiment_id: a3fbaca112274408b5a61ebe00de0bbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 0.9878270983695984
        entropy_coeff: 0.0001
        kl: 0.005273265577852726
        model: {}
        policy_loss: -0.01443924605846405
        total_loss: 19.540371704101563
        vf_explained_var: 0.9709212183952332
        vf_loss: 19.55385627746582
    num_steps_sampled: 1213440
    num_steps_trained: 1213440
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.763157894736842
    gpu_util_percent0: 0.33473684210526317
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.478947368421052
    vram_util_percent0: 0.11634962282715645
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12391073808355933
    mean_env_wait_ms: 0.6467882051144439
    mean_inference_ms: 4.81757522324978
    mean_raw_obs_processing_ms: 0.2708519663997358
  time_since_restore: 259.55595803260803
  time_this_iter_s: 16.935641527175903
  time_total_s: 259.55595803260803
  timers:
    learn_throughput: 7377.326
    learn_time_ms: 10965.491
    sample_throughput: 13609.618
    sample_time_ms: 5944.032
    update_time_ms: 33.054
  timestamp: 1602433829
  timesteps_since_restore: 0
  timesteps_total: 1213440
  training_iteration: 15
  trial_id: 742c8_00000
  
== Status ==
Memory usage on this node: 26.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |     15 |          259.556 | 1213440 |  233.621 |              283.596 |               146.02 |            843.696 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_742c8_00000:
  custom_metrics:
    time_step_max: 4092
    time_step_mean: 3507.775483011326
    time_step_min: 3184
  date: 2020-10-11_16-30-46
  done: false
  episode_len_mean: 841.0646235842771
  episode_reward_max: 283.59595959595947
  episode_reward_mean: 234.53906823060714
  episode_reward_min: 146.02020202020225
  episodes_this_iter: 79
  episodes_total: 1501
  experiment_id: a3fbaca112274408b5a61ebe00de0bbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 0.97277330160141
        entropy_coeff: 0.0001
        kl: 0.005540623422712087
        model: {}
        policy_loss: -0.01531378725776449
        total_loss: 12.622322082519531
        vf_explained_var: 0.9739503860473633
        vf_loss: 12.636624717712403
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.68
    gpu_util_percent0: 0.3145
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5
    vram_util_percent0: 0.11634962282715647
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12368770892289047
    mean_env_wait_ms: 0.6471635713741419
    mean_inference_ms: 4.799930085863596
    mean_raw_obs_processing_ms: 0.2702354887858795
  time_since_restore: 276.57739901542664
  time_this_iter_s: 17.021440982818604
  time_total_s: 276.57739901542664
  timers:
    learn_throughput: 7379.887
    learn_time_ms: 10961.685
    sample_throughput: 13657.722
    sample_time_ms: 5923.096
    update_time_ms: 32.54
  timestamp: 1602433846
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 16
  trial_id: 742c8_00000
  
== Status ==
Memory usage on this node: 26.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |     16 |          276.577 | 1294336 |  234.539 |              283.596 |               146.02 |            841.065 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_742c8_00000:
  custom_metrics:
    time_step_max: 4092
    time_step_mean: 3502.0474383301707
    time_step_min: 3167
  date: 2020-10-11_16-31-04
  done: false
  episode_len_mean: 838.7457305502846
  episode_reward_max: 286.1717171717169
  episode_reward_mean: 235.40695378835792
  episode_reward_min: 146.02020202020225
  episodes_this_iter: 80
  episodes_total: 1581
  experiment_id: a3fbaca112274408b5a61ebe00de0bbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 0.9531836867332458
        entropy_coeff: 0.0001
        kl: 0.005672357883304358
        model: {}
        policy_loss: -0.013997910264879464
        total_loss: 14.515528297424316
        vf_explained_var: 0.9702242016792297
        vf_loss: 14.528486824035644
    num_steps_sampled: 1375232
    num_steps_trained: 1375232
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.18421052631579
    gpu_util_percent0: 0.27999999999999997
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5
    vram_util_percent0: 0.11634962282715645
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12347598325254748
    mean_env_wait_ms: 0.6475391807235957
    mean_inference_ms: 4.783241483975615
    mean_raw_obs_processing_ms: 0.2696401929180935
  time_since_restore: 293.35855436325073
  time_this_iter_s: 16.781155347824097
  time_total_s: 293.35855436325073
  timers:
    learn_throughput: 7383.637
    learn_time_ms: 10956.118
    sample_throughput: 13717.343
    sample_time_ms: 5897.352
    update_time_ms: 32.495
  timestamp: 1602433864
  timesteps_since_restore: 0
  timesteps_total: 1375232
  training_iteration: 17
  trial_id: 742c8_00000
  
== Status ==
Memory usage on this node: 26.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |     17 |          293.359 | 1375232 |  235.407 |              286.172 |               146.02 |            838.746 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_742c8_00000:
  custom_metrics:
    time_step_max: 4092
    time_step_mean: 3492.5957200694043
    time_step_min: 3149
  date: 2020-10-11_16-31-20
  done: false
  episode_len_mean: 834.5801041064199
  episode_reward_max: 288.89898989899024
  episode_reward_mean: 236.83903231271648
  episode_reward_min: 146.02020202020225
  episodes_this_iter: 148
  episodes_total: 1729
  experiment_id: a3fbaca112274408b5a61ebe00de0bbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 0.926102340221405
        entropy_coeff: 0.0001
        kl: 0.005256259627640247
        model: {}
        policy_loss: -0.011589129082858562
        total_loss: 17.027903366088868
        vf_explained_var: 0.976334273815155
        vf_loss: 17.03853416442871
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.078947368421055
    gpu_util_percent0: 0.30736842105263157
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5
    vram_util_percent0: 0.11634962282715645
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12312441460932014
    mean_env_wait_ms: 0.648343690032881
    mean_inference_ms: 4.755624730657635
    mean_raw_obs_processing_ms: 0.2686697171666438
  time_since_restore: 310.24891924858093
  time_this_iter_s: 16.8903648853302
  time_total_s: 310.24891924858093
  timers:
    learn_throughput: 7382.71
    learn_time_ms: 10957.494
    sample_throughput: 13726.563
    sample_time_ms: 5893.391
    update_time_ms: 32.684
  timestamp: 1602433880
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 18
  trial_id: 742c8_00000
  
== Status ==
Memory usage on this node: 26.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |     18 |          310.249 | 1456128 |  236.839 |              288.899 |               146.02 |             834.58 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_742c8_00000:
  custom_metrics:
    time_step_max: 4092
    time_step_mean: 3488.034672537149
    time_step_min: 3149
  date: 2020-10-11_16-31-38
  done: false
  episode_len_mean: 832.3307649972483
  episode_reward_max: 288.89898989899024
  episode_reward_mean: 237.53010012063393
  episode_reward_min: 146.02020202020225
  episodes_this_iter: 88
  episodes_total: 1817
  experiment_id: a3fbaca112274408b5a61ebe00de0bbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 0.9310240507125854
        entropy_coeff: 0.0001
        kl: 0.005109604261815548
        model: {}
        policy_loss: -0.01098379292525351
        total_loss: 14.388118743896484
        vf_explained_var: 0.9739601016044617
        vf_loss: 14.39817409515381
    num_steps_sampled: 1537024
    num_steps_trained: 1537024
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.665000000000003
    gpu_util_percent0: 0.3235
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5
    vram_util_percent0: 0.11634962282715647
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12294127448875178
    mean_env_wait_ms: 0.6486993428048557
    mean_inference_ms: 4.740853319106202
    mean_raw_obs_processing_ms: 0.26813263802760673
  time_since_restore: 327.2235713005066
  time_this_iter_s: 16.97465205192566
  time_total_s: 327.2235713005066
  timers:
    learn_throughput: 7381.381
    learn_time_ms: 10959.466
    sample_throughput: 13738.498
    sample_time_ms: 5888.271
    update_time_ms: 39.048
  timestamp: 1602433898
  timesteps_since_restore: 0
  timesteps_total: 1537024
  training_iteration: 19
  trial_id: 742c8_00000
  
== Status ==
Memory usage on this node: 26.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |     19 |          327.224 | 1537024 |   237.53 |              288.899 |               146.02 |            832.331 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_742c8_00000:
  custom_metrics:
    time_step_max: 4092
    time_step_mean: 3484.7273206751056
    time_step_min: 3149
  date: 2020-10-11_16-31-55
  done: false
  episode_len_mean: 830.3449367088608
  episode_reward_max: 288.89898989899024
  episode_reward_mean: 238.03121403912542
  episode_reward_min: 146.02020202020225
  episodes_this_iter: 79
  episodes_total: 1896
  experiment_id: a3fbaca112274408b5a61ebe00de0bbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 0.9225889205932617
        entropy_coeff: 0.0001
        kl: 0.005407916381955147
        model: {}
        policy_loss: -0.014131060149520636
        total_loss: 14.700571441650391
        vf_explained_var: 0.9705582857131958
        vf_loss: 14.713712692260742
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.373684210526314
    gpu_util_percent0: 0.2631578947368421
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5
    vram_util_percent0: 0.11634962282715645
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12278455012592983
    mean_env_wait_ms: 0.6490578024317554
    mean_inference_ms: 4.72843451159651
    mean_raw_obs_processing_ms: 0.26768106747298975
  time_since_restore: 344.2278187274933
  time_this_iter_s: 17.004247426986694
  time_total_s: 344.2278187274933
  timers:
    learn_throughput: 7378.816
    learn_time_ms: 10963.277
    sample_throughput: 13736.616
    sample_time_ms: 5889.078
    update_time_ms: 40.776
  timestamp: 1602433915
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 20
  trial_id: 742c8_00000
  
== Status ==
Memory usage on this node: 26.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |     20 |          344.228 | 1617920 |  238.031 |              288.899 |               146.02 |            830.345 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_742c8_00000:
  custom_metrics:
    time_step_max: 4092
    time_step_mean: 3479.526524541398
    time_step_min: 3149
  date: 2020-10-11_16-32-12
  done: false
  episode_len_mean: 827.4918195339613
  episode_reward_max: 288.89898989899024
  episode_reward_mean: 238.81921345332347
  episode_reward_min: 146.02020202020225
  episodes_this_iter: 121
  episodes_total: 2017
  experiment_id: a3fbaca112274408b5a61ebe00de0bbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 0.8949668288230896
        entropy_coeff: 0.0001
        kl: 0.00522464383393526
        model: {}
        policy_loss: -0.015539329266175628
        total_loss: 16.214202308654784
        vf_explained_var: 0.9754984974861145
        vf_loss: 16.228786277770997
    num_steps_sampled: 1698816
    num_steps_trained: 1698816
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.69473684210527
    gpu_util_percent0: 0.33999999999999997
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5
    vram_util_percent0: 0.11634962282715645
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1225520215946057
    mean_env_wait_ms: 0.6497088133943331
    mean_inference_ms: 4.710737726018366
    mean_raw_obs_processing_ms: 0.26705498019710205
  time_since_restore: 361.12535190582275
  time_this_iter_s: 16.897533178329468
  time_total_s: 361.12535190582275
  timers:
    learn_throughput: 7385.687
    learn_time_ms: 10953.077
    sample_throughput: 13738.814
    sample_time_ms: 5888.136
    update_time_ms: 40.739
  timestamp: 1602433932
  timesteps_since_restore: 0
  timesteps_total: 1698816
  training_iteration: 21
  trial_id: 742c8_00000
  
== Status ==
Memory usage on this node: 26.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |     21 |          361.125 | 1698816 |  238.819 |              288.899 |               146.02 |            827.492 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_742c8_00000:
  custom_metrics:
    time_step_max: 4092
    time_step_mean: 3474.1439287388653
    time_step_min: 3149
  date: 2020-10-11_16-32-29
  done: false
  episode_len_mean: 825.413033286451
  episode_reward_max: 288.89898989899024
  episode_reward_mean: 239.63475827188907
  episode_reward_min: 146.02020202020225
  episodes_this_iter: 116
  episodes_total: 2133
  experiment_id: a3fbaca112274408b5a61ebe00de0bbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 0.8959186911582947
        entropy_coeff: 0.0001
        kl: 0.00528133912011981
        model: {}
        policy_loss: -0.011150027438998223
        total_loss: 11.039695358276367
        vf_explained_var: 0.9806930422782898
        vf_loss: 11.04987850189209
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.763157894736842
    gpu_util_percent0: 0.3678947368421053
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.4842105263157896
    vram_util_percent0: 0.11634962282715645
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12236587347955238
    mean_env_wait_ms: 0.6501740845442628
    mean_inference_ms: 4.69544019947536
    mean_raw_obs_processing_ms: 0.26648938245529985
  time_since_restore: 378.08043003082275
  time_this_iter_s: 16.955078125
  time_total_s: 378.08043003082275
  timers:
    learn_throughput: 7380.602
    learn_time_ms: 10960.624
    sample_throughput: 13752.486
    sample_time_ms: 5882.282
    update_time_ms: 39.439
  timestamp: 1602433949
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 22
  trial_id: 742c8_00000
  
== Status ==
Memory usage on this node: 26.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |     22 |           378.08 | 1779712 |  239.635 |              288.899 |               146.02 |            825.413 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_742c8_00000:
  custom_metrics:
    time_step_max: 4092
    time_step_mean: 3471.4570524412297
    time_step_min: 3149
  date: 2020-10-11_16-32-46
  done: false
  episode_len_mean: 824.0126582278481
  episode_reward_max: 288.89898989899024
  episode_reward_mean: 240.0418607412278
  episode_reward_min: 146.02020202020225
  episodes_this_iter: 79
  episodes_total: 2212
  experiment_id: a3fbaca112274408b5a61ebe00de0bbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 0.8983033895492554
        entropy_coeff: 0.0001
        kl: 0.005707137286663055
        model: {}
        policy_loss: -0.011461784783750772
        total_loss: 10.742603302001953
        vf_explained_var: 0.9777244329452515
        vf_loss: 10.753013420104981
    num_steps_sampled: 1860608
    num_steps_trained: 1860608
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.334999999999997
    gpu_util_percent0: 0.2815
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5
    vram_util_percent0: 0.11634962282715647
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12224187395329024
    mean_env_wait_ms: 0.6505199073617374
    mean_inference_ms: 4.685692670587312
    mean_raw_obs_processing_ms: 0.26613615202034235
  time_since_restore: 394.8987329006195
  time_this_iter_s: 16.818302869796753
  time_total_s: 394.8987329006195
  timers:
    learn_throughput: 7383.038
    learn_time_ms: 10957.008
    sample_throughput: 13757.499
    sample_time_ms: 5880.138
    update_time_ms: 41.136
  timestamp: 1602433966
  timesteps_since_restore: 0
  timesteps_total: 1860608
  training_iteration: 23
  trial_id: 742c8_00000
  
== Status ==
Memory usage on this node: 26.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |     23 |          394.899 | 1860608 |  240.042 |              288.899 |               146.02 |            824.013 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_742c8_00000:
  custom_metrics:
    time_step_max: 4092
    time_step_mean: 3468.180911062907
    time_step_min: 3149
  date: 2020-10-11_16-33-03
  done: false
  episode_len_mean: 822.7310195227766
  episode_reward_max: 288.89898989899024
  episode_reward_mean: 240.53824579854947
  episode_reward_min: 146.02020202020225
  episodes_this_iter: 93
  episodes_total: 2305
  experiment_id: a3fbaca112274408b5a61ebe00de0bbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 0.8726944923400879
        entropy_coeff: 0.0001
        kl: 0.005827944166958332
        model: {}
        policy_loss: -0.012724796333350242
        total_loss: 12.167643547058105
        vf_explained_var: 0.9788719415664673
        vf_loss: 12.179289817810059
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 24
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.563157894736854
    gpu_util_percent0: 0.38999999999999996
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5
    vram_util_percent0: 0.11634962282715645
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1221003815882753
    mean_env_wait_ms: 0.6509422861487458
    mean_inference_ms: 4.674851482809558
    mean_raw_obs_processing_ms: 0.2657481067948324
  time_since_restore: 411.8134672641754
  time_this_iter_s: 16.914734363555908
  time_total_s: 411.8134672641754
  timers:
    learn_throughput: 7378.802
    learn_time_ms: 10963.297
    sample_throughput: 13780.188
    sample_time_ms: 5870.457
    update_time_ms: 40.887
  timestamp: 1602433983
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 24
  trial_id: 742c8_00000
  
== Status ==
Memory usage on this node: 26.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |     24 |          411.813 | 1941504 |  240.538 |              288.899 |               146.02 |            822.731 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_742c8_00000:
  custom_metrics:
    time_step_max: 4092
    time_step_mean: 3462.297794117647
    time_step_min: 3149
  date: 2020-10-11_16-33-19
  done: false
  episode_len_mean: 820.6352124183006
  episode_reward_max: 288.89898989899024
  episode_reward_mean: 241.42962715389186
  episode_reward_min: 146.02020202020225
  episodes_this_iter: 143
  episodes_total: 2448
  experiment_id: a3fbaca112274408b5a61ebe00de0bbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 0.8506251096725463
        entropy_coeff: 0.0001
        kl: 0.004865732230246067
        model: {}
        policy_loss: -0.011699284473434091
        total_loss: 13.54094352722168
        vf_explained_var: 0.9798793792724609
        vf_loss: 13.551755332946778
    num_steps_sampled: 2022400
    num_steps_trained: 2022400
  iterations_since_restore: 25
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.863157894736847
    gpu_util_percent0: 0.24789473684210525
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5
    vram_util_percent0: 0.11634962282715645
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1219047600643383
    mean_env_wait_ms: 0.6515183312848983
    mean_inference_ms: 4.659499636596185
    mean_raw_obs_processing_ms: 0.2651838569848832
  time_since_restore: 428.57146096229553
  time_this_iter_s: 16.757993698120117
  time_total_s: 428.57146096229553
  timers:
    learn_throughput: 7383.23
    learn_time_ms: 10956.722
    sample_throughput: 13801.215
    sample_time_ms: 5861.513
    update_time_ms: 39.443
  timestamp: 1602433999
  timesteps_since_restore: 0
  timesteps_total: 2022400
  training_iteration: 25
  trial_id: 742c8_00000
  
== Status ==
Memory usage on this node: 26.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |     25 |          428.571 | 2022400 |   241.43 |              288.899 |               146.02 |            820.635 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_742c8_00000:
  custom_metrics:
    time_step_max: 4092
    time_step_mean: 3460.0423259493673
    time_step_min: 3149
  date: 2020-10-11_16-33-37
  done: false
  episode_len_mean: 819.539161392405
  episode_reward_max: 288.89898989899024
  episode_reward_mean: 241.7713647551464
  episode_reward_min: 146.02020202020225
  episodes_this_iter: 80
  episodes_total: 2528
  experiment_id: a3fbaca112274408b5a61ebe00de0bbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.8542515873908997
        entropy_coeff: 0.0001
        kl: 0.005588684789836406
        model: {}
        policy_loss: -0.013171911868266762
        total_loss: 15.62488899230957
        vf_explained_var: 0.9691354632377625
        vf_loss: 15.637587738037109
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 26
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.915
    gpu_util_percent0: 0.2845
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5
    vram_util_percent0: 0.11634962282715647
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12180448369067126
    mean_env_wait_ms: 0.6518283478915357
    mean_inference_ms: 4.651488543781857
    mean_raw_obs_processing_ms: 0.2648939093712547
  time_since_restore: 445.5921413898468
  time_this_iter_s: 17.02068042755127
  time_total_s: 445.5921413898468
  timers:
    learn_throughput: 7386.73
    learn_time_ms: 10951.531
    sample_throughput: 13808.288
    sample_time_ms: 5858.51
    update_time_ms: 46.879
  timestamp: 1602434017
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 26
  trial_id: 742c8_00000
  
== Status ==
Memory usage on this node: 26.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |     26 |          445.592 | 2103296 |  241.771 |              288.899 |               146.02 |            819.539 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_742c8_00000:
  custom_metrics:
    time_step_max: 4092
    time_step_mean: 3456.8169984686065
    time_step_min: 3149
  date: 2020-10-11_16-33-53
  done: false
  episode_len_mean: 818.4391271056661
  episode_reward_max: 288.89898989899024
  episode_reward_mean: 242.26005073707984
  episode_reward_min: 146.02020202020225
  episodes_this_iter: 84
  episodes_total: 2612
  experiment_id: a3fbaca112274408b5a61ebe00de0bbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.8317709803581238
        entropy_coeff: 0.0001
        kl: 0.00648640925064683
        model: {}
        policy_loss: -0.016052717715501784
        total_loss: 10.588752174377442
        vf_explained_var: 0.9785087704658508
        vf_loss: 10.60423927307129
    num_steps_sampled: 2184192
    num_steps_trained: 2184192
  iterations_since_restore: 27
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.04210526315789
    gpu_util_percent0: 0.33999999999999997
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5
    vram_util_percent0: 0.11634962282715645
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12170000229942377
    mean_env_wait_ms: 0.6521662077100546
    mean_inference_ms: 4.643533374018082
    mean_raw_obs_processing_ms: 0.26460304791080924
  time_since_restore: 462.44021677970886
  time_this_iter_s: 16.84807538986206
  time_total_s: 462.44021677970886
  timers:
    learn_throughput: 7383.646
    learn_time_ms: 10956.105
    sample_throughput: 13798.625
    sample_time_ms: 5862.613
    update_time_ms: 45.061
  timestamp: 1602434033
  timesteps_since_restore: 0
  timesteps_total: 2184192
  training_iteration: 27
  trial_id: 742c8_00000
  
== Status ==
Memory usage on this node: 26.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |     27 |           462.44 | 2184192 |   242.26 |              288.899 |               146.02 |            818.439 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_742c8_00000:
  custom_metrics:
    time_step_max: 4092
    time_step_mean: 3452.055938975663
    time_step_min: 3111
  date: 2020-10-11_16-34-10
  done: false
  episode_len_mean: 816.755539411551
  episode_reward_max: 294.65656565656593
  episode_reward_mean: 242.98142338752584
  episode_reward_min: 146.02020202020225
  episodes_this_iter: 141
  episodes_total: 2753
  experiment_id: a3fbaca112274408b5a61ebe00de0bbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.8073569655418396
        entropy_coeff: 0.0001
        kl: 0.007314516603946686
        model: {}
        policy_loss: -0.012918723002076148
        total_loss: 14.855539894104004
        vf_explained_var: 0.9783770442008972
        vf_loss: 14.867807388305664
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 28
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.88421052631579
    gpu_util_percent0: 0.3910526315789474
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5
    vram_util_percent0: 0.11634962282715645
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12153785932976834
    mean_env_wait_ms: 0.6527151245819349
    mean_inference_ms: 4.630862286777733
    mean_raw_obs_processing_ms: 0.2641544072429254
  time_since_restore: 479.31437849998474
  time_this_iter_s: 16.87416172027588
  time_total_s: 479.31437849998474
  timers:
    learn_throughput: 7390.723
    learn_time_ms: 10945.614
    sample_throughput: 13777.872
    sample_time_ms: 5871.444
    update_time_ms: 44.828
  timestamp: 1602434050
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 28
  trial_id: 742c8_00000
  
== Status ==
Memory usage on this node: 26.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |     28 |          479.314 | 2265088 |  242.981 |              294.657 |               146.02 |            816.756 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_742c8_00000:
  custom_metrics:
    time_step_max: 4092
    time_step_mean: 3449.462728551336
    time_step_min: 3111
  date: 2020-10-11_16-34-28
  done: false
  episode_len_mean: 815.731364275668
  episode_reward_max: 294.65656565656593
  episode_reward_mean: 243.3743340578784
  episode_reward_min: 146.02020202020225
  episodes_this_iter: 91
  episodes_total: 2844
  experiment_id: a3fbaca112274408b5a61ebe00de0bbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.8145095586776734
        entropy_coeff: 0.0001
        kl: 0.005709170270711184
        model: {}
        policy_loss: -0.011662486474961042
        total_loss: 12.014441299438477
        vf_explained_var: 0.9769560098648071
        vf_loss: 12.025614356994629
    num_steps_sampled: 2345984
    num_steps_trained: 2345984
  iterations_since_restore: 29
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.785000000000004
    gpu_util_percent0: 0.274
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5
    vram_util_percent0: 0.11634962282715647
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1214422344724671
    mean_env_wait_ms: 0.6530009353317395
    mean_inference_ms: 4.623333907881865
    mean_raw_obs_processing_ms: 0.26387314444224774
  time_since_restore: 496.35931181907654
  time_this_iter_s: 17.044933319091797
  time_total_s: 496.35931181907654
  timers:
    learn_throughput: 7390.31
    learn_time_ms: 10946.225
    sample_throughput: 13767.349
    sample_time_ms: 5875.932
    update_time_ms: 38.656
  timestamp: 1602434068
  timesteps_since_restore: 0
  timesteps_total: 2345984
  training_iteration: 29
  trial_id: 742c8_00000
  
== Status ==
Memory usage on this node: 26.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |     29 |          496.359 | 2345984 |  243.374 |              294.657 |               146.02 |            815.731 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_742c8_00000:
  custom_metrics:
    time_step_max: 4092
    time_step_mean: 3446.7897435897435
    time_step_min: 3111
  date: 2020-10-11_16-34-45
  done: false
  episode_len_mean: 814.8417094017094
  episode_reward_max: 294.65656565656593
  episode_reward_mean: 243.7793317793318
  episode_reward_min: 146.02020202020225
  episodes_this_iter: 81
  episodes_total: 2925
  experiment_id: a3fbaca112274408b5a61ebe00de0bbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.8143168568611145
        entropy_coeff: 0.0001
        kl: 0.006050251703709364
        model: {}
        policy_loss: -0.014920068671926856
        total_loss: 10.06276626586914
        vf_explained_var: 0.9785787463188171
        vf_loss: 10.07716236114502
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 30
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.821052631578944
    gpu_util_percent0: 0.3684210526315789
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5
    vram_util_percent0: 0.11634962282715645
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12135757858033507
    mean_env_wait_ms: 0.6532775139903034
    mean_inference_ms: 4.616883042420374
    mean_raw_obs_processing_ms: 0.26363995161920145
  time_since_restore: 513.1962876319885
  time_this_iter_s: 16.836975812911987
  time_total_s: 513.1962876319885
  timers:
    learn_throughput: 7405.345
    learn_time_ms: 10924.001
    sample_throughput: 13750.589
    sample_time_ms: 5883.093
    update_time_ms: 36.706
  timestamp: 1602434085
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 30
  trial_id: 742c8_00000
  
== Status ==
Memory usage on this node: 26.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |     30 |          513.196 | 2426880 |  243.779 |              294.657 |               146.02 |            814.842 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_742c8_00000:
  custom_metrics:
    time_step_max: 4092
    time_step_mean: 3443.8039408866994
    time_step_min: 3111
  date: 2020-10-11_16-35-02
  done: false
  episode_len_mean: 813.6032840722496
  episode_reward_max: 294.65656565656593
  episode_reward_mean: 244.2317261282779
  episode_reward_min: 146.02020202020225
  episodes_this_iter: 120
  episodes_total: 3045
  experiment_id: a3fbaca112274408b5a61ebe00de0bbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.7847271919250488
        entropy_coeff: 0.0001
        kl: 0.006011144630610943
        model: {}
        policy_loss: -0.0123886376619339
        total_loss: 13.336679077148437
        vf_explained_var: 0.9797344207763672
        vf_loss: 13.348544883728028
    num_steps_sampled: 2507776
    num_steps_trained: 2507776
  iterations_since_restore: 31
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.92105263157895
    gpu_util_percent0: 0.26315789473684204
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5
    vram_util_percent0: 0.11634962282715645
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12123641241438077
    mean_env_wait_ms: 0.6537218561047831
    mean_inference_ms: 4.6077991278621475
    mean_raw_obs_processing_ms: 0.2633179398646692
  time_since_restore: 530.1246099472046
  time_this_iter_s: 16.928322315216064
  time_total_s: 530.1246099472046
  timers:
    learn_throughput: 7404.912
    learn_time_ms: 10924.641
    sample_throughput: 13747.273
    sample_time_ms: 5884.513
    update_time_ms: 36.485
  timestamp: 1602434102
  timesteps_since_restore: 0
  timesteps_total: 2507776
  training_iteration: 31
  trial_id: 742c8_00000
  
== Status ==
Memory usage on this node: 26.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |     31 |          530.125 | 2507776 |  244.232 |              294.657 |               146.02 |            813.603 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_742c8_00000:
  custom_metrics:
    time_step_max: 4092
    time_step_mean: 3441.074050632911
    time_step_min: 3111
  date: 2020-10-11_16-35-19
  done: false
  episode_len_mean: 812.5060126582279
  episode_reward_max: 294.65656565656593
  episode_reward_mean: 244.64534586370036
  episode_reward_min: 146.02020202020225
  episodes_this_iter: 115
  episodes_total: 3160
  experiment_id: a3fbaca112274408b5a61ebe00de0bbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.7759140849113464
        entropy_coeff: 0.0001
        kl: 0.005504181887954473
        model: {}
        policy_loss: -0.011239721812307835
        total_loss: 11.656171417236328
        vf_explained_var: 0.9791274070739746
        vf_loss: 11.666938591003419
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 32
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.235000000000003
    gpu_util_percent0: 0.31
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5
    vram_util_percent0: 0.11634962282715647
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12113687445987069
    mean_env_wait_ms: 0.6540608571178146
    mean_inference_ms: 4.599696534562951
    mean_raw_obs_processing_ms: 0.26302098056308076
  time_since_restore: 547.3567974567413
  time_this_iter_s: 17.232187509536743
  time_total_s: 547.3567974567413
  timers:
    learn_throughput: 7410.863
    learn_time_ms: 10915.868
    sample_throughput: 13667.621
    sample_time_ms: 5918.806
    update_time_ms: 37.934
  timestamp: 1602434119
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 32
  trial_id: 742c8_00000
  
== Status ==
Memory usage on this node: 26.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |     32 |          547.357 | 2588672 |  244.645 |              294.657 |               146.02 |            812.506 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_742c8_00000:
  custom_metrics:
    time_step_max: 4092
    time_step_mean: 3439.0583333333334
    time_step_min: 3111
  date: 2020-10-11_16-35-36
  done: false
  episode_len_mean: 811.7601851851852
  episode_reward_max: 294.65656565656593
  episode_reward_mean: 244.95075757575762
  episode_reward_min: 146.02020202020225
  episodes_this_iter: 80
  episodes_total: 3240
  experiment_id: a3fbaca112274408b5a61ebe00de0bbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.7811835169792175
        entropy_coeff: 0.0001
        kl: 0.006416494492441416
        model: {}
        policy_loss: -0.012559976987540722
        total_loss: 8.990324211120605
        vf_explained_var: 0.9806587100028992
        vf_loss: 9.002320289611816
    num_steps_sampled: 2669568
    num_steps_trained: 2669568
  iterations_since_restore: 33
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.16315789473685
    gpu_util_percent0: 0.3494736842105263
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5
    vram_util_percent0: 0.11634962282715645
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12106636804940506
    mean_env_wait_ms: 0.654308418437876
    mean_inference_ms: 4.594290281235995
    mean_raw_obs_processing_ms: 0.26282625189540965
  time_since_restore: 564.2302570343018
  time_this_iter_s: 16.873459577560425
  time_total_s: 564.2302570343018
  timers:
    learn_throughput: 7407.876
    learn_time_ms: 10920.269
    sample_throughput: 13664.264
    sample_time_ms: 5920.26
    update_time_ms: 37.37
  timestamp: 1602434136
  timesteps_since_restore: 0
  timesteps_total: 2669568
  training_iteration: 33
  trial_id: 742c8_00000
  
== Status ==
Memory usage on this node: 26.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |     33 |           564.23 | 2669568 |  244.951 |              294.657 |               146.02 |             811.76 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_742c8_00000:
  custom_metrics:
    time_step_max: 4092
    time_step_mean: 3436.664176874813
    time_step_min: 3111
  date: 2020-10-11_16-35-53
  done: false
  episode_len_mean: 810.7051090528831
  episode_reward_max: 294.65656565656593
  episode_reward_mean: 245.3135085543213
  episode_reward_min: 146.02020202020225
  episodes_this_iter: 107
  episodes_total: 3347
  experiment_id: a3fbaca112274408b5a61ebe00de0bbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.7612020254135132
        entropy_coeff: 0.0001
        kl: 0.005618926044553519
        model: {}
        policy_loss: -0.014426779658242595
        total_loss: 10.50188980102539
        vf_explained_var: 0.9819744229316711
        vf_loss: 10.515831184387206
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 34
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.440000000000005
    gpu_util_percent0: 0.2825
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5
    vram_util_percent0: 0.11634962282715647
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12097591505642284
    mean_env_wait_ms: 0.654678447565111
    mean_inference_ms: 4.587428459993633
    mean_raw_obs_processing_ms: 0.26258601176828894
  time_since_restore: 581.2578387260437
  time_this_iter_s: 17.027581691741943
  time_total_s: 581.2578387260437
  timers:
    learn_throughput: 7403.63
    learn_time_ms: 10926.532
    sample_throughput: 13652.925
    sample_time_ms: 5925.177
    update_time_ms: 37.988
  timestamp: 1602434153
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 34
  trial_id: 742c8_00000
  
== Status ==
Memory usage on this node: 26.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |     34 |          581.258 | 2750464 |  245.314 |              294.657 |               146.02 |            810.705 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_742c8_00000:
  custom_metrics:
    time_step_max: 4092
    time_step_mean: 3433.486323063634
    time_step_min: 3111
  date: 2020-10-11_16-36-10
  done: false
  episode_len_mean: 809.8491217967176
  episode_reward_max: 294.65656565656593
  episode_reward_mean: 245.79500155601514
  episode_reward_min: 146.02020202020225
  episodes_this_iter: 126
  episodes_total: 3473
  experiment_id: a3fbaca112274408b5a61ebe00de0bbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.755747628211975
        entropy_coeff: 0.0001
        kl: 0.00591852879151702
        model: {}
        policy_loss: -0.012422900833189487
        total_loss: 9.482335662841797
        vf_explained_var: 0.9842199087142944
        vf_loss: 9.494241714477539
    num_steps_sampled: 2831360
    num_steps_trained: 2831360
  iterations_since_restore: 35
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.01578947368421
    gpu_util_percent0: 0.38684210526315793
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5
    vram_util_percent0: 0.11634962282715645
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12087802096321525
    mean_env_wait_ms: 0.6550253058413934
    mean_inference_ms: 4.579750068083864
    mean_raw_obs_processing_ms: 0.2623052128500548
  time_since_restore: 598.2881736755371
  time_this_iter_s: 17.030334949493408
  time_total_s: 598.2881736755371
  timers:
    learn_throughput: 7403.573
    learn_time_ms: 10926.617
    sample_throughput: 13595.729
    sample_time_ms: 5950.104
    update_time_ms: 39.679
  timestamp: 1602434170
  timesteps_since_restore: 0
  timesteps_total: 2831360
  training_iteration: 35
  trial_id: 742c8_00000
  
== Status ==
Memory usage on this node: 26.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |     35 |          598.288 | 2831360 |  245.795 |              294.657 |               146.02 |            809.849 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_742c8_00000:
  custom_metrics:
    time_step_max: 4092
    time_step_mean: 3432.0928270042195
    time_step_min: 3111
  date: 2020-10-11_16-36-27
  done: true
  episode_len_mean: 809.4239099859353
  episode_reward_max: 294.65656565656593
  episode_reward_mean: 246.00613732259308
  episode_reward_min: 146.02020202020225
  episodes_this_iter: 82
  episodes_total: 3555
  experiment_id: a3fbaca112274408b5a61ebe00de0bbd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.762268352508545
        entropy_coeff: 0.0001
        kl: 0.005749249923974275
        model: {}
        policy_loss: -0.014044645662215772
        total_loss: 8.698633766174316
        vf_explained_var: 0.9826677441596985
        vf_loss: 8.712179946899415
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 36
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.85
    gpu_util_percent0: 0.31549999999999995
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5
    vram_util_percent0: 0.11634962282715647
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 61121
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12081720783745345
    mean_env_wait_ms: 0.6552418949605134
    mean_inference_ms: 4.575020157942163
    mean_raw_obs_processing_ms: 0.2621333728839125
  time_since_restore: 615.3142302036285
  time_this_iter_s: 17.02605652809143
  time_total_s: 615.3142302036285
  timers:
    learn_throughput: 7405.578
    learn_time_ms: 10923.658
    sample_throughput: 13569.903
    sample_time_ms: 5961.428
    update_time_ms: 31.246
  timestamp: 1602434187
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 36
  trial_id: 742c8_00000
  
== Status ==
Memory usage on this node: 26.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_742c8_00000 | TERMINATED |       |     36 |          615.314 | 2912256 |  246.006 |              294.657 |               146.02 |            809.424 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 26.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_742c8_00000 | TERMINATED |       |     36 |          615.314 | 2912256 |  246.006 |              294.657 |               146.02 |            809.424 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Traceback (most recent call last):
  File "train.py", line 72, in <module>
    train_func()
  File "train.py", line 57, in train_func
    result = analysis.dataframe().to_dict('index')[0]
  File "/root/miniconda3/lib/python3.8/site-packages/ray/tune/analysis/experiment_analysis.py", line 89, in dataframe
    metric = self._validate_metric(metric)
  File "/root/miniconda3/lib/python3.8/site-packages/ray/tune/analysis/experiment_analysis.py", line 64, in _validate_metric
    raise ValueError(
ValueError: No `metric` has been passed and  `default_metric` has not been set. Please specify the `metric` parameter.
