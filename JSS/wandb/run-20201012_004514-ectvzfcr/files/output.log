2020-10-12 00:45:18,882	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_345e0_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=47436)[0m 2020-10-12 00:45:21,610	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=47423)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47423)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47382)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47382)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47432)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47432)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47380)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47380)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47422)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47422)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47386)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47386)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47381)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47381)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47415)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47415)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47397)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47397)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47419)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47419)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47376)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47376)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47410)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47410)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47402)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47402)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47357)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47357)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47371)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47371)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47401)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47401)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47367)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47367)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47412)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47412)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47303)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47303)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47375)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47375)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47327)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47327)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47404)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47404)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47299)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47299)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47396)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47396)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47321)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47321)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47362)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47362)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47310)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47310)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47370)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47370)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47335)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47335)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47378)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47378)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47393)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47393)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47317)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47317)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47319)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47319)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47325)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47325)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47359)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47359)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47313)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47313)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47406)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47406)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47372)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47372)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47296)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47296)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47361)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47361)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47399)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47399)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47305)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47305)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47298)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47298)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47354)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47354)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47300)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47300)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47333)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47333)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47403)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47403)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47316)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47316)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47329)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47329)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47369)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47369)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47408)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47408)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47351)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47351)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47308)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47308)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47384)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47384)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47315)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47315)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47390)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47390)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47388)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47388)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47309)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47309)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47391)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47391)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47323)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47323)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47366)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47366)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47377)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47377)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47416)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47416)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47334)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47334)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47312)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47312)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47311)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47311)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47400)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47400)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47387)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47387)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47302)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47302)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47368)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47368)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47304)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47304)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47353)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47353)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47374)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47374)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47295)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47295)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47379)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47379)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47307)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47307)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47301)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47301)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47373)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47373)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47297)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47297)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_345e0_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-12_00-45-58
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: f6c01053906b4e4493539028ac8806cd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 1.1833713452021282
        entropy_coeff: 0.0005000000000000001
        kl: 0.006212767446413636
        model: {}
        policy_loss: -0.012007266942722103
        total_loss: 502.23599497477215
        vf_explained_var: 0.5664147734642029
        vf_loss: 502.24672444661456
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.13076923076922
    gpu_util_percent0: 0.30435897435897435
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5717948717948715
    vram_util_percent0: 0.08727325478719382
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47436
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17466809212995849
    mean_env_wait_ms: 1.1800632965568407
    mean_inference_ms: 5.924136013703495
    mean_raw_obs_processing_ms: 0.46759631612412017
  time_since_restore: 31.866060972213745
  time_this_iter_s: 31.866060972213745
  time_total_s: 31.866060972213745
  timers:
    learn_throughput: 7169.853
    learn_time_ms: 22565.595
    sample_throughput: 17552.659
    sample_time_ms: 9217.521
    update_time_ms: 52.13
  timestamp: 1602463558
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 345e0_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_345e0_00000 | RUNNING  | 172.17.0.4:47436 |      1 |          31.8661 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_345e0_00000:
  custom_metrics:
    time_step_max: 4088
    time_step_mean: 3618.4270833333335
    time_step_min: 3379
  date: 2020-10-12_00-46-28
  done: false
  episode_len_mean: 891.2310126582279
  episode_reward_max: 274.3535353535351
  episode_reward_mean: 216.94895154072344
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: f6c01053906b4e4493539028ac8806cd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 1.154136836528778
        entropy_coeff: 0.0005000000000000001
        kl: 0.007569237030111253
        model: {}
        policy_loss: -0.01255445987044368
        total_loss: 124.45339457194011
        vf_explained_var: 0.8155669569969177
        vf_loss: 124.46425120035808
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.189189189189193
    gpu_util_percent0: 0.35243243243243244
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7567567567567566
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47436
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1692313015212992
    mean_env_wait_ms: 1.173300488622412
    mean_inference_ms: 5.677835734002925
    mean_raw_obs_processing_ms: 0.45484920646044397
  time_since_restore: 61.93977355957031
  time_this_iter_s: 30.073712587356567
  time_total_s: 61.93977355957031
  timers:
    learn_throughput: 7237.599
    learn_time_ms: 22354.375
    sample_throughput: 19023.5
    sample_time_ms: 8504.849
    update_time_ms: 41.949
  timestamp: 1602463588
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 345e0_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_345e0_00000 | RUNNING  | 172.17.0.4:47436 |      2 |          61.9398 | 323584 |  216.949 |              274.354 |              145.717 |            891.231 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_345e0_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3615.392376681614
    time_step_min: 3341
  date: 2020-10-12_00-46-58
  done: false
  episode_len_mean: 888.9746835443038
  episode_reward_max: 274.3535353535351
  episode_reward_mean: 218.15739675233323
  episode_reward_min: 137.98989898989862
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: f6c01053906b4e4493539028ac8806cd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 1.1441917916138966
        entropy_coeff: 0.0005000000000000001
        kl: 0.008875227766111493
        model: {}
        policy_loss: -0.016180873654472332
        total_loss: 52.78328069051107
        vf_explained_var: 0.9064672589302063
        vf_loss: 52.79737059275309
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.53142857142857
    gpu_util_percent0: 0.3742857142857143
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7714285714285722
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47436
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16573754527558057
    mean_env_wait_ms: 1.1703861759569625
    mean_inference_ms: 5.479402993519361
    mean_raw_obs_processing_ms: 0.44469508677300745
  time_since_restore: 91.17180871963501
  time_this_iter_s: 29.232035160064697
  time_total_s: 91.17180871963501
  timers:
    learn_throughput: 7267.638
    learn_time_ms: 22261.979
    sample_throughput: 20170.35
    sample_time_ms: 8021.279
    update_time_ms: 41.802
  timestamp: 1602463618
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 345e0_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_345e0_00000 | RUNNING  | 172.17.0.4:47436 |      3 |          91.1718 | 485376 |  218.157 |              274.354 |               137.99 |            888.975 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_345e0_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3602.865894039735
    time_step_min: 3341
  date: 2020-10-12_00-47-27
  done: false
  episode_len_mean: 885.7848101265823
  episode_reward_max: 274.3535353535351
  episode_reward_mean: 220.27533243830692
  episode_reward_min: 137.98989898989862
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: f6c01053906b4e4493539028ac8806cd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 1.1299392580986023
        entropy_coeff: 0.0005000000000000001
        kl: 0.009590955373520652
        model: {}
        policy_loss: -0.017993397855510313
        total_loss: 32.58618529637655
        vf_explained_var: 0.9377539157867432
        vf_loss: 32.60186640421549
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.549999999999997
    gpu_util_percent0: 0.40527777777777785
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.775000000000001
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47436
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1632548940381471
    mean_env_wait_ms: 1.1691875967202994
    mean_inference_ms: 5.332121977461857
    mean_raw_obs_processing_ms: 0.4368526398006968
  time_since_restore: 120.47114586830139
  time_this_iter_s: 29.299337148666382
  time_total_s: 120.47114586830139
  timers:
    learn_throughput: 7261.025
    learn_time_ms: 22282.255
    sample_throughput: 20925.538
    sample_time_ms: 7731.797
    update_time_ms: 43.166
  timestamp: 1602463647
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 345e0_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_345e0_00000 | RUNNING  | 172.17.0.4:47436 |      4 |          120.471 | 647168 |  220.275 |              274.354 |               137.99 |            885.785 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_345e0_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3591.181102362205
    time_step_min: 3198
  date: 2020-10-12_00-47-57
  done: false
  episode_len_mean: 882.0696202531645
  episode_reward_max: 281.47474747474763
  episode_reward_mean: 221.85315177087307
  episode_reward_min: 137.98989898989862
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: f6c01053906b4e4493539028ac8806cd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 1.1023077368736267
        entropy_coeff: 0.0005000000000000001
        kl: 0.00855852453969419
        model: {}
        policy_loss: -0.015917088525990646
        total_loss: 27.57396427790324
        vf_explained_var: 0.9499914646148682
        vf_loss: 27.587865352630615
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.78571428571428
    gpu_util_percent0: 0.37657142857142856
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7771428571428576
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47436
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16139388914130487
    mean_env_wait_ms: 1.1690468366273645
    mean_inference_ms: 5.218980345573929
    mean_raw_obs_processing_ms: 0.4306834177517305
  time_since_restore: 149.81983304023743
  time_this_iter_s: 29.348687171936035
  time_total_s: 149.81983304023743
  timers:
    learn_throughput: 7256.99
    learn_time_ms: 22294.641
    sample_throughput: 21376.247
    sample_time_ms: 7568.775
    update_time_ms: 42.179
  timestamp: 1602463677
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 345e0_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_345e0_00000 | RUNNING  | 172.17.0.4:47436 |      5 |           149.82 | 808960 |  221.853 |              281.475 |               137.99 |             882.07 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_345e0_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3575.1917545541705
    time_step_min: 3198
  date: 2020-10-12_00-48-26
  done: false
  episode_len_mean: 874.626517273576
  episode_reward_max: 281.47474747474763
  episode_reward_mean: 224.40319157966195
  episode_reward_min: 137.98989898989862
  episodes_this_iter: 281
  episodes_total: 1071
  experiment_id: f6c01053906b4e4493539028ac8806cd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 1.0830090641975403
        entropy_coeff: 0.0005000000000000001
        kl: 0.008911309841399392
        model: {}
        policy_loss: -0.01526048178008447
        total_loss: 31.409974416097004
        vf_explained_var: 0.9619443416595459
        vf_loss: 31.42310380935669
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.391666666666666
    gpu_util_percent0: 0.3994444444444445
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.769444444444445
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47436
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15908398221937464
    mean_env_wait_ms: 1.1707701337417973
    mean_inference_ms: 5.078050201472461
    mean_raw_obs_processing_ms: 0.4231260582464787
  time_since_restore: 179.18016266822815
  time_this_iter_s: 29.360329627990723
  time_total_s: 179.18016266822815
  timers:
    learn_throughput: 7253.264
    learn_time_ms: 22306.097
    sample_throughput: 21718.54
    sample_time_ms: 7449.488
    update_time_ms: 48.442
  timestamp: 1602463706
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 345e0_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_345e0_00000 | RUNNING  | 172.17.0.4:47436 |      6 |           179.18 | 970752 |  224.403 |              281.475 |               137.99 |            874.627 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_345e0_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3565.563915857605
    time_step_min: 3198
  date: 2020-10-12_00-48-56
  done: false
  episode_len_mean: 870.3322784810126
  episode_reward_max: 281.47474747474763
  episode_reward_mean: 225.80539572944616
  episode_reward_min: 137.98989898989862
  episodes_this_iter: 193
  episodes_total: 1264
  experiment_id: f6c01053906b4e4493539028ac8806cd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 1.089710811773936
        entropy_coeff: 0.0005000000000000001
        kl: 0.008759717689827085
        model: {}
        policy_loss: -0.016991691634757444
        total_loss: 19.009854157765705
        vf_explained_var: 0.9661710262298584
        vf_loss: 19.024761994679768
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.754285714285718
    gpu_util_percent0: 0.4082857142857143
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.788571428571429
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47436
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15793859610372174
    mean_env_wait_ms: 1.172041393520259
    mean_inference_ms: 5.0078970475932705
    mean_raw_obs_processing_ms: 0.4193719117245946
  time_since_restore: 208.7519769668579
  time_this_iter_s: 29.57181429862976
  time_total_s: 208.7519769668579
  timers:
    learn_throughput: 7251.673
    learn_time_ms: 22310.99
    sample_throughput: 21853.287
    sample_time_ms: 7403.555
    update_time_ms: 48.049
  timestamp: 1602463736
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 345e0_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_345e0_00000 | RUNNING  | 172.17.0.4:47436 |      7 |          208.752 | 1132544 |  225.805 |              281.475 |               137.99 |            870.332 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_345e0_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3559.1492109038736
    time_step_min: 3198
  date: 2020-10-12_00-49-25
  done: false
  episode_len_mean: 867.2693389592124
  episode_reward_max: 281.47474747474763
  episode_reward_mean: 226.87708306695626
  episode_reward_min: 137.98989898989862
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: f6c01053906b4e4493539028ac8806cd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 1.0660984218120575
        entropy_coeff: 0.0005000000000000001
        kl: 0.009453735159089168
        model: {}
        policy_loss: -0.020104794059686053
        total_loss: 16.28125063578288
        vf_explained_var: 0.9705528616905212
        vf_loss: 16.299052079518635
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.166666666666668
    gpu_util_percent0: 0.34388888888888897
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7805555555555554
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47436
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15716764004609984
    mean_env_wait_ms: 1.1729151061527654
    mean_inference_ms: 4.959790418176246
    mean_raw_obs_processing_ms: 0.41677275804556757
  time_since_restore: 237.9665608406067
  time_this_iter_s: 29.21458387374878
  time_total_s: 237.9665608406067
  timers:
    learn_throughput: 7253.591
    learn_time_ms: 22305.089
    sample_throughput: 22071.996
    sample_time_ms: 7330.193
    update_time_ms: 46.146
  timestamp: 1602463765
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 345e0_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_345e0_00000 | RUNNING  | 172.17.0.4:47436 |      8 |          237.967 | 1294336 |  226.877 |              281.475 |               137.99 |            867.269 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_345e0_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3550.8099226804125
    time_step_min: 3198
  date: 2020-10-12_00-49-54
  done: false
  episode_len_mean: 863.8911392405063
  episode_reward_max: 281.47474747474763
  episode_reward_mean: 228.41318245748607
  episode_reward_min: 137.98989898989862
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: f6c01053906b4e4493539028ac8806cd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 1.0449092785517375
        entropy_coeff: 0.0005000000000000001
        kl: 0.009408840288718542
        model: {}
        policy_loss: -0.01796298132588466
        total_loss: 13.678425470987955
        vf_explained_var: 0.9720842242240906
        vf_loss: 13.694087902704874
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.73428571428571
    gpu_util_percent0: 0.4094285714285714
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7857142857142865
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47436
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15649693114709246
    mean_env_wait_ms: 1.1737845878917839
    mean_inference_ms: 4.917677006837467
    mean_raw_obs_processing_ms: 0.41445007407816264
  time_since_restore: 267.24239110946655
  time_this_iter_s: 29.275830268859863
  time_total_s: 267.24239110946655
  timers:
    learn_throughput: 7259.972
    learn_time_ms: 22285.485
    sample_throughput: 22162.914
    sample_time_ms: 7300.123
    update_time_ms: 44.784
  timestamp: 1602463794
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 345e0_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_345e0_00000 | RUNNING  | 172.17.0.4:47436 |      9 |          267.242 | 1456128 |  228.413 |              281.475 |               137.99 |            863.891 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_345e0_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3541.9615825688074
    time_step_min: 3198
  date: 2020-10-12_00-50-24
  done: false
  episode_len_mean: 859.5886004514673
  episode_reward_max: 281.47474747474763
  episode_reward_mean: 230.00679481040638
  episode_reward_min: 137.98989898989862
  episodes_this_iter: 192
  episodes_total: 1772
  experiment_id: f6c01053906b4e4493539028ac8806cd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 1.0038335124651592
        entropy_coeff: 0.0005000000000000001
        kl: 0.009950989546875158
        model: {}
        policy_loss: -0.017110984966469307
        total_loss: 15.106614033381144
        vf_explained_var: 0.9766802191734314
        vf_loss: 15.121241410573324
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.965714285714288
    gpu_util_percent0: 0.4014285714285714
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.765714285714286
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47436
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1557950814892169
    mean_env_wait_ms: 1.1751411829226066
    mean_inference_ms: 4.873303059860268
    mean_raw_obs_processing_ms: 0.41200537295688155
  time_since_restore: 296.38342809677124
  time_this_iter_s: 29.141036987304688
  time_total_s: 296.38342809677124
  timers:
    learn_throughput: 7260.458
    learn_time_ms: 22283.995
    sample_throughput: 22316.535
    sample_time_ms: 7249.871
    update_time_ms: 42.49
  timestamp: 1602463824
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 345e0_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_345e0_00000 | RUNNING  | 172.17.0.4:47436 |     10 |          296.383 | 1617920 |  230.007 |              281.475 |               137.99 |            859.589 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_345e0_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3528.941234567901
    time_step_min: 3198
  date: 2020-10-12_00-50-53
  done: false
  episode_len_mean: 855.1709693132002
  episode_reward_max: 281.47474747474763
  episode_reward_mean: 232.06169340752862
  episode_reward_min: 137.98989898989862
  episodes_this_iter: 281
  episodes_total: 2053
  experiment_id: f6c01053906b4e4493539028ac8806cd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 1.011017769575119
        entropy_coeff: 0.0005000000000000001
        kl: 0.008228297190119823
        model: {}
        policy_loss: -0.016195291313730802
        total_loss: 14.69644538561503
        vf_explained_var: 0.9784245491027832
        vf_loss: 14.710677146911621
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.391428571428573
    gpu_util_percent0: 0.3722857142857143
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7685714285714287
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47436
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15494001396939983
    mean_env_wait_ms: 1.17676497090697
    mean_inference_ms: 4.819682631549486
    mean_raw_obs_processing_ms: 0.40906608098045266
  time_since_restore: 325.49534797668457
  time_this_iter_s: 29.11191987991333
  time_total_s: 325.49534797668457
  timers:
    learn_throughput: 7270.046
    learn_time_ms: 22254.606
    sample_throughput: 23105.875
    sample_time_ms: 7002.202
    update_time_ms: 41.552
  timestamp: 1602463853
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 345e0_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_345e0_00000 | RUNNING  | 172.17.0.4:47436 |     11 |          325.495 | 1779712 |  232.062 |              281.475 |               137.99 |            855.171 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_345e0_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3520.17673992674
    time_step_min: 3198
  date: 2020-10-12_00-51-22
  done: false
  episode_len_mean: 852.8155515370705
  episode_reward_max: 281.47474747474763
  episode_reward_mean: 233.24313204376483
  episode_reward_min: 137.98989898989862
  episodes_this_iter: 159
  episodes_total: 2212
  experiment_id: f6c01053906b4e4493539028ac8806cd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 0.9910989354054133
        entropy_coeff: 0.0005000000000000001
        kl: 0.009553672512993217
        model: {}
        policy_loss: -0.018956959538627416
        total_loss: 11.005234241485596
        vf_explained_var: 0.9791452884674072
        vf_loss: 11.021820704142252
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.154285714285713
    gpu_util_percent0: 0.34657142857142853
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.782857142857143
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47436
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1545324088269734
    mean_env_wait_ms: 1.1775961274348117
    mean_inference_ms: 4.793872172896804
    mean_raw_obs_processing_ms: 0.4076439321256364
  time_since_restore: 354.58913493156433
  time_this_iter_s: 29.09378695487976
  time_total_s: 354.58913493156433
  timers:
    learn_throughput: 7267.948
    learn_time_ms: 22261.03
    sample_throughput: 23436.187
    sample_time_ms: 6903.512
    update_time_ms: 41.172
  timestamp: 1602463882
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 345e0_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_345e0_00000 | RUNNING  | 172.17.0.4:47436 |     12 |          354.589 | 1941504 |  233.243 |              281.475 |               137.99 |            852.816 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_345e0_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3512.809137489325
    time_step_min: 3184
  date: 2020-10-12_00-51-51
  done: false
  episode_len_mean: 850.8873417721519
  episode_reward_max: 283.5959595959594
  episode_reward_mean: 234.344265439202
  episode_reward_min: 137.98989898989862
  episodes_this_iter: 158
  episodes_total: 2370
  experiment_id: f6c01053906b4e4493539028ac8806cd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 0.9733495265245438
        entropy_coeff: 0.0005000000000000001
        kl: 0.008800534453863898
        model: {}
        policy_loss: -0.015832588775083423
        total_loss: 10.703865051269531
        vf_explained_var: 0.9788469672203064
        vf_loss: 10.717543840408325
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.886111111111113
    gpu_util_percent0: 0.4119444444444445
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7777777777777786
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47436
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15416508537875837
    mean_env_wait_ms: 1.1783621055671119
    mean_inference_ms: 4.770488666161953
    mean_raw_obs_processing_ms: 0.40633795448016274
  time_since_restore: 383.91424584388733
  time_this_iter_s: 29.325110912322998
  time_total_s: 383.91424584388733
  timers:
    learn_throughput: 7253.955
    learn_time_ms: 22303.97
    sample_throughput: 23545.7
    sample_time_ms: 6871.403
    update_time_ms: 39.9
  timestamp: 1602463911
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 345e0_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_345e0_00000 | RUNNING  | 172.17.0.4:47436 |     13 |          383.914 | 2103296 |  234.344 |              283.596 |               137.99 |            850.887 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_345e0_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3503.960614415124
    time_step_min: 3184
  date: 2020-10-12_00-52-21
  done: false
  episode_len_mean: 848.375146084924
  episode_reward_max: 283.5959595959594
  episode_reward_mean: 235.70814101277668
  episode_reward_min: 137.98989898989862
  episodes_this_iter: 197
  episodes_total: 2567
  experiment_id: f6c01053906b4e4493539028ac8806cd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 0.929638201991717
        entropy_coeff: 0.0005000000000000001
        kl: 0.009409984263281027
        model: {}
        policy_loss: -0.017946248796458047
        total_loss: 11.88581109046936
        vf_explained_var: 0.9808126091957092
        vf_loss: 11.901399374008179
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.548571428571428
    gpu_util_percent0: 0.35714285714285715
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7800000000000002
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47436
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15375607190022428
    mean_env_wait_ms: 1.17933018372544
    mean_inference_ms: 4.744237446293541
    mean_raw_obs_processing_ms: 0.4048724409146151
  time_since_restore: 413.4353229999542
  time_this_iter_s: 29.521077156066895
  time_total_s: 413.4353229999542
  timers:
    learn_throughput: 7246.327
    learn_time_ms: 22327.449
    sample_throughput: 23545.587
    sample_time_ms: 6871.436
    update_time_ms: 37.13
  timestamp: 1602463941
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 345e0_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_345e0_00000 | RUNNING  | 172.17.0.4:47436 |     14 |          413.435 | 2265088 |  235.708 |              283.596 |               137.99 |            848.375 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_345e0_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3491.0928165007113
    time_step_min: 3129
  date: 2020-10-12_00-52-50
  done: false
  episode_len_mean: 844.6514084507043
  episode_reward_max: 292.080808080808
  episode_reward_mean: 237.68990965997997
  episode_reward_min: 137.98989898989862
  episodes_this_iter: 273
  episodes_total: 2840
  experiment_id: f6c01053906b4e4493539028ac8806cd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 0.9267557958761851
        entropy_coeff: 0.0005000000000000001
        kl: 0.008255064293431738
        model: {}
        policy_loss: -0.01584411404716472
        total_loss: 13.214595874150595
        vf_explained_var: 0.9797441363334656
        vf_loss: 13.228426933288574
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.371428571428574
    gpu_util_percent0: 0.38485714285714295
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.765714285714286
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47436
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15326250271029415
    mean_env_wait_ms: 1.1806141220054618
    mean_inference_ms: 4.712460453463089
    mean_raw_obs_processing_ms: 0.4031134092723702
  time_since_restore: 442.5493223667145
  time_this_iter_s: 29.113999366760254
  time_total_s: 442.5493223667145
  timers:
    learn_throughput: 7248.527
    learn_time_ms: 22320.672
    sample_throughput: 23600.148
    sample_time_ms: 6855.55
    update_time_ms: 35.105
  timestamp: 1602463970
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 345e0_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_345e0_00000 | RUNNING  | 172.17.0.4:47436 |     15 |          442.549 | 2426880 |   237.69 |              292.081 |               137.99 |            844.651 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_345e0_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3485.059179556153
    time_step_min: 3129
  date: 2020-10-12_00-53-20
  done: false
  episode_len_mean: 842.215856095936
  episode_reward_max: 294.80808080808106
  episode_reward_mean: 238.66596343178608
  episode_reward_min: 137.98989898989862
  episodes_this_iter: 162
  episodes_total: 3002
  experiment_id: f6c01053906b4e4493539028ac8806cd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 0.9185355405012766
        entropy_coeff: 0.0005000000000000001
        kl: 0.007524380072330435
        model: {}
        policy_loss: -0.01612155915548404
        total_loss: 10.858510653177897
        vf_explained_var: 0.9787821769714355
        vf_loss: 10.87283452351888
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.71111111111111
    gpu_util_percent0: 0.4077777777777778
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7861111111111123
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47436
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15299873723232552
    mean_env_wait_ms: 1.1813156001864487
    mean_inference_ms: 4.695686708556633
    mean_raw_obs_processing_ms: 0.4021813753551272
  time_since_restore: 472.0602126121521
  time_this_iter_s: 29.510890245437622
  time_total_s: 472.0602126121521
  timers:
    learn_throughput: 7240.182
    learn_time_ms: 22346.398
    sample_throughput: 23624.705
    sample_time_ms: 6848.424
    update_time_ms: 31.605
  timestamp: 1602464000
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 345e0_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_345e0_00000 | RUNNING  | 172.17.0.4:47436 |     16 |           472.06 | 2588672 |  238.666 |              294.808 |               137.99 |            842.216 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_345e0_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3478.184227330779
    time_step_min: 3121
  date: 2020-10-12_00-53-49
  done: false
  episode_len_mean: 840.3145569620253
  episode_reward_max: 294.80808080808106
  episode_reward_mean: 239.5967267612836
  episode_reward_min: 137.98989898989862
  episodes_this_iter: 158
  episodes_total: 3160
  experiment_id: f6c01053906b4e4493539028ac8806cd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 0.9025567024946213
        entropy_coeff: 0.0005000000000000001
        kl: 0.008413400229377052
        model: {}
        policy_loss: -0.017192933126352727
        total_loss: 10.977550268173218
        vf_explained_var: 0.978069007396698
        vf_loss: 10.99267061551412
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.3
    gpu_util_percent0: 0.3651428571428571
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.791428571428572
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47436
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1527625120127001
    mean_env_wait_ms: 1.182004415257509
    mean_inference_ms: 4.68053304093452
    mean_raw_obs_processing_ms: 0.4013356904513806
  time_since_restore: 501.4114582538605
  time_this_iter_s: 29.351245641708374
  time_total_s: 501.4114582538605
  timers:
    learn_throughput: 7236.559
    learn_time_ms: 22357.587
    sample_throughput: 23732.612
    sample_time_ms: 6817.286
    update_time_ms: 29.181
  timestamp: 1602464029
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 345e0_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_345e0_00000 | RUNNING  | 172.17.0.4:47436 |     17 |          501.411 | 2750464 |  239.597 |              294.808 |               137.99 |            840.315 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_345e0_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3469.714159292035
    time_step_min: 3121
  date: 2020-10-12_00-54-19
  done: false
  episode_len_mean: 837.4698654183733
  episode_reward_max: 294.80808080808106
  episode_reward_mean: 240.8820297769975
  episode_reward_min: 137.98989898989862
  episodes_this_iter: 258
  episodes_total: 3418
  experiment_id: f6c01053906b4e4493539028ac8806cd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 0.8680883149305979
        entropy_coeff: 0.0005000000000000001
        kl: 0.007989299017935991
        model: {}
        policy_loss: -0.016737083322368562
        total_loss: 17.22478421529134
        vf_explained_var: 0.9754977822303772
        vf_loss: 17.23955790201823
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.26285714285714
    gpu_util_percent0: 0.394
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7685714285714287
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47436
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.152420009715658
    mean_env_wait_ms: 1.183183555118103
    mean_inference_ms: 4.658412854906427
    mean_raw_obs_processing_ms: 0.40012677940317487
  time_since_restore: 530.5832307338715
  time_this_iter_s: 29.171772480010986
  time_total_s: 530.5832307338715
  timers:
    learn_throughput: 7234.093
    learn_time_ms: 22365.209
    sample_throughput: 23758.02
    sample_time_ms: 6809.995
    update_time_ms: 28.556
  timestamp: 1602464059
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 345e0_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_345e0_00000 | RUNNING  | 172.17.0.4:47436 |     18 |          530.583 | 2912256 |  240.882 |              294.808 |               137.99 |             837.47 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_345e0_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3463.2785793562707
    time_step_min: 3121
  date: 2020-10-12_00-54-48
  done: false
  episode_len_mean: 835.4920154185022
  episode_reward_max: 294.80808080808106
  episode_reward_mean: 241.857248142215
  episode_reward_min: 137.98989898989862
  episodes_this_iter: 214
  episodes_total: 3632
  experiment_id: f6c01053906b4e4493539028ac8806cd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 0.8695576190948486
        entropy_coeff: 0.0005000000000000001
        kl: 0.008117443261047205
        model: {}
        policy_loss: -0.015923517329307895
        total_loss: 10.550395727157593
        vf_explained_var: 0.9820896983146667
        vf_loss: 10.564318736394247
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.922222222222224
    gpu_util_percent0: 0.3244444444444444
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7777777777777786
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47436
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15215567144073255
    mean_env_wait_ms: 1.1839981187828224
    mean_inference_ms: 4.641429103170416
    mean_raw_obs_processing_ms: 0.399202998454737
  time_since_restore: 559.9650430679321
  time_this_iter_s: 29.38181233406067
  time_total_s: 559.9650430679321
  timers:
    learn_throughput: 7222.389
    learn_time_ms: 22401.451
    sample_throughput: 23851.558
    sample_time_ms: 6783.289
    update_time_ms: 28.83
  timestamp: 1602464088
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 345e0_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_345e0_00000 | RUNNING  | 172.17.0.4:47436 |     19 |          559.965 | 3074048 |  241.857 |              294.808 |               137.99 |            835.492 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_345e0_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3457.942348565356
    time_step_min: 3121
  date: 2020-10-12_00-55-18
  done: false
  episode_len_mean: 834.2584388185654
  episode_reward_max: 294.80808080808106
  episode_reward_mean: 242.6137082853854
  episode_reward_min: 137.98989898989862
  episodes_this_iter: 160
  episodes_total: 3792
  experiment_id: f6c01053906b4e4493539028ac8806cd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 0.864985778927803
        entropy_coeff: 0.0005000000000000001
        kl: 0.008597165889417132
        model: {}
        policy_loss: -0.015313343309874957
        total_loss: 9.74034825960795
        vf_explained_var: 0.9802703857421875
        vf_loss: 9.753514687220255
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.485714285714284
    gpu_util_percent0: 0.4000000000000001
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.791428571428572
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47436
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15197613758798725
    mean_env_wait_ms: 1.1845766902881472
    mean_inference_ms: 4.629886646949476
    mean_raw_obs_processing_ms: 0.3985716787427595
  time_since_restore: 589.2529845237732
  time_this_iter_s: 29.287941455841064
  time_total_s: 589.2529845237732
  timers:
    learn_throughput: 7223.145
    learn_time_ms: 22399.108
    sample_throughput: 23802.182
    sample_time_ms: 6797.36
    update_time_ms: 31.024
  timestamp: 1602464118
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 345e0_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_345e0_00000 | RUNNING  | 172.17.0.4:47436 |     20 |          589.253 | 3235840 |  242.614 |              294.808 |               137.99 |            834.258 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_345e0_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3453.922391857506
    time_step_min: 3121
  date: 2020-10-12_00-55-47
  done: true
  episode_len_mean: 833.4047498736736
  episode_reward_max: 294.80808080808106
  episode_reward_mean: 243.15963577156091
  episode_reward_min: 137.98989898989862
  episodes_this_iter: 166
  episodes_total: 3958
  experiment_id: f6c01053906b4e4493539028ac8806cd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 0.8350698401530584
        entropy_coeff: 0.0005000000000000001
        kl: 0.009108915032508472
        model: {}
        policy_loss: -0.015712019987404346
        total_loss: 10.455434004465738
        vf_explained_var: 0.9813240170478821
        vf_loss: 10.468830903371176
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.177142857142858
    gpu_util_percent0: 0.3402857142857143
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7800000000000002
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47436
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15179945344185877
    mean_env_wait_ms: 1.1851483591129843
    mean_inference_ms: 4.618588088770536
    mean_raw_obs_processing_ms: 0.3979463193665
  time_since_restore: 618.3314800262451
  time_this_iter_s: 29.078495502471924
  time_total_s: 618.3314800262451
  timers:
    learn_throughput: 7228.406
    learn_time_ms: 22382.804
    sample_throughput: 23762.32
    sample_time_ms: 6808.763
    update_time_ms: 31.609
  timestamp: 1602464147
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: 345e0_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_345e0_00000 | TERMINATED |       |     21 |          618.331 | 3397632 |   243.16 |              294.808 |               137.99 |            833.405 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_345e0_00000 | TERMINATED |       |     21 |          618.331 | 3397632 |   243.16 |              294.808 |               137.99 |            833.405 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


