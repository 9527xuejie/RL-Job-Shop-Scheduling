2020-10-12 15:54:29,045	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_36ca6_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=53896)[0m 2020-10-12 15:54:31,825	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=53874)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53874)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53852)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53852)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53844)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53844)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53880)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53880)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53862)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53862)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53887)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53887)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53870)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53870)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53891)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53891)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53827)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53827)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53858)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53858)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53837)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53837)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53855)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53855)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53830)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53830)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53839)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53839)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53834)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53834)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53893)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53893)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53756)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53756)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53836)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53836)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53828)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53828)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53899)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53899)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53760)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53760)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53859)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53859)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53826)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53826)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53777)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53777)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53816)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53816)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53757)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53757)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53795)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53795)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53788)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53788)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53841)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53841)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53829)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53829)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53785)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53785)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53831)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53831)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53763)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53763)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53790)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53790)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53758)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53758)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53845)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53845)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53787)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53787)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53759)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53759)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53784)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53784)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53766)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53766)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53868)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53868)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53823)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53823)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53775)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53775)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53771)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53771)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53773)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53773)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53833)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53833)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53832)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53832)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53869)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53869)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53890)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53890)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53755)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53755)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53761)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53761)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53877)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53877)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53789)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53789)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53764)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53764)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53767)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53767)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53840)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53840)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53772)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53772)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53822)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53822)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53873)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53873)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53812)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53812)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53863)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53863)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53781)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53781)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53774)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53774)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53882)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53882)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53765)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53765)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53866)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53866)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53835)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53835)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53895)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53895)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53814)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53814)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53824)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53824)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53779)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53779)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53792)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53792)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53850)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53850)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53768)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53768)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53878)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53878)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53794)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53794)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53838)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53838)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53819)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53819)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=53843)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=53843)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_36ca6_00000:
  custom_metrics:
    time_step_max: 3691
    time_step_mean: 3418.869230769231
    time_step_min: 3176
  date: 2020-10-12_15-55-06
  done: false
  episode_len_mean: 886.753164556962
  episode_reward_max: 282.343434343434
  episode_reward_mean: 241.94642628819824
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 15977362134b4f9b82743425ad3e8c1e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1849032640457153
        entropy_coeff: 0.0005000000000000001
        kl: 0.004784370268074174
        model: {}
        policy_loss: -0.008921080657576871
        total_loss: 488.36802927652997
        vf_explained_var: 0.49538537859916687
        vf_loss: 488.3765920003255
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.21470588235294
    gpu_util_percent0: 0.27705882352941175
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5647058823529414
    vram_util_percent0: 0.08636872262844136
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 53896
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1709903394340475
    mean_env_wait_ms: 1.1551793043390397
    mean_inference_ms: 6.025685828274582
    mean_raw_obs_processing_ms: 0.4640582668519971
  time_since_restore: 29.185962915420532
  time_this_iter_s: 29.185962915420532
  time_total_s: 29.185962915420532
  timers:
    learn_throughput: 8291.278
    learn_time_ms: 19513.518
    sample_throughput: 16874.899
    sample_time_ms: 9587.732
    update_time_ms: 47.3
  timestamp: 1602518106
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 36ca6_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36ca6_00000 | RUNNING  | 172.17.0.4:53896 |      1 |           29.186 | 161792 |  241.946 |              282.343 |              165.677 |            886.753 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36ca6_00000:
  custom_metrics:
    time_step_max: 3759
    time_step_mean: 3440.1076388888887
    time_step_min: 3176
  date: 2020-10-12_15-55-33
  done: false
  episode_len_mean: 883.6139240506329
  episode_reward_max: 282.343434343434
  episode_reward_mean: 240.93616545198802
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 15977362134b4f9b82743425ad3e8c1e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1520658334096272
        entropy_coeff: 0.0005000000000000001
        kl: 0.00744400251035889
        model: {}
        policy_loss: -0.009384491364471614
        total_loss: 127.12748146057129
        vf_explained_var: 0.7977762818336487
        vf_loss: 127.13669649759929
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.340625000000003
    gpu_util_percent0: 0.2840625
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7531250000000003
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 53896
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16665598261411857
    mean_env_wait_ms: 1.152540360201219
    mean_inference_ms: 5.752484708411441
    mean_raw_obs_processing_ms: 0.4511592906816358
  time_since_restore: 56.60361957550049
  time_this_iter_s: 27.417656660079956
  time_total_s: 56.60361957550049
  timers:
    learn_throughput: 8275.067
    learn_time_ms: 19551.746
    sample_throughput: 18687.768
    sample_time_ms: 8657.642
    update_time_ms: 45.539
  timestamp: 1602518133
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 36ca6_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36ca6_00000 | RUNNING  | 172.17.0.4:53896 |      2 |          56.6036 | 323584 |  240.936 |              282.343 |              165.677 |            883.614 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36ca6_00000:
  custom_metrics:
    time_step_max: 3906
    time_step_mean: 3441.580717488789
    time_step_min: 3176
  date: 2020-10-12_15-56-00
  done: false
  episode_len_mean: 879.1814345991561
  episode_reward_max: 282.343434343434
  episode_reward_mean: 241.48644674594024
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 15977362134b4f9b82743425ad3e8c1e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1369050244490306
        entropy_coeff: 0.0005000000000000001
        kl: 0.011053523048758507
        model: {}
        policy_loss: -0.012346668188304951
        total_loss: 52.218987782796226
        vf_explained_var: 0.8901453614234924
        vf_loss: 52.23079872131348
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.822580645161295
    gpu_util_percent0: 0.33999999999999997
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 53896
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16368535461416475
    mean_env_wait_ms: 1.1517789807439969
    mean_inference_ms: 5.540083011416139
    mean_raw_obs_processing_ms: 0.44184919997907823
  time_since_restore: 83.42736053466797
  time_this_iter_s: 26.82374095916748
  time_total_s: 83.42736053466797
  timers:
    learn_throughput: 8285.13
    learn_time_ms: 19527.998
    sample_throughput: 19756.6
    sample_time_ms: 8189.263
    update_time_ms: 43.315
  timestamp: 1602518160
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 36ca6_00000
  
== Status ==
Memory usage on this node: 28.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36ca6_00000 | RUNNING  | 172.17.0.4:53896 |      3 |          83.4274 | 485376 |  241.486 |              282.343 |              165.677 |            879.181 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36ca6_00000:
  custom_metrics:
    time_step_max: 3906
    time_step_mean: 3438.958609271523
    time_step_min: 3176
  date: 2020-10-12_15-56-27
  done: false
  episode_len_mean: 875.8180379746835
  episode_reward_max: 286.13131313131294
  episode_reward_mean: 242.47984592763052
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 15977362134b4f9b82743425ad3e8c1e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1127794881661732
        entropy_coeff: 0.0005000000000000001
        kl: 0.009236348637690147
        model: {}
        policy_loss: -0.01357063123335441
        total_loss: 39.06841214497884
        vf_explained_var: 0.9182509779930115
        vf_loss: 39.08161576588949
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.661290322580644
    gpu_util_percent0: 0.32129032258064505
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7677419354838704
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 53896
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16156825770839872
    mean_env_wait_ms: 1.1518694470326245
    mean_inference_ms: 5.386059716543504
    mean_raw_obs_processing_ms: 0.4346403727296637
  time_since_restore: 110.0738275051117
  time_this_iter_s: 26.646466970443726
  time_total_s: 110.0738275051117
  timers:
    learn_throughput: 8309.156
    learn_time_ms: 19471.533
    sample_throughput: 20340.596
    sample_time_ms: 7954.143
    update_time_ms: 42.022
  timestamp: 1602518187
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 36ca6_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36ca6_00000 | RUNNING  | 172.17.0.4:53896 |      4 |          110.074 | 647168 |   242.48 |              286.131 |              165.677 |            875.818 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36ca6_00000:
  custom_metrics:
    time_step_max: 3906
    time_step_mean: 3433.030183727034
    time_step_min: 3154
  date: 2020-10-12_15-56-54
  done: false
  episode_len_mean: 871.8582278481013
  episode_reward_max: 286.13131313131294
  episode_reward_mean: 243.81274773046908
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 15977362134b4f9b82743425ad3e8c1e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.075794368982315
        entropy_coeff: 0.0005000000000000001
        kl: 0.007777562830597162
        model: {}
        policy_loss: -0.011302593076834455
        total_loss: 29.236744085947674
        vf_explained_var: 0.947382390499115
        vf_loss: 29.247807184855144
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.12903225806452
    gpu_util_percent0: 0.2825806451612904
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322577
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 53896
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1599463386034476
    mean_env_wait_ms: 1.1528680661386046
    mean_inference_ms: 5.26985637904323
    mean_raw_obs_processing_ms: 0.4289535994172319
  time_since_restore: 136.83810353279114
  time_this_iter_s: 26.764276027679443
  time_total_s: 136.83810353279114
  timers:
    learn_throughput: 8305.525
    learn_time_ms: 19480.044
    sample_throughput: 20753.945
    sample_time_ms: 7795.723
    update_time_ms: 41.162
  timestamp: 1602518214
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 36ca6_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36ca6_00000 | RUNNING  | 172.17.0.4:53896 |      5 |          136.838 | 808960 |  243.813 |              286.131 |              165.677 |            871.858 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36ca6_00000:
  custom_metrics:
    time_step_max: 3906
    time_step_mean: 3423.0584415584417
    time_step_min: 3154
  date: 2020-10-12_15-57-20
  done: false
  episode_len_mean: 861.6636528028934
  episode_reward_max: 287.7979797979799
  episode_reward_mean: 245.7200577200576
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 316
  episodes_total: 1106
  experiment_id: 15977362134b4f9b82743425ad3e8c1e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0736831625302632
        entropy_coeff: 0.0005000000000000001
        kl: 0.00783942472965767
        model: {}
        policy_loss: -0.010518070853625735
        total_loss: 27.994863510131836
        vf_explained_var: 0.9606881737709045
        vf_loss: 28.00513442357381
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.9741935483871
    gpu_util_percent0: 0.3696774193548387
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 53896
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15771594206221334
    mean_env_wait_ms: 1.1560755820147435
    mean_inference_ms: 5.111517495894029
    mean_raw_obs_processing_ms: 0.42142289686541984
  time_since_restore: 163.26222133636475
  time_this_iter_s: 26.42411780357361
  time_total_s: 163.26222133636475
  timers:
    learn_throughput: 8314.951
    learn_time_ms: 19457.961
    sample_throughput: 21114.209
    sample_time_ms: 7662.707
    update_time_ms: 39.065
  timestamp: 1602518240
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 36ca6_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36ca6_00000 | RUNNING  | 172.17.0.4:53896 |      6 |          163.262 | 970752 |   245.72 |              287.798 |              165.677 |            861.664 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36ca6_00000:
  custom_metrics:
    time_step_max: 3906
    time_step_mean: 3417.413430420712
    time_step_min: 3154
  date: 2020-10-12_15-57-47
  done: false
  episode_len_mean: 856.7879746835443
  episode_reward_max: 290.6767676767679
  episode_reward_mean: 246.58477975962143
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: 15977362134b4f9b82743425ad3e8c1e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.053666094938914
        entropy_coeff: 0.0005000000000000001
        kl: 0.00802672584541142
        model: {}
        policy_loss: -0.011159917781090675
        total_loss: 19.830265998840332
        vf_explained_var: 0.9614474773406982
        vf_loss: 19.841150124867756
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.07096774193549
    gpu_util_percent0: 0.3093548387096774
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.783870967741935
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 53896
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1569188186774967
    mean_env_wait_ms: 1.1574747546062651
    mean_inference_ms: 5.0541867701624925
    mean_raw_obs_processing_ms: 0.41864557816679143
  time_since_restore: 189.84946727752686
  time_this_iter_s: 26.58724594116211
  time_total_s: 189.84946727752686
  timers:
    learn_throughput: 8313.466
    learn_time_ms: 19461.437
    sample_throughput: 21373.484
    sample_time_ms: 7569.753
    update_time_ms: 38.265
  timestamp: 1602518267
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 36ca6_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36ca6_00000 | RUNNING  | 172.17.0.4:53896 |      7 |          189.849 | 1132544 |  246.585 |              290.677 |              165.677 |            856.788 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36ca6_00000:
  custom_metrics:
    time_step_max: 3906
    time_step_mean: 3414.711621233859
    time_step_min: 3154
  date: 2020-10-12_15-58-13
  done: false
  episode_len_mean: 853.1174402250351
  episode_reward_max: 290.6767676767679
  episode_reward_mean: 246.98339939479166
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 15977362134b4f9b82743425ad3e8c1e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0378634532292683
        entropy_coeff: 0.0005000000000000001
        kl: 0.006901592792322238
        model: {}
        policy_loss: -0.010785317203650871
        total_loss: 20.057416280110676
        vf_explained_var: 0.9610694050788879
        vf_loss: 20.06803019841512
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.069999999999997
    gpu_util_percent0: 0.32166666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7833333333333328
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 53896
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15622067538209256
    mean_env_wait_ms: 1.1587791450492089
    mean_inference_ms: 5.0040616747316395
    mean_raw_obs_processing_ms: 0.4161319218221481
  time_since_restore: 215.99336576461792
  time_this_iter_s: 26.143898487091064
  time_total_s: 215.99336576461792
  timers:
    learn_throughput: 8327.525
    learn_time_ms: 19428.581
    sample_throughput: 21627.418
    sample_time_ms: 7480.875
    update_time_ms: 38.041
  timestamp: 1602518293
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 36ca6_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36ca6_00000 | RUNNING  | 172.17.0.4:53896 |      8 |          215.993 | 1294336 |  246.983 |              290.677 |              165.677 |            853.117 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36ca6_00000:
  custom_metrics:
    time_step_max: 3906
    time_step_mean: 3409.408622908623
    time_step_min: 3154
  date: 2020-10-12_15-58-39
  done: false
  episode_len_mean: 849.3470290771176
  episode_reward_max: 292.79797979797934
  episode_reward_mean: 247.87210920839226
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 160
  episodes_total: 1582
  experiment_id: 15977362134b4f9b82743425ad3e8c1e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9882466793060303
        entropy_coeff: 0.0005000000000000001
        kl: 0.0072092009941115975
        model: {}
        policy_loss: -0.0129079805725875
        total_loss: 17.17254622777303
        vf_explained_var: 0.9699942469596863
        vf_loss: 17.185227394104004
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.40666666666667
    gpu_util_percent0: 0.2793333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7633333333333328
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 53896
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.155594340231264
    mean_env_wait_ms: 1.1603174092875947
    mean_inference_ms: 4.959447601649163
    mean_raw_obs_processing_ms: 0.41381818172873613
  time_since_restore: 242.0682258605957
  time_this_iter_s: 26.074860095977783
  time_total_s: 242.0682258605957
  timers:
    learn_throughput: 8340.615
    learn_time_ms: 19398.091
    sample_throughput: 21838.709
    sample_time_ms: 7408.496
    update_time_ms: 38.369
  timestamp: 1602518319
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 36ca6_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36ca6_00000 | RUNNING  | 172.17.0.4:53896 |      9 |          242.068 | 1456128 |  247.872 |              292.798 |              165.677 |            849.347 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36ca6_00000:
  custom_metrics:
    time_step_max: 3906
    time_step_mean: 3399.7323340471094
    time_step_min: 3102
  date: 2020-10-12_15-59-06
  done: false
  episode_len_mean: 842.037447257384
  episode_reward_max: 295.07070707070704
  episode_reward_mean: 249.20564825469876
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 314
  episodes_total: 1896
  experiment_id: 15977362134b4f9b82743425ad3e8c1e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9735767543315887
        entropy_coeff: 0.0005000000000000001
        kl: 0.0065773469395935535
        model: {}
        policy_loss: -0.011116733350415112
        total_loss: 21.422983805338543
        vf_explained_var: 0.9707332253456116
        vf_loss: 21.43393023808797
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.080645161290327
    gpu_util_percent0: 0.3925806451612903
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.761290322580645
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 53896
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15460431137449884
    mean_env_wait_ms: 1.1633245089151933
    mean_inference_ms: 4.888414302574512
    mean_raw_obs_processing_ms: 0.41022299854503697
  time_since_restore: 268.48336362838745
  time_this_iter_s: 26.415137767791748
  time_total_s: 268.48336362838745
  timers:
    learn_throughput: 8345.14
    learn_time_ms: 19387.572
    sample_throughput: 21954.252
    sample_time_ms: 7369.506
    update_time_ms: 38.739
  timestamp: 1602518346
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 36ca6_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36ca6_00000 | RUNNING  | 172.17.0.4:53896 |     10 |          268.483 | 1617920 |  249.206 |              295.071 |              165.677 |            842.037 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36ca6_00000:
  custom_metrics:
    time_step_max: 3906
    time_step_mean: 3394.6860809476802
    time_step_min: 3102
  date: 2020-10-12_15-59-32
  done: false
  episode_len_mean: 838.7770204479066
  episode_reward_max: 295.07070707070704
  episode_reward_mean: 250.0402417554315
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: 15977362134b4f9b82743425ad3e8c1e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9505527665217718
        entropy_coeff: 0.0005000000000000001
        kl: 0.006363538365500669
        model: {}
        policy_loss: -0.010260378786673149
        total_loss: 13.269665638605753
        vf_explained_var: 0.974217414855957
        vf_loss: 13.279764652252197
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.867741935483874
    gpu_util_percent0: 0.3596774193548387
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.783870967741935
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 53896
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15419184861852228
    mean_env_wait_ms: 1.164648731916935
    mean_inference_ms: 4.858946093479226
    mean_raw_obs_processing_ms: 0.40871369628427384
  time_since_restore: 294.8563377857208
  time_this_iter_s: 26.372974157333374
  time_total_s: 294.8563377857208
  timers:
    learn_throughput: 8353.03
    learn_time_ms: 19369.259
    sample_throughput: 22777.53
    sample_time_ms: 7103.141
    update_time_ms: 37.856
  timestamp: 1602518372
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 36ca6_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36ca6_00000 | RUNNING  | 172.17.0.4:53896 |     11 |          294.856 | 1779712 |   250.04 |              295.071 |              165.677 |            838.777 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36ca6_00000:
  custom_metrics:
    time_step_max: 3906
    time_step_mean: 3389.5119047619046
    time_step_min: 3102
  date: 2020-10-12_15-59-59
  done: false
  episode_len_mean: 835.617088607595
  episode_reward_max: 295.07070707070704
  episode_reward_mean: 250.86917547993488
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 15977362134b4f9b82743425ad3e8c1e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9334837744633356
        entropy_coeff: 0.0005000000000000001
        kl: 0.006569515137622754
        model: {}
        policy_loss: -0.012398959409135083
        total_loss: 11.898517767588297
        vf_explained_var: 0.9744560122489929
        vf_loss: 11.910726388295492
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.066666666666666
    gpu_util_percent0: 0.3853333333333334
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7866666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 53896
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1538148374684384
    mean_env_wait_ms: 1.165974789172853
    mean_inference_ms: 4.832143105080463
    mean_raw_obs_processing_ms: 0.40729081412210666
  time_since_restore: 321.1194977760315
  time_this_iter_s: 26.26315999031067
  time_total_s: 321.1194977760315
  timers:
    learn_throughput: 8366.707
    learn_time_ms: 19337.597
    sample_throughput: 23043.947
    sample_time_ms: 7021.02
    update_time_ms: 36.629
  timestamp: 1602518399
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 36ca6_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36ca6_00000 | RUNNING  | 172.17.0.4:53896 |     12 |          321.119 | 1941504 |  250.869 |              295.071 |              165.677 |            835.617 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36ca6_00000:
  custom_metrics:
    time_step_max: 3906
    time_step_mean: 3380.3735772357722
    time_step_min: 3102
  date: 2020-10-12_16-00-25
  done: false
  episode_len_mean: 830.5144694533763
  episode_reward_max: 295.07070707070704
  episode_reward_mean: 252.2050123420701
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 276
  episodes_total: 2488
  experiment_id: 15977362134b4f9b82743425ad3e8c1e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8941035866737366
        entropy_coeff: 0.0005000000000000001
        kl: 0.006269749913675089
        model: {}
        policy_loss: -0.00925206916872412
        total_loss: 16.93541383743286
        vf_explained_var: 0.9757897853851318
        vf_loss: 16.944485187530518
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.900000000000002
    gpu_util_percent0: 0.2703225806451613
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322577
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 53896
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15324187236309547
    mean_env_wait_ms: 1.1684932453027022
    mean_inference_ms: 4.791049202473926
    mean_raw_obs_processing_ms: 0.40515660067825937
  time_since_restore: 347.6027443408966
  time_this_iter_s: 26.483246564865112
  time_total_s: 347.6027443408966
  timers:
    learn_throughput: 8370.747
    learn_time_ms: 19328.263
    sample_throughput: 23122.013
    sample_time_ms: 6997.315
    update_time_ms: 35.092
  timestamp: 1602518425
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 36ca6_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36ca6_00000 | RUNNING  | 172.17.0.4:53896 |     13 |          347.603 | 2103296 |  252.205 |              295.071 |              165.677 |            830.514 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36ca6_00000:
  custom_metrics:
    time_step_max: 3906
    time_step_mean: 3372.4428141459744
    time_step_min: 3102
  date: 2020-10-12_16-00-52
  done: false
  episode_len_mean: 827.0316455696203
  episode_reward_max: 295.07070707070704
  episode_reward_mean: 253.20390050918706
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 198
  episodes_total: 2686
  experiment_id: 15977362134b4f9b82743425ad3e8c1e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8781916697820028
        entropy_coeff: 0.0005000000000000001
        kl: 0.006277749276099105
        model: {}
        policy_loss: -0.011392164584928347
        total_loss: 12.567232608795166
        vf_explained_var: 0.9758232235908508
        vf_loss: 12.578436215718588
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.59354838709678
    gpu_util_percent0: 0.3167741935483871
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.770967741935483
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 53896
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15288923841810342
    mean_env_wait_ms: 1.1699827746705296
    mean_inference_ms: 4.7661547465869
    mean_raw_obs_processing_ms: 0.4038238009855732
  time_since_restore: 374.08534693717957
  time_this_iter_s: 26.48260259628296
  time_total_s: 374.08534693717957
  timers:
    learn_throughput: 8373.26
    learn_time_ms: 19322.462
    sample_throughput: 23181.274
    sample_time_ms: 6979.427
    update_time_ms: 40.915
  timestamp: 1602518452
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 36ca6_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36ca6_00000 | RUNNING  | 172.17.0.4:53896 |     14 |          374.085 | 2265088 |  253.204 |              295.071 |              165.677 |            827.032 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36ca6_00000:
  custom_metrics:
    time_step_max: 3906
    time_step_mean: 3367.6711647727275
    time_step_min: 3102
  date: 2020-10-12_16-01-18
  done: false
  episode_len_mean: 824.3741209563995
  episode_reward_max: 295.07070707070704
  episode_reward_mean: 253.88053531091498
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: 15977362134b4f9b82743425ad3e8c1e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8726825912793478
        entropy_coeff: 0.0005000000000000001
        kl: 0.005345542721139888
        model: {}
        policy_loss: -0.01224327425006777
        total_loss: 12.99477251370748
        vf_explained_var: 0.971616268157959
        vf_loss: 13.006917715072632
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.716666666666665
    gpu_util_percent0: 0.4033333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.78
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 53896
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15263237296789114
    mean_env_wait_ms: 1.1711629992327353
    mean_inference_ms: 4.747831464459137
    mean_raw_obs_processing_ms: 0.40283740122675993
  time_since_restore: 400.40739703178406
  time_this_iter_s: 26.322050094604492
  time_total_s: 400.40739703178406
  timers:
    learn_throughput: 8381.848
    learn_time_ms: 19302.664
    sample_throughput: 23268.414
    sample_time_ms: 6953.289
    update_time_ms: 41.457
  timestamp: 1602518478
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 36ca6_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36ca6_00000 | RUNNING  | 172.17.0.4:53896 |     15 |          400.407 | 2426880 |  253.881 |              295.071 |              165.677 |            824.374 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36ca6_00000:
  custom_metrics:
    time_step_max: 3906
    time_step_mean: 3361.8309258043337
    time_step_min: 3102
  date: 2020-10-12_16-01-45
  done: false
  episode_len_mean: 820.5810019518542
  episode_reward_max: 295.07070707070704
  episode_reward_mean: 254.76314215676598
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 230
  episodes_total: 3074
  experiment_id: 15977362134b4f9b82743425ad3e8c1e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.832097460826238
        entropy_coeff: 0.0005000000000000001
        kl: 0.005490843905135989
        model: {}
        policy_loss: -0.010333318127474437
        total_loss: 13.920937776565552
        vf_explained_var: 0.9784757494926453
        vf_loss: 13.931138038635254
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.14193548387097
    gpu_util_percent0: 0.2803225806451613
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7677419354838704
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 53896
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1522977939135001
    mean_env_wait_ms: 1.1729858563681044
    mean_inference_ms: 4.723501160677559
    mean_raw_obs_processing_ms: 0.4015396013523361
  time_since_restore: 426.90421438217163
  time_this_iter_s: 26.496817350387573
  time_total_s: 426.90421438217163
  timers:
    learn_throughput: 8380.177
    learn_time_ms: 19306.512
    sample_throughput: 23268.112
    sample_time_ms: 6953.379
    update_time_ms: 42.344
  timestamp: 1602518505
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 36ca6_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36ca6_00000 | RUNNING  | 172.17.0.4:53896 |     16 |          426.904 | 2588672 |  254.763 |              295.071 |              165.677 |            820.581 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36ca6_00000:
  custom_metrics:
    time_step_max: 3906
    time_step_mean: 3354.8726443768996
    time_step_min: 3076
  date: 2020-10-12_16-02-11
  done: false
  episode_len_mean: 817.1323086196504
  episode_reward_max: 297.49494949494914
  episode_reward_mean: 255.8385116992711
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 244
  episodes_total: 3318
  experiment_id: 15977362134b4f9b82743425ad3e8c1e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8182818094889323
        entropy_coeff: 0.0005000000000000001
        kl: 0.005390155672406157
        model: {}
        policy_loss: -0.008973776893981267
        total_loss: 10.671323935190836
        vf_explained_var: 0.9803421497344971
        vf_loss: 10.68016799290975
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.15806451612903
    gpu_util_percent0: 0.3803225806451613
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.770967741935483
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 53896
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15197021346044498
    mean_env_wait_ms: 1.1746817923841757
    mean_inference_ms: 4.70082620474763
    mean_raw_obs_processing_ms: 0.40031116270094547
  time_since_restore: 453.12146282196045
  time_this_iter_s: 26.21724843978882
  time_total_s: 453.12146282196045
  timers:
    learn_throughput: 8392.234
    learn_time_ms: 19278.777
    sample_throughput: 23301.007
    sample_time_ms: 6943.563
    update_time_ms: 43.058
  timestamp: 1602518531
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 36ca6_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36ca6_00000 | RUNNING  | 172.17.0.4:53896 |     17 |          453.121 | 2750464 |  255.839 |              297.495 |              165.677 |            817.132 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36ca6_00000:
  custom_metrics:
    time_step_max: 3906
    time_step_mean: 3350.8645591647332
    time_step_min: 3076
  date: 2020-10-12_16-02-38
  done: false
  episode_len_mean: 815.0719217491369
  episode_reward_max: 297.49494949494914
  episode_reward_mean: 256.3523962292661
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 158
  episodes_total: 3476
  experiment_id: 15977362134b4f9b82743425ad3e8c1e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8158556421597799
        entropy_coeff: 0.0005000000000000001
        kl: 0.005813289627743264
        model: {}
        policy_loss: -0.01080344397147807
        total_loss: 9.102331479390463
        vf_explained_var: 0.979426383972168
        vf_loss: 9.112961610158285
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.67666666666667
    gpu_util_percent0: 0.2943333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.776666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 53896
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15177938188918702
    mean_env_wait_ms: 1.1757522261296356
    mean_inference_ms: 4.6873733926230585
    mean_raw_obs_processing_ms: 0.39958732653118906
  time_since_restore: 479.319815158844
  time_this_iter_s: 26.198352336883545
  time_total_s: 479.319815158844
  timers:
    learn_throughput: 8395.264
    learn_time_ms: 19271.817
    sample_throughput: 23264.119
    sample_time_ms: 6954.572
    update_time_ms: 43.479
  timestamp: 1602518558
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 36ca6_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36ca6_00000 | RUNNING  | 172.17.0.4:53896 |     18 |           479.32 | 2912256 |  256.352 |              297.495 |              165.677 |            815.072 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36ca6_00000:
  custom_metrics:
    time_step_max: 3906
    time_step_mean: 3346.2407103825135
    time_step_min: 3076
  date: 2020-10-12_16-03-04
  done: false
  episode_len_mean: 812.5924620390456
  episode_reward_max: 298.2525252525252
  episode_reward_mean: 256.9936101798899
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 212
  episodes_total: 3688
  experiment_id: 15977362134b4f9b82743425ad3e8c1e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.783480112751325
        entropy_coeff: 0.0005000000000000001
        kl: 0.005505596792014937
        model: {}
        policy_loss: -0.010511156249170503
        total_loss: 13.502816677093506
        vf_explained_var: 0.978053629398346
        vf_loss: 13.513169129689535
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.000000000000004
    gpu_util_percent0: 0.333225806451613
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 53896
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15154610328195095
    mean_env_wait_ms: 1.1772776422719902
    mean_inference_ms: 4.670514142901643
    mean_raw_obs_processing_ms: 0.39870064596722976
  time_since_restore: 505.6347494125366
  time_this_iter_s: 26.314934253692627
  time_total_s: 505.6347494125366
  timers:
    learn_throughput: 8393.741
    learn_time_ms: 19275.314
    sample_throughput: 23192.852
    sample_time_ms: 6975.943
    update_time_ms: 41.508
  timestamp: 1602518584
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 36ca6_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36ca6_00000 | RUNNING  | 172.17.0.4:53896 |     19 |          505.635 | 3074048 |  256.994 |              298.253 |              165.677 |            812.592 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36ca6_00000:
  custom_metrics:
    time_step_max: 3906
    time_step_mean: 3341.0226925038246
    time_step_min: 3076
  date: 2020-10-12_16-03-31
  done: false
  episode_len_mean: 809.9488607594936
  episode_reward_max: 301.4343434343433
  episode_reward_mean: 257.75697481140514
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 262
  episodes_total: 3950
  experiment_id: 15977362134b4f9b82743425ad3e8c1e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7689148386319479
        entropy_coeff: 0.0005000000000000001
        kl: 0.005313604371622205
        model: {}
        policy_loss: -0.010639291993963221
        total_loss: 11.459484736124674
        vf_explained_var: 0.9803845286369324
        vf_loss: 11.469976902008057
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.316129032258065
    gpu_util_percent0: 0.30387096774193556
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322577
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 53896
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15127856569216622
    mean_env_wait_ms: 1.178923328769109
    mean_inference_ms: 4.6519578216673025
    mean_raw_obs_processing_ms: 0.39769159873573273
  time_since_restore: 532.3037974834442
  time_this_iter_s: 26.669048070907593
  time_total_s: 532.3037974834442
  timers:
    learn_throughput: 8389.515
    learn_time_ms: 19285.024
    sample_throughput: 23141.965
    sample_time_ms: 6991.282
    update_time_ms: 41.332
  timestamp: 1602518611
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 36ca6_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36ca6_00000 | RUNNING  | 172.17.0.4:53896 |     20 |          532.304 | 3235840 |  257.757 |              301.434 |              165.677 |            809.949 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36ca6_00000:
  custom_metrics:
    time_step_max: 3906
    time_step_mean: 3338.275
    time_step_min: 3059
  date: 2020-10-12_16-03-57
  done: false
  episode_len_mean: 808.4980525803311
  episode_reward_max: 301.4343434343433
  episode_reward_mean: 258.1885702202157
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 158
  episodes_total: 4108
  experiment_id: 15977362134b4f9b82743425ad3e8c1e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7616968055566152
        entropy_coeff: 0.0005000000000000001
        kl: 0.0063063996300722165
        model: {}
        policy_loss: -0.012424984869236747
        total_loss: 9.233952124913534
        vf_explained_var: 0.9793080687522888
        vf_loss: 9.246127367019653
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.174193548387095
    gpu_util_percent0: 0.312258064516129
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7774193548387096
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 53896
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1511319742586823
    mean_env_wait_ms: 1.179874064402723
    mean_inference_ms: 4.641585216685568
    mean_raw_obs_processing_ms: 0.3971343685122083
  time_since_restore: 558.7777724266052
  time_this_iter_s: 26.47397494316101
  time_total_s: 558.7777724266052
  timers:
    learn_throughput: 8385.269
    learn_time_ms: 19294.789
    sample_throughput: 23134.832
    sample_time_ms: 6993.437
    update_time_ms: 41.5
  timestamp: 1602518637
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: 36ca6_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36ca6_00000 | RUNNING  | 172.17.0.4:53896 |     21 |          558.778 | 3397632 |  258.189 |              301.434 |              165.677 |            808.498 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36ca6_00000:
  custom_metrics:
    time_step_max: 3906
    time_step_mean: 3334.966557530402
    time_step_min: 3059
  date: 2020-10-12_16-04-24
  done: false
  episode_len_mean: 806.9435408921933
  episode_reward_max: 301.4343434343433
  episode_reward_mean: 258.63860022154626
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 196
  episodes_total: 4304
  experiment_id: 15977362134b4f9b82743425ad3e8c1e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7464395960172018
        entropy_coeff: 0.0005000000000000001
        kl: 0.005762962042354047
        model: {}
        policy_loss: -0.011503236756349603
        total_loss: 11.199698448181152
        vf_explained_var: 0.9805458188056946
        vf_loss: 11.210998773574829
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.769999999999996
    gpu_util_percent0: 0.30566666666666664
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.776666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 53896
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1509595676281518
    mean_env_wait_ms: 1.1810865012553036
    mean_inference_ms: 4.629429097188147
    mean_raw_obs_processing_ms: 0.39649016095262407
  time_since_restore: 584.9550654888153
  time_this_iter_s: 26.177293062210083
  time_total_s: 584.9550654888153
  timers:
    learn_throughput: 8393.201
    learn_time_ms: 19276.554
    sample_throughput: 23113.294
    sample_time_ms: 6999.954
    update_time_ms: 42.199
  timestamp: 1602518664
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: 36ca6_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36ca6_00000 | RUNNING  | 172.17.0.4:53896 |     22 |          584.955 | 3559424 |  258.639 |              301.434 |              165.677 |            806.944 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36ca6_00000:
  custom_metrics:
    time_step_max: 3906
    time_step_mean: 3331.2821695213
    time_step_min: 3059
  date: 2020-10-12_16-04-50
  done: true
  episode_len_mean: 804.9172850283719
  episode_reward_max: 301.4343434343433
  episode_reward_mean: 259.23495981200034
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 278
  episodes_total: 4582
  experiment_id: 15977362134b4f9b82743425ad3e8c1e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7183542102575302
        entropy_coeff: 0.0005000000000000001
        kl: 0.005707078341705103
        model: {}
        policy_loss: -0.0085253130334119
        total_loss: 10.668026685714722
        vf_explained_var: 0.9826880097389221
        vf_loss: 10.676340103149414
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.970967741935482
    gpu_util_percent0: 0.2951612903225806
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 53896
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1507442154649067
    mean_env_wait_ms: 1.1826636995359807
    mean_inference_ms: 4.613886349462009
    mean_raw_obs_processing_ms: 0.3956456802675646
  time_since_restore: 611.3645873069763
  time_this_iter_s: 26.40952181816101
  time_total_s: 611.3645873069763
  timers:
    learn_throughput: 8393.152
    learn_time_ms: 19276.668
    sample_throughput: 23146.231
    sample_time_ms: 6989.993
    update_time_ms: 43.84
  timestamp: 1602518690
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: 36ca6_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36ca6_00000 | TERMINATED |       |     23 |          611.365 | 3721216 |  259.235 |              301.434 |              165.677 |            804.917 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36ca6_00000 | TERMINATED |       |     23 |          611.365 | 3721216 |  259.235 |              301.434 |              165.677 |            804.917 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


