2020-10-11 20:18:05,800	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_dfeb0_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=48597)[0m 2020-10-11 20:18:08,590	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=48585)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48585)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48570)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48570)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48567)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48567)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48600)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48600)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48558)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48558)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48598)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48598)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48595)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48595)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48588)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48588)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48591)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48591)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48614)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48614)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48565)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48565)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48535)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48535)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48550)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48550)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48533)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48533)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48596)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48596)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48613)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48613)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48553)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48553)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48617)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48617)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48579)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48579)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48568)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48568)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48480)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48480)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48496)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48496)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48590)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48590)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48509)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48509)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48495)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48495)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48539)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48539)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48500)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48500)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48503)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48503)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48487)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48487)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48531)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48531)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48556)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48556)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48486)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48486)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48587)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48587)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48563)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48563)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48569)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48569)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48491)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48491)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48610)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48610)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48546)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48546)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48489)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48489)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48549)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48549)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48586)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48586)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48517)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48517)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48545)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48545)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48508)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48508)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48581)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48581)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48484)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48484)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48593)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48593)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48494)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48494)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48605)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48605)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48555)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48555)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48584)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48584)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48483)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48483)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48551)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48551)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48560)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48560)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48559)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48559)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48542)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48542)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48554)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48554)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48477)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48477)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48557)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48557)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48599)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48599)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48552)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48552)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48492)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48492)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48513)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48513)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48475)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48475)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48478)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48478)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48481)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48481)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48576)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48576)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48485)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48485)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48493)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48493)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48510)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48510)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48497)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48497)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48548)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48548)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48527)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48527)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48479)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48479)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48507)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48507)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48476)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48476)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48534)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48534)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48488)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48488)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48516)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48516)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_dfeb0_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-11_20-18-42
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 486c986d2ff845b0b26d77aba5b4b507
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1826184193293254
        entropy_coeff: 0.0005000000000000001
        kl: 0.006616147429061432
        model: {}
        policy_loss: -0.008133015158819035
        total_loss: 507.07523854573566
        vf_explained_var: 0.540532648563385
        vf_loss: 507.0832926432292
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.127272727272725
    gpu_util_percent0: 0.3506060606060606
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5606060606060606
    vram_util_percent0: 0.08582297226114873
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48597
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1683247269727301
    mean_env_wait_ms: 1.1628085015989742
    mean_inference_ms: 6.007336148070346
    mean_raw_obs_processing_ms: 0.4543961680719389
  time_since_restore: 28.43995237350464
  time_this_iter_s: 28.43995237350464
  time_total_s: 28.43995237350464
  timers:
    learn_throughput: 8628.213
    learn_time_ms: 18751.508
    sample_throughput: 16823.05
    sample_time_ms: 9617.281
    update_time_ms: 31.059
  timestamp: 1602447522
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: dfeb0_00000
  
== Status ==
Memory usage on this node: 27.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      1 |            28.44 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dfeb0_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3620.503472222222
    time_step_min: 3313
  date: 2020-10-11_20-19-08
  done: false
  episode_len_mean: 889.1613924050633
  episode_reward_max: 265.8686868686868
  episode_reward_mean: 217.79810765886694
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 486c986d2ff845b0b26d77aba5b4b507
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1493095755577087
        entropy_coeff: 0.0005000000000000001
        kl: 0.008436032105237246
        model: {}
        policy_loss: -0.010742687620222569
        total_loss: 128.25170707702637
        vf_explained_var: 0.8104302883148193
        vf_loss: 128.26218032836914
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.041935483870965
    gpu_util_percent0: 0.2812903225806452
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.754838709677419
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48597
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1641174120999257
    mean_env_wait_ms: 1.161537109361996
    mean_inference_ms: 5.692598517415019
    mean_raw_obs_processing_ms: 0.44176304933602323
  time_since_restore: 54.913392305374146
  time_this_iter_s: 26.473439931869507
  time_total_s: 54.913392305374146
  timers:
    learn_throughput: 8644.657
    learn_time_ms: 18715.839
    sample_throughput: 18672.544
    sample_time_ms: 8664.701
    update_time_ms: 34.541
  timestamp: 1602447548
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: dfeb0_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      2 |          54.9134 | 323584 |  217.798 |              265.869 |              145.717 |            889.161 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dfeb0_00000:
  custom_metrics:
    time_step_max: 4376
    time_step_mean: 3623.385650224215
    time_step_min: 3285
  date: 2020-10-11_20-19-34
  done: false
  episode_len_mean: 884.6371308016878
  episode_reward_max: 280.5656565656561
  episode_reward_mean: 217.91957550185379
  episode_reward_min: 102.98989898989872
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 486c986d2ff845b0b26d77aba5b4b507
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1392555435498555
        entropy_coeff: 0.0005000000000000001
        kl: 0.00957879020522038
        model: {}
        policy_loss: -0.013498059211997315
        total_loss: 65.20246982574463
        vf_explained_var: 0.8920263648033142
        vf_loss: 65.21557839711507
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.12333333333333
    gpu_util_percent0: 0.29900000000000004
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.77
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48597
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16137101559306874
    mean_env_wait_ms: 1.1624113133988414
    mean_inference_ms: 5.471956785195863
    mean_raw_obs_processing_ms: 0.4328824318519803
  time_since_restore: 80.61326289176941
  time_this_iter_s: 25.699870586395264
  time_total_s: 80.61326289176941
  timers:
    learn_throughput: 8673.855
    learn_time_ms: 18652.836
    sample_throughput: 19886.525
    sample_time_ms: 8135.76
    update_time_ms: 37.024
  timestamp: 1602447574
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: dfeb0_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      3 |          80.6133 | 485376 |   217.92 |              280.566 |               102.99 |            884.637 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dfeb0_00000:
  custom_metrics:
    time_step_max: 4555
    time_step_mean: 3621.849337748344
    time_step_min: 3285
  date: 2020-10-11_20-20-00
  done: false
  episode_len_mean: 881.6772151898734
  episode_reward_max: 280.5656565656561
  episode_reward_mean: 218.88892085411052
  episode_reward_min: 75.86868686868725
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 486c986d2ff845b0b26d77aba5b4b507
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1236704488595326
        entropy_coeff: 0.0005000000000000001
        kl: 0.007535708253271878
        model: {}
        policy_loss: -0.013356986630242318
        total_loss: 48.56767304738363
        vf_explained_var: 0.9157173037528992
        vf_loss: 48.58083724975586
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.296666666666663
    gpu_util_percent0: 0.4023333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.766666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48597
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1593975281871441
    mean_env_wait_ms: 1.1630363827485917
    mean_inference_ms: 5.315944442746125
    mean_raw_obs_processing_ms: 0.42613695533758145
  time_since_restore: 106.19969916343689
  time_this_iter_s: 25.58643627166748
  time_total_s: 106.19969916343689
  timers:
    learn_throughput: 8681.107
    learn_time_ms: 18637.255
    sample_throughput: 20668.006
    sample_time_ms: 7828.138
    update_time_ms: 38.696
  timestamp: 1602447600
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: dfeb0_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      4 |            106.2 | 647168 |  218.889 |              280.566 |              75.8687 |            881.677 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dfeb0_00000:
  custom_metrics:
    time_step_max: 4555
    time_step_mean: 3610.6456692913384
    time_step_min: 3278
  date: 2020-10-11_20-20-26
  done: false
  episode_len_mean: 878.0367088607595
  episode_reward_max: 280.5656565656561
  episode_reward_mean: 220.18495077355817
  episode_reward_min: 75.86868686868725
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 486c986d2ff845b0b26d77aba5b4b507
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.090914100408554
        entropy_coeff: 0.0005000000000000001
        kl: 0.0074959762472038465
        model: {}
        policy_loss: -0.012363930135810127
        total_loss: 36.32484753926595
        vf_explained_var: 0.9411559104919434
        vf_loss: 36.33700720469157
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.69
    gpu_util_percent0: 0.27466666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7733333333333334
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48597
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15796218411921265
    mean_env_wait_ms: 1.1639934756279489
    mean_inference_ms: 5.2000617098190585
    mean_raw_obs_processing_ms: 0.4209348049282861
  time_since_restore: 131.93419408798218
  time_this_iter_s: 25.734494924545288
  time_total_s: 131.93419408798218
  timers:
    learn_throughput: 8680.33
    learn_time_ms: 18638.923
    sample_throughput: 21108.552
    sample_time_ms: 7664.761
    update_time_ms: 36.284
  timestamp: 1602447626
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: dfeb0_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      5 |          131.934 | 808960 |  220.185 |              280.566 |              75.8687 |            878.037 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dfeb0_00000:
  custom_metrics:
    time_step_max: 4555
    time_step_mean: 3584.0131208997186
    time_step_min: 3238
  date: 2020-10-11_20-20-51
  done: false
  episode_len_mean: 870.7881278538813
  episode_reward_max: 280.5656565656561
  episode_reward_mean: 224.09796596097948
  episode_reward_min: 75.86868686868725
  episodes_this_iter: 305
  episodes_total: 1095
  experiment_id: 486c986d2ff845b0b26d77aba5b4b507
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0736289421717327
        entropy_coeff: 0.0005000000000000001
        kl: 0.0076567893071721
        model: {}
        policy_loss: -0.012293024260240296
        total_loss: 33.63621966044108
        vf_explained_var: 0.9586592316627502
        vf_loss: 33.64828300476074
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.536666666666672
    gpu_util_percent0: 0.28833333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.766666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48597
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15607596891536865
    mean_env_wait_ms: 1.1671366247994843
    mean_inference_ms: 5.0500729045139465
    mean_raw_obs_processing_ms: 0.4143215108904387
  time_since_restore: 157.5549192428589
  time_this_iter_s: 25.62072515487671
  time_total_s: 157.5549192428589
  timers:
    learn_throughput: 8674.401
    learn_time_ms: 18651.663
    sample_throughput: 21499.526
    sample_time_ms: 7525.375
    update_time_ms: 33.988
  timestamp: 1602447651
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: dfeb0_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      6 |          157.555 | 970752 |  224.098 |              280.566 |              75.8687 |            870.788 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dfeb0_00000:
  custom_metrics:
    time_step_max: 4555
    time_step_mean: 3570.73786407767
    time_step_min: 3238
  date: 2020-10-11_20-21-17
  done: false
  episode_len_mean: 867.189082278481
  episode_reward_max: 280.5656565656561
  episode_reward_mean: 226.04501502365406
  episode_reward_min: 75.86868686868725
  episodes_this_iter: 169
  episodes_total: 1264
  experiment_id: 486c986d2ff845b0b26d77aba5b4b507
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0686622162659962
        entropy_coeff: 0.0005000000000000001
        kl: 0.007437769207172096
        model: {}
        policy_loss: -0.012086212953969758
        total_loss: 20.895000457763672
        vf_explained_var: 0.9618611931800842
        vf_loss: 20.906877199808758
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.706666666666663
    gpu_util_percent0: 0.313
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7833333333333328
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48597
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1553269146624884
    mean_env_wait_ms: 1.1685347068037049
    mean_inference_ms: 4.989185923698291
    mean_raw_obs_processing_ms: 0.41171449184267606
  time_since_restore: 183.35250997543335
  time_this_iter_s: 25.797590732574463
  time_total_s: 183.35250997543335
  timers:
    learn_throughput: 8659.305
    learn_time_ms: 18684.179
    sample_throughput: 21782.079
    sample_time_ms: 7427.757
    update_time_ms: 32.583
  timestamp: 1602447677
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: dfeb0_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      7 |          183.353 | 1132544 |  226.045 |              280.566 |              75.8687 |            867.189 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dfeb0_00000:
  custom_metrics:
    time_step_max: 4555
    time_step_mean: 3558.4670014347203
    time_step_min: 3238
  date: 2020-10-11_20-21-43
  done: false
  episode_len_mean: 863.3881856540085
  episode_reward_max: 280.5656565656561
  episode_reward_mean: 227.5396155649319
  episode_reward_min: 75.86868686868725
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 486c986d2ff845b0b26d77aba5b4b507
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0467442870140076
        entropy_coeff: 0.0005000000000000001
        kl: 0.00735667875657479
        model: {}
        policy_loss: -0.012476529033544162
        total_loss: 16.631463209788006
        vf_explained_var: 0.9689691066741943
        vf_loss: 16.643727620442707
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.706666666666667
    gpu_util_percent0: 0.3546666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7866666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48597
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1547256264044939
    mean_env_wait_ms: 1.1697889323469424
    mean_inference_ms: 4.941149080036455
    mean_raw_obs_processing_ms: 0.4095648767577179
  time_since_restore: 208.95958399772644
  time_this_iter_s: 25.60707402229309
  time_total_s: 208.95958399772644
  timers:
    learn_throughput: 8657.699
    learn_time_ms: 18687.644
    sample_throughput: 22008.019
    sample_time_ms: 7351.502
    update_time_ms: 31.768
  timestamp: 1602447703
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: dfeb0_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      8 |           208.96 | 1294336 |   227.54 |              280.566 |              75.8687 |            863.388 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dfeb0_00000:
  custom_metrics:
    time_step_max: 4555
    time_step_mean: 3548.3775773195875
    time_step_min: 3238
  date: 2020-10-11_20-22-08
  done: false
  episode_len_mean: 859.5791139240506
  episode_reward_max: 280.5656565656561
  episode_reward_mean: 229.39314026339326
  episode_reward_min: 75.86868686868725
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 486c986d2ff845b0b26d77aba5b4b507
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0254518787066143
        entropy_coeff: 0.0005000000000000001
        kl: 0.007505126879550517
        model: {}
        policy_loss: -0.013200220981768021
        total_loss: 16.60719045003255
        vf_explained_var: 0.9654716849327087
        vf_loss: 16.620153188705444
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.97586206896552
    gpu_util_percent0: 0.373103448275862
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7689655172413787
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48597
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15420505835699988
    mean_env_wait_ms: 1.1709664764376828
    mean_inference_ms: 4.899308239449433
    mean_raw_obs_processing_ms: 0.4076704455336656
  time_since_restore: 234.6318006515503
  time_this_iter_s: 25.672216653823853
  time_total_s: 234.6318006515503
  timers:
    learn_throughput: 8657.476
    learn_time_ms: 18688.125
    sample_throughput: 22163.621
    sample_time_ms: 7299.89
    update_time_ms: 32.627
  timestamp: 1602447728
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: dfeb0_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      9 |          234.632 | 1456128 |  229.393 |              280.566 |              75.8687 |            859.579 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dfeb0_00000:
  custom_metrics:
    time_step_max: 4555
    time_step_mean: 3530.453984287318
    time_step_min: 3189
  date: 2020-10-11_20-22-34
  done: false
  episode_len_mean: 855.0779005524862
  episode_reward_max: 282.83838383838395
  episode_reward_mean: 231.6610859981024
  episode_reward_min: 75.86868686868725
  episodes_this_iter: 230
  episodes_total: 1810
  experiment_id: 486c986d2ff845b0b26d77aba5b4b507
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9783310542503992
        entropy_coeff: 0.0005000000000000001
        kl: 0.007558321657901009
        model: {}
        policy_loss: -0.012323003092509074
        total_loss: 21.252121289571125
        vf_explained_var: 0.9696983695030212
        vf_loss: 21.264177322387695
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.10322580645162
    gpu_util_percent0: 0.44322580645161286
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7580645161290316
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48597
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15357945616241028
    mean_env_wait_ms: 1.1729293401628718
    mean_inference_ms: 4.848476154423788
    mean_raw_obs_processing_ms: 0.4053396875096163
  time_since_restore: 260.496376991272
  time_this_iter_s: 25.86457633972168
  time_total_s: 260.496376991272
  timers:
    learn_throughput: 8649.232
    learn_time_ms: 18705.938
    sample_throughput: 22309.364
    sample_time_ms: 7252.201
    update_time_ms: 32.981
  timestamp: 1602447754
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: dfeb0_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     10 |          260.496 | 1617920 |  231.661 |              282.838 |              75.8687 |            855.078 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dfeb0_00000:
  custom_metrics:
    time_step_max: 4555
    time_step_mean: 3515.8815399802565
    time_step_min: 3189
  date: 2020-10-11_20-23-00
  done: false
  episode_len_mean: 851.3515092502435
  episode_reward_max: 282.83838383838395
  episode_reward_mean: 233.5874027519596
  episode_reward_min: 75.86868686868725
  episodes_this_iter: 244
  episodes_total: 2054
  experiment_id: 486c986d2ff845b0b26d77aba5b4b507
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9831370264291763
        entropy_coeff: 0.0005000000000000001
        kl: 0.007093390799127519
        model: {}
        policy_loss: -0.012145887061099833
        total_loss: 15.38879140218099
        vf_explained_var: 0.9745174050331116
        vf_loss: 15.400719245274862
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.058620689655175
    gpu_util_percent0: 0.34068965517241384
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.772413793103448
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48597
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15299769941749414
    mean_env_wait_ms: 1.174449037632307
    mean_inference_ms: 4.802499299001492
    mean_raw_obs_processing_ms: 0.40323562982226707
  time_since_restore: 285.89834547042847
  time_this_iter_s: 25.401968479156494
  time_total_s: 285.89834547042847
  timers:
    learn_throughput: 8657.708
    learn_time_ms: 18687.626
    sample_throughput: 23227.447
    sample_time_ms: 6965.552
    update_time_ms: 32.734
  timestamp: 1602447780
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: dfeb0_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     11 |          285.898 | 1779712 |  233.587 |              282.838 |              75.8687 |            851.352 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dfeb0_00000:
  custom_metrics:
    time_step_max: 4555
    time_step_mean: 3507.2843406593406
    time_step_min: 3187
  date: 2020-10-11_20-23-26
  done: false
  episode_len_mean: 849.3214285714286
  episode_reward_max: 283.1414141414142
  episode_reward_mean: 234.8278764133193
  episode_reward_min: 75.86868686868725
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 486c986d2ff845b0b26d77aba5b4b507
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9695532222588857
        entropy_coeff: 0.0005000000000000001
        kl: 0.006893695720161001
        model: {}
        policy_loss: -0.013366622074196735
        total_loss: 11.94997787475586
        vf_explained_var: 0.9762477278709412
        vf_loss: 11.963139851888021
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.98
    gpu_util_percent0: 0.39133333333333326
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7833333333333328
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48597
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15267911592020442
    mean_env_wait_ms: 1.1754082858107124
    mean_inference_ms: 4.7771672423033875
    mean_raw_obs_processing_ms: 0.40206413935896457
  time_since_restore: 311.4134485721588
  time_this_iter_s: 25.515103101730347
  time_total_s: 311.4134485721588
  timers:
    learn_throughput: 8665.219
    learn_time_ms: 18671.427
    sample_throughput: 23495.398
    sample_time_ms: 6886.115
    update_time_ms: 31.361
  timestamp: 1602447806
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: dfeb0_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     12 |          311.413 | 1941504 |  234.828 |              283.141 |              75.8687 |            849.321 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dfeb0_00000:
  custom_metrics:
    time_step_max: 4555
    time_step_mean: 3499.359948761742
    time_step_min: 3187
  date: 2020-10-11_20-23-51
  done: false
  episode_len_mean: 847.2481012658228
  episode_reward_max: 284.2020202020199
  episode_reward_mean: 236.03087840429595
  episode_reward_min: 75.86868686868725
  episodes_this_iter: 158
  episodes_total: 2370
  experiment_id: 486c986d2ff845b0b26d77aba5b4b507
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9525636037190756
        entropy_coeff: 0.0005000000000000001
        kl: 0.007253999511400859
        model: {}
        policy_loss: -0.011778777848424701
        total_loss: 12.683573007583618
        vf_explained_var: 0.9729364514350891
        vf_loss: 12.695102532704672
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.848275862068967
    gpu_util_percent0: 0.4362068965517242
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7758620689655173
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48597
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15238677910288023
    mean_env_wait_ms: 1.1762651426265218
    mean_inference_ms: 4.754077360657
    mean_raw_obs_processing_ms: 0.40096428130312095
  time_since_restore: 336.9129900932312
  time_this_iter_s: 25.499541521072388
  time_total_s: 336.9129900932312
  timers:
    learn_throughput: 8658.975
    learn_time_ms: 18684.892
    sample_throughput: 23608.495
    sample_time_ms: 6853.126
    update_time_ms: 29.201
  timestamp: 1602447831
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: dfeb0_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     13 |          336.913 | 2103296 |  236.031 |              284.202 |              75.8687 |            847.248 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dfeb0_00000:
  custom_metrics:
    time_step_max: 4555
    time_step_mean: 3489.3022256930885
    time_step_min: 3187
  date: 2020-10-11_20-24-17
  done: false
  episode_len_mean: 845.1205098493626
  episode_reward_max: 285.111111111111
  episode_reward_mean: 237.57315916991453
  episode_reward_min: 75.86868686868725
  episodes_this_iter: 219
  episodes_total: 2589
  experiment_id: 486c986d2ff845b0b26d77aba5b4b507
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9141986866792043
        entropy_coeff: 0.0005000000000000001
        kl: 0.006633194202246766
        model: {}
        policy_loss: -0.011397288045069823
        total_loss: 14.408097267150879
        vf_explained_var: 0.9782162308692932
        vf_loss: 14.419288237889608
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.483333333333338
    gpu_util_percent0: 0.38299999999999995
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.77
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48597
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15203612506882044
    mean_env_wait_ms: 1.177434403681755
    mean_inference_ms: 4.725975916232662
    mean_raw_obs_processing_ms: 0.3996285154228699
  time_since_restore: 362.68629479408264
  time_this_iter_s: 25.77330470085144
  time_total_s: 362.68629479408264
  timers:
    learn_throughput: 8642.561
    learn_time_ms: 18720.378
    sample_throughput: 23665.671
    sample_time_ms: 6836.569
    update_time_ms: 27.867
  timestamp: 1602447857
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: dfeb0_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     14 |          362.686 | 2265088 |  237.573 |              285.111 |              75.8687 |            845.121 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dfeb0_00000:
  custom_metrics:
    time_step_max: 4555
    time_step_mean: 3478.2078152753106
    time_step_min: 3114
  date: 2020-10-11_20-24-43
  done: false
  episode_len_mean: 843.0049243756595
  episode_reward_max: 294.20202020201987
  episode_reward_mean: 239.0910085732455
  episode_reward_min: 75.86868686868725
  episodes_this_iter: 254
  episodes_total: 2843
  experiment_id: 486c986d2ff845b0b26d77aba5b4b507
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.906439483165741
        entropy_coeff: 0.0005000000000000001
        kl: 0.00629633719411989
        model: {}
        policy_loss: -0.008484600538698336
        total_loss: 13.794315973917643
        vf_explained_var: 0.977971076965332
        vf_loss: 13.802624225616455
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.4
    gpu_util_percent0: 0.2956666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.769999999999999
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48597
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15166958436902533
    mean_env_wait_ms: 1.1785378851431692
    mean_inference_ms: 4.696807133847539
    mean_raw_obs_processing_ms: 0.39823878821593045
  time_since_restore: 388.19724225997925
  time_this_iter_s: 25.510947465896606
  time_total_s: 388.19724225997925
  timers:
    learn_throughput: 8641.51
    learn_time_ms: 18722.653
    sample_throughput: 23758.911
    sample_time_ms: 6809.74
    update_time_ms: 28.865
  timestamp: 1602447883
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: dfeb0_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     15 |          388.197 | 2426880 |  239.091 |              294.202 |              75.8687 |            843.005 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dfeb0_00000:
  custom_metrics:
    time_step_max: 4555
    time_step_mean: 3471.2484868863485
    time_step_min: 3114
  date: 2020-10-11_20-25-08
  done: false
  episode_len_mean: 841.4696868754164
  episode_reward_max: 294.20202020201987
  episode_reward_mean: 240.07658867152526
  episode_reward_min: 75.86868686868725
  episodes_this_iter: 159
  episodes_total: 3002
  experiment_id: 486c986d2ff845b0b26d77aba5b4b507
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8939206699530283
        entropy_coeff: 0.0005000000000000001
        kl: 0.007120410058026512
        model: {}
        policy_loss: -0.013225489509447167
        total_loss: 11.056419531504313
        vf_explained_var: 0.977925717830658
        vf_loss: 11.069379409154257
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.989655172413798
    gpu_util_percent0: 0.32172413793103455
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7827586206896546
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48597
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15146700941909105
    mean_env_wait_ms: 1.1791897641952667
    mean_inference_ms: 4.6806621211616175
    mean_raw_obs_processing_ms: 0.3974652038101286
  time_since_restore: 413.7767312526703
  time_this_iter_s: 25.57948899269104
  time_total_s: 413.7767312526703
  timers:
    learn_throughput: 8641.857
    learn_time_ms: 18721.903
    sample_throughput: 23771.571
    sample_time_ms: 6806.113
    update_time_ms: 28.84
  timestamp: 1602447908
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: dfeb0_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     16 |          413.777 | 2588672 |  240.077 |              294.202 |              75.8687 |             841.47 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dfeb0_00000:
  custom_metrics:
    time_step_max: 4555
    time_step_mean: 3464.836845466156
    time_step_min: 3114
  date: 2020-10-11_20-25-34
  done: false
  episode_len_mean: 839.8240506329114
  episode_reward_max: 294.20202020201987
  episode_reward_mean: 240.94871180155977
  episode_reward_min: 75.86868686868725
  episodes_this_iter: 158
  episodes_total: 3160
  experiment_id: 486c986d2ff845b0b26d77aba5b4b507
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8823149502277374
        entropy_coeff: 0.0005000000000000001
        kl: 0.006691928138025105
        model: {}
        policy_loss: -0.011884851943856726
        total_loss: 10.509639422098795
        vf_explained_var: 0.9782719612121582
        vf_loss: 10.521296262741089
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.383333333333336
    gpu_util_percent0: 0.266
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7800000000000002
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48597
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1512813004386509
    mean_env_wait_ms: 1.179821308066897
    mean_inference_ms: 4.665766796337426
    mean_raw_obs_processing_ms: 0.3967421105344154
  time_since_restore: 439.20659351348877
  time_this_iter_s: 25.42986226081848
  time_total_s: 439.20659351348877
  timers:
    learn_throughput: 8657.028
    learn_time_ms: 18689.092
    sample_throughput: 23787.343
    sample_time_ms: 6801.6
    update_time_ms: 28.419
  timestamp: 1602447934
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: dfeb0_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     17 |          439.207 | 2750464 |  240.949 |              294.202 |              75.8687 |            839.824 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dfeb0_00000:
  custom_metrics:
    time_step_max: 4555
    time_step_mean: 3454.8194444444443
    time_step_min: 3114
  date: 2020-10-11_20-25-59
  done: false
  episode_len_mean: 837.3622508792497
  episode_reward_max: 294.20202020201987
  episode_reward_mean: 242.37695536845584
  episode_reward_min: 75.86868686868725
  episodes_this_iter: 252
  episodes_total: 3412
  experiment_id: 486c986d2ff845b0b26d77aba5b4b507
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.851616899172465
        entropy_coeff: 0.0005000000000000001
        kl: 0.006081323605030775
        model: {}
        policy_loss: -0.010536718415096402
        total_loss: 13.626426935195923
        vf_explained_var: 0.9793136715888977
        vf_loss: 13.636781613032023
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.706666666666663
    gpu_util_percent0: 0.302
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7633333333333328
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48597
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.151021285653716
    mean_env_wait_ms: 1.1808787240074101
    mean_inference_ms: 4.644646637518742
    mean_raw_obs_processing_ms: 0.395716154310957
  time_since_restore: 464.71025347709656
  time_this_iter_s: 25.503659963607788
  time_total_s: 464.71025347709656
  timers:
    learn_throughput: 8660.443
    learn_time_ms: 18681.723
    sample_throughput: 23804.094
    sample_time_ms: 6796.814
    update_time_ms: 29.145
  timestamp: 1602447959
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: dfeb0_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     18 |           464.71 | 2912256 |  242.377 |              294.202 |              75.8687 |            837.362 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dfeb0_00000:
  custom_metrics:
    time_step_max: 4555
    time_step_mean: 3447.6802551303385
    time_step_min: 3114
  date: 2020-10-11_20-26-25
  done: false
  episode_len_mean: 835.4837644468905
  episode_reward_max: 294.20202020201987
  episode_reward_mean: 243.5167414374898
  episode_reward_min: 75.86868686868725
  episodes_this_iter: 222
  episodes_total: 3634
  experiment_id: 486c986d2ff845b0b26d77aba5b4b507
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8403268406788508
        entropy_coeff: 0.0005000000000000001
        kl: 0.006061406301644941
        model: {}
        policy_loss: -0.008233758644716241
        total_loss: 10.79630970954895
        vf_explained_var: 0.9808487892150879
        vf_loss: 10.804357449213663
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.273333333333333
    gpu_util_percent0: 0.40166666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7766666666666664
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48597
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15079811866017936
    mean_env_wait_ms: 1.1816707724435114
    mean_inference_ms: 4.627169590964196
    mean_raw_obs_processing_ms: 0.3948970998715084
  time_since_restore: 490.4313905239105
  time_this_iter_s: 25.721137046813965
  time_total_s: 490.4313905239105
  timers:
    learn_throughput: 8653.987
    learn_time_ms: 18695.661
    sample_throughput: 23843.805
    sample_time_ms: 6785.494
    update_time_ms: 30.641
  timestamp: 1602447985
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: dfeb0_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     19 |          490.431 | 3074048 |  243.517 |              294.202 |              75.8687 |            835.484 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dfeb0_00000:
  custom_metrics:
    time_step_max: 4555
    time_step_mean: 3442.4577577045698
    time_step_min: 3114
  date: 2020-10-11_20-26-51
  done: false
  episode_len_mean: 833.8357067510549
  episode_reward_max: 294.20202020201987
  episode_reward_mean: 244.24585251246634
  episode_reward_min: 75.86868686868725
  episodes_this_iter: 158
  episodes_total: 3792
  experiment_id: 486c986d2ff845b0b26d77aba5b4b507
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8331598043441772
        entropy_coeff: 0.0005000000000000001
        kl: 0.006495586984480421
        model: {}
        policy_loss: -0.011495542149835577
        total_loss: 9.008565505345663
        vf_explained_var: 0.9805734753608704
        vf_loss: 9.019828001658121
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.196551724137933
    gpu_util_percent0: 0.44793103448275867
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7827586206896546
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48597
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1506571880081456
    mean_env_wait_ms: 1.1822421411112307
    mean_inference_ms: 4.615975210350845
    mean_raw_obs_processing_ms: 0.39436020417931467
  time_since_restore: 515.9194169044495
  time_this_iter_s: 25.48802638053894
  time_total_s: 515.9194169044495
  timers:
    learn_throughput: 8662.909
    learn_time_ms: 18676.405
    sample_throughput: 23887.718
    sample_time_ms: 6773.02
    update_time_ms: 31.114
  timestamp: 1602448011
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: dfeb0_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     20 |          515.919 | 3235840 |  244.246 |              294.202 |              75.8687 |            833.836 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dfeb0_00000:
  custom_metrics:
    time_step_max: 4555
    time_step_mean: 3437.3735398679532
    time_step_min: 3114
  date: 2020-10-11_20-27-17
  done: false
  episode_len_mean: 832.0063035804337
  episode_reward_max: 294.20202020201987
  episode_reward_mean: 245.05460810831454
  episode_reward_min: 75.86868686868725
  episodes_this_iter: 174
  episodes_total: 3966
  experiment_id: 486c986d2ff845b0b26d77aba5b4b507
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8113537778457006
        entropy_coeff: 0.0005000000000000001
        kl: 0.00662113749422133
        model: {}
        policy_loss: -0.010862251704869172
        total_loss: 9.200959205627441
        vf_explained_var: 0.9829750061035156
        vf_loss: 9.211564620335897
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.746666666666666
    gpu_util_percent0: 0.43233333333333335
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.783333333333333
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48597
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1505154580684014
    mean_env_wait_ms: 1.1829182364579118
    mean_inference_ms: 4.604545436836301
    mean_raw_obs_processing_ms: 0.393806888186482
  time_since_restore: 541.447582244873
  time_this_iter_s: 25.528165340423584
  time_total_s: 541.447582244873
  timers:
    learn_throughput: 8659.833
    learn_time_ms: 18683.039
    sample_throughput: 23874.125
    sample_time_ms: 6776.877
    update_time_ms: 32.246
  timestamp: 1602448037
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: dfeb0_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     21 |          541.448 | 3397632 |  245.055 |              294.202 |              75.8687 |            832.006 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dfeb0_00000:
  custom_metrics:
    time_step_max: 4555
    time_step_mean: 3429.0718336483933
    time_step_min: 3114
  date: 2020-10-11_20-27-42
  done: false
  episode_len_mean: 829.4262910798122
  episode_reward_max: 294.20202020201987
  episode_reward_mean: 246.28809218950053
  episode_reward_min: 75.86868686868725
  episodes_this_iter: 294
  episodes_total: 4260
  experiment_id: 486c986d2ff845b0b26d77aba5b4b507
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7864142805337906
        entropy_coeff: 0.0005000000000000001
        kl: 0.006753043349211414
        model: {}
        policy_loss: -0.010421635362339051
        total_loss: 12.085295756657919
        vf_explained_var: 0.9821670055389404
        vf_loss: 12.095435539881388
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.77666666666666
    gpu_util_percent0: 0.35666666666666663
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.773333333333333
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48597
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15028690275812004
    mean_env_wait_ms: 1.1839689693172888
    mean_inference_ms: 4.58657535166017
    mean_raw_obs_processing_ms: 0.39294259805891246
  time_since_restore: 567.0153458118439
  time_this_iter_s: 25.567763566970825
  time_total_s: 567.0153458118439
  timers:
    learn_throughput: 8657.11
    learn_time_ms: 18688.916
    sample_throughput: 23884.796
    sample_time_ms: 6773.849
    update_time_ms: 33.756
  timestamp: 1602448062
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: dfeb0_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     22 |          567.015 | 3559424 |  246.288 |              294.202 |              75.8687 |            829.426 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dfeb0_00000:
  custom_metrics:
    time_step_max: 4555
    time_step_mean: 3424.5079617834394
    time_step_min: 3096
  date: 2020-10-11_20-28-08
  done: false
  episode_len_mean: 828.3363471971066
  episode_reward_max: 296.9292929292926
  episode_reward_mean: 246.92703253146288
  episode_reward_min: 75.86868686868725
  episodes_this_iter: 164
  episodes_total: 4424
  experiment_id: 486c986d2ff845b0b26d77aba5b4b507
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7751223593950272
        entropy_coeff: 0.0005000000000000001
        kl: 0.006270660436712205
        model: {}
        policy_loss: -0.012993110887085399
        total_loss: 9.126743952433268
        vf_explained_var: 0.9815302491188049
        vf_loss: 9.13949735959371
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.034482758620694
    gpu_util_percent0: 0.37655172413793103
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7793103448275853
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48597
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15016941325618596
    mean_env_wait_ms: 1.1844954628333266
    mean_inference_ms: 4.577346269372596
    mean_raw_obs_processing_ms: 0.3924992256454737
  time_since_restore: 592.4772689342499
  time_this_iter_s: 25.461923122406006
  time_total_s: 592.4772689342499
  timers:
    learn_throughput: 8658.163
    learn_time_ms: 18686.643
    sample_throughput: 23893.516
    sample_time_ms: 6771.377
    update_time_ms: 35.505
  timestamp: 1602448088
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: dfeb0_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     23 |          592.477 | 3721216 |  246.927 |              296.929 |              75.8687 |            828.336 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dfeb0_00000:
  custom_metrics:
    time_step_max: 4555
    time_step_mean: 3420.217391304348
    time_step_min: 3096
  date: 2020-10-11_20-28-34
  done: true
  episode_len_mean: 827.2712789175033
  episode_reward_max: 298.59595959595964
  episode_reward_mean: 247.62179190420122
  episode_reward_min: 75.86868686868725
  episodes_this_iter: 158
  episodes_total: 4582
  experiment_id: 486c986d2ff845b0b26d77aba5b4b507
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7690570255120596
        entropy_coeff: 0.0005000000000000001
        kl: 0.006819716926353673
        model: {}
        policy_loss: -0.011298634965593616
        total_loss: 7.405012885729472
        vf_explained_var: 0.9835589528083801
        vf_loss: 7.416013916333516
    num_steps_sampled: 3883008
    num_steps_trained: 3883008
  iterations_since_restore: 24
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.09666666666667
    gpu_util_percent0: 0.37433333333333335
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7899999999999996
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 48597
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1500637869801008
    mean_env_wait_ms: 1.1850024778129549
    mean_inference_ms: 4.568983072556478
    mean_raw_obs_processing_ms: 0.3920924925269654
  time_since_restore: 618.0373919010162
  time_this_iter_s: 25.560122966766357
  time_total_s: 618.0373919010162
  timers:
    learn_throughput: 8670.217
    learn_time_ms: 18660.662
    sample_throughput: 23876.765
    sample_time_ms: 6776.127
    update_time_ms: 34.493
  timestamp: 1602448114
  timesteps_since_restore: 0
  timesteps_total: 3883008
  training_iteration: 24
  trial_id: dfeb0_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dfeb0_00000 | TERMINATED |       |     24 |          618.037 | 3883008 |  247.622 |              298.596 |              75.8687 |            827.271 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dfeb0_00000 | TERMINATED |       |     24 |          618.037 | 3883008 |  247.622 |              298.596 |              75.8687 |            827.271 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


