2020-10-12 14:50:25,174	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_43ae8_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=66695)[0m 2020-10-12 14:50:27,989	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=66699)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66699)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66670)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66670)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66642)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66642)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66700)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66700)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66656)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66656)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66627)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66627)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66645)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66645)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66649)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66649)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66650)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66650)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66648)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66648)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66688)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66688)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66683)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66683)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66655)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66655)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66687)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66687)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66657)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66657)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66643)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66643)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66653)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66653)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66624)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66624)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66572)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66572)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66686)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66686)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66633)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66633)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66620)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66620)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66590)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66590)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66565)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66565)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66678)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66678)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66587)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66587)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66652)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66652)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66646)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66646)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66596)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66596)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66701)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66701)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66638)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66638)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66651)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66651)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66571)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66571)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66573)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66573)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66659)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66659)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66654)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66654)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66585)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66585)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66576)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66576)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66577)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66577)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66580)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66580)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66672)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66672)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66622)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66622)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66578)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66578)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66584)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66584)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66676)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66676)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66664)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66664)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66595)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66595)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66658)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66658)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66592)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66592)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66589)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66589)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66564)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66564)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66667)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66667)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66634)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66634)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66570)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66570)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66588)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66588)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66566)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66566)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66582)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66582)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66586)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66586)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66594)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66594)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66617)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66617)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66567)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66567)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66631)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66631)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66647)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66647)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66623)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66623)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66684)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66684)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66581)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66581)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66629)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66629)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66632)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66632)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66644)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66644)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66666)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66666)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66639)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66639)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66635)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66635)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66568)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66568)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66692)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66692)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66661)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66661)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66597)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66597)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66583)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66583)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66574)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66574)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66569)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66569)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_43ae8_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3561.048780487805
    time_step_min: 3288
  date: 2020-10-12_14-51-02
  done: false
  episode_len_mean: 897.367088607595
  episode_reward_max: 273.50505050505103
  episode_reward_mean: 205.7902442142946
  episode_reward_min: 128.35353535353502
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: abb29ce576004b5f95025d6ff36773a1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1812196671962738
        entropy_coeff: 0.0005000000000000001
        kl: 0.004003119072876871
        model: {}
        policy_loss: -0.007752152906808381
        total_loss: 417.5151901245117
        vf_explained_var: 0.5535116195678711
        vf_loss: 417.5227355957031
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.761764705882353
    gpu_util_percent0: 0.26588235294117646
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5529411764705885
    vram_util_percent0: 0.08474813342851081
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 66695
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16851957214581592
    mean_env_wait_ms: 1.1629927235644848
    mean_inference_ms: 6.207467971594476
    mean_raw_obs_processing_ms: 0.4589409134792081
  time_since_restore: 28.91505455970764
  time_this_iter_s: 28.91505455970764
  time_total_s: 28.91505455970764
  timers:
    learn_throughput: 8546.514
    learn_time_ms: 18930.759
    sample_throughput: 16329.468
    sample_time_ms: 9907.977
    update_time_ms: 45.328
  timestamp: 1602514262
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 43ae8_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_43ae8_00000 | RUNNING  | 172.17.0.4:66695 |      1 |          28.9151 | 161792 |   205.79 |              273.505 |              128.354 |            897.367 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_43ae8_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3569.6227758007117
    time_step_min: 3288
  date: 2020-10-12_14-51-28
  done: false
  episode_len_mean: 896.1867088607595
  episode_reward_max: 273.50505050505103
  episode_reward_mean: 206.45959595959573
  episode_reward_min: 128.35353535353502
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: abb29ce576004b5f95025d6ff36773a1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1479040284951527
        entropy_coeff: 0.0005000000000000001
        kl: 0.008545062194267908
        model: {}
        policy_loss: -0.010045574104879051
        total_loss: 102.10054206848145
        vf_explained_var: 0.8203843235969543
        vf_loss: 102.1103064219157
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.203225806451616
    gpu_util_percent0: 0.42645161290322575
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7548387096774185
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 66695
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16394520772499283
    mean_env_wait_ms: 1.1594185346602066
    mean_inference_ms: 5.835192505794831
    mean_raw_obs_processing_ms: 0.44462105440111144
  time_since_restore: 55.43004536628723
  time_this_iter_s: 26.51499080657959
  time_total_s: 55.43004536628723
  timers:
    learn_throughput: 8560.635
    learn_time_ms: 18899.533
    sample_throughput: 18532.895
    sample_time_ms: 8729.991
    update_time_ms: 41.276
  timestamp: 1602514288
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 43ae8_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_43ae8_00000 | RUNNING  | 172.17.0.4:66695 |      2 |            55.43 | 323584 |   206.46 |              273.505 |              128.354 |            896.187 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_43ae8_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3554.0
    time_step_min: 3195
  date: 2020-10-12_14-51-54
  done: false
  episode_len_mean: 889.2383966244726
  episode_reward_max: 273.50505050505103
  episode_reward_mean: 208.2390998593528
  episode_reward_min: 128.35353535353502
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: abb29ce576004b5f95025d6ff36773a1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.137634406487147
        entropy_coeff: 0.0005000000000000001
        kl: 0.007693540576534967
        model: {}
        policy_loss: -0.011871370700343201
        total_loss: 50.18517557779948
        vf_explained_var: 0.8948180079460144
        vf_loss: 50.1968469619751
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.633333333333333
    gpu_util_percent0: 0.3226666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.776666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 66695
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16107528978979022
    mean_env_wait_ms: 1.1604898501720622
    mean_inference_ms: 5.585189091205444
    mean_raw_obs_processing_ms: 0.4349696728820593
  time_since_restore: 81.36568903923035
  time_this_iter_s: 25.935643672943115
  time_total_s: 81.36568903923035
  timers:
    learn_throughput: 8570.083
    learn_time_ms: 18878.697
    sample_throughput: 19824.738
    sample_time_ms: 8161.117
    update_time_ms: 37.018
  timestamp: 1602514314
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 43ae8_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_43ae8_00000 | RUNNING  | 172.17.0.4:66695 |      3 |          81.3657 | 485376 |  208.239 |              273.505 |              128.354 |            889.238 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_43ae8_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3551.257956448911
    time_step_min: 3195
  date: 2020-10-12_14-52-20
  done: false
  episode_len_mean: 884.371835443038
  episode_reward_max: 273.50505050505103
  episode_reward_mean: 208.62444060861762
  episode_reward_min: 128.35353535353502
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: abb29ce576004b5f95025d6ff36773a1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1220806539058685
        entropy_coeff: 0.0005000000000000001
        kl: 0.008578164658198753
        model: {}
        policy_loss: -0.012210655714928484
        total_loss: 37.28772290547689
        vf_explained_var: 0.9263750910758972
        vf_loss: 37.29963652292887
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.839999999999993
    gpu_util_percent0: 0.2703333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.776666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 66695
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15908616876916812
    mean_env_wait_ms: 1.1625002294413749
    mean_inference_ms: 5.409104632619824
    mean_raw_obs_processing_ms: 0.4276879136192362
  time_since_restore: 107.2057249546051
  time_this_iter_s: 25.840035915374756
  time_total_s: 107.2057249546051
  timers:
    learn_throughput: 8573.25
    learn_time_ms: 18871.724
    sample_throughput: 20626.706
    sample_time_ms: 7843.812
    update_time_ms: 39.784
  timestamp: 1602514340
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 43ae8_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_43ae8_00000 | RUNNING  | 172.17.0.4:66695 |      4 |          107.206 | 647168 |  208.624 |              273.505 |              128.354 |            884.372 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_43ae8_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3548.7311258278146
    time_step_min: 3195
  date: 2020-10-12_14-52-46
  done: false
  episode_len_mean: 878.8354430379746
  episode_reward_max: 273.50505050505103
  episode_reward_mean: 209.16481268379982
  episode_reward_min: 128.35353535353502
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: abb29ce576004b5f95025d6ff36773a1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0830539067586262
        entropy_coeff: 0.0005000000000000001
        kl: 0.007865200944555303
        model: {}
        policy_loss: -0.012452944797890572
        total_loss: 32.10198322931925
        vf_explained_var: 0.9422528147697449
        vf_loss: 32.11419185002645
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.673333333333336
    gpu_util_percent0: 0.3
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.77
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 66695
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.157606084943933
    mean_env_wait_ms: 1.1652191144739192
    mean_inference_ms: 5.27831853879035
    mean_raw_obs_processing_ms: 0.4219715417689615
  time_since_restore: 132.95304369926453
  time_this_iter_s: 25.747318744659424
  time_total_s: 132.95304369926453
  timers:
    learn_throughput: 8573.543
    learn_time_ms: 18871.078
    sample_throughput: 21197.983
    sample_time_ms: 7632.424
    update_time_ms: 40.23
  timestamp: 1602514366
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 43ae8_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_43ae8_00000 | RUNNING  | 172.17.0.4:66695 |      5 |          132.953 | 808960 |  209.165 |              273.505 |              128.354 |            878.835 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_43ae8_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3527.9485500467727
    time_step_min: 3187
  date: 2020-10-12_14-53-12
  done: false
  episode_len_mean: 865.7038043478261
  episode_reward_max: 273.50505050505103
  episode_reward_mean: 212.2182696530521
  episode_reward_min: 128.35353535353502
  episodes_this_iter: 314
  episodes_total: 1104
  experiment_id: abb29ce576004b5f95025d6ff36773a1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0722917715708415
        entropy_coeff: 0.0005000000000000001
        kl: 0.008053469937294722
        model: {}
        policy_loss: -0.011176503176102415
        total_loss: 36.43024476369222
        vf_explained_var: 0.9526867270469666
        vf_loss: 36.44115161895752
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.91333333333334
    gpu_util_percent0: 0.32200000000000006
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.769999999999999
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 66695
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1556210669186496
    mean_env_wait_ms: 1.1708647403928836
    mean_inference_ms: 5.10392218025462
    mean_raw_obs_processing_ms: 0.4147084076228137
  time_since_restore: 158.86544561386108
  time_this_iter_s: 25.912401914596558
  time_total_s: 158.86544561386108
  timers:
    learn_throughput: 8571.47
    learn_time_ms: 18875.641
    sample_throughput: 21532.839
    sample_time_ms: 7513.733
    update_time_ms: 40.584
  timestamp: 1602514392
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 43ae8_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_43ae8_00000 | RUNNING  | 172.17.0.4:66695 |      6 |          158.865 | 970752 |  212.218 |              273.505 |              128.354 |            865.704 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_43ae8_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3519.5760781122863
    time_step_min: 3187
  date: 2020-10-12_14-53-38
  done: false
  episode_len_mean: 860.2832278481013
  episode_reward_max: 273.50505050505103
  episode_reward_mean: 213.76049258406843
  episode_reward_min: 128.35353535353502
  episodes_this_iter: 160
  episodes_total: 1264
  experiment_id: abb29ce576004b5f95025d6ff36773a1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0584441026051838
        entropy_coeff: 0.0005000000000000001
        kl: 0.007266054550806682
        model: {}
        policy_loss: -0.011817739791392038
        total_loss: 21.57445494333903
        vf_explained_var: 0.95844966173172
        vf_loss: 21.58607578277588
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.909677419354843
    gpu_util_percent0: 0.41935483870967744
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7806451612903222
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 66695
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15488735759400232
    mean_env_wait_ms: 1.1730138140539799
    mean_inference_ms: 5.041461794844065
    mean_raw_obs_processing_ms: 0.411995870516573
  time_since_restore: 184.96865510940552
  time_this_iter_s: 26.103209495544434
  time_total_s: 184.96865510940552
  timers:
    learn_throughput: 8565.997
    learn_time_ms: 18887.702
    sample_throughput: 21754.412
    sample_time_ms: 7437.204
    update_time_ms: 50.516
  timestamp: 1602514418
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 43ae8_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_43ae8_00000 | RUNNING  | 172.17.0.4:66695 |      7 |          184.969 | 1132544 |   213.76 |              273.505 |              128.354 |            860.283 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_43ae8_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3509.0281182408075
    time_step_min: 3120
  date: 2020-10-12_14-54-04
  done: false
  episode_len_mean: 855.4535864978903
  episode_reward_max: 274.5656565656565
  episode_reward_mean: 215.1003281762774
  episode_reward_min: 128.35353535353502
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: abb29ce576004b5f95025d6ff36773a1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0401013692220051
        entropy_coeff: 0.0005000000000000001
        kl: 0.007276753972594936
        model: {}
        policy_loss: -0.01209554991995295
        total_loss: 20.411585489908855
        vf_explained_var: 0.9587884545326233
        vf_loss: 20.423472722371418
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.393103448275866
    gpu_util_percent0: 0.4048275862068965
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.775862068965517
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 66695
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15426383086458587
    mean_env_wait_ms: 1.1750041289866462
    mean_inference_ms: 4.987781378141801
    mean_raw_obs_processing_ms: 0.40960749653288
  time_since_restore: 210.6306917667389
  time_this_iter_s: 25.662036657333374
  time_total_s: 210.6306917667389
  timers:
    learn_throughput: 8570.82
    learn_time_ms: 18877.074
    sample_throughput: 22003.464
    sample_time_ms: 7353.024
    update_time_ms: 49.793
  timestamp: 1602514444
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 43ae8_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_43ae8_00000 | RUNNING  | 172.17.0.4:66695 |      8 |          210.631 | 1294336 |    215.1 |              274.566 |              128.354 |            855.454 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_43ae8_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3501.862783171521
    time_step_min: 3120
  date: 2020-10-12_14-54-30
  done: false
  episode_len_mean: 851.6063291139241
  episode_reward_max: 274.5656565656565
  episode_reward_mean: 216.40263393427938
  episode_reward_min: 128.35353535353502
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: abb29ce576004b5f95025d6ff36773a1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0068644384543102
        entropy_coeff: 0.0005000000000000001
        kl: 0.007244308828376234
        model: {}
        policy_loss: -0.012283675799456736
        total_loss: 22.011494477589924
        vf_explained_var: 0.9590733051300049
        vf_loss: 22.023557662963867
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.010000000000005
    gpu_util_percent0: 0.3056666666666668
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.773333333333333
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 66695
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15372450175162714
    mean_env_wait_ms: 1.176897350272609
    mean_inference_ms: 4.941021439795961
    mean_raw_obs_processing_ms: 0.4074628418578119
  time_since_restore: 236.3831431865692
  time_this_iter_s: 25.752451419830322
  time_total_s: 236.3831431865692
  timers:
    learn_throughput: 8573.552
    learn_time_ms: 18871.059
    sample_throughput: 22175.617
    sample_time_ms: 7295.941
    update_time_ms: 48.512
  timestamp: 1602514470
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 43ae8_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_43ae8_00000 | RUNNING  | 172.17.0.4:66695 |      9 |          236.383 | 1456128 |  216.403 |              274.566 |              128.354 |            851.606 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_43ae8_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3485.0683530678148
    time_step_min: 3120
  date: 2020-10-12_14-54-56
  done: false
  episode_len_mean: 845.2070787110407
  episode_reward_max: 275.6262626262626
  episode_reward_mean: 219.26062527013386
  episode_reward_min: 128.35353535353502
  episodes_this_iter: 313
  episodes_total: 1893
  experiment_id: abb29ce576004b5f95025d6ff36773a1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9907859414815903
        entropy_coeff: 0.0005000000000000001
        kl: 0.006813797284848988
        model: {}
        policy_loss: -0.011380279174773023
        total_loss: 25.875819365183514
        vf_explained_var: 0.9651870727539062
        vf_loss: 25.88701327641805
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.233333333333334
    gpu_util_percent0: 0.29933333333333334
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7633333333333328
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 66695
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15286297499446364
    mean_env_wait_ms: 1.1803855674373969
    mean_inference_ms: 4.866299174265992
    mean_raw_obs_processing_ms: 0.4041149575194436
  time_since_restore: 262.11199259757996
  time_this_iter_s: 25.728849411010742
  time_total_s: 262.11199259757996
  timers:
    learn_throughput: 8576.816
    learn_time_ms: 18863.878
    sample_throughput: 22319.562
    sample_time_ms: 7248.888
    update_time_ms: 47.23
  timestamp: 1602514496
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 43ae8_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_43ae8_00000 | RUNNING  | 172.17.0.4:66695 |     10 |          262.112 | 1617920 |  219.261 |              275.626 |              128.354 |            845.207 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_43ae8_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3476.02823179792
    time_step_min: 3099
  date: 2020-10-12_14-55-21
  done: false
  episode_len_mean: 842.4542356377799
  episode_reward_max: 277.7474747474749
  episode_reward_mean: 220.41979188181708
  episode_reward_min: 128.35353535353502
  episodes_this_iter: 161
  episodes_total: 2054
  experiment_id: abb29ce576004b5f95025d6ff36773a1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9728940029939016
        entropy_coeff: 0.0005000000000000001
        kl: 0.0065002391347661614
        model: {}
        policy_loss: -0.010479286599244611
        total_loss: 17.72179587682088
        vf_explained_var: 0.9665319323539734
        vf_loss: 17.73211161295573
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.876666666666665
    gpu_util_percent0: 0.42200000000000004
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7833333333333328
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 66695
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15250471368407925
    mean_env_wait_ms: 1.1818181750956533
    mean_inference_ms: 4.835054501971094
    mean_raw_obs_processing_ms: 0.4026839278212024
  time_since_restore: 287.6876769065857
  time_this_iter_s: 25.575684309005737
  time_total_s: 287.6876769065857
  timers:
    learn_throughput: 8584.095
    learn_time_ms: 18847.881
    sample_throughput: 23343.474
    sample_time_ms: 6930.931
    update_time_ms: 44.8
  timestamp: 1602514521
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 43ae8_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_43ae8_00000 | RUNNING  | 172.17.0.4:66695 |     11 |          287.688 | 1779712 |   220.42 |              277.747 |              128.354 |            842.454 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_43ae8_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3467.6876435461645
    time_step_min: 3099
  date: 2020-10-12_14-55-47
  done: false
  episode_len_mean: 839.7314647377939
  episode_reward_max: 277.7474747474749
  episode_reward_mean: 221.8002310628892
  episode_reward_min: 128.35353535353502
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: abb29ce576004b5f95025d6ff36773a1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9636171956857046
        entropy_coeff: 0.0005000000000000001
        kl: 0.0065782947931438684
        model: {}
        policy_loss: -0.012532726783926288
        total_loss: 14.463757356007894
        vf_explained_var: 0.9673574566841125
        vf_loss: 14.47611395517985
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.927586206896557
    gpu_util_percent0: 0.4786206896551723
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7827586206896546
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 66695
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15218327423275577
    mean_env_wait_ms: 1.1831740872276673
    mean_inference_ms: 4.807267582001534
    mean_raw_obs_processing_ms: 0.4013949734311126
  time_since_restore: 313.3649048805237
  time_this_iter_s: 25.67722797393799
  time_total_s: 313.3649048805237
  timers:
    learn_throughput: 8586.869
    learn_time_ms: 18841.793
    sample_throughput: 23608.458
    sample_time_ms: 6853.137
    update_time_ms: 44.202
  timestamp: 1602514547
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 43ae8_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_43ae8_00000 | RUNNING  | 172.17.0.4:66695 |     12 |          313.365 | 1941504 |    221.8 |              277.747 |              128.354 |            839.731 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_43ae8_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3456.561816652649
    time_step_min: 3099
  date: 2020-10-12_14-56-13
  done: false
  episode_len_mean: 836.0049730625777
  episode_reward_max: 277.7474747474749
  episode_reward_mean: 223.48370149903505
  episode_reward_min: 128.35353535353502
  episodes_this_iter: 201
  episodes_total: 2413
  experiment_id: abb29ce576004b5f95025d6ff36773a1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9162271420160929
        entropy_coeff: 0.0005000000000000001
        kl: 0.006539546923401455
        model: {}
        policy_loss: -0.010849950471310876
        total_loss: 16.26166319847107
        vf_explained_var: 0.9718396663665771
        vf_loss: 16.272317091623943
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.919354838709676
    gpu_util_percent0: 0.3367741935483871
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7612903225806447
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 66695
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15182299870390983
    mean_env_wait_ms: 1.1849544951696498
    mean_inference_ms: 4.775845625614335
    mean_raw_obs_processing_ms: 0.39992500590240576
  time_since_restore: 339.284854888916
  time_this_iter_s: 25.919950008392334
  time_total_s: 339.284854888916
  timers:
    learn_throughput: 8583.848
    learn_time_ms: 18848.423
    sample_throughput: 23672.879
    sample_time_ms: 6834.488
    update_time_ms: 45.344
  timestamp: 1602514573
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 43ae8_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_43ae8_00000 | RUNNING  | 172.17.0.4:66695 |     13 |          339.285 | 2103296 |  223.484 |              277.747 |              128.354 |            836.005 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_43ae8_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3441.1576763485477
    time_step_min: 3054
  date: 2020-10-12_14-56-39
  done: false
  episode_len_mean: 831.4266567386449
  episode_reward_max: 284.56565656565675
  episode_reward_mean: 225.76486006754052
  episode_reward_min: 128.35353535353502
  episodes_this_iter: 273
  episodes_total: 2686
  experiment_id: abb29ce576004b5f95025d6ff36773a1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9097392161687216
        entropy_coeff: 0.0005000000000000001
        kl: 0.005902522980856399
        model: {}
        policy_loss: -0.010862464109474482
        total_loss: 15.4582626024882
        vf_explained_var: 0.9729016423225403
        vf_loss: 15.468989531199137
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.44137931034483
    gpu_util_percent0: 0.28241379310344833
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.772413793103448
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 66695
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15139175463418134
    mean_env_wait_ms: 1.1871279480650543
    mean_inference_ms: 4.738935112713308
    mean_raw_obs_processing_ms: 0.3981922407954192
  time_since_restore: 365.00967717170715
  time_this_iter_s: 25.724822282791138
  time_total_s: 365.00967717170715
  timers:
    learn_throughput: 8584.42
    learn_time_ms: 18847.167
    sample_throughput: 23703.245
    sample_time_ms: 6825.732
    update_time_ms: 42.883
  timestamp: 1602514599
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 43ae8_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_43ae8_00000 | RUNNING  | 172.17.0.4:66695 |     14 |           365.01 | 2265088 |  225.765 |              284.566 |              128.354 |            831.427 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_43ae8_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3433.8907084371663
    time_step_min: 3054
  date: 2020-10-12_14-57-05
  done: false
  episode_len_mean: 829.2387482419128
  episode_reward_max: 284.56565656565675
  episode_reward_mean: 226.9806290755657
  episode_reward_min: 128.35353535353502
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: abb29ce576004b5f95025d6ff36773a1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9017603745063146
        entropy_coeff: 0.0005000000000000001
        kl: 0.005951517377980053
        model: {}
        policy_loss: -0.01264588067230458
        total_loss: 10.179479281107584
        vf_explained_var: 0.9765340685844421
        vf_loss: 10.191980838775635
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.03666666666667
    gpu_util_percent0: 0.3153333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.776666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 66695
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1511748313841467
    mean_env_wait_ms: 1.188265490797885
    mean_inference_ms: 4.720177573539785
    mean_raw_obs_processing_ms: 0.3973076917292915
  time_since_restore: 390.8389992713928
  time_this_iter_s: 25.82932209968567
  time_total_s: 390.8389992713928
  timers:
    learn_throughput: 8583.896
    learn_time_ms: 18848.318
    sample_throughput: 23680.594
    sample_time_ms: 6832.261
    update_time_ms: 42.991
  timestamp: 1602514625
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 43ae8_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_43ae8_00000 | RUNNING  | 172.17.0.4:66695 |     15 |          390.839 | 2426880 |  226.981 |              284.566 |              128.354 |            829.239 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_43ae8_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3426.399663299663
    time_step_min: 3054
  date: 2020-10-12_14-57-30
  done: false
  episode_len_mean: 826.922462562396
  episode_reward_max: 284.56565656565675
  episode_reward_mean: 228.09966554059724
  episode_reward_min: 128.35353535353502
  episodes_this_iter: 161
  episodes_total: 3005
  experiment_id: abb29ce576004b5f95025d6ff36773a1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8762048035860062
        entropy_coeff: 0.0005000000000000001
        kl: 0.006493303109891713
        model: {}
        policy_loss: -0.013002060974637667
        total_loss: 14.075467268625895
        vf_explained_var: 0.9701388478279114
        vf_loss: 14.088258266448975
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.980000000000008
    gpu_util_percent0: 0.2856666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7766666666666664
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 66695
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15097022339520574
    mean_env_wait_ms: 1.1894155947201162
    mean_inference_ms: 4.702506383818074
    mean_raw_obs_processing_ms: 0.39646821954196904
  time_since_restore: 416.38196897506714
  time_this_iter_s: 25.542969703674316
  time_total_s: 416.38196897506714
  timers:
    learn_throughput: 8594.381
    learn_time_ms: 18825.323
    sample_throughput: 23724.209
    sample_time_ms: 6819.7
    update_time_ms: 40.82
  timestamp: 1602514650
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 43ae8_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_43ae8_00000 | RUNNING  | 172.17.0.4:66695 |     16 |          416.382 | 2588672 |    228.1 |              284.566 |              128.354 |            826.922 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_43ae8_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3413.207800121877
    time_step_min: 3054
  date: 2020-10-12_14-57-56
  done: false
  episode_len_mean: 822.9445281881218
  episode_reward_max: 290.9292929292928
  episode_reward_mean: 229.984344500172
  episode_reward_min: 128.35353535353502
  episodes_this_iter: 312
  episodes_total: 3317
  experiment_id: abb29ce576004b5f95025d6ff36773a1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.839088092247645
        entropy_coeff: 0.0005000000000000001
        kl: 0.0055505180498585105
        model: {}
        policy_loss: -0.01150182525937756
        total_loss: 16.7764093875885
        vf_explained_var: 0.9746711850166321
        vf_loss: 16.78777551651001
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.04137931034483
    gpu_util_percent0: 0.42551724137931035
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.762068965517241
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 66695
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15061627918023063
    mean_env_wait_ms: 1.1915591224935413
    mean_inference_ms: 4.672124329531188
    mean_raw_obs_processing_ms: 0.395047049949586
  time_since_restore: 441.8480408191681
  time_this_iter_s: 25.466071844100952
  time_total_s: 441.8480408191681
  timers:
    learn_throughput: 8610.173
    learn_time_ms: 18790.796
    sample_throughput: 23806.111
    sample_time_ms: 6796.238
    update_time_ms: 33.711
  timestamp: 1602514676
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 43ae8_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_43ae8_00000 | RUNNING  | 172.17.0.4:66695 |     17 |          441.848 | 2750464 |  229.984 |              290.929 |              128.354 |            822.945 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_43ae8_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3406.6451612903224
    time_step_min: 3054
  date: 2020-10-12_14-58-22
  done: false
  episode_len_mean: 821.0917721518987
  episode_reward_max: 290.9292929292928
  episode_reward_mean: 230.9796817426276
  episode_reward_min: 128.35353535353502
  episodes_this_iter: 159
  episodes_total: 3476
  experiment_id: abb29ce576004b5f95025d6ff36773a1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8368375897407532
        entropy_coeff: 0.0005000000000000001
        kl: 0.005631982310054203
        model: {}
        policy_loss: -0.01084599293123271
        total_loss: 10.226332902908325
        vf_explained_var: 0.9766200184822083
        vf_loss: 10.23703408241272
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.40666666666667
    gpu_util_percent0: 0.2956666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.783333333333333
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 66695
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15045434480097805
    mean_env_wait_ms: 1.1925187299322075
    mean_inference_ms: 4.658321204030453
    mean_raw_obs_processing_ms: 0.39439767221254035
  time_since_restore: 467.5975935459137
  time_this_iter_s: 25.749552726745605
  time_total_s: 467.5975935459137
  timers:
    learn_throughput: 8609.61
    learn_time_ms: 18792.025
    sample_throughput: 23784.313
    sample_time_ms: 6802.467
    update_time_ms: 33.895
  timestamp: 1602514702
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 43ae8_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_43ae8_00000 | RUNNING  | 172.17.0.4:66695 |     18 |          467.598 | 2912256 |   230.98 |              290.929 |              128.354 |            821.092 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_43ae8_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3401.0494444444444
    time_step_min: 3054
  date: 2020-10-12_14-58-48
  done: false
  episode_len_mean: 819.3532324621733
  episode_reward_max: 290.9292929292928
  episode_reward_mean: 231.91557945340608
  episode_reward_min: 128.35353535353502
  episodes_this_iter: 159
  episodes_total: 3635
  experiment_id: abb29ce576004b5f95025d6ff36773a1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8324753443400065
        entropy_coeff: 0.0005000000000000001
        kl: 0.006413979882684846
        model: {}
        policy_loss: -0.01057599096869429
        total_loss: 11.734215180079142
        vf_explained_var: 0.9724454283714294
        vf_loss: 11.744565884272257
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.33666666666667
    gpu_util_percent0: 0.30966666666666665
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.773333333333333
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 66695
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15030468083505347
    mean_env_wait_ms: 1.193485224187149
    mean_inference_ms: 4.645427264307423
    mean_raw_obs_processing_ms: 0.39378699266825135
  time_since_restore: 493.5012743473053
  time_this_iter_s: 25.9036808013916
  time_total_s: 493.5012743473053
  timers:
    learn_throughput: 8602.626
    learn_time_ms: 18807.281
    sample_throughput: 23787.066
    sample_time_ms: 6801.68
    update_time_ms: 33.308
  timestamp: 1602514728
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 43ae8_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_43ae8_00000 | RUNNING  | 172.17.0.4:66695 |     19 |          493.501 | 3074048 |  231.916 |              290.929 |              128.354 |            819.353 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_43ae8_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3390.977389516958
    time_step_min: 3054
  date: 2020-10-12_14-59-14
  done: false
  episode_len_mean: 816.5324675324675
  episode_reward_max: 290.9292929292928
  episode_reward_mean: 233.36511023142032
  episode_reward_min: 128.35353535353502
  episodes_this_iter: 292
  episodes_total: 3927
  experiment_id: abb29ce576004b5f95025d6ff36773a1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7915658603111903
        entropy_coeff: 0.0005000000000000001
        kl: 0.005714234585563342
        model: {}
        policy_loss: -0.009224428193798909
        total_loss: 16.07810894648234
        vf_explained_var: 0.9758429527282715
        vf_loss: 16.08715844154358
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.406666666666673
    gpu_util_percent0: 0.37666666666666665
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.763333333333333
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 66695
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1500513151659073
    mean_env_wait_ms: 1.1951877258551862
    mean_inference_ms: 4.623836575987137
    mean_raw_obs_processing_ms: 0.39277747374298005
  time_since_restore: 519.3563897609711
  time_this_iter_s: 25.85511541366577
  time_total_s: 519.3563897609711
  timers:
    learn_throughput: 8595.616
    learn_time_ms: 18822.617
    sample_throughput: 23793.673
    sample_time_ms: 6799.791
    update_time_ms: 33.103
  timestamp: 1602514754
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 43ae8_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_43ae8_00000 | RUNNING  | 172.17.0.4:66695 |     20 |          519.356 | 3235840 |  233.365 |              290.929 |              128.354 |            816.532 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_43ae8_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3385.9975448072673
    time_step_min: 3019
  date: 2020-10-12_14-59-40
  done: false
  episode_len_mean: 815.0759493670886
  episode_reward_max: 290.9292929292928
  episode_reward_mean: 234.15135040767947
  episode_reward_min: 128.35353535353502
  episodes_this_iter: 181
  episodes_total: 4108
  experiment_id: abb29ce576004b5f95025d6ff36773a1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7875451942284902
        entropy_coeff: 0.0005000000000000001
        kl: 0.005900586722418666
        model: {}
        policy_loss: -0.011265025086080035
        total_loss: 12.707908233006796
        vf_explained_var: 0.9739854335784912
        vf_loss: 12.718976736068726
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.89
    gpu_util_percent0: 0.3003333333333334
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7833333333333328
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 66695
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14991268208141206
    mean_env_wait_ms: 1.196126244385832
    mean_inference_ms: 4.611774571914464
    mean_raw_obs_processing_ms: 0.3922082966572173
  time_since_restore: 545.3724272251129
  time_this_iter_s: 26.016037464141846
  time_total_s: 545.3724272251129
  timers:
    learn_throughput: 8585.376
    learn_time_ms: 18845.068
    sample_throughput: 23732.126
    sample_time_ms: 6817.426
    update_time_ms: 34.878
  timestamp: 1602514780
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: 43ae8_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_43ae8_00000 | RUNNING  | 172.17.0.4:66695 |     21 |          545.372 | 3397632 |  234.151 |              290.929 |              128.354 |            815.076 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_43ae8_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3380.8260458520444
    time_step_min: 3010
  date: 2020-10-12_15-00-06
  done: false
  episode_len_mean: 813.7878574777309
  episode_reward_max: 291.2323232323234
  episode_reward_mean: 234.91894330079978
  episode_reward_min: 128.35353535353502
  episodes_this_iter: 158
  episodes_total: 4266
  experiment_id: abb29ce576004b5f95025d6ff36773a1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.786624605456988
        entropy_coeff: 0.0005000000000000001
        kl: 0.005671430650788049
        model: {}
        policy_loss: -0.012116239978543794
        total_loss: 10.708203315734863
        vf_explained_var: 0.9747191071510315
        vf_loss: 10.72014570236206
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.84666666666667
    gpu_util_percent0: 0.25766666666666665
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7833333333333328
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 66695
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14979691176523519
    mean_env_wait_ms: 1.1969079062548251
    mean_inference_ms: 4.601856782507672
    mean_raw_obs_processing_ms: 0.3917345430884464
  time_since_restore: 571.2259695529938
  time_this_iter_s: 25.85354232788086
  time_total_s: 571.2259695529938
  timers:
    learn_throughput: 8579.641
    learn_time_ms: 18857.666
    sample_throughput: 23716.352
    sample_time_ms: 6821.96
    update_time_ms: 35.352
  timestamp: 1602514806
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: 43ae8_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_43ae8_00000 | RUNNING  | 172.17.0.4:66695 |     22 |          571.226 | 3559424 |  234.919 |              291.232 |              128.354 |            813.788 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_43ae8_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3372.76435246996
    time_step_min: 3010
  date: 2020-10-12_15-00-32
  done: false
  episode_len_mean: 811.6392139545153
  episode_reward_max: 291.2323232323234
  episode_reward_mean: 236.14765004873192
  episode_reward_min: 128.35353535353502
  episodes_this_iter: 263
  episodes_total: 4529
  experiment_id: abb29ce576004b5f95025d6ff36773a1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7510873725016912
        entropy_coeff: 0.0005000000000000001
        kl: 0.005892521197286745
        model: {}
        policy_loss: -0.009724960681827119
        total_loss: 13.870153268178305
        vf_explained_var: 0.9768733978271484
        vf_loss: 13.879664421081543
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.783333333333335
    gpu_util_percent0: 0.3469999999999999
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7766666666666664
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 66695
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14961602629236403
    mean_env_wait_ms: 1.1981937736041648
    mean_inference_ms: 4.58647971649387
    mean_raw_obs_processing_ms: 0.39100095386956474
  time_since_restore: 596.9192793369293
  time_this_iter_s: 25.693309783935547
  time_total_s: 596.9192793369293
  timers:
    learn_throughput: 8585.102
    learn_time_ms: 18845.67
    sample_throughput: 23724.767
    sample_time_ms: 6819.54
    update_time_ms: 33.428
  timestamp: 1602514832
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: 43ae8_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_43ae8_00000 | RUNNING  | 172.17.0.4:66695 |     23 |          596.919 | 3721216 |  236.148 |              291.232 |              128.354 |            811.639 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_43ae8_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3367.1287991498407
    time_step_min: 3010
  date: 2020-10-12_15-00-58
  done: true
  episode_len_mean: 810.2875527426161
  episode_reward_max: 291.2323232323234
  episode_reward_mean: 237.05446873801301
  episode_reward_min: 128.35353535353502
  episodes_this_iter: 211
  episodes_total: 4740
  experiment_id: abb29ce576004b5f95025d6ff36773a1
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7363142818212509
        entropy_coeff: 0.0005000000000000001
        kl: 0.005312932499994834
        model: {}
        policy_loss: -0.010551177416346036
        total_loss: 10.422034819920858
        vf_explained_var: 0.9792265892028809
        vf_loss: 10.432422717412313
    num_steps_sampled: 3883008
    num_steps_trained: 3883008
  iterations_since_restore: 24
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.209999999999997
    gpu_util_percent0: 0.4323333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7666666666666657
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 66695
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14948628400715025
    mean_env_wait_ms: 1.1991268278046607
    mean_inference_ms: 4.5752583299770295
    mean_raw_obs_processing_ms: 0.39047598085297275
  time_since_restore: 622.5367081165314
  time_this_iter_s: 25.61742877960205
  time_total_s: 622.5367081165314
  timers:
    learn_throughput: 8590.66
    learn_time_ms: 18833.476
    sample_throughput: 23749.015
    sample_time_ms: 6812.577
    update_time_ms: 33.28
  timestamp: 1602514858
  timesteps_since_restore: 0
  timesteps_total: 3883008
  training_iteration: 24
  trial_id: 43ae8_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_43ae8_00000 | TERMINATED |       |     24 |          622.537 | 3883008 |  237.054 |              291.232 |              128.354 |            810.288 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.52 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_43ae8_00000 | TERMINATED |       |     24 |          622.537 | 3883008 |  237.054 |              291.232 |              128.354 |            810.288 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


