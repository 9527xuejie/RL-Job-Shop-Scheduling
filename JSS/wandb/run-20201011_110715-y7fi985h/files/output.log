2020-10-11 11:07:17,351	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8266[39m[22m
== Status ==
Memory usage on this node: 32.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_ed8b7_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=11517)[0m 2020-10-11 11:07:20,307	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=11458)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11458)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11409)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11409)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11378)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11378)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11383)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11383)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11439)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11439)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11461)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11461)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11478)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11478)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11379)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11379)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11492)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11492)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11472)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11472)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11382)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11382)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11482)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11482)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11398)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11398)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11462)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11462)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11506)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11506)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11473)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11473)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11476)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11476)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11499)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11499)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11505)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11505)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11516)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11516)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11424)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11424)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11486)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11486)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11494)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11494)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11446)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11446)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11479)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11479)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11391)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11391)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11395)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11395)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11397)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11397)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11413)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11413)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11474)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11474)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11447)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11447)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11469)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11469)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11475)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11475)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11468)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11468)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11510)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11510)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11519)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11519)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11404)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11404)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11466)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11466)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11460)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11460)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11498)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11498)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11403)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11403)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11385)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11385)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11496)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11496)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11453)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11453)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11417)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11417)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11503)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11503)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11520)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11520)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11463)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11463)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11411)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11411)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11381)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11381)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11400)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11400)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11465)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11465)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11420)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11420)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11450)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11450)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11415)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11415)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11455)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11455)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11422)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11422)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11451)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11451)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11419)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11419)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11390)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11390)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11459)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11459)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11467)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11467)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11484)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11484)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11386)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11386)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11440)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11440)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11489)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11489)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11388)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11388)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11393)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11393)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11392)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11392)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11384)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11384)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11442)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11442)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11470)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11470)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11456)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11456)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11480)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11480)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11394)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11394)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11405)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11405)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11454)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11454)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11443)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11443)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11464)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11464)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_ed8b7_00000:
  custom_metrics: {}
  date: 2020-10-11_11-07-43
  done: false
  episode_len_mean: .nan
  episode_reward_max: .nan
  episode_reward_mean: .nan
  episode_reward_min: .nan
  episodes_this_iter: 0
  episodes_total: 0
  experiment_id: ee8f92ed3fe143e58f93e958dfaea929
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 0.00010000000000000002
        entropy: 1.2355760846819197
        entropy_coeff: 0.00010000000000000002
        kl: 0.010150781566543239
        model: {}
        policy_loss: -0.034750696537750106
        total_loss: 483.26939610072543
        vf_explained_var: 0.12598323822021484
        vf_loss: 483.30223301478793
    num_steps_sampled: 80896
    num_steps_trained: 80896
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.990476190476194
    gpu_util_percent0: 0.3447619047619047
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0004761904761904762
    ram_util_percent: 6.061904761904761
    vram_util_percent0: 0.18846928735416763
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 11517
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf: {}
  time_since_restore: 17.069397449493408
  time_this_iter_s: 17.069397449493408
  time_total_s: 17.069397449493408
  timers:
    learn_throughput: 6812.619
    learn_time_ms: 11874.434
    sample_throughput: 15793.705
    sample_time_ms: 5122.041
    update_time_ms: 46.92
  timestamp: 1602414463
  timesteps_since_restore: 0
  timesteps_total: 80896
  training_iteration: 1
  trial_id: ed8b7_00000
  
== Status ==
Memory usage on this node: 46.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |      1 |          17.0694 | 80896 |      nan |                  nan |                  nan |                nan |
+-------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed8b7_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3621.1951219512193
    time_step_min: 3341
  date: 2020-10-11_11-07-59
  done: false
  episode_len_mean: 890.7215189873418
  episode_reward_max: 264.20202020201947
  episode_reward_mean: 215.95211609768555
  episode_reward_min: 129.0505050505048
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: ee8f92ed3fe143e58f93e958dfaea929
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 0.00010000000000000002
        entropy: 1.104918122291565
        entropy_coeff: 0.00010000000000000002
        kl: 0.010646762725497996
        model: {}
        policy_loss: -0.02715139969119004
        total_loss: 541.7598702566964
        vf_explained_var: 0.5573452711105347
        vf_loss: 541.7850167410714
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.663157894736845
    gpu_util_percent0: 0.35105263157894734
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.178947368421054
    vram_util_percent0: 0.2038373237126927
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 11517
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17199406472206408
    mean_env_wait_ms: 1.2088235111360235
    mean_inference_ms: 5.708397346795727
    mean_raw_obs_processing_ms: 0.4642650336901248
  time_since_restore: 33.077258348464966
  time_this_iter_s: 16.007860898971558
  time_total_s: 33.077258348464966
  timers:
    learn_throughput: 6884.162
    learn_time_ms: 11751.032
    sample_throughput: 17143.081
    sample_time_ms: 4718.872
    update_time_ms: 36.16
  timestamp: 1602414479
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 2
  trial_id: ed8b7_00000
  
== Status ==
Memory usage on this node: 46.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |      2 |          33.0773 | 161792 |  215.952 |              264.202 |              129.051 |            890.722 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed8b7_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3621.1951219512193
    time_step_min: 3341
  date: 2020-10-11_11-08-14
  done: false
  episode_len_mean: 890.7215189873418
  episode_reward_max: 264.20202020201947
  episode_reward_mean: 215.95211609768555
  episode_reward_min: 129.0505050505048
  episodes_this_iter: 0
  episodes_total: 158
  experiment_id: ee8f92ed3fe143e58f93e958dfaea929
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 0.00010000000000000002
        entropy: 1.1451326949255807
        entropy_coeff: 0.00010000000000000002
        kl: 0.013103859898235117
        model: {}
        policy_loss: -0.03772170841693878
        total_loss: 61.807167053222656
        vf_explained_var: 0.3047725260257721
        vf_loss: 61.842381068638396
    num_steps_sampled: 242688
    num_steps_trained: 242688
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.03684210526316
    gpu_util_percent0: 0.3068421052631579
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.205263157894738
    vram_util_percent0: 0.2038373237126927
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 11517
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17199406472206408
    mean_env_wait_ms: 1.2088235111360235
    mean_inference_ms: 5.708397346795727
    mean_raw_obs_processing_ms: 0.4642650336901248
  time_since_restore: 48.5854651927948
  time_this_iter_s: 15.508206844329834
  time_total_s: 48.5854651927948
  timers:
    learn_throughput: 6932.543
    learn_time_ms: 11669.022
    sample_throughput: 18134.025
    sample_time_ms: 4461.006
    update_time_ms: 31.075
  timestamp: 1602414494
  timesteps_since_restore: 0
  timesteps_total: 242688
  training_iteration: 3
  trial_id: ed8b7_00000
  
== Status ==
Memory usage on this node: 46.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |      3 |          48.5855 | 242688 |  215.952 |              264.202 |              129.051 |            890.722 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed8b7_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3618.8718861209964
    time_step_min: 3341
  date: 2020-10-11_11-08-30
  done: false
  episode_len_mean: 879.4493670886076
  episode_reward_max: 268.4444444444444
  episode_reward_mean: 217.9453075054339
  episode_reward_min: 129.0505050505048
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: ee8f92ed3fe143e58f93e958dfaea929
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 0.00010000000000000002
        entropy: 1.1018210308892387
        entropy_coeff: 0.00010000000000000002
        kl: 0.011968836055270262
        model: {}
        policy_loss: -0.030419912987521718
        total_loss: 338.2612871442522
        vf_explained_var: 0.7406534552574158
        vf_loss: 338.2894199916295
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.910526315789475
    gpu_util_percent0: 0.4221052631578948
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.205263157894738
    vram_util_percent0: 0.2038373237126927
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 11517
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1664683872326604
    mean_env_wait_ms: 1.2090395135359495
    mean_inference_ms: 5.448400692912778
    mean_raw_obs_processing_ms: 0.44806285347677643
  time_since_restore: 64.0004415512085
  time_this_iter_s: 15.414976358413696
  time_total_s: 64.0004415512085
  timers:
    learn_throughput: 6942.391
    learn_time_ms: 11652.47
    sample_throughput: 18954.078
    sample_time_ms: 4268.0
    update_time_ms: 31.145
  timestamp: 1602414510
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 4
  trial_id: ed8b7_00000
  
== Status ==
Memory usage on this node: 46.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |      4 |          64.0004 | 323584 |  217.945 |              268.444 |              129.051 |            879.449 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed8b7_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3619.0141843971633
    time_step_min: 3341
  date: 2020-10-11_11-08-45
  done: false
  episode_len_mean: 879.3028391167193
  episode_reward_max: 268.4444444444444
  episode_reward_mean: 217.9397125832455
  episode_reward_min: 129.0505050505048
  episodes_this_iter: 1
  episodes_total: 317
  experiment_id: ee8f92ed3fe143e58f93e958dfaea929
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 0.00010000000000000002
        entropy: 1.0629650694983346
        entropy_coeff: 0.00010000000000000002
        kl: 0.013246477182422365
        model: {}
        policy_loss: -0.0353440453431436
        total_loss: 32.55528858729771
        vf_explained_var: 0.8335528373718262
        vf_loss: 32.588090079171316
    num_steps_sampled: 404480
    num_steps_trained: 404480
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.61666666666666
    gpu_util_percent0: 0.3338888888888889
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.222222222222222
    vram_util_percent0: 0.2038373237126927
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 11517
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1664021890297938
    mean_env_wait_ms: 1.2090652828885642
    mean_inference_ms: 5.445749303343484
    mean_raw_obs_processing_ms: 0.44791848390135747
  time_since_restore: 79.37057852745056
  time_this_iter_s: 15.370136976242065
  time_total_s: 79.37057852745056
  timers:
    learn_throughput: 6943.782
    learn_time_ms: 11650.135
    sample_throughput: 19496.779
    sample_time_ms: 4149.198
    update_time_ms: 29.133
  timestamp: 1602414525
  timesteps_since_restore: 0
  timesteps_total: 404480
  training_iteration: 5
  trial_id: ed8b7_00000
  
== Status ==
Memory usage on this node: 46.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |      5 |          79.3706 | 404480 |   217.94 |              268.444 |              129.051 |            879.303 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed8b7_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3614.5466970387242
    time_step_min: 3301
  date: 2020-10-11_11-09-01
  done: false
  episode_len_mean: 874.873417721519
  episode_reward_max: 268.4444444444444
  episode_reward_mean: 218.84496867408242
  episode_reward_min: 129.0505050505048
  episodes_this_iter: 157
  episodes_total: 474
  experiment_id: ee8f92ed3fe143e58f93e958dfaea929
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 0.00010000000000000002
        entropy: 1.1305710928780692
        entropy_coeff: 0.00010000000000000002
        kl: 0.00940956494637898
        model: {}
        policy_loss: -0.02775775800858225
        total_loss: 86.53898402622768
        vf_explained_var: 0.8763986229896545
        vf_loss: 86.56497410365513
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.37368421052631
    gpu_util_percent0: 0.3310526315789474
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.1947368421052635
    vram_util_percent0: 0.2038373237126927
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 11517
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16330449318082624
    mean_env_wait_ms: 1.2084176545278669
    mean_inference_ms: 5.27002022088971
    mean_raw_obs_processing_ms: 0.43788779842756653
  time_since_restore: 94.90622282028198
  time_this_iter_s: 15.535644292831421
  time_total_s: 94.90622282028198
  timers:
    learn_throughput: 6931.717
    learn_time_ms: 11670.414
    sample_throughput: 19865.372
    sample_time_ms: 4072.212
    update_time_ms: 30.704
  timestamp: 1602414541
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 6
  trial_id: ed8b7_00000
  
== Status ==
Memory usage on this node: 46.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |      6 |          94.9062 | 485376 |  218.845 |              268.444 |              129.051 |            874.873 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed8b7_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3599.7512605042016
    time_step_min: 3234
  date: 2020-10-11_11-09-16
  done: false
  episode_len_mean: 870.7253968253968
  episode_reward_max: 282.68686868686825
  episode_reward_mean: 221.0759980759979
  episode_reward_min: 129.0505050505048
  episodes_this_iter: 156
  episodes_total: 630
  experiment_id: ee8f92ed3fe143e58f93e958dfaea929
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 0.00010000000000000002
        entropy: 1.0338162354060583
        entropy_coeff: 0.00010000000000000002
        kl: 0.01128895820251533
        model: {}
        policy_loss: -0.030630421425615038
        total_loss: 76.87986101422992
        vf_explained_var: 0.9067110419273376
        vf_loss: 76.90833718436105
    num_steps_sampled: 566272
    num_steps_trained: 566272
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.899999999999995
    gpu_util_percent0: 0.34444444444444444
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.211111111111112
    vram_util_percent0: 0.2038373237126927
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 11517
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16143699532427172
    mean_env_wait_ms: 1.2088684311529978
    mean_inference_ms: 5.161913655684243
    mean_raw_obs_processing_ms: 0.4322594420046009
  time_since_restore: 110.28288292884827
  time_this_iter_s: 15.376660108566284
  time_total_s: 110.28288292884827
  timers:
    learn_throughput: 6934.629
    learn_time_ms: 11665.512
    sample_throughput: 20147.728
    sample_time_ms: 4015.143
    update_time_ms: 30.898
  timestamp: 1602414556
  timesteps_since_restore: 0
  timesteps_total: 566272
  training_iteration: 7
  trial_id: ed8b7_00000
  
== Status ==
Memory usage on this node: 46.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |      7 |          110.283 | 566272 |  221.076 |              282.687 |              129.051 |            870.725 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed8b7_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3600.165829145729
    time_step_min: 3234
  date: 2020-10-11_11-09-32
  done: false
  episode_len_mean: 870.8433544303797
  episode_reward_max: 282.68686868686825
  episode_reward_mean: 221.01516749776226
  episode_reward_min: 129.0505050505048
  episodes_this_iter: 2
  episodes_total: 632
  experiment_id: ee8f92ed3fe143e58f93e958dfaea929
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 0.00010000000000000002
        entropy: 1.0777911799294608
        entropy_coeff: 0.00010000000000000002
        kl: 0.012940970515566213
        model: {}
        policy_loss: -0.03934905957430601
        total_loss: 11.274031366620745
        vf_explained_var: 0.8349117636680603
        vf_loss: 11.310900688171387
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.973684210526315
    gpu_util_percent0: 0.3068421052631579
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.215789473684211
    vram_util_percent0: 0.2038373237126927
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 11517
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1614256084534045
    mean_env_wait_ms: 1.2089110374403544
    mean_inference_ms: 5.160506855743884
    mean_raw_obs_processing_ms: 0.4322031186244616
  time_since_restore: 125.68149065971375
  time_this_iter_s: 15.398607730865479
  time_total_s: 125.68149065971375
  timers:
    learn_throughput: 6932.158
    learn_time_ms: 11669.671
    sample_throughput: 20402.25
    sample_time_ms: 3965.053
    update_time_ms: 32.067
  timestamp: 1602414572
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 8
  trial_id: ed8b7_00000
  
== Status ==
Memory usage on this node: 46.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |      8 |          125.681 | 647168 |  221.015 |              282.687 |              129.051 |            870.843 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed8b7_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3583.548344370861
    time_step_min: 3234
  date: 2020-10-11_11-09-47
  done: false
  episode_len_mean: 864.9392405063292
  episode_reward_max: 282.68686868686825
  episode_reward_mean: 223.6602096918551
  episode_reward_min: 129.0505050505048
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: ee8f92ed3fe143e58f93e958dfaea929
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 0.00010000000000000002
        entropy: 1.0281649146761214
        entropy_coeff: 0.00010000000000000002
        kl: 0.010988853871822357
        model: {}
        policy_loss: -0.03038667674575533
        total_loss: 99.28263092041016
        vf_explained_var: 0.9136572480201721
        vf_loss: 99.31092398507255
    num_steps_sampled: 728064
    num_steps_trained: 728064
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.577777777777776
    gpu_util_percent0: 0.35444444444444445
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.211111111111112
    vram_util_percent0: 0.2038373237126927
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 11517
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15995345913671608
    mean_env_wait_ms: 1.2100571945889735
    mean_inference_ms: 5.073819843280334
    mean_raw_obs_processing_ms: 0.42774308899470204
  time_since_restore: 140.99153351783752
  time_this_iter_s: 15.31004285812378
  time_total_s: 140.99153351783752
  timers:
    learn_throughput: 6935.861
    learn_time_ms: 11663.441
    sample_throughput: 20591.808
    sample_time_ms: 3928.553
    update_time_ms: 31.2
  timestamp: 1602414587
  timesteps_since_restore: 0
  timesteps_total: 728064
  training_iteration: 9
  trial_id: ed8b7_00000
  
== Status ==
Memory usage on this node: 46.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |      9 |          140.992 | 728064 |   223.66 |              282.687 |              129.051 |            864.939 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed8b7_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3581.105128205128
    time_step_min: 3234
  date: 2020-10-11_11-10-02
  done: false
  episode_len_mean: 863.6822085889571
  episode_reward_max: 282.68686868686825
  episode_reward_mean: 224.0084898060356
  episode_reward_min: 129.0505050505048
  episodes_this_iter: 25
  episodes_total: 815
  experiment_id: ee8f92ed3fe143e58f93e958dfaea929
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 0.00010000000000000002
        entropy: 0.987507028239114
        entropy_coeff: 0.00010000000000000002
        kl: 0.013111596660954612
        model: {}
        policy_loss: -0.03521772553878171
        total_loss: 20.77414403642927
        vf_explained_var: 0.9506732225418091
        vf_loss: 20.806838989257812
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.28421052631579
    gpu_util_percent0: 0.3494736842105264
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.215789473684211
    vram_util_percent0: 0.2038373237126927
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 11517
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15973198961384183
    mean_env_wait_ms: 1.2103405669664478
    mean_inference_ms: 5.061434809621857
    mean_raw_obs_processing_ms: 0.42702146120421813
  time_since_restore: 156.33395624160767
  time_this_iter_s: 15.342422723770142
  time_total_s: 156.33395624160767
  timers:
    learn_throughput: 6938.897
    learn_time_ms: 11658.337
    sample_throughput: 20727.776
    sample_time_ms: 3902.782
    update_time_ms: 30.607
  timestamp: 1602414602
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 10
  trial_id: ed8b7_00000
  
== Status ==
Memory usage on this node: 46.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     10 |          156.334 | 808960 |  224.008 |              282.687 |              129.051 |            863.682 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed8b7_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3571.9802847754654
    time_step_min: 3234
  date: 2020-10-11_11-10-18
  done: false
  episode_len_mean: 859.967299578059
  episode_reward_max: 282.68686868686825
  episode_reward_mean: 225.29475131057393
  episode_reward_min: 129.0505050505048
  episodes_this_iter: 133
  episodes_total: 948
  experiment_id: ee8f92ed3fe143e58f93e958dfaea929
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 0.00010000000000000002
        entropy: 1.045826860836574
        entropy_coeff: 0.00010000000000000002
        kl: 0.009954532741435937
        model: {}
        policy_loss: -0.029595830610820224
        total_loss: 18.947863715035574
        vf_explained_var: 0.9571961164474487
        vf_loss: 18.975573131016322
    num_steps_sampled: 889856
    num_steps_trained: 889856
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.211111111111112
    gpu_util_percent0: 0.3644444444444444
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.194444444444445
    vram_util_percent0: 0.2038373237126927
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 11517
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15879813645463797
    mean_env_wait_ms: 1.211128149274603
    mean_inference_ms: 5.005509192438234
    mean_raw_obs_processing_ms: 0.42413205982647995
  time_since_restore: 171.7176637649536
  time_this_iter_s: 15.383707523345947
  time_total_s: 171.7176637649536
  timers:
    learn_throughput: 6953.498
    learn_time_ms: 11633.857
    sample_throughput: 21513.646
    sample_time_ms: 3760.218
    update_time_ms: 28.069
  timestamp: 1602414618
  timesteps_since_restore: 0
  timesteps_total: 889856
  training_iteration: 11
  trial_id: ed8b7_00000
  
== Status ==
Memory usage on this node: 46.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     11 |          171.718 | 889856 |  225.295 |              282.687 |              129.051 |            859.967 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed8b7_00000:
  custom_metrics:
    time_step_max: 4279
    time_step_mean: 3566.089635854342
    time_step_min: 3234
  date: 2020-10-11_11-10-33
  done: false
  episode_len_mean: 856.50904159132
  episode_reward_max: 282.68686868686825
  episode_reward_mean: 226.2248707691744
  episode_reward_min: 117.68686868686848
  episodes_this_iter: 158
  episodes_total: 1106
  experiment_id: ee8f92ed3fe143e58f93e958dfaea929
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 0.00010000000000000002
        entropy: 0.9601052488599505
        entropy_coeff: 0.00010000000000000002
        kl: 0.012055230060858386
        model: {}
        policy_loss: -0.030359721343432153
        total_loss: 37.07370104108538
        vf_explained_var: 0.9558514952659607
        vf_loss: 37.10174560546875
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.46315789473684
    gpu_util_percent0: 0.3863157894736842
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.210526315789474
    vram_util_percent0: 0.2038373237126927
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 11517
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15789295050711372
    mean_env_wait_ms: 1.2122332529673068
    mean_inference_ms: 4.951915592301066
    mean_raw_obs_processing_ms: 0.4213907139795608
  time_since_restore: 187.1134786605835
  time_this_iter_s: 15.395814895629883
  time_total_s: 187.1134786605835
  timers:
    learn_throughput: 6954.196
    learn_time_ms: 11632.689
    sample_throughput: 21859.474
    sample_time_ms: 3700.729
    update_time_ms: 27.535
  timestamp: 1602414633
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 12
  trial_id: ed8b7_00000
  
== Status ==
Memory usage on this node: 46.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     12 |          187.113 | 970752 |  226.225 |              282.687 |              117.687 |            856.509 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed8b7_00000:
  custom_metrics:
    time_step_max: 4279
    time_step_mean: 3566.089635854342
    time_step_min: 3234
  date: 2020-10-11_11-10-49
  done: false
  episode_len_mean: 856.50904159132
  episode_reward_max: 282.68686868686825
  episode_reward_mean: 226.2248707691744
  episode_reward_min: 117.68686868686848
  episodes_this_iter: 0
  episodes_total: 1106
  experiment_id: ee8f92ed3fe143e58f93e958dfaea929
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 0.00010000000000000002
        entropy: 0.9797454476356506
        entropy_coeff: 0.00010000000000000002
        kl: 0.012896751053631306
        model: {}
        policy_loss: -0.041537076767001836
        total_loss: 7.74065773827689
        vf_explained_var: 0.9532109498977661
        vf_loss: 7.779713494437082
    num_steps_sampled: 1051648
    num_steps_trained: 1051648
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.205555555555556
    gpu_util_percent0: 0.36388888888888893
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.216666666666667
    vram_util_percent0: 0.2038373237126927
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 11517
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1578929505071137
    mean_env_wait_ms: 1.2122332529673068
    mean_inference_ms: 4.951915592301066
    mean_raw_obs_processing_ms: 0.42139071397956074
  time_since_restore: 202.41565418243408
  time_this_iter_s: 15.302175521850586
  time_total_s: 202.41565418243408
  timers:
    learn_throughput: 6946.916
    learn_time_ms: 11644.879
    sample_throughput: 22062.043
    sample_time_ms: 3666.75
    update_time_ms: 28.95
  timestamp: 1602414649
  timesteps_since_restore: 0
  timesteps_total: 1051648
  training_iteration: 13
  trial_id: ed8b7_00000
  
== Status ==
Memory usage on this node: 46.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     13 |          202.416 | 1051648 |  226.225 |              282.687 |              117.687 |            856.509 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed8b7_00000:
  custom_metrics:
    time_step_max: 4279
    time_step_mean: 3559.820179007323
    time_step_min: 3212
  date: 2020-10-11_11-11-04
  done: false
  episode_len_mean: 853.4018987341772
  episode_reward_max: 282.68686868686825
  episode_reward_mean: 227.41044943101886
  episode_reward_min: 117.68686868686848
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: ee8f92ed3fe143e58f93e958dfaea929
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 0.00010000000000000002
        entropy: 0.9573245303971427
        entropy_coeff: 0.00010000000000000002
        kl: 0.010491540655493736
        model: {}
        policy_loss: -0.02854319236108235
        total_loss: 28.880344118390763
        vf_explained_var: 0.9712379574775696
        vf_loss: 28.906884329659597
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.321052631578947
    gpu_util_percent0: 0.2831578947368421
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.215789473684211
    vram_util_percent0: 0.2038373237126927
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 11517
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1571431737437744
    mean_env_wait_ms: 1.213288599347626
    mean_inference_ms: 4.906653870888696
    mean_raw_obs_processing_ms: 0.4189866891285491
  time_since_restore: 217.90839791297913
  time_this_iter_s: 15.492743730545044
  time_total_s: 217.90839791297913
  timers:
    learn_throughput: 6942.93
    learn_time_ms: 11651.565
    sample_throughput: 22027.115
    sample_time_ms: 3672.564
    update_time_ms: 29.496
  timestamp: 1602414664
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 14
  trial_id: ed8b7_00000
  
== Status ==
Memory usage on this node: 46.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     14 |          217.908 | 1132544 |   227.41 |              282.687 |              117.687 |            853.402 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed8b7_00000:
  custom_metrics:
    time_step_max: 4279
    time_step_mean: 3553.6249062265565
    time_step_min: 3212
  date: 2020-10-11_11-11-20
  done: false
  episode_len_mean: 851.2441520467836
  episode_reward_max: 282.68686868686825
  episode_reward_mean: 228.1558125110755
  episode_reward_min: 117.68686868686848
  episodes_this_iter: 104
  episodes_total: 1368
  experiment_id: ee8f92ed3fe143e58f93e958dfaea929
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 0.00010000000000000002
        entropy: 0.9227380497114999
        entropy_coeff: 0.00010000000000000002
        kl: 0.012362753839365073
        model: {}
        policy_loss: -0.03274130182606833
        total_loss: 24.246925626482284
        vf_explained_var: 0.9645282626152039
        vf_loss: 24.277286802019393
    num_steps_sampled: 1213440
    num_steps_trained: 1213440
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.694444444444443
    gpu_util_percent0: 0.37611111111111106
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.211111111111112
    vram_util_percent0: 0.2038373237126927
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 11517
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15669643186371113
    mean_env_wait_ms: 1.213879770455507
    mean_inference_ms: 4.880938505249473
    mean_raw_obs_processing_ms: 0.41758802125738176
  time_since_restore: 233.22773909568787
  time_this_iter_s: 15.31934118270874
  time_total_s: 233.22773909568787
  timers:
    learn_throughput: 6940.425
    learn_time_ms: 11655.771
    sample_throughput: 22087.15
    sample_time_ms: 3662.582
    update_time_ms: 29.445
  timestamp: 1602414680
  timesteps_since_restore: 0
  timesteps_total: 1213440
  training_iteration: 15
  trial_id: ed8b7_00000
  
== Status ==
Memory usage on this node: 46.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     15 |          233.228 | 1213440 |  228.156 |              282.687 |              117.687 |            851.244 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed8b7_00000:
  custom_metrics:
    time_step_max: 4279
    time_step_mean: 3550.6575342465753
    time_step_min: 3212
  date: 2020-10-11_11-11-35
  done: false
  episode_len_mean: 850.6476793248945
  episode_reward_max: 282.68686868686825
  episode_reward_mean: 228.66575033030716
  episode_reward_min: 117.68686868686848
  episodes_this_iter: 54
  episodes_total: 1422
  experiment_id: ee8f92ed3fe143e58f93e958dfaea929
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 0.00010000000000000002
        entropy: 0.9501965812274388
        entropy_coeff: 0.00010000000000000002
        kl: 0.011891363986900874
        model: {}
        policy_loss: -0.03691769976701055
        total_loss: 6.539995942796979
        vf_explained_var: 0.9532654881477356
        vf_loss: 6.574630396706717
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.257894736842108
    gpu_util_percent0: 0.3689473684210527
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.205263157894738
    vram_util_percent0: 0.2038373237126927
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 11517
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15652106777015845
    mean_env_wait_ms: 1.2141530806568188
    mean_inference_ms: 4.869173612186312
    mean_raw_obs_processing_ms: 0.41700752465286606
  time_since_restore: 248.63334608078003
  time_this_iter_s: 15.405606985092163
  time_total_s: 248.63334608078003
  timers:
    learn_throughput: 6948.54
    learn_time_ms: 11642.158
    sample_throughput: 22107.419
    sample_time_ms: 3659.224
    update_time_ms: 27.808
  timestamp: 1602414695
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 16
  trial_id: ed8b7_00000
  
== Status ==
Memory usage on this node: 46.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     16 |          248.633 | 1294336 |  228.666 |              282.687 |              117.687 |            850.648 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed8b7_00000:
  custom_metrics:
    time_step_max: 4279
    time_step_mean: 3544.044012944984
    time_step_min: 3212
  date: 2020-10-11_11-11-51
  done: false
  episode_len_mean: 847.9379746835443
  episode_reward_max: 282.68686868686825
  episode_reward_mean: 229.5562587904359
  episode_reward_min: 117.68686868686848
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: ee8f92ed3fe143e58f93e958dfaea929
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 0.00010000000000000002
        entropy: 0.8869837948254177
        entropy_coeff: 0.00010000000000000002
        kl: 0.010574847858931338
        model: {}
        policy_loss: -0.030033384316733906
        total_loss: 23.887325014386857
        vf_explained_var: 0.9734358191490173
        vf_loss: 23.9153322492327
    num_steps_sampled: 1375232
    num_steps_trained: 1375232
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.12777777777778
    gpu_util_percent0: 0.37111111111111117
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.211111111111112
    vram_util_percent0: 0.2038373237126927
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 11517
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15598861878496514
    mean_env_wait_ms: 1.2151207173575873
    mean_inference_ms: 4.836795072091276
    mean_raw_obs_processing_ms: 0.41531330512907777
  time_since_restore: 264.00063276290894
  time_this_iter_s: 15.367286682128906
  time_total_s: 264.00063276290894
  timers:
    learn_throughput: 6950.277
    learn_time_ms: 11639.249
    sample_throughput: 22092.804
    sample_time_ms: 3661.645
    update_time_ms: 26.446
  timestamp: 1602414711
  timesteps_since_restore: 0
  timesteps_total: 1375232
  training_iteration: 17
  trial_id: ed8b7_00000
  
== Status ==
Memory usage on this node: 46.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     17 |          264.001 | 1375232 |  229.556 |              282.687 |              117.687 |            847.938 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed8b7_00000:
  custom_metrics:
    time_step_max: 4279
    time_step_mean: 3543.446233097231
    time_step_min: 3212
  date: 2020-10-11_11-12-06
  done: false
  episode_len_mean: 847.7896725440806
  episode_reward_max: 282.68686868686825
  episode_reward_mean: 229.63910515736697
  episode_reward_min: 117.68686868686848
  episodes_this_iter: 8
  episodes_total: 1588
  experiment_id: ee8f92ed3fe143e58f93e958dfaea929
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 0.00010000000000000002
        entropy: 0.8809702311243329
        entropy_coeff: 0.00010000000000000002
        kl: 0.013751132280698844
        model: {}
        policy_loss: -0.04006186420364039
        total_loss: 8.013969761984688
        vf_explained_var: 0.9799981117248535
        vf_loss: 8.05136946269444
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.18888888888889
    gpu_util_percent0: 0.34388888888888886
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.216666666666667
    vram_util_percent0: 0.2038373237126927
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 11517
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15596295876330984
    mean_env_wait_ms: 1.2152144628972157
    mean_inference_ms: 4.835293774425444
    mean_raw_obs_processing_ms: 0.4152315100989919
  time_since_restore: 279.209707736969
  time_this_iter_s: 15.209074974060059
  time_total_s: 279.209707736969
  timers:
    learn_throughput: 6958.713
    learn_time_ms: 11625.139
    sample_throughput: 22105.921
    sample_time_ms: 3659.472
    update_time_ms: 24.606
  timestamp: 1602414726
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 18
  trial_id: ed8b7_00000
  
== Status ==
Memory usage on this node: 46.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     18 |           279.21 | 1456128 |  229.639 |              282.687 |              117.687 |             847.79 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed8b7_00000:
  custom_metrics:
    time_step_max: 4279
    time_step_mean: 3538.6934820904285
    time_step_min: 3212
  date: 2020-10-11_11-12-22
  done: false
  episode_len_mean: 846.4361334867664
  episode_reward_max: 282.68686868686825
  episode_reward_mean: 230.19087886924467
  episode_reward_min: 117.68686868686848
  episodes_this_iter: 150
  episodes_total: 1738
  experiment_id: ee8f92ed3fe143e58f93e958dfaea929
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 0.00010000000000000002
        entropy: 0.8852814521108355
        entropy_coeff: 0.00010000000000000002
        kl: 0.0099599530388202
        model: {}
        policy_loss: -0.027756639091031893
        total_loss: 17.517151968819753
        vf_explained_var: 0.9784713387489319
        vf_loss: 17.543005534580775
    num_steps_sampled: 1537024
    num_steps_trained: 1537024
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.321052631578947
    gpu_util_percent0: 0.3547368421052632
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.189473684210527
    vram_util_percent0: 0.2038373237126927
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 11517
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15553169296870034
    mean_env_wait_ms: 1.2159003987180077
    mean_inference_ms: 4.808477786258893
    mean_raw_obs_processing_ms: 0.4138048648065393
  time_since_restore: 294.74597215652466
  time_this_iter_s: 15.536264419555664
  time_total_s: 294.74597215652466
  timers:
    learn_throughput: 6952.935
    learn_time_ms: 11634.798
    sample_throughput: 22040.273
    sample_time_ms: 3670.372
    update_time_ms: 25.99
  timestamp: 1602414742
  timesteps_since_restore: 0
  timesteps_total: 1537024
  training_iteration: 19
  trial_id: ed8b7_00000
  
== Status ==
Memory usage on this node: 46.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     19 |          294.746 | 1537024 |  230.191 |              282.687 |              117.687 |            846.436 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed8b7_00000:
  custom_metrics:
    time_step_max: 4279
    time_step_mean: 3532.3775620280476
    time_step_min: 3212
  date: 2020-10-11_11-12-37
  done: false
  episode_len_mean: 844.0365272631021
  episode_reward_max: 282.68686868686825
  episode_reward_mean: 231.15752014587363
  episode_reward_min: 117.68686868686848
  episodes_this_iter: 151
  episodes_total: 1889
  experiment_id: ee8f92ed3fe143e58f93e958dfaea929
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 0.00010000000000000002
        entropy: 0.8439452222415379
        entropy_coeff: 0.00010000000000000002
        kl: 0.01139848040682929
        model: {}
        policy_loss: -0.03071598948112556
        total_loss: 18.11450685773577
        vf_explained_var: 0.9758296608924866
        vf_loss: 18.143027441842214
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.226315789473684
    gpu_util_percent0: 0.3752631578947369
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.210526315789474
    vram_util_percent0: 0.2038373237126927
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 11517
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1551511801015778
    mean_env_wait_ms: 1.2166455419470106
    mean_inference_ms: 4.784982314134217
    mean_raw_obs_processing_ms: 0.4125990287185259
  time_since_restore: 310.2400779724121
  time_this_iter_s: 15.494105815887451
  time_total_s: 310.2400779724121
  timers:
    learn_throughput: 6943.523
    learn_time_ms: 11650.57
    sample_throughput: 22063.796
    sample_time_ms: 3666.459
    update_time_ms: 28.532
  timestamp: 1602414757
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 20
  trial_id: ed8b7_00000
  
== Status ==
Memory usage on this node: 46.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     20 |           310.24 | 1617920 |  231.158 |              282.687 |              117.687 |            844.037 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed8b7_00000:
  custom_metrics:
    time_step_max: 4279
    time_step_mean: 3531.802256851155
    time_step_min: 3212
  date: 2020-10-11_11-12-53
  done: false
  episode_len_mean: 843.964135021097
  episode_reward_max: 282.68686868686825
  episode_reward_mean: 231.25578570515262
  episode_reward_min: 117.68686868686848
  episodes_this_iter: 7
  episodes_total: 1896
  experiment_id: ee8f92ed3fe143e58f93e958dfaea929
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 0.00010000000000000002
        entropy: 0.849527929510389
        entropy_coeff: 0.00010000000000000002
        kl: 0.012149149152849401
        model: {}
        policy_loss: -0.0404457508453301
        total_loss: 5.171197891235352
        vf_explained_var: 0.9693788886070251
        vf_loss: 5.209298746926444
    num_steps_sampled: 1698816
    num_steps_trained: 1698816
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.477777777777774
    gpu_util_percent0: 0.3211111111111111
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.216666666666667
    vram_util_percent0: 0.2038373237126927
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 11517
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15513663481693202
    mean_env_wait_ms: 1.2166701954384804
    mean_inference_ms: 4.784032923931228
    mean_raw_obs_processing_ms: 0.412545884382204
  time_since_restore: 325.52921962738037
  time_this_iter_s: 15.289141654968262
  time_total_s: 325.52921962738037
  timers:
    learn_throughput: 6945.797
    learn_time_ms: 11646.755
    sample_throughput: 22099.962
    sample_time_ms: 3660.459
    update_time_ms: 28.36
  timestamp: 1602414773
  timesteps_since_restore: 0
  timesteps_total: 1698816
  training_iteration: 21
  trial_id: ed8b7_00000
  
== Status ==
Memory usage on this node: 46.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     21 |          325.529 | 1698816 |  231.256 |              282.687 |              117.687 |            843.964 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed8b7_00000:
  custom_metrics:
    time_step_max: 4279
    time_step_mean: 3524.741456166419
    time_step_min: 3212
  date: 2020-10-11_11-13-08
  done: false
  episode_len_mean: 841.4780915287245
  episode_reward_max: 282.68686868686825
  episode_reward_mean: 232.2242089837025
  episode_reward_min: 117.68686868686848
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: ee8f92ed3fe143e58f93e958dfaea929
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 0.00010000000000000002
        entropy: 0.8218174661908831
        entropy_coeff: 0.00010000000000000002
        kl: 0.010251943288104874
        model: {}
        policy_loss: -0.02944521393094744
        total_loss: 17.44329833984375
        vf_explained_var: 0.9816536903381348
        vf_loss: 17.47077533176967
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.842105263157894
    gpu_util_percent0: 0.4152631578947369
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.210526315789474
    vram_util_percent0: 0.2038373237126927
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 11517
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15478313317442852
    mean_env_wait_ms: 1.2174722675860634
    mean_inference_ms: 4.762186846049648
    mean_raw_obs_processing_ms: 0.41139221014187294
  time_since_restore: 340.94291734695435
  time_this_iter_s: 15.413697719573975
  time_total_s: 340.94291734695435
  timers:
    learn_throughput: 6938.785
    learn_time_ms: 11658.525
    sample_throughput: 22166.284
    sample_time_ms: 3649.507
    update_time_ms: 28.858
  timestamp: 1602414788
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 22
  trial_id: ed8b7_00000
  
== Status ==
Memory usage on this node: 46.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     22 |          340.943 | 1779712 |  232.224 |              282.687 |              117.687 |            841.478 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed8b7_00000:
  custom_metrics:
    time_step_max: 4279
    time_step_mean: 3521.2922932330825
    time_step_min: 3174
  date: 2020-10-11_11-13-24
  done: false
  episode_len_mean: 839.4711049468331
  episode_reward_max: 285.1111111111108
  episode_reward_mean: 232.7377239804423
  episode_reward_min: 117.68686868686848
  episodes_this_iter: 109
  episodes_total: 2163
  experiment_id: ee8f92ed3fe143e58f93e958dfaea929
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 0.00010000000000000002
        entropy: 0.8014648301260812
        entropy_coeff: 0.00010000000000000002
        kl: 0.010746340666498457
        model: {}
        policy_loss: -0.030137435400060246
        total_loss: 15.846869196210589
        vf_explained_var: 0.9765214920043945
        vf_loss: 15.874937057495117
    num_steps_sampled: 1860608
    num_steps_trained: 1860608
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.450000000000003
    gpu_util_percent0: 0.37111111111111117
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.211111111111112
    vram_util_percent0: 0.2038373237126927
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 11517
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15456071634715085
    mean_env_wait_ms: 1.2180728870997632
    mean_inference_ms: 4.748850502955983
    mean_raw_obs_processing_ms: 0.41069641132000073
  time_since_restore: 356.4750211238861
  time_this_iter_s: 15.532103776931763
  time_total_s: 356.4750211238861
  timers:
    learn_throughput: 6936.205
    learn_time_ms: 11662.861
    sample_throughput: 22060.373
    sample_time_ms: 3667.028
    update_time_ms: 29.02
  timestamp: 1602414804
  timesteps_since_restore: 0
  timesteps_total: 1860608
  training_iteration: 23
  trial_id: ed8b7_00000
  
== Status ==
Memory usage on this node: 46.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     23 |          356.475 | 1860608 |  232.738 |              285.111 |              117.687 |            839.471 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed8b7_00000:
  custom_metrics:
    time_step_max: 4279
    time_step_mean: 3520.273311897106
    time_step_min: 3174
  date: 2020-10-11_11-13-39
  done: false
  episode_len_mean: 838.866636528029
  episode_reward_max: 285.1111111111108
  episode_reward_mean: 232.95071876084518
  episode_reward_min: 117.68686868686848
  episodes_this_iter: 49
  episodes_total: 2212
  experiment_id: ee8f92ed3fe143e58f93e958dfaea929
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 0.00010000000000000002
        entropy: 0.8027615376881191
        entropy_coeff: 0.00010000000000000002
        kl: 0.011178621756178992
        model: {}
        policy_loss: -0.03632411014820848
        total_loss: 5.472229072025844
        vf_explained_var: 0.9705377817153931
        vf_loss: 5.506397928510394
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 24
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.073684210526316
    gpu_util_percent0: 0.3136842105263158
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.210526315789474
    vram_util_percent0: 0.2038373237126927
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 11517
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1544685852667721
    mean_env_wait_ms: 1.2182278892020562
    mean_inference_ms: 4.742784170217995
    mean_raw_obs_processing_ms: 0.4103645265367753
  time_since_restore: 371.84721636772156
  time_this_iter_s: 15.37219524383545
  time_total_s: 371.84721636772156
  timers:
    learn_throughput: 6939.484
    learn_time_ms: 11657.352
    sample_throughput: 22095.085
    sample_time_ms: 3661.267
    update_time_ms: 27.78
  timestamp: 1602414819
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 24
  trial_id: ed8b7_00000
  
== Status ==
Memory usage on this node: 46.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     24 |          371.847 | 1941504 |  232.951 |              285.111 |              117.687 |            838.867 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed8b7_00000:
  custom_metrics:
    time_step_max: 4279
    time_step_mean: 3514.3297644539616
    time_step_min: 3174
  date: 2020-10-11_11-13-55
  done: false
  episode_len_mean: 836.1455696202531
  episode_reward_max: 285.1111111111108
  episode_reward_mean: 233.97161488300716
  episode_reward_min: 117.68686868686848
  episodes_this_iter: 158
  episodes_total: 2370
  experiment_id: ee8f92ed3fe143e58f93e958dfaea929
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 0.00010000000000000002
        entropy: 0.7634506140436444
        entropy_coeff: 0.00010000000000000002
        kl: 0.01075770945421287
        model: {}
        policy_loss: -0.03034432658127376
        total_loss: 13.53955432346889
        vf_explained_var: 0.9839022755622864
        vf_loss: 13.567823546273369
    num_steps_sampled: 2022400
    num_steps_trained: 2022400
  iterations_since_restore: 25
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.66842105263158
    gpu_util_percent0: 0.3626315789473684
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.210526315789474
    vram_util_percent0: 0.2038373237126927
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 11517
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15418583463624513
    mean_env_wait_ms: 1.219061598042449
    mean_inference_ms: 4.7252878782857275
    mean_raw_obs_processing_ms: 0.40943558152485915
  time_since_restore: 387.34790420532227
  time_this_iter_s: 15.500687837600708
  time_total_s: 387.34790420532227
  timers:
    learn_throughput: 6935.852
    learn_time_ms: 11663.455
    sample_throughput: 22038.179
    sample_time_ms: 3670.721
    update_time_ms: 29.508
  timestamp: 1602414835
  timesteps_since_restore: 0
  timesteps_total: 2022400
  training_iteration: 25
  trial_id: ed8b7_00000
  
== Status ==
Memory usage on this node: 46.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     25 |          387.348 | 2022400 |  233.972 |              285.111 |              117.687 |            836.146 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed8b7_00000:
  custom_metrics:
    time_step_max: 4279
    time_step_mean: 3512.205439330544
    time_step_min: 3174
  date: 2020-10-11_11-14-10
  done: false
  episode_len_mean: 835.2358762886598
  episode_reward_max: 285.1111111111108
  episode_reward_mean: 234.24388212017067
  episode_reward_min: 117.68686868686848
  episodes_this_iter: 55
  episodes_total: 2425
  experiment_id: ee8f92ed3fe143e58f93e958dfaea929
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 0.00010000000000000002
        entropy: 0.7645284192902702
        entropy_coeff: 0.00010000000000000002
        kl: 0.011046201921999454
        model: {}
        policy_loss: -0.03211360025618758
        total_loss: 11.541997228349958
        vf_explained_var: 0.9777361750602722
        vf_loss: 11.571977751595634
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 26
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.450000000000003
    gpu_util_percent0: 0.32944444444444443
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.211111111111112
    vram_util_percent0: 0.2038373237126927
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 11517
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1540866708881542
    mean_env_wait_ms: 1.2193572901306673
    mean_inference_ms: 4.719611668274306
    mean_raw_obs_processing_ms: 0.4091137457703957
  time_since_restore: 402.7666323184967
  time_this_iter_s: 15.418728113174438
  time_total_s: 402.7666323184967
  timers:
    learn_throughput: 6927.737
    learn_time_ms: 11677.118
    sample_throughput: 22093.872
    sample_time_ms: 3661.468
    update_time_ms: 31.122
  timestamp: 1602414850
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 26
  trial_id: ed8b7_00000
  
== Status ==
Memory usage on this node: 46.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     26 |          402.767 | 2103296 |  234.244 |              285.111 |              117.687 |            835.236 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed8b7_00000:
  custom_metrics:
    time_step_max: 4279
    time_step_mean: 3508.1211391897314
    time_step_min: 3174
  date: 2020-10-11_11-14-26
  done: false
  episode_len_mean: 834.1194620253165
  episode_reward_max: 285.1111111111108
  episode_reward_mean: 234.74916490857933
  episode_reward_min: 117.68686868686848
  episodes_this_iter: 103
  episodes_total: 2528
  experiment_id: ee8f92ed3fe143e58f93e958dfaea929
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 0.00010000000000000002
        entropy: 0.7696538737842015
        entropy_coeff: 0.00010000000000000002
        kl: 0.009899940873895372
        model: {}
        policy_loss: -0.03010483897690262
        total_loss: 7.996133531842913
        vf_explained_var: 0.9810003042221069
        vf_loss: 8.024335248129708
    num_steps_sampled: 2184192
    num_steps_trained: 2184192
  iterations_since_restore: 27
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.047368421052635
    gpu_util_percent0: 0.32263157894736844
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.205263157894737
    vram_util_percent0: 0.2038373237126927
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 11517
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15393358815170508
    mean_env_wait_ms: 1.2198577496072052
    mean_inference_ms: 4.709424175827586
    mean_raw_obs_processing_ms: 0.40858386146833126
  time_since_restore: 418.18699383735657
  time_this_iter_s: 15.420361518859863
  time_total_s: 418.18699383735657
  timers:
    learn_throughput: 6928.452
    learn_time_ms: 11675.912
    sample_throughput: 22068.825
    sample_time_ms: 3665.623
    update_time_ms: 33.599
  timestamp: 1602414866
  timesteps_since_restore: 0
  timesteps_total: 2184192
  training_iteration: 27
  trial_id: ed8b7_00000
  
== Status ==
Memory usage on this node: 46.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     27 |          418.187 | 2184192 |  234.749 |              285.111 |              117.687 |            834.119 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed8b7_00000:
  custom_metrics:
    time_step_max: 4279
    time_step_mean: 3502.2642506606267
    time_step_min: 3174
  date: 2020-10-11_11-14-41
  done: false
  episode_len_mean: 832.1322652757079
  episode_reward_max: 288.8989898989897
  episode_reward_mean: 235.60601920847813
  episode_reward_min: 117.68686868686848
  episodes_this_iter: 156
  episodes_total: 2684
  experiment_id: ee8f92ed3fe143e58f93e958dfaea929
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 0.00010000000000000002
        entropy: 0.7382196017674038
        entropy_coeff: 0.00010000000000000002
        kl: 0.010356013397020953
        model: {}
        policy_loss: -0.028260654636791775
        total_loss: 13.343521799360003
        vf_explained_var: 0.9828724265098572
        vf_loss: 13.36978530883789
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 28
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.80526315789474
    gpu_util_percent0: 0.35578947368421054
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.210526315789474
    vram_util_percent0: 0.2038373237126927
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 11517
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1537085266981266
    mean_env_wait_ms: 1.220682130353048
    mean_inference_ms: 4.6951938469222805
    mean_raw_obs_processing_ms: 0.40782552885921136
  time_since_restore: 433.7264211177826
  time_this_iter_s: 15.539427280426025
  time_total_s: 433.7264211177826
  timers:
    learn_throughput: 6914.972
    learn_time_ms: 11698.674
    sample_throughput: 22014.804
    sample_time_ms: 3674.618
    update_time_ms: 33.996
  timestamp: 1602414881
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 28
  trial_id: ed8b7_00000
  
== Status ==
Memory usage on this node: 46.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     28 |          433.726 | 2265088 |  235.606 |              288.899 |              117.687 |            832.132 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed8b7_00000:
  custom_metrics:
    time_step_max: 4279
    time_step_mean: 3501.7143393393394
    time_step_min: 3174
  date: 2020-10-11_11-14-57
  done: false
  episode_len_mean: 831.9573916265283
  episode_reward_max: 288.8989898989897
  episode_reward_mean: 235.6916291480944
  episode_reward_min: 117.68686868686848
  episodes_this_iter: 15
  episodes_total: 2699
  experiment_id: ee8f92ed3fe143e58f93e958dfaea929
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 0.00010000000000000002
        entropy: 0.741259115082877
        entropy_coeff: 0.00010000000000000002
        kl: 0.011515548718827111
        model: {}
        policy_loss: -0.0386028066277504
        total_loss: 5.7686494418552945
        vf_explained_var: 0.9847227931022644
        vf_loss: 5.805023602076939
    num_steps_sampled: 2345984
    num_steps_trained: 2345984
  iterations_since_restore: 29
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.344444444444445
    gpu_util_percent0: 0.3016666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.211111111111112
    vram_util_percent0: 0.2038373237126927
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 11517
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15368784955660025
    mean_env_wait_ms: 1.220787727557082
    mean_inference_ms: 4.693690857541116
    mean_raw_obs_processing_ms: 0.40773859312733546
  time_since_restore: 449.04663133621216
  time_this_iter_s: 15.320210218429565
  time_total_s: 449.04663133621216
  timers:
    learn_throughput: 6918.65
    learn_time_ms: 11692.455
    sample_throughput: 22099.217
    sample_time_ms: 3660.582
    update_time_ms: 32.081
  timestamp: 1602414897
  timesteps_since_restore: 0
  timesteps_total: 2345984
  training_iteration: 29
  trial_id: ed8b7_00000
  
== Status ==
Memory usage on this node: 46.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     29 |          449.047 | 2345984 |  235.692 |              288.899 |              117.687 |            831.957 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed8b7_00000:
  custom_metrics:
    time_step_max: 4279
    time_step_mean: 3496.444998220007
    time_step_min: 3174
  date: 2020-10-11_11-15-13
  done: false
  episode_len_mean: 830.2095639943741
  episode_reward_max: 288.8989898989897
  episode_reward_mean: 236.55434087712558
  episode_reward_min: 117.68686868686848
  episodes_this_iter: 145
  episodes_total: 2844
  experiment_id: ee8f92ed3fe143e58f93e958dfaea929
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 0.00010000000000000002
        entropy: 0.7333477054323468
        entropy_coeff: 0.00010000000000000002
        kl: 0.009345830285123416
        model: {}
        policy_loss: -0.027462404487388476
        total_loss: 9.17048522404262
        vf_explained_var: 0.985461413860321
        vf_loss: 9.196151460920062
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 30
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.994736842105265
    gpu_util_percent0: 0.3536842105263157
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.210526315789474
    vram_util_percent0: 0.2038373237126927
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 11517
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1534987590693203
    mean_env_wait_ms: 1.2214597079228968
    mean_inference_ms: 4.681632229679235
    mean_raw_obs_processing_ms: 0.4070969874551114
  time_since_restore: 464.6360778808594
  time_this_iter_s: 15.589446544647217
  time_total_s: 464.6360778808594
  timers:
    learn_throughput: 6916.731
    learn_time_ms: 11695.698
    sample_throughput: 22056.083
    sample_time_ms: 3667.741
    update_time_ms: 30.853
  timestamp: 1602414913
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 30
  trial_id: ed8b7_00000
  
== Status ==
Memory usage on this node: 46.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     30 |          464.636 | 2426880 |  236.554 |              288.899 |              117.687 |             830.21 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed8b7_00000:
  custom_metrics:
    time_step_max: 4279
    time_step_mean: 3491.385887913572
    time_step_min: 3174
  date: 2020-10-11_11-15-28
  done: false
  episode_len_mean: 828.4894894894895
  episode_reward_max: 288.8989898989897
  episode_reward_mean: 237.34450612228375
  episode_reward_min: 117.68686868686848
  episodes_this_iter: 153
  episodes_total: 2997
  experiment_id: ee8f92ed3fe143e58f93e958dfaea929
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 0.00010000000000000002
        entropy: 0.7141761098589215
        entropy_coeff: 0.00010000000000000002
        kl: 0.010538498205798013
        model: {}
        policy_loss: -0.03002121073326894
        total_loss: 12.987276213509697
        vf_explained_var: 0.9814284443855286
        vf_loss: 13.015260968889509
    num_steps_sampled: 2507776
    num_steps_trained: 2507776
  iterations_since_restore: 31
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.484210526315795
    gpu_util_percent0: 0.3489473684210526
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.210526315789474
    vram_util_percent0: 0.2038373237126927
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 11517
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1533164741883748
    mean_env_wait_ms: 1.2222260271011502
    mean_inference_ms: 4.669791183442398
    mean_raw_obs_processing_ms: 0.4064721500356665
  time_since_restore: 480.01299381256104
  time_this_iter_s: 15.37691593170166
  time_total_s: 480.01299381256104
  timers:
    learn_throughput: 6914.421
    learn_time_ms: 11699.606
    sample_throughput: 22037.607
    sample_time_ms: 3670.816
    update_time_ms: 32.095
  timestamp: 1602414928
  timesteps_since_restore: 0
  timesteps_total: 2507776
  training_iteration: 31
  trial_id: ed8b7_00000
  
== Status ==
Memory usage on this node: 46.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     31 |          480.013 | 2507776 |  237.345 |              288.899 |              117.687 |            828.489 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed8b7_00000:
  custom_metrics:
    time_step_max: 4279
    time_step_mean: 3491.1973728528124
    time_step_min: 3174
  date: 2020-10-11_11-15-44
  done: false
  episode_len_mean: 828.3931424766978
  episode_reward_max: 288.8989898989897
  episode_reward_mean: 237.37692840522388
  episode_reward_min: 117.68686868686848
  episodes_this_iter: 7
  episodes_total: 3004
  experiment_id: ee8f92ed3fe143e58f93e958dfaea929
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 0.00010000000000000002
        entropy: 0.7138987694467817
        entropy_coeff: 0.00010000000000000002
        kl: 0.011370175118957247
        model: {}
        policy_loss: -0.04013798572123051
        total_loss: 4.070477996553693
        vf_explained_var: 0.9827483892440796
        vf_loss: 4.10841349193028
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 32
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.51111111111111
    gpu_util_percent0: 0.36277777777777775
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.222222222222222
    vram_util_percent0: 0.2038373237126927
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 11517
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1533064561571048
    mean_env_wait_ms: 1.2222521564882434
    mean_inference_ms: 4.6691816857432045
    mean_raw_obs_processing_ms: 0.40643459995117087
  time_since_restore: 495.2956557273865
  time_this_iter_s: 15.28266191482544
  time_total_s: 495.2956557273865
  timers:
    learn_throughput: 6922.456
    learn_time_ms: 11686.026
    sample_throughput: 22035.276
    sample_time_ms: 3671.204
    update_time_ms: 31.844
  timestamp: 1602414944
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 32
  trial_id: ed8b7_00000
  
== Status ==
Memory usage on this node: 46.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     32 |          495.296 | 2588672 |  237.377 |              288.899 |              117.687 |            828.393 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed8b7_00000:
  custom_metrics:
    time_step_max: 4279
    time_step_mean: 3486.02176
    time_step_min: 3174
  date: 2020-10-11_11-15-59
  done: false
  episode_len_mean: 826.7759493670886
  episode_reward_max: 288.8989898989897
  episode_reward_mean: 238.20249968034767
  episode_reward_min: 117.68686868686848
  episodes_this_iter: 156
  episodes_total: 3160
  experiment_id: ee8f92ed3fe143e58f93e958dfaea929
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 0.00010000000000000002
        entropy: 0.7064724820000785
        entropy_coeff: 0.00010000000000000002
        kl: 0.009518824517726898
        model: {}
        policy_loss: -0.029149129454578673
        total_loss: 8.81074333190918
        vf_explained_var: 0.988771378993988
        vf_loss: 8.838059425354004
    num_steps_sampled: 2669568
    num_steps_trained: 2669568
  iterations_since_restore: 33
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.18888888888889
    gpu_util_percent0: 0.32944444444444443
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.216666666666667
    vram_util_percent0: 0.2038373237126927
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 11517
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1531353521503298
    mean_env_wait_ms: 1.2230012031400455
    mean_inference_ms: 4.657997312372352
    mean_raw_obs_processing_ms: 0.405836882924193
  time_since_restore: 510.6310017108917
  time_this_iter_s: 15.335345983505249
  time_total_s: 510.6310017108917
  timers:
    learn_throughput: 6922.808
    learn_time_ms: 11685.432
    sample_throughput: 22142.487
    sample_time_ms: 3653.429
    update_time_ms: 30.31
  timestamp: 1602414959
  timesteps_since_restore: 0
  timesteps_total: 2669568
  training_iteration: 33
  trial_id: ed8b7_00000
  
== Status ==
Memory usage on this node: 46.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     33 |          510.631 | 2669568 |  238.202 |              288.899 |              117.687 |            826.776 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed8b7_00000:
  custom_metrics:
    time_step_max: 4279
    time_step_mean: 3481.9266871165646
    time_step_min: 3174
  date: 2020-10-11_11-16-15
  done: false
  episode_len_mean: 825.322913505311
  episode_reward_max: 288.8989898989897
  episode_reward_mean: 238.75570576784526
  episode_reward_min: 117.68686868686848
  episodes_this_iter: 135
  episodes_total: 3295
  experiment_id: ee8f92ed3fe143e58f93e958dfaea929
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 0.00010000000000000002
        entropy: 0.6861251592636108
        entropy_coeff: 0.00010000000000000002
        kl: 0.009984563237854413
        model: {}
        policy_loss: -0.028198028781584332
        total_loss: 13.189177240644183
        vf_explained_var: 0.9802125096321106
        vf_loss: 13.21544715336391
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 34
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.45263157894737
    gpu_util_percent0: 0.3442105263157894
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.210526315789474
    vram_util_percent0: 0.2038373237126927
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 11517
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1529844828154928
    mean_env_wait_ms: 1.223661539893914
    mean_inference_ms: 4.648884962993294
    mean_raw_obs_processing_ms: 0.4053319879620939
  time_since_restore: 526.1448483467102
  time_this_iter_s: 15.513846635818481
  time_total_s: 526.1448483467102
  timers:
    learn_throughput: 6915.508
    learn_time_ms: 11697.767
    sample_throughput: 22132.635
    sample_time_ms: 3655.055
    update_time_ms: 30.002
  timestamp: 1602414975
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 34
  trial_id: ed8b7_00000
  
== Status ==
Memory usage on this node: 46.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     34 |          526.145 | 2750464 |  238.756 |              288.899 |              117.687 |            825.323 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed8b7_00000:
  custom_metrics:
    time_step_max: 4279
    time_step_mean: 3480.9317697228144
    time_step_min: 3174
  date: 2020-10-11_11-16-30
  done: false
  episode_len_mean: 825.1428571428571
  episode_reward_max: 288.8989898989897
  episode_reward_mean: 238.89698065647423
  episode_reward_min: 117.68686868686848
  episodes_this_iter: 23
  episodes_total: 3318
  experiment_id: ee8f92ed3fe143e58f93e958dfaea929
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 0.00010000000000000002
        entropy: 0.6846187114715576
        entropy_coeff: 0.00010000000000000002
        kl: 0.010950947712574686
        model: {}
        policy_loss: -0.03858303331903049
        total_loss: 3.6150619983673096
        vf_explained_var: 0.9793863296508789
        vf_loss: 3.6515232835497176
    num_steps_sampled: 2831360
    num_steps_trained: 2831360
  iterations_since_restore: 35
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.778947368421054
    gpu_util_percent0: 0.29
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.215789473684211
    vram_util_percent0: 0.2038373237126927
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 11517
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15297329920887245
    mean_env_wait_ms: 1.2237476763616006
    mean_inference_ms: 4.6474416361949995
    mean_raw_obs_processing_ms: 0.4052684775842852
  time_since_restore: 541.7210958003998
  time_this_iter_s: 15.576247453689575
  time_total_s: 541.7210958003998
  timers:
    learn_throughput: 6910.252
    learn_time_ms: 11706.663
    sample_throughput: 22141.4
    sample_time_ms: 3653.608
    update_time_ms: 30.476
  timestamp: 1602414990
  timesteps_since_restore: 0
  timesteps_total: 2831360
  training_iteration: 35
  trial_id: ed8b7_00000
  
== Status ==
Memory usage on this node: 46.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     35 |          541.721 | 2831360 |  238.897 |              288.899 |              117.687 |            825.143 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed8b7_00000:
  custom_metrics:
    time_step_max: 4279
    time_step_mean: 3476.683812845103
    time_step_min: 3174
  date: 2020-10-11_11-16-46
  done: false
  episode_len_mean: 823.734752589183
  episode_reward_max: 288.8989898989897
  episode_reward_mean: 239.4782868965837
  episode_reward_min: 117.68686868686848
  episodes_this_iter: 158
  episodes_total: 3476
  experiment_id: ee8f92ed3fe143e58f93e958dfaea929
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 0.00010000000000000002
        entropy: 0.6705271346228463
        entropy_coeff: 0.00010000000000000002
        kl: 0.009495977844510759
        model: {}
        policy_loss: -0.027984988210456713
        total_loss: 10.82583590916225
        vf_explained_var: 0.9875221252441406
        vf_loss: 10.851988383701869
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 36
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.383333333333336
    gpu_util_percent0: 0.3
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.222222222222222
    vram_util_percent0: 0.2038373237126927
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 11517
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15282164445607432
    mean_env_wait_ms: 1.2244793275638173
    mean_inference_ms: 4.63757056643333
    mean_raw_obs_processing_ms: 0.4047337000957116
  time_since_restore: 557.1422667503357
  time_this_iter_s: 15.421170949935913
  time_total_s: 557.1422667503357
  timers:
    learn_throughput: 6913.815
    learn_time_ms: 11700.631
    sample_throughput: 22094.423
    sample_time_ms: 3661.376
    update_time_ms: 28.494
  timestamp: 1602415006
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 36
  trial_id: ed8b7_00000
  
== Status ==
Memory usage on this node: 46.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     36 |          557.142 | 2912256 |  239.478 |              288.899 |              117.687 |            823.735 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed8b7_00000:
  custom_metrics:
    time_step_max: 4279
    time_step_mean: 3474.3468811741463
    time_step_min: 3172
  date: 2020-10-11_11-17-02
  done: false
  episode_len_mean: 822.8353828954723
  episode_reward_max: 288.8989898989897
  episode_reward_mean: 239.84187317557905
  episode_reward_min: 117.68686868686848
  episodes_this_iter: 102
  episodes_total: 3578
  experiment_id: ee8f92ed3fe143e58f93e958dfaea929
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 0.00010000000000000002
        entropy: 0.6732551966394696
        entropy_coeff: 0.00010000000000000002
        kl: 0.010459980927407742
        model: {}
        policy_loss: -0.02988721669784614
        total_loss: 12.020891189575195
        vf_explained_var: 0.9796990156173706
        vf_loss: 12.04875387464251
    num_steps_sampled: 2993152
    num_steps_trained: 2993152
  iterations_since_restore: 37
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.978947368421053
    gpu_util_percent0: 0.3431578947368421
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.215789473684211
    vram_util_percent0: 0.2038373237126927
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 11517
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1527189275009953
    mean_env_wait_ms: 1.2249342826484029
    mean_inference_ms: 4.63159545625294
    mean_raw_obs_processing_ms: 0.4044093019860797
  time_since_restore: 572.7838077545166
  time_this_iter_s: 15.641541004180908
  time_total_s: 572.7838077545166
  timers:
    learn_throughput: 6895.582
    learn_time_ms: 11731.569
    sample_throughput: 22149.093
    sample_time_ms: 3652.339
    update_time_ms: 28.275
  timestamp: 1602415022
  timesteps_since_restore: 0
  timesteps_total: 2993152
  training_iteration: 37
  trial_id: ed8b7_00000
  
== Status ==
Memory usage on this node: 46.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     37 |          572.784 | 2993152 |  239.842 |              288.899 |              117.687 |            822.835 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed8b7_00000:
  custom_metrics:
    time_step_max: 4279
    time_step_mean: 3472.9027507641013
    time_step_min: 3172
  date: 2020-10-11_11-17-17
  done: false
  episode_len_mean: 822.44551458448
  episode_reward_max: 288.8989898989897
  episode_reward_mean: 240.0620375466274
  episode_reward_min: 117.68686868686848
  episodes_this_iter: 56
  episodes_total: 3634
  experiment_id: ee8f92ed3fe143e58f93e958dfaea929
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 0.00010000000000000002
        entropy: 0.657863906451634
        entropy_coeff: 0.00010000000000000002
        kl: 0.010496733177985464
        model: {}
        policy_loss: -0.0346918199211359
        total_loss: 4.282534122467041
        vf_explained_var: 0.9811368584632874
        vf_loss: 4.315192358834403
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 38
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.42105263157895
    gpu_util_percent0: 0.3310526315789474
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.215789473684211
    vram_util_percent0: 0.2038373237126927
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 11517
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15268028988154853
    mean_env_wait_ms: 1.2251785091633063
    mean_inference_ms: 4.628354002228403
    mean_raw_obs_processing_ms: 0.4042345731914658
  time_since_restore: 588.1606180667877
  time_this_iter_s: 15.376810312271118
  time_total_s: 588.1606180667877
  timers:
    learn_throughput: 6899.122
    learn_time_ms: 11725.55
    sample_throughput: 22216.641
    sample_time_ms: 3641.234
    update_time_ms: 28.207
  timestamp: 1602415037
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 38
  trial_id: ed8b7_00000
  
== Status ==
Memory usage on this node: 46.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     38 |          588.161 | 3074048 |  240.062 |              288.899 |              117.687 |            822.446 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ed8b7_00000:
  custom_metrics:
    time_step_max: 4279
    time_step_mean: 3469.076923076923
    time_step_min: 3172
  date: 2020-10-11_11-17-33
  done: true
  episode_len_mean: 821.0094936708861
  episode_reward_max: 288.8989898989897
  episode_reward_mean: 240.60125783147927
  episode_reward_min: 117.68686868686848
  episodes_this_iter: 158
  episodes_total: 3792
  experiment_id: ee8f92ed3fe143e58f93e958dfaea929
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 0.00010000000000000002
        entropy: 0.642860301903316
        entropy_coeff: 0.00010000000000000002
        kl: 0.009801473202449935
        model: {}
        policy_loss: -0.027483725188566104
        total_loss: 13.555409022739955
        vf_explained_var: 0.9839209318161011
        vf_loss: 13.580996922084264
    num_steps_sampled: 3154944
    num_steps_trained: 3154944
  iterations_since_restore: 39
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.233333333333334
    gpu_util_percent0: 0.2744444444444445
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.216666666666667
    vram_util_percent0: 0.2038373237126927
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 11517
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15254677791204402
    mean_env_wait_ms: 1.2258875543427181
    mean_inference_ms: 4.619694203955828
    mean_raw_obs_processing_ms: 0.4037668223539728
  time_since_restore: 603.536078453064
  time_this_iter_s: 15.375460386276245
  time_total_s: 603.536078453064
  timers:
    learn_throughput: 6895.914
    learn_time_ms: 11731.006
    sample_throughput: 22231.775
    sample_time_ms: 3638.756
    update_time_ms: 30.262
  timestamp: 1602415053
  timesteps_since_restore: 0
  timesteps_total: 3154944
  training_iteration: 39
  trial_id: ed8b7_00000
  
== Status ==
Memory usage on this node: 46.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed8b7_00000 | TERMINATED |       |     39 |          603.536 | 3154944 |  240.601 |              288.899 |              117.687 |            821.009 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 46.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ed8b7_00000 | TERMINATED |       |     39 |          603.536 | 3154944 |  240.601 |              288.899 |              117.687 |            821.009 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Traceback (most recent call last):
  File "/root/miniconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py", line 2895, in get_loc
    return self._engine.get_loc(casted_key)
  File "pandas/_libs/index.pyx", line 70, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/index.pyx", line 101, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 1675, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 1683, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'custom_metrics/time_step_min'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "train.py", line 72, in <module>
    train_func()
  File "train.py", line 57, in train_func
    result = analysis.dataframe(metric='custom_metrics/time_step_min', mode='min').to_dict('index')[0]
  File "/root/miniconda3/lib/python3.8/site-packages/ray/tune/analysis/experiment_analysis.py", line 92, in dataframe
    rows = self._retrieve_rows(metric=metric, mode=mode)
  File "/root/miniconda3/lib/python3.8/site-packages/ray/tune/analysis/experiment_analysis.py", line 254, in _retrieve_rows
    idx = df[metric].idxmin()
  File "/root/miniconda3/lib/python3.8/site-packages/pandas/core/frame.py", line 2902, in __getitem__
    indexer = self.columns.get_loc(key)
  File "/root/miniconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py", line 2897, in get_loc
    raise KeyError(key) from err
KeyError: 'custom_metrics/time_step_min'
