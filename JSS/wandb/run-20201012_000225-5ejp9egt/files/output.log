2020-10-12 00:02:29,181	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_38ad8_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=35888)[0m 2020-10-12 00:02:31,868	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=35814)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35814)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35797)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35797)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35911)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35911)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35809)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35809)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35811)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35811)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35900)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35900)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35861)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35861)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35905)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35905)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35872)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35872)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35875)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35875)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35796)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35796)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35926)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35926)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35847)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35847)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35893)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35893)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35909)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35909)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35917)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35917)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35792)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35792)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35852)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35852)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35807)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35807)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35908)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35908)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35854)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35854)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35863)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35863)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35922)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35922)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35884)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35884)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35920)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35920)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35830)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35830)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35795)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35795)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35798)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35798)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35856)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35856)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35850)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35850)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35901)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35901)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35801)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35801)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35803)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35803)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35915)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35915)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35898)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35898)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35913)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35913)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35829)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35829)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35906)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35906)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35873)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35873)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35810)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35810)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35904)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35904)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35799)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35799)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35896)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35896)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35890)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35890)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35791)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35791)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35881)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35881)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35804)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35804)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35794)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35794)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35865)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35865)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35859)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35859)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35821)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35821)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35851)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35851)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35855)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35855)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35816)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35816)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35808)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35808)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35892)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35892)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35877)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35877)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35891)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35891)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35824)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35824)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35825)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35825)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35883)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35883)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35845)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35845)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35858)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35858)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35826)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35826)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35812)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35812)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35889)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35889)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35880)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35880)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35868)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35868)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35867)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35867)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35828)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35828)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35813)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35813)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35864)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35864)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35869)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35869)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35802)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35802)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35874)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35874)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35805)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35805)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35879)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35879)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35878)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35878)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35793)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35793)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_38ad8_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-12_00-03-05
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 424830f2440148588e4ddf5b5af9392e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1823383669058483
        entropy_coeff: 0.0005000000000000001
        kl: 0.006917016425480445
        model: {}
        policy_loss: -0.009157503198366612
        total_loss: 507.07493591308594
        vf_explained_var: 0.540532648563385
        vf_loss: 507.0832926432292
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.217142857142846
    gpu_util_percent0: 0.3345714285714286
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5542857142857147
    vram_util_percent0: 0.08529494447828329
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35888
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1705460225994773
    mean_env_wait_ms: 1.1738074433107957
    mean_inference_ms: 5.919744409724273
    mean_raw_obs_processing_ms: 0.45995171697981097
  time_since_restore: 28.17985725402832
  time_this_iter_s: 28.17985725402832
  time_total_s: 28.17985725402832
  timers:
    learn_throughput: 8657.411
    learn_time_ms: 18688.266
    sample_throughput: 17159.427
    sample_time_ms: 9428.753
    update_time_ms: 31.228
  timestamp: 1602460985
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 38ad8_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_38ad8_00000 | RUNNING  | 172.17.0.4:35888 |      1 |          28.1799 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_38ad8_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3614.2256944444443
    time_step_min: 3379
  date: 2020-10-12_00-03-31
  done: false
  episode_len_mean: 892.4873417721519
  episode_reward_max: 264.3535353535352
  episode_reward_mean: 217.54734049354283
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 424830f2440148588e4ddf5b5af9392e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.149937113126119
        entropy_coeff: 0.0005000000000000001
        kl: 0.007523950111741821
        model: {}
        policy_loss: -0.00998671705989788
        total_loss: 126.33550771077473
        vf_explained_var: 0.8110877871513367
        vf_loss: 126.34455998738606
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.89354838709678
    gpu_util_percent0: 0.32612903225806456
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7612903225806447
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35888
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16532785795281776
    mean_env_wait_ms: 1.1675377399861264
    mean_inference_ms: 5.599600196896671
    mean_raw_obs_processing_ms: 0.44367281658259045
  time_since_restore: 54.191771507263184
  time_this_iter_s: 26.011914253234863
  time_total_s: 54.191771507263184
  timers:
    learn_throughput: 8708.785
    learn_time_ms: 18578.021
    sample_throughput: 19173.34
    sample_time_ms: 8438.384
    update_time_ms: 38.216
  timestamp: 1602461011
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 38ad8_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_38ad8_00000 | RUNNING  | 172.17.0.4:35888 |      2 |          54.1918 | 323584 |  217.547 |              264.354 |              133.899 |            892.487 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_38ad8_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3605.479820627803
    time_step_min: 3310
  date: 2020-10-12_00-03-57
  done: false
  episode_len_mean: 888.5801687763714
  episode_reward_max: 264.50505050505006
  episode_reward_mean: 219.20585602864062
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 424830f2440148588e4ddf5b5af9392e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1411352157592773
        entropy_coeff: 0.0005000000000000001
        kl: 0.010440803055341044
        model: {}
        policy_loss: -0.013970387983135879
        total_loss: 54.93683338165283
        vf_explained_var: 0.8966913819313049
        vf_loss: 54.94928582509359
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.740625
    gpu_util_percent0: 0.3309375
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.765625
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35888
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.162143412285803
    mean_env_wait_ms: 1.16589225308245
    mean_inference_ms: 5.381287823308977
    mean_raw_obs_processing_ms: 0.4329348394939265
  time_since_restore: 79.88770079612732
  time_this_iter_s: 25.695929288864136
  time_total_s: 79.88770079612732
  timers:
    learn_throughput: 8698.805
    learn_time_ms: 18599.337
    sample_throughput: 20389.276
    sample_time_ms: 7935.152
    update_time_ms: 34.472
  timestamp: 1602461037
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 38ad8_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_38ad8_00000 | RUNNING  | 172.17.0.4:35888 |      3 |          79.8877 | 485376 |  219.206 |              264.505 |              133.899 |             888.58 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_38ad8_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3591.1639072847684
    time_step_min: 3227
  date: 2020-10-12_00-04-23
  done: false
  episode_len_mean: 885.4873417721519
  episode_reward_max: 277.0808080808083
  episode_reward_mean: 221.420326684567
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 424830f2440148588e4ddf5b5af9392e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1191200812657673
        entropy_coeff: 0.0005000000000000001
        kl: 0.011468215147033334
        model: {}
        policy_loss: -0.013862663588952273
        total_loss: 39.326786041259766
        vf_explained_var: 0.9241357445716858
        vf_loss: 39.33891359965006
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.506451612903227
    gpu_util_percent0: 0.41354838709677416
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7677419354838704
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35888
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15994308749954278
    mean_env_wait_ms: 1.165447850621288
    mean_inference_ms: 5.228931831454086
    mean_raw_obs_processing_ms: 0.42526886564902194
  time_since_restore: 105.40826535224915
  time_this_iter_s: 25.520564556121826
  time_total_s: 105.40826535224915
  timers:
    learn_throughput: 8697.012
    learn_time_ms: 18603.17
    sample_throughput: 21159.622
    sample_time_ms: 7646.261
    update_time_ms: 30.706
  timestamp: 1602461063
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 38ad8_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_38ad8_00000 | RUNNING  | 172.17.0.4:35888 |      4 |          105.408 | 647168 |   221.42 |              277.081 |              133.899 |            885.487 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_38ad8_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3577.469816272966
    time_step_min: 3227
  date: 2020-10-12_00-04-48
  done: false
  episode_len_mean: 882.6164556962025
  episode_reward_max: 277.0808080808083
  episode_reward_mean: 223.37348165196246
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 424830f2440148588e4ddf5b5af9392e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0904998779296875
        entropy_coeff: 0.0005000000000000001
        kl: 0.010465693194419146
        model: {}
        policy_loss: -0.013936646308138734
        total_loss: 29.070746898651123
        vf_explained_var: 0.9454066157341003
        vf_loss: 29.0831356048584
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.150000000000002
    gpu_util_percent0: 0.3736666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.77
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35888
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15833525836805945
    mean_env_wait_ms: 1.16572011703855
    mean_inference_ms: 5.11623297624468
    mean_raw_obs_processing_ms: 0.4194761657972339
  time_since_restore: 130.6455147266388
  time_this_iter_s: 25.23724937438965
  time_total_s: 130.6455147266388
  timers:
    learn_throughput: 8708.827
    learn_time_ms: 18577.933
    sample_throughput: 21702.205
    sample_time_ms: 7455.095
    update_time_ms: 28.631
  timestamp: 1602461088
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 38ad8_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_38ad8_00000 | RUNNING  | 172.17.0.4:35888 |      5 |          130.646 | 808960 |  223.373 |              277.081 |              133.899 |            882.616 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_38ad8_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3562.2380487804876
    time_step_min: 3215
  date: 2020-10-12_00-05-13
  done: false
  episode_len_mean: 875.4055080721747
  episode_reward_max: 278.89898989898927
  episode_reward_mean: 225.90998302109395
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 263
  episodes_total: 1053
  experiment_id: 424830f2440148588e4ddf5b5af9392e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0669801433881123
        entropy_coeff: 0.0005000000000000001
        kl: 0.010119187956055006
        model: {}
        policy_loss: -0.014624884177464992
        total_loss: 30.67037757237752
        vf_explained_var: 0.9617660641670227
        vf_loss: 30.683512210845947
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.616129032258062
    gpu_util_percent0: 0.3712903225806452
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.761290322580645
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35888
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15647074578768883
    mean_env_wait_ms: 1.1677799730627454
    mean_inference_ms: 4.985433555232009
    mean_raw_obs_processing_ms: 0.4128342996267347
  time_since_restore: 156.17299938201904
  time_this_iter_s: 25.52748465538025
  time_total_s: 156.17299938201904
  timers:
    learn_throughput: 8701.215
    learn_time_ms: 18594.184
    sample_throughput: 22039.135
    sample_time_ms: 7341.123
    update_time_ms: 29.373
  timestamp: 1602461113
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 38ad8_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_38ad8_00000 | RUNNING  | 172.17.0.4:35888 |      6 |          156.173 | 970752 |   225.91 |              278.899 |              133.899 |            875.406 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_38ad8_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3547.7540453074434
    time_step_min: 3215
  date: 2020-10-12_00-05-39
  done: false
  episode_len_mean: 868.5514240506329
  episode_reward_max: 278.89898989898927
  episode_reward_mean: 228.15807601329732
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 211
  episodes_total: 1264
  experiment_id: 424830f2440148588e4ddf5b5af9392e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0668786863485973
        entropy_coeff: 0.0005000000000000001
        kl: 0.012256689059237639
        model: {}
        policy_loss: -0.01610318278350557
        total_loss: 20.370780150095623
        vf_explained_var: 0.963979959487915
        vf_loss: 20.384966214497883
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.293548387096774
    gpu_util_percent0: 0.3848387096774193
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322577
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35888
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15545241140433297
    mean_env_wait_ms: 1.1694290398205969
    mean_inference_ms: 4.9113541261332445
    mean_raw_obs_processing_ms: 0.4092044965379162
  time_since_restore: 181.44678163528442
  time_this_iter_s: 25.27378225326538
  time_total_s: 181.44678163528442
  timers:
    learn_throughput: 8706.255
    learn_time_ms: 18583.421
    sample_throughput: 22324.836
    sample_time_ms: 7247.175
    update_time_ms: 28.386
  timestamp: 1602461139
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 38ad8_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_38ad8_00000 | RUNNING  | 172.17.0.4:35888 |      7 |          181.447 | 1132544 |  228.158 |              278.899 |              133.899 |            868.551 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_38ad8_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3536.647776183644
    time_step_min: 3215
  date: 2020-10-12_00-06-05
  done: false
  episode_len_mean: 862.704641350211
  episode_reward_max: 278.89898989898927
  episode_reward_mean: 229.98016025231198
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 424830f2440148588e4ddf5b5af9392e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0334690809249878
        entropy_coeff: 0.0005000000000000001
        kl: 0.010793289790550867
        model: {}
        policy_loss: -0.015747709141578525
        total_loss: 15.715624650319418
        vf_explained_var: 0.969296395778656
        vf_loss: 15.729730685551962
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.361290322580647
    gpu_util_percent0: 0.3612903225806452
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7806451612903222
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35888
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1548142541021499
    mean_env_wait_ms: 1.1707778601291974
    mean_inference_ms: 4.86597365353758
    mean_raw_obs_processing_ms: 0.40691559219231155
  time_since_restore: 207.11959719657898
  time_this_iter_s: 25.672815561294556
  time_total_s: 207.11959719657898
  timers:
    learn_throughput: 8697.824
    learn_time_ms: 18601.433
    sample_throughput: 22479.48
    sample_time_ms: 7197.319
    update_time_ms: 30.727
  timestamp: 1602461165
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 38ad8_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_38ad8_00000 | RUNNING  | 172.17.0.4:35888 |      8 |           207.12 | 1294336 |   229.98 |              278.899 |              133.899 |            862.705 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_38ad8_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3525.568943298969
    time_step_min: 3215
  date: 2020-10-12_00-06-30
  done: false
  episode_len_mean: 857.1208860759493
  episode_reward_max: 279.3535353535359
  episode_reward_mean: 231.70662319396482
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 424830f2440148588e4ddf5b5af9392e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0033017992973328
        entropy_coeff: 0.0005000000000000001
        kl: 0.010770521514738599
        model: {}
        policy_loss: -0.015525121105990062
        total_loss: 16.273523728052776
        vf_explained_var: 0.9674468040466309
        vf_loss: 16.28739635149638
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.94193548387096
    gpu_util_percent0: 0.3658064516129032
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.774193548387097
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35888
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15426186350070775
    mean_env_wait_ms: 1.1722984909544845
    mean_inference_ms: 4.826558493342755
    mean_raw_obs_processing_ms: 0.4048862748960313
  time_since_restore: 232.56334686279297
  time_this_iter_s: 25.44374966621399
  time_total_s: 232.56334686279297
  timers:
    learn_throughput: 8700.954
    learn_time_ms: 18594.742
    sample_throughput: 22618.022
    sample_time_ms: 7153.234
    update_time_ms: 32.435
  timestamp: 1602461190
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 38ad8_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_38ad8_00000 | RUNNING  | 172.17.0.4:35888 |      9 |          232.563 | 1456128 |  231.707 |              279.354 |              133.899 |            857.121 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_38ad8_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3504.7218934911243
    time_step_min: 3186
  date: 2020-10-12_00-06-56
  done: false
  episode_len_mean: 847.3826179120297
  episode_reward_max: 284.0505050505049
  episode_reward_mean: 234.9192882722293
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 307
  episodes_total: 1887
  experiment_id: 424830f2440148588e4ddf5b5af9392e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9698180854320526
        entropy_coeff: 0.0005000000000000001
        kl: 0.008762541770314177
        model: {}
        policy_loss: -0.011754670903125467
        total_loss: 22.15676514307658
        vf_explained_var: 0.9699413776397705
        vf_loss: 22.167253017425537
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.567741935483877
    gpu_util_percent0: 0.37225806451612903
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322573
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35888
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15338472038748524
    mean_env_wait_ms: 1.175694037053138
    mean_inference_ms: 4.764439713713173
    mean_raw_obs_processing_ms: 0.4017777737986886
  time_since_restore: 258.0672380924225
  time_this_iter_s: 25.503891229629517
  time_total_s: 258.0672380924225
  timers:
    learn_throughput: 8701.687
    learn_time_ms: 18593.177
    sample_throughput: 22717.03
    sample_time_ms: 7122.058
    update_time_ms: 31.87
  timestamp: 1602461216
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 38ad8_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_38ad8_00000 | RUNNING  | 172.17.0.4:35888 |     10 |          258.067 | 1617920 |  234.919 |              284.051 |              133.899 |            847.383 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_38ad8_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3494.990128331688
    time_step_min: 3159
  date: 2020-10-12_00-07-21
  done: false
  episode_len_mean: 842.626582278481
  episode_reward_max: 287.38383838383817
  episode_reward_mean: 236.53693212553955
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 167
  episodes_total: 2054
  experiment_id: 424830f2440148588e4ddf5b5af9392e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.959399938583374
        entropy_coeff: 0.0005000000000000001
        kl: 0.009050344349816442
        model: {}
        policy_loss: -0.014448691198291877
        total_loss: 14.143741130828857
        vf_explained_var: 0.9704552292823792
        vf_loss: 14.156859795252482
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.233333333333334
    gpu_util_percent0: 0.3473333333333332
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7833333333333328
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35888
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15299982535000925
    mean_env_wait_ms: 1.1774149031613308
    mean_inference_ms: 4.736937049420722
    mean_raw_obs_processing_ms: 0.4004275925414483
  time_since_restore: 283.3717555999756
  time_this_iter_s: 25.3045175075531
  time_total_s: 283.3717555999756
  timers:
    learn_throughput: 8712.774
    learn_time_ms: 18569.517
    sample_throughput: 23594.979
    sample_time_ms: 6857.052
    update_time_ms: 30.636
  timestamp: 1602461241
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 38ad8_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_38ad8_00000 | RUNNING  | 172.17.0.4:35888 |     11 |          283.372 | 1779712 |  236.537 |              287.384 |              133.899 |            842.627 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_38ad8_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3486.236721611722
    time_step_min: 3147
  date: 2020-10-12_00-07-46
  done: false
  episode_len_mean: 839.50226039783
  episode_reward_max: 289.20202020202026
  episode_reward_mean: 237.80845069136197
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 424830f2440148588e4ddf5b5af9392e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9463174144426981
        entropy_coeff: 0.0005000000000000001
        kl: 0.009074758971109986
        model: {}
        policy_loss: -0.014368217787705362
        total_loss: 10.841783205668131
        vf_explained_var: 0.9763579368591309
        vf_loss: 10.854809761047363
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.30967741935485
    gpu_util_percent0: 0.307741935483871
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7838709677419353
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35888
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15266913510570285
    mean_env_wait_ms: 1.1789496133387285
    mean_inference_ms: 4.7135203654920925
    mean_raw_obs_processing_ms: 0.3992437671885101
  time_since_restore: 308.64534068107605
  time_this_iter_s: 25.273585081100464
  time_total_s: 308.64534068107605
  timers:
    learn_throughput: 8712.26
    learn_time_ms: 18570.612
    sample_throughput: 23847.433
    sample_time_ms: 6784.462
    update_time_ms: 28.189
  timestamp: 1602461266
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 38ad8_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_38ad8_00000 | RUNNING  | 172.17.0.4:35888 |     12 |          308.645 | 1941504 |  237.808 |              289.202 |              133.899 |            839.502 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_38ad8_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3477.1867900715188
    time_step_min: 3147
  date: 2020-10-12_00-08-12
  done: false
  episode_len_mean: 836.276923076923
  episode_reward_max: 289.20202020202026
  episode_reward_mean: 239.12358512358495
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 193
  episodes_total: 2405
  experiment_id: 424830f2440148588e4ddf5b5af9392e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9069925745328268
        entropy_coeff: 0.0005000000000000001
        kl: 0.009530291194096208
        model: {}
        policy_loss: -0.014515867456793785
        total_loss: 15.319237470626831
        vf_explained_var: 0.9747470021247864
        vf_loss: 15.332300901412964
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.503225806451614
    gpu_util_percent0: 0.40258064516129033
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322577
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35888
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15231688711814467
    mean_env_wait_ms: 1.1808122653597843
    mean_inference_ms: 4.6877738799975
    mean_raw_obs_processing_ms: 0.3979406621493078
  time_since_restore: 334.04357171058655
  time_this_iter_s: 25.398231029510498
  time_total_s: 334.04357171058655
  timers:
    learn_throughput: 8718.069
    learn_time_ms: 18558.238
    sample_throughput: 23892.516
    sample_time_ms: 6771.66
    update_time_ms: 27.812
  timestamp: 1602461292
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 38ad8_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_38ad8_00000 | RUNNING  | 172.17.0.4:35888 |     13 |          334.044 | 2103296 |  239.124 |              289.202 |              133.899 |            836.277 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_38ad8_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3465.9672686230247
    time_step_min: 3147
  date: 2020-10-12_00-08-38
  done: false
  episode_len_mean: 832.3082650781831
  episode_reward_max: 289.20202020202026
  episode_reward_mean: 240.80178553968565
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 281
  episodes_total: 2686
  experiment_id: 424830f2440148588e4ddf5b5af9392e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9011691262324651
        entropy_coeff: 0.0005000000000000001
        kl: 0.010886709050585827
        model: {}
        policy_loss: -0.01605825025762897
        total_loss: 13.799258867899576
        vf_explained_var: 0.9779562950134277
        vf_loss: 13.813590288162231
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.45161290322581
    gpu_util_percent0: 0.36838709677419357
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322577
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35888
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15185818100646556
    mean_env_wait_ms: 1.183195344246723
    mean_inference_ms: 4.656053234519618
    mean_raw_obs_processing_ms: 0.39633218509580354
  time_since_restore: 359.67288851737976
  time_this_iter_s: 25.629316806793213
  time_total_s: 359.67288851737976
  timers:
    learn_throughput: 8712.172
    learn_time_ms: 18570.799
    sample_throughput: 23888.008
    sample_time_ms: 6772.938
    update_time_ms: 28.196
  timestamp: 1602461318
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 38ad8_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_38ad8_00000 | RUNNING  | 172.17.0.4:35888 |     14 |          359.673 | 2265088 |  240.802 |              289.202 |              133.899 |            832.308 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_38ad8_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3459.754971590909
    time_step_min: 3147
  date: 2020-10-12_00-09-03
  done: false
  episode_len_mean: 830.3291139240506
  episode_reward_max: 289.20202020202026
  episode_reward_mean: 241.694508374888
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: 424830f2440148588e4ddf5b5af9392e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8705271085103353
        entropy_coeff: 0.0005000000000000001
        kl: 0.010132285223032037
        model: {}
        policy_loss: -0.01209646585630253
        total_loss: 9.354986588160196
        vf_explained_var: 0.9806396961212158
        vf_loss: 9.36549154917399
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.341935483870973
    gpu_util_percent0: 0.37290322580645163
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7806451612903222
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35888
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15163640699198197
    mean_env_wait_ms: 1.1843937455124571
    mean_inference_ms: 4.640345626681212
    mean_raw_obs_processing_ms: 0.39553170687224104
  time_since_restore: 385.27909803390503
  time_this_iter_s: 25.60620951652527
  time_total_s: 385.27909803390503
  timers:
    learn_throughput: 8699.345
    learn_time_ms: 18598.182
    sample_throughput: 23859.418
    sample_time_ms: 6781.054
    update_time_ms: 28.663
  timestamp: 1602461343
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 38ad8_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_38ad8_00000 | RUNNING  | 172.17.0.4:35888 |     15 |          385.279 | 2426880 |  241.695 |              289.202 |              133.899 |            830.329 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_38ad8_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3454.032279757902
    time_step_min: 3147
  date: 2020-10-12_00-09-29
  done: false
  episode_len_mean: 828.5073284477015
  episode_reward_max: 289.20202020202026
  episode_reward_mean: 242.50461645098542
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 158
  episodes_total: 3002
  experiment_id: 424830f2440148588e4ddf5b5af9392e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8471738596757253
        entropy_coeff: 0.0005000000000000001
        kl: 0.009305963292717934
        model: {}
        policy_loss: -0.01094130908313673
        total_loss: 10.646601835886637
        vf_explained_var: 0.9784726500511169
        vf_loss: 10.656105756759644
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.151612903225804
    gpu_util_percent0: 0.3609677419354839
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7741935483870965
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35888
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15143195011662824
    mean_env_wait_ms: 1.1855340509367762
    mean_inference_ms: 4.625828179601424
    mean_raw_obs_processing_ms: 0.39477621431866683
  time_since_restore: 410.6588988304138
  time_this_iter_s: 25.37980079650879
  time_total_s: 410.6588988304138
  timers:
    learn_throughput: 8710.881
    learn_time_ms: 18573.553
    sample_throughput: 23847.31
    sample_time_ms: 6784.497
    update_time_ms: 28.114
  timestamp: 1602461369
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 38ad8_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_38ad8_00000 | RUNNING  | 172.17.0.4:35888 |     16 |          410.659 | 2588672 |  242.505 |              289.202 |              133.899 |            828.507 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_38ad8_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3446.2361408882084
    time_step_min: 3147
  date: 2020-10-12_00-09-54
  done: false
  episode_len_mean: 825.9881566960219
  episode_reward_max: 289.9595959595964
  episode_reward_mean: 243.72948433622582
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 291
  episodes_total: 3293
  experiment_id: 424830f2440148588e4ddf5b5af9392e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8250234176715215
        entropy_coeff: 0.0005000000000000001
        kl: 0.008491925351942578
        model: {}
        policy_loss: -0.014777651784243062
        total_loss: 15.209494908650717
        vf_explained_var: 0.9786728024482727
        vf_loss: 15.222986777623495
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.383333333333336
    gpu_util_percent0: 0.3856666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7666666666666657
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35888
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15109252989368827
    mean_env_wait_ms: 1.1875422869010752
    mean_inference_ms: 4.601965999990543
    mean_raw_obs_processing_ms: 0.3935635858364597
  time_since_restore: 435.99139618873596
  time_this_iter_s: 25.332497358322144
  time_total_s: 435.99139618873596
  timers:
    learn_throughput: 8716.143
    learn_time_ms: 18562.338
    sample_throughput: 23792.186
    sample_time_ms: 6800.216
    update_time_ms: 28.625
  timestamp: 1602461394
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 38ad8_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_38ad8_00000 | RUNNING  | 172.17.0.4:35888 |     17 |          435.991 | 2750464 |  243.729 |               289.96 |              133.899 |            825.988 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_38ad8_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3440.9040023201856
    time_step_min: 3098
  date: 2020-10-12_00-10-20
  done: false
  episode_len_mean: 824.563003452244
  episode_reward_max: 296.62626262626276
  episode_reward_mean: 244.5732671943833
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 183
  episodes_total: 3476
  experiment_id: 424830f2440148588e4ddf5b5af9392e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8241499215364456
        entropy_coeff: 0.0005000000000000001
        kl: 0.007864817045629025
        model: {}
        policy_loss: -0.01140341673938868
        total_loss: 8.79675587018331
        vf_explained_var: 0.9828992486000061
        vf_loss: 8.806998491287231
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.693749999999998
    gpu_util_percent0: 0.4125
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.778125
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35888
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15090536671861077
    mean_env_wait_ms: 1.188611895685233
    mean_inference_ms: 4.58863601346352
    mean_raw_obs_processing_ms: 0.39288562197002064
  time_since_restore: 461.70954942703247
  time_this_iter_s: 25.71815323829651
  time_total_s: 461.70954942703247
  timers:
    learn_throughput: 8711.781
    learn_time_ms: 18571.633
    sample_throughput: 23827.853
    sample_time_ms: 6790.037
    update_time_ms: 33.002
  timestamp: 1602461420
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 38ad8_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_38ad8_00000 | RUNNING  | 172.17.0.4:35888 |     18 |           461.71 | 2912256 |  244.573 |              296.626 |              133.899 |            824.563 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_38ad8_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3436.840266222962
    time_step_min: 3098
  date: 2020-10-12_00-10-46
  done: false
  episode_len_mean: 823.8428728673638
  episode_reward_max: 296.62626262626276
  episode_reward_mean: 245.09397497262097
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 158
  episodes_total: 3634
  experiment_id: 424830f2440148588e4ddf5b5af9392e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8113949745893478
        entropy_coeff: 0.0005000000000000001
        kl: 0.008743428780386845
        model: {}
        policy_loss: -0.012751462903300611
        total_loss: 8.8964794476827
        vf_explained_var: 0.9816879630088806
        vf_loss: 8.907887935638428
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.17096774193548
    gpu_util_percent0: 0.38225806451612904
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7903225806451615
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35888
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1507539224319964
    mean_env_wait_ms: 1.1894729387839469
    mean_inference_ms: 4.577928846678204
    mean_raw_obs_processing_ms: 0.3923383321071273
  time_since_restore: 487.6133711338043
  time_this_iter_s: 25.90382170677185
  time_total_s: 487.6133711338043
  timers:
    learn_throughput: 8691.855
    learn_time_ms: 18614.208
    sample_throughput: 23815.232
    sample_time_ms: 6793.635
    update_time_ms: 32.09
  timestamp: 1602461446
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 38ad8_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_38ad8_00000 | RUNNING  | 172.17.0.4:35888 |     19 |          487.613 | 3074048 |  245.094 |              296.626 |              133.899 |            823.843 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_38ad8_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3432.525217850541
    time_step_min: 3098
  date: 2020-10-12_00-11-12
  done: false
  episode_len_mean: 823.0579292267365
  episode_reward_max: 296.62626262626276
  episode_reward_mean: 245.79004990931585
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 181
  episodes_total: 3815
  experiment_id: 424830f2440148588e4ddf5b5af9392e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7609985868136088
        entropy_coeff: 0.0005000000000000001
        kl: 0.00916624628007412
        model: {}
        policy_loss: -0.012107667707217237
        total_loss: 10.657151778539022
        vf_explained_var: 0.9814252257347107
        vf_loss: 10.66780686378479
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.222580645161294
    gpu_util_percent0: 0.34935483870967743
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35888
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15059414484364572
    mean_env_wait_ms: 1.1904148853220353
    mean_inference_ms: 4.5664116726025386
    mean_raw_obs_processing_ms: 0.39175226546207903
  time_since_restore: 513.0929601192474
  time_this_iter_s: 25.479588985443115
  time_total_s: 513.0929601192474
  timers:
    learn_throughput: 8688.073
    learn_time_ms: 18622.311
    sample_throughput: 23858.88
    sample_time_ms: 6781.207
    update_time_ms: 32.635
  timestamp: 1602461472
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 38ad8_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_38ad8_00000 | RUNNING  | 172.17.0.4:35888 |     20 |          513.093 | 3235840 |   245.79 |              296.626 |              133.899 |            823.058 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_38ad8_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3425.473593711619
    time_step_min: 3098
  date: 2020-10-12_00-11-37
  done: false
  episode_len_mean: 821.8972920224445
  episode_reward_max: 296.62626262626276
  episode_reward_mean: 246.80025184758034
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 284
  episodes_total: 4099
  experiment_id: 424830f2440148588e4ddf5b5af9392e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7578712403774261
        entropy_coeff: 0.0005000000000000001
        kl: 0.0086368964985013
        model: {}
        policy_loss: -0.011422600480727851
        total_loss: 10.725571791330973
        vf_explained_var: 0.9839944839477539
        vf_loss: 10.735645691553751
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.43225806451613
    gpu_util_percent0: 0.4212903225806452
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.761290322580645
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35888
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15036548589593
    mean_env_wait_ms: 1.1916948020130713
    mean_inference_ms: 4.550194461979054
    mean_raw_obs_processing_ms: 0.39093340180103914
  time_since_restore: 538.4597160816193
  time_this_iter_s: 25.366755962371826
  time_total_s: 538.4597160816193
  timers:
    learn_throughput: 8684.027
    learn_time_ms: 18630.988
    sample_throughput: 23871.539
    sample_time_ms: 6777.611
    update_time_ms: 33.037
  timestamp: 1602461497
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: 38ad8_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_38ad8_00000 | RUNNING  | 172.17.0.4:35888 |     21 |           538.46 | 3397632 |    246.8 |              296.626 |              133.899 |            821.897 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_38ad8_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3421.670599339311
    time_step_min: 3098
  date: 2020-10-12_00-12-03
  done: false
  episode_len_mean: 821.5065635255509
  episode_reward_max: 296.62626262626276
  episode_reward_mean: 247.35105627299706
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 167
  episodes_total: 4266
  experiment_id: 424830f2440148588e4ddf5b5af9392e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7521579414606094
        entropy_coeff: 0.0005000000000000001
        kl: 0.007824398732433716
        model: {}
        policy_loss: -0.01322558480508936
        total_loss: 7.959930698076884
        vf_explained_var: 0.9843184947967529
        vf_loss: 7.971967538197835
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.564516129032263
    gpu_util_percent0: 0.3803225806451612
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7838709677419353
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35888
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1502433745449996
    mean_env_wait_ms: 1.1923587050469684
    mean_inference_ms: 4.5414281354845105
    mean_raw_obs_processing_ms: 0.39048775962667837
  time_since_restore: 564.0169410705566
  time_this_iter_s: 25.557224988937378
  time_total_s: 564.0169410705566
  timers:
    learn_throughput: 8676.536
    learn_time_ms: 18647.073
    sample_throughput: 23837.337
    sample_time_ms: 6787.335
    update_time_ms: 34.613
  timestamp: 1602461523
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: 38ad8_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_38ad8_00000 | RUNNING  | 172.17.0.4:35888 |     22 |          564.017 | 3559424 |  247.351 |              296.626 |              133.899 |            821.507 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_38ad8_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3418.63762511374
    time_step_min: 3098
  date: 2020-10-12_00-12-28
  done: false
  episode_len_mean: 821.0913200723327
  episode_reward_max: 296.62626262626276
  episode_reward_mean: 247.84626098233684
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 158
  episodes_total: 4424
  experiment_id: 424830f2440148588e4ddf5b5af9392e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.739922359585762
        entropy_coeff: 0.0005000000000000001
        kl: 0.008788479414458076
        model: {}
        policy_loss: -0.013709326779159406
        total_loss: 7.252472162246704
        vf_explained_var: 0.9847645163536072
        vf_loss: 7.264793713887532
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.37741935483871
    gpu_util_percent0: 0.3687096774193548
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7741935483870965
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35888
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15013449898161615
    mean_env_wait_ms: 1.1929503556006977
    mean_inference_ms: 4.533601410080655
    mean_raw_obs_processing_ms: 0.39008855279895144
  time_since_restore: 589.3189885616302
  time_this_iter_s: 25.30204749107361
  time_total_s: 589.3189885616302
  timers:
    learn_throughput: 8679.494
    learn_time_ms: 18640.717
    sample_throughput: 23851.836
    sample_time_ms: 6783.209
    update_time_ms: 34.519
  timestamp: 1602461548
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: 38ad8_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_38ad8_00000 | RUNNING  | 172.17.0.4:35888 |     23 |          589.319 | 3721216 |  247.846 |              296.626 |              133.899 |            821.091 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_38ad8_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3414.4957691473205
    time_step_min: 3098
  date: 2020-10-12_00-12-54
  done: true
  episode_len_mean: 820.656243260729
  episode_reward_max: 296.62626262626276
  episode_reward_mean: 248.46065137029112
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 213
  episodes_total: 4637
  experiment_id: 424830f2440148588e4ddf5b5af9392e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7039715051651001
        entropy_coeff: 0.0005000000000000001
        kl: 0.007829503583100935
        model: {}
        policy_loss: -0.010663946062171211
        total_loss: 8.341045339902243
        vf_explained_var: 0.9864241480827332
        vf_loss: 8.350495417912802
    num_steps_sampled: 3883008
    num_steps_trained: 3883008
  iterations_since_restore: 24
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.87
    gpu_util_percent0: 0.31966666666666665
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7666666666666657
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 35888
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15000030985065685
    mean_env_wait_ms: 1.193727411241895
    mean_inference_ms: 4.523741309343154
    mean_raw_obs_processing_ms: 0.38958539553126126
  time_since_restore: 614.7505757808685
  time_this_iter_s: 25.43158721923828
  time_total_s: 614.7505757808685
  timers:
    learn_throughput: 8688.989
    learn_time_ms: 18620.348
    sample_throughput: 23848.875
    sample_time_ms: 6784.052
    update_time_ms: 35.311
  timestamp: 1602461574
  timesteps_since_restore: 0
  timesteps_total: 3883008
  training_iteration: 24
  trial_id: 38ad8_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_38ad8_00000 | TERMINATED |       |     24 |          614.751 | 3883008 |  248.461 |              296.626 |              133.899 |            820.656 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_38ad8_00000 | TERMINATED |       |     24 |          614.751 | 3883008 |  248.461 |              296.626 |              133.899 |            820.656 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


