2020-10-11 18:09:16,493	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_e0e0e_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=504)[0m 2020-10-11 18:09:19,294	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=499)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=499)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=510)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=510)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=515)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=515)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=475)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=475)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=464)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=464)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=501)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=501)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=448)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=448)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=482)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=482)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=409)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=409)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=455)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=455)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=443)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=443)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=512)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=512)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=472)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=472)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=477)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=477)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=395)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=395)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=398)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=398)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=438)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=438)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=507)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=507)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=476)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=476)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=453)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=453)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=436)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=436)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=389)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=389)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=447)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=447)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=399)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=399)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=463)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=463)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=469)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=469)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=400)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=400)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=401)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=401)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=404)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=404)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=500)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=500)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=417)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=417)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=382)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=382)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=393)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=393)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=460)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=460)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=470)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=470)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=419)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=419)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=385)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=385)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=491)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=491)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=465)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=465)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=387)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=387)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=412)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=412)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=452)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=452)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=468)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=468)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=390)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=390)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=439)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=439)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=486)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=486)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=392)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=392)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=479)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=479)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=411)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=411)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=473)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=473)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=397)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=397)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=446)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=446)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=467)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=467)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=496)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=496)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=388)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=388)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=413)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=413)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=405)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=405)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=483)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=483)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=458)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=458)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=498)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=498)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=391)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=391)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=402)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=402)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=462)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=462)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=505)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=505)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=408)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=408)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=480)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=480)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=502)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=502)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=384)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=384)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=457)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=457)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=456)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=456)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=396)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=396)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=403)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=403)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=440)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=440)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=461)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=461)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=422)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=422)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=383)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=383)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=488)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=488)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=485)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=485)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=466)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=466)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_e0e0e_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-11_18-09-58
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: ba64d8304d8f43cd808e4d1968703b2e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1822590112686158
        entropy_coeff: 0.0001
        kl: 0.006789430300705135
        model: {}
        policy_loss: -0.01618297097738832
        total_loss: 495.8575469970703
        vf_explained_var: 0.602023720741272
        vf_loss: 495.8724884033203
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.185000000000002
    gpu_util_percent0: 0.41600000000000004
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.59
    vram_util_percent0: 0.07252377828796328
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 504
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1654910687938006
    mean_env_wait_ms: 1.1607838795854193
    mean_inference_ms: 5.343805406151748
    mean_raw_obs_processing_ms: 0.4323734579059804
  time_since_restore: 33.820472955703735
  time_this_iter_s: 33.820472955703735
  time_total_s: 33.820472955703735
  timers:
    learn_throughput: 6420.483
    learn_time_ms: 25199.349
    sample_throughput: 18926.765
    sample_time_ms: 8548.318
    update_time_ms: 43.169
  timestamp: 1602439798
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: e0e0e_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e0e0e_00000 | RUNNING  | 172.17.0.4:504 |      1 |          33.8205 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e0e0e_00000:
  custom_metrics:
    time_step_max: 4228
    time_step_mean: 3627.9513888888887
    time_step_min: 3344
  date: 2020-10-11_18-10-31
  done: false
  episode_len_mean: 891.9746835443038
  episode_reward_max: 259.3535353535351
  episode_reward_mean: 216.2858330136809
  episode_reward_min: 125.41414141414181
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: ba64d8304d8f43cd808e4d1968703b2e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1500211298465728
        entropy_coeff: 0.0001
        kl: 0.007826181827113032
        model: {}
        policy_loss: -0.01755326254060492
        total_loss: 111.1799472808838
        vf_explained_var: 0.8411966562271118
        vf_loss: 111.1960506439209
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.05263157894737
    gpu_util_percent0: 0.4689473684210526
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7605263157894746
    vram_util_percent0: 0.08043620859298131
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 504
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1620452651598559
    mean_env_wait_ms: 1.158641703842922
    mean_inference_ms: 5.20532098172316
    mean_raw_obs_processing_ms: 0.4250921571751352
  time_since_restore: 66.49236035346985
  time_this_iter_s: 32.67188739776611
  time_total_s: 66.49236035346985
  timers:
    learn_throughput: 6450.213
    learn_time_ms: 25083.204
    sample_throughput: 20021.78
    sample_time_ms: 8080.8
    update_time_ms: 39.615
  timestamp: 1602439831
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: e0e0e_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e0e0e_00000 | RUNNING  | 172.17.0.4:504 |      2 |          66.4924 | 323584 |  216.286 |              259.354 |              125.414 |            891.975 |
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e0e0e_00000:
  custom_metrics:
    time_step_max: 4228
    time_step_mean: 3615.8991031390133
    time_step_min: 3239
  date: 2020-10-11_18-11-03
  done: false
  episode_len_mean: 891.6919831223629
  episode_reward_max: 275.2626262626263
  episode_reward_mean: 217.54110727528428
  episode_reward_min: 114.80808080808087
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: ba64d8304d8f43cd808e4d1968703b2e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1375112414360047
        entropy_coeff: 0.0001
        kl: 0.009918415034189821
        model: {}
        policy_loss: -0.020439266902394594
        total_loss: 36.36845512390137
        vf_explained_var: 0.9370883703231812
        vf_loss: 36.38702449798584
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.868421052631582
    gpu_util_percent0: 0.48236842105263156
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.776315789473686
    vram_util_percent0: 0.08043620859298131
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 504
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15966378803385847
    mean_env_wait_ms: 1.158153899556887
    mean_inference_ms: 5.076769702756241
    mean_raw_obs_processing_ms: 0.41903578209290016
  time_since_restore: 98.99189448356628
  time_this_iter_s: 32.499534130096436
  time_total_s: 98.99189448356628
  timers:
    learn_throughput: 6430.531
    learn_time_ms: 25159.976
    sample_throughput: 20859.879
    sample_time_ms: 7756.133
    update_time_ms: 36.447
  timestamp: 1602439863
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: e0e0e_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e0e0e_00000 | RUNNING  | 172.17.0.4:504 |      3 |          98.9919 | 485376 |  217.541 |              275.263 |              114.808 |            891.692 |
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e0e0e_00000:
  custom_metrics:
    time_step_max: 4307
    time_step_mean: 3611.155629139073
    time_step_min: 3239
  date: 2020-10-11_18-11-36
  done: false
  episode_len_mean: 890.376582278481
  episode_reward_max: 275.2626262626263
  episode_reward_mean: 218.82203362741316
  episode_reward_min: 113.44444444444416
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: ba64d8304d8f43cd808e4d1968703b2e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1236192345619203
        entropy_coeff: 0.0001
        kl: 0.009516586968675255
        model: {}
        policy_loss: -0.020308381202630697
        total_loss: 22.23741798400879
        vf_explained_var: 0.9602130055427551
        vf_loss: 22.25593509674072
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.063157894736843
    gpu_util_percent0: 0.44973684210526316
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7710526315789483
    vram_util_percent0: 0.08043620859298131
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 504
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15801152838726587
    mean_env_wait_ms: 1.158087240618811
    mean_inference_ms: 4.981462558243761
    mean_raw_obs_processing_ms: 0.4145343786555456
  time_since_restore: 131.230797290802
  time_this_iter_s: 32.23890280723572
  time_total_s: 131.230797290802
  timers:
    learn_throughput: 6449.83
    learn_time_ms: 25084.691
    sample_throughput: 21211.446
    sample_time_ms: 7627.58
    update_time_ms: 48.401
  timestamp: 1602439896
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: e0e0e_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e0e0e_00000 | RUNNING  | 172.17.0.4:504 |      4 |          131.231 | 647168 |  218.822 |              275.263 |              113.444 |            890.377 |
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e0e0e_00000:
  custom_metrics:
    time_step_max: 4307
    time_step_mean: 3600.4370078740158
    time_step_min: 3239
  date: 2020-10-11_18-12-08
  done: false
  episode_len_mean: 887.7898734177215
  episode_reward_max: 275.2626262626263
  episode_reward_mean: 220.85142564889378
  episode_reward_min: 113.44444444444416
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: ba64d8304d8f43cd808e4d1968703b2e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0974919080734253
        entropy_coeff: 0.0001
        kl: 0.009487595083191991
        model: {}
        policy_loss: -0.019841649942100047
        total_loss: 21.439920902252197
        vf_explained_var: 0.9591807126998901
        vf_loss: 21.457975006103517
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.110810810810808
    gpu_util_percent0: 0.4081081081081081
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.770270270270271
    vram_util_percent0: 0.08043620859298131
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 504
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15674073240088549
    mean_env_wait_ms: 1.1584939446295808
    mean_inference_ms: 4.90770088458398
    mean_raw_obs_processing_ms: 0.4108448776510105
  time_since_restore: 163.59595727920532
  time_this_iter_s: 32.36515998840332
  time_total_s: 163.59595727920532
  timers:
    learn_throughput: 6449.539
    learn_time_ms: 25085.824
    sample_throughput: 21464.599
    sample_time_ms: 7537.62
    update_time_ms: 47.894
  timestamp: 1602439928
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: e0e0e_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e0e0e_00000 | RUNNING  | 172.17.0.4:504 |      5 |          163.596 | 808960 |  220.851 |              275.263 |              113.444 |             887.79 |
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e0e0e_00000:
  custom_metrics:
    time_step_max: 4307
    time_step_mean: 3583.1344969199176
    time_step_min: 3239
  date: 2020-10-11_18-12-40
  done: false
  episode_len_mean: 882.442115768463
  episode_reward_max: 286.7777777777778
  episode_reward_mean: 223.30623601282264
  episode_reward_min: 113.44444444444416
  episodes_this_iter: 212
  episodes_total: 1002
  experiment_id: ba64d8304d8f43cd808e4d1968703b2e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0659566462039947
        entropy_coeff: 0.0001
        kl: 0.00923141185194254
        model: {}
        policy_loss: -0.01887500686571002
        total_loss: 20.934257602691652
        vf_explained_var: 0.9717755317687988
        vf_loss: 20.951392555236815
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.55
    gpu_util_percent0: 0.46763157894736834
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7657894736842117
    vram_util_percent0: 0.08043620859298131
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 504
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15548138287436514
    mean_env_wait_ms: 1.160308204103206
    mean_inference_ms: 4.8342649913091105
    mean_raw_obs_processing_ms: 0.40720444300824243
  time_since_restore: 195.71077585220337
  time_this_iter_s: 32.11481857299805
  time_total_s: 195.71077585220337
  timers:
    learn_throughput: 6453.106
    learn_time_ms: 25071.957
    sample_throughput: 21703.378
    sample_time_ms: 7454.692
    update_time_ms: 43.433
  timestamp: 1602439960
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: e0e0e_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e0e0e_00000 | RUNNING  | 172.17.0.4:504 |      6 |          195.711 | 970752 |  223.306 |              286.778 |              113.444 |            882.442 |
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e0e0e_00000:
  custom_metrics:
    time_step_max: 4307
    time_step_mean: 3568.5186084142397
    time_step_min: 3239
  date: 2020-10-11_18-13-13
  done: false
  episode_len_mean: 875.5498417721519
  episode_reward_max: 286.7777777777778
  episode_reward_mean: 226.13204034010977
  episode_reward_min: 113.44444444444416
  episodes_this_iter: 262
  episodes_total: 1264
  experiment_id: ba64d8304d8f43cd808e4d1968703b2e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0790646553039551
        entropy_coeff: 0.0001
        kl: 0.008998072682879865
        model: {}
        policy_loss: -0.019116526865400375
        total_loss: 16.98468189239502
        vf_explained_var: 0.972199559211731
        vf_loss: 17.002107000350954
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.823684210526316
    gpu_util_percent0: 0.4884210526315789
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.763157894736843
    vram_util_percent0: 0.08043620859298131
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 504
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1543501234605243
    mean_env_wait_ms: 1.1624699060906205
    mean_inference_ms: 4.767647235098443
    mean_raw_obs_processing_ms: 0.4039720937754499
  time_since_restore: 228.32590770721436
  time_this_iter_s: 32.615131855010986
  time_total_s: 228.32590770721436
  timers:
    learn_throughput: 6442.465
    learn_time_ms: 25113.371
    sample_throughput: 21825.806
    sample_time_ms: 7412.876
    update_time_ms: 42.501
  timestamp: 1602439993
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: e0e0e_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e0e0e_00000 | RUNNING  | 172.17.0.4:504 |      7 |          228.326 | 1132544 |  226.132 |              286.778 |              113.444 |             875.55 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e0e0e_00000:
  custom_metrics:
    time_step_max: 4307
    time_step_mean: 3558.718794835007
    time_step_min: 3239
  date: 2020-10-11_18-13-45
  done: false
  episode_len_mean: 872.1364275668074
  episode_reward_max: 286.7777777777778
  episode_reward_mean: 227.3879938626772
  episode_reward_min: 113.44444444444416
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: ba64d8304d8f43cd808e4d1968703b2e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.056176209449768
        entropy_coeff: 0.0001
        kl: 0.008947713486850261
        model: {}
        policy_loss: -0.02066257141996175
        total_loss: 11.25270676612854
        vf_explained_var: 0.9793199300765991
        vf_loss: 11.27168550491333
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.757894736842108
    gpu_util_percent0: 0.44684210526315793
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.781578947368422
    vram_util_percent0: 0.08043620859298131
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 504
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1538264512754254
    mean_env_wait_ms: 1.1636766520892936
    mean_inference_ms: 4.736771876188321
    mean_raw_obs_processing_ms: 0.40246266186684587
  time_since_restore: 260.5508830547333
  time_this_iter_s: 32.22497534751892
  time_total_s: 260.5508830547333
  timers:
    learn_throughput: 6442.891
    learn_time_ms: 25111.707
    sample_throughput: 21964.991
    sample_time_ms: 7365.903
    update_time_ms: 40.953
  timestamp: 1602440025
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: e0e0e_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e0e0e_00000 | RUNNING  | 172.17.0.4:504 |      8 |          260.551 | 1294336 |  227.388 |              286.778 |              113.444 |            872.136 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e0e0e_00000:
  custom_metrics:
    time_step_max: 4307
    time_step_mean: 3548.7957474226805
    time_step_min: 3239
  date: 2020-10-11_18-14-17
  done: false
  episode_len_mean: 868.9120253164557
  episode_reward_max: 286.7777777777778
  episode_reward_mean: 228.59663086561804
  episode_reward_min: 113.44444444444416
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: ba64d8304d8f43cd808e4d1968703b2e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.04150692820549
        entropy_coeff: 0.0001
        kl: 0.008408830966800451
        model: {}
        policy_loss: -0.020661341992672534
        total_loss: 11.870151948928832
        vf_explained_var: 0.9770104289054871
        vf_loss: 11.889235639572144
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.159459459459462
    gpu_util_percent0: 0.0
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.802702702702704
    vram_util_percent0: 0.08043620859298131
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 504
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15337709009692468
    mean_env_wait_ms: 1.1648243211085343
    mean_inference_ms: 4.709741203271254
    mean_raw_obs_processing_ms: 0.4010989253579508
  time_since_restore: 292.69824719429016
  time_this_iter_s: 32.147364139556885
  time_total_s: 292.69824719429016
  timers:
    learn_throughput: 6441.507
    learn_time_ms: 25117.106
    sample_throughput: 22117.171
    sample_time_ms: 7315.221
    update_time_ms: 38.745
  timestamp: 1602440057
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: e0e0e_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e0e0e_00000 | RUNNING  | 172.17.0.4:504 |      9 |          292.698 | 1456128 |  228.597 |              286.778 |              113.444 |            868.912 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e0e0e_00000:
  custom_metrics:
    time_step_max: 4307
    time_step_mean: 3542.2349503214496
    time_step_min: 3216
  date: 2020-10-11_18-14-50
  done: false
  episode_len_mean: 865.7308798159862
  episode_reward_max: 286.7777777777778
  episode_reward_mean: 229.6337381869295
  episode_reward_min: 113.44444444444416
  episodes_this_iter: 159
  episodes_total: 1739
  experiment_id: ba64d8304d8f43cd808e4d1968703b2e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0038828194141387
        entropy_coeff: 0.0001
        kl: 0.009003697615116834
        model: {}
        policy_loss: -0.020532561629079283
        total_loss: 12.685962820053101
        vf_explained_var: 0.9782112240791321
        vf_loss: 12.704795122146606
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.963157894736838
    gpu_util_percent0: 0.0
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.839473684210528
    vram_util_percent0: 0.08043620859298131
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 504
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15298242516178368
    mean_env_wait_ms: 1.1659871744192787
    mean_inference_ms: 4.685709363218348
    mean_raw_obs_processing_ms: 0.39983664429277016
  time_since_restore: 324.89720273017883
  time_this_iter_s: 32.19895553588867
  time_total_s: 324.89720273017883
  timers:
    learn_throughput: 6440.855
    learn_time_ms: 25119.645
    sample_throughput: 22223.772
    sample_time_ms: 7280.132
    update_time_ms: 38.96
  timestamp: 1602440090
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: e0e0e_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e0e0e_00000 | RUNNING  | 172.17.0.4:504 |     10 |          324.897 | 1617920 |  229.634 |              286.778 |              113.444 |            865.731 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e0e0e_00000:
  custom_metrics:
    time_step_max: 4307
    time_step_mean: 3527.1446260525013
    time_step_min: 3216
  date: 2020-10-11_18-15-22
  done: false
  episode_len_mean: 859.2242305813386
  episode_reward_max: 286.7777777777778
  episode_reward_mean: 231.78658593753843
  episode_reward_min: 113.44444444444416
  episodes_this_iter: 308
  episodes_total: 2047
  experiment_id: ba64d8304d8f43cd808e4d1968703b2e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9934336423873902
        entropy_coeff: 0.0001
        kl: 0.008886505849659443
        model: {}
        policy_loss: -0.018800200463738294
        total_loss: 14.649124050140381
        vf_explained_var: 0.9810547828674316
        vf_loss: 14.666246271133422
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.576923076923077
    gpu_util_percent0: 0.3094871794871794
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.761538461538463
    vram_util_percent0: 0.08043620859298131
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 504
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15235294086574327
    mean_env_wait_ms: 1.168423930539034
    mean_inference_ms: 4.64760612983905
    mean_raw_obs_processing_ms: 0.3979475517811178
  time_since_restore: 357.49417448043823
  time_this_iter_s: 32.5969717502594
  time_total_s: 357.49417448043823
  timers:
    learn_throughput: 6436.03
    learn_time_ms: 25138.48
    sample_throughput: 22673.07
    sample_time_ms: 7135.867
    update_time_ms: 39.73
  timestamp: 1602440122
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: e0e0e_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e0e0e_00000 | RUNNING  | 172.17.0.4:504 |     11 |          357.494 | 1779712 |  231.787 |              286.778 |              113.444 |            859.224 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e0e0e_00000:
  custom_metrics:
    time_step_max: 4307
    time_step_mean: 3519.9070512820513
    time_step_min: 3216
  date: 2020-10-11_18-15-55
  done: false
  episode_len_mean: 856.2246835443038
  episode_reward_max: 286.7777777777778
  episode_reward_mean: 232.80016256598523
  episode_reward_min: 113.44444444444416
  episodes_this_iter: 165
  episodes_total: 2212
  experiment_id: ba64d8304d8f43cd808e4d1968703b2e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.979712375998497
        entropy_coeff: 0.0001
        kl: 0.008705975906923413
        model: {}
        policy_loss: -0.021710433671250938
        total_loss: 8.643640518188477
        vf_explained_var: 0.9844452738761902
        vf_loss: 8.663707733154297
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.036842105263162
    gpu_util_percent0: 0.4905263157894737
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.778947368421054
    vram_util_percent0: 0.08043620859298131
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 504
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15207441137324548
    mean_env_wait_ms: 1.1695809480042192
    mean_inference_ms: 4.630302393439471
    mean_raw_obs_processing_ms: 0.3970926997408623
  time_since_restore: 390.0754554271698
  time_this_iter_s: 32.58128094673157
  time_total_s: 390.0754554271698
  timers:
    learn_throughput: 6427.323
    learn_time_ms: 25172.533
    sample_throughput: 22806.405
    sample_time_ms: 7094.147
    update_time_ms: 38.32
  timestamp: 1602440155
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: e0e0e_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e0e0e_00000 | RUNNING  | 172.17.0.4:504 |     12 |          390.075 | 1941504 |    232.8 |              286.778 |              113.444 |            856.225 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e0e0e_00000:
  custom_metrics:
    time_step_max: 4307
    time_step_mean: 3514.3057216054654
    time_step_min: 3207
  date: 2020-10-11_18-16-28
  done: false
  episode_len_mean: 853.6776371308017
  episode_reward_max: 286.7777777777778
  episode_reward_mean: 233.54385628436248
  episode_reward_min: 113.44444444444416
  episodes_this_iter: 158
  episodes_total: 2370
  experiment_id: ba64d8304d8f43cd808e4d1968703b2e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9625891000032425
        entropy_coeff: 0.0001
        kl: 0.008588547119870782
        model: {}
        policy_loss: -0.021796545071993023
        total_loss: 9.561217546463013
        vf_explained_var: 0.982124924659729
        vf_loss: 9.581392621994018
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.03421052631579
    gpu_util_percent0: 0.42552631578947375
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7736842105263175
    vram_util_percent0: 0.08043620859298131
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 504
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15183431609968978
    mean_env_wait_ms: 1.1706636677089741
    mean_inference_ms: 4.6153764479871695
    mean_raw_obs_processing_ms: 0.39635698980254386
  time_since_restore: 422.66256856918335
  time_this_iter_s: 32.58711314201355
  time_total_s: 422.66256856918335
  timers:
    learn_throughput: 6424.16
    learn_time_ms: 25184.927
    sample_throughput: 22816.902
    sample_time_ms: 7090.884
    update_time_ms: 37.347
  timestamp: 1602440188
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: e0e0e_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e0e0e_00000 | RUNNING  | 172.17.0.4:504 |     13 |          422.663 | 2103296 |  233.544 |              286.778 |              113.444 |            853.678 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e0e0e_00000:
  custom_metrics:
    time_step_max: 4307
    time_step_mean: 3507.626740947075
    time_step_min: 3170
  date: 2020-10-11_18-17-00
  done: false
  episode_len_mean: 851.1629279811098
  episode_reward_max: 286.7777777777778
  episode_reward_mean: 234.47207613323306
  episode_reward_min: 113.44444444444416
  episodes_this_iter: 171
  episodes_total: 2541
  experiment_id: ba64d8304d8f43cd808e4d1968703b2e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9257766485214234
        entropy_coeff: 0.0001
        kl: 0.008564990665763616
        model: {}
        policy_loss: -0.0206657359842211
        total_loss: 9.499241161346436
        vf_explained_var: 0.9844285249710083
        vf_loss: 9.51828646659851
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.03947368421053
    gpu_util_percent0: 0.44552631578947366
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7657894736842117
    vram_util_percent0: 0.08043620859298131
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 504
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15159961963923113
    mean_env_wait_ms: 1.1718466248530253
    mean_inference_ms: 4.600904867229665
    mean_raw_obs_processing_ms: 0.3956441505296498
  time_since_restore: 454.74143266677856
  time_this_iter_s: 32.078864097595215
  time_total_s: 454.74143266677856
  timers:
    learn_throughput: 6419.446
    learn_time_ms: 25203.422
    sample_throughput: 22908.246
    sample_time_ms: 7062.61
    update_time_ms: 31.157
  timestamp: 1602440220
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: e0e0e_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e0e0e_00000 | RUNNING  | 172.17.0.4:504 |     14 |          454.741 | 2265088 |  234.472 |              286.778 |              113.444 |            851.163 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e0e0e_00000:
  custom_metrics:
    time_step_max: 4307
    time_step_mean: 3498.019196587273
    time_step_min: 3170
  date: 2020-10-11_18-17-32
  done: false
  episode_len_mean: 846.5047518479408
  episode_reward_max: 286.7777777777778
  episode_reward_mean: 235.94617772231277
  episode_reward_min: 113.44444444444416
  episodes_this_iter: 300
  episodes_total: 2841
  experiment_id: ba64d8304d8f43cd808e4d1968703b2e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9195137023925781
        entropy_coeff: 0.0001
        kl: 0.007970930938608945
        model: {}
        policy_loss: -0.019044552370905875
        total_loss: 13.088710308074951
        vf_explained_var: 0.982725977897644
        vf_loss: 13.10625262260437
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.973684210526315
    gpu_util_percent0: 0.2657894736842106
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7657894736842112
    vram_util_percent0: 0.08043620859298131
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 504
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15123755655808493
    mean_env_wait_ms: 1.173880720679686
    mean_inference_ms: 4.577963194893783
    mean_raw_obs_processing_ms: 0.3945152788487978
  time_since_restore: 486.9382131099701
  time_this_iter_s: 32.19678044319153
  time_total_s: 486.9382131099701
  timers:
    learn_throughput: 6416.74
    learn_time_ms: 25214.049
    sample_throughput: 23013.354
    sample_time_ms: 7030.353
    update_time_ms: 28.516
  timestamp: 1602440252
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: e0e0e_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e0e0e_00000 | RUNNING  | 172.17.0.4:504 |     15 |          486.938 | 2426880 |  235.946 |              286.778 |              113.444 |            846.505 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e0e0e_00000:
  custom_metrics:
    time_step_max: 4307
    time_step_mean: 3495.030598520511
    time_step_min: 3170
  date: 2020-10-11_18-18-05
  done: false
  episode_len_mean: 844.3620919387075
  episode_reward_max: 286.7777777777778
  episode_reward_mean: 236.5985033546658
  episode_reward_min: 113.44444444444416
  episodes_this_iter: 161
  episodes_total: 3002
  experiment_id: ba64d8304d8f43cd808e4d1968703b2e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8979267865419388
        entropy_coeff: 0.0001
        kl: 0.008113308134488762
        model: {}
        policy_loss: -0.020726724155247213
        total_loss: 8.743919515609742
        vf_explained_var: 0.9845118522644043
        vf_loss: 8.763113594055175
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.32162162162162
    gpu_util_percent0: 0.03351351351351352
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.781081081081082
    vram_util_percent0: 0.08043620859298131
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 504
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15107042687404212
    mean_env_wait_ms: 1.1748742933375522
    mean_inference_ms: 4.567207797015643
    mean_raw_obs_processing_ms: 0.3939841033506346
  time_since_restore: 519.0689408779144
  time_this_iter_s: 32.130727767944336
  time_total_s: 519.0689408779144
  timers:
    learn_throughput: 6411.096
    learn_time_ms: 25236.245
    sample_throughput: 23084.104
    sample_time_ms: 7008.806
    update_time_ms: 29.321
  timestamp: 1602440285
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: e0e0e_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e0e0e_00000 | RUNNING  | 172.17.0.4:504 |     16 |          519.069 | 2588672 |  236.599 |              286.778 |              113.444 |            844.362 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e0e0e_00000:
  custom_metrics:
    time_step_max: 4307
    time_step_mean: 3490.2250957854408
    time_step_min: 3170
  date: 2020-10-11_18-18-37
  done: false
  episode_len_mean: 842.1898734177215
  episode_reward_max: 287.23232323232327
  episode_reward_mean: 237.30630673826866
  episode_reward_min: 113.44444444444416
  episodes_this_iter: 158
  episodes_total: 3160
  experiment_id: ba64d8304d8f43cd808e4d1968703b2e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.883949139714241
        entropy_coeff: 0.0001
        kl: 0.008083893172442912
        model: {}
        policy_loss: -0.020766629185527564
        total_loss: 8.374863266944885
        vf_explained_var: 0.9833923578262329
        vf_loss: 8.394101428985596
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.865789473684217
    gpu_util_percent0: 0.3655263157894737
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7710526315789483
    vram_util_percent0: 0.08043620859298131
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 504
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15091718662360942
    mean_env_wait_ms: 1.1758458555775186
    mean_inference_ms: 4.557409245262824
    mean_raw_obs_processing_ms: 0.39348869179089524
  time_since_restore: 551.0367650985718
  time_this_iter_s: 31.96782422065735
  time_total_s: 551.0367650985718
  timers:
    learn_throughput: 6419.372
    learn_time_ms: 25203.713
    sample_throughput: 23190.802
    sample_time_ms: 6976.559
    update_time_ms: 28.247
  timestamp: 1602440317
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: e0e0e_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e0e0e_00000 | RUNNING  | 172.17.0.4:504 |     17 |          551.037 | 2750464 |  237.306 |              287.232 |              113.444 |             842.19 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e0e0e_00000:
  custom_metrics:
    time_step_max: 4307
    time_step_mean: 3483.991969066032
    time_step_min: 3170
  date: 2020-10-11_18-19-09
  done: false
  episode_len_mean: 839.3492625368732
  episode_reward_max: 287.23232323232327
  episode_reward_mean: 238.2485474211137
  episode_reward_min: 113.44444444444416
  episodes_this_iter: 230
  episodes_total: 3390
  experiment_id: ba64d8304d8f43cd808e4d1968703b2e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8489474296569824
        entropy_coeff: 0.0001
        kl: 0.008070239285007118
        model: {}
        policy_loss: -0.01894974336028099
        total_loss: 12.062173080444335
        vf_explained_var: 0.9826620817184448
        vf_loss: 12.079593467712403
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.95263157894737
    gpu_util_percent0: 0.3173684210526316
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.76842105263158
    vram_util_percent0: 0.08043620859298131
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 504
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15071732680731612
    mean_env_wait_ms: 1.1773080748077887
    mean_inference_ms: 4.544521687232769
    mean_raw_obs_processing_ms: 0.3928460787657975
  time_since_restore: 583.5397388935089
  time_this_iter_s: 32.502973794937134
  time_total_s: 583.5397388935089
  timers:
    learn_throughput: 6411.658
    learn_time_ms: 25234.034
    sample_throughput: 23200.521
    sample_time_ms: 6973.636
    update_time_ms: 28.358
  timestamp: 1602440349
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: e0e0e_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e0e0e_00000 | RUNNING  | 172.17.0.4:504 |     18 |           583.54 | 2912256 |  238.249 |              287.232 |              113.444 |            839.349 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e0e0e_00000:
  custom_metrics:
    time_step_max: 4307
    time_step_mean: 3477.5784803105935
    time_step_min: 3170
  date: 2020-10-11_18-19-42
  done: true
  episode_len_mean: 836.569069895432
  episode_reward_max: 287.23232323232327
  episode_reward_mean: 239.2851992684133
  episode_reward_min: 113.44444444444416
  episodes_this_iter: 244
  episodes_total: 3634
  experiment_id: ba64d8304d8f43cd808e4d1968703b2e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8423188507556916
        entropy_coeff: 0.0001
        kl: 0.007756812777370214
        model: {}
        policy_loss: -0.019163974159164356
        total_loss: 8.819017696380616
        vf_explained_var: 0.985927939414978
        vf_loss: 8.83671441078186
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.992105263157896
    gpu_util_percent0: 0.005
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8421052631578956
    vram_util_percent0: 0.08043620859298131
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 504
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15051878125632012
    mean_env_wait_ms: 1.178694836919221
    mean_inference_ms: 4.531797204687566
    mean_raw_obs_processing_ms: 0.3922145270250115
  time_since_restore: 615.7464284896851
  time_this_iter_s: 32.20668959617615
  time_total_s: 615.7464284896851
  timers:
    learn_throughput: 6410.994
    learn_time_ms: 25236.649
    sample_throughput: 23195.005
    sample_time_ms: 6975.295
    update_time_ms: 28.921
  timestamp: 1602440382
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: e0e0e_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e0e0e_00000 | TERMINATED |       |     19 |          615.746 | 3074048 |  239.285 |              287.232 |              113.444 |            836.569 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e0e0e_00000 | TERMINATED |       |     19 |          615.746 | 3074048 |  239.285 |              287.232 |              113.444 |            836.569 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


