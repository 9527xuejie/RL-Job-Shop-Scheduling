2020-10-12 14:18:10,755	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_c29f8_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=70054)[0m 2020-10-12 14:18:13,502	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=70052)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=70052)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=70034)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=70034)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=70041)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=70041)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=70019)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=70019)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=70045)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=70045)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=70044)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=70044)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=70068)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=70068)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=70070)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=70070)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=70077)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=70077)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=70017)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=70017)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=70032)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=70032)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=70020)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=70020)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=70033)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=70033)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=70035)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=70035)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=70042)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=70042)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=70055)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=70055)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=70046)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=70046)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=70025)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=70025)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=70084)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=70084)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=70076)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=70076)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=70048)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=70048)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=70030)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=70030)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69979)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69979)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69958)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69958)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69945)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69945)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=70016)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=70016)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=70026)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=70026)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=70027)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=70027)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=70028)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=70028)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69959)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69959)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69962)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69962)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=70057)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=70057)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69946)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69946)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69963)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69963)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69987)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69987)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=70023)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=70023)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69953)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69953)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69950)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69950)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=70060)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=70060)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=70009)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=70009)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69981)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69981)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69965)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69965)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69986)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69986)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69947)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69947)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=70056)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=70056)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=70082)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=70082)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=70018)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=70018)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=70010)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=70010)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69972)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69972)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69968)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69968)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69984)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69984)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69966)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69966)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69967)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69967)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=70051)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=70051)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69956)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69956)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69949)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69949)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=70059)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=70059)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=70021)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=70021)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=70066)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=70066)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=70011)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=70011)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=70072)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=70072)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69955)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69955)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=70007)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=70007)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=70064)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=70064)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69975)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69975)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69961)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69961)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69951)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69951)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=70014)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=70014)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=70015)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=70015)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=70024)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=70024)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69954)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69954)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69960)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69960)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=70022)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=70022)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69973)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69973)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69978)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69978)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=70029)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=70029)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69948)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69948)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=70086)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=70086)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=70013)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=70013)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_c29f8_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-12_14-18-46
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 824facd13c99490c857fa26d81a874e0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1851047078768413
        entropy_coeff: 0.0005000000000000001
        kl: 0.004071502441850801
        model: {}
        policy_loss: -0.00785889983914482
        total_loss: 507.07567087809247
        vf_explained_var: 0.540532648563385
        vf_loss: 507.0832926432292
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.659374999999997
    gpu_util_percent0: 0.24875000000000003
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.55625
    vram_util_percent0: 0.08526873565103313
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 70054
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16994892060296626
    mean_env_wait_ms: 1.169091189632669
    mean_inference_ms: 5.872200097004254
    mean_raw_obs_processing_ms: 0.45335577092961277
  time_since_restore: 27.71648859977722
  time_this_iter_s: 27.71648859977722
  time_total_s: 27.71648859977722
  timers:
    learn_throughput: 8874.446
    learn_time_ms: 18231.223
    sample_throughput: 17216.996
    sample_time_ms: 9397.226
    update_time_ms: 45.065
  timestamp: 1602512326
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: c29f8_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c29f8_00000 | RUNNING  | 172.17.0.4:70054 |      1 |          27.7165 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c29f8_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3614.4305555555557
    time_step_min: 3250
  date: 2020-10-12_14-19-13
  done: false
  episode_len_mean: 890.8607594936709
  episode_reward_max: 273.5959595959592
  episode_reward_mean: 217.6365234624726
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 824facd13c99490c857fa26d81a874e0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1561074058214824
        entropy_coeff: 0.0005000000000000001
        kl: 0.007923512797181806
        model: {}
        policy_loss: -0.010965243893830726
        total_loss: 127.46906661987305
        vf_explained_var: 0.8076093792915344
        vf_loss: 127.47981770833333
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.34193548387097
    gpu_util_percent0: 0.3187096774193548
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.748387096774193
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 70054
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16561765606620044
    mean_env_wait_ms: 1.165680428994888
    mean_inference_ms: 5.6226371336530185
    mean_raw_obs_processing_ms: 0.4413906555255206
  time_since_restore: 54.19657015800476
  time_this_iter_s: 26.48008155822754
  time_total_s: 54.19657015800476
  timers:
    learn_throughput: 8799.877
    learn_time_ms: 18385.711
    sample_throughput: 18754.589
    sample_time_ms: 8626.795
    update_time_ms: 41.168
  timestamp: 1602512353
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: c29f8_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c29f8_00000 | RUNNING  | 172.17.0.4:70054 |      2 |          54.1966 | 323584 |  217.637 |              273.596 |              145.717 |            890.861 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c29f8_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3601.8677130044844
    time_step_min: 3250
  date: 2020-10-12_14-19-39
  done: false
  episode_len_mean: 885.132911392405
  episode_reward_max: 273.5959595959592
  episode_reward_mean: 219.87009333844756
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 824facd13c99490c857fa26d81a874e0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1456398169199626
        entropy_coeff: 0.0005000000000000001
        kl: 0.008224547879459957
        model: {}
        policy_loss: -0.013529085864623388
        total_loss: 61.275455474853516
        vf_explained_var: 0.8916645646095276
        vf_loss: 61.28873507181803
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.036666666666665
    gpu_util_percent0: 0.4583333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.766666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 70054
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16292763164001656
    mean_env_wait_ms: 1.1660419208572714
    mean_inference_ms: 5.433839896911039
    mean_raw_obs_processing_ms: 0.4330986534385022
  time_since_restore: 80.38152575492859
  time_this_iter_s: 26.184955596923828
  time_total_s: 80.38152575492859
  timers:
    learn_throughput: 8760.554
    learn_time_ms: 18468.239
    sample_throughput: 19699.668
    sample_time_ms: 8212.93
    update_time_ms: 40.926
  timestamp: 1602512379
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: c29f8_00000
  
== Status ==
Memory usage on this node: 28.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c29f8_00000 | RUNNING  | 172.17.0.4:70054 |      3 |          80.3815 | 485376 |   219.87 |              273.596 |              145.717 |            885.133 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c29f8_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3596.0099337748343
    time_step_min: 3231
  date: 2020-10-12_14-20-04
  done: false
  episode_len_mean: 878.7689873417721
  episode_reward_max: 276.47474747474763
  episode_reward_mean: 220.6047340493541
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 824facd13c99490c857fa26d81a874e0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1263898611068726
        entropy_coeff: 0.0005000000000000001
        kl: 0.008100568510902425
        model: {}
        policy_loss: -0.013406771836647144
        total_loss: 47.16934140523275
        vf_explained_var: 0.9198758602142334
        vf_loss: 47.18250052134196
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.53103448275862
    gpu_util_percent0: 0.2900000000000001
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.768965517241379
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 70054
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16094661920745734
    mean_env_wait_ms: 1.167455903288604
    mean_inference_ms: 5.2910087094709635
    mean_raw_obs_processing_ms: 0.42653092723086955
  time_since_restore: 105.78936982154846
  time_this_iter_s: 25.407844066619873
  time_total_s: 105.78936982154846
  timers:
    learn_throughput: 8772.696
    learn_time_ms: 18442.677
    sample_throughput: 20485.045
    sample_time_ms: 7898.054
    update_time_ms: 40.294
  timestamp: 1602512404
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: c29f8_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c29f8_00000 | RUNNING  | 172.17.0.4:70054 |      4 |          105.789 | 647168 |  220.605 |              276.475 |              145.717 |            878.769 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c29f8_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3581.6985583224114
    time_step_min: 3204
  date: 2020-10-12_14-20-30
  done: false
  episode_len_mean: 872.4867256637168
  episode_reward_max: 280.5656565656565
  episode_reward_mean: 222.48133675567283
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 159
  episodes_total: 791
  experiment_id: 824facd13c99490c857fa26d81a874e0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0873714486757915
        entropy_coeff: 0.0005000000000000001
        kl: 0.006956188706681132
        model: {}
        policy_loss: -0.011262792395427823
        total_loss: 34.19948164621989
        vf_explained_var: 0.9459590911865234
        vf_loss: 34.2105925877889
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.066666666666663
    gpu_util_percent0: 0.43766666666666665
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7666666666666657
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 70054
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15940651242537818
    mean_env_wait_ms: 1.169971635752512
    mean_inference_ms: 5.180106083655211
    mean_raw_obs_processing_ms: 0.4212780660858121
  time_since_restore: 131.2926995754242
  time_this_iter_s: 25.503329753875732
  time_total_s: 131.2926995754242
  timers:
    learn_throughput: 8760.483
    learn_time_ms: 18468.388
    sample_throughput: 21079.592
    sample_time_ms: 7675.291
    update_time_ms: 36.471
  timestamp: 1602512430
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: c29f8_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c29f8_00000 | RUNNING  | 172.17.0.4:70054 |      5 |          131.293 | 808960 |  222.481 |              280.566 |              145.717 |            872.487 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c29f8_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3564.887755102041
    time_step_min: 3204
  date: 2020-10-12_14-20-56
  done: false
  episode_len_mean: 860.6943942133815
  episode_reward_max: 280.5656565656565
  episode_reward_mean: 225.7112809834327
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 315
  episodes_total: 1106
  experiment_id: 824facd13c99490c857fa26d81a874e0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0886386533578236
        entropy_coeff: 0.0005000000000000001
        kl: 0.007588425030310948
        model: {}
        policy_loss: -0.01092883839737624
        total_loss: 30.730765342712402
        vf_explained_var: 0.9611188769340515
        vf_loss: 30.741480032602947
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.18965517241379
    gpu_util_percent0: 0.2837931034482758
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7620689655172406
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 70054
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15734562235197594
    mean_env_wait_ms: 1.1756497799942263
    mean_inference_ms: 5.0326967604555675
    mean_raw_obs_processing_ms: 0.41464838863890185
  time_since_restore: 156.71548414230347
  time_this_iter_s: 25.422784566879272
  time_total_s: 156.71548414230347
  timers:
    learn_throughput: 8759.305
    learn_time_ms: 18470.871
    sample_throughput: 21462.045
    sample_time_ms: 7538.517
    update_time_ms: 36.673
  timestamp: 1602512456
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: c29f8_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c29f8_00000 | RUNNING  | 172.17.0.4:70054 |      6 |          156.715 | 970752 |  225.711 |              280.566 |              145.717 |            860.694 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c29f8_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3552.704692556634
    time_step_min: 3179
  date: 2020-10-12_14-21-21
  done: false
  episode_len_mean: 855.0387658227849
  episode_reward_max: 284.35353535353545
  episode_reward_mean: 227.46978487405684
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: 824facd13c99490c857fa26d81a874e0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0706470410029094
        entropy_coeff: 0.0005000000000000001
        kl: 0.007387861027382314
        model: {}
        policy_loss: -0.013462736414415607
        total_loss: 19.742233912150066
        vf_explained_var: 0.9632093906402588
        vf_loss: 19.75549300511678
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.182758620689658
    gpu_util_percent0: 0.30241379310344835
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.775862068965517
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 70054
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15659944710447274
    mean_env_wait_ms: 1.1781296386862312
    mean_inference_ms: 4.979102261022608
    mean_raw_obs_processing_ms: 0.41223103840983283
  time_since_restore: 182.10720825195312
  time_this_iter_s: 25.391724109649658
  time_total_s: 182.10720825195312
  timers:
    learn_throughput: 8762.399
    learn_time_ms: 18464.35
    sample_throughput: 21732.82
    sample_time_ms: 7444.593
    update_time_ms: 36.744
  timestamp: 1602512481
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: c29f8_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c29f8_00000 | RUNNING  | 172.17.0.4:70054 |      7 |          182.107 | 1132544 |   227.47 |              284.354 |              145.717 |            855.039 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c29f8_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3540.6398852223815
    time_step_min: 3179
  date: 2020-10-12_14-21-47
  done: false
  episode_len_mean: 850.7552742616034
  episode_reward_max: 284.35353535353545
  episode_reward_mean: 229.23441162681647
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 824facd13c99490c857fa26d81a874e0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0475670397281647
        entropy_coeff: 0.0005000000000000001
        kl: 0.007399068369219701
        model: {}
        policy_loss: -0.009183195322596779
        total_loss: 16.652963479359943
        vf_explained_var: 0.9667003154754639
        vf_loss: 16.661930561065674
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.253333333333334
    gpu_util_percent0: 0.2806666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7799999999999994
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 70054
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15595371849321574
    mean_env_wait_ms: 1.180315259362135
    mean_inference_ms: 4.9327435791243825
    mean_raw_obs_processing_ms: 0.41007655943868965
  time_since_restore: 207.71829748153687
  time_this_iter_s: 25.61108922958374
  time_total_s: 207.71829748153687
  timers:
    learn_throughput: 8754.58
    learn_time_ms: 18480.842
    sample_throughput: 21923.488
    sample_time_ms: 7379.847
    update_time_ms: 36.947
  timestamp: 1602512507
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: c29f8_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c29f8_00000 | RUNNING  | 172.17.0.4:70054 |      8 |          207.718 | 1294336 |  229.234 |              284.354 |              145.717 |            850.755 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c29f8_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3526.8721374045804
    time_step_min: 3179
  date: 2020-10-12_14-22-12
  done: false
  episode_len_mean: 845.9875
  episode_reward_max: 285.7171717171716
  episode_reward_mean: 231.28724747474732
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 178
  episodes_total: 1600
  experiment_id: 824facd13c99490c857fa26d81a874e0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9999773452679316
        entropy_coeff: 0.0005000000000000001
        kl: 0.007928823702968657
        model: {}
        policy_loss: -0.011458211791856835
        total_loss: 16.58501172065735
        vf_explained_var: 0.9729644656181335
        vf_loss: 16.596176783243816
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.09655172413794
    gpu_util_percent0: 0.330344827586207
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7655172413793094
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 70054
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1553442693731311
    mean_env_wait_ms: 1.1829385956215384
    mean_inference_ms: 4.888015955975619
    mean_raw_obs_processing_ms: 0.40796869947584896
  time_since_restore: 233.08506870269775
  time_this_iter_s: 25.36677122116089
  time_total_s: 233.08506870269775
  timers:
    learn_throughput: 8757.326
    learn_time_ms: 18475.045
    sample_throughput: 22100.651
    sample_time_ms: 7320.689
    update_time_ms: 37.313
  timestamp: 1602512532
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: c29f8_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c29f8_00000 | RUNNING  | 172.17.0.4:70054 |      9 |          233.085 | 1456128 |  231.287 |              285.717 |              145.717 |            845.987 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c29f8_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3508.0337259100643
    time_step_min: 3173
  date: 2020-10-12_14-22-38
  done: false
  episode_len_mean: 839.0052742616034
  episode_reward_max: 285.7171717171716
  episode_reward_mean: 234.27066551591852
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 296
  episodes_total: 1896
  experiment_id: 824facd13c99490c857fa26d81a874e0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9948871235052744
        entropy_coeff: 0.0005000000000000001
        kl: 0.006681857941051324
        model: {}
        policy_loss: -0.011002168253374597
        total_loss: 15.828110535939535
        vf_explained_var: 0.9757750630378723
        vf_loss: 15.838941733042398
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.416666666666664
    gpu_util_percent0: 0.3216666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7666666666666657
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 70054
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1544757639430998
    mean_env_wait_ms: 1.1866667174257324
    mean_inference_ms: 4.827216442181437
    mean_raw_obs_processing_ms: 0.4051510158420033
  time_since_restore: 258.75922751426697
  time_this_iter_s: 25.674158811569214
  time_total_s: 258.75922751426697
  timers:
    learn_throughput: 8753.953
    learn_time_ms: 18482.164
    sample_throughput: 22185.497
    sample_time_ms: 7292.692
    update_time_ms: 37.276
  timestamp: 1602512558
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: c29f8_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c29f8_00000 | RUNNING  | 172.17.0.4:70054 |     10 |          258.759 | 1617920 |  234.271 |              285.717 |              145.717 |            839.005 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c29f8_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3499.19842053307
    time_step_min: 3171
  date: 2020-10-12_14-23-03
  done: false
  episode_len_mean: 835.7263875365142
  episode_reward_max: 294.20202020201987
  episode_reward_mean: 235.87525203347977
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: 824facd13c99490c857fa26d81a874e0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.975288137793541
        entropy_coeff: 0.0005000000000000001
        kl: 0.007294710182274382
        model: {}
        policy_loss: -0.012727556153549813
        total_loss: 11.962000767389933
        vf_explained_var: 0.9750909805297852
        vf_loss: 11.974486589431763
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.86896551724138
    gpu_util_percent0: 0.27379310344827584
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7689655172413787
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 70054
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15410069639168583
    mean_env_wait_ms: 1.1884041371910867
    mean_inference_ms: 4.80050943889577
    mean_raw_obs_processing_ms: 0.4038948239073662
  time_since_restore: 284.22235012054443
  time_this_iter_s: 25.463122606277466
  time_total_s: 284.22235012054443
  timers:
    learn_throughput: 8742.492
    learn_time_ms: 18506.394
    sample_throughput: 22972.665
    sample_time_ms: 7042.805
    update_time_ms: 36.522
  timestamp: 1602512583
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: c29f8_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c29f8_00000 | RUNNING  | 172.17.0.4:70054 |     11 |          284.222 | 1779712 |  235.875 |              294.202 |              145.717 |            835.726 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c29f8_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3490.923534798535
    time_step_min: 3159
  date: 2020-10-12_14-23-29
  done: false
  episode_len_mean: 832.6595840867993
  episode_reward_max: 294.20202020201987
  episode_reward_mean: 237.1319752680511
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 824facd13c99490c857fa26d81a874e0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9521185209353765
        entropy_coeff: 0.0005000000000000001
        kl: 0.006661186693236232
        model: {}
        policy_loss: -0.013089668517447231
        total_loss: 12.603836615880331
        vf_explained_var: 0.9737562537193298
        vf_loss: 12.61673672993978
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.60666666666667
    gpu_util_percent0: 0.30966666666666665
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.776666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 70054
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1537581162752723
    mean_env_wait_ms: 1.1899998485728014
    mean_inference_ms: 4.776173893611087
    mean_raw_obs_processing_ms: 0.402719028810241
  time_since_restore: 310.0318901538849
  time_this_iter_s: 25.809540033340454
  time_total_s: 310.0318901538849
  timers:
    learn_throughput: 8738.029
    learn_time_ms: 18515.847
    sample_throughput: 23227.582
    sample_time_ms: 6965.512
    update_time_ms: 36.536
  timestamp: 1602512609
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: c29f8_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c29f8_00000 | RUNNING  | 172.17.0.4:70054 |     12 |          310.032 | 1941504 |  237.132 |              294.202 |              145.717 |             832.66 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c29f8_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3477.030998389694
    time_step_min: 3151
  date: 2020-10-12_14-23-55
  done: false
  episode_len_mean: 827.7671178343949
  episode_reward_max: 294.20202020201987
  episode_reward_mean: 239.24816235604442
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 300
  episodes_total: 2512
  experiment_id: 824facd13c99490c857fa26d81a874e0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9211943199237188
        entropy_coeff: 0.0005000000000000001
        kl: 0.0069003046955913305
        model: {}
        policy_loss: -0.011187698284629732
        total_loss: 15.527917702992758
        vf_explained_var: 0.9792836308479309
        vf_loss: 15.538876056671143
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.586206896551722
    gpu_util_percent0: 0.3679310344827586
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7689655172413787
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 70054
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1531841320180545
    mean_env_wait_ms: 1.1929027427026
    mean_inference_ms: 4.736359624859733
    mean_raw_obs_processing_ms: 0.4008259788956888
  time_since_restore: 335.47738766670227
  time_this_iter_s: 25.445497512817383
  time_total_s: 335.47738766670227
  timers:
    learn_throughput: 8742.777
    learn_time_ms: 18505.79
    sample_throughput: 23418.141
    sample_time_ms: 6908.832
    update_time_ms: 36.053
  timestamp: 1602512635
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: c29f8_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c29f8_00000 | RUNNING  | 172.17.0.4:70054 |     13 |          335.477 | 2103296 |  239.248 |              294.202 |              145.717 |            827.767 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c29f8_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3468.7953348382243
    time_step_min: 3151
  date: 2020-10-12_14-24-20
  done: false
  episode_len_mean: 825.1623231571109
  episode_reward_max: 294.20202020201987
  episode_reward_mean: 240.4743300465563
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 174
  episodes_total: 2686
  experiment_id: 824facd13c99490c857fa26d81a874e0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9143994450569153
        entropy_coeff: 0.0005000000000000001
        kl: 0.0060155229875817895
        model: {}
        policy_loss: -0.012139652118397256
        total_loss: 10.54153060913086
        vf_explained_var: 0.979185163974762
        vf_loss: 10.553526004155477
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.258620689655178
    gpu_util_percent0: 0.34551724137931034
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7793103448275853
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 70054
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15290204645036995
    mean_env_wait_ms: 1.194294714663936
    mean_inference_ms: 4.716242447895825
    mean_raw_obs_processing_ms: 0.39984871320613224
  time_since_restore: 360.86685967445374
  time_this_iter_s: 25.389472007751465
  time_total_s: 360.86685967445374
  timers:
    learn_throughput: 8733.637
    learn_time_ms: 18525.158
    sample_throughput: 23492.85
    sample_time_ms: 6886.861
    update_time_ms: 36.108
  timestamp: 1602512660
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: c29f8_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c29f8_00000 | RUNNING  | 172.17.0.4:70054 |     14 |          360.867 | 2265088 |  240.474 |              294.202 |              145.717 |            825.162 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c29f8_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3462.4602272727275
    time_step_min: 3131
  date: 2020-10-12_14-24-46
  done: false
  episode_len_mean: 822.9542897327707
  episode_reward_max: 294.20202020201987
  episode_reward_mean: 241.45540851553497
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: 824facd13c99490c857fa26d81a874e0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9019962549209595
        entropy_coeff: 0.0005000000000000001
        kl: 0.006133316123547654
        model: {}
        policy_loss: -0.012229806568939239
        total_loss: 9.555021127065023
        vf_explained_var: 0.9795403480529785
        vf_loss: 9.567088762919107
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.093333333333337
    gpu_util_percent0: 0.38433333333333336
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7733333333333334
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 70054
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15266091665082349
    mean_env_wait_ms: 1.1954806841085772
    mean_inference_ms: 4.699493939756923
    mean_raw_obs_processing_ms: 0.39902570544565097
  time_since_restore: 386.6415421962738
  time_this_iter_s: 25.77468252182007
  time_total_s: 386.6415421962738
  timers:
    learn_throughput: 8734.254
    learn_time_ms: 18523.849
    sample_throughput: 23377.608
    sample_time_ms: 6920.811
    update_time_ms: 37.781
  timestamp: 1602512686
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: c29f8_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c29f8_00000 | RUNNING  | 172.17.0.4:70054 |     15 |          386.642 | 2426880 |  241.455 |              294.202 |              145.717 |            822.954 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c29f8_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3453.8821989528797
    time_step_min: 3083
  date: 2020-10-12_14-25-12
  done: false
  episode_len_mean: 819.9792477302204
  episode_reward_max: 298.8989898989898
  episode_reward_mean: 242.75903981448718
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 240
  episodes_total: 3084
  experiment_id: 824facd13c99490c857fa26d81a874e0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8659086326758066
        entropy_coeff: 0.0005000000000000001
        kl: 0.00634678197093308
        model: {}
        policy_loss: -0.012134946203635385
        total_loss: 13.195513248443604
        vf_explained_var: 0.980156421661377
        vf_loss: 13.207446098327637
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.246666666666666
    gpu_util_percent0: 0.27166666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7599999999999993
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 70054
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15233324998404252
    mean_env_wait_ms: 1.19726387522671
    mean_inference_ms: 4.676664805029115
    mean_raw_obs_processing_ms: 0.397877379632373
  time_since_restore: 412.30074191093445
  time_this_iter_s: 25.659199714660645
  time_total_s: 412.30074191093445
  timers:
    learn_throughput: 8723.561
    learn_time_ms: 18546.555
    sample_throughput: 23382.326
    sample_time_ms: 6919.414
    update_time_ms: 37.616
  timestamp: 1602512712
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: c29f8_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c29f8_00000 | RUNNING  | 172.17.0.4:70054 |     16 |          412.301 | 2588672 |  242.759 |              298.899 |              145.717 |            819.979 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c29f8_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3445.377811550152
    time_step_min: 3083
  date: 2020-10-12_14-25-37
  done: false
  episode_len_mean: 817.4445449065702
  episode_reward_max: 298.8989898989898
  episode_reward_mean: 243.9846110289147
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 234
  episodes_total: 3318
  experiment_id: 824facd13c99490c857fa26d81a874e0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8606445689996084
        entropy_coeff: 0.0005000000000000001
        kl: 0.005582816433161497
        model: {}
        policy_loss: -0.011729711521184072
        total_loss: 9.780861934026083
        vf_explained_var: 0.9827695488929749
        vf_loss: 9.792463779449463
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.810344827586206
    gpu_util_percent0: 0.30241379310344824
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7689655172413787
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 70054
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15203665970332733
    mean_env_wait_ms: 1.1987745508593406
    mean_inference_ms: 4.656443454540404
    mean_raw_obs_processing_ms: 0.396903348145582
  time_since_restore: 437.6155774593353
  time_this_iter_s: 25.31483554840088
  time_total_s: 437.6155774593353
  timers:
    learn_throughput: 8723.232
    learn_time_ms: 18547.254
    sample_throughput: 23412.969
    sample_time_ms: 6910.358
    update_time_ms: 36.759
  timestamp: 1602512737
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: c29f8_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c29f8_00000 | RUNNING  | 172.17.0.4:70054 |     17 |          437.616 | 2750464 |  243.985 |              298.899 |              145.717 |            817.445 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c29f8_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3440.181554524362
    time_step_min: 3083
  date: 2020-10-12_14-26-03
  done: false
  episode_len_mean: 815.873417721519
  episode_reward_max: 298.8989898989898
  episode_reward_mean: 244.73267194383405
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 3476
  experiment_id: 824facd13c99490c857fa26d81a874e0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8570553759733835
        entropy_coeff: 0.0005000000000000001
        kl: 0.00693794801676025
        model: {}
        policy_loss: -0.012595690621916825
        total_loss: 9.302302360534668
        vf_explained_var: 0.9800246357917786
        vf_loss: 9.314632733662924
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.163333333333338
    gpu_util_percent0: 0.381
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.769999999999999
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 70054
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15185712779332625
    mean_env_wait_ms: 1.199710318189535
    mean_inference_ms: 4.644104190401529
    mean_raw_obs_processing_ms: 0.3962936192363309
  time_since_restore: 463.3882637023926
  time_this_iter_s: 25.77268624305725
  time_total_s: 463.3882637023926
  timers:
    learn_throughput: 8720.372
    learn_time_ms: 18553.337
    sample_throughput: 23381.253
    sample_time_ms: 6919.732
    update_time_ms: 36.533
  timestamp: 1602512763
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: c29f8_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c29f8_00000 | RUNNING  | 172.17.0.4:70054 |     18 |          463.388 | 2912256 |  244.733 |              298.899 |              145.717 |            815.873 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c29f8_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3435.160891089109
    time_step_min: 3083
  date: 2020-10-12_14-26-29
  done: false
  episode_len_mean: 814.1853165938865
  episode_reward_max: 298.8989898989898
  episode_reward_mean: 245.55176216311577
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 188
  episodes_total: 3664
  experiment_id: 824facd13c99490c857fa26d81a874e0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8260929683844248
        entropy_coeff: 0.0005000000000000001
        kl: 0.00627721450291574
        model: {}
        policy_loss: -0.010709817167177485
        total_loss: 11.524338483810425
        vf_explained_var: 0.9801642894744873
        vf_loss: 11.534833749135336
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.593333333333337
    gpu_util_percent0: 0.318
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.77
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 70054
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1516663633147783
    mean_env_wait_ms: 1.200796751918906
    mean_inference_ms: 4.630549002943618
    mean_raw_obs_processing_ms: 0.3956178793006496
  time_since_restore: 489.116322517395
  time_this_iter_s: 25.72805881500244
  time_total_s: 489.116322517395
  timers:
    learn_throughput: 8712.411
    learn_time_ms: 18570.291
    sample_throughput: 23321.248
    sample_time_ms: 6937.536
    update_time_ms: 36.981
  timestamp: 1602512789
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: c29f8_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c29f8_00000 | RUNNING  | 172.17.0.4:70054 |     19 |          489.116 | 3074048 |  245.552 |              298.899 |              145.717 |            814.185 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c29f8_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3428.4441611422744
    time_step_min: 3083
  date: 2020-10-12_14-26-55
  done: false
  episode_len_mean: 812.0630379746835
  episode_reward_max: 298.8989898989898
  episode_reward_mean: 246.60976857179378
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 286
  episodes_total: 3950
  experiment_id: 824facd13c99490c857fa26d81a874e0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8063790599505106
        entropy_coeff: 0.0005000000000000001
        kl: 0.00581474454763035
        model: {}
        policy_loss: -0.010059737542178482
        total_loss: 10.378987232844034
        vf_explained_var: 0.9842923283576965
        vf_loss: 10.388868490854898
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.49666666666667
    gpu_util_percent0: 0.2636666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7666666666666657
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 70054
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.151379091067901
    mean_env_wait_ms: 1.2023026371171521
    mean_inference_ms: 4.611525890706571
    mean_raw_obs_processing_ms: 0.39469639645267685
  time_since_restore: 514.9221925735474
  time_this_iter_s: 25.805870056152344
  time_total_s: 514.9221925735474
  timers:
    learn_throughput: 8708.443
    learn_time_ms: 18578.752
    sample_throughput: 23306.117
    sample_time_ms: 6942.04
    update_time_ms: 35.557
  timestamp: 1602512815
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: c29f8_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c29f8_00000 | RUNNING  | 172.17.0.4:70054 |     20 |          514.922 | 3235840 |   246.61 |              298.899 |              145.717 |            812.063 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c29f8_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3424.633333333333
    time_step_min: 3083
  date: 2020-10-12_14-27-21
  done: false
  episode_len_mean: 811.1747809152872
  episode_reward_max: 298.8989898989898
  episode_reward_mean: 247.171761431255
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 4108
  experiment_id: 824facd13c99490c857fa26d81a874e0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8050975054502487
        entropy_coeff: 0.0005000000000000001
        kl: 0.006411496355819206
        model: {}
        policy_loss: -0.0109325938198405
        total_loss: 8.397321462631226
        vf_explained_var: 0.9822394847869873
        vf_loss: 8.408015330632528
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.976666666666667
    gpu_util_percent0: 0.3596666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.78
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 70054
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15123849418675206
    mean_env_wait_ms: 1.2030438060176072
    mean_inference_ms: 4.602018050185606
    mean_raw_obs_processing_ms: 0.3942315478536576
  time_since_restore: 540.661639213562
  time_this_iter_s: 25.73944664001465
  time_total_s: 540.661639213562
  timers:
    learn_throughput: 8696.685
    learn_time_ms: 18603.871
    sample_throughput: 23300.176
    sample_time_ms: 6943.81
    update_time_ms: 35.604
  timestamp: 1602512841
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: c29f8_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c29f8_00000 | RUNNING  | 172.17.0.4:70054 |     21 |          540.662 | 3397632 |  247.172 |              298.899 |              145.717 |            811.175 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c29f8_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3421.5082547169814
    time_step_min: 3083
  date: 2020-10-12_14-27-47
  done: false
  episode_len_mean: 810.3659793814433
  episode_reward_max: 298.8989898989898
  episode_reward_mean: 247.6299262541061
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 160
  episodes_total: 4268
  experiment_id: 824facd13c99490c857fa26d81a874e0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7943403224150339
        entropy_coeff: 0.0005000000000000001
        kl: 0.006092905105712513
        model: {}
        policy_loss: -0.012508889408006022
        total_loss: 10.069480101267496
        vf_explained_var: 0.9799533486366272
        vf_loss: 10.08177661895752
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.76896551724138
    gpu_util_percent0: 0.3496551724137931
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.775862068965517
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 70054
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15110498222396582
    mean_env_wait_ms: 1.2037468267128497
    mean_inference_ms: 4.5929102343134245
    mean_raw_obs_processing_ms: 0.39377986799603193
  time_since_restore: 566.2624063491821
  time_this_iter_s: 25.600767135620117
  time_total_s: 566.2624063491821
  timers:
    learn_throughput: 8694.37
    learn_time_ms: 18608.823
    sample_throughput: 23385.89
    sample_time_ms: 6918.36
    update_time_ms: 34.166
  timestamp: 1602512867
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: c29f8_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c29f8_00000 | RUNNING  | 172.17.0.4:70054 |     22 |          566.262 | 3559424 |   247.63 |              298.899 |              145.717 |            810.366 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c29f8_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3415.407570422535
    time_step_min: 3083
  date: 2020-10-12_14-28-12
  done: false
  episode_len_mean: 808.5879265091863
  episode_reward_max: 298.8989898989898
  episode_reward_mean: 248.62850287653427
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 304
  episodes_total: 4572
  experiment_id: 824facd13c99490c857fa26d81a874e0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7644506990909576
        entropy_coeff: 0.0005000000000000001
        kl: 0.005771325357879202
        model: {}
        policy_loss: -0.009549629636846172
        total_loss: 10.615382512410482
        vf_explained_var: 0.9846494197845459
        vf_loss: 10.624737024307251
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.48666666666667
    gpu_util_percent0: 0.44200000000000006
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.766666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 70054
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15086919759533143
    mean_env_wait_ms: 1.2050598122602258
    mean_inference_ms: 4.577019989818888
    mean_raw_obs_processing_ms: 0.393010041486978
  time_since_restore: 591.745041847229
  time_this_iter_s: 25.482635498046875
  time_total_s: 591.745041847229
  timers:
    learn_throughput: 8693.831
    learn_time_ms: 18609.977
    sample_throughput: 23376.57
    sample_time_ms: 6921.118
    update_time_ms: 32.574
  timestamp: 1602512892
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: c29f8_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c29f8_00000 | RUNNING  | 172.17.0.4:70054 |     23 |          591.745 | 3721216 |  248.629 |              298.899 |              145.717 |            808.588 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c29f8_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3412.3495331069607
    time_step_min: 3083
  date: 2020-10-12_14-28-38
  done: true
  episode_len_mean: 807.6881856540084
  episode_reward_max: 298.8989898989898
  episode_reward_mean: 249.11699271192933
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 168
  episodes_total: 4740
  experiment_id: 824facd13c99490c857fa26d81a874e0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7512289037307104
        entropy_coeff: 0.0005000000000000001
        kl: 0.006618439607943098
        model: {}
        policy_loss: -0.011942399355272451
        total_loss: 7.106495062510173
        vf_explained_var: 0.9852812886238098
        vf_loss: 7.118151148160298
    num_steps_sampled: 3883008
    num_steps_trained: 3883008
  iterations_since_restore: 24
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.52068965517242
    gpu_util_percent0: 0.3986206896551724
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.775862068965517
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 70054
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15074855349590177
    mean_env_wait_ms: 1.2056933373904657
    mean_inference_ms: 4.568882464918616
    mean_raw_obs_processing_ms: 0.39261300070807614
  time_since_restore: 617.0268259048462
  time_this_iter_s: 25.281784057617188
  time_total_s: 617.0268259048462
  timers:
    learn_throughput: 8701.912
    learn_time_ms: 18592.696
    sample_throughput: 23358.275
    sample_time_ms: 6926.539
    update_time_ms: 32.355
  timestamp: 1602512918
  timesteps_since_restore: 0
  timesteps_total: 3883008
  training_iteration: 24
  trial_id: c29f8_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c29f8_00000 | TERMINATED |       |     24 |          617.027 | 3883008 |  249.117 |              298.899 |              145.717 |            807.688 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c29f8_00000 | TERMINATED |       |     24 |          617.027 | 3883008 |  249.117 |              298.899 |              145.717 |            807.688 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


