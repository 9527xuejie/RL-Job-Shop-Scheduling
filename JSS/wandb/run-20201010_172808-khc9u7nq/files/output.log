2020-10-10 17:28:10,656	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8266[39m[22m
== Status ==
Memory usage on this node: 32.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_f8bfc_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=5012)[0m 2020-10-10 17:28:13,666	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=5074)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5074)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5054)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5054)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5002)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5002)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5019)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5019)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5018)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5018)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5015)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5015)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5038)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5038)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=4963)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=4963)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5076)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5076)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=4960)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=4960)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=4977)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=4977)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=4958)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=4958)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5022)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5022)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=4949)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=4949)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5009)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5009)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5014)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5014)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=4944)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=4944)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5061)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5061)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=4941)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=4941)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5020)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5020)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5048)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5048)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5021)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5021)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5044)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5044)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5057)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5057)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5035)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5035)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5028)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5028)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5011)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5011)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5029)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5029)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=4975)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=4975)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=4945)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=4945)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5004)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5004)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5008)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5008)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5006)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5006)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5013)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5013)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=4940)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=4940)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=4954)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=4954)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=4942)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=4942)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5046)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5046)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=4962)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=4962)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=4974)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=4974)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5067)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5067)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=4952)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=4952)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5064)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5064)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=4978)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=4978)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5010)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5010)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5030)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5030)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=4943)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=4943)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=4947)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=4947)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5043)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5043)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5007)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5007)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5042)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5042)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=4969)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=4969)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=4939)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=4939)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=4999)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=4999)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=4968)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=4968)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5023)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5023)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5078)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5078)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=4950)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=4950)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5031)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5031)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=4938)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=4938)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=4951)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=4951)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5016)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5016)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5063)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5063)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5050)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5050)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=4955)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=4955)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=4967)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=4967)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=4965)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=4965)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5024)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5024)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=4971)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=4971)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5056)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5056)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=4937)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=4937)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5001)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5001)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5017)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5017)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=4953)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=4953)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5027)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5027)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5045)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5045)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5040)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5040)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5025)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5025)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=5005)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5005)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_f8bfc_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-10_17-28-52
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 7a3190a271cb4384b9e5f48fcc324a7d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.18521021093641
        entropy_coeff: 0.0
        kl: 0.004181917856580445
        model: {}
        policy_loss: -0.0043955518298649365
        total_loss: 19.856436320713588
        vf_explained_var: 0.45542749762535095
        vf_loss: 19.85999502454485
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.93658536585366
    gpu_util_percent0: 0.2902439024390244
    gpu_util_percent1: 0.00024390243902439024
    gpu_util_percent2: 0.0
    ram_util_percent: 6.27560975609756
    vram_util_percent0: 0.1906702717404347
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 5012
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1734512137130073
    mean_env_wait_ms: 1.2016299831605908
    mean_inference_ms: 6.189893620659738
    mean_raw_obs_processing_ms: 0.47107876138430976
  time_since_restore: 33.57032227516174
  time_this_iter_s: 33.57032227516174
  time_total_s: 33.57032227516174
  timers:
    learn_throughput: 6849.154
    learn_time_ms: 23622.187
    sample_throughput: 16409.341
    sample_time_ms: 9859.75
    update_time_ms: 46.849
  timestamp: 1602350932
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: f8bfc_00000
  
== Status ==
Memory usage on this node: 48.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f8bfc_00000 | RUNNING  | 172.17.0.4:5012 |      1 |          33.5703 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f8bfc_00000:
  custom_metrics:
    time_step_max: 4072
    time_step_mean: 3609.8541666666665
    time_step_min: 3258
  date: 2020-10-10_17-29-24
  done: false
  episode_len_mean: 882.3575949367089
  episode_reward_max: 272.38383838383845
  episode_reward_mean: 217.32294463623555
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 7a3190a271cb4384b9e5f48fcc324a7d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.1554901855332511
        entropy_coeff: 0.0
        kl: 0.0067025132676852605
        model: {}
        policy_loss: -0.004621441925077566
        total_loss: 12.059275150299072
        vf_explained_var: 0.7772969007492065
        vf_loss: 12.063226427350726
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.907894736842106
    gpu_util_percent0: 0.32421052631578945
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.46578947368421
    vram_util_percent0: 0.2046572646769433
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 5012
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16850974122435095
    mean_env_wait_ms: 1.1986682571634855
    mean_inference_ms: 5.8308941351330965
    mean_raw_obs_processing_ms: 0.45567204159579194
  time_since_restore: 65.02655577659607
  time_this_iter_s: 31.456233501434326
  time_total_s: 65.02655577659607
  timers:
    learn_throughput: 6867.383
    learn_time_ms: 23559.483
    sample_throughput: 18262.325
    sample_time_ms: 8859.332
    update_time_ms: 45.11
  timestamp: 1602350964
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: f8bfc_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f8bfc_00000 | RUNNING  | 172.17.0.4:5012 |      2 |          65.0266 | 323584 |  217.323 |              272.384 |              145.717 |            882.358 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f8bfc_00000:
  custom_metrics:
    time_step_max: 4072
    time_step_mean: 3605.688340807175
    time_step_min: 3258
  date: 2020-10-10_17-29-55
  done: false
  episode_len_mean: 872.6561181434599
  episode_reward_max: 272.38383838383845
  episode_reward_mean: 218.6570131696712
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 7a3190a271cb4384b9e5f48fcc324a7d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.1345107640538896
        entropy_coeff: 0.0
        kl: 0.008632942169372524
        model: {}
        policy_loss: -0.005036757913850514
        total_loss: 13.964550767626081
        vf_explained_var: 0.8594231605529785
        vf_loss: 13.96872431891305
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.626315789473683
    gpu_util_percent0: 0.39473684210526316
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.481578947368421
    vram_util_percent0: 0.2046572646769433
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 5012
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16536223635391378
    mean_env_wait_ms: 1.1993704445684341
    mean_inference_ms: 5.591614155420394
    mean_raw_obs_processing_ms: 0.44587676789505326
  time_since_restore: 96.11830139160156
  time_this_iter_s: 31.091745615005493
  time_total_s: 96.11830139160156
  timers:
    learn_throughput: 6874.139
    learn_time_ms: 23536.328
    sample_throughput: 19232.573
    sample_time_ms: 8412.395
    update_time_ms: 41.821
  timestamp: 1602350995
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: f8bfc_00000
  
== Status ==
Memory usage on this node: 48.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f8bfc_00000 | RUNNING  | 172.17.0.4:5012 |      3 |          96.1183 | 485376 |  218.657 |              272.384 |              145.717 |            872.656 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f8bfc_00000:
  custom_metrics:
    time_step_max: 4072
    time_step_mean: 3601.8526490066224
    time_step_min: 3258
  date: 2020-10-10_17-30-26
  done: false
  episode_len_mean: 863.9256329113924
  episode_reward_max: 272.38383838383845
  episode_reward_mean: 219.90901099603613
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 7a3190a271cb4384b9e5f48fcc324a7d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.1115031668118067
        entropy_coeff: 0.0
        kl: 0.00563989340194634
        model: {}
        policy_loss: -0.005306224912471537
        total_loss: 15.673490728650775
        vf_explained_var: 0.8959417939186096
        vf_loss: 15.678233351026263
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.97027027027027
    gpu_util_percent0: 0.25135135135135134
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.491891891891891
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 5012
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16313131218015758
    mean_env_wait_ms: 1.2017393843481805
    mean_inference_ms: 5.425110522239796
    mean_raw_obs_processing_ms: 0.43858316334727654
  time_since_restore: 127.16822552680969
  time_this_iter_s: 31.04992413520813
  time_total_s: 127.16822552680969
  timers:
    learn_throughput: 6873.278
    learn_time_ms: 23539.278
    sample_throughput: 19817.5
    sample_time_ms: 8164.097
    update_time_ms: 39.849
  timestamp: 1602351026
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: f8bfc_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f8bfc_00000 | RUNNING  | 172.17.0.4:5012 |      4 |          127.168 | 647168 |  219.909 |              272.384 |              145.717 |            863.926 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f8bfc_00000:
  custom_metrics:
    time_step_max: 4157
    time_step_mean: 3588.981026785714
    time_step_min: 3246
  date: 2020-10-10_17-30-57
  done: false
  episode_len_mean: 849.3203463203463
  episode_reward_max: 274.2020202020201
  episode_reward_mean: 221.79056801784057
  episode_reward_min: 136.17171717171735
  episodes_this_iter: 292
  episodes_total: 924
  experiment_id: 7a3190a271cb4384b9e5f48fcc324a7d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.0765756964683533
        entropy_coeff: 0.0
        kl: 0.004565858980640769
        model: {}
        policy_loss: -0.004306623350463009
        total_loss: 21.548018591744558
        vf_explained_var: 0.9350501298904419
        vf_loss: 21.551867621285574
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.521052631578947
    gpu_util_percent0: 0.41026315789473683
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.471052631578948
    vram_util_percent0: 0.2046572646769433
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 5012
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16050038357148674
    mean_env_wait_ms: 1.208666811528717
    mean_inference_ms: 5.230887480804078
    mean_raw_obs_processing_ms: 0.430033408934164
  time_since_restore: 158.0989248752594
  time_this_iter_s: 30.930699348449707
  time_total_s: 158.0989248752594
  timers:
    learn_throughput: 6877.638
    learn_time_ms: 23524.354
    sample_throughput: 20214.833
    sample_time_ms: 8003.628
    update_time_ms: 42.42
  timestamp: 1602351057
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: f8bfc_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f8bfc_00000 | RUNNING  | 172.17.0.4:5012 |      5 |          158.099 | 808960 |  221.791 |              274.202 |              136.172 |             849.32 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f8bfc_00000:
  custom_metrics:
    time_step_max: 4157
    time_step_mean: 3584.553803339518
    time_step_min: 3246
  date: 2020-10-10_17-31-28
  done: false
  episode_len_mean: 841.5488245931284
  episode_reward_max: 274.2020202020201
  episode_reward_mean: 223.2338849617329
  episode_reward_min: 136.17171717171735
  episodes_this_iter: 182
  episodes_total: 1106
  experiment_id: 7a3190a271cb4384b9e5f48fcc324a7d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 1.0e-05
        entropy: 1.065244802406856
        entropy_coeff: 0.0
        kl: 0.005820262977587325
        model: {}
        policy_loss: -0.004607323310795307
        total_loss: 14.176639897482735
        vf_explained_var: 0.9457564353942871
        vf_loss: 14.180956091199603
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.910810810810805
    gpu_util_percent0: 0.3845945945945946
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4837837837837835
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 5012
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15940475709576307
    mean_env_wait_ms: 1.2119442965580054
    mean_inference_ms: 5.149369724480973
    mean_raw_obs_processing_ms: 0.42644633812747723
  time_since_restore: 188.7956006526947
  time_this_iter_s: 30.696675777435303
  time_total_s: 188.7956006526947
  timers:
    learn_throughput: 6888.223
    learn_time_ms: 23488.206
    sample_throughput: 20537.566
    sample_time_ms: 7877.856
    update_time_ms: 49.403
  timestamp: 1602351088
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: f8bfc_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f8bfc_00000 | RUNNING  | 172.17.0.4:5012 |      6 |          188.796 | 970752 |  223.234 |              274.202 |              136.172 |            841.549 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f8bfc_00000:
  custom_metrics:
    time_step_max: 4157
    time_step_mean: 3576.9563106796118
    time_step_min: 3246
  date: 2020-10-10_17-31-59
  done: false
  episode_len_mean: 835.945411392405
  episode_reward_max: 274.2020202020201
  episode_reward_mean: 224.22803190129127
  episode_reward_min: 136.17171717171735
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: 7a3190a271cb4384b9e5f48fcc324a7d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 1.0e-05
        entropy: 1.035650108541761
        entropy_coeff: 0.0
        kl: 0.005149299910824213
        model: {}
        policy_loss: -0.00529632278318916
        total_loss: 12.649611609322685
        vf_explained_var: 0.9595790505409241
        vf_loss: 12.65465041569301
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.98918918918919
    gpu_util_percent0: 0.31675675675675674
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.489189189189189
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 5012
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15862355682457221
    mean_env_wait_ms: 1.2146448841474056
    mean_inference_ms: 5.091162992315229
    mean_raw_obs_processing_ms: 0.4238094479855794
  time_since_restore: 219.63431358337402
  time_this_iter_s: 30.83871293067932
  time_total_s: 219.63431358337402
  timers:
    learn_throughput: 6897.287
    learn_time_ms: 23457.341
    sample_throughput: 20682.083
    sample_time_ms: 7822.81
    update_time_ms: 45.333
  timestamp: 1602351119
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: f8bfc_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f8bfc_00000 | RUNNING  | 172.17.0.4:5012 |      7 |          219.634 | 1132544 |  224.228 |              274.202 |              136.172 |            835.945 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f8bfc_00000:
  custom_metrics:
    time_step_max: 4157
    time_step_mean: 3571.948350071736
    time_step_min: 3246
  date: 2020-10-10_17-32-30
  done: false
  episode_len_mean: 831.2693389592124
  episode_reward_max: 274.2020202020201
  episode_reward_mean: 224.83258747815697
  episode_reward_min: 136.17171717171735
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 7a3190a271cb4384b9e5f48fcc324a7d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 1.0e-05
        entropy: 0.9876430800982884
        entropy_coeff: 0.0
        kl: 0.0048613638417529205
        model: {}
        policy_loss: -0.0038391962131884482
        total_loss: 11.079199382237025
        vf_explained_var: 0.973587155342102
        vf_loss: 11.0827956199646
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.8
    gpu_util_percent0: 0.34526315789473677
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.484210526315789
    vram_util_percent0: 0.2046572646769433
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 5012
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1579492335579466
    mean_env_wait_ms: 1.2174116709610454
    mean_inference_ms: 5.041324159215554
    mean_raw_obs_processing_ms: 0.42145660775482524
  time_since_restore: 250.8199179172516
  time_this_iter_s: 31.185604333877563
  time_total_s: 250.8199179172516
  timers:
    learn_throughput: 6896.279
    learn_time_ms: 23460.767
    sample_throughput: 20751.866
    sample_time_ms: 7796.504
    update_time_ms: 44.336
  timestamp: 1602351150
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: f8bfc_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f8bfc_00000 | RUNNING  | 172.17.0.4:5012 |      8 |           250.82 | 1294336 |  224.833 |              274.202 |              136.172 |            831.269 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f8bfc_00000:
  custom_metrics:
    time_step_max: 4157
    time_step_mean: 3570.4929824561405
    time_step_min: 3246
  date: 2020-10-10_17-33-01
  done: false
  episode_len_mean: 823.4706559263522
  episode_reward_max: 274.2020202020201
  episode_reward_mean: 225.47690948611537
  episode_reward_min: 136.17171717171735
  episodes_this_iter: 316
  episodes_total: 1738
  experiment_id: 7a3190a271cb4384b9e5f48fcc324a7d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025000000000000005
        cur_lr: 1.0e-05
        entropy: 0.9545726605824062
        entropy_coeff: 0.0
        kl: 0.00576184327448053
        model: {}
        policy_loss: -0.0032061740538275835
        total_loss: 13.817561626434326
        vf_explained_var: 0.9781784415245056
        vf_loss: 13.820623806544713
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.462162162162166
    gpu_util_percent0: 0.32405405405405396
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.475675675675675
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 5012
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15688975200861519
    mean_env_wait_ms: 1.2225674261992556
    mean_inference_ms: 4.962892874757223
    mean_raw_obs_processing_ms: 0.4179136370047913
  time_since_restore: 281.7865037918091
  time_this_iter_s: 30.966585874557495
  time_total_s: 281.7865037918091
  timers:
    learn_throughput: 6903.102
    learn_time_ms: 23437.579
    sample_throughput: 20800.843
    sample_time_ms: 7778.146
    update_time_ms: 42.834
  timestamp: 1602351181
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: f8bfc_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f8bfc_00000 | RUNNING  | 172.17.0.4:5012 |      9 |          281.787 | 1456128 |  225.477 |              274.202 |              136.172 |            823.471 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f8bfc_00000:
  custom_metrics:
    time_step_max: 4157
    time_step_mean: 3569.3029978586724
    time_step_min: 3229
  date: 2020-10-10_17-33-33
  done: false
  episode_len_mean: 820.4815400843881
  episode_reward_max: 276.77777777777794
  episode_reward_mean: 225.6196777905638
  episode_reward_min: 100.7171717171719
  episodes_this_iter: 158
  episodes_total: 1896
  experiment_id: 7a3190a271cb4384b9e5f48fcc324a7d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025000000000000005
        cur_lr: 1.0e-05
        entropy: 0.9165504659925189
        entropy_coeff: 0.0
        kl: 0.004750620274405394
        model: {}
        policy_loss: -0.0044803082710132
        total_loss: 8.149441310337611
        vf_explained_var: 0.983643114566803
        vf_loss: 8.153802939823695
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.434210526315788
    gpu_util_percent0: 0.3063157894736842
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.494736842105263
    vram_util_percent0: 0.2046572646769433
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 5012
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15646804803507489
    mean_env_wait_ms: 1.224690212992767
    mean_inference_ms: 4.931803812690074
    mean_raw_obs_processing_ms: 0.41648402146131425
  time_since_restore: 313.1291105747223
  time_this_iter_s: 31.342606782913208
  time_total_s: 313.1291105747223
  timers:
    learn_throughput: 6892.697
    learn_time_ms: 23472.959
    sample_throughput: 20888.232
    sample_time_ms: 7745.605
    update_time_ms: 42.453
  timestamp: 1602351213
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: f8bfc_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f8bfc_00000 | RUNNING  | 172.17.0.4:5012 |     10 |          313.129 | 1617920 |   225.62 |              276.778 |              100.717 |            820.482 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f8bfc_00000:
  custom_metrics:
    time_step_max: 4157
    time_step_mean: 3567.0202369200397
    time_step_min: 3229
  date: 2020-10-10_17-34-04
  done: false
  episode_len_mean: 817.7857838364167
  episode_reward_max: 276.77777777777794
  episode_reward_mean: 225.90837292103106
  episode_reward_min: 100.7171717171719
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: 7a3190a271cb4384b9e5f48fcc324a7d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.012500000000000002
        cur_lr: 1.0e-05
        entropy: 0.8845704197883606
        entropy_coeff: 0.0
        kl: 0.004450545879080892
        model: {}
        policy_loss: -0.003589001251384616
        total_loss: 6.514957223619733
        vf_explained_var: 0.9874895811080933
        vf_loss: 6.518490552902222
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.357894736842105
    gpu_util_percent0: 0.37026315789473685
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.494736842105263
    vram_util_percent0: 0.2046572646769433
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 5012
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1560916046231749
    mean_env_wait_ms: 1.2267599758856367
    mean_inference_ms: 4.903950868012113
    mean_raw_obs_processing_ms: 0.41517656271143005
  time_since_restore: 344.2589662075043
  time_this_iter_s: 31.129855632781982
  time_total_s: 344.2589662075043
  timers:
    learn_throughput: 6894.968
    learn_time_ms: 23465.23
    sample_throughput: 21547.518
    sample_time_ms: 7508.614
    update_time_ms: 41.897
  timestamp: 1602351244
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: f8bfc_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f8bfc_00000 | RUNNING  | 172.17.0.4:5012 |     11 |          344.259 | 1779712 |  225.908 |              276.778 |              100.717 |            817.786 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f8bfc_00000:
  custom_metrics:
    time_step_max: 4157
    time_step_mean: 3563.6676633917127
    time_step_min: 3229
  date: 2020-10-10_17-34-35
  done: false
  episode_len_mean: 813.3313634444913
  episode_reward_max: 276.77777777777794
  episode_reward_mean: 226.42863416776459
  episode_reward_min: 100.7171717171719
  episodes_this_iter: 315
  episodes_total: 2369
  experiment_id: 7a3190a271cb4384b9e5f48fcc324a7d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.006250000000000001
        cur_lr: 1.0e-05
        entropy: 0.8480414748191833
        entropy_coeff: 0.0
        kl: 0.004410409169005496
        model: {}
        policy_loss: -0.0027276175138207953
        total_loss: 9.373853410993304
        vf_explained_var: 0.9887224435806274
        vf_loss: 9.376553467341832
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.61315789473684
    gpu_util_percent0: 0.30631578947368415
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.476315789473684
    vram_util_percent0: 0.2046572646769433
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 5012
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15545510366551746
    mean_env_wait_ms: 1.2307008613546706
    mean_inference_ms: 4.857339021075196
    mean_raw_obs_processing_ms: 0.4130697152770339
  time_since_restore: 375.7193486690521
  time_this_iter_s: 31.46038246154785
  time_total_s: 375.7193486690521
  timers:
    learn_throughput: 6887.065
    learn_time_ms: 23492.157
    sample_throughput: 21618.185
    sample_time_ms: 7484.07
    update_time_ms: 40.127
  timestamp: 1602351275
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: f8bfc_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f8bfc_00000 | RUNNING  | 172.17.0.4:5012 |     12 |          375.719 | 1941504 |  226.429 |              276.778 |              100.717 |            813.331 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f8bfc_00000:
  custom_metrics:
    time_step_max: 4157
    time_step_mean: 3561.3096
    time_step_min: 3229
  date: 2020-10-10_17-35-06
  done: false
  episode_len_mean: 811.4303797468355
  episode_reward_max: 276.77777777777794
  episode_reward_mean: 226.72407620508878
  episode_reward_min: 100.7171717171719
  episodes_this_iter: 159
  episodes_total: 2528
  experiment_id: 7a3190a271cb4384b9e5f48fcc324a7d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0031250000000000006
        cur_lr: 1.0e-05
        entropy: 0.8040223036493573
        entropy_coeff: 0.0
        kl: 0.0037234847799741794
        model: {}
        policy_loss: -0.003430925723348212
        total_loss: 5.382291419165475
        vf_explained_var: 0.9906600713729858
        vf_loss: 5.385710750307355
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.124324324324323
    gpu_util_percent0: 0.3613513513513514
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.489189189189189
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 5012
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1551767087718892
    mean_env_wait_ms: 1.2324346626751832
    mean_inference_ms: 4.8370962780476034
    mean_raw_obs_processing_ms: 0.41216013222204434
  time_since_restore: 406.4420847892761
  time_this_iter_s: 30.722736120224
  time_total_s: 406.4420847892761
  timers:
    learn_throughput: 6889.162
    learn_time_ms: 23485.004
    sample_throughput: 21703.249
    sample_time_ms: 7454.736
    update_time_ms: 38.89
  timestamp: 1602351306
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: f8bfc_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f8bfc_00000 | RUNNING  | 172.17.0.4:5012 |     13 |          406.442 | 2103296 |  226.724 |              276.778 |              100.717 |             811.43 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f8bfc_00000:
  custom_metrics:
    time_step_max: 4157
    time_step_mean: 3558.5854025583144
    time_step_min: 3229
  date: 2020-10-10_17-35-37
  done: false
  episode_len_mean: 809.5908413998511
  episode_reward_max: 276.77777777777794
  episode_reward_mean: 227.09389501869023
  episode_reward_min: 100.7171717171719
  episodes_this_iter: 158
  episodes_total: 2686
  experiment_id: 7a3190a271cb4384b9e5f48fcc324a7d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0015625000000000003
        cur_lr: 1.0e-05
        entropy: 0.7891876825264522
        entropy_coeff: 0.0
        kl: 0.0034359586924048407
        model: {}
        policy_loss: -0.003198671925929375
        total_loss: 4.493153538022723
        vf_explained_var: 0.9916778206825256
        vf_loss: 4.496346916471209
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.291891891891893
    gpu_util_percent0: 0.3732432432432433
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.494594594594594
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 5012
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15492306688531893
    mean_env_wait_ms: 1.23409661921337
    mean_inference_ms: 4.818545775883968
    mean_raw_obs_processing_ms: 0.4113035652681148
  time_since_restore: 437.3478500843048
  time_this_iter_s: 30.905765295028687
  time_total_s: 437.3478500843048
  timers:
    learn_throughput: 6896.287
    learn_time_ms: 23460.742
    sample_throughput: 21673.628
    sample_time_ms: 7464.925
    update_time_ms: 37.37
  timestamp: 1602351337
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: f8bfc_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f8bfc_00000 | RUNNING  | 172.17.0.4:5012 |     14 |          437.348 | 2265088 |  227.094 |              276.778 |              100.717 |            809.591 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f8bfc_00000:
  custom_metrics:
    time_step_max: 4157
    time_step_mean: 3552.9182773821635
    time_step_min: 3229
  date: 2020-10-10_17-36-08
  done: false
  episode_len_mean: 806.573731944911
  episode_reward_max: 276.77777777777794
  episode_reward_mean: 227.8234206356477
  episode_reward_min: 100.7171717171719
  episodes_this_iter: 291
  episodes_total: 2977
  experiment_id: 7a3190a271cb4384b9e5f48fcc324a7d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0007812500000000002
        cur_lr: 1.0e-05
        entropy: 0.7685182350022453
        entropy_coeff: 0.0
        kl: 0.0033993622554200037
        model: {}
        policy_loss: -0.0015988632221706212
        total_loss: 5.565674883978708
        vf_explained_var: 0.9930247068405151
        vf_loss: 5.56727089200701
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.818421052631578
    gpu_util_percent0: 0.3410526315789474
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.476315789473684
    vram_util_percent0: 0.2046572646769433
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 5012
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1545163726071719
    mean_env_wait_ms: 1.2371537315443453
    mean_inference_ms: 4.788446362698512
    mean_raw_obs_processing_ms: 0.409932225778926
  time_since_restore: 468.2020859718323
  time_this_iter_s: 30.854235887527466
  time_total_s: 468.2020859718323
  timers:
    learn_throughput: 6903.362
    learn_time_ms: 23436.696
    sample_throughput: 21617.856
    sample_time_ms: 7484.183
    update_time_ms: 34.03
  timestamp: 1602351368
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: f8bfc_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f8bfc_00000 | RUNNING  | 172.17.0.4:5012 |     15 |          468.202 | 2426880 |  227.823 |              276.778 |              100.717 |            806.574 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f8bfc_00000:
  custom_metrics:
    time_step_max: 4157
    time_step_mean: 3551.205938697318
    time_step_min: 3229
  date: 2020-10-10_17-36-39
  done: false
  episode_len_mean: 804.9724683544304
  episode_reward_max: 276.77777777777794
  episode_reward_mean: 228.2297340493543
  episode_reward_min: 100.7171717171719
  episodes_this_iter: 183
  episodes_total: 3160
  experiment_id: 7a3190a271cb4384b9e5f48fcc324a7d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0003906250000000001
        cur_lr: 1.0e-05
        entropy: 0.7189180893557412
        entropy_coeff: 0.0
        kl: 0.003198932091306363
        model: {}
        policy_loss: -0.0036332401900186335
        total_loss: 3.995160290173122
        vf_explained_var: 0.9930302500724792
        vf_loss: 3.9987922736576627
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.591891891891894
    gpu_util_percent0: 0.2518918918918919
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497297297297297
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 5012
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1542828879077917
    mean_env_wait_ms: 1.2387433761905249
    mean_inference_ms: 4.771404432685825
    mean_raw_obs_processing_ms: 0.40913808044512834
  time_since_restore: 499.10194182395935
  time_this_iter_s: 30.899855852127075
  time_total_s: 499.10194182395935
  timers:
    learn_throughput: 6899.927
    learn_time_ms: 23448.365
    sample_throughput: 21579.283
    sample_time_ms: 7497.561
    update_time_ms: 28.858
  timestamp: 1602351399
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: f8bfc_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f8bfc_00000 | RUNNING  | 172.17.0.4:5012 |     16 |          499.102 | 2588672 |   228.23 |              276.778 |              100.717 |            804.972 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f8bfc_00000:
  custom_metrics:
    time_step_max: 4157
    time_step_mean: 3548.2285714285713
    time_step_min: 3229
  date: 2020-10-10_17-37-10
  done: false
  episode_len_mean: 803.7983725135624
  episode_reward_max: 276.77777777777794
  episode_reward_mean: 228.74984930681134
  episode_reward_min: 100.7171717171719
  episodes_this_iter: 158
  episodes_total: 3318
  experiment_id: 7a3190a271cb4384b9e5f48fcc324a7d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.00019531250000000004
        cur_lr: 1.0e-05
        entropy: 0.720745291028704
        entropy_coeff: 0.0
        kl: 0.0032887847129521625
        model: {}
        policy_loss: -0.003221184648542216
        total_loss: 3.1312393631253923
        vf_explained_var: 0.9939590096473694
        vf_loss: 3.1344599383217946
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.748648648648647
    gpu_util_percent0: 0.34297297297297297
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.486486486486487
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 5012
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15410076701690778
    mean_env_wait_ms: 1.2400880211296124
    mean_inference_ms: 4.7579181152478
    mean_raw_obs_processing_ms: 0.40850664282523147
  time_since_restore: 529.9507126808167
  time_this_iter_s: 30.8487708568573
  time_total_s: 529.9507126808167
  timers:
    learn_throughput: 6900.281
    learn_time_ms: 23447.162
    sample_throughput: 21574.951
    sample_time_ms: 7499.067
    update_time_ms: 28.831
  timestamp: 1602351430
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: f8bfc_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f8bfc_00000 | RUNNING  | 172.17.0.4:5012 |     17 |          529.951 | 2750464 |   228.75 |              276.778 |              100.717 |            803.798 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f8bfc_00000:
  custom_metrics:
    time_step_max: 4157
    time_step_mean: 3543.5831435079726
    time_step_min: 3221
  date: 2020-10-10_17-37-41
  done: false
  episode_len_mean: 802.3757062146892
  episode_reward_max: 277.98989898989873
  episode_reward_mean: 229.42963533641503
  episode_reward_min: 100.7171717171719
  episodes_this_iter: 222
  episodes_total: 3540
  experiment_id: 7a3190a271cb4384b9e5f48fcc324a7d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 9.765625000000002e-05
        cur_lr: 1.0e-05
        entropy: 0.7082104853221348
        entropy_coeff: 0.0
        kl: 0.0030144364406753865
        model: {}
        policy_loss: -0.0037207648690257755
        total_loss: 3.457715170724051
        vf_explained_var: 0.9949556589126587
        vf_loss: 3.4614357267107283
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.555263157894732
    gpu_util_percent0: 0.31000000000000005
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4789473684210535
    vram_util_percent0: 0.2046572646769433
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 5012
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15386739876844718
    mean_env_wait_ms: 1.24191321733753
    mean_inference_ms: 4.740235713684227
    mean_raw_obs_processing_ms: 0.4076593891550801
  time_since_restore: 560.7750132083893
  time_this_iter_s: 30.824300527572632
  time_total_s: 560.7750132083893
  timers:
    learn_throughput: 6905.876
    learn_time_ms: 23428.165
    sample_throughput: 21623.805
    sample_time_ms: 7482.124
    update_time_ms: 27.623
  timestamp: 1602351461
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: f8bfc_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f8bfc_00000 | RUNNING  | 172.17.0.4:5012 |     18 |          560.775 | 2912256 |   229.43 |               277.99 |              100.717 |            802.376 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f8bfc_00000:
  custom_metrics:
    time_step_max: 4157
    time_step_mean: 3539.1107863974494
    time_step_min: 3221
  date: 2020-10-10_17-38-12
  done: false
  episode_len_mean: 800.970200421941
  episode_reward_max: 277.98989898989873
  episode_reward_mean: 230.15138729062778
  episode_reward_min: 100.7171717171719
  episodes_this_iter: 252
  episodes_total: 3792
  experiment_id: 7a3190a271cb4384b9e5f48fcc324a7d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 4.882812500000001e-05
        cur_lr: 1.0e-05
        entropy: 0.6687438530581338
        entropy_coeff: 0.0
        kl: 0.0027752666335020748
        model: {}
        policy_loss: -0.003984752210921475
        total_loss: 3.264700327600752
        vf_explained_var: 0.9945142865180969
        vf_loss: 3.268685017313276
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.113513513513514
    gpu_util_percent0: 0.3478378378378378
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.478378378378378
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 5012
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15362293849789188
    mean_env_wait_ms: 1.2438292232247674
    mean_inference_ms: 4.722553222846685
    mean_raw_obs_processing_ms: 0.4068445794127131
  time_since_restore: 591.6060683727264
  time_this_iter_s: 30.831055164337158
  time_total_s: 591.6060683727264
  timers:
    learn_throughput: 6907.105
    learn_time_ms: 23423.995
    sample_throughput: 21650.575
    sample_time_ms: 7472.873
    update_time_ms: 26.641
  timestamp: 1602351492
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: f8bfc_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f8bfc_00000 | RUNNING  | 172.17.0.4:5012 |     19 |          591.606 | 3074048 |  230.151 |               277.99 |              100.717 |             800.97 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f8bfc_00000:
  custom_metrics:
    time_step_max: 4157
    time_step_mean: 3536.3067312595613
    time_step_min: 3221
  date: 2020-10-10_17-38-43
  done: true
  episode_len_mean: 800.0326582278481
  episode_reward_max: 277.98989898989873
  episode_reward_mean: 230.58065464774327
  episode_reward_min: 100.7171717171719
  episodes_this_iter: 158
  episodes_total: 3950
  experiment_id: 7a3190a271cb4384b9e5f48fcc324a7d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 2.4414062500000005e-05
        cur_lr: 1.0e-05
        entropy: 0.6546231252806527
        entropy_coeff: 0.0
        kl: 0.0029033783191282836
        model: {}
        policy_loss: -0.0034258951844614266
        total_loss: 2.642258678163801
        vf_explained_var: 0.994458019733429
        vf_loss: 2.6456845147269115
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.294736842105266
    gpu_util_percent0: 0.42131578947368425
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.484210526315789
    vram_util_percent0: 0.2046572646769433
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 5012
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1534869210750773
    mean_env_wait_ms: 1.2449260094691008
    mean_inference_ms: 4.7122401993056355
    mean_raw_obs_processing_ms: 0.40635671845215265
  time_since_restore: 622.4825134277344
  time_this_iter_s: 30.876445055007935
  time_total_s: 622.4825134277344
  timers:
    learn_throughput: 6922.059
    learn_time_ms: 23373.393
    sample_throughput: 21655.84
    sample_time_ms: 7471.056
    update_time_ms: 25.536
  timestamp: 1602351523
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: f8bfc_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f8bfc_00000 | TERMINATED |       |     20 |          622.483 | 3235840 |  230.581 |               277.99 |              100.717 |            800.033 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f8bfc_00000 | TERMINATED |       |     20 |          622.483 | 3235840 |  230.581 |               277.99 |              100.717 |            800.033 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


