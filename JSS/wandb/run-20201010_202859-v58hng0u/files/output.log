2020-10-10 20:29:01,998	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8266[39m[22m
== Status ==
Memory usage on this node: 32.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_3ca26_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=36715)[0m 2020-10-10 20:29:04,905	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=36743)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36743)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36738)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36738)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36728)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36728)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36699)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36699)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36730)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36730)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36731)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36731)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36760)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36760)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36759)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36759)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36753)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36753)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36748)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36748)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36712)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36712)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36644)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36644)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36665)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36665)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36655)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36655)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36719)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36719)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36736)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36736)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36747)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36747)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36669)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36669)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36739)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36739)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36708)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36708)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36741)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36741)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36718)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36718)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36626)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36626)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36629)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36629)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36717)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36717)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36635)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36635)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36637)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36637)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36716)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36716)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36700)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36700)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36722)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36722)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36724)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36724)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36653)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36653)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36702)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36702)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36707)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36707)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36643)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36643)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36751)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36751)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36660)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36660)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36631)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36631)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36690)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36690)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36661)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36661)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36641)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36641)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36628)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36628)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36627)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36627)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36703)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36703)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36640)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36640)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36701)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36701)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36691)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36691)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36711)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36711)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36632)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36632)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36733)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36733)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36642)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36642)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36633)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36633)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36634)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36634)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36662)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36662)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36709)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36709)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36704)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36704)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36636)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36636)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36645)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36645)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36698)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36698)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36761)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36761)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36638)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36638)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36720)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36720)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36647)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36647)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36692)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36692)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36664)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36664)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36725)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36725)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36706)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36706)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36681)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36681)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36696)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36696)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36713)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36713)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36667)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36667)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36684)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36684)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36745)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36745)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36687)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36687)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36650)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36650)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36762)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36762)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36657)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36657)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36705)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36705)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=36694)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36694)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_3ca26_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-10_20-29-51
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 348505c9e11c4d1eaa9e9167dedebe7e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.184572662625994
        entropy_coeff: 0.00010000000000000002
        kl: 0.004290332651830145
        model: {}
        policy_loss: -0.014887163847950953
        total_loss: 496.40611049107144
        vf_explained_var: 0.5996591448783875
        vf_loss: 496.4202641078404
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.366666666666664
    gpu_util_percent0: 0.3095833333333333
    gpu_util_percent1: 0.00020833333333333335
    gpu_util_percent2: 0.00020833333333333335
    ram_util_percent: 6.314583333333334
    vram_util_percent0: 0.19469839838198313
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 36715
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16802085848199103
    mean_env_wait_ms: 1.1937850388011362
    mean_inference_ms: 5.316682899760109
    mean_raw_obs_processing_ms: 0.44696864392809676
  time_since_restore: 40.547186851501465
  time_this_iter_s: 40.547186851501465
  time_total_s: 40.547186851501465
  timers:
    learn_throughput: 5060.6
    learn_time_ms: 31970.914
    sample_throughput: 19021.158
    sample_time_ms: 8505.896
    update_time_ms: 27.111
  timestamp: 1602361791
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 3ca26_00000
  
== Status ==
Memory usage on this node: 48.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3ca26_00000 | RUNNING  | 172.17.0.4:36715 |      1 |          40.5472 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3ca26_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.565972222222
    time_step_min: 3338
  date: 2020-10-10_20-30-30
  done: false
  episode_len_mean: 890.1487341772151
  episode_reward_max: 260.26262626262616
  episode_reward_mean: 217.57802710650793
  episode_reward_min: 142.98989898989902
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 348505c9e11c4d1eaa9e9167dedebe7e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.1577468173844474
        entropy_coeff: 0.00010000000000000002
        kl: 0.00526529410853982
        model: {}
        policy_loss: -0.015002683570076312
        total_loss: 107.79001726422992
        vf_explained_var: 0.8407418131828308
        vf_loss: 107.8046133858817
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.929787234042553
    gpu_util_percent0: 0.2827659574468085
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.474468085106382
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267445
    vram_util_percent2: 0.0009075233687267445
  pid: 36715
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16475086536743475
    mean_env_wait_ms: 1.1902655155900623
    mean_inference_ms: 5.220734678601932
    mean_raw_obs_processing_ms: 0.44125676766538297
  time_since_restore: 80.27952194213867
  time_this_iter_s: 39.73233509063721
  time_total_s: 80.27952194213867
  timers:
    learn_throughput: 5086.034
    learn_time_ms: 31811.033
    sample_throughput: 19708.113
    sample_time_ms: 8209.411
    update_time_ms: 32.684
  timestamp: 1602361830
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 3ca26_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3ca26_00000 | RUNNING  | 172.17.0.4:36715 |      2 |          80.2795 | 323584 |  217.578 |              260.263 |               142.99 |            890.149 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3ca26_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3613.7399103139014
    time_step_min: 3327
  date: 2020-10-10_20-31-10
  done: false
  episode_len_mean: 887.57805907173
  episode_reward_max: 264.8080808080806
  episode_reward_mean: 218.61290116353385
  episode_reward_min: 142.98989898989902
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 348505c9e11c4d1eaa9e9167dedebe7e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.1472248520169939
        entropy_coeff: 0.00010000000000000002
        kl: 0.0062358824735773465
        model: {}
        policy_loss: -0.017274564718328684
        total_loss: 36.25342014857701
        vf_explained_var: 0.9399197697639465
        vf_loss: 36.270186288016184
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.104347826086954
    gpu_util_percent0: 0.4260869565217392
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.493478260869565
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 36715
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1624480199213214
    mean_env_wait_ms: 1.188226032493961
    mean_inference_ms: 5.127308096659146
    mean_raw_obs_processing_ms: 0.4362896571428927
  time_since_restore: 119.5096127986908
  time_this_iter_s: 39.230090856552124
  time_total_s: 119.5096127986908
  timers:
    learn_throughput: 5093.847
    learn_time_ms: 31762.243
    sample_throughput: 20307.889
    sample_time_ms: 7966.953
    update_time_ms: 30.367
  timestamp: 1602361870
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 3ca26_00000
  
== Status ==
Memory usage on this node: 48.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3ca26_00000 | RUNNING  | 172.17.0.4:36715 |      3 |           119.51 | 485376 |  218.613 |              264.808 |               142.99 |            887.578 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3ca26_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3604.274834437086
    time_step_min: 3254
  date: 2020-10-10_20-31-49
  done: false
  episode_len_mean: 884.9509493670886
  episode_reward_max: 272.9898989898987
  episode_reward_mean: 219.81791011379593
  episode_reward_min: 142.98989898989902
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 348505c9e11c4d1eaa9e9167dedebe7e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.1355815955570765
        entropy_coeff: 0.00010000000000000002
        kl: 0.005972383344279868
        model: {}
        policy_loss: -0.01816182759856539
        total_loss: 23.19033690861293
        vf_explained_var: 0.9584003686904907
        vf_loss: 23.208015169416154
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.636956521739133
    gpu_util_percent0: 0.3215217391304348
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.484782608695651
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 36715
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16077713708344396
    mean_env_wait_ms: 1.1874618088333802
    mean_inference_ms: 5.049068842058449
    mean_raw_obs_processing_ms: 0.43183091446859656
  time_since_restore: 158.54307913780212
  time_this_iter_s: 39.03346633911133
  time_total_s: 158.54307913780212
  timers:
    learn_throughput: 5099.876
    learn_time_ms: 31724.691
    sample_throughput: 20709.07
    sample_time_ms: 7812.615
    update_time_ms: 28.832
  timestamp: 1602361909
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 3ca26_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3ca26_00000 | RUNNING  | 172.17.0.4:36715 |      4 |          158.543 | 647168 |  219.818 |               272.99 |               142.99 |            884.951 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3ca26_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3602.5918635170606
    time_step_min: 3254
  date: 2020-10-10_20-32-28
  done: false
  episode_len_mean: 882.9037974683545
  episode_reward_max: 272.9898989898987
  episode_reward_mean: 220.20585602864065
  episode_reward_min: 142.98989898989902
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 348505c9e11c4d1eaa9e9167dedebe7e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.1161063058035714
        entropy_coeff: 0.00010000000000000002
        kl: 0.006218417348074061
        model: {}
        policy_loss: -0.018155116130531366
        total_loss: 19.613547325134277
        vf_explained_var: 0.9662923812866211
        vf_loss: 19.631191662379674
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.023913043478263
    gpu_util_percent0: 0.31826086956521743
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.495652173913044
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 36715
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15952696044771109
    mean_env_wait_ms: 1.1873738728482772
    mean_inference_ms: 4.984004523966383
    mean_raw_obs_processing_ms: 0.42801065123005194
  time_since_restore: 197.6176598072052
  time_this_iter_s: 39.074580669403076
  time_total_s: 197.6176598072052
  timers:
    learn_throughput: 5101.614
    learn_time_ms: 31713.885
    sample_throughput: 20966.899
    sample_time_ms: 7716.544
    update_time_ms: 27.553
  timestamp: 1602361948
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 3ca26_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3ca26_00000 | RUNNING  | 172.17.0.4:36715 |      5 |          197.618 | 808960 |  220.206 |               272.99 |               142.99 |            882.904 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3ca26_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3589.935294117647
    time_step_min: 3254
  date: 2020-10-10_20-33-07
  done: false
  episode_len_mean: 876.9456106870228
  episode_reward_max: 272.9898989898987
  episode_reward_mean: 222.150059757884
  episode_reward_min: 142.98989898989902
  episodes_this_iter: 258
  episodes_total: 1048
  experiment_id: 348505c9e11c4d1eaa9e9167dedebe7e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.092036443097251
        entropy_coeff: 0.00010000000000000002
        kl: 0.005909352130921823
        model: {}
        policy_loss: -0.017842766338227584
        total_loss: 24.014152118137904
        vf_explained_var: 0.9710985422134399
        vf_loss: 24.03151253291539
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.546666666666667
    gpu_util_percent0: 0.36000000000000004
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.488888888888889
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 36715
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15803633221943086
    mean_env_wait_ms: 1.1890931891273036
    mean_inference_ms: 4.903406637942031
    mean_raw_obs_processing_ms: 0.42315155047206876
  time_since_restore: 236.6438491344452
  time_this_iter_s: 39.02618932723999
  time_total_s: 236.6438491344452
  timers:
    learn_throughput: 5101.648
    learn_time_ms: 31713.673
    sample_throughput: 21192.397
    sample_time_ms: 7634.436
    update_time_ms: 29.374
  timestamp: 1602361987
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 3ca26_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3ca26_00000 | RUNNING  | 172.17.0.4:36715 |      6 |          236.644 | 970752 |   222.15 |               272.99 |               142.99 |            876.946 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3ca26_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3579.605987055016
    time_step_min: 3254
  date: 2020-10-10_20-33-46
  done: false
  episode_len_mean: 872.6344936708861
  episode_reward_max: 276.4747474747472
  episode_reward_mean: 223.75310861782364
  episode_reward_min: 142.98989898989902
  episodes_this_iter: 216
  episodes_total: 1264
  experiment_id: 348505c9e11c4d1eaa9e9167dedebe7e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.1089249849319458
        entropy_coeff: 0.00010000000000000002
        kl: 0.005627510736563376
        model: {}
        policy_loss: -0.01750247649449323
        total_loss: 15.459003380366735
        vf_explained_var: 0.974345326423645
        vf_loss: 15.476053578513008
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.993478260869566
    gpu_util_percent0: 0.36000000000000004
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.489130434782608
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 36715
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15715747529866458
    mean_env_wait_ms: 1.1905201755971129
    mean_inference_ms: 4.853483270659352
    mean_raw_obs_processing_ms: 0.42025183769086005
  time_since_restore: 275.9453685283661
  time_this_iter_s: 39.3015193939209
  time_total_s: 275.9453685283661
  timers:
    learn_throughput: 5095.795
    learn_time_ms: 31750.1
    sample_throughput: 21343.385
    sample_time_ms: 7580.428
    update_time_ms: 28.201
  timestamp: 1602362026
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 3ca26_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3ca26_00000 | RUNNING  | 172.17.0.4:36715 |      7 |          275.945 | 1132544 |  223.753 |              276.475 |               142.99 |            872.634 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3ca26_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3569.2424677187946
    time_step_min: 3254
  date: 2020-10-10_20-34-26
  done: false
  episode_len_mean: 869.3459915611814
  episode_reward_max: 276.4747474747472
  episode_reward_mean: 225.1441418403442
  episode_reward_min: 142.98989898989902
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 348505c9e11c4d1eaa9e9167dedebe7e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.0884097388812475
        entropy_coeff: 0.00010000000000000002
        kl: 0.005754549488691347
        model: {}
        policy_loss: -0.017048894070155387
        total_loss: 12.176557609013148
        vf_explained_var: 0.9774592518806458
        vf_loss: 12.193139621189662
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.92340425531915
    gpu_util_percent0: 0.28723404255319146
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497872340425534
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267445
    vram_util_percent2: 0.0009075233687267445
  pid: 36715
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.156599268806009
    mean_env_wait_ms: 1.1914443615272134
    mean_inference_ms: 4.822592802933879
    mean_raw_obs_processing_ms: 0.41834570432824036
  time_since_restore: 315.6856870651245
  time_this_iter_s: 39.74031853675842
  time_total_s: 315.6856870651245
  timers:
    learn_throughput: 5088.957
    learn_time_ms: 31792.76
    sample_throughput: 21350.761
    sample_time_ms: 7577.809
    update_time_ms: 29.092
  timestamp: 1602362066
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 3ca26_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3ca26_00000 | RUNNING  | 172.17.0.4:36715 |      8 |          315.686 | 1294336 |  225.144 |              276.475 |               142.99 |            869.346 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3ca26_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3562.882087628866
    time_step_min: 3201
  date: 2020-10-10_20-35-06
  done: false
  episode_len_mean: 866.7278481012659
  episode_reward_max: 281.0202020202019
  episode_reward_mean: 226.17392277202387
  episode_reward_min: 142.98989898989902
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 348505c9e11c4d1eaa9e9167dedebe7e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.0753096512385778
        entropy_coeff: 0.00010000000000000002
        kl: 0.0059789559870426145
        model: {}
        policy_loss: -0.018114968369315778
        total_loss: 15.035192966461182
        vf_explained_var: 0.9716295599937439
        vf_loss: 15.052817208426339
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.541304347826088
    gpu_util_percent0: 0.2991304347826087
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.495652173913043
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 36715
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15610789048088217
    mean_env_wait_ms: 1.1922386665192368
    mean_inference_ms: 4.7951436102417055
    mean_raw_obs_processing_ms: 0.41663378510322613
  time_since_restore: 354.8096535205841
  time_this_iter_s: 39.123966455459595
  time_total_s: 354.8096535205841
  timers:
    learn_throughput: 5089.991
    learn_time_ms: 31786.302
    sample_throughput: 21438.21
    sample_time_ms: 7546.899
    update_time_ms: 28.993
  timestamp: 1602362106
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 3ca26_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3ca26_00000 | RUNNING  | 172.17.0.4:36715 |      9 |           354.81 | 1456128 |  226.174 |               281.02 |               142.99 |            866.728 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3ca26_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3557.33761682243
    time_step_min: 3201
  date: 2020-10-10_20-35-45
  done: false
  episode_len_mean: 864.4752873563218
  episode_reward_max: 281.0202020202019
  episode_reward_mean: 226.8884535005223
  episode_reward_min: 142.98989898989902
  episodes_this_iter: 160
  episodes_total: 1740
  experiment_id: 348505c9e11c4d1eaa9e9167dedebe7e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.0470998202051436
        entropy_coeff: 0.00010000000000000002
        kl: 0.005920592096767255
        model: {}
        policy_loss: -0.018603539327159524
        total_loss: 14.001715523856026
        vf_explained_var: 0.9775304794311523
        vf_loss: 14.019832066127233
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.02444444444444
    gpu_util_percent0: 0.2784444444444445
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.502222222222223
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 36715
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15566026071980824
    mean_env_wait_ms: 1.1930201495157988
    mean_inference_ms: 4.7702280225573865
    mean_raw_obs_processing_ms: 0.4150106621130476
  time_since_restore: 393.87602281570435
  time_this_iter_s: 39.06636929512024
  time_total_s: 393.87602281570435
  timers:
    learn_throughput: 5090.339
    learn_time_ms: 31784.133
    sample_throughput: 21529.929
    sample_time_ms: 7514.748
    update_time_ms: 28.36
  timestamp: 1602362145
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 3ca26_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3ca26_00000 | RUNNING  | 172.17.0.4:36715 |     10 |          393.876 | 1617920 |  226.888 |               281.02 |               142.99 |            864.475 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3ca26_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3545.3536102868447
    time_step_min: 3185
  date: 2020-10-10_20-36-24
  done: false
  episode_len_mean: 859.5756097560976
  episode_reward_max: 283.4444444444443
  episode_reward_mean: 228.9576743040156
  episode_reward_min: 142.98989898989902
  episodes_this_iter: 310
  episodes_total: 2050
  experiment_id: 348505c9e11c4d1eaa9e9167dedebe7e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.044018634728023
        entropy_coeff: 0.00010000000000000002
        kl: 0.005389363538207752
        model: {}
        policy_loss: -0.0171132072864566
        total_loss: 17.30039187840053
        vf_explained_var: 0.9777446389198303
        vf_loss: 17.317070688520158
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.345652173913045
    gpu_util_percent0: 0.29043478260869565
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.489130434782608
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 36715
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15494979095722283
    mean_env_wait_ms: 1.1947708823968335
    mean_inference_ms: 4.730854379305164
    mean_raw_obs_processing_ms: 0.4125183961587828
  time_since_restore: 433.05830216407776
  time_this_iter_s: 39.18227934837341
  time_total_s: 433.05830216407776
  timers:
    learn_throughput: 5091.436
    learn_time_ms: 31777.28
    sample_throughput: 21918.191
    sample_time_ms: 7381.631
    update_time_ms: 29.563
  timestamp: 1602362184
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 3ca26_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3ca26_00000 | RUNNING  | 172.17.0.4:36715 |     11 |          433.058 | 1779712 |  228.958 |              283.444 |               142.99 |            859.576 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3ca26_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3540.6955128205127
    time_step_min: 3185
  date: 2020-10-10_20-37-03
  done: false
  episode_len_mean: 857.5773056057866
  episode_reward_max: 283.4444444444443
  episode_reward_mean: 229.83458910990538
  episode_reward_min: 142.98989898989902
  episodes_this_iter: 162
  episodes_total: 2212
  experiment_id: 348505c9e11c4d1eaa9e9167dedebe7e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.03353955915996
        entropy_coeff: 0.00010000000000000002
        kl: 0.0057014519282217535
        model: {}
        policy_loss: -0.018617915455511787
        total_loss: 12.2282806124006
        vf_explained_var: 0.9786781668663025
        vf_loss: 12.24643155506679
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.908695652173915
    gpu_util_percent0: 0.29760869565217385
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.5
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 36715
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15463611148628467
    mean_env_wait_ms: 1.1955136031754503
    mean_inference_ms: 4.713115869628607
    mean_raw_obs_processing_ms: 0.41137479828262763
  time_since_restore: 472.40048122406006
  time_this_iter_s: 39.3421790599823
  time_total_s: 472.40048122406006
  timers:
    learn_throughput: 5086.745
    learn_time_ms: 31806.587
    sample_throughput: 22096.832
    sample_time_ms: 7321.955
    update_time_ms: 28.038
  timestamp: 1602362223
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 3ca26_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3ca26_00000 | RUNNING  | 172.17.0.4:36715 |     12 |            472.4 | 1941504 |  229.835 |              283.444 |               142.99 |            857.577 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3ca26_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3535.464560204953
    time_step_min: 3117
  date: 2020-10-10_20-37-42
  done: false
  episode_len_mean: 855.3004219409282
  episode_reward_max: 293.74747474747466
  episode_reward_mean: 230.7215829177853
  episode_reward_min: 142.98989898989902
  episodes_this_iter: 158
  episodes_total: 2370
  experiment_id: 348505c9e11c4d1eaa9e9167dedebe7e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.0232054506029402
        entropy_coeff: 0.00010000000000000002
        kl: 0.005656714251797114
        model: {}
        policy_loss: -0.01893296533463789
        total_loss: 10.16007239477975
        vf_explained_var: 0.9811720848083496
        vf_loss: 10.17854220526559
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.057777777777776
    gpu_util_percent0: 0.2653333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.5
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 36715
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15435720496288038
    mean_env_wait_ms: 1.1962373777983575
    mean_inference_ms: 4.697485646477877
    mean_raw_obs_processing_ms: 0.41037362634520097
  time_since_restore: 511.2252790927887
  time_this_iter_s: 38.82479786872864
  time_total_s: 511.2252790927887
  timers:
    learn_throughput: 5085.556
    learn_time_ms: 31814.026
    sample_throughput: 22242.542
    sample_time_ms: 7273.989
    update_time_ms: 28.139
  timestamp: 1602362262
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 3ca26_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3ca26_00000 | RUNNING  | 172.17.0.4:36715 |     13 |          511.225 | 2103296 |  230.722 |              293.747 |               142.99 |              855.3 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3ca26_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3528.42206235012
    time_step_min: 3117
  date: 2020-10-10_20-38-21
  done: false
  episode_len_mean: 853.3826086956522
  episode_reward_max: 293.74747474747466
  episode_reward_mean: 231.61572244180925
  episode_reward_min: 142.98989898989902
  episodes_this_iter: 160
  episodes_total: 2530
  experiment_id: 348505c9e11c4d1eaa9e9167dedebe7e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 0.9976314050810677
        entropy_coeff: 0.00010000000000000002
        kl: 0.006070009698825223
        model: {}
        policy_loss: -0.018122249881603887
        total_loss: 10.595218794686454
        vf_explained_var: 0.9810782670974731
        vf_loss: 10.612833499908447
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.286956521739132
    gpu_util_percent0: 0.3189130434782609
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.504347826086956
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 36715
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15410317218733283
    mean_env_wait_ms: 1.1969417839774223
    mean_inference_ms: 4.682832820807794
    mean_raw_obs_processing_ms: 0.4094192533706711
  time_since_restore: 550.1800272464752
  time_this_iter_s: 38.95474815368652
  time_total_s: 550.1800272464752
  timers:
    learn_throughput: 5083.124
    learn_time_ms: 31829.246
    sample_throughput: 22323.213
    sample_time_ms: 7247.702
    update_time_ms: 29.967
  timestamp: 1602362301
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 3ca26_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3ca26_00000 | RUNNING  | 172.17.0.4:36715 |     14 |           550.18 | 2265088 |  231.616 |              293.747 |               142.99 |            853.383 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3ca26_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3517.1133022588742
    time_step_min: 3117
  date: 2020-10-10_20-39-01
  done: false
  episode_len_mean: 850.4394746183883
  episode_reward_max: 293.74747474747466
  episode_reward_mean: 233.1093576876323
  episode_reward_min: 142.98989898989902
  episodes_this_iter: 287
  episodes_total: 2817
  experiment_id: 348505c9e11c4d1eaa9e9167dedebe7e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 0.9807325729301998
        entropy_coeff: 0.00010000000000000002
        kl: 0.005719199111419064
        model: {}
        policy_loss: -0.01626504046414214
        total_loss: 15.310536793300084
        vf_explained_var: 0.9803282618522644
        vf_loss: 15.32632841382708
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.758695652173916
    gpu_util_percent0: 0.24304347826086956
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.489130434782608
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 36715
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15370569151188004
    mean_env_wait_ms: 1.1982412977299415
    mean_inference_ms: 4.659997597021233
    mean_raw_obs_processing_ms: 0.40797742543484417
  time_since_restore: 589.2323668003082
  time_this_iter_s: 39.05233955383301
  time_total_s: 589.2323668003082
  timers:
    learn_throughput: 5080.816
    learn_time_ms: 31843.707
    sample_throughput: 22402.922
    sample_time_ms: 7221.915
    update_time_ms: 37.619
  timestamp: 1602362341
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 3ca26_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3ca26_00000 | RUNNING  | 172.17.0.4:36715 |     15 |          589.232 | 2426880 |  233.109 |              293.747 |               142.99 |            850.439 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3ca26_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3511.3866845998655
    time_step_min: 3117
  date: 2020-10-10_20-39-40
  done: true
  episode_len_mean: 848.6678880746169
  episode_reward_max: 293.74747474747466
  episode_reward_mean: 234.06155828774067
  episode_reward_min: 142.98989898989902
  episodes_this_iter: 185
  episodes_total: 3002
  experiment_id: 348505c9e11c4d1eaa9e9167dedebe7e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 0.9734845587185451
        entropy_coeff: 0.00010000000000000002
        kl: 0.005824278042252574
        model: {}
        policy_loss: -0.018990414815821817
        total_loss: 8.521320479256767
        vf_explained_var: 0.9850918650627136
        vf_loss: 8.539825916290283
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.22608695652174
    gpu_util_percent0: 0.35652173913043483
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.504347826086956
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 36715
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1534877592696426
    mean_env_wait_ms: 1.1989968627847136
    mean_inference_ms: 4.646898355989869
    mean_raw_obs_processing_ms: 0.40714139400200905
  time_since_restore: 628.530403137207
  time_this_iter_s: 39.298036336898804
  time_total_s: 628.530403137207
  timers:
    learn_throughput: 5077.751
    learn_time_ms: 31862.925
    sample_throughput: 22377.252
    sample_time_ms: 7230.2
    update_time_ms: 36.435
  timestamp: 1602362380
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 3ca26_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3ca26_00000 | TERMINATED |       |     16 |           628.53 | 2588672 |  234.062 |              293.747 |               142.99 |            848.668 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3ca26_00000 | TERMINATED |       |     16 |           628.53 | 2588672 |  234.062 |              293.747 |               142.99 |            848.668 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


