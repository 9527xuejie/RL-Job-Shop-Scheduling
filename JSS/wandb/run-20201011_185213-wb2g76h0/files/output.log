2020-10-11 18:52:17,946	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_e3809_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=12114)[0m 2020-10-11 18:52:20,634	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=12007)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12007)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12059)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12059)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12079)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12079)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12066)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12066)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12004)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12004)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12083)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12083)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12064)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12064)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11986)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11986)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12026)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12026)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12071)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12071)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12063)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12063)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12067)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12067)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12113)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12113)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12087)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12087)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12097)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12097)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12012)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12012)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12078)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12078)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12024)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12024)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11999)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11999)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12056)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12056)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12074)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12074)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12105)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12105)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12070)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12070)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11993)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11993)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12076)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12076)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12073)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12073)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12017)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12017)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12050)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12050)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12025)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12025)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12107)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12107)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12058)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12058)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11985)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11985)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11984)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11984)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12081)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12081)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12001)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12001)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12092)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12092)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11989)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11989)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12019)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12019)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12060)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12060)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12052)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12052)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12088)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12088)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12112)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12112)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12061)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12061)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12062)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12062)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12096)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12096)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12118)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12118)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12101)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12101)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12093)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12093)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12116)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12116)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12110)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12110)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12005)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12005)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12075)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12075)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12103)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12103)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12011)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12011)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12021)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12021)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12069)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12069)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11997)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11997)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11998)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11998)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12100)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12100)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11994)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11994)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11990)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11990)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11996)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11996)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12072)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12072)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12084)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12084)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12123)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12123)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12091)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12091)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11992)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11992)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12068)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12068)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12016)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12016)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12065)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12065)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11988)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11988)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12000)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12000)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12086)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12086)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12055)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12055)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11987)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11987)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12054)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12054)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12002)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12002)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12095)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12095)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12013)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12013)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_e3809_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-11_18-52-57
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 397e399b3a4b4abdad5f39073ca2f6e6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.1841148257255554
        entropy_coeff: 0.0001
        kl: 0.004917999496683478
        model: {}
        policy_loss: -0.010679529746994376
        total_loss: 505.8379760742188
        vf_explained_var: 0.542610764503479
        vf_loss: 505.84778747558596
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.74871794871795
    gpu_util_percent0: 0.36974358974358973
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.576923076923076
    vram_util_percent0: 0.09199527377618558
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 12114
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16580506584165125
    mean_env_wait_ms: 1.1685283186259772
    mean_inference_ms: 5.361024391949269
    mean_raw_obs_processing_ms: 0.43733373325744795
  time_since_restore: 31.29965305328369
  time_this_iter_s: 31.29965305328369
  time_total_s: 31.29965305328369
  timers:
    learn_throughput: 7199.621
    learn_time_ms: 22472.293
    sample_throughput: 18590.953
    sample_time_ms: 8702.727
    update_time_ms: 88.559
  timestamp: 1602442377
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: e3809_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e3809_00000 | RUNNING  | 172.17.0.4:12114 |      1 |          31.2997 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e3809_00000:
  custom_metrics:
    time_step_max: 4264
    time_step_mean: 3617.4166666666665
    time_step_min: 3282
  date: 2020-10-11_18-53-27
  done: false
  episode_len_mean: 889.9462025316456
  episode_reward_max: 268.74747474747466
  episode_reward_mean: 217.02710650811898
  episode_reward_min: 119.95959595959577
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 397e399b3a4b4abdad5f39073ca2f6e6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.1527080178260802
        entropy_coeff: 0.0001
        kl: 0.006816077511757612
        model: {}
        policy_loss: -0.012106262380257249
        total_loss: 132.2905502319336
        vf_explained_var: 0.8015682101249695
        vf_loss: 132.30208740234374
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.244444444444447
    gpu_util_percent0: 0.3411111111111111
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.761111111111111
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 12114
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16234505619132217
    mean_env_wait_ms: 1.1650825587434057
    mean_inference_ms: 5.2440343614352445
    mean_raw_obs_processing_ms: 0.4292663738072794
  time_since_restore: 61.670570373535156
  time_this_iter_s: 30.370917320251465
  time_total_s: 61.670570373535156
  timers:
    learn_throughput: 7180.166
    learn_time_ms: 22533.184
    sample_throughput: 19752.846
    sample_time_ms: 8190.82
    update_time_ms: 64.661
  timestamp: 1602442407
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: e3809_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e3809_00000 | RUNNING  | 172.17.0.4:12114 |      2 |          61.6706 | 323584 |  217.027 |              268.747 |               119.96 |            889.946 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e3809_00000:
  custom_metrics:
    time_step_max: 4264
    time_step_mean: 3616.6614349775787
    time_step_min: 3282
  date: 2020-10-11_18-53-57
  done: false
  episode_len_mean: 884.951476793249
  episode_reward_max: 268.74747474747466
  episode_reward_mean: 217.58234241145615
  episode_reward_min: 119.95959595959577
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 397e399b3a4b4abdad5f39073ca2f6e6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.139493715763092
        entropy_coeff: 0.0001
        kl: 0.009640024416148663
        model: {}
        policy_loss: -0.013698664214462041
        total_loss: 61.53116455078125
        vf_explained_var: 0.8929950594902039
        vf_loss: 61.54401397705078
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.57777777777778
    gpu_util_percent0: 0.3461111111111111
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7722222222222235
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 12114
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15987245576012207
    mean_env_wait_ms: 1.164587722028583
    mean_inference_ms: 5.121275687622418
    mean_raw_obs_processing_ms: 0.42251686239535097
  time_since_restore: 91.45302629470825
  time_this_iter_s: 29.782455921173096
  time_total_s: 91.45302629470825
  timers:
    learn_throughput: 7165.952
    learn_time_ms: 22577.878
    sample_throughput: 20739.589
    sample_time_ms: 7801.119
    update_time_ms: 55.141
  timestamp: 1602442437
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: e3809_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e3809_00000 | RUNNING  | 172.17.0.4:12114 |      3 |           91.453 | 485376 |  217.582 |              268.747 |               119.96 |            884.951 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e3809_00000:
  custom_metrics:
    time_step_max: 4264
    time_step_mean: 3608.6258278145697
    time_step_min: 3217
  date: 2020-10-11_18-54-27
  done: false
  episode_len_mean: 881.7689873417721
  episode_reward_max: 278.5959595959589
  episode_reward_mean: 219.19602672292524
  episode_reward_min: 119.95959595959577
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 397e399b3a4b4abdad5f39073ca2f6e6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.1232908010482787
        entropy_coeff: 0.0001
        kl: 0.008994864206761122
        model: {}
        policy_loss: -0.014683684846386314
        total_loss: 43.65212631225586
        vf_explained_var: 0.9194347262382507
        vf_loss: 43.66602249145508
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.31111111111111
    gpu_util_percent0: 0.3425
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.775000000000001
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 12114
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1580291079649694
    mean_env_wait_ms: 1.1650087358527945
    mean_inference_ms: 5.021194826221017
    mean_raw_obs_processing_ms: 0.4170894067740478
  time_since_restore: 121.10047793388367
  time_this_iter_s: 29.647451639175415
  time_total_s: 121.10047793388367
  timers:
    learn_throughput: 7169.495
    learn_time_ms: 22566.723
    sample_throughput: 21258.681
    sample_time_ms: 7610.632
    update_time_ms: 47.874
  timestamp: 1602442467
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: e3809_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e3809_00000 | RUNNING  | 172.17.0.4:12114 |      4 |            121.1 | 647168 |  219.196 |              278.596 |               119.96 |            881.769 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e3809_00000:
  custom_metrics:
    time_step_max: 4264
    time_step_mean: 3599.246719160105
    time_step_min: 3217
  date: 2020-10-11_18-54-56
  done: false
  episode_len_mean: 878.1721518987342
  episode_reward_max: 278.5959595959589
  episode_reward_mean: 220.83320547244577
  episode_reward_min: 119.95959595959577
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 397e399b3a4b4abdad5f39073ca2f6e6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.0947289705276488
        entropy_coeff: 0.0001
        kl: 0.00860484605655074
        model: {}
        policy_loss: -0.015152098797261714
        total_loss: 30.289466094970702
        vf_explained_var: 0.9471577405929565
        vf_loss: 30.30386734008789
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.85
    gpu_util_percent0: 0.37916666666666665
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.769444444444445
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 12114
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1566301533317159
    mean_env_wait_ms: 1.165724961793946
    mean_inference_ms: 4.94173390170013
    mean_raw_obs_processing_ms: 0.4127599020332697
  time_since_restore: 150.53310012817383
  time_this_iter_s: 29.43262219429016
  time_total_s: 150.53310012817383
  timers:
    learn_throughput: 7168.804
    learn_time_ms: 22568.896
    sample_throughput: 21742.927
    sample_time_ms: 7441.133
    update_time_ms: 46.996
  timestamp: 1602442496
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: e3809_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e3809_00000 | RUNNING  | 172.17.0.4:12114 |      5 |          150.533 | 808960 |  220.833 |              278.596 |               119.96 |            878.172 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e3809_00000:
  custom_metrics:
    time_step_max: 4264
    time_step_mean: 3572.980318650422
    time_step_min: 3176
  date: 2020-10-11_18-55-26
  done: false
  episode_len_mean: 870.0584474885844
  episode_reward_max: 284.80808080808083
  episode_reward_mean: 224.50311332503094
  episode_reward_min: 119.95959595959577
  episodes_this_iter: 305
  episodes_total: 1095
  experiment_id: 397e399b3a4b4abdad5f39073ca2f6e6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.0759007573127746
        entropy_coeff: 0.0001
        kl: 0.008370665367692709
        model: {}
        policy_loss: -0.01382834855467081
        total_loss: 32.52159156799316
        vf_explained_var: 0.9592925906181335
        vf_loss: 32.53469066619873
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.28888888888889
    gpu_util_percent0: 0.42083333333333334
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7666666666666666
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 12114
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15477750062397666
    mean_env_wait_ms: 1.1688020658915697
    mean_inference_ms: 4.835280001799335
    mean_raw_obs_processing_ms: 0.4072203209251659
  time_since_restore: 180.02933502197266
  time_this_iter_s: 29.496234893798828
  time_total_s: 180.02933502197266
  timers:
    learn_throughput: 7180.403
    learn_time_ms: 22532.439
    sample_throughput: 21959.616
    sample_time_ms: 7367.706
    update_time_ms: 45.876
  timestamp: 1602442526
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: e3809_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e3809_00000 | RUNNING  | 172.17.0.4:12114 |      6 |          180.029 | 970752 |  224.503 |              284.808 |               119.96 |            870.058 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e3809_00000:
  custom_metrics:
    time_step_max: 4264
    time_step_mean: 3562.7888349514565
    time_step_min: 3176
  date: 2020-10-11_18-55-56
  done: false
  episode_len_mean: 865.2650316455696
  episode_reward_max: 284.80808080808083
  episode_reward_mean: 226.04777202403767
  episode_reward_min: 119.95959595959577
  episodes_this_iter: 169
  episodes_total: 1264
  experiment_id: 397e399b3a4b4abdad5f39073ca2f6e6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.0651807546615601
        entropy_coeff: 0.0001
        kl: 0.008109573926776647
        model: {}
        policy_loss: -0.014530989015474916
        total_loss: 20.533876609802245
        vf_explained_var: 0.9642189145088196
        vf_loss: 20.547703170776366
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.144444444444442
    gpu_util_percent0: 0.39611111111111114
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7861111111111114
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 12114
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15405179814987857
    mean_env_wait_ms: 1.1701885959629739
    mean_inference_ms: 4.792692358215222
    mean_raw_obs_processing_ms: 0.40495663548472993
  time_since_restore: 209.79072618484497
  time_this_iter_s: 29.761391162872314
  time_total_s: 209.79072618484497
  timers:
    learn_throughput: 7174.134
    learn_time_ms: 22552.13
    sample_throughput: 22139.606
    sample_time_ms: 7307.809
    update_time_ms: 44.277
  timestamp: 1602442556
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: e3809_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e3809_00000 | RUNNING  | 172.17.0.4:12114 |      7 |          209.791 | 1132544 |  226.048 |              284.808 |               119.96 |            865.265 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e3809_00000:
  custom_metrics:
    time_step_max: 4264
    time_step_mean: 3554.24175035868
    time_step_min: 3176
  date: 2020-10-11_18-56-26
  done: false
  episode_len_mean: 861.1947960618846
  episode_reward_max: 284.80808080808083
  episode_reward_mean: 227.48772535481376
  episode_reward_min: 119.95959595959577
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 397e399b3a4b4abdad5f39073ca2f6e6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.0406574487686158
        entropy_coeff: 0.0001
        kl: 0.008543166937306524
        model: {}
        policy_loss: -0.01388885620981455
        total_loss: 19.90455379486084
        vf_explained_var: 0.9641757011413574
        vf_loss: 19.917692184448242
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.45277777777778
    gpu_util_percent0: 0.39916666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7805555555555554
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 12114
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15347772100214693
    mean_env_wait_ms: 1.1715203656960016
    mean_inference_ms: 4.758990465627428
    mean_raw_obs_processing_ms: 0.4031715208312057
  time_since_restore: 239.38362884521484
  time_this_iter_s: 29.592902660369873
  time_total_s: 239.38362884521484
  timers:
    learn_throughput: 7181.912
    learn_time_ms: 22527.706
    sample_throughput: 22210.501
    sample_time_ms: 7284.482
    update_time_ms: 42.839
  timestamp: 1602442586
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: e3809_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e3809_00000 | RUNNING  | 172.17.0.4:12114 |      8 |          239.384 | 1294336 |  227.488 |              284.808 |               119.96 |            861.195 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e3809_00000:
  custom_metrics:
    time_step_max: 4264
    time_step_mean: 3545.873067010309
    time_step_min: 3176
  date: 2020-10-11_18-56-56
  done: false
  episode_len_mean: 857.8462025316455
  episode_reward_max: 284.80808080808083
  episode_reward_mean: 228.75351617440208
  episode_reward_min: 119.95959595959577
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 397e399b3a4b4abdad5f39073ca2f6e6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.0099902987480163
        entropy_coeff: 0.0001
        kl: 0.00771885197609663
        model: {}
        policy_loss: -0.014868383202701807
        total_loss: 16.671735191345213
        vf_explained_var: 0.969342052936554
        vf_loss: 16.68593273162842
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.902777777777782
    gpu_util_percent0: 0.40333333333333343
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7805555555555563
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 12114
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1529948782437235
    mean_env_wait_ms: 1.1727521026761392
    mean_inference_ms: 4.730063960481842
    mean_raw_obs_processing_ms: 0.40160510756070167
  time_since_restore: 269.5598385334015
  time_this_iter_s: 30.176209688186646
  time_total_s: 269.5598385334015
  timers:
    learn_throughput: 7169.607
    learn_time_ms: 22566.368
    sample_throughput: 22236.298
    sample_time_ms: 7276.031
    update_time_ms: 42.402
  timestamp: 1602442616
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: e3809_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e3809_00000 | RUNNING  | 172.17.0.4:12114 |      9 |           269.56 | 1456128 |  228.754 |              284.808 |               119.96 |            857.846 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e3809_00000:
  custom_metrics:
    time_step_max: 4264
    time_step_mean: 3531.832136940917
    time_step_min: 3159
  date: 2020-10-11_18-57-26
  done: false
  episode_len_mean: 852.9891245241979
  episode_reward_max: 287.3838383838387
  episode_reward_mean: 231.01979007036087
  episode_reward_min: 119.95959595959577
  episodes_this_iter: 259
  episodes_total: 1839
  experiment_id: 397e399b3a4b4abdad5f39073ca2f6e6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.9737480700016021
        entropy_coeff: 0.0001
        kl: 0.00783180040307343
        model: {}
        policy_loss: -0.013539057364687324
        total_loss: 23.508492088317873
        vf_explained_var: 0.9699012637138367
        vf_loss: 23.521345710754396
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.572222222222223
    gpu_util_percent0: 0.3669444444444444
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.763888888888889
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 12114
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15234042487740104
    mean_env_wait_ms: 1.174804551662901
    mean_inference_ms: 4.690673485085449
    mean_raw_obs_processing_ms: 0.39948633252025995
  time_since_restore: 299.5255310535431
  time_this_iter_s: 29.9656925201416
  time_total_s: 299.5255310535431
  timers:
    learn_throughput: 7164.023
    learn_time_ms: 22583.959
    sample_throughput: 22277.434
    sample_time_ms: 7262.596
    update_time_ms: 41.3
  timestamp: 1602442646
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: e3809_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e3809_00000 | RUNNING  | 172.17.0.4:12114 |     10 |          299.526 | 1617920 |   231.02 |              287.384 |               119.96 |            852.989 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e3809_00000:
  custom_metrics:
    time_step_max: 4264
    time_step_mean: 3523.1377097729514
    time_step_min: 3159
  date: 2020-10-11_18-57-56
  done: false
  episode_len_mean: 849.1124634858812
  episode_reward_max: 287.3838383838387
  episode_reward_mean: 232.63088037138655
  episode_reward_min: 119.95959595959577
  episodes_this_iter: 215
  episodes_total: 2054
  experiment_id: 397e399b3a4b4abdad5f39073ca2f6e6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.9689526498317719
        entropy_coeff: 0.0001
        kl: 0.0073252371046692135
        model: {}
        policy_loss: -0.013649152778089046
        total_loss: 17.32485408782959
        vf_explained_var: 0.9711908102035522
        vf_loss: 17.337867546081544
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.888888888888893
    gpu_util_percent0: 0.36555555555555563
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7722222222222226
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 12114
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15190740028814487
    mean_env_wait_ms: 1.1762496187285572
    mean_inference_ms: 4.664643473901366
    mean_raw_obs_processing_ms: 0.3981362631326222
  time_since_restore: 329.4869866371155
  time_this_iter_s: 29.961455583572388
  time_total_s: 329.4869866371155
  timers:
    learn_throughput: 7153.172
    learn_time_ms: 22618.218
    sample_throughput: 22790.693
    sample_time_ms: 7099.038
    update_time_ms: 34.92
  timestamp: 1602442676
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: e3809_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e3809_00000 | RUNNING  | 172.17.0.4:12114 |     11 |          329.487 | 1779712 |  232.631 |              287.384 |               119.96 |            849.112 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e3809_00000:
  custom_metrics:
    time_step_max: 4264
    time_step_mean: 3514.3374542124543
    time_step_min: 3159
  date: 2020-10-11_18-58-26
  done: false
  episode_len_mean: 846.121609403255
  episode_reward_max: 287.3838383838387
  episode_reward_mean: 233.92289531846478
  episode_reward_min: 119.95959595959577
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 397e399b3a4b4abdad5f39073ca2f6e6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.9541051328182221
        entropy_coeff: 0.0001
        kl: 0.007601859327405691
        model: {}
        policy_loss: -0.014244027761742472
        total_loss: 14.842232513427735
        vf_explained_var: 0.9712217450141907
        vf_loss: 14.855811882019044
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.916666666666668
    gpu_util_percent0: 0.38222222222222224
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7833333333333337
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 12114
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15161971726052578
    mean_env_wait_ms: 1.1772906118823288
    mean_inference_ms: 4.6473014543911315
    mean_raw_obs_processing_ms: 0.39720726303156684
  time_since_restore: 358.91483640670776
  time_this_iter_s: 29.427849769592285
  time_total_s: 358.91483640670776
  timers:
    learn_throughput: 7156.255
    learn_time_ms: 22608.473
    sample_throughput: 23057.354
    sample_time_ms: 7016.937
    update_time_ms: 32.691
  timestamp: 1602442706
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: e3809_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e3809_00000 | RUNNING  | 172.17.0.4:12114 |     12 |          358.915 | 1941504 |  233.923 |              287.384 |               119.96 |            846.122 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e3809_00000:
  custom_metrics:
    time_step_max: 4264
    time_step_mean: 3507.3275053304906
    time_step_min: 3159
  date: 2020-10-11_18-58-55
  done: false
  episode_len_mean: 843.1411715128529
  episode_reward_max: 287.3838383838387
  episode_reward_mean: 235.12043315583128
  episode_reward_min: 119.95959595959577
  episodes_this_iter: 161
  episodes_total: 2373
  experiment_id: 397e399b3a4b4abdad5f39073ca2f6e6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.9289745569229126
        entropy_coeff: 0.0001
        kl: 0.007398022385314107
        model: {}
        policy_loss: -0.014882047101855278
        total_loss: 14.037666606903077
        vf_explained_var: 0.9735888242721558
        vf_loss: 14.051901912689209
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.765714285714285
    gpu_util_percent0: 0.43485714285714283
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.774285714285715
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 12114
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15135686724715114
    mean_env_wait_ms: 1.1783845144168796
    mean_inference_ms: 4.631130967341509
    mean_raw_obs_processing_ms: 0.3963395092275038
  time_since_restore: 388.48759722709656
  time_this_iter_s: 29.572760820388794
  time_total_s: 388.48759722709656
  timers:
    learn_throughput: 7157.171
    learn_time_ms: 22605.579
    sample_throughput: 23117.359
    sample_time_ms: 6998.723
    update_time_ms: 33.066
  timestamp: 1602442735
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: e3809_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e3809_00000 | RUNNING  | 172.17.0.4:12114 |     13 |          388.488 | 2103296 |   235.12 |              287.384 |               119.96 |            843.141 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e3809_00000:
  custom_metrics:
    time_step_max: 4264
    time_step_mean: 3494.4560938682816
    time_step_min: 3157
  date: 2020-10-11_18-59-25
  done: false
  episode_len_mean: 838.3681647940075
  episode_reward_max: 287.6868686868685
  episode_reward_mean: 237.1203609124956
  episode_reward_min: 119.95959595959577
  episodes_this_iter: 297
  episodes_total: 2670
  experiment_id: 397e399b3a4b4abdad5f39073ca2f6e6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.9042334794998169
        entropy_coeff: 0.0001
        kl: 0.007176685938611626
        model: {}
        policy_loss: -0.01298322482034564
        total_loss: 18.53554630279541
        vf_explained_var: 0.9748600721359253
        vf_loss: 18.547901725769044
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.366666666666664
    gpu_util_percent0: 0.32527777777777783
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7722222222222226
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 12114
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15092707792811333
    mean_env_wait_ms: 1.180342373817292
    mean_inference_ms: 4.6049439738858755
    mean_raw_obs_processing_ms: 0.39492955833051746
  time_since_restore: 418.00484442710876
  time_this_iter_s: 29.517247200012207
  time_total_s: 418.00484442710876
  timers:
    learn_throughput: 7156.439
    learn_time_ms: 22607.892
    sample_throughput: 23180.407
    sample_time_ms: 6979.688
    update_time_ms: 33.772
  timestamp: 1602442765
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: e3809_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e3809_00000 | RUNNING  | 172.17.0.4:12114 |     14 |          418.005 | 2265088 |   237.12 |              287.687 |               119.96 |            838.368 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e3809_00000:
  custom_metrics:
    time_step_max: 4264
    time_step_mean: 3488.01171875
    time_step_min: 3157
  date: 2020-10-11_18-59-55
  done: false
  episode_len_mean: 836.1722925457103
  episode_reward_max: 291.777777777778
  episode_reward_mean: 238.0940523377231
  episode_reward_min: 119.95959595959577
  episodes_this_iter: 174
  episodes_total: 2844
  experiment_id: 397e399b3a4b4abdad5f39073ca2f6e6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.8849878549575806
        entropy_coeff: 0.0001
        kl: 0.006577923148870468
        model: {}
        policy_loss: -0.01324602598324418
        total_loss: 13.78815574645996
        vf_explained_var: 0.9754125475883484
        vf_loss: 13.800832366943359
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.961111111111112
    gpu_util_percent0: 0.37527777777777777
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7833333333333345
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 12114
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15070718190900614
    mean_env_wait_ms: 1.1813508532390076
    mean_inference_ms: 4.591342447454449
    mean_raw_obs_processing_ms: 0.39422758422370574
  time_since_restore: 447.6463203430176
  time_this_iter_s: 29.641475915908813
  time_total_s: 447.6463203430176
  timers:
    learn_throughput: 7153.134
    learn_time_ms: 22618.338
    sample_throughput: 23148.125
    sample_time_ms: 6989.421
    update_time_ms: 33.67
  timestamp: 1602442795
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: e3809_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e3809_00000 | RUNNING  | 172.17.0.4:12114 |     15 |          447.646 | 2426880 |  238.094 |              291.778 |               119.96 |            836.172 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e3809_00000:
  custom_metrics:
    time_step_max: 4264
    time_step_mean: 3482.3352387357095
    time_step_min: 3157
  date: 2020-10-11_19-00-24
  done: false
  episode_len_mean: 834.288474350433
  episode_reward_max: 291.777777777778
  episode_reward_mean: 238.9443132187967
  episode_reward_min: 119.95959595959577
  episodes_this_iter: 158
  episodes_total: 3002
  experiment_id: 397e399b3a4b4abdad5f39073ca2f6e6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.8710641145706177
        entropy_coeff: 0.0001
        kl: 0.006570755923166871
        model: {}
        policy_loss: -0.01373581833904609
        total_loss: 12.521038341522218
        vf_explained_var: 0.9755568504333496
        vf_loss: 12.534204292297364
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.066666666666666
    gpu_util_percent0: 0.38916666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7805555555555554
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 12114
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15052334938371806
    mean_env_wait_ms: 1.182216425611126
    mean_inference_ms: 4.579978019009281
    mean_raw_obs_processing_ms: 0.3936156634804434
  time_since_restore: 477.19787669181824
  time_this_iter_s: 29.55155634880066
  time_total_s: 477.19787669181824
  timers:
    learn_throughput: 7147.969
    learn_time_ms: 22634.682
    sample_throughput: 23187.734
    sample_time_ms: 6977.482
    update_time_ms: 31.788
  timestamp: 1602442824
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: e3809_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e3809_00000 | RUNNING  | 172.17.0.4:12114 |     16 |          477.198 | 2588672 |  238.944 |              291.778 |               119.96 |            834.288 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e3809_00000:
  custom_metrics:
    time_step_max: 4264
    time_step_mean: 3475.0545569221067
    time_step_min: 3157
  date: 2020-10-11_19-00-54
  done: false
  episode_len_mean: 832.2644576430134
  episode_reward_max: 291.777777777778
  episode_reward_mean: 240.09685476206255
  episode_reward_min: 119.95959595959577
  episodes_this_iter: 197
  episodes_total: 3199
  experiment_id: 397e399b3a4b4abdad5f39073ca2f6e6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.8405522584915162
        entropy_coeff: 0.0001
        kl: 0.006990063795819878
        model: {}
        policy_loss: -0.013194853393360972
        total_loss: 13.419609355926514
        vf_explained_var: 0.9782096743583679
        vf_loss: 13.43218936920166
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.831428571428567
    gpu_util_percent0: 0.35942857142857143
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.774285714285714
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 12114
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15031928485253254
    mean_env_wait_ms: 1.1833071661386916
    mean_inference_ms: 4.566897725630749
    mean_raw_obs_processing_ms: 0.3929189212831601
  time_since_restore: 506.65759778022766
  time_this_iter_s: 29.459721088409424
  time_total_s: 506.65759778022766
  timers:
    learn_throughput: 7152.749
    learn_time_ms: 22619.556
    sample_throughput: 23216.886
    sample_time_ms: 6968.721
    update_time_ms: 30.126
  timestamp: 1602442854
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: e3809_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e3809_00000 | RUNNING  | 172.17.0.4:12114 |     17 |          506.658 | 2750464 |  240.097 |              291.778 |               119.96 |            832.264 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e3809_00000:
  custom_metrics:
    time_step_max: 4264
    time_step_mean: 3466.5212085996513
    time_step_min: 3157
  date: 2020-10-11_19-01-23
  done: false
  episode_len_mean: 830.2054755043227
  episode_reward_max: 291.777777777778
  episode_reward_mean: 241.34467149885006
  episode_reward_min: 119.95959595959577
  episodes_this_iter: 271
  episodes_total: 3470
  experiment_id: 397e399b3a4b4abdad5f39073ca2f6e6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.8385762095451355
        entropy_coeff: 0.0001
        kl: 0.006472347024828196
        model: {}
        policy_loss: -0.012117055349517614
        total_loss: 14.5984956741333
        vf_explained_var: 0.978177547454834
        vf_loss: 14.6100492477417
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.469444444444445
    gpu_util_percent0: 0.4030555555555556
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.769444444444445
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 12114
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15005114431049252
    mean_env_wait_ms: 1.1845789740863975
    mean_inference_ms: 4.550644836078752
    mean_raw_obs_processing_ms: 0.39204310934881764
  time_since_restore: 536.1043119430542
  time_this_iter_s: 29.446714162826538
  time_total_s: 536.1043119430542
  timers:
    learn_throughput: 7151.903
    learn_time_ms: 22622.23
    sample_throughput: 23266.789
    sample_time_ms: 6953.774
    update_time_ms: 29.632
  timestamp: 1602442883
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: e3809_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e3809_00000 | RUNNING  | 172.17.0.4:12114 |     18 |          536.104 | 2912256 |  241.345 |              291.778 |               119.96 |            830.205 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e3809_00000:
  custom_metrics:
    time_step_max: 4264
    time_step_mean: 3461.2457016084304
    time_step_min: 3148
  date: 2020-10-11_19-01-53
  done: false
  episode_len_mean: 829.0487066593286
  episode_reward_max: 291.777777777778
  episode_reward_mean: 242.10728362324392
  episode_reward_min: 119.95959595959577
  episodes_this_iter: 164
  episodes_total: 3634
  experiment_id: 397e399b3a4b4abdad5f39073ca2f6e6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.8289688408374787
        entropy_coeff: 0.0001
        kl: 0.006461284589022398
        model: {}
        policy_loss: -0.014005647134035825
        total_loss: 9.973568439483643
        vf_explained_var: 0.980167031288147
        vf_loss: 9.987010669708251
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.97222222222222
    gpu_util_percent0: 0.3847222222222222
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7777777777777777
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 12114
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14991053897386084
    mean_env_wait_ms: 1.185305499586016
    mean_inference_ms: 4.541854730449529
    mean_raw_obs_processing_ms: 0.39157653089194994
  time_since_restore: 565.7951860427856
  time_this_iter_s: 29.690874099731445
  time_total_s: 565.7951860427856
  timers:
    learn_throughput: 7162.941
    learn_time_ms: 22587.372
    sample_throughput: 23334.687
    sample_time_ms: 6933.541
    update_time_ms: 29.542
  timestamp: 1602442913
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: e3809_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e3809_00000 | RUNNING  | 172.17.0.4:12114 |     19 |          565.795 | 3074048 |  242.107 |              291.778 |               119.96 |            829.049 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e3809_00000:
  custom_metrics:
    time_step_max: 4264
    time_step_mean: 3457.132837407014
    time_step_min: 3148
  date: 2020-10-11_19-02-23
  done: false
  episode_len_mean: 828.0261075949367
  episode_reward_max: 291.9292929292927
  episode_reward_mean: 242.7260660401482
  episode_reward_min: 119.95959595959577
  episodes_this_iter: 158
  episodes_total: 3792
  experiment_id: 397e399b3a4b4abdad5f39073ca2f6e6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.8085484802722931
        entropy_coeff: 0.0001
        kl: 0.006762820947915316
        model: {}
        policy_loss: -0.013417985104024411
        total_loss: 10.215676021575927
        vf_explained_var: 0.9797428250312805
        vf_loss: 10.228498649597167
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.319999999999997
    gpu_util_percent0: 0.348
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7942857142857145
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 12114
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14978141637730552
    mean_env_wait_ms: 1.1859642426360892
    mean_inference_ms: 4.533759577668097
    mean_raw_obs_processing_ms: 0.39113454521053903
  time_since_restore: 595.062586069107
  time_this_iter_s: 29.26740002632141
  time_total_s: 595.062586069107
  timers:
    learn_throughput: 7173.896
    learn_time_ms: 22552.879
    sample_throughput: 23459.224
    sample_time_ms: 6896.733
    update_time_ms: 29.89
  timestamp: 1602442943
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: e3809_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e3809_00000 | RUNNING  | 172.17.0.4:12114 |     20 |          595.063 | 3235840 |  242.726 |              291.929 |               119.96 |            828.026 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e3809_00000:
  custom_metrics:
    time_step_max: 4264
    time_step_mean: 3449.796576531878
    time_step_min: 3102
  date: 2020-10-11_19-02-52
  done: true
  episode_len_mean: 826.1335304262134
  episode_reward_max: 296.0202020202016
  episode_reward_mean: 243.79704659305537
  episode_reward_min: 119.95959595959577
  episodes_this_iter: 267
  episodes_total: 4059
  experiment_id: 397e399b3a4b4abdad5f39073ca2f6e6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.7875589549541473
        entropy_coeff: 0.0001
        kl: 0.00667554372921586
        model: {}
        policy_loss: -0.012445284612476825
        total_loss: 16.451650047302245
        vf_explained_var: 0.9765976071357727
        vf_loss: 16.463505935668945
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.238888888888894
    gpu_util_percent0: 0.41305555555555556
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7666666666666675
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 12114
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14958395128317584
    mean_env_wait_ms: 1.1870712488579755
    mean_inference_ms: 4.521278791365636
    mean_raw_obs_processing_ms: 0.3904646226343669
  time_since_restore: 624.734792470932
  time_this_iter_s: 29.67220640182495
  time_total_s: 624.734792470932
  timers:
    learn_throughput: 7178.789
    learn_time_ms: 22537.507
    sample_throughput: 23515.174
    sample_time_ms: 6880.323
    update_time_ms: 31.984
  timestamp: 1602442972
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: e3809_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e3809_00000 | TERMINATED |       |     21 |          624.735 | 3397632 |  243.797 |               296.02 |               119.96 |            826.134 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e3809_00000 | TERMINATED |       |     21 |          624.735 | 3397632 |  243.797 |               296.02 |               119.96 |            826.134 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


