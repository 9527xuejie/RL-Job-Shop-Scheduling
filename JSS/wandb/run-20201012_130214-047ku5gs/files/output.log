2020-10-12 13:02:17,820	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_28e47_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=56863)[0m 2020-10-12 13:02:20,596	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=56835)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56835)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56877)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56877)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56885)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56885)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56848)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56848)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56834)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56834)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56841)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56841)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56838)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56838)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56869)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56869)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56865)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56865)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56879)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56879)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56881)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56881)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56859)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56859)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56772)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56772)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56856)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56856)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56788)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56788)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56843)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56843)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56874)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56874)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56873)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56873)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56866)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56866)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56824)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56824)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56761)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56761)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56757)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56757)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56854)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56854)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56759)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56759)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56769)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56769)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56839)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56839)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56789)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56789)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56782)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56782)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56851)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56851)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56758)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56758)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56837)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56837)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56764)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56764)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56771)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56771)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56767)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56767)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56827)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56827)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56850)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56850)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56765)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56765)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56836)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56836)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56795)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56795)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56760)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56760)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56817)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56817)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56794)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56794)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56858)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56858)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56775)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56775)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56822)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56822)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56831)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56831)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56888)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56888)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56815)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56815)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56828)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56828)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56756)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56756)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56868)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56868)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56791)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56791)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56846)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56846)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56830)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56830)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56826)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56826)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56852)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56852)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56773)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56773)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56870)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56870)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56770)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56770)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56776)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56776)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56829)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56829)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56784)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56784)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56862)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56862)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56781)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56781)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56819)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56819)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56833)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56833)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56825)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56825)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56766)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56766)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56860)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56860)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56871)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56871)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56832)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56832)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56840)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56840)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56777)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56777)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56847)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56847)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56785)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56785)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56774)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56774)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56778)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56778)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56842)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56842)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=56763)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=56763)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_28e47_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3561.048780487805
    time_step_min: 3288
  date: 2020-10-12_13-02-53
  done: false
  episode_len_mean: 897.367088607595
  episode_reward_max: 273.50505050505103
  episode_reward_mean: 205.7902442142946
  episode_reward_min: 128.35353535353502
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: b2124891260f4214b9ee1feca592c995
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1782870590686798
        entropy_coeff: 0.0005000000000000001
        kl: 0.007015097692298393
        model: {}
        policy_loss: -0.008879863986900697
        total_loss: 417.51466115315753
        vf_explained_var: 0.5535116195678711
        vf_loss: 417.5227355957031
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.75588235294118
    gpu_util_percent0: 0.3305882352941177
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5529411764705885
    vram_util_percent0: 0.0862288503463045
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56863
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1697268284335111
    mean_env_wait_ms: 1.176014146748867
    mean_inference_ms: 5.616144732068666
    mean_raw_obs_processing_ms: 0.45216618956294696
  time_since_restore: 27.897011518478394
  time_this_iter_s: 27.897011518478394
  time_total_s: 27.897011518478394
  timers:
    learn_throughput: 8543.23
    learn_time_ms: 18938.035
    sample_throughput: 18215.35
    sample_time_ms: 8882.179
    update_time_ms: 26.702
  timestamp: 1602507773
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 28e47_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_28e47_00000 | RUNNING  | 172.17.0.4:56863 |      1 |           27.897 | 161792 |   205.79 |              273.505 |              128.354 |            897.367 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_28e47_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3587.8256227758006
    time_step_min: 3288
  date: 2020-10-12_13-03-20
  done: false
  episode_len_mean: 897.5886075949367
  episode_reward_max: 273.50505050505103
  episode_reward_mean: 204.7358713719471
  episode_reward_min: 128.35353535353502
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: b2124891260f4214b9ee1feca592c995
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1491195062796276
        entropy_coeff: 0.0005000000000000001
        kl: 0.008500338182784617
        model: {}
        policy_loss: -0.010485470003914088
        total_loss: 106.73909568786621
        vf_explained_var: 0.818848192691803
        vf_loss: 106.7484556833903
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.966666666666665
    gpu_util_percent0: 0.34363636363636363
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7515151515151515
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56863
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16511017655101948
    mean_env_wait_ms: 1.1692837868671886
    mean_inference_ms: 5.412249574928946
    mean_raw_obs_processing_ms: 0.4413235985365841
  time_since_restore: 54.499075412750244
  time_this_iter_s: 26.60206389427185
  time_total_s: 54.499075412750244
  timers:
    learn_throughput: 8575.0
    learn_time_ms: 18867.872
    sample_throughput: 19568.331
    sample_time_ms: 8268.053
    update_time_ms: 33.318
  timestamp: 1602507800
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 28e47_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_28e47_00000 | RUNNING  | 172.17.0.4:56863 |      2 |          54.4991 | 323584 |  204.736 |              273.505 |              128.354 |            897.589 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_28e47_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3567.8063781321184
    time_step_min: 3238
  date: 2020-10-12_13-03-46
  done: false
  episode_len_mean: 893.0337552742616
  episode_reward_max: 273.50505050505103
  episode_reward_mean: 206.47046413502085
  episode_reward_min: 128.35353535353502
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: b2124891260f4214b9ee1feca592c995
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1356079280376434
        entropy_coeff: 0.0005000000000000001
        kl: 0.010122421740864715
        model: {}
        policy_loss: -0.01226654858328402
        total_loss: 45.434102058410645
        vf_explained_var: 0.906123161315918
        vf_loss: 45.44491195678711
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.909677419354836
    gpu_util_percent0: 0.3325806451612903
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322573
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56863
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1620751737899552
    mean_env_wait_ms: 1.166819267197093
    mean_inference_ms: 5.252808141155886
    mean_raw_obs_processing_ms: 0.43321753584692074
  time_since_restore: 80.56479620933533
  time_this_iter_s: 26.065720796585083
  time_total_s: 80.56479620933533
  timers:
    learn_throughput: 8598.241
    learn_time_ms: 18816.872
    sample_throughput: 20382.413
    sample_time_ms: 7937.824
    update_time_ms: 31.093
  timestamp: 1602507826
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 28e47_00000
  
== Status ==
Memory usage on this node: 28.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_28e47_00000 | RUNNING  | 172.17.0.4:56863 |      3 |          80.5648 | 485376 |   206.47 |              273.505 |              128.354 |            893.034 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_28e47_00000:
  custom_metrics:
    time_step_max: 4129
    time_step_mean: 3557.4003350083754
    time_step_min: 3238
  date: 2020-10-12_13-04-12
  done: false
  episode_len_mean: 891.6044303797469
  episode_reward_max: 273.50505050505103
  episode_reward_mean: 207.6815464774323
  episode_reward_min: 121.68686868686854
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: b2124891260f4214b9ee1feca592c995
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1216794153054555
        entropy_coeff: 0.0005000000000000001
        kl: 0.012428985831017295
        model: {}
        policy_loss: -0.012654943314070502
        total_loss: 36.42785835266113
        vf_explained_var: 0.9228587746620178
        vf_loss: 36.438588778177895
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.699999999999996
    gpu_util_percent0: 0.32
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.771875
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56863
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15993939724808276
    mean_env_wait_ms: 1.1655753878448298
    mean_inference_ms: 5.13328933582891
    mean_raw_obs_processing_ms: 0.42684660742335184
  time_since_restore: 106.64495706558228
  time_this_iter_s: 26.08016085624695
  time_total_s: 106.64495706558228
  timers:
    learn_throughput: 8576.576
    learn_time_ms: 18864.404
    sample_throughput: 21002.4
    sample_time_ms: 7703.5
    update_time_ms: 28.264
  timestamp: 1602507852
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 28e47_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_28e47_00000 | RUNNING  | 172.17.0.4:56863 |      4 |          106.645 | 647168 |  207.682 |              273.505 |              121.687 |            891.604 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_28e47_00000:
  custom_metrics:
    time_step_max: 4129
    time_step_mean: 3544.8834437086093
    time_step_min: 3238
  date: 2020-10-12_13-04-38
  done: false
  episode_len_mean: 890.340506329114
  episode_reward_max: 273.50505050505103
  episode_reward_mean: 210.23615905894366
  episode_reward_min: 121.68686868686854
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: b2124891260f4214b9ee1feca592c995
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.093275894721349
        entropy_coeff: 0.0005000000000000001
        kl: 0.010155414774393043
        model: {}
        policy_loss: -0.014055442259026071
        total_loss: 28.660432656606037
        vf_explained_var: 0.9349424242973328
        vf_loss: 28.67300319671631
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.361290322580647
    gpu_util_percent0: 0.3783870967741935
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322577
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56863
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1583898649246188
    mean_env_wait_ms: 1.1649471232459359
    mean_inference_ms: 5.0416267222852325
    mean_raw_obs_processing_ms: 0.42176641482110294
  time_since_restore: 132.45448184013367
  time_this_iter_s: 25.80952477455139
  time_total_s: 132.45448184013367
  timers:
    learn_throughput: 8587.866
    learn_time_ms: 18839.604
    sample_throughput: 21398.898
    sample_time_ms: 7560.763
    update_time_ms: 28.161
  timestamp: 1602507878
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 28e47_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_28e47_00000 | RUNNING  | 172.17.0.4:56863 |      5 |          132.454 | 808960 |  210.236 |              273.505 |              121.687 |            890.341 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_28e47_00000:
  custom_metrics:
    time_step_max: 4129
    time_step_mean: 3531.05981112277
    time_step_min: 3193
  date: 2020-10-12_13-05-04
  done: false
  episode_len_mean: 885.2368421052631
  episode_reward_max: 273.50505050505103
  episode_reward_mean: 212.7505418558048
  episode_reward_min: 121.68686868686854
  episodes_this_iter: 198
  episodes_total: 988
  experiment_id: b2124891260f4214b9ee1feca592c995
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0417915781339009
        entropy_coeff: 0.0005000000000000001
        kl: 0.010881505518530806
        model: {}
        policy_loss: -0.013679537267307751
        total_loss: 27.896196365356445
        vf_explained_var: 0.9544363617897034
        vf_loss: 27.908219655354817
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.806451612903228
    gpu_util_percent0: 0.36645161290322587
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7548387096774185
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56863
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15693948537608463
    mean_env_wait_ms: 1.1658510531620465
    mean_inference_ms: 4.9542717081841605
    mean_raw_obs_processing_ms: 0.41676251644117634
  time_since_restore: 158.4363272190094
  time_this_iter_s: 25.981845378875732
  time_total_s: 158.4363272190094
  timers:
    learn_throughput: 8585.401
    learn_time_ms: 18845.014
    sample_throughput: 21649.877
    sample_time_ms: 7473.114
    update_time_ms: 27.013
  timestamp: 1602507904
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 28e47_00000
  
== Status ==
Memory usage on this node: 28.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_28e47_00000 | RUNNING  | 172.17.0.4:56863 |      6 |          158.436 | 970752 |  212.751 |              273.505 |              121.687 |            885.237 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_28e47_00000:
  custom_metrics:
    time_step_max: 4129
    time_step_mean: 3510.677786818552
    time_step_min: 3179
  date: 2020-10-12_13-05-30
  done: false
  episode_len_mean: 877.7879746835443
  episode_reward_max: 273.50505050505103
  episode_reward_mean: 215.9020825342026
  episode_reward_min: 121.68686868686854
  episodes_this_iter: 276
  episodes_total: 1264
  experiment_id: b2124891260f4214b9ee1feca592c995
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.063179651896159
        entropy_coeff: 0.0005000000000000001
        kl: 0.009490801487118006
        model: {}
        policy_loss: -0.013579409115360855
        total_loss: 23.54713201522827
        vf_explained_var: 0.9591490626335144
        vf_loss: 23.55934476852417
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.187096774193552
    gpu_util_percent0: 0.37774193548387097
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7612903225806447
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56863
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15551511564424814
    mean_env_wait_ms: 1.167400441949277
    mean_inference_ms: 4.867069241014814
    mean_raw_obs_processing_ms: 0.4119982862401177
  time_since_restore: 184.2303318977356
  time_this_iter_s: 25.794004678726196
  time_total_s: 184.2303318977356
  timers:
    learn_throughput: 8586.228
    learn_time_ms: 18843.2
    sample_throughput: 21894.158
    sample_time_ms: 7389.734
    update_time_ms: 25.954
  timestamp: 1602507930
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 28e47_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_28e47_00000 | RUNNING  | 172.17.0.4:56863 |      7 |           184.23 | 1132544 |  215.902 |              273.505 |              121.687 |            877.788 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_28e47_00000:
  custom_metrics:
    time_step_max: 4129
    time_step_mean: 3498.6964671953856
    time_step_min: 3179
  date: 2020-10-12_13-05-56
  done: false
  episode_len_mean: 874.4662447257384
  episode_reward_max: 273.50505050505103
  episode_reward_mean: 217.0389123300514
  episode_reward_min: 121.68686868686854
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: b2124891260f4214b9ee1feca592c995
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0327588319778442
        entropy_coeff: 0.0005000000000000001
        kl: 0.010183676534021894
        model: {}
        policy_loss: -0.01289736533847948
        total_loss: 19.030736605326336
        vf_explained_var: 0.9623994827270508
        vf_loss: 19.04211409886678
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.693749999999998
    gpu_util_percent0: 0.36375
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7718750000000005
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56863
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1548740111764799
    mean_env_wait_ms: 1.1681744724767913
    mean_inference_ms: 4.828264906214805
    mean_raw_obs_processing_ms: 0.4098155001928072
  time_since_restore: 209.93966913223267
  time_this_iter_s: 25.70933723449707
  time_total_s: 209.93966913223267
  timers:
    learn_throughput: 8593.308
    learn_time_ms: 18827.673
    sample_throughput: 22091.579
    sample_time_ms: 7323.695
    update_time_ms: 24.737
  timestamp: 1602507956
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 28e47_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_28e47_00000 | RUNNING  | 172.17.0.4:56863 |      8 |           209.94 | 1294336 |  217.039 |              273.505 |              121.687 |            874.466 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_28e47_00000:
  custom_metrics:
    time_step_max: 4129
    time_step_mean: 3491.126213592233
    time_step_min: 3164
  date: 2020-10-12_13-06-22
  done: false
  episode_len_mean: 870.1759493670886
  episode_reward_max: 273.50505050505103
  episode_reward_mean: 218.1968418360822
  episode_reward_min: 121.68686868686854
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: b2124891260f4214b9ee1feca592c995
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0174057682355244
        entropy_coeff: 0.0005000000000000001
        kl: 0.008495178073644638
        model: {}
        policy_loss: -0.014782088573459381
        total_loss: 20.93352810541789
        vf_explained_var: 0.9572171568870544
        vf_loss: 20.947120507558186
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.92258064516129
    gpu_util_percent0: 0.32838709677419353
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.770967741935483
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56863
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15431615746511043
    mean_env_wait_ms: 1.1691127856635612
    mean_inference_ms: 4.794287351237139
    mean_raw_obs_processing_ms: 0.4078657795803801
  time_since_restore: 235.88616228103638
  time_this_iter_s: 25.94649314880371
  time_total_s: 235.88616228103638
  timers:
    learn_throughput: 8589.055
    learn_time_ms: 18836.997
    sample_throughput: 22214.631
    sample_time_ms: 7283.128
    update_time_ms: 24.675
  timestamp: 1602507982
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 28e47_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_28e47_00000 | RUNNING  | 172.17.0.4:56863 |      9 |          235.886 | 1456128 |  218.197 |              273.505 |              121.687 |            870.176 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_28e47_00000:
  custom_metrics:
    time_step_max: 4129
    time_step_mean: 3480.5858644859813
    time_step_min: 3164
  date: 2020-10-12_13-06-48
  done: false
  episode_len_mean: 865.5861476817402
  episode_reward_max: 273.50505050505103
  episode_reward_mean: 219.8855989777568
  episode_reward_min: 121.68686868686854
  episodes_this_iter: 167
  episodes_total: 1747
  experiment_id: b2124891260f4214b9ee1feca592c995
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9728623678286871
        entropy_coeff: 0.0005000000000000001
        kl: 0.010040685534477234
        model: {}
        policy_loss: -0.01270879537332803
        total_loss: 16.9856014251709
        vf_explained_var: 0.9669668078422546
        vf_loss: 16.996788024902344
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.280645161290323
    gpu_util_percent0: 0.3509677419354839
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322577
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56863
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15379804020884819
    mean_env_wait_ms: 1.1702483446591312
    mean_inference_ms: 4.76257571083422
    mean_raw_obs_processing_ms: 0.40600599172264695
  time_since_restore: 261.7367296218872
  time_this_iter_s: 25.85056734085083
  time_total_s: 261.7367296218872
  timers:
    learn_throughput: 8587.468
    learn_time_ms: 18840.477
    sample_throughput: 22330.933
    sample_time_ms: 7245.197
    update_time_ms: 24.203
  timestamp: 1602508008
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 28e47_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_28e47_00000 | RUNNING  | 172.17.0.4:56863 |     10 |          261.737 | 1617920 |  219.886 |              273.505 |              121.687 |            865.586 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_28e47_00000:
  custom_metrics:
    time_step_max: 4129
    time_step_mean: 3463.4774193548387
    time_step_min: 3157
  date: 2020-10-12_13-07-14
  done: false
  episode_len_mean: 857.0868292682927
  episode_reward_max: 280.47474747474735
  episode_reward_mean: 222.37932988420778
  episode_reward_min: 121.68686868686854
  episodes_this_iter: 303
  episodes_total: 2050
  experiment_id: b2124891260f4214b9ee1feca592c995
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9602140337228775
        entropy_coeff: 0.0005000000000000001
        kl: 0.008206206606701016
        model: {}
        policy_loss: -0.011960915561454991
        total_loss: 20.725976785024006
        vf_explained_var: 0.9694435000419617
        vf_loss: 20.736776034037273
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.848387096774196
    gpu_util_percent0: 0.3712903225806452
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.761290322580645
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56863
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15302446624676533
    mean_env_wait_ms: 1.1726988348181377
    mean_inference_ms: 4.715085996591123
    mean_raw_obs_processing_ms: 0.40331260714464634
  time_since_restore: 287.5226502418518
  time_this_iter_s: 25.7859206199646
  time_total_s: 287.5226502418518
  timers:
    learn_throughput: 8590.749
    learn_time_ms: 18833.281
    sample_throughput: 22976.799
    sample_time_ms: 7041.538
    update_time_ms: 23.452
  timestamp: 1602508034
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 28e47_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_28e47_00000 | RUNNING  | 172.17.0.4:56863 |     11 |          287.523 | 1779712 |  222.379 |              280.475 |              121.687 |            857.087 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_28e47_00000:
  custom_metrics:
    time_step_max: 4129
    time_step_mean: 3455.7184198438217
    time_step_min: 3065
  date: 2020-10-12_13-07-40
  done: false
  episode_len_mean: 853.0524412296564
  episode_reward_max: 282.8989898989899
  episode_reward_mean: 223.6667716952526
  episode_reward_min: 121.68686868686854
  episodes_this_iter: 162
  episodes_total: 2212
  experiment_id: b2124891260f4214b9ee1feca592c995
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9489618092775345
        entropy_coeff: 0.0005000000000000001
        kl: 0.009340218656385938
        model: {}
        policy_loss: -0.012813029791383693
        total_loss: 13.610804637273153
        vf_explained_var: 0.9708378314971924
        vf_loss: 13.62222417195638
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.012903225806458
    gpu_util_percent0: 0.39741935483870955
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7677419354838704
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56863
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1526768062050635
    mean_env_wait_ms: 1.1739195948962453
    mean_inference_ms: 4.694116749682869
    mean_raw_obs_processing_ms: 0.40211159285641096
  time_since_restore: 313.314151763916
  time_this_iter_s: 25.79150152206421
  time_total_s: 313.314151763916
  timers:
    learn_throughput: 8584.811
    learn_time_ms: 18846.31
    sample_throughput: 23266.523
    sample_time_ms: 6953.854
    update_time_ms: 21.864
  timestamp: 1602508060
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 28e47_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_28e47_00000 | RUNNING  | 172.17.0.4:56863 |     12 |          313.314 | 1941504 |  223.667 |              282.899 |              121.687 |            853.052 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_28e47_00000:
  custom_metrics:
    time_step_max: 4129
    time_step_mean: 3449.0312633832978
    time_step_min: 3065
  date: 2020-10-12_13-08-05
  done: false
  episode_len_mean: 849.6168776371308
  episode_reward_max: 282.8989898989899
  episode_reward_mean: 224.8443293696457
  episode_reward_min: 121.68686868686854
  episodes_this_iter: 158
  episodes_total: 2370
  experiment_id: b2124891260f4214b9ee1feca592c995
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9358962376912435
        entropy_coeff: 0.0005000000000000001
        kl: 0.009110118184859553
        model: {}
        policy_loss: -0.014057660242542624
        total_loss: 12.233402808507284
        vf_explained_var: 0.9716771245002747
        vf_loss: 12.246106068293253
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.84193548387097
    gpu_util_percent0: 0.33774193548387094
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56863
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15236871091833
    mean_env_wait_ms: 1.1751299834791602
    mean_inference_ms: 4.6752963280788595
    mean_raw_obs_processing_ms: 0.4010342656303068
  time_since_restore: 338.9723103046417
  time_this_iter_s: 25.658158540725708
  time_total_s: 338.9723103046417
  timers:
    learn_throughput: 8584.296
    learn_time_ms: 18847.439
    sample_throughput: 23407.557
    sample_time_ms: 6911.956
    update_time_ms: 21.088
  timestamp: 1602508085
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 28e47_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_28e47_00000 | RUNNING  | 172.17.0.4:56863 |     13 |          338.972 | 2103296 |  224.844 |              282.899 |              121.687 |            849.617 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_28e47_00000:
  custom_metrics:
    time_step_max: 4129
    time_step_mean: 3438.568596968519
    time_step_min: 3065
  date: 2020-10-12_13-08-31
  done: false
  episode_len_mean: 844.5809049079754
  episode_reward_max: 287.29292929292905
  episode_reward_mean: 226.54627563983382
  episode_reward_min: 121.68686868686854
  episodes_this_iter: 238
  episodes_total: 2608
  experiment_id: b2124891260f4214b9ee1feca592c995
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.88819586733977
        entropy_coeff: 0.0005000000000000001
        kl: 0.008180352044291794
        model: {}
        policy_loss: -0.012070766960581144
        total_loss: 16.36778982480367
        vf_explained_var: 0.9728206992149353
        vf_loss: 16.378668546676636
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.203225806451616
    gpu_util_percent0: 0.3854838709677419
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7612903225806447
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56863
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15195937446521438
    mean_env_wait_ms: 1.1771070288004886
    mean_inference_ms: 4.649835402225931
    mean_raw_obs_processing_ms: 0.39958259785468786
  time_since_restore: 364.7812623977661
  time_this_iter_s: 25.80895209312439
  time_total_s: 364.7812623977661
  timers:
    learn_throughput: 8591.823
    learn_time_ms: 18830.928
    sample_throughput: 23445.192
    sample_time_ms: 6900.86
    update_time_ms: 21.135
  timestamp: 1602508111
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 28e47_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_28e47_00000 | RUNNING  | 172.17.0.4:56863 |     14 |          364.781 | 2265088 |  226.546 |              287.293 |              121.687 |            844.581 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_28e47_00000:
  custom_metrics:
    time_step_max: 4129
    time_step_mean: 3428.1819152723388
    time_step_min: 3065
  date: 2020-10-12_13-08-57
  done: false
  episode_len_mean: 839.8804500703235
  episode_reward_max: 287.29292929292905
  episode_reward_mean: 228.02440011933675
  episode_reward_min: 121.68686868686854
  episodes_this_iter: 236
  episodes_total: 2844
  experiment_id: b2124891260f4214b9ee1feca592c995
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8926832427581152
        entropy_coeff: 0.0005000000000000001
        kl: 0.008696844025204578
        model: {}
        policy_loss: -0.01215913209792537
        total_loss: 12.413879791895548
        vf_explained_var: 0.9757079482078552
        vf_loss: 12.42474595705668
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.86129032258065
    gpu_util_percent0: 0.36161290322580647
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7612903225806447
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56863
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15159867071772853
    mean_env_wait_ms: 1.1788533855903753
    mean_inference_ms: 4.628340910332939
    mean_raw_obs_processing_ms: 0.3983414894342601
  time_since_restore: 390.5454113483429
  time_this_iter_s: 25.764148950576782
  time_total_s: 390.5454113483429
  timers:
    learn_throughput: 8589.59
    learn_time_ms: 18835.822
    sample_throughput: 23477.065
    sample_time_ms: 6891.492
    update_time_ms: 20.233
  timestamp: 1602508137
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 28e47_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_28e47_00000 | RUNNING  | 172.17.0.4:56863 |     15 |          390.545 | 2426880 |  228.024 |              287.293 |              121.687 |             839.88 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_28e47_00000:
  custom_metrics:
    time_step_max: 4129
    time_step_mean: 3422.3245702730032
    time_step_min: 3065
  date: 2020-10-12_13-09-23
  done: false
  episode_len_mean: 837.0286475682879
  episode_reward_max: 287.29292929292905
  episode_reward_mean: 228.9062981581302
  episode_reward_min: 121.68686868686854
  episodes_this_iter: 158
  episodes_total: 3002
  experiment_id: b2124891260f4214b9ee1feca592c995
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.884347140789032
        entropy_coeff: 0.0005000000000000001
        kl: 0.009455407969653606
        model: {}
        policy_loss: -0.01691609772387892
        total_loss: 10.041658480962118
        vf_explained_var: 0.9760048985481262
        vf_loss: 10.057125568389893
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.675
    gpu_util_percent0: 0.31375
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.778125
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56863
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15138283551742562
    mean_env_wait_ms: 1.1799999411310889
    mean_inference_ms: 4.615217893318503
    mean_raw_obs_processing_ms: 0.3975769914795083
  time_since_restore: 416.3559925556183
  time_this_iter_s: 25.81058120727539
  time_total_s: 416.3559925556183
  timers:
    learn_throughput: 8588.889
    learn_time_ms: 18837.361
    sample_throughput: 23545.872
    sample_time_ms: 6871.353
    update_time_ms: 20.616
  timestamp: 1602508163
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 28e47_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_28e47_00000 | RUNNING  | 172.17.0.4:56863 |     16 |          416.356 | 2588672 |  228.906 |              287.293 |              121.687 |            837.029 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_28e47_00000:
  custom_metrics:
    time_step_max: 4129
    time_step_mean: 3415.493510604622
    time_step_min: 3065
  date: 2020-10-12_13-09-49
  done: false
  episode_len_mean: 833.5745147150908
  episode_reward_max: 287.29292929292905
  episode_reward_mean: 229.99686280462728
  episode_reward_min: 121.68686868686854
  episodes_this_iter: 192
  episodes_total: 3194
  experiment_id: b2124891260f4214b9ee1feca592c995
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8397218187650045
        entropy_coeff: 0.0005000000000000001
        kl: 0.007703252059097092
        model: {}
        policy_loss: -0.01650365562333415
        total_loss: 14.373824914296469
        vf_explained_var: 0.9715592861175537
        vf_loss: 14.38920791943868
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.38387096774194
    gpu_util_percent0: 0.34580645161290324
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7677419354838704
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56863
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1511423585981362
    mean_env_wait_ms: 1.1814654870979406
    mean_inference_ms: 4.600433961745958
    mean_raw_obs_processing_ms: 0.39670615809991866
  time_since_restore: 442.1780424118042
  time_this_iter_s: 25.822049856185913
  time_total_s: 442.1780424118042
  timers:
    learn_throughput: 8589.62
    learn_time_ms: 18835.758
    sample_throughput: 23532.896
    sample_time_ms: 6875.142
    update_time_ms: 20.56
  timestamp: 1602508189
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 28e47_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_28e47_00000 | RUNNING  | 172.17.0.4:56863 |     17 |          442.178 | 2750464 |  229.997 |              287.293 |              121.687 |            833.575 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_28e47_00000:
  custom_metrics:
    time_step_max: 4129
    time_step_mean: 3407.030804998547
    time_step_min: 3065
  date: 2020-10-12_13-10-15
  done: false
  episode_len_mean: 828.8955696202531
  episode_reward_max: 287.29292929292905
  episode_reward_mean: 231.3798717904011
  episode_reward_min: 121.68686868686854
  episodes_this_iter: 282
  episodes_total: 3476
  experiment_id: b2124891260f4214b9ee1feca592c995
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8362490981817245
        entropy_coeff: 0.0005000000000000001
        kl: 0.006584137639341255
        model: {}
        policy_loss: -0.010846812239227196
        total_loss: 15.19317102432251
        vf_explained_var: 0.9743531346321106
        vf_loss: 15.203119357426962
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.97096774193549
    gpu_util_percent0: 0.39870967741935476
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7612903225806447
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56863
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15082393046747997
    mean_env_wait_ms: 1.1835217283125066
    mean_inference_ms: 4.58122347047034
    mean_raw_obs_processing_ms: 0.39559273303153614
  time_since_restore: 468.3612153530121
  time_this_iter_s: 26.183172941207886
  time_total_s: 468.3612153530121
  timers:
    learn_throughput: 8574.428
    learn_time_ms: 18869.131
    sample_throughput: 23475.536
    sample_time_ms: 6891.941
    update_time_ms: 23.054
  timestamp: 1602508215
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 28e47_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_28e47_00000 | RUNNING  | 172.17.0.4:56863 |     18 |          468.361 | 2912256 |   231.38 |              287.293 |              121.687 |            828.896 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_28e47_00000:
  custom_metrics:
    time_step_max: 4129
    time_step_mean: 3402.0783550986384
    time_step_min: 3065
  date: 2020-10-12_13-10-42
  done: false
  episode_len_mean: 826.437259218492
  episode_reward_max: 287.29292929292905
  episode_reward_mean: 232.15896721758025
  episode_reward_min: 121.68686868686854
  episodes_this_iter: 158
  episodes_total: 3634
  experiment_id: b2124891260f4214b9ee1feca592c995
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8370668143033981
        entropy_coeff: 0.0005000000000000001
        kl: 0.00821769159908096
        model: {}
        policy_loss: -0.011755507284154495
        total_loss: 11.110737800598145
        vf_explained_var: 0.9729089140892029
        vf_loss: 11.121268192927042
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.553125
    gpu_util_percent0: 0.341875
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7750000000000004
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56863
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15066267994964702
    mean_env_wait_ms: 1.1846146946326384
    mean_inference_ms: 4.571435500230488
    mean_raw_obs_processing_ms: 0.3950176224719191
  time_since_restore: 494.5016076564789
  time_this_iter_s: 26.140392303466797
  time_total_s: 494.5016076564789
  timers:
    learn_throughput: 8566.711
    learn_time_ms: 18886.128
    sample_throughput: 23476.662
    sample_time_ms: 6891.61
    update_time_ms: 24.966
  timestamp: 1602508242
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 28e47_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_28e47_00000 | RUNNING  | 172.17.0.4:56863 |     19 |          494.502 | 3074048 |  232.159 |              287.293 |              121.687 |            826.437 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_28e47_00000:
  custom_metrics:
    time_step_max: 4129
    time_step_mean: 3396.773963559546
    time_step_min: 3065
  date: 2020-10-12_13-11-08
  done: false
  episode_len_mean: 823.6946624803768
  episode_reward_max: 287.29292929292905
  episode_reward_mean: 232.98497534211813
  episode_reward_min: 121.68686868686854
  episodes_this_iter: 188
  episodes_total: 3822
  experiment_id: b2124891260f4214b9ee1feca592c995
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8015544364849726
        entropy_coeff: 0.0005000000000000001
        kl: 0.008135161052147547
        model: {}
        policy_loss: -0.013570779759902507
        total_loss: 12.73607842127482
        vf_explained_var: 0.9744771122932434
        vf_loss: 12.748423417409262
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.803125
    gpu_util_percent0: 0.284375
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.771875
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56863
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15048174906581033
    mean_env_wait_ms: 1.1859225353633531
    mean_inference_ms: 4.560467596945895
    mean_raw_obs_processing_ms: 0.3943577555380012
  time_since_restore: 520.7181749343872
  time_this_iter_s: 26.216567277908325
  time_total_s: 520.7181749343872
  timers:
    learn_throughput: 8556.935
    learn_time_ms: 18907.704
    sample_throughput: 23431.058
    sample_time_ms: 6905.023
    update_time_ms: 25.738
  timestamp: 1602508268
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 28e47_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_28e47_00000 | RUNNING  | 172.17.0.4:56863 |     20 |          520.718 | 3235840 |  232.985 |              287.293 |              121.687 |            823.695 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_28e47_00000:
  custom_metrics:
    time_step_max: 4129
    time_step_mean: 3388.4534740977165
    time_step_min: 3065
  date: 2020-10-12_13-11-34
  done: false
  episode_len_mean: 819.9761441090556
  episode_reward_max: 287.29292929292905
  episode_reward_mean: 234.24282011940235
  episode_reward_min: 121.68686868686854
  episodes_this_iter: 286
  episodes_total: 4108
  experiment_id: b2124891260f4214b9ee1feca592c995
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.786194329460462
        entropy_coeff: 0.0005000000000000001
        kl: 0.007542054518125951
        model: {}
        policy_loss: -0.011482890016244104
        total_loss: 14.260780175526937
        vf_explained_var: 0.9762682318687439
        vf_loss: 14.271147886912027
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.98387096774194
    gpu_util_percent0: 0.3667741935483871
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.764516129032258
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56863
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15023341538469365
    mean_env_wait_ms: 1.187838472126512
    mean_inference_ms: 4.545476004701757
    mean_raw_obs_processing_ms: 0.3934789434992657
  time_since_restore: 546.6242377758026
  time_this_iter_s: 25.906062841415405
  time_total_s: 546.6242377758026
  timers:
    learn_throughput: 8553.317
    learn_time_ms: 18915.703
    sample_throughput: 23424.013
    sample_time_ms: 6907.1
    update_time_ms: 26.743
  timestamp: 1602508294
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: 28e47_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_28e47_00000 | RUNNING  | 172.17.0.4:56863 |     21 |          546.624 | 3397632 |  234.243 |              287.293 |              121.687 |            819.976 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_28e47_00000:
  custom_metrics:
    time_step_max: 4129
    time_step_mean: 3384.4961002127156
    time_step_min: 3057
  date: 2020-10-12_13-12-00
  done: false
  episode_len_mean: 818.0457102672293
  episode_reward_max: 287.29292929292905
  episode_reward_mean: 234.81850147040015
  episode_reward_min: 121.68686868686854
  episodes_this_iter: 158
  episodes_total: 4266
  experiment_id: b2124891260f4214b9ee1feca592c995
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7922306607166926
        entropy_coeff: 0.0005000000000000001
        kl: 0.007512495891811947
        model: {}
        policy_loss: -0.012487672832018385
        total_loss: 10.314622084299723
        vf_explained_var: 0.9758312106132507
        vf_loss: 10.326003313064575
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.25806451612903
    gpu_util_percent0: 0.3803225806451613
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56863
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15010648891358794
    mean_env_wait_ms: 1.188830459159871
    mean_inference_ms: 4.5378401629998555
    mean_raw_obs_processing_ms: 0.39302770791527936
  time_since_restore: 572.4283874034882
  time_this_iter_s: 25.804149627685547
  time_total_s: 572.4283874034882
  timers:
    learn_throughput: 8557.844
    learn_time_ms: 18905.696
    sample_throughput: 23387.652
    sample_time_ms: 6917.839
    update_time_ms: 27.284
  timestamp: 1602508320
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: 28e47_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_28e47_00000 | RUNNING  | 172.17.0.4:56863 |     22 |          572.428 | 3559424 |  234.819 |              287.293 |              121.687 |            818.046 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_28e47_00000:
  custom_metrics:
    time_step_max: 4129
    time_step_mean: 3379.566674213267
    time_step_min: 3057
  date: 2020-10-12_13-12-26
  done: false
  episode_len_mean: 815.9321653189578
  episode_reward_max: 287.29292929292905
  episode_reward_mean: 235.5083721310136
  episode_reward_min: 121.68686868686854
  episodes_this_iter: 186
  episodes_total: 4452
  experiment_id: b2124891260f4214b9ee1feca592c995
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.758012443780899
        entropy_coeff: 0.0005000000000000001
        kl: 0.0076204077728713555
        model: {}
        policy_loss: -0.012390402844175696
        total_loss: 12.12289826075236
        vf_explained_var: 0.9758632183074951
        vf_loss: 12.134143511454264
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.74375
    gpu_util_percent0: 0.348125
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.771875
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56863
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1499623731655712
    mean_env_wait_ms: 1.189992378001714
    mean_inference_ms: 4.529242543906134
    mean_raw_obs_processing_ms: 0.392511192639838
  time_since_restore: 598.3538408279419
  time_this_iter_s: 25.925453424453735
  time_total_s: 598.3538408279419
  timers:
    learn_throughput: 8551.073
    learn_time_ms: 18920.667
    sample_throughput: 23351.154
    sample_time_ms: 6928.651
    update_time_ms: 27.22
  timestamp: 1602508346
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: 28e47_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_28e47_00000 | RUNNING  | 172.17.0.4:56863 |     23 |          598.354 | 3721216 |  235.508 |              287.293 |              121.687 |            815.932 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_28e47_00000:
  custom_metrics:
    time_step_max: 4129
    time_step_mean: 3373.2557397959185
    time_step_min: 3015
  date: 2020-10-12_13-12-52
  done: true
  episode_len_mean: 813.3745515931631
  episode_reward_max: 290.4747474747476
  episode_reward_mean: 236.49167982845972
  episode_reward_min: 121.68686868686854
  episodes_this_iter: 287
  episodes_total: 4739
  experiment_id: b2124891260f4214b9ee1feca592c995
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7452520926793417
        entropy_coeff: 0.0005000000000000001
        kl: 0.007488196521687011
        model: {}
        policy_loss: -0.01202371165951869
        total_loss: 12.353691180547079
        vf_explained_var: 0.979881763458252
        vf_loss: 12.36458913485209
    num_steps_sampled: 3883008
    num_steps_trained: 3883008
  iterations_since_restore: 24
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.22258064516129
    gpu_util_percent0: 0.3874193548387096
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322577
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 56863
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14976419725689222
    mean_env_wait_ms: 1.1917099075734823
    mean_inference_ms: 4.517260322881482
    mean_raw_obs_processing_ms: 0.3918139957284075
  time_since_restore: 624.0455734729767
  time_this_iter_s: 25.69173264503479
  time_total_s: 624.0455734729767
  timers:
    learn_throughput: 8560.585
    learn_time_ms: 18899.644
    sample_throughput: 23324.399
    sample_time_ms: 6936.599
    update_time_ms: 27.498
  timestamp: 1602508372
  timesteps_since_restore: 0
  timesteps_total: 3883008
  training_iteration: 24
  trial_id: 28e47_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_28e47_00000 | TERMINATED |       |     24 |          624.046 | 3883008 |  236.492 |              290.475 |              121.687 |            813.375 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_28e47_00000 | TERMINATED |       |     24 |          624.046 | 3883008 |  236.492 |              290.475 |              121.687 |            813.375 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


