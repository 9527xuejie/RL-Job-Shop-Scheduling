diff --git a/JSS/.ipynb_checkpoints/PPO-checkpoint.ipynb b/JSS/.ipynb_checkpoints/PPO-checkpoint.ipynb
index 4ec3a0c..9879da6 100644
--- a/JSS/.ipynb_checkpoints/PPO-checkpoint.ipynb
+++ b/JSS/.ipynb_checkpoints/PPO-checkpoint.ipynb
@@ -2,7 +2,7 @@
  "cells": [
   {
    "cell_type": "code",
-   "execution_count": 7,
+   "execution_count": 14,
    "metadata": {},
    "outputs": [
     {
@@ -64,9 +64,9 @@
     "        },\n",
     "        'parameters': {\n",
     "            'instance_path': {\n",
-    "                'values': ['/JSS/JSS/env/instances/ta51', '/JSS/JSS/env/instances/ta52', '/JSS/JSS/env/instances/ta53', '/JSS/JSS/env/instances/ta54',\n",
-    "                           '/JSS/JSS/env/instances/ta55', '/JSS/JSS/env/instances/ta56', '/JSS/JSS/env/instances/ta57', '/JSS/JSS/env/instances/ta58',\n",
-    "                           '/JSS/JSS/env/instances/ta59', '/JSS/JSS/env/instances/ta60']\n",
+    "                'values': ['/JSS/JSS/env/instances/ta40', '/JSS/JSS/env/instances/ta41', '/JSS/JSS/env/instances/ta42', '/JSS/JSS/env/instances/ta43', '/JSS/JSS/env/instances/ta44',\n",
+    "                           '/JSS/JSS/env/instances/ta45', '/JSS/JSS/env/instances/ta46', '/JSS/JSS/env/instances/ta47', '/JSS/JSS/env/instances/ta48',\n",
+    "                           '/JSS/JSS/env/instances/ta49', '/JSS/JSS/env/instances/ta50']\n",
     "            }\n",
     "        }\n",
     "    }"
@@ -74,25 +74,25 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 8,
+   "execution_count": 15,
    "metadata": {},
    "outputs": [
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "Create sweep with ID: 1x8v92mc\n",
-      "Sweep URL: https://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/1x8v92mc\n"
+      "Create sweep with ID: 9xhkl8my\n",
+      "Sweep URL: https://wandb.ai/ingambe/RLLIB_SWEEP_3/sweeps/9xhkl8my\n"
      ]
     }
    ],
    "source": [
-    "sweep_id = wandb.sweep(sweep_config, project=\"RLLIB_SWEEP_2\")"
+    "sweep_id = wandb.sweep(sweep_config, project=\"RLLIB_SWEEP_3\")"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 9,
+   "execution_count": 16,
    "metadata": {},
    "outputs": [
     {
@@ -100,67 +100,13616 @@
      "output_type": "stream",
      "text": [
       "\u001b[34m\u001b[1mwandb\u001b[0m: Starting wandb agent üïµÔ∏è\n",
-      "2020-10-13 11:45:51,946 - wandb.wandb_agent - INFO - Running runs: []\n",
-      "2020-10-13 11:45:52,259 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-13 11:45:52,260 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tinstance_path: /JSS/JSS/env/instances/ta51\n",
-      "2020-10-13 11:45:52,261 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python RandomGreedy.py --instance_path=/JSS/JSS/env/instances/ta51\n",
+      "2020-11-01 11:53:51,776 - wandb.wandb_agent - INFO - Running runs: []\n",
+      "2020-11-01 11:53:52,086 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-11-01 11:53:52,086 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tinstance_path: /JSS/JSS/env/instances/la/la11.txt\n",
+      "2020-11-01 11:53:52,088 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --instance_path=/JSS/JSS/env/instances/la/la11.txt\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.8 is available!  To upgrade, please run:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mrandom\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/1x8v92mc\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/3qwfavbb\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201013_114553-3qwfavbb\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmisty-sweep-1\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/sweeps/9xhkl8my\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/kqo0l7if\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201101_115353-kqo0l7if\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
-      "2020-10-13 11:45:57,278 - wandb.wandb_agent - INFO - Running runs: ['3qwfavbb']\n",
+      "2020-11-01 11:53:57,102 - wandb.wandb_agent - INFO - Running runs: ['kqo0l7if']\n",
+      "2020-11-01 11:53:57,683\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
+      "== Status ==\n",
+      "Memory usage on this node: 12.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  |       |\n",
+      "+-------------------------+----------+-------+\n",
       "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 39394\n",
+      "\n",
+      "\u001b[2m\u001b[36m(pid=20230)\u001b[0m 2020-11-01 11:54:00,466\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=20215)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20215)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20191)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20191)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20206)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20206)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20222)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20222)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20202)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20202)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20171)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20171)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20193)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20193)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20199)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20199)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20235)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20235)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20233)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20233)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20232)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20232)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20198)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20198)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20211)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20211)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20205)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20205)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20226)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20226)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20187)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20187)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20207)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20207)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20216)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20216)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20237)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20237)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20166)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20166)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20236)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20236)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20247)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20247)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20151)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20151)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20175)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20175)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20138)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20138)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20174)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20174)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20178)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20178)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20116)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20116)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20128)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20128)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20181)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20181)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20123)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20123)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20142)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20142)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20169)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20169)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20196)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20196)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20209)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20209)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20188)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20188)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20112)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20112)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20120)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20120)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20210)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20210)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20131)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20131)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20127)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20127)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20134)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20134)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20170)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20170)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20125)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20125)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20129)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20129)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20212)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20212)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20203)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20203)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20180)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20180)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20194)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20194)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20150)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20150)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20219)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20219)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20197)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20197)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20176)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20176)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20192)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20192)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20130)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20130)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20149)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20149)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20195)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20195)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20124)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20124)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20132)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20132)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20240)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20240)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20200)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20200)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20117)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20117)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20173)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20173)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20183)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20183)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20184)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20184)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20145)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20145)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20141)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20141)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20148)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20148)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20122)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20122)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20118)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20118)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20115)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20115)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20214)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20214)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20147)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20147)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20135)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20135)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20114)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20114)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20119)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20119)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20241)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20241)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20113)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20113)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20225)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20225)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1434.4832653061223\n",
+      "    time_step_min: 1245\n",
+      "  date: 2020-11-01_11-54-27\n",
+      "  done: false\n",
+      "  episode_len_mean: 116.93913043478261\n",
+      "  episode_reward_max: 45.68367346938774\n",
+      "  episode_reward_mean: 35.80144389771718\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1265\n",
+      "  episodes_total: 1265\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1484567523002625\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006624576014777024\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007466505475652714\n",
+      "        total_loss: 52.51902961730957\n",
+      "        vf_explained_var: 0.7593300342559814\n",
+      "        vf_loss: 52.52574666341146\n",
+      "    num_steps_sampled: 161792\n",
+      "    num_steps_trained: 161792\n",
+      "  iterations_since_restore: 1\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 31.92222222222222\n",
+      "    gpu_util_percent0: 0.3044444444444444\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.4370370370370376\n",
+      "    vram_util_percent0: 0.0819728386963546\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.17175637313856013\n",
+      "    mean_env_wait_ms: 0.6787065283307273\n",
+      "    mean_inference_ms: 5.169812775871786\n",
+      "    mean_raw_obs_processing_ms: 0.45531381926816505\n",
+      "  time_since_restore: 22.264521837234497\n",
+      "  time_this_iter_s: 22.264521837234497\n",
+      "  time_total_s: 22.264521837234497\n",
+      "  timers:\n",
+      "    learn_throughput: 11076.145\n",
+      "    learn_time_ms: 14607.249\n",
+      "    sample_throughput: 21315.374\n",
+      "    sample_time_ms: 7590.39\n",
+      "    update_time_ms: 20.181\n",
+      "  timestamp: 1604231667\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 161792\n",
+      "  training_iteration: 1\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |      1 |          22.2645 | 161792 |  35.8014 |              45.6837 |              15.7347 |            116.939 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1426.9196226415095\n",
+      "    time_step_min: 1245\n",
+      "  date: 2020-11-01_11-54-49\n",
+      "  done: false\n",
+      "  episode_len_mean: 115.78401486988848\n",
+      "  episode_reward_max: 45.68367346938774\n",
+      "  episode_reward_mean: 36.37903042257795\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1425\n",
+      "  episodes_total: 2690\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.130055993795395\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.00956034411986669\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011216347149456851\n",
+      "        total_loss: 10.385109821955362\n",
+      "        vf_explained_var: 0.894355058670044\n",
+      "        vf_loss: 10.394978761672974\n",
+      "    num_steps_sampled: 323584\n",
+      "    num_steps_trained: 323584\n",
+      "  iterations_since_restore: 2\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 28.388\n",
+      "    gpu_util_percent0: 0.3824\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5120000000000005\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16652532875458848\n",
+      "    mean_env_wait_ms: 0.6684123457284149\n",
+      "    mean_inference_ms: 4.952915318761355\n",
+      "    mean_raw_obs_processing_ms: 0.44064388796599707\n",
+      "  time_since_restore: 43.21846151351929\n",
+      "  time_this_iter_s: 20.95393967628479\n",
+      "  time_total_s: 43.21846151351929\n",
+      "  timers:\n",
+      "    learn_throughput: 11096.611\n",
+      "    learn_time_ms: 14580.307\n",
+      "    sample_throughput: 23271.686\n",
+      "    sample_time_ms: 6952.311\n",
+      "    update_time_ms: 21.999\n",
+      "  timestamp: 1604231689\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 323584\n",
+      "  training_iteration: 2\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.5/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |      2 |          43.2185 | 323584 |   36.379 |              45.6837 |              15.7347 |            115.784 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1408.408178256611\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_11-55-09\n",
+      "  done: false\n",
+      "  episode_len_mean: 114.67119301648884\n",
+      "  episode_reward_max: 46.85714285714286\n",
+      "  episode_reward_mean: 37.28042419683683\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1434\n",
+      "  episodes_total: 4124\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1140848398208618\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.009810077414537469\n",
+      "        model: {}\n",
+      "        policy_loss: -0.015473847355072698\n",
+      "        total_loss: 7.254512945810954\n",
+      "        vf_explained_var: 0.9246422648429871\n",
+      "        vf_loss: 7.2685816287994385\n",
+      "    num_steps_sampled: 485376\n",
+      "    num_steps_trained: 485376\n",
+      "  iterations_since_restore: 3\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.775000000000002\n",
+      "    gpu_util_percent0: 0.34500000000000003\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.516666666666667\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16318379996682947\n",
+      "    mean_env_wait_ms: 0.662199655734115\n",
+      "    mean_inference_ms: 4.788160816000921\n",
+      "    mean_raw_obs_processing_ms: 0.43056477316095654\n",
+      "  time_since_restore: 63.56497097015381\n",
+      "  time_this_iter_s: 20.34650945663452\n",
+      "  time_total_s: 63.56497097015381\n",
+      "  timers:\n",
+      "    learn_throughput: 11127.786\n",
+      "    learn_time_ms: 14539.46\n",
+      "    sample_throughput: 24626.159\n",
+      "    sample_time_ms: 6569.924\n",
+      "    update_time_ms: 21.5\n",
+      "  timestamp: 1604231709\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 485376\n",
+      "  training_iteration: 3\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.5/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |      3 |           63.565 | 485376 |  37.2804 |              46.8571 |              15.7347 |            114.671 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1389.7721856660146\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_11-55-30\n",
+      "  done: false\n",
+      "  episode_len_mean: 113.25304608864559\n",
+      "  episode_reward_max: 46.857142857142875\n",
+      "  episode_reward_mean: 38.234928122758895\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1539\n",
+      "  episodes_total: 5663\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0880944629510243\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.009488985563317934\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01440603454830125\n",
+      "        total_loss: 5.48736047744751\n",
+      "        vf_explained_var: 0.9440011978149414\n",
+      "        vf_loss: 5.500412583351135\n",
+      "    num_steps_sampled: 647168\n",
+      "    num_steps_trained: 647168\n",
+      "  iterations_since_restore: 4\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.516666666666666\n",
+      "    gpu_util_percent0: 0.34874999999999995\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5125000000000006\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16068983053902333\n",
+      "    mean_env_wait_ms: 0.6583389151369388\n",
+      "    mean_inference_ms: 4.664128900411232\n",
+      "    mean_raw_obs_processing_ms: 0.42299876801925573\n",
+      "  time_since_restore: 84.06657981872559\n",
+      "  time_this_iter_s: 20.501608848571777\n",
+      "  time_total_s: 84.06657981872559\n",
+      "  timers:\n",
+      "    learn_throughput: 11095.44\n",
+      "    learn_time_ms: 14581.846\n",
+      "    sample_throughput: 25479.527\n",
+      "    sample_time_ms: 6349.882\n",
+      "    update_time_ms: 24.143\n",
+      "  timestamp: 1604231730\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 647168\n",
+      "  training_iteration: 4\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |      4 |          84.0666 | 647168 |  38.2349 |              46.8571 |              15.7347 |            113.253 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1374.424760022586\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_11-55-50\n",
+      "  done: false\n",
+      "  episode_len_mean: 112.05460415496911\n",
+      "  episode_reward_max: 46.857142857142875\n",
+      "  episode_reward_mean: 39.03776398262842\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1461\n",
+      "  episodes_total: 7124\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0627730786800385\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.009283728742351135\n",
+      "        model: {}\n",
+      "        policy_loss: -0.015454331073366726\n",
+      "        total_loss: 4.347856322924296\n",
+      "        vf_explained_var: 0.9541513323783875\n",
+      "        vf_loss: 4.3619853258132935\n",
+      "    num_steps_sampled: 808960\n",
+      "    num_steps_trained: 808960\n",
+      "  iterations_since_restore: 5\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.604166666666668\n",
+      "    gpu_util_percent0: 0.3541666666666667\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5124999999999997\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15895058912495744\n",
+      "    mean_env_wait_ms: 0.6558977259961688\n",
+      "    mean_inference_ms: 4.577574740810779\n",
+      "    mean_raw_obs_processing_ms: 0.4175203436251983\n",
+      "  time_since_restore: 104.25312542915344\n",
+      "  time_this_iter_s: 20.186545610427856\n",
+      "  time_total_s: 104.25312542915344\n",
+      "  timers:\n",
+      "    learn_throughput: 11116.23\n",
+      "    learn_time_ms: 14554.575\n",
+      "    sample_throughput: 26067.237\n",
+      "    sample_time_ms: 6206.718\n",
+      "    update_time_ms: 26.186\n",
+      "  timestamp: 1604231750\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 808960\n",
+      "  training_iteration: 5\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |      5 |          104.253 | 808960 |  39.0378 |              46.8571 |              15.7347 |            112.055 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1360.2383485601943\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_11-56-11\n",
+      "  done: false\n",
+      "  episode_len_mean: 110.9338091400944\n",
+      "  episode_reward_max: 46.85714285714288\n",
+      "  episode_reward_mean: 39.78162771958098\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1563\n",
+      "  episodes_total: 8687\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0209535757700603\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.009677846527968844\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013495485666984072\n",
+      "        total_loss: 3.3039915561676025\n",
+      "        vf_explained_var: 0.9663781523704529\n",
+      "        vf_loss: 3.3160619735717773\n",
+      "    num_steps_sampled: 970752\n",
+      "    num_steps_trained: 970752\n",
+      "  iterations_since_restore: 6\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.1\n",
+      "    gpu_util_percent0: 0.3948\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.52\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15752045783718058\n",
+      "    mean_env_wait_ms: 0.6540636684528683\n",
+      "    mean_inference_ms: 4.50681489407211\n",
+      "    mean_raw_obs_processing_ms: 0.4129356375354034\n",
+      "  time_since_restore: 124.68163776397705\n",
+      "  time_this_iter_s: 20.42851233482361\n",
+      "  time_total_s: 124.68163776397705\n",
+      "  timers:\n",
+      "    learn_throughput: 11114.998\n",
+      "    learn_time_ms: 14556.188\n",
+      "    sample_throughput: 26385.183\n",
+      "    sample_time_ms: 6131.926\n",
+      "    update_time_ms: 25.903\n",
+      "  timestamp: 1604231771\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 970752\n",
+      "  training_iteration: 6\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |      6 |          124.682 | 970752 |  39.7816 |              46.8571 |              15.7347 |            110.934 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1346.8549304058029\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_11-56-31\n",
+      "  done: false\n",
+      "  episode_len_mean: 109.96026166764304\n",
+      "  episode_reward_max: 46.85714285714288\n",
+      "  episode_reward_mean: 40.448761402627824\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1555\n",
+      "  episodes_total: 10242\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9796850432952245\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.008622131776064634\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012602110786247067\n",
+      "        total_loss: 2.7198241551717124\n",
+      "        vf_explained_var: 0.9723749160766602\n",
+      "        vf_loss: 2.731191635131836\n",
+      "    num_steps_sampled: 1132544\n",
+      "    num_steps_trained: 1132544\n",
+      "  iterations_since_restore: 7\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.520833333333332\n",
+      "    gpu_util_percent0: 0.36541666666666667\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5208333333333335\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15640676678928592\n",
+      "    mean_env_wait_ms: 0.6528313389539068\n",
+      "    mean_inference_ms: 4.45161866768078\n",
+      "    mean_raw_obs_processing_ms: 0.40931756815016995\n",
+      "  time_since_restore: 145.21865725517273\n",
+      "  time_this_iter_s: 20.53701949119568\n",
+      "  time_total_s: 145.21865725517273\n",
+      "  timers:\n",
+      "    learn_throughput: 11103.013\n",
+      "    learn_time_ms: 14571.9\n",
+      "    sample_throughput: 26614.769\n",
+      "    sample_time_ms: 6079.031\n",
+      "    update_time_ms: 25.131\n",
+      "  timestamp: 1604231791\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1132544\n",
+      "  training_iteration: 7\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |      7 |          145.219 | 1132544 |  40.4488 |              46.8571 |              15.7347 |             109.96 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1335.6309301139263\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_11-56-52\n",
+      "  done: false\n",
+      "  episode_len_mean: 109.09913573970513\n",
+      "  episode_reward_max: 46.8571428571429\n",
+      "  episode_reward_mean: 41.02892366911177\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1560\n",
+      "  episodes_total: 11802\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.937453493475914\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.007955724994341532\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01194375741033582\n",
+      "        total_loss: 2.2597323656082153\n",
+      "        vf_explained_var: 0.9770286083221436\n",
+      "        vf_loss: 2.2705536683400473\n",
+      "    num_steps_sampled: 1294336\n",
+      "    num_steps_trained: 1294336\n",
+      "  iterations_since_restore: 8\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.436000000000003\n",
+      "    gpu_util_percent0: 0.3632\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1554915965562696\n",
+      "    mean_env_wait_ms: 0.6518904790353526\n",
+      "    mean_inference_ms: 4.406507393012131\n",
+      "    mean_raw_obs_processing_ms: 0.40631830746764874\n",
+      "  time_since_restore: 166.04925441741943\n",
+      "  time_this_iter_s: 20.830597162246704\n",
+      "  time_total_s: 166.04925441741943\n",
+      "  timers:\n",
+      "    learn_throughput: 11082.871\n",
+      "    learn_time_ms: 14598.383\n",
+      "    sample_throughput: 26705.585\n",
+      "    sample_time_ms: 6058.358\n",
+      "    update_time_ms: 26.617\n",
+      "  timestamp: 1604231812\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1294336\n",
+      "  training_iteration: 8\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |      8 |          166.049 | 1294336 |  41.0289 |              46.8571 |              15.7347 |            109.099 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1325.960990247562\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_11-57-13\n",
+      "  done: false\n",
+      "  episode_len_mean: 108.36514584891549\n",
+      "  episode_reward_max: 46.8571428571429\n",
+      "  episode_reward_mean: 41.523987605513405\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1568\n",
+      "  episodes_total: 13370\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8931734959284464\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.007821322418749332\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011547995522657098\n",
+      "        total_loss: 1.8110616604487102\n",
+      "        vf_explained_var: 0.9818581938743591\n",
+      "        vf_loss: 1.8214919765790303\n",
+      "    num_steps_sampled: 1456128\n",
+      "    num_steps_trained: 1456128\n",
+      "  iterations_since_restore: 9\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.3625\n",
+      "    gpu_util_percent0: 0.34625\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5749999999999997\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15472443847934\n",
+      "    mean_env_wait_ms: 0.6512116120864969\n",
+      "    mean_inference_ms: 4.368900491259558\n",
+      "    mean_raw_obs_processing_ms: 0.40380683055783845\n",
+      "  time_since_restore: 186.4968512058258\n",
+      "  time_this_iter_s: 20.447596788406372\n",
+      "  time_total_s: 186.4968512058258\n",
+      "  timers:\n",
+      "    learn_throughput: 11083.852\n",
+      "    learn_time_ms: 14597.092\n",
+      "    sample_throughput: 26872.567\n",
+      "    sample_time_ms: 6020.713\n",
+      "    update_time_ms: 27.945\n",
+      "  timestamp: 1604231833\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1456128\n",
+      "  training_iteration: 9\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |      9 |          186.497 | 1456128 |   41.524 |              46.8571 |              15.7347 |            108.365 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1317.3690564013145\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_11-57-34\n",
+      "  done: false\n",
+      "  episode_len_mean: 107.72182462711524\n",
+      "  episode_reward_max: 46.8571428571429\n",
+      "  episode_reward_mean: 41.96634652790953\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1581\n",
+      "  episodes_total: 14951\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8531899998585383\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.007403539726510644\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011224584576363364\n",
+      "        total_loss: 1.351464072863261\n",
+      "        vf_explained_var: 0.9865902066230774\n",
+      "        vf_loss: 1.3616345326105754\n",
+      "    num_steps_sampled: 1617920\n",
+      "    num_steps_trained: 1617920\n",
+      "  iterations_since_restore: 10\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.612\n",
+      "    gpu_util_percent0: 0.37999999999999995\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.572\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15406610086889994\n",
+      "    mean_env_wait_ms: 0.6506878167628722\n",
+      "    mean_inference_ms: 4.336866675743429\n",
+      "    mean_raw_obs_processing_ms: 0.4016399376622533\n",
+      "  time_since_restore: 207.11356925964355\n",
+      "  time_this_iter_s: 20.61671805381775\n",
+      "  time_total_s: 207.11356925964355\n",
+      "  timers:\n",
+      "    learn_throughput: 11075.434\n",
+      "    learn_time_ms: 14608.186\n",
+      "    sample_throughput: 27020.124\n",
+      "    sample_time_ms: 5987.833\n",
+      "    update_time_ms: 29.042\n",
+      "  timestamp: 1604231854\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1617920\n",
+      "  training_iteration: 10\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     10 |          207.114 | 1617920 |  41.9663 |              46.8571 |              15.7347 |            107.722 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1309.7214852504694\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_11-57-55\n",
+      "  done: false\n",
+      "  episode_len_mean: 107.15910326907971\n",
+      "  episode_reward_max: 46.857142857142904\n",
+      "  episode_reward_mean: 42.36176364315742\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1598\n",
+      "  episodes_total: 16549\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8141860415538152\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006707225965025525\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011368195065491212\n",
+      "        total_loss: 1.1314103106657665\n",
+      "        vf_explained_var: 0.9888380169868469\n",
+      "        vf_loss: 1.1418441633383434\n",
+      "    num_steps_sampled: 1779712\n",
+      "    num_steps_trained: 1779712\n",
+      "  iterations_since_restore: 11\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.291666666666668\n",
+      "    gpu_util_percent0: 0.38208333333333333\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5749999999999997\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15349391695430212\n",
+      "    mean_env_wait_ms: 0.6503003794675789\n",
+      "    mean_inference_ms: 4.309108284972775\n",
+      "    mean_raw_obs_processing_ms: 0.3997656568156822\n",
+      "  time_since_restore: 227.4893569946289\n",
+      "  time_this_iter_s: 20.37578773498535\n",
+      "  time_total_s: 227.4893569946289\n",
+      "  timers:\n",
+      "    learn_throughput: 11080.893\n",
+      "    learn_time_ms: 14600.989\n",
+      "    sample_throughput: 27896.222\n",
+      "    sample_time_ms: 5799.782\n",
+      "    update_time_ms: 29.058\n",
+      "  timestamp: 1604231875\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1779712\n",
+      "  training_iteration: 11\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     11 |          227.489 | 1779712 |  42.3618 |              46.8571 |              15.7347 |            107.159 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1303.0352388842862\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_11-58-16\n",
+      "  done: false\n",
+      "  episode_len_mean: 106.65836318545054\n",
+      "  episode_reward_max: 46.857142857142904\n",
+      "  episode_reward_mean: 42.7044331097002\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1596\n",
+      "  episodes_total: 18145\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7753126074870428\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006863077365172406\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012638252902737198\n",
+      "        total_loss: 0.8784026602904002\n",
+      "        vf_explained_var: 0.9913859963417053\n",
+      "        vf_loss: 0.8900559494892756\n",
+      "    num_steps_sampled: 1941504\n",
+      "    num_steps_trained: 1941504\n",
+      "  iterations_since_restore: 12\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.460000000000004\n",
+      "    gpu_util_percent0: 0.35159999999999997\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5679999999999996\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15300041083206697\n",
+      "    mean_env_wait_ms: 0.6500163020439707\n",
+      "    mean_inference_ms: 4.28507024712119\n",
+      "    mean_raw_obs_processing_ms: 0.39814727184542376\n",
+      "  time_since_restore: 248.12101984024048\n",
+      "  time_this_iter_s: 20.631662845611572\n",
+      "  time_total_s: 248.12101984024048\n",
+      "  timers:\n",
+      "    learn_throughput: 11075.423\n",
+      "    learn_time_ms: 14608.2\n",
+      "    sample_throughput: 28116.695\n",
+      "    sample_time_ms: 5754.304\n",
+      "    update_time_ms: 29.472\n",
+      "  timestamp: 1604231896\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1941504\n",
+      "  training_iteration: 12\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     12 |          248.121 | 1941504 |  42.7044 |              46.8571 |              15.7347 |            106.658 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1297.1705583756345\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_11-58-37\n",
+      "  done: false\n",
+      "  episode_len_mean: 106.2274062816616\n",
+      "  episode_reward_max: 46.857142857142904\n",
+      "  episode_reward_mean: 43.00436542398114\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1595\n",
+      "  episodes_total: 19740\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7383754253387451\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006651315527657668\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010724902463455996\n",
+      "        total_loss: 0.7107721914847692\n",
+      "        vf_explained_var: 0.9930524230003357\n",
+      "        vf_loss: 0.720536028345426\n",
+      "    num_steps_sampled: 2103296\n",
+      "    num_steps_trained: 2103296\n",
+      "  iterations_since_restore: 13\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.279166666666665\n",
+      "    gpu_util_percent0: 0.3491666666666666\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5749999999999997\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15256633452651727\n",
+      "    mean_env_wait_ms: 0.649802245161823\n",
+      "    mean_inference_ms: 4.264010160654567\n",
+      "    mean_raw_obs_processing_ms: 0.39671502855945817\n",
+      "  time_since_restore: 268.6334173679352\n",
+      "  time_this_iter_s: 20.512397527694702\n",
+      "  time_total_s: 268.6334173679352\n",
+      "  timers:\n",
+      "    learn_throughput: 11061.736\n",
+      "    learn_time_ms: 14626.276\n",
+      "    sample_throughput: 28152.503\n",
+      "    sample_time_ms: 5746.985\n",
+      "    update_time_ms: 29.255\n",
+      "  timestamp: 1604231917\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2103296\n",
+      "  training_iteration: 13\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     13 |          268.633 | 2103296 |  43.0044 |              46.8571 |              15.7347 |            106.227 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1292.0809922014469\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_11-58-58\n",
+      "  done: false\n",
+      "  episode_len_mean: 105.85140204445278\n",
+      "  episode_reward_max: 46.857142857142904\n",
+      "  episode_reward_mean: 43.26472333282933\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1586\n",
+      "  episodes_total: 21326\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7001272787650427\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.0061410532022515936\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010832997679244727\n",
+      "        total_loss: 0.6119682043790817\n",
+      "        vf_explained_var: 0.9940410256385803\n",
+      "        vf_loss: 0.621923049290975\n",
+      "    num_steps_sampled: 2265088\n",
+      "    num_steps_trained: 2265088\n",
+      "  iterations_since_restore: 14\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.02\n",
+      "    gpu_util_percent0: 0.368\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15218124195639093\n",
+      "    mean_env_wait_ms: 0.6496403257727554\n",
+      "    mean_inference_ms: 4.245421485662705\n",
+      "    mean_raw_obs_processing_ms: 0.3954453584998017\n",
+      "  time_since_restore: 289.35663652420044\n",
+      "  time_this_iter_s: 20.72321915626526\n",
+      "  time_total_s: 289.35663652420044\n",
+      "  timers:\n",
+      "    learn_throughput: 11062.187\n",
+      "    learn_time_ms: 14625.679\n",
+      "    sample_throughput: 28102.045\n",
+      "    sample_time_ms: 5757.304\n",
+      "    update_time_ms: 34.762\n",
+      "  timestamp: 1604231938\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2265088\n",
+      "  training_iteration: 14\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     14 |          289.357 | 2265088 |  43.2647 |              46.8571 |              15.7347 |            105.851 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1287.5182239314745\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_11-59-18\n",
+      "  done: false\n",
+      "  episode_len_mean: 105.5031847133758\n",
+      "  episode_reward_max: 46.857142857142904\n",
+      "  episode_reward_mean: 43.497414924437614\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1596\n",
+      "  episodes_total: 22922\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.6637579500675201\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005367214015374581\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009309418620735718\n",
+      "        total_loss: 0.47650496910015744\n",
+      "        vf_explained_var: 0.9953997731208801\n",
+      "        vf_loss: 0.4850728213787079\n",
+      "    num_steps_sampled: 2426880\n",
+      "    num_steps_trained: 2426880\n",
+      "  iterations_since_restore: 15\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.845833333333335\n",
+      "    gpu_util_percent0: 0.40166666666666667\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5749999999999997\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15183678083046764\n",
+      "    mean_env_wait_ms: 0.6495392872625815\n",
+      "    mean_inference_ms: 4.2286469238398325\n",
+      "    mean_raw_obs_processing_ms: 0.39431499646823304\n",
+      "  time_since_restore: 309.672310590744\n",
+      "  time_this_iter_s: 20.31567406654358\n",
+      "  time_total_s: 309.672310590744\n",
+      "  timers:\n",
+      "    learn_throughput: 11054.878\n",
+      "    learn_time_ms: 14635.35\n",
+      "    sample_throughput: 28119.821\n",
+      "    sample_time_ms: 5753.664\n",
+      "    update_time_ms: 33.135\n",
+      "  timestamp: 1604231958\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2426880\n",
+      "  training_iteration: 15\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     15 |          309.672 | 2426880 |  43.4974 |              46.8571 |              15.7347 |            105.503 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1283.4805964052287\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_11-59-39\n",
+      "  done: false\n",
+      "  episode_len_mean: 105.19265905383361\n",
+      "  episode_reward_max: 46.857142857142904\n",
+      "  episode_reward_mean: 43.70432092086426\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1598\n",
+      "  episodes_total: 24520\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.6296272675196329\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.0055771675348902745\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009812832868192345\n",
+      "        total_loss: 0.3527320822079976\n",
+      "        vf_explained_var: 0.9965917468070984\n",
+      "        vf_loss: 0.3617442895968755\n",
+      "    num_steps_sampled: 2588672\n",
+      "    num_steps_trained: 2588672\n",
+      "  iterations_since_restore: 16\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.162500000000005\n",
+      "    gpu_util_percent0: 0.42416666666666664\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.570833333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1515236024097143\n",
+      "    mean_env_wait_ms: 0.6494728987544927\n",
+      "    mean_inference_ms: 4.213501380549204\n",
+      "    mean_raw_obs_processing_ms: 0.3932868129355243\n",
+      "  time_since_restore: 330.0610761642456\n",
+      "  time_this_iter_s: 20.388765573501587\n",
+      "  time_total_s: 330.0610761642456\n",
+      "  timers:\n",
+      "    learn_throughput: 11058.672\n",
+      "    learn_time_ms: 14630.328\n",
+      "    sample_throughput: 28143.68\n",
+      "    sample_time_ms: 5748.786\n",
+      "    update_time_ms: 32.726\n",
+      "  timestamp: 1604231979\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2588672\n",
+      "  training_iteration: 16\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     16 |          330.061 | 2588672 |  43.7043 |              46.8571 |              15.7347 |            105.193 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1279.8473329245862\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_12-00-00\n",
+      "  done: false\n",
+      "  episode_len_mean: 104.910927456382\n",
+      "  episode_reward_max: 46.857142857142904\n",
+      "  episode_reward_mean: 43.890595815920484\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1616\n",
+      "  episodes_total: 26136\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.5843918571869532\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005636528095540901\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009946482673209781\n",
+      "        total_loss: 0.2803831646839778\n",
+      "        vf_explained_var: 0.9972963333129883\n",
+      "        vf_loss: 0.28949454923470813\n",
+      "    num_steps_sampled: 2750464\n",
+      "    num_steps_trained: 2750464\n",
+      "  iterations_since_restore: 17\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.984\n",
+      "    gpu_util_percent0: 0.36920000000000003\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15123654271663214\n",
+      "    mean_env_wait_ms: 0.6494373187304042\n",
+      "    mean_inference_ms: 4.199623866436883\n",
+      "    mean_raw_obs_processing_ms: 0.3923463354120984\n",
+      "  time_since_restore: 350.56322145462036\n",
+      "  time_this_iter_s: 20.502145290374756\n",
+      "  time_total_s: 350.56322145462036\n",
+      "  timers:\n",
+      "    learn_throughput: 11060.535\n",
+      "    learn_time_ms: 14627.863\n",
+      "    sample_throughput: 28221.412\n",
+      "    sample_time_ms: 5732.952\n",
+      "    update_time_ms: 40.383\n",
+      "  timestamp: 1604232000\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2750464\n",
+      "  training_iteration: 17\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     17 |          350.563 | 2750464 |  43.8906 |              46.8571 |              15.7347 |            104.911 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1276.563322872705\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_12-00-21\n",
+      "  done: false\n",
+      "  episode_len_mean: 104.65475633036776\n",
+      "  episode_reward_max: 46.857142857142904\n",
+      "  episode_reward_mean: 44.05809376302477\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1627\n",
+      "  episodes_total: 27763\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.5512450536092123\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.0052360318368300796\n",
+      "        model: {}\n",
+      "        policy_loss: -0.00858212105807373\n",
+      "        total_loss: 0.2300113836924235\n",
+      "        vf_explained_var: 0.997800350189209\n",
+      "        vf_loss: 0.2378219154973825\n",
+      "    num_steps_sampled: 2912256\n",
+      "    num_steps_trained: 2912256\n",
+      "  iterations_since_restore: 18\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.133333333333336\n",
+      "    gpu_util_percent0: 0.3545833333333333\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5749999999999997\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15097539441634178\n",
+      "    mean_env_wait_ms: 0.649425583111441\n",
+      "    mean_inference_ms: 4.186930579711764\n",
+      "    mean_raw_obs_processing_ms: 0.3914892612304368\n",
+      "  time_since_restore: 371.091876745224\n",
+      "  time_this_iter_s: 20.528655290603638\n",
+      "  time_total_s: 371.091876745224\n",
+      "  timers:\n",
+      "    learn_throughput: 11066.918\n",
+      "    learn_time_ms: 14619.428\n",
+      "    sample_throughput: 28359.109\n",
+      "    sample_time_ms: 5705.116\n",
+      "    update_time_ms: 40.411\n",
+      "  timestamp: 1604232021\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2912256\n",
+      "  training_iteration: 18\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     18 |          371.092 | 2912256 |  44.0581 |              46.8571 |              15.7347 |            104.655 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1273.6519278628166\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_12-00-43\n",
+      "  done: false\n",
+      "  episode_len_mean: 104.42508426105607\n",
+      "  episode_reward_max: 46.857142857142904\n",
+      "  episode_reward_mean: 44.20715088200534\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1610\n",
+      "  episodes_total: 29373\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.525387316942215\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.004920089112905164\n",
+      "        model: {}\n",
+      "        policy_loss: -0.008422184953815304\n",
+      "        total_loss: 0.1757721391816934\n",
+      "        vf_explained_var: 0.9983048439025879\n",
+      "        vf_loss: 0.1834729996820291\n",
+      "    num_steps_sampled: 3074048\n",
+      "    num_steps_trained: 3074048\n",
+      "  iterations_since_restore: 19\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.212000000000003\n",
+      "    gpu_util_percent0: 0.336\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15073736984322064\n",
+      "    mean_env_wait_ms: 0.649427266881627\n",
+      "    mean_inference_ms: 4.175450336968136\n",
+      "    mean_raw_obs_processing_ms: 0.3907110068982923\n",
+      "  time_since_restore: 391.7044517993927\n",
+      "  time_this_iter_s: 20.6125750541687\n",
+      "  time_total_s: 391.7044517993927\n",
+      "  timers:\n",
+      "    learn_throughput: 11052.788\n",
+      "    learn_time_ms: 14638.117\n",
+      "    sample_throughput: 28425.972\n",
+      "    sample_time_ms: 5691.696\n",
+      "    update_time_ms: 45.734\n",
+      "  timestamp: 1604232043\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3074048\n",
+      "  training_iteration: 19\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     19 |          391.704 | 3074048 |  44.2072 |              46.8571 |              15.7347 |            104.425 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1271.0431296475913\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_12-01-04\n",
+      "  done: false\n",
+      "  episode_len_mean: 104.21682273167582\n",
+      "  episode_reward_max: 46.857142857142904\n",
+      "  episode_reward_mean: 44.34093230446844\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1597\n",
+      "  episodes_total: 30970\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.49314410984516144\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005798064754344523\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009414856787770987\n",
+      "        total_loss: 0.13895704535146555\n",
+      "        vf_explained_var: 0.9986486434936523\n",
+      "        vf_loss: 0.1480386642118295\n",
+      "    num_steps_sampled: 3235840\n",
+      "    num_steps_trained: 3235840\n",
+      "  iterations_since_restore: 20\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.116666666666664\n",
+      "    gpu_util_percent0: 0.35833333333333334\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5749999999999997\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15052181952677304\n",
+      "    mean_env_wait_ms: 0.649438443211961\n",
+      "    mean_inference_ms: 4.164995515225137\n",
+      "    mean_raw_obs_processing_ms: 0.3900008446460127\n",
+      "  time_since_restore: 412.16121435165405\n",
+      "  time_this_iter_s: 20.456762552261353\n",
+      "  time_total_s: 412.16121435165405\n",
+      "  timers:\n",
+      "    learn_throughput: 11057.384\n",
+      "    learn_time_ms: 14632.032\n",
+      "    sample_throughput: 28470.363\n",
+      "    sample_time_ms: 5682.822\n",
+      "    update_time_ms: 44.871\n",
+      "  timestamp: 1604232064\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3235840\n",
+      "  training_iteration: 20\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     20 |          412.161 | 3235840 |  44.3409 |              46.8571 |              15.7347 |            104.217 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1268.6647814593964\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_12-01-24\n",
+      "  done: false\n",
+      "  episode_len_mean: 104.02566464051084\n",
+      "  episode_reward_max: 46.857142857142904\n",
+      "  episode_reward_mean: 44.4626028897468\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1604\n",
+      "  episodes_total: 32574\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.46102594832579297\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005838079610839486\n",
+      "        model: {}\n",
+      "        policy_loss: -0.00808940147787022\n",
+      "        total_loss: 0.11789208464324474\n",
+      "        vf_explained_var: 0.9988470077514648\n",
+      "        vf_loss: 0.12562819197773933\n",
+      "    num_steps_sampled: 3397632\n",
+      "    num_steps_trained: 3397632\n",
+      "  iterations_since_restore: 21\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.463999999999995\n",
+      "    gpu_util_percent0: 0.3728\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5679999999999996\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15032141681707573\n",
+      "    mean_env_wait_ms: 0.6494592765291238\n",
+      "    mean_inference_ms: 4.155300920389142\n",
+      "    mean_raw_obs_processing_ms: 0.3893410843403339\n",
+      "  time_since_restore: 432.50473642349243\n",
+      "  time_this_iter_s: 20.34352207183838\n",
+      "  time_total_s: 432.50473642349243\n",
+      "  timers:\n",
+      "    learn_throughput: 11057.81\n",
+      "    learn_time_ms: 14631.468\n",
+      "    sample_throughput: 28523.95\n",
+      "    sample_time_ms: 5672.146\n",
+      "    update_time_ms: 46.215\n",
+      "  timestamp: 1604232084\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3397632\n",
+      "  training_iteration: 21\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     21 |          432.505 | 3397632 |  44.4626 |              46.8571 |              15.7347 |            104.026 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1266.4863559173157\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_12-01-46\n",
+      "  done: false\n",
+      "  episode_len_mean: 103.8470199450196\n",
+      "  episode_reward_max: 46.857142857142904\n",
+      "  episode_reward_mean: 44.57447720270771\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1620\n",
+      "  episodes_total: 34194\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.43294235815604526\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005431869920964043\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009014388362023359\n",
+      "        total_loss: 0.08529840596020222\n",
+      "        vf_explained_var: 0.9991478323936462\n",
+      "        vf_loss: 0.09398608033855756\n",
+      "    num_steps_sampled: 3559424\n",
+      "    num_steps_trained: 3559424\n",
+      "  iterations_since_restore: 22\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.592\n",
+      "    gpu_util_percent0: 0.35\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.572\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1501333983360748\n",
+      "    mean_env_wait_ms: 0.6494934869624449\n",
+      "    mean_inference_ms: 4.146224608744544\n",
+      "    mean_raw_obs_processing_ms: 0.3887246826845676\n",
+      "  time_since_restore: 453.3322539329529\n",
+      "  time_this_iter_s: 20.82751750946045\n",
+      "  time_total_s: 453.3322539329529\n",
+      "  timers:\n",
+      "    learn_throughput: 11039.758\n",
+      "    learn_time_ms: 14655.394\n",
+      "    sample_throughput: 28584.579\n",
+      "    sample_time_ms: 5660.115\n",
+      "    update_time_ms: 47.568\n",
+      "  timestamp: 1604232106\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3559424\n",
+      "  training_iteration: 22\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     22 |          453.332 | 3559424 |  44.5745 |              46.8571 |              15.7347 |            103.847 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1264.481222756231\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_12-02-07\n",
+      "  done: false\n",
+      "  episode_len_mean: 103.68064083956682\n",
+      "  episode_reward_max: 46.857142857142904\n",
+      "  episode_reward_mean: 44.67719666296796\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1634\n",
+      "  episodes_total: 35828\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.4028966749707858\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.0056398319235692424\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010392234045866644\n",
+      "        total_loss: 0.08119491549829642\n",
+      "        vf_explained_var: 0.9991843700408936\n",
+      "        vf_loss: 0.0912246151516835\n",
+      "    num_steps_sampled: 3721216\n",
+      "    num_steps_trained: 3721216\n",
+      "  iterations_since_restore: 23\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.024999999999995\n",
+      "    gpu_util_percent0: 0.36624999999999996\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5749999999999997\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.14995601669875397\n",
+      "    mean_env_wait_ms: 0.6495352227224097\n",
+      "    mean_inference_ms: 4.137711997351269\n",
+      "    mean_raw_obs_processing_ms: 0.38814230126504\n",
+      "  time_since_restore: 473.85256695747375\n",
+      "  time_this_iter_s: 20.520313024520874\n",
+      "  time_total_s: 473.85256695747375\n",
+      "  timers:\n",
+      "    learn_throughput: 11045.845\n",
+      "    learn_time_ms: 14647.318\n",
+      "    sample_throughput: 28580.616\n",
+      "    sample_time_ms: 5660.9\n",
+      "    update_time_ms: 49.009\n",
+      "  timestamp: 1604232127\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3721216\n",
+      "  training_iteration: 23\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     23 |          473.853 | 3721216 |  44.6772 |              46.8571 |              15.7347 |            103.681 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1262.6683067707777\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_12-02-28\n",
+      "  done: false\n",
+      "  episode_len_mean: 103.53063895715354\n",
+      "  episode_reward_max: 46.857142857142904\n",
+      "  episode_reward_mean: 44.77006117651676\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1608\n",
+      "  episodes_total: 37436\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.3745071937640508\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005321652473260959\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007234078652497071\n",
+      "        total_loss: 0.05749547202140093\n",
+      "        vf_explained_var: 0.9994208812713623\n",
+      "        vf_loss: 0.06438463802138965\n",
+      "    num_steps_sampled: 3883008\n",
+      "    num_steps_trained: 3883008\n",
+      "  iterations_since_restore: 24\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.864\n",
+      "    gpu_util_percent0: 0.39199999999999996\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.14979390065628823\n",
+      "    mean_env_wait_ms: 0.649588420666768\n",
+      "    mean_inference_ms: 4.1299192587977664\n",
+      "    mean_raw_obs_processing_ms: 0.38760946260698614\n",
+      "  time_since_restore: 494.24922704696655\n",
+      "  time_this_iter_s: 20.396660089492798\n",
+      "  time_total_s: 494.24922704696655\n",
+      "  timers:\n",
+      "    learn_throughput: 11054.341\n",
+      "    learn_time_ms: 14636.061\n",
+      "    sample_throughput: 28685.318\n",
+      "    sample_time_ms: 5640.237\n",
+      "    update_time_ms: 42.265\n",
+      "  timestamp: 1604232148\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3883008\n",
+      "  training_iteration: 24\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "2020-11-01 12:02:29,652\tWARNING util.py:136 -- The `process_trial` operation took 0.5228226184844971 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     24 |          494.249 | 3883008 |  44.7701 |              46.8571 |              15.7347 |            103.531 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1261.0109236371095\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_12-02-50\n",
+      "  done: false\n",
+      "  episode_len_mean: 103.39151595880936\n",
+      "  episode_reward_max: 46.857142857142904\n",
+      "  episode_reward_mean: 44.854644767892296\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1602\n",
+      "  episodes_total: 39038\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.3481475959221522\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.004828551318496466\n",
+      "        model: {}\n",
+      "        policy_loss: -0.0070124387663478656\n",
+      "        total_loss: 0.06740419659763575\n",
+      "        vf_explained_var: 0.9993410706520081\n",
+      "        vf_loss: 0.07410785431663196\n",
+      "    num_steps_sampled: 4044800\n",
+      "    num_steps_trained: 4044800\n",
+      "  iterations_since_restore: 25\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.944000000000003\n",
+      "    gpu_util_percent0: 0.3452\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5679999999999996\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.14964195104865902\n",
+      "    mean_env_wait_ms: 0.6496402901027807\n",
+      "    mean_inference_ms: 4.122656867380491\n",
+      "    mean_raw_obs_processing_ms: 0.3871109943323948\n",
+      "  time_since_restore: 514.7466752529144\n",
+      "  time_this_iter_s: 20.497448205947876\n",
+      "  time_total_s: 514.7466752529144\n",
+      "  timers:\n",
+      "    learn_throughput: 11049.552\n",
+      "    learn_time_ms: 14642.403\n",
+      "    sample_throughput: 28661.043\n",
+      "    sample_time_ms: 5645.014\n",
+      "    update_time_ms: 44.89\n",
+      "  timestamp: 1604232170\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4044800\n",
+      "  training_iteration: 25\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "2020-11-01 12:02:51,023\tWARNING util.py:136 -- The `process_trial` operation took 0.5479519367218018 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     25 |          514.747 | 4044800 |  44.8546 |              46.8571 |              15.7347 |            103.392 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1259.4838947990543\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_12-03-11\n",
+      "  done: false\n",
+      "  episode_len_mean: 103.26077543790592\n",
+      "  episode_reward_max: 46.857142857142904\n",
+      "  episode_reward_mean: 44.933213572774115\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1610\n",
+      "  episodes_total: 40648\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.05000000000000001\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.32285959521929425\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005153231516790886\n",
+      "        model: {}\n",
+      "        policy_loss: -0.006437089536727096\n",
+      "        total_loss: 0.04760071821510792\n",
+      "        vf_explained_var: 0.9995192885398865\n",
+      "        vf_loss: 0.05394157860428095\n",
+      "    num_steps_sampled: 4206592\n",
+      "    num_steps_trained: 4206592\n",
+      "  iterations_since_restore: 26\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.183333333333334\n",
+      "    gpu_util_percent0: 0.30583333333333335\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.570833333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.14949842842548025\n",
+      "    mean_env_wait_ms: 0.6496982049535759\n",
+      "    mean_inference_ms: 4.115822249881849\n",
+      "    mean_raw_obs_processing_ms: 0.3866408622949027\n",
+      "  time_since_restore: 535.2055022716522\n",
+      "  time_this_iter_s: 20.458827018737793\n",
+      "  time_total_s: 535.2055022716522\n",
+      "  timers:\n",
+      "    learn_throughput: 11044.133\n",
+      "    learn_time_ms: 14649.588\n",
+      "    sample_throughput: 28693.76\n",
+      "    sample_time_ms: 5638.578\n",
+      "    update_time_ms: 44.672\n",
+      "  timestamp: 1604232191\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4206592\n",
+      "  training_iteration: 26\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "2020-11-01 12:03:12,271\tWARNING util.py:136 -- The `process_trial` operation took 0.5345759391784668 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     26 |          535.206 | 4206592 |  44.9332 |              46.8571 |              15.7347 |            103.261 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1258.0401912516568\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_12-03-32\n",
+      "  done: false\n",
+      "  episode_len_mean: 103.137958758986\n",
+      "  episode_reward_max: 46.857142857142904\n",
+      "  episode_reward_mean: 45.007320067641125\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1640\n",
+      "  episodes_total: 42288\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.05000000000000001\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.2982073624928792\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.004597992869094014\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007848733845700432\n",
+      "        total_loss: 0.03614849457517266\n",
+      "        vf_explained_var: 0.9996141791343689\n",
+      "        vf_loss: 0.043916432497402035\n",
+      "    num_steps_sampled: 4368384\n",
+      "    num_steps_trained: 4368384\n",
+      "  iterations_since_restore: 27\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.736\n",
+      "    gpu_util_percent0: 0.4024000000000001\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.14936013846680316\n",
+      "    mean_env_wait_ms: 0.6497567301190108\n",
+      "    mean_inference_ms: 4.109265721932972\n",
+      "    mean_raw_obs_processing_ms: 0.38618524014647837\n",
+      "  time_since_restore: 555.6780240535736\n",
+      "  time_this_iter_s: 20.472521781921387\n",
+      "  time_total_s: 555.6780240535736\n",
+      "  timers:\n",
+      "    learn_throughput: 11047.092\n",
+      "    learn_time_ms: 14645.664\n",
+      "    sample_throughput: 28676.643\n",
+      "    sample_time_ms: 5641.943\n",
+      "    update_time_ms: 36.998\n",
+      "  timestamp: 1604232212\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4368384\n",
+      "  training_iteration: 27\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "2020-11-01 12:03:33,510\tWARNING util.py:136 -- The `process_trial` operation took 0.567908525466919 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     27 |          555.678 | 4368384 |  45.0073 |              46.8571 |              15.7347 |            103.138 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1256.7130644903914\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_12-03-53\n",
+      "  done: false\n",
+      "  episode_len_mean: 103.02484797412713\n",
+      "  episode_reward_max: 46.857142857142904\n",
+      "  episode_reward_mean: 45.07519232440738\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1619\n",
+      "  episodes_total: 43907\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.025000000000000005\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.27154965202013653\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.004386523951931546\n",
+      "        model: {}\n",
+      "        policy_loss: -0.006109707096281151\n",
+      "        total_loss: 0.029498847822348278\n",
+      "        vf_explained_var: 0.9996840357780457\n",
+      "        vf_loss: 0.03563466699173053\n",
+      "    num_steps_sampled: 4530176\n",
+      "    num_steps_trained: 4530176\n",
+      "  iterations_since_restore: 28\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.215999999999998\n",
+      "    gpu_util_percent0: 0.35719999999999996\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5679999999999996\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.14923164336873793\n",
+      "    mean_env_wait_ms: 0.6498215067723312\n",
+      "    mean_inference_ms: 4.103192802934885\n",
+      "    mean_raw_obs_processing_ms: 0.3857616555198185\n",
+      "  time_since_restore: 576.108469247818\n",
+      "  time_this_iter_s: 20.430445194244385\n",
+      "  time_total_s: 576.108469247818\n",
+      "  timers:\n",
+      "    learn_throughput: 11053.539\n",
+      "    learn_time_ms: 14637.122\n",
+      "    sample_throughput: 28704.812\n",
+      "    sample_time_ms: 5636.407\n",
+      "    update_time_ms: 34.761\n",
+      "  timestamp: 1604232233\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4530176\n",
+      "  training_iteration: 28\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "2020-11-01 12:03:54,833\tWARNING util.py:136 -- The `process_trial` operation took 0.5623390674591064 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     28 |          576.108 | 4530176 |  45.0752 |              46.8571 |              15.7347 |            103.025 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1255.498240520806\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_12-04-15\n",
+      "  done: false\n",
+      "  episode_len_mean: 102.92078315900501\n",
+      "  episode_reward_max: 46.857142857142904\n",
+      "  episode_reward_mean: 45.13765263071036\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1601\n",
+      "  episodes_total: 45508\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.012500000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.25443976496656734\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.004423999693244696\n",
+      "        model: {}\n",
+      "        policy_loss: -0.005417319412420814\n",
+      "        total_loss: 0.024296301572273176\n",
+      "        vf_explained_var: 0.9997418522834778\n",
+      "        vf_loss: 0.02978554057578246\n",
+      "    num_steps_sampled: 4691968\n",
+      "    num_steps_trained: 4691968\n",
+      "  iterations_since_restore: 29\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.112\n",
+      "    gpu_util_percent0: 0.33520000000000005\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5679999999999996\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1491126560484596\n",
+      "    mean_env_wait_ms: 0.6498944683718904\n",
+      "    mean_inference_ms: 4.097513752031446\n",
+      "    mean_raw_obs_processing_ms: 0.38536978766235913\n",
+      "  time_since_restore: 596.6098058223724\n",
+      "  time_this_iter_s: 20.501336574554443\n",
+      "  time_total_s: 596.6098058223724\n",
+      "  timers:\n",
+      "    learn_throughput: 11066.443\n",
+      "    learn_time_ms: 14620.054\n",
+      "    sample_throughput: 28671.129\n",
+      "    sample_time_ms: 5643.029\n",
+      "    update_time_ms: 27.975\n",
+      "  timestamp: 1604232255\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4691968\n",
+      "  training_iteration: 29\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "2020-11-01 12:04:16,277\tWARNING util.py:136 -- The `process_trial` operation took 0.5899343490600586 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     29 |           596.61 | 4691968 |  45.1377 |              46.8571 |              15.7347 |            102.921 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1254.3588893845729\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_12-04-36\n",
+      "  done: true\n",
+      "  episode_len_mean: 102.82308492348184\n",
+      "  episode_reward_max: 46.857142857142904\n",
+      "  episode_reward_mean: 45.196090857543105\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1605\n",
+      "  episodes_total: 47113\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.006250000000000001\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.23119975750645003\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.004294859090199073\n",
+      "        model: {}\n",
+      "        policy_loss: -0.006582304151379503\n",
+      "        total_loss: 0.016346099126773577\n",
+      "        vf_explained_var: 0.9998031258583069\n",
+      "        vf_loss: 0.02301716012880206\n",
+      "    num_steps_sampled: 4853760\n",
+      "    num_steps_trained: 4853760\n",
+      "  iterations_since_restore: 30\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.433333333333334\n",
+      "    gpu_util_percent0: 0.3558333333333333\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.570833333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1489996674476156\n",
+      "    mean_env_wait_ms: 0.6499679628512286\n",
+      "    mean_inference_ms: 4.0921381946019215\n",
+      "    mean_raw_obs_processing_ms: 0.38499719572571234\n",
+      "  time_since_restore: 616.9446895122528\n",
+      "  time_this_iter_s: 20.33488368988037\n",
+      "  time_total_s: 616.9446895122528\n",
+      "  timers:\n",
+      "    learn_throughput: 11076.785\n",
+      "    learn_time_ms: 14606.404\n",
+      "    sample_throughput: 28687.763\n",
+      "    sample_time_ms: 5639.757\n",
+      "    update_time_ms: 27.238\n",
+      "  timestamp: 1604232276\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4853760\n",
+      "  training_iteration: 30\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "2020-11-01 12:04:37,528\tWARNING util.py:136 -- The `process_trial` operation took 0.6967248916625977 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 24.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | TERMINATED |       |     30 |          616.945 | 4853760 |  45.1961 |              46.8571 |              15.7347 |            102.823 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "== Status ==\n",
+      "Memory usage on this node: 24.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | TERMINATED |       |     30 |          616.945 | 4853760 |  45.1961 |              46.8571 |              15.7347 |            102.823 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 20006\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201101_115353-kqo0l7if/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201101_115353-kqo0l7if/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 1222\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 645\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1604232278\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 1737\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 1254.35889\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 46.85714\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 15.73469\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 45.19609\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 47113\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 30\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mmisty-sweep-1\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/kqo0l7if\u001b[0m\n",
+      "2020-11-01 12:04:48,722 - wandb.wandb_agent - INFO - Cleaning up finished run: kqo0l7if\n",
+      "2020-11-01 12:04:49,030 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-11-01 12:04:49,030 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tinstance_path: /JSS/JSS/env/instances/la/la12.txt\n",
+      "2020-11-01 12:04:49,033 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --instance_path=/JSS/JSS/env/instances/la/la12.txt\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.8 is available!  To upgrade, please run:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
+      "2020-11-01 12:04:54,049 - wandb.wandb_agent - INFO - Running runs: ['tkx2xsoj']\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdecent-sweep-2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/sweeps/9xhkl8my\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/tkx2xsoj\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201101_120450-tkx2xsoj\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
+      "\n",
+      "2020-11-01 12:04:54,756\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
+      "== Status ==\n",
+      "Memory usage on this node: 12.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  |       |\n",
+      "+-------------------------+----------+-------+\n",
+      "\n",
+      "\n",
+      "\u001b[2m\u001b[36m(pid=52265)\u001b[0m 2020-11-01 12:04:57,569\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=52167)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52167)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52239)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52239)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52176)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52176)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52249)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52249)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52260)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52260)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52258)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52258)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52169)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52169)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52253)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52253)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52221)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52221)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52215)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52215)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52275)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52275)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52158)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52158)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52224)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52224)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52256)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52256)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52219)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52219)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52231)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52231)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52262)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52262)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52209)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52209)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52236)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52236)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52151)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52151)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52269)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52269)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52220)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52220)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52161)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52161)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52156)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52156)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52229)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52229)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52153)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52153)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52279)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52279)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52267)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52267)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52243)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52243)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52172)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52172)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52235)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52235)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52154)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52154)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52233)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52233)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52164)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52164)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52250)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52250)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52202)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52202)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52166)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52166)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52242)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52242)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52150)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52150)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52225)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52225)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52148)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52148)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52162)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52162)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52163)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52163)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52149)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52149)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52177)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52177)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52261)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52261)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52155)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52155)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52157)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52157)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52270)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52270)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52234)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52234)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52173)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52173)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52181)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52181)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52230)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52230)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52168)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52168)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52218)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52218)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52223)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52223)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52171)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52171)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52180)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52180)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52228)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52228)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52251)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52251)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52226)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52226)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52216)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52216)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52184)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52184)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52237)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52237)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52227)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52227)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52206)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52206)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52259)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52259)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52152)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52152)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52273)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52273)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52212)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52212)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52204)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52204)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52247)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52247)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52165)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52165)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52222)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52222)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52257)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52257)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52147)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52147)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52277)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52277)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52255)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52255)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52160)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52160)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1270.6712550607288\n",
+      "    time_step_min: 1054\n",
+      "  date: 2020-11-01_12-05-25\n",
+      "  done: false\n",
+      "  episode_len_mean: 116.74350904799371\n",
+      "  episode_reward_max: 41.65306122448979\n",
+      "  episode_reward_mean: 30.6028275983879\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1271\n",
+      "  episodes_total: 1271\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1384523808956146\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006007326611628135\n",
+      "        model: {}\n",
+      "        policy_loss: -0.006815222654646884\n",
+      "        total_loss: 36.897240002950035\n",
+      "        vf_explained_var: 0.7482123374938965\n",
+      "        vf_loss: 36.903422355651855\n",
+      "    num_steps_sampled: 161792\n",
+      "    num_steps_trained: 161792\n",
+      "  iterations_since_restore: 1\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 32.62222222222222\n",
+      "    gpu_util_percent0: 0.40222222222222226\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.4333333333333336\n",
+      "    vram_util_percent0: 0.08172381958869332\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16969461340934525\n",
+      "    mean_env_wait_ms: 0.6709388448442125\n",
+      "    mean_inference_ms: 5.213710332296094\n",
+      "    mean_raw_obs_processing_ms: 0.4500044725167772\n",
+      "  time_since_restore: 22.275667190551758\n",
+      "  time_this_iter_s: 22.275667190551758\n",
+      "  time_total_s: 22.275667190551758\n",
+      "  timers:\n",
+      "    learn_throughput: 11194.703\n",
+      "    learn_time_ms: 14452.55\n",
+      "    sample_throughput: 20900.055\n",
+      "    sample_time_ms: 7741.224\n",
+      "    update_time_ms: 42.347\n",
+      "  timestamp: 1604232325\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 161792\n",
+      "  training_iteration: 1\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |      1 |          22.2757 | 161792 |  30.6028 |              41.6531 |              10.2755 |            116.744 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1252.1281568036186\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-05-46\n",
+      "  done: false\n",
+      "  episode_len_mean: 116.04722945332837\n",
+      "  episode_reward_max: 42.41836734693876\n",
+      "  episode_reward_mean: 31.48901419995294\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1418\n",
+      "  episodes_total: 2689\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1159119109312694\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.010711442679166794\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012819082303982062\n",
+      "        total_loss: 9.95718256632487\n",
+      "        vf_explained_var: 0.8801858425140381\n",
+      "        vf_loss: 9.968417485555014\n",
+      "    num_steps_sampled: 323584\n",
+      "    num_steps_trained: 323584\n",
+      "  iterations_since_restore: 2\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.4\n",
+      "    gpu_util_percent0: 0.3830769230769231\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5076923076923077\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1663996838490878\n",
+      "    mean_env_wait_ms: 0.6661199624654368\n",
+      "    mean_inference_ms: 5.065247663215141\n",
+      "    mean_raw_obs_processing_ms: 0.443431096131331\n",
+      "  time_since_restore: 43.45249390602112\n",
+      "  time_this_iter_s: 21.17682671546936\n",
+      "  time_total_s: 43.45249390602112\n",
+      "  timers:\n",
+      "    learn_throughput: 11200.574\n",
+      "    learn_time_ms: 14444.974\n",
+      "    sample_throughput: 22507.211\n",
+      "    sample_time_ms: 7188.452\n",
+      "    update_time_ms: 40.119\n",
+      "  timestamp: 1604232346\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 323584\n",
+      "  training_iteration: 2\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.5/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |      2 |          43.4525 | 323584 |   31.489 |              42.4184 |              10.2755 |            116.047 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1229.5523227383862\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-06-06\n",
+      "  done: false\n",
+      "  episode_len_mean: 114.94789142026175\n",
+      "  episode_reward_max: 42.41836734693877\n",
+      "  episode_reward_mean: 32.67046455033783\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1437\n",
+      "  episodes_total: 4126\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0916709005832672\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.011045165204753479\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012844632374860035\n",
+      "        total_loss: 6.921001553535461\n",
+      "        vf_explained_var: 0.9159042239189148\n",
+      "        vf_loss: 6.9321829080581665\n",
+      "    num_steps_sampled: 485376\n",
+      "    num_steps_trained: 485376\n",
+      "  iterations_since_restore: 3\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 28.06\n",
+      "    gpu_util_percent0: 0.4312\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.516\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16376589972908362\n",
+      "    mean_env_wait_ms: 0.6617033666285996\n",
+      "    mean_inference_ms: 4.920294910569432\n",
+      "    mean_raw_obs_processing_ms: 0.43664206722952675\n",
+      "  time_since_restore: 63.84919023513794\n",
+      "  time_this_iter_s: 20.39669632911682\n",
+      "  time_total_s: 63.84919023513794\n",
+      "  timers:\n",
+      "    learn_throughput: 11232.084\n",
+      "    learn_time_ms: 14404.451\n",
+      "    sample_throughput: 23846.064\n",
+      "    sample_time_ms: 6784.851\n",
+      "    update_time_ms: 37.748\n",
+      "  timestamp: 1604232366\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 485376\n",
+      "  training_iteration: 3\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |      3 |          63.8492 | 485376 |  32.6705 |              42.4184 |              10.2755 |            114.948 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1208.264137437366\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-06-27\n",
+      "  done: false\n",
+      "  episode_len_mean: 113.67087482219061\n",
+      "  episode_reward_max: 42.41836734693879\n",
+      "  episode_reward_mean: 33.766906406944\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1498\n",
+      "  episodes_total: 5624\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.064699391523997\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.010414493580659231\n",
+      "        model: {}\n",
+      "        policy_loss: -0.015563213809703788\n",
+      "        total_loss: 5.088392059008281\n",
+      "        vf_explained_var: 0.9388461709022522\n",
+      "        vf_loss: 5.102404753367106\n",
+      "    num_steps_sampled: 647168\n",
+      "    num_steps_trained: 647168\n",
+      "  iterations_since_restore: 4\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.656000000000002\n",
+      "    gpu_util_percent0: 0.4268\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5120000000000005\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16163926361569136\n",
+      "    mean_env_wait_ms: 0.6582592695889212\n",
+      "    mean_inference_ms: 4.803322913432019\n",
+      "    mean_raw_obs_processing_ms: 0.43060689585891204\n",
+      "  time_since_restore: 84.06805443763733\n",
+      "  time_this_iter_s: 20.21886420249939\n",
+      "  time_total_s: 84.06805443763733\n",
+      "  timers:\n",
+      "    learn_throughput: 11266.122\n",
+      "    learn_time_ms: 14360.931\n",
+      "    sample_throughput: 24659.344\n",
+      "    sample_time_ms: 6561.083\n",
+      "    update_time_ms: 34.947\n",
+      "  timestamp: 1604232387\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 647168\n",
+      "  training_iteration: 4\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |      4 |          84.0681 | 647168 |  33.7669 |              42.4184 |              10.2755 |            113.671 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1189.914229193161\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-06-47\n",
+      "  done: false\n",
+      "  episode_len_mean: 112.46028398706594\n",
+      "  episode_reward_max: 42.4183673469388\n",
+      "  episode_reward_mean: 34.71768564026201\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1489\n",
+      "  episodes_total: 7113\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0440024832884471\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.009285129917164644\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013422702313012755\n",
+      "        total_loss: 3.5668797492980957\n",
+      "        vf_explained_var: 0.956657886505127\n",
+      "        vf_loss: 3.5789673924446106\n",
+      "    num_steps_sampled: 808960\n",
+      "    num_steps_trained: 808960\n",
+      "  iterations_since_restore: 5\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.128\n",
+      "    gpu_util_percent0: 0.3836\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.508\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15996949149852113\n",
+      "    mean_env_wait_ms: 0.6557683164407656\n",
+      "    mean_inference_ms: 4.714004318455946\n",
+      "    mean_raw_obs_processing_ms: 0.42569876525023526\n",
+      "  time_since_restore: 104.25618076324463\n",
+      "  time_this_iter_s: 20.1881263256073\n",
+      "  time_total_s: 104.25618076324463\n",
+      "  timers:\n",
+      "    learn_throughput: 11286.122\n",
+      "    learn_time_ms: 14335.482\n",
+      "    sample_throughput: 25221.502\n",
+      "    sample_time_ms: 6414.844\n",
+      "    update_time_ms: 36.706\n",
+      "  timestamp: 1604232407\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 808960\n",
+      "  training_iteration: 5\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |      5 |          104.256 | 808960 |  34.7177 |              42.4184 |              10.2755 |             112.46 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1173.5402272200324\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-07-08\n",
+      "  done: false\n",
+      "  episode_len_mean: 111.30085430616485\n",
+      "  episode_reward_max: 42.4183673469388\n",
+      "  episode_reward_mean: 35.54994369024451\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1549\n",
+      "  episodes_total: 8662\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.00481882194678\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.00909763171027104\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013866825815057382\n",
+      "        total_loss: 2.7730772693951926\n",
+      "        vf_explained_var: 0.9670748114585876\n",
+      "        vf_loss: 2.785626987616221\n",
+      "    num_steps_sampled: 970752\n",
+      "    num_steps_trained: 970752\n",
+      "  iterations_since_restore: 6\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.65416666666667\n",
+      "    gpu_util_percent0: 0.4445833333333334\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5083333333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1585845452097359\n",
+      "    mean_env_wait_ms: 0.6539711743603752\n",
+      "    mean_inference_ms: 4.639796008274598\n",
+      "    mean_raw_obs_processing_ms: 0.4215553460221708\n",
+      "  time_since_restore: 124.31111264228821\n",
+      "  time_this_iter_s: 20.05493187904358\n",
+      "  time_total_s: 124.31111264228821\n",
+      "  timers:\n",
+      "    learn_throughput: 11300.348\n",
+      "    learn_time_ms: 14317.435\n",
+      "    sample_throughput: 25694.821\n",
+      "    sample_time_ms: 6296.677\n",
+      "    update_time_ms: 36.949\n",
+      "  timestamp: 1604232428\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 970752\n",
+      "  training_iteration: 6\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |      6 |          124.311 | 970752 |  35.5499 |              42.4184 |              10.2755 |            111.301 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1160.6071287908626\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-07-28\n",
+      "  done: false\n",
+      "  episode_len_mean: 110.30445447409733\n",
+      "  episode_reward_max: 42.41836734693881\n",
+      "  episode_reward_mean: 36.22964990548809\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1530\n",
+      "  episodes_total: 10192\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9723203877607981\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.008056929800659418\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013902826050374037\n",
+      "        total_loss: 2.177985966205597\n",
+      "        vf_explained_var: 0.9740824103355408\n",
+      "        vf_loss: 2.1907635927200317\n",
+      "    num_steps_sampled: 1132544\n",
+      "    num_steps_trained: 1132544\n",
+      "  iterations_since_restore: 7\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.691999999999997\n",
+      "    gpu_util_percent0: 0.4035999999999999\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.516\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15747431107692764\n",
+      "    mean_env_wait_ms: 0.652680726552872\n",
+      "    mean_inference_ms: 4.58049716107533\n",
+      "    mean_raw_obs_processing_ms: 0.4181133612914104\n",
+      "  time_since_restore: 144.8035752773285\n",
+      "  time_this_iter_s: 20.492462635040283\n",
+      "  time_total_s: 144.8035752773285\n",
+      "  timers:\n",
+      "    learn_throughput: 11282.551\n",
+      "    learn_time_ms: 14340.019\n",
+      "    sample_throughput: 25937.899\n",
+      "    sample_time_ms: 6237.668\n",
+      "    update_time_ms: 37.177\n",
+      "  timestamp: 1604232448\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1132544\n",
+      "  training_iteration: 7\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |      7 |          144.804 | 1132544 |  36.2296 |              42.4184 |              10.2755 |            110.304 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1148.888252883383\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-07-49\n",
+      "  done: false\n",
+      "  episode_len_mean: 109.45600885784856\n",
+      "  episode_reward_max: 42.41836734693881\n",
+      "  episode_reward_mean: 36.816230060715206\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1549\n",
+      "  episodes_total: 11741\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9466134955485662\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.007931554379562536\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013606403217030069\n",
+      "        total_loss: 1.6076118151346843\n",
+      "        vf_explained_var: 0.9807720184326172\n",
+      "        vf_loss: 1.6201052069664001\n",
+      "    num_steps_sampled: 1294336\n",
+      "    num_steps_trained: 1294336\n",
+      "  iterations_since_restore: 8\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.764000000000006\n",
+      "    gpu_util_percent0: 0.38\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5679999999999996\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15654498685345614\n",
+      "    mean_env_wait_ms: 0.6516967139634099\n",
+      "    mean_inference_ms: 4.530832158888852\n",
+      "    mean_raw_obs_processing_ms: 0.4150856418377815\n",
+      "  time_since_restore: 165.37314867973328\n",
+      "  time_this_iter_s: 20.569573402404785\n",
+      "  time_total_s: 165.37314867973328\n",
+      "  timers:\n",
+      "    learn_throughput: 11279.608\n",
+      "    learn_time_ms: 14343.761\n",
+      "    sample_throughput: 26039.205\n",
+      "    sample_time_ms: 6213.4\n",
+      "    update_time_ms: 37.773\n",
+      "  timestamp: 1604232469\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1294336\n",
+      "  training_iteration: 8\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |      8 |          165.373 | 1294336 |  36.8162 |              42.4184 |              10.2755 |            109.456 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1139.0165774998115\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-08-10\n",
+      "  done: false\n",
+      "  episode_len_mean: 108.7133839332682\n",
+      "  episode_reward_max: 42.41836734693881\n",
+      "  episode_reward_mean: 37.319474329147006\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1566\n",
+      "  episodes_total: 13307\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9164896359046301\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.007841601696175834\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011578070591591919\n",
+      "        total_loss: 1.2525162895520527\n",
+      "        vf_explained_var: 0.985228955745697\n",
+      "        vf_loss: 1.262984275817871\n",
+      "    num_steps_sampled: 1456128\n",
+      "    num_steps_trained: 1456128\n",
+      "  iterations_since_restore: 9\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.692000000000004\n",
+      "    gpu_util_percent0: 0.4428\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15575594110735325\n",
+      "    mean_env_wait_ms: 0.6509075806283173\n",
+      "    mean_inference_ms: 4.488645311807507\n",
+      "    mean_raw_obs_processing_ms: 0.41243497179424105\n",
+      "  time_since_restore: 185.73600935935974\n",
+      "  time_this_iter_s: 20.362860679626465\n",
+      "  time_total_s: 185.73600935935974\n",
+      "  timers:\n",
+      "    learn_throughput: 11283.252\n",
+      "    learn_time_ms: 14339.128\n",
+      "    sample_throughput: 26176.544\n",
+      "    sample_time_ms: 6180.801\n",
+      "    update_time_ms: 37.693\n",
+      "  timestamp: 1604232490\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1456128\n",
+      "  training_iteration: 9\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |      9 |          185.736 | 1456128 |  37.3195 |              42.4184 |              10.2755 |            108.713 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1130.5417816982022\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-08-30\n",
+      "  done: false\n",
+      "  episode_len_mean: 108.05662658695506\n",
+      "  episode_reward_max: 42.41836734693881\n",
+      "  episode_reward_mean: 37.75363452292987\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1580\n",
+      "  episodes_total: 14887\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.879222497344017\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.007466738965983192\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010042240721910881\n",
+      "        total_loss: 1.0435242255528767\n",
+      "        vf_explained_var: 0.9878211617469788\n",
+      "        vf_loss: 1.0525127152601879\n",
+      "    num_steps_sampled: 1617920\n",
+      "    num_steps_trained: 1617920\n",
+      "  iterations_since_restore: 10\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.332000000000004\n",
+      "    gpu_util_percent0: 0.3956\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15508348116310283\n",
+      "    mean_env_wait_ms: 0.6503758051109494\n",
+      "    mean_inference_ms: 4.452355943495541\n",
+      "    mean_raw_obs_processing_ms: 0.41015056238268827\n",
+      "  time_since_restore: 206.0984218120575\n",
+      "  time_this_iter_s: 20.362412452697754\n",
+      "  time_total_s: 206.0984218120575\n",
+      "  timers:\n",
+      "    learn_throughput: 11288.763\n",
+      "    learn_time_ms: 14332.129\n",
+      "    sample_throughput: 26298.441\n",
+      "    sample_time_ms: 6152.152\n",
+      "    update_time_ms: 42.189\n",
+      "  timestamp: 1604232510\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1617920\n",
+      "  training_iteration: 10\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     10 |          206.098 | 1617920 |  37.7536 |              42.4184 |              10.2755 |            108.057 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1123.1655117918795\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-08-51\n",
+      "  done: false\n",
+      "  episode_len_mean: 107.44680980106745\n",
+      "  episode_reward_max: 42.41836734693881\n",
+      "  episode_reward_mean: 38.12998569151096\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1601\n",
+      "  episodes_total: 16488\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.852480560541153\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006807499914430082\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010430590346610794\n",
+      "        total_loss: 0.7860654095808665\n",
+      "        vf_explained_var: 0.9908618927001953\n",
+      "        vf_loss: 0.7955607374509176\n",
+      "    num_steps_sampled: 1779712\n",
+      "    num_steps_trained: 1779712\n",
+      "  iterations_since_restore: 11\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.468000000000004\n",
+      "    gpu_util_percent0: 0.3796\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5679999999999996\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15448994642998015\n",
+      "    mean_env_wait_ms: 0.6499845600676837\n",
+      "    mean_inference_ms: 4.420542043950926\n",
+      "    mean_raw_obs_processing_ms: 0.408110786931221\n",
+      "  time_since_restore: 226.6547131538391\n",
+      "  time_this_iter_s: 20.556291341781616\n",
+      "  time_total_s: 226.6547131538391\n",
+      "  timers:\n",
+      "    learn_throughput: 11290.905\n",
+      "    learn_time_ms: 14329.409\n",
+      "    sample_throughput: 27104.621\n",
+      "    sample_time_ms: 5969.167\n",
+      "    update_time_ms: 41.488\n",
+      "  timestamp: 1604232531\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1779712\n",
+      "  training_iteration: 11\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     11 |          226.655 | 1779712 |    38.13 |              42.4184 |              10.2755 |            107.447 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1116.8649711879432\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-09-12\n",
+      "  done: false\n",
+      "  episode_len_mean: 106.92020570670206\n",
+      "  episode_reward_max: 42.41836734693881\n",
+      "  episode_reward_mean: 38.44685289510628\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1596\n",
+      "  episodes_total: 18084\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8233269800742468\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.00662518401319782\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011712064248664925\n",
+      "        total_loss: 0.6785962084929148\n",
+      "        vf_explained_var: 0.9921655654907227\n",
+      "        vf_loss: 0.6893948912620544\n",
+      "    num_steps_sampled: 1941504\n",
+      "    num_steps_trained: 1941504\n",
+      "  iterations_since_restore: 12\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.354166666666668\n",
+      "    gpu_util_percent0: 0.39875\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.570833333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15396759428958923\n",
+      "    mean_env_wait_ms: 0.6497269679106826\n",
+      "    mean_inference_ms: 4.392758580495196\n",
+      "    mean_raw_obs_processing_ms: 0.4063257369659057\n",
+      "  time_since_restore: 247.07435011863708\n",
+      "  time_this_iter_s: 20.419636964797974\n",
+      "  time_total_s: 247.07435011863708\n",
+      "  timers:\n",
+      "    learn_throughput: 11289.741\n",
+      "    learn_time_ms: 14330.887\n",
+      "    sample_throughput: 27482.894\n",
+      "    sample_time_ms: 5887.007\n",
+      "    update_time_ms: 40.889\n",
+      "  timestamp: 1604232552\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1941504\n",
+      "  training_iteration: 12\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     12 |          247.074 | 1941504 |  38.4469 |              42.4184 |              10.2755 |             106.92 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1111.391848572737\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-09-33\n",
+      "  done: false\n",
+      "  episode_len_mean: 106.44390268677942\n",
+      "  episode_reward_max: 42.418367346938815\n",
+      "  episode_reward_mean: 38.727613885718846\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1605\n",
+      "  episodes_total: 19689\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7883199751377106\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006895307102240622\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01035230930817003\n",
+      "        total_loss: 0.501528188586235\n",
+      "        vf_explained_var: 0.9942240118980408\n",
+      "        vf_loss: 0.5108955974380175\n",
+      "    num_steps_sampled: 2103296\n",
+      "    num_steps_trained: 2103296\n",
+      "  iterations_since_restore: 13\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.084\n",
+      "    gpu_util_percent0: 0.40480000000000005\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5679999999999996\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15350402726485754\n",
+      "    mean_env_wait_ms: 0.6495522826808918\n",
+      "    mean_inference_ms: 4.367981018992163\n",
+      "    mean_raw_obs_processing_ms: 0.40472308429202836\n",
+      "  time_since_restore: 267.40077471733093\n",
+      "  time_this_iter_s: 20.326424598693848\n",
+      "  time_total_s: 267.40077471733093\n",
+      "  timers:\n",
+      "    learn_throughput: 11287.514\n",
+      "    learn_time_ms: 14333.714\n",
+      "    sample_throughput: 27563.917\n",
+      "    sample_time_ms: 5869.703\n",
+      "    update_time_ms: 41.691\n",
+      "  timestamp: 1604232573\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2103296\n",
+      "  training_iteration: 13\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     13 |          267.401 | 2103296 |  38.7276 |              42.4184 |              10.2755 |            106.444 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1106.5129543424084\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-09-53\n",
+      "  done: false\n",
+      "  episode_len_mean: 106.01774397972116\n",
+      "  episode_reward_max: 42.418367346938815\n",
+      "  episode_reward_mean: 38.97570046184929\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1614\n",
+      "  episodes_total: 21303\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7583291182915369\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006845557557729383\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010322557670103075\n",
+      "        total_loss: 0.39304836342732113\n",
+      "        vf_explained_var: 0.9954751133918762\n",
+      "        vf_loss: 0.40238098055124283\n",
+      "    num_steps_sampled: 2265088\n",
+      "    num_steps_trained: 2265088\n",
+      "  iterations_since_restore: 14\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.124000000000002\n",
+      "    gpu_util_percent0: 0.4536\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15309019602292354\n",
+      "    mean_env_wait_ms: 0.6494461564466915\n",
+      "    mean_inference_ms: 4.34582608361679\n",
+      "    mean_raw_obs_processing_ms: 0.40327786899763196\n",
+      "  time_since_restore: 287.4316370487213\n",
+      "  time_this_iter_s: 20.03086233139038\n",
+      "  time_total_s: 287.4316370487213\n",
+      "  timers:\n",
+      "    learn_throughput: 11292.259\n",
+      "    learn_time_ms: 14327.692\n",
+      "    sample_throughput: 27660.58\n",
+      "    sample_time_ms: 5849.19\n",
+      "    update_time_ms: 42.894\n",
+      "  timestamp: 1604232593\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2265088\n",
+      "  training_iteration: 14\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     14 |          287.432 | 2265088 |  38.9757 |              42.4184 |              10.2755 |            106.018 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1102.2523617914626\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-10-14\n",
+      "  done: false\n",
+      "  episode_len_mean: 105.64558951965066\n",
+      "  episode_reward_max: 42.418367346938815\n",
+      "  episode_reward_mean: 39.19350548079495\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1597\n",
+      "  episodes_total: 22900\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7275536010662714\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006344522737587492\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01266244207120811\n",
+      "        total_loss: 0.31657364467779797\n",
+      "        vf_explained_var: 0.9963433742523193\n",
+      "        vf_loss: 0.32833095143238705\n",
+      "    num_steps_sampled: 2426880\n",
+      "    num_steps_trained: 2426880\n",
+      "  iterations_since_restore: 15\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.668000000000003\n",
+      "    gpu_util_percent0: 0.4212\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15272256161153888\n",
+      "    mean_env_wait_ms: 0.6493956761565493\n",
+      "    mean_inference_ms: 4.3261627778248455\n",
+      "    mean_raw_obs_processing_ms: 0.40199333508455115\n",
+      "  time_since_restore: 308.00055265426636\n",
+      "  time_this_iter_s: 20.568915605545044\n",
+      "  time_total_s: 308.00055265426636\n",
+      "  timers:\n",
+      "    learn_throughput: 11279.674\n",
+      "    learn_time_ms: 14343.677\n",
+      "    sample_throughput: 27657.34\n",
+      "    sample_time_ms: 5849.876\n",
+      "    update_time_ms: 42.541\n",
+      "  timestamp: 1604232614\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2426880\n",
+      "  training_iteration: 15\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     15 |          308.001 | 2426880 |  39.1935 |              42.4184 |              10.2755 |            105.646 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1098.492356115108\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-10-35\n",
+      "  done: false\n",
+      "  episode_len_mean: 105.31371428571428\n",
+      "  episode_reward_max: 42.418367346938815\n",
+      "  episode_reward_mean: 39.386209912536444\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1600\n",
+      "  episodes_total: 24500\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.6992116371790568\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.00605107715819031\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010152409401295396\n",
+      "        total_loss: 0.2749015986919403\n",
+      "        vf_explained_var: 0.9968383312225342\n",
+      "        vf_loss: 0.28419339408477146\n",
+      "    num_steps_sampled: 2588672\n",
+      "    num_steps_trained: 2588672\n",
+      "  iterations_since_restore: 16\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.163999999999998\n",
+      "    gpu_util_percent0: 0.4179999999999999\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1523902557025731\n",
+      "    mean_env_wait_ms: 0.6493845108910767\n",
+      "    mean_inference_ms: 4.308344642074162\n",
+      "    mean_raw_obs_processing_ms: 0.4008263717279235\n",
+      "  time_since_restore: 328.0859045982361\n",
+      "  time_this_iter_s: 20.085351943969727\n",
+      "  time_total_s: 328.0859045982361\n",
+      "  timers:\n",
+      "    learn_throughput: 11277.087\n",
+      "    learn_time_ms: 14346.967\n",
+      "    sample_throughput: 27688.425\n",
+      "    sample_time_ms: 5843.308\n",
+      "    update_time_ms: 42.686\n",
+      "  timestamp: 1604232635\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2588672\n",
+      "  training_iteration: 16\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     16 |          328.086 | 2588672 |  39.3862 |              42.4184 |              10.2755 |            105.314 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1095.0764746490756\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-10-55\n",
+      "  done: false\n",
+      "  episode_len_mean: 105.01325162772883\n",
+      "  episode_reward_max: 42.418367346938815\n",
+      "  episode_reward_mean: 39.561036900397845\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1610\n",
+      "  episodes_total: 26110\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.6637826611598333\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006695269180151324\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012259619931379953\n",
+      "        total_loss: 0.2071586512029171\n",
+      "        vf_explained_var: 0.9976064562797546\n",
+      "        vf_loss: 0.21841111406683922\n",
+      "    num_steps_sampled: 2750464\n",
+      "    num_steps_trained: 2750464\n",
+      "  iterations_since_restore: 17\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.967999999999996\n",
+      "    gpu_util_percent0: 0.3992\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15208441102089912\n",
+      "    mean_env_wait_ms: 0.649415271515101\n",
+      "    mean_inference_ms: 4.292010650770931\n",
+      "    mean_raw_obs_processing_ms: 0.3997617754479261\n",
+      "  time_since_restore: 348.3640911579132\n",
+      "  time_this_iter_s: 20.278186559677124\n",
+      "  time_total_s: 348.3640911579132\n",
+      "  timers:\n",
+      "    learn_throughput: 11280.385\n",
+      "    learn_time_ms: 14342.773\n",
+      "    sample_throughput: 27802.66\n",
+      "    sample_time_ms: 5819.299\n",
+      "    update_time_ms: 42.587\n",
+      "  timestamp: 1604232655\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2750464\n",
+      "  training_iteration: 17\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     17 |          348.364 | 2750464 |   39.561 |              42.4184 |              10.2755 |            105.013 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1091.992488262911\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-11-16\n",
+      "  done: false\n",
+      "  episode_len_mean: 104.74269638606363\n",
+      "  episode_reward_max: 42.41836734693882\n",
+      "  episode_reward_mean: 39.71753728541839\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1616\n",
+      "  episodes_total: 27726\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.6395211120446523\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005430514691397548\n",
+      "        model: {}\n",
+      "        policy_loss: -0.008808797846237818\n",
+      "        total_loss: 0.18516152476270994\n",
+      "        vf_explained_var: 0.9978885650634766\n",
+      "        vf_loss: 0.19320398072401682\n",
+      "    num_steps_sampled: 2912256\n",
+      "    num_steps_trained: 2912256\n",
+      "  iterations_since_restore: 18\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.428\n",
+      "    gpu_util_percent0: 0.4108\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15180253257231568\n",
+      "    mean_env_wait_ms: 0.6494706645035929\n",
+      "    mean_inference_ms: 4.277042903419588\n",
+      "    mean_raw_obs_processing_ms: 0.3987841767593947\n",
+      "  time_since_restore: 368.70942068099976\n",
+      "  time_this_iter_s: 20.345329523086548\n",
+      "  time_total_s: 368.70942068099976\n",
+      "  timers:\n",
+      "    learn_throughput: 11277.054\n",
+      "    learn_time_ms: 14347.01\n",
+      "    sample_throughput: 27960.312\n",
+      "    sample_time_ms: 5786.488\n",
+      "    update_time_ms: 42.249\n",
+      "  timestamp: 1604232676\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2912256\n",
+      "  training_iteration: 18\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     18 |          368.709 | 2912256 |  39.7175 |              42.4184 |              10.2755 |            104.743 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1089.2314356857796\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-11-37\n",
+      "  done: false\n",
+      "  episode_len_mean: 104.499846693694\n",
+      "  episode_reward_max: 42.41836734693882\n",
+      "  episode_reward_mean: 39.85814856041556\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1627\n",
+      "  episodes_total: 29353\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.6059375007947286\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006107187946327031\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009194978279992938\n",
+      "        total_loss: 0.15118268628915152\n",
+      "        vf_explained_var: 0.9982755184173584\n",
+      "        vf_loss: 0.15945919354756674\n",
+      "    num_steps_sampled: 3074048\n",
+      "    num_steps_trained: 3074048\n",
+      "  iterations_since_restore: 19\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.02\n",
+      "    gpu_util_percent0: 0.35119999999999996\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15154050336998873\n",
+      "    mean_env_wait_ms: 0.6495464583308167\n",
+      "    mean_inference_ms: 4.263205291197448\n",
+      "    mean_raw_obs_processing_ms: 0.39787967312168704\n",
+      "  time_since_restore: 389.13511419296265\n",
+      "  time_this_iter_s: 20.42569351196289\n",
+      "  time_total_s: 389.13511419296265\n",
+      "  timers:\n",
+      "    learn_throughput: 11265.913\n",
+      "    learn_time_ms: 14361.197\n",
+      "    sample_throughput: 28034.364\n",
+      "    sample_time_ms: 5771.203\n",
+      "    update_time_ms: 43.0\n",
+      "  timestamp: 1604232697\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3074048\n",
+      "  training_iteration: 19\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     19 |          389.135 | 3074048 |  39.8581 |              42.4184 |              10.2755 |              104.5 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1086.7530964007374\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-11-58\n",
+      "  done: false\n",
+      "  episode_len_mean: 104.28143673891276\n",
+      "  episode_reward_max: 42.41836734693883\n",
+      "  episode_reward_mean: 39.98449496404396\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1606\n",
+      "  episodes_total: 30959\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.5802051573991776\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006146465195342898\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010908293537795544\n",
+      "        total_loss: 0.12315286882221699\n",
+      "        vf_explained_var: 0.9985630512237549\n",
+      "        vf_loss: 0.13312197600801787\n",
+      "    num_steps_sampled: 3235840\n",
+      "    num_steps_trained: 3235840\n",
+      "  iterations_since_restore: 20\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.708000000000002\n",
+      "    gpu_util_percent0: 0.35119999999999996\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5679999999999996\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15130250937481887\n",
+      "    mean_env_wait_ms: 0.649629966463628\n",
+      "    mean_inference_ms: 4.25060756388231\n",
+      "    mean_raw_obs_processing_ms: 0.39705657157981417\n",
+      "  time_since_restore: 409.49588918685913\n",
+      "  time_this_iter_s: 20.360774993896484\n",
+      "  time_total_s: 409.49588918685913\n",
+      "  timers:\n",
+      "    learn_throughput: 11247.919\n",
+      "    learn_time_ms: 14384.172\n",
+      "    sample_throughput: 28152.747\n",
+      "    sample_time_ms: 5746.935\n",
+      "    update_time_ms: 38.327\n",
+      "  timestamp: 1604232718\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3235840\n",
+      "  training_iteration: 20\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     20 |          409.496 | 3235840 |  39.9845 |              42.4184 |              10.2755 |            104.281 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1084.4941429669484\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-12-19\n",
+      "  done: false\n",
+      "  episode_len_mean: 104.08316697890113\n",
+      "  episode_reward_max: 42.41836734693883\n",
+      "  episode_reward_mean: 40.09885276551578\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1602\n",
+      "  episodes_total: 32561\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.5567689687013626\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.0057975016146277385\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010689061540081942\n",
+      "        total_loss: 0.10724692543347676\n",
+      "        vf_explained_var: 0.9987431168556213\n",
+      "        vf_loss: 0.11705487407743931\n",
+      "    num_steps_sampled: 3397632\n",
+      "    num_steps_trained: 3397632\n",
+      "  iterations_since_restore: 21\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.752000000000002\n",
+      "    gpu_util_percent0: 0.2972\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5679999999999996\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15108181784508506\n",
+      "    mean_env_wait_ms: 0.6497188533760437\n",
+      "    mean_inference_ms: 4.2389675381303915\n",
+      "    mean_raw_obs_processing_ms: 0.3962976370894028\n",
+      "  time_since_restore: 429.649621963501\n",
+      "  time_this_iter_s: 20.153732776641846\n",
+      "  time_total_s: 429.649621963501\n",
+      "  timers:\n",
+      "    learn_throughput: 11259.927\n",
+      "    learn_time_ms: 14368.833\n",
+      "    sample_throughput: 28275.485\n",
+      "    sample_time_ms: 5721.988\n",
+      "    update_time_ms: 38.431\n",
+      "  timestamp: 1604232739\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3397632\n",
+      "  training_iteration: 21\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     21 |           429.65 | 3397632 |  40.0989 |              42.4184 |              10.2755 |            104.083 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1082.431136496778\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-12-40\n",
+      "  done: false\n",
+      "  episode_len_mean: 103.90098314606742\n",
+      "  episode_reward_max: 42.41836734693883\n",
+      "  episode_reward_mean: 40.20364481818009\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1615\n",
+      "  episodes_total: 34176\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.5254394511381785\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005307760516492029\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007776977017783793\n",
+      "        total_loss: 0.0964116957038641\n",
+      "        vf_explained_var: 0.9988983273506165\n",
+      "        vf_loss: 0.10338984616100788\n",
+      "    num_steps_sampled: 3559424\n",
+      "    num_steps_trained: 3559424\n",
+      "  iterations_since_restore: 22\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.846153846153847\n",
+      "    gpu_util_percent0: 0.39384615384615385\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.565384615384615\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15087377501627616\n",
+      "    mean_env_wait_ms: 0.6498094517683312\n",
+      "    mean_inference_ms: 4.22804968427196\n",
+      "    mean_raw_obs_processing_ms: 0.3955819072644963\n",
+      "  time_since_restore: 449.9894530773163\n",
+      "  time_this_iter_s: 20.339831113815308\n",
+      "  time_total_s: 449.9894530773163\n",
+      "  timers:\n",
+      "    learn_throughput: 11271.985\n",
+      "    learn_time_ms: 14353.461\n",
+      "    sample_throughput: 28273.456\n",
+      "    sample_time_ms: 5722.399\n",
+      "    update_time_ms: 39.023\n",
+      "  timestamp: 1604232760\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3559424\n",
+      "  training_iteration: 22\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     22 |          449.989 | 3559424 |  40.2036 |              42.4184 |              10.2755 |            103.901 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1080.5109731890743\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-13-01\n",
+      "  done: false\n",
+      "  episode_len_mean: 103.7305683563748\n",
+      "  episode_reward_max: 42.41836734693883\n",
+      "  episode_reward_mean: 40.301032520255696\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1629\n",
+      "  episodes_total: 35805\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.5021042550603548\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.0054971032465497656\n",
+      "        model: {}\n",
+      "        policy_loss: -0.00953363478280759\n",
+      "        total_loss: 0.06499722289542358\n",
+      "        vf_explained_var: 0.9992148876190186\n",
+      "        vf_loss: 0.07368248887360096\n",
+      "    num_steps_sampled: 3721216\n",
+      "    num_steps_trained: 3721216\n",
+      "  iterations_since_restore: 23\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.044\n",
+      "    gpu_util_percent0: 0.4084\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5679999999999996\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15067991150821478\n",
+      "    mean_env_wait_ms: 0.649905891759336\n",
+      "    mean_inference_ms: 4.2178278275443795\n",
+      "    mean_raw_obs_processing_ms: 0.39491348951426497\n",
+      "  time_since_restore: 470.5632412433624\n",
+      "  time_this_iter_s: 20.573788166046143\n",
+      "  time_total_s: 470.5632412433624\n",
+      "  timers:\n",
+      "    learn_throughput: 11273.798\n",
+      "    learn_time_ms: 14351.154\n",
+      "    sample_throughput: 28167.439\n",
+      "    sample_time_ms: 5743.937\n",
+      "    update_time_ms: 38.419\n",
+      "  timestamp: 1604232781\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3721216\n",
+      "  training_iteration: 23\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     23 |          470.563 | 3721216 |   40.301 |              42.4184 |              10.2755 |            103.731 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1078.7812073715463\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-13-22\n",
+      "  done: false\n",
+      "  episode_len_mean: 103.57635678593378\n",
+      "  episode_reward_max: 42.41836734693883\n",
+      "  episode_reward_mean: 40.38915989130335\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1618\n",
+      "  episodes_total: 37423\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.47640378028154373\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005069411902998884\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007647299599436034\n",
+      "        total_loss: 0.07074602444966634\n",
+      "        vf_explained_var: 0.9991908073425293\n",
+      "        vf_loss: 0.07761764402190845\n",
+      "    num_steps_sampled: 3883008\n",
+      "    num_steps_trained: 3883008\n",
+      "  iterations_since_restore: 24\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.191999999999997\n",
+      "    gpu_util_percent0: 0.3423999999999999\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5679999999999996\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1505016968490393\n",
+      "    mean_env_wait_ms: 0.6500103427408599\n",
+      "    mean_inference_ms: 4.208361564693216\n",
+      "    mean_raw_obs_processing_ms: 0.39429321916174187\n",
+      "  time_since_restore: 490.8706216812134\n",
+      "  time_this_iter_s: 20.307380437850952\n",
+      "  time_total_s: 490.8706216812134\n",
+      "  timers:\n",
+      "    learn_throughput: 11268.008\n",
+      "    learn_time_ms: 14358.528\n",
+      "    sample_throughput: 28090.142\n",
+      "    sample_time_ms: 5759.743\n",
+      "    update_time_ms: 37.55\n",
+      "  timestamp: 1604232802\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3883008\n",
+      "  training_iteration: 24\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "2020-11-01 12:13:23,494\tWARNING util.py:136 -- The `process_trial` operation took 0.5319008827209473 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     24 |          490.871 | 3883008 |  40.3892 |              42.4184 |              10.2755 |            103.576 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1077.1880225698897\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-13-43\n",
+      "  done: false\n",
+      "  episode_len_mean: 103.43532516783682\n",
+      "  episode_reward_max: 42.41836734693883\n",
+      "  episode_reward_mean: 40.4702521709755\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1603\n",
+      "  episodes_total: 39026\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.4569598063826561\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005172949323120217\n",
+      "        model: {}\n",
+      "        policy_loss: -0.008714882539303895\n",
+      "        total_loss: 0.04905764168749253\n",
+      "        vf_explained_var: 0.999389111995697\n",
+      "        vf_loss: 0.056966414054234825\n",
+      "    num_steps_sampled: 4044800\n",
+      "    num_steps_trained: 4044800\n",
+      "  iterations_since_restore: 25\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.62\n",
+      "    gpu_util_percent0: 0.41119999999999995\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5679999999999996\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15033752613342766\n",
+      "    mean_env_wait_ms: 0.6501147929596541\n",
+      "    mean_inference_ms: 4.199582565004314\n",
+      "    mean_raw_obs_processing_ms: 0.3937192610273736\n",
+      "  time_since_restore: 511.1436126232147\n",
+      "  time_this_iter_s: 20.272990942001343\n",
+      "  time_total_s: 511.1436126232147\n",
+      "  timers:\n",
+      "    learn_throughput: 11277.804\n",
+      "    learn_time_ms: 14346.056\n",
+      "    sample_throughput: 28126.832\n",
+      "    sample_time_ms: 5752.23\n",
+      "    update_time_ms: 37.351\n",
+      "  timestamp: 1604232823\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4044800\n",
+      "  training_iteration: 25\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "2020-11-01 12:13:44,581\tWARNING util.py:136 -- The `process_trial` operation took 0.5550427436828613 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     25 |          511.144 | 4044800 |  40.4703 |              42.4184 |              10.2755 |            103.435 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1075.718860070445\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-14-04\n",
+      "  done: false\n",
+      "  episode_len_mean: 103.30375292235757\n",
+      "  episode_reward_max: 42.41836734693883\n",
+      "  episode_reward_mean: 40.545045112914124\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1609\n",
+      "  episodes_total: 40635\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.4321967264016469\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.0049026469544818\n",
+      "        model: {}\n",
+      "        policy_loss: -0.00738874361559283\n",
+      "        total_loss: 0.0522269361341993\n",
+      "        vf_explained_var: 0.9993705749511719\n",
+      "        vf_loss: 0.058851247653365135\n",
+      "    num_steps_sampled: 4206592\n",
+      "    num_steps_trained: 4206592\n",
+      "  iterations_since_restore: 26\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.028000000000002\n",
+      "    gpu_util_percent0: 0.35119999999999996\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5679999999999996\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15018377726680818\n",
+      "    mean_env_wait_ms: 0.650226839982744\n",
+      "    mean_inference_ms: 4.191307577339299\n",
+      "    mean_raw_obs_processing_ms: 0.39318264874410647\n",
+      "  time_since_restore: 531.2994961738586\n",
+      "  time_this_iter_s: 20.15588355064392\n",
+      "  time_total_s: 531.2994961738586\n",
+      "  timers:\n",
+      "    learn_throughput: 11281.716\n",
+      "    learn_time_ms: 14341.08\n",
+      "    sample_throughput: 28095.697\n",
+      "    sample_time_ms: 5758.604\n",
+      "    update_time_ms: 36.136\n",
+      "  timestamp: 1604232844\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4206592\n",
+      "  training_iteration: 26\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "2020-11-01 12:14:05,496\tWARNING util.py:136 -- The `process_trial` operation took 0.5645184516906738 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     26 |          531.299 | 4206592 |   40.545 |              42.4184 |              10.2755 |            103.304 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1074.3374860851236\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-14-26\n",
+      "  done: false\n",
+      "  episode_len_mean: 103.18162671273399\n",
+      "  episode_reward_max: 42.41836734693883\n",
+      "  episode_reward_mean: 40.61544301559989\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1622\n",
+      "  episodes_total: 42257\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.41156937927007675\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005988262050474684\n",
+      "        model: {}\n",
+      "        policy_loss: -0.0108474350903028\n",
+      "        total_loss: 0.03666358132613823\n",
+      "        vf_explained_var: 0.9995186924934387\n",
+      "        vf_loss: 0.04711797585090002\n",
+      "    num_steps_sampled: 4368384\n",
+      "    num_steps_trained: 4368384\n",
+      "  iterations_since_restore: 27\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.450000000000003\n",
+      "    gpu_util_percent0: 0.37384615384615383\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.565384615384615\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15003777931603987\n",
+      "    mean_env_wait_ms: 0.6503388710349208\n",
+      "    mean_inference_ms: 4.1834680864066325\n",
+      "    mean_raw_obs_processing_ms: 0.39267008619808885\n",
+      "  time_since_restore: 551.8160552978516\n",
+      "  time_this_iter_s: 20.51655912399292\n",
+      "  time_total_s: 551.8160552978516\n",
+      "  timers:\n",
+      "    learn_throughput: 11287.466\n",
+      "    learn_time_ms: 14333.775\n",
+      "    sample_throughput: 28001.168\n",
+      "    sample_time_ms: 5778.045\n",
+      "    update_time_ms: 35.1\n",
+      "  timestamp: 1604232866\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4368384\n",
+      "  training_iteration: 27\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "2020-11-01 12:14:26,878\tWARNING util.py:136 -- The `process_trial` operation took 0.603750467300415 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     27 |          551.816 | 4368384 |  40.6154 |              42.4184 |              10.2755 |            103.182 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1073.064150513113\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-14-47\n",
+      "  done: false\n",
+      "  episode_len_mean: 103.0678804174452\n",
+      "  episode_reward_max: 42.41836734693883\n",
+      "  episode_reward_mean: 40.68016949294415\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1629\n",
+      "  episodes_total: 43886\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.38193487375974655\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.0054754362208768725\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007502093746249254\n",
+      "        total_loss: 0.052860286086797714\n",
+      "        vf_explained_var: 0.999366819858551\n",
+      "        vf_loss: 0.06000580328206221\n",
+      "    num_steps_sampled: 4530176\n",
+      "    num_steps_trained: 4530176\n",
+      "  iterations_since_restore: 28\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.916000000000004\n",
+      "    gpu_util_percent0: 0.35960000000000003\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1498996451948512\n",
+      "    mean_env_wait_ms: 0.6504529892483883\n",
+      "    mean_inference_ms: 4.176045627745146\n",
+      "    mean_raw_obs_processing_ms: 0.3921857888681881\n",
+      "  time_since_restore: 572.0441946983337\n",
+      "  time_this_iter_s: 20.228139400482178\n",
+      "  time_total_s: 572.0441946983337\n",
+      "  timers:\n",
+      "    learn_throughput: 11297.604\n",
+      "    learn_time_ms: 14320.912\n",
+      "    sample_throughput: 28005.61\n",
+      "    sample_time_ms: 5777.128\n",
+      "    update_time_ms: 32.987\n",
+      "  timestamp: 1604232887\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4530176\n",
+      "  training_iteration: 28\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "2020-11-01 12:14:47,924\tWARNING util.py:136 -- The `process_trial` operation took 0.6126041412353516 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     28 |          572.044 | 4530176 |  40.6802 |              42.4184 |              10.2755 |            103.068 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1071.8849808631385\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-15-08\n",
+      "  done: false\n",
+      "  episode_len_mean: 102.9628774891204\n",
+      "  episode_reward_max: 42.41836734693883\n",
+      "  episode_reward_mean: 40.74035570973741\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1612\n",
+      "  episodes_total: 45498\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.3544607609510422\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005010240633661549\n",
+      "        model: {}\n",
+      "        policy_loss: -0.006979774484837738\n",
+      "        total_loss: 0.030745272990316153\n",
+      "        vf_explained_var: 0.999602735042572\n",
+      "        vf_loss: 0.037401253978411354\n",
+      "    num_steps_sampled: 4691968\n",
+      "    num_steps_trained: 4691968\n",
+      "  iterations_since_restore: 29\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.657692307692308\n",
+      "    gpu_util_percent0: 0.32384615384615384\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.565384615384615\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1497713859875804\n",
+      "    mean_env_wait_ms: 0.650569464769825\n",
+      "    mean_inference_ms: 4.169137947749732\n",
+      "    mean_raw_obs_processing_ms: 0.39173452138746384\n",
+      "  time_since_restore: 592.6739168167114\n",
+      "  time_this_iter_s: 20.629722118377686\n",
+      "  time_total_s: 592.6739168167114\n",
+      "  timers:\n",
+      "    learn_throughput: 11299.681\n",
+      "    learn_time_ms: 14318.28\n",
+      "    sample_throughput: 27922.916\n",
+      "    sample_time_ms: 5794.237\n",
+      "    update_time_ms: 30.389\n",
+      "  timestamp: 1604232908\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4691968\n",
+      "  training_iteration: 29\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "2020-11-01 12:15:09,523\tWARNING util.py:136 -- The `process_trial` operation took 0.6120882034301758 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     29 |          592.674 | 4691968 |  40.7404 |              42.4184 |              10.2755 |            102.963 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1070.7854881546798\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-15-29\n",
+      "  done: true\n",
+      "  episode_len_mean: 102.86573533470627\n",
+      "  episode_reward_max: 42.41836734693883\n",
+      "  episode_reward_mean: 40.79621711744931\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1603\n",
+      "  episodes_total: 47101\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.3281017740567525\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005293768752987186\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007335715092873822\n",
+      "        total_loss: 0.022672869653130572\n",
+      "        vf_explained_var: 0.9996854662895203\n",
+      "        vf_loss: 0.029643258700768154\n",
+      "    num_steps_sampled: 4853760\n",
+      "    num_steps_trained: 4853760\n",
+      "  iterations_since_restore: 30\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.851999999999997\n",
+      "    gpu_util_percent0: 0.41879999999999995\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1496498957417332\n",
+      "    mean_env_wait_ms: 0.6506846363524779\n",
+      "    mean_inference_ms: 4.162635555621303\n",
+      "    mean_raw_obs_processing_ms: 0.39130720698712607\n",
+      "  time_since_restore: 613.0474860668182\n",
+      "  time_this_iter_s: 20.37356925010681\n",
+      "  time_total_s: 613.0474860668182\n",
+      "  timers:\n",
+      "    learn_throughput: 11310.582\n",
+      "    learn_time_ms: 14304.481\n",
+      "    sample_throughput: 27887.371\n",
+      "    sample_time_ms: 5801.623\n",
+      "    update_time_ms: 30.76\n",
+      "  timestamp: 1604232929\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4853760\n",
+      "  training_iteration: 30\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "2020-11-01 12:15:30,803\tWARNING util.py:136 -- The `process_trial` operation took 0.6821863651275635 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 24.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | TERMINATED |       |     30 |          613.047 | 4853760 |  40.7962 |              42.4184 |              10.2755 |            102.866 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "== Status ==\n",
+      "Memory usage on this node: 24.1/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | TERMINATED |       |     30 |          613.047 | 4853760 |  40.7962 |              42.4184 |              10.2755 |            102.866 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 52047\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201101_120450-tkx2xsoj/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201101_120450-tkx2xsoj/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 1039\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 641\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1604232931\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 1669\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 1070.78549\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 42.41837\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 10.27551\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 40.79622\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 47101\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 30\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mdecent-sweep-2\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/tkx2xsoj\u001b[0m\n",
+      "2020-11-01 12:15:40,799 - wandb.wandb_agent - INFO - Cleaning up finished run: tkx2xsoj\n",
+      "2020-11-01 12:15:41,119 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-11-01 12:15:41,119 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tinstance_path: /JSS/JSS/env/instances/la/la13.txt\n",
+      "2020-11-01 12:15:41,121 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --instance_path=/JSS/JSS/env/instances/la/la13.txt\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.8 is available!  To upgrade, please run:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
+      "2020-11-01 12:15:46,139 - wandb.wandb_agent - INFO - Running runs: ['dcx4y6ut']\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdaily-sweep-3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/sweeps/9xhkl8my\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/dcx4y6ut\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201101_121542-dcx4y6ut\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
+      "\n",
+      "2020-11-01 12:15:46,749\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
+      "== Status ==\n",
+      "Memory usage on this node: 12.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  |       |\n",
+      "+-------------------------+----------+-------+\n",
+      "\n",
+      "\n",
+      "\u001b[2m\u001b[36m(pid=2614)\u001b[0m 2020-11-01 12:15:49,495\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=2570)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2570)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2590)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2590)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2557)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2557)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2589)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2589)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2599)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2599)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2591)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2591)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2583)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2583)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2625)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2625)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2573)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2573)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2595)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2595)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2597)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2597)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2587)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2587)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2582)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2582)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2621)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2621)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2600)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2600)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2615)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2615)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2594)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2594)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2527)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2527)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2554)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2554)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2526)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2526)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2560)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2560)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2561)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2561)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2562)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2562)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2511)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2511)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2556)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2556)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2501)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2501)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2553)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2553)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2520)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2520)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2571)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2571)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2612)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2612)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2508)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2508)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2493)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2493)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2565)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2565)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2605)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2605)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2566)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2566)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2506)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2506)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2518)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2518)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2502)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2502)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2503)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2503)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2507)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2507)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2576)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2576)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2567)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2567)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2610)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2610)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2487)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2487)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2603)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2603)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2488)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2488)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2492)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2492)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2497)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2497)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2552)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2552)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2504)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2504)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2563)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2563)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2500)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2500)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2558)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2558)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2555)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2555)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2496)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2496)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2579)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2579)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2564)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2564)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2523)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2523)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2598)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2598)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2524)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2524)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2572)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2572)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2551)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2551)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2505)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2505)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2592)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2592)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2514)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2514)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2498)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2498)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2580)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2580)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2495)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2495)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2568)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2568)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2490)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2490)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2602)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2602)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2569)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2569)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2489)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2489)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2491)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2491)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2559)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2559)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2517)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2517)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2509)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2509)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2596)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2596)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2577)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2577)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1589\n",
+      "    time_step_mean: 1337.9852140077821\n",
+      "    time_step_min: 1155\n",
+      "  date: 2020-11-01_12-16-16\n",
+      "  done: false\n",
+      "  episode_len_mean: 114.43149129447389\n",
+      "  episode_reward_max: 47.39175257731958\n",
+      "  episode_reward_mean: 38.01323583352193\n",
+      "  episode_reward_min: 22.08247422680411\n",
+      "  episodes_this_iter: 1321\n",
+      "  episodes_total: 1321\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1485573450724285\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005282467735620837\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007238074458048989\n",
+      "        total_loss: 63.078263918558754\n",
+      "        vf_explained_var: 0.7385819554328918\n",
+      "        vf_loss: 63.0850191116333\n",
+      "    num_steps_sampled: 161792\n",
+      "    num_steps_trained: 161792\n",
+      "  iterations_since_restore: 1\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 30.44814814814815\n",
+      "    gpu_util_percent0: 0.3718518518518519\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.4370370370370376\n",
+      "    vram_util_percent0: 0.08366130971903357\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16663877415658362\n",
+      "    mean_env_wait_ms: 0.6660098682308551\n",
+      "    mean_inference_ms: 4.715280418736184\n",
+      "    mean_raw_obs_processing_ms: 0.42943359101439976\n",
+      "  time_since_restore: 21.794464588165283\n",
+      "  time_this_iter_s: 21.794464588165283\n",
+      "  time_total_s: 21.794464588165283\n",
+      "  timers:\n",
+      "    learn_throughput: 11044.835\n",
+      "    learn_time_ms: 14648.658\n",
+      "    sample_throughput: 22922.781\n",
+      "    sample_time_ms: 7058.131\n",
+      "    update_time_ms: 38.538\n",
+      "  timestamp: 1604232976\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 161792\n",
+      "  training_iteration: 1\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |      1 |          21.7945 | 161792 |  38.0132 |              47.3918 |              22.0825 |            114.431 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1326.7179115300942\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-16-37\n",
+      "  done: false\n",
+      "  episode_len_mean: 113.38081603435934\n",
+      "  episode_reward_max: 47.64948453608249\n",
+      "  episode_reward_mean: 38.63342287228155\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1473\n",
+      "  episodes_total: 2794\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1314232647418976\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.009286719684799513\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01014851212191085\n",
+      "        total_loss: 10.35303783416748\n",
+      "        vf_explained_var: 0.901028573513031\n",
+      "        vf_loss: 10.361894766489664\n",
+      "    num_steps_sampled: 323584\n",
+      "    num_steps_trained: 323584\n",
+      "  iterations_since_restore: 2\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 30.084615384615383\n",
+      "    gpu_util_percent0: 0.4496153846153846\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5076923076923077\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16450090814338433\n",
+      "    mean_env_wait_ms: 0.6642577249066655\n",
+      "    mean_inference_ms: 4.744188369781305\n",
+      "    mean_raw_obs_processing_ms: 0.42877125861262844\n",
+      "  time_since_restore: 43.1419882774353\n",
+      "  time_this_iter_s: 21.34752368927002\n",
+      "  time_total_s: 43.1419882774353\n",
+      "  timers:\n",
+      "    learn_throughput: 11211.024\n",
+      "    learn_time_ms: 14431.51\n",
+      "    sample_throughput: 23059.328\n",
+      "    sample_time_ms: 7016.336\n",
+      "    update_time_ms: 41.882\n",
+      "  timestamp: 1604232997\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 323584\n",
+      "  training_iteration: 2\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.5/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |      2 |           43.142 | 323584 |  38.6334 |              47.6495 |              21.2577 |            113.381 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1309.3502958579882\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-16-58\n",
+      "  done: false\n",
+      "  episode_len_mean: 112.32527575686458\n",
+      "  episode_reward_max: 47.64948453608249\n",
+      "  episode_reward_mean: 39.48478286641973\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1467\n",
+      "  episodes_total: 4261\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1132993400096893\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.010391402058303356\n",
+      "        model: {}\n",
+      "        policy_loss: -0.014095689790944258\n",
+      "        total_loss: 6.80802857875824\n",
+      "        vf_explained_var: 0.9351071715354919\n",
+      "        vf_loss: 6.820602655410767\n",
+      "    num_steps_sampled: 485376\n",
+      "    num_steps_trained: 485376\n",
+      "  iterations_since_restore: 3\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 28.832000000000004\n",
+      "    gpu_util_percent0: 0.4172\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5120000000000005\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16256613873280876\n",
+      "    mean_env_wait_ms: 0.6625184290389695\n",
+      "    mean_inference_ms: 4.69345067144062\n",
+      "    mean_raw_obs_processing_ms: 0.4260658546666288\n",
+      "  time_since_restore: 63.90490484237671\n",
+      "  time_this_iter_s: 20.762916564941406\n",
+      "  time_total_s: 63.90490484237671\n",
+      "  timers:\n",
+      "    learn_throughput: 11227.805\n",
+      "    learn_time_ms: 14409.94\n",
+      "    sample_throughput: 23883.846\n",
+      "    sample_time_ms: 6774.118\n",
+      "    update_time_ms: 41.076\n",
+      "  timestamp: 1604233018\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 485376\n",
+      "  training_iteration: 3\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.5/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |      3 |          63.9049 | 485376 |  39.4848 |              47.6495 |              21.2577 |            112.325 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1293.2727912706794\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-17-19\n",
+      "  done: false\n",
+      "  episode_len_mean: 111.25918153200419\n",
+      "  episode_reward_max: 47.649484536082525\n",
+      "  episode_reward_mean: 40.30362789959723\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1457\n",
+      "  episodes_total: 5718\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.084079662958781\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.009383795782923698\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013835826587940877\n",
+      "        total_loss: 4.933180093765259\n",
+      "        vf_explained_var: 0.9529300332069397\n",
+      "        vf_loss: 4.94568133354187\n",
+      "    num_steps_sampled: 647168\n",
+      "    num_steps_trained: 647168\n",
+      "  iterations_since_restore: 4\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.936\n",
+      "    gpu_util_percent0: 0.4576\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.508\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16088212665214047\n",
+      "    mean_env_wait_ms: 0.660815453354488\n",
+      "    mean_inference_ms: 4.632879361030093\n",
+      "    mean_raw_obs_processing_ms: 0.42268288067938126\n",
+      "  time_since_restore: 84.33310127258301\n",
+      "  time_this_iter_s: 20.4281964302063\n",
+      "  time_total_s: 84.33310127258301\n",
+      "  timers:\n",
+      "    learn_throughput: 11238.354\n",
+      "    learn_time_ms: 14396.415\n",
+      "    sample_throughput: 24616.712\n",
+      "    sample_time_ms: 6572.446\n",
+      "    update_time_ms: 38.648\n",
+      "  timestamp: 1604233039\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 647168\n",
+      "  training_iteration: 4\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |      4 |          84.3331 | 647168 |  40.3036 |              47.6495 |              21.2577 |            111.259 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1278.2911882694702\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-17-39\n",
+      "  done: false\n",
+      "  episode_len_mean: 110.2100481761872\n",
+      "  episode_reward_max: 47.649484536082525\n",
+      "  episode_reward_mean: 41.07122129117859\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1547\n",
+      "  episodes_total: 7265\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0668250819047291\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.008654051227495074\n",
+      "        model: {}\n",
+      "        policy_loss: -0.015438533756726732\n",
+      "        total_loss: 3.750304361184438\n",
+      "        vf_explained_var: 0.9650198817253113\n",
+      "        vf_loss: 3.764545480410258\n",
+      "    num_steps_sampled: 808960\n",
+      "    num_steps_trained: 808960\n",
+      "  iterations_since_restore: 5\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.02\n",
+      "    gpu_util_percent0: 0.3504\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5120000000000005\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1594046299420155\n",
+      "    mean_env_wait_ms: 0.6591918943938871\n",
+      "    mean_inference_ms: 4.572498944569763\n",
+      "    mean_raw_obs_processing_ms: 0.4190994577823986\n",
+      "  time_since_restore: 104.45204615592957\n",
+      "  time_this_iter_s: 20.118944883346558\n",
+      "  time_total_s: 104.45204615592957\n",
+      "  timers:\n",
+      "    learn_throughput: 11259.021\n",
+      "    learn_time_ms: 14369.989\n",
+      "    sample_throughput: 25254.408\n",
+      "    sample_time_ms: 6406.486\n",
+      "    update_time_ms: 37.632\n",
+      "  timestamp: 1604233059\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 808960\n",
+      "  training_iteration: 5\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |      5 |          104.452 | 808960 |  41.0712 |              47.6495 |              21.2577 |             110.21 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1266.0983158852982\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-18-00\n",
+      "  done: false\n",
+      "  episode_len_mean: 109.32014959202176\n",
+      "  episode_reward_max: 47.649484536082525\n",
+      "  episode_reward_mean: 41.69816035928256\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1559\n",
+      "  episodes_total: 8824\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.034409632285436\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.008218800959487757\n",
+      "        model: {}\n",
+      "        policy_loss: -0.015976834343746305\n",
+      "        total_loss: 3.275542378425598\n",
+      "        vf_explained_var: 0.9698309898376465\n",
+      "        vf_loss: 3.2903926372528076\n",
+      "    num_steps_sampled: 970752\n",
+      "    num_steps_trained: 970752\n",
+      "  iterations_since_restore: 6\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.4375\n",
+      "    gpu_util_percent0: 0.43624999999999997\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5208333333333335\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15817094139921792\n",
+      "    mean_env_wait_ms: 0.6579144407066476\n",
+      "    mean_inference_ms: 4.520312188626085\n",
+      "    mean_raw_obs_processing_ms: 0.41585575516420453\n",
+      "  time_since_restore: 124.74504113197327\n",
+      "  time_this_iter_s: 20.2929949760437\n",
+      "  time_total_s: 124.74504113197327\n",
+      "  timers:\n",
+      "    learn_throughput: 11268.321\n",
+      "    learn_time_ms: 14358.128\n",
+      "    sample_throughput: 25609.299\n",
+      "    sample_time_ms: 6317.705\n",
+      "    update_time_ms: 37.615\n",
+      "  timestamp: 1604233080\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 970752\n",
+      "  training_iteration: 6\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |      6 |          124.745 | 970752 |  41.6982 |              47.6495 |              21.2577 |             109.32 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1255.5475730032877\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-18-20\n",
+      "  done: false\n",
+      "  episode_len_mean: 108.51175563692426\n",
+      "  episode_reward_max: 47.649484536082525\n",
+      "  episode_reward_mean: 42.23890644960692\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1554\n",
+      "  episodes_total: 10378\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9993852277596792\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.008948890104268989\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011871834401972592\n",
+      "        total_loss: 2.572846511999766\n",
+      "        vf_explained_var: 0.9761440753936768\n",
+      "        vf_loss: 2.5834282437960305\n",
+      "    num_steps_sampled: 1132544\n",
+      "    num_steps_trained: 1132544\n",
+      "  iterations_since_restore: 7\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.36\n",
+      "    gpu_util_percent0: 0.3956\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5120000000000005\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15713379589800733\n",
+      "    mean_env_wait_ms: 0.6568649191044983\n",
+      "    mean_inference_ms: 4.475812919755018\n",
+      "    mean_raw_obs_processing_ms: 0.4129610571474045\n",
+      "  time_since_restore: 144.9028398990631\n",
+      "  time_this_iter_s: 20.157798767089844\n",
+      "  time_total_s: 144.9028398990631\n",
+      "  timers:\n",
+      "    learn_throughput: 11276.333\n",
+      "    learn_time_ms: 14347.927\n",
+      "    sample_throughput: 25944.994\n",
+      "    sample_time_ms: 6235.962\n",
+      "    update_time_ms: 37.126\n",
+      "  timestamp: 1604233100\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1132544\n",
+      "  training_iteration: 7\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |      7 |          144.903 | 1132544 |  42.2389 |              47.6495 |              21.2577 |            108.512 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1246.681210592686\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-18-41\n",
+      "  done: false\n",
+      "  episode_len_mean: 107.82323359316068\n",
+      "  episode_reward_max: 47.649484536082525\n",
+      "  episode_reward_mean: 42.700832190594205\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1553\n",
+      "  episodes_total: 11931\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9713874608278275\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.00811462321629127\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013652926543727517\n",
+      "        total_loss: 2.0792956252892814\n",
+      "        vf_explained_var: 0.9808939099311829\n",
+      "        vf_loss: 2.0918113390604653\n",
+      "    num_steps_sampled: 1294336\n",
+      "    num_steps_trained: 1294336\n",
+      "  iterations_since_restore: 8\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.708000000000002\n",
+      "    gpu_util_percent0: 0.412\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.52\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15626045608420333\n",
+      "    mean_env_wait_ms: 0.6560445478078366\n",
+      "    mean_inference_ms: 4.437668893602004\n",
+      "    mean_raw_obs_processing_ms: 0.41044660220855933\n",
+      "  time_since_restore: 165.08657550811768\n",
+      "  time_this_iter_s: 20.183735609054565\n",
+      "  time_total_s: 165.08657550811768\n",
+      "  timers:\n",
+      "    learn_throughput: 11297.099\n",
+      "    learn_time_ms: 14321.553\n",
+      "    sample_throughput: 26119.381\n",
+      "    sample_time_ms: 6194.327\n",
+      "    update_time_ms: 35.89\n",
+      "  timestamp: 1604233121\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1294336\n",
+      "  training_iteration: 8\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |      8 |          165.087 | 1294336 |  42.7008 |              47.6495 |              21.2577 |            107.823 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1238.4053151213718\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-19-01\n",
+      "  done: false\n",
+      "  episode_len_mean: 107.21781298585918\n",
+      "  episode_reward_max: 47.649484536082525\n",
+      "  episode_reward_mean: 43.115104119360794\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1576\n",
+      "  episodes_total: 13507\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9416759212811788\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.0077835753715286655\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013627580524674462\n",
+      "        total_loss: 1.650565932194392\n",
+      "        vf_explained_var: 0.9848251938819885\n",
+      "        vf_loss: 1.663107653458913\n",
+      "    num_steps_sampled: 1456128\n",
+      "    num_steps_trained: 1456128\n",
+      "  iterations_since_restore: 9\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.308000000000003\n",
+      "    gpu_util_percent0: 0.392\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15550241078926047\n",
+      "    mean_env_wait_ms: 0.6554019389170324\n",
+      "    mean_inference_ms: 4.404255773765493\n",
+      "    mean_raw_obs_processing_ms: 0.40821271351444455\n",
+      "  time_since_restore: 185.5122389793396\n",
+      "  time_this_iter_s: 20.425663471221924\n",
+      "  time_total_s: 185.5122389793396\n",
+      "  timers:\n",
+      "    learn_throughput: 11288.215\n",
+      "    learn_time_ms: 14332.825\n",
+      "    sample_throughput: 26270.178\n",
+      "    sample_time_ms: 6158.771\n",
+      "    update_time_ms: 34.616\n",
+      "  timestamp: 1604233141\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1456128\n",
+      "  training_iteration: 9\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |      9 |          185.512 | 1456128 |  43.1151 |              47.6495 |              21.2577 |            107.218 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1231.2265303412562\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-19-22\n",
+      "  done: false\n",
+      "  episode_len_mean: 106.66975758378594\n",
+      "  episode_reward_max: 47.64948453608253\n",
+      "  episode_reward_mean: 43.48257774293858\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1591\n",
+      "  episodes_total: 15098\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9080682247877121\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.007657797929520409\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010565590860399729\n",
+      "        total_loss: 1.296636829773585\n",
+      "        vf_explained_var: 0.988224446773529\n",
+      "        vf_loss: 1.3061249554157257\n",
+      "    num_steps_sampled: 1617920\n",
+      "    num_steps_trained: 1617920\n",
+      "  iterations_since_restore: 10\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.03333333333333\n",
+      "    gpu_util_percent0: 0.4579166666666667\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5749999999999997\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15484288964237733\n",
+      "    mean_env_wait_ms: 0.6549145589836158\n",
+      "    mean_inference_ms: 4.3750244337617135\n",
+      "    mean_raw_obs_processing_ms: 0.4062248434702486\n",
+      "  time_since_restore: 205.5452425479889\n",
+      "  time_this_iter_s: 20.033003568649292\n",
+      "  time_total_s: 205.5452425479889\n",
+      "  timers:\n",
+      "    learn_throughput: 11294.037\n",
+      "    learn_time_ms: 14325.435\n",
+      "    sample_throughput: 26494.427\n",
+      "    sample_time_ms: 6106.643\n",
+      "    update_time_ms: 33.514\n",
+      "  timestamp: 1604233162\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1617920\n",
+      "  training_iteration: 10\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     10 |          205.545 | 1617920 |  43.4826 |              47.6495 |              21.2577 |             106.67 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1224.8779111644658\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-19-42\n",
+      "  done: false\n",
+      "  episode_len_mean: 106.19435793004313\n",
+      "  episode_reward_max: 47.64948453608253\n",
+      "  episode_reward_mean: 43.804279931238554\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1598\n",
+      "  episodes_total: 16696\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8727221091588339\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.007556108757853508\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012766734405886382\n",
+      "        total_loss: 1.0635682841142018\n",
+      "        vf_explained_var: 0.9903334975242615\n",
+      "        vf_loss: 1.0752601623535156\n",
+      "    num_steps_sampled: 1779712\n",
+      "    num_steps_trained: 1779712\n",
+      "  iterations_since_restore: 11\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.6375\n",
+      "    gpu_util_percent0: 0.4445833333333334\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.570833333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1542607271772269\n",
+      "    mean_env_wait_ms: 0.6545202251025621\n",
+      "    mean_inference_ms: 4.349215320409436\n",
+      "    mean_raw_obs_processing_ms: 0.4044561449167446\n",
+      "  time_since_restore: 225.5202054977417\n",
+      "  time_this_iter_s: 19.974962949752808\n",
+      "  time_total_s: 225.5202054977417\n",
+      "  timers:\n",
+      "    learn_throughput: 11330.871\n",
+      "    learn_time_ms: 14278.867\n",
+      "    sample_throughput: 27121.909\n",
+      "    sample_time_ms: 5965.362\n",
+      "    update_time_ms: 33.265\n",
+      "  timestamp: 1604233182\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1779712\n",
+      "  training_iteration: 11\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     11 |           225.52 | 1779712 |  43.8043 |              47.6495 |              21.2577 |            106.194 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1219.3561336254106\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-20-02\n",
+      "  done: false\n",
+      "  episode_len_mean: 105.77831219938784\n",
+      "  episode_reward_max: 47.64948453608253\n",
+      "  episode_reward_mean: 44.08295937594382\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1600\n",
+      "  episodes_total: 18296\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8348831733067831\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.007376410067081451\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009320069143238166\n",
+      "        total_loss: 0.8637631287177404\n",
+      "        vf_explained_var: 0.99216228723526\n",
+      "        vf_loss: 0.8720253507296244\n",
+      "    num_steps_sampled: 1941504\n",
+      "    num_steps_trained: 1941504\n",
+      "  iterations_since_restore: 12\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.623999999999995\n",
+      "    gpu_util_percent0: 0.364\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5679999999999996\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15375450185882147\n",
+      "    mean_env_wait_ms: 0.6542416074847509\n",
+      "    mean_inference_ms: 4.326388244632185\n",
+      "    mean_raw_obs_processing_ms: 0.4028915881034749\n",
+      "  time_since_restore: 245.75802636146545\n",
+      "  time_this_iter_s: 20.237820863723755\n",
+      "  time_total_s: 245.75802636146545\n",
+      "  timers:\n",
+      "    learn_throughput: 11325.614\n",
+      "    learn_time_ms: 14285.495\n",
+      "    sample_throughput: 27660.054\n",
+      "    sample_time_ms: 5849.302\n",
+      "    update_time_ms: 30.809\n",
+      "  timestamp: 1604233202\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1941504\n",
+      "  training_iteration: 12\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     12 |          245.758 | 1941504 |   44.083 |              47.6495 |              21.2577 |            105.778 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1214.5580739397603\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-20-23\n",
+      "  done: false\n",
+      "  episode_len_mean: 105.4173956762192\n",
+      "  episode_reward_max: 47.64948453608254\n",
+      "  episode_reward_mean: 44.32935526840925\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1594\n",
+      "  episodes_total: 19890\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7998430083195368\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006828729490128656\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011044965135321641\n",
+      "        total_loss: 0.67805515229702\n",
+      "        vf_explained_var: 0.9938119053840637\n",
+      "        vf_loss: 0.6881343126296997\n",
+      "    num_steps_sampled: 2103296\n",
+      "    num_steps_trained: 2103296\n",
+      "  iterations_since_restore: 13\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.831999999999997\n",
+      "    gpu_util_percent0: 0.43200000000000005\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.153302992513867\n",
+      "    mean_env_wait_ms: 0.6540089232561519\n",
+      "    mean_inference_ms: 4.306101213317678\n",
+      "    mean_raw_obs_processing_ms: 0.40148742506884494\n",
+      "  time_since_restore: 266.1050407886505\n",
+      "  time_this_iter_s: 20.34701442718506\n",
+      "  time_total_s: 266.1050407886505\n",
+      "  timers:\n",
+      "    learn_throughput: 11312.078\n",
+      "    learn_time_ms: 14302.589\n",
+      "    sample_throughput: 27960.684\n",
+      "    sample_time_ms: 5786.411\n",
+      "    update_time_ms: 28.901\n",
+      "  timestamp: 1604233223\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2103296\n",
+      "  training_iteration: 13\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     13 |          266.105 | 2103296 |  44.3294 |              47.6495 |              21.2577 |            105.417 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1210.317556539986\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-20-43\n",
+      "  done: false\n",
+      "  episode_len_mean: 105.1013919277501\n",
+      "  episode_reward_max: 47.64948453608254\n",
+      "  episode_reward_mean: 44.54546357677872\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1591\n",
+      "  episodes_total: 21481\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7677376766999563\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.00645853765308857\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009221890567763088\n",
+      "        total_loss: 0.5704321513573328\n",
+      "        vf_explained_var: 0.9948087334632874\n",
+      "        vf_loss: 0.5787462194760641\n",
+      "    num_steps_sampled: 2265088\n",
+      "    num_steps_trained: 2265088\n",
+      "  iterations_since_restore: 14\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.299999999999997\n",
+      "    gpu_util_percent0: 0.3692\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5679999999999996\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15289862610010913\n",
+      "    mean_env_wait_ms: 0.6538353499990455\n",
+      "    mean_inference_ms: 4.287840220794161\n",
+      "    mean_raw_obs_processing_ms: 0.40022401934261076\n",
+      "  time_since_restore: 286.03195905685425\n",
+      "  time_this_iter_s: 19.926918268203735\n",
+      "  time_total_s: 286.03195905685425\n",
+      "  timers:\n",
+      "    learn_throughput: 11326.239\n",
+      "    learn_time_ms: 14284.707\n",
+      "    sample_throughput: 28153.263\n",
+      "    sample_time_ms: 5746.83\n",
+      "    update_time_ms: 28.453\n",
+      "  timestamp: 1604233243\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2265088\n",
+      "  training_iteration: 14\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     14 |          286.032 | 2265088 |  44.5455 |              47.6495 |              21.2577 |            105.101 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1206.554523354749\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-21-04\n",
+      "  done: false\n",
+      "  episode_len_mean: 104.81341019417475\n",
+      "  episode_reward_max: 47.64948453608254\n",
+      "  episode_reward_mean: 44.73924255043826\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1591\n",
+      "  episodes_total: 23072\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.733478844165802\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.00630180553222696\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01086452438418443\n",
+      "        total_loss: 0.44883622725804645\n",
+      "        vf_explained_var: 0.9958701133728027\n",
+      "        vf_loss: 0.4588071381052335\n",
+      "    num_steps_sampled: 2426880\n",
+      "    num_steps_trained: 2426880\n",
+      "  iterations_since_restore: 15\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.691666666666666\n",
+      "    gpu_util_percent0: 0.42\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.570833333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1525331053770261\n",
+      "    mean_env_wait_ms: 0.6537007767835614\n",
+      "    mean_inference_ms: 4.271271460769205\n",
+      "    mean_raw_obs_processing_ms: 0.39907289277823804\n",
+      "  time_since_restore: 306.18409848213196\n",
+      "  time_this_iter_s: 20.15213942527771\n",
+      "  time_total_s: 306.18409848213196\n",
+      "  timers:\n",
+      "    learn_throughput: 11336.437\n",
+      "    learn_time_ms: 14271.856\n",
+      "    sample_throughput: 28161.1\n",
+      "    sample_time_ms: 5745.23\n",
+      "    update_time_ms: 27.237\n",
+      "  timestamp: 1604233264\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2426880\n",
+      "  training_iteration: 15\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     15 |          306.184 | 2426880 |  44.7392 |              47.6495 |              21.2577 |            104.813 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1203.1918253034055\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-21-25\n",
+      "  done: false\n",
+      "  episode_len_mean: 104.54650832894256\n",
+      "  episode_reward_max: 47.64948453608254\n",
+      "  episode_reward_mean: 44.91062311529655\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1601\n",
+      "  episodes_total: 24673\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7046740502119064\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.00598089622023205\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010109954212869829\n",
+      "        total_loss: 0.3878796820839246\n",
+      "        vf_explained_var: 0.9964661002159119\n",
+      "        vf_loss: 0.39714578290780383\n",
+      "    num_steps_sampled: 2588672\n",
+      "    num_steps_trained: 2588672\n",
+      "  iterations_since_restore: 16\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.084\n",
+      "    gpu_util_percent0: 0.4572\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15220062387999952\n",
+      "    mean_env_wait_ms: 0.653596423305203\n",
+      "    mean_inference_ms: 4.256089606710892\n",
+      "    mean_raw_obs_processing_ms: 0.3980153671992771\n",
+      "  time_since_restore: 326.27552032470703\n",
+      "  time_this_iter_s: 20.091421842575073\n",
+      "  time_total_s: 326.27552032470703\n",
+      "  timers:\n",
+      "    learn_throughput: 11333.689\n",
+      "    learn_time_ms: 14275.316\n",
+      "    sample_throughput: 28301.321\n",
+      "    sample_time_ms: 5716.765\n",
+      "    update_time_ms: 25.405\n",
+      "  timestamp: 1604233285\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2588672\n",
+      "  training_iteration: 16\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     16 |          326.276 | 2588672 |  44.9106 |              47.6495 |              21.2577 |            104.547 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1200.1823688521467\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-21-45\n",
+      "  done: false\n",
+      "  episode_len_mean: 104.30184515883583\n",
+      "  episode_reward_max: 47.64948453608254\n",
+      "  episode_reward_mean: 45.06611508661011\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1612\n",
+      "  episodes_total: 26285\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.6727208147446314\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.0061663844001789885\n",
+      "        model: {}\n",
+      "        policy_loss: -0.00950972737094465\n",
+      "        total_loss: 0.2949073016643524\n",
+      "        vf_explained_var: 0.9973233342170715\n",
+      "        vf_loss: 0.3035201082626979\n",
+      "    num_steps_sampled: 2750464\n",
+      "    num_steps_trained: 2750464\n",
+      "  iterations_since_restore: 17\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.068\n",
+      "    gpu_util_percent0: 0.38800000000000007\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5679999999999996\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15189563586672175\n",
+      "    mean_env_wait_ms: 0.653528700746639\n",
+      "    mean_inference_ms: 4.242058406187237\n",
+      "    mean_raw_obs_processing_ms: 0.3970431055250104\n",
+      "  time_since_restore: 346.44066858291626\n",
+      "  time_this_iter_s: 20.16514825820923\n",
+      "  time_total_s: 346.44066858291626\n",
+      "  timers:\n",
+      "    learn_throughput: 11331.786\n",
+      "    learn_time_ms: 14277.714\n",
+      "    sample_throughput: 28373.21\n",
+      "    sample_time_ms: 5702.28\n",
+      "    update_time_ms: 26.064\n",
+      "  timestamp: 1604233305\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2750464\n",
+      "  training_iteration: 17\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     17 |          346.441 | 2750464 |  45.0661 |              47.6495 |              21.2577 |            104.302 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1197.4265528618562\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-22-06\n",
+      "  done: false\n",
+      "  episode_len_mean: 104.07865329512894\n",
+      "  episode_reward_max: 47.64948453608255\n",
+      "  episode_reward_mean: 45.20858749593833\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1635\n",
+      "  episodes_total: 27920\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.6462279756863912\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005753972722838323\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01063174061710015\n",
+      "        total_loss: 0.2318790778517723\n",
+      "        vf_explained_var: 0.997880220413208\n",
+      "        vf_loss: 0.2416831391553084\n",
+      "    num_steps_sampled: 2912256\n",
+      "    num_steps_trained: 2912256\n",
+      "  iterations_since_restore: 18\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.45416666666667\n",
+      "    gpu_util_percent0: 0.44875\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5749999999999997\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1516142332871325\n",
+      "    mean_env_wait_ms: 0.6534803822249593\n",
+      "    mean_inference_ms: 4.229062941307127\n",
+      "    mean_raw_obs_processing_ms: 0.3961363429731068\n",
+      "  time_since_restore: 366.4673285484314\n",
+      "  time_this_iter_s: 20.026659965515137\n",
+      "  time_total_s: 366.4673285484314\n",
+      "  timers:\n",
+      "    learn_throughput: 11321.995\n",
+      "    learn_time_ms: 14290.061\n",
+      "    sample_throughput: 28529.416\n",
+      "    sample_time_ms: 5671.059\n",
+      "    update_time_ms: 25.131\n",
+      "  timestamp: 1604233326\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2912256\n",
+      "  training_iteration: 18\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     18 |          366.467 | 2912256 |  45.2086 |              47.6495 |              21.2577 |            104.079 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1194.9799281209737\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-22-27\n",
+      "  done: false\n",
+      "  episode_len_mean: 103.87829326109042\n",
+      "  episode_reward_max: 47.64948453608255\n",
+      "  episode_reward_mean: 45.33514231552049\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1610\n",
+      "  episodes_total: 29530\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.6139073818922043\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005659738904796541\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009704548533287985\n",
+      "        total_loss: 0.19860607013106346\n",
+      "        vf_explained_var: 0.9981780648231506\n",
+      "        vf_loss: 0.20748562117417654\n",
+      "    num_steps_sampled: 3074048\n",
+      "    num_steps_trained: 3074048\n",
+      "  iterations_since_restore: 19\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.747999999999998\n",
+      "    gpu_util_percent0: 0.39640000000000003\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15135749897686426\n",
+      "    mean_env_wait_ms: 0.6534384087466466\n",
+      "    mean_inference_ms: 4.217280786349381\n",
+      "    mean_raw_obs_processing_ms: 0.3953083892816526\n",
+      "  time_since_restore: 386.6138005256653\n",
+      "  time_this_iter_s: 20.146471977233887\n",
+      "  time_total_s: 386.6138005256653\n",
+      "  timers:\n",
+      "    learn_throughput: 11328.703\n",
+      "    learn_time_ms: 14281.599\n",
+      "    sample_throughput: 28668.019\n",
+      "    sample_time_ms: 5643.641\n",
+      "    update_time_ms: 26.007\n",
+      "  timestamp: 1604233347\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3074048\n",
+      "  training_iteration: 19\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     19 |          386.614 | 3074048 |  45.3351 |              47.6495 |              21.2577 |            103.878 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1192.755491943006\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-22-47\n",
+      "  done: false\n",
+      "  episode_len_mean: 103.69467022199376\n",
+      "  episode_reward_max: 47.64948453608255\n",
+      "  episode_reward_mean: 45.44938246008456\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1597\n",
+      "  episodes_total: 31127\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.5885171492894491\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.00575300360408922\n",
+      "        model: {}\n",
+      "        policy_loss: -0.008459999109618366\n",
+      "        total_loss: 0.1491255114475886\n",
+      "        vf_explained_var: 0.9986266493797302\n",
+      "        vf_loss: 0.15672916546463966\n",
+      "    num_steps_sampled: 3235840\n",
+      "    num_steps_trained: 3235840\n",
+      "  iterations_since_restore: 20\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.32\n",
+      "    gpu_util_percent0: 0.33520000000000005\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5679999999999996\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15111988887105687\n",
+      "    mean_env_wait_ms: 0.6534000992030266\n",
+      "    mean_inference_ms: 4.206433415272165\n",
+      "    mean_raw_obs_processing_ms: 0.39454176059647716\n",
+      "  time_since_restore: 406.58024430274963\n",
+      "  time_this_iter_s: 19.96644377708435\n",
+      "  time_total_s: 406.58024430274963\n",
+      "  timers:\n",
+      "    learn_throughput: 11334.136\n",
+      "    learn_time_ms: 14274.754\n",
+      "    sample_throughput: 28704.988\n",
+      "    sample_time_ms: 5636.372\n",
+      "    update_time_ms: 26.077\n",
+      "  timestamp: 1604233367\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3235840\n",
+      "  training_iteration: 20\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     20 |           406.58 | 3235840 |  45.4494 |              47.6495 |              21.2577 |            103.695 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1190.7317714705164\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-23-08\n",
+      "  done: false\n",
+      "  episode_len_mean: 103.52679335207137\n",
+      "  episode_reward_max: 47.64948453608255\n",
+      "  episode_reward_mean: 45.553595837989505\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1605\n",
+      "  episodes_total: 32732\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.5605561385552088\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.0051246628087634844\n",
+      "        model: {}\n",
+      "        policy_loss: -0.00707746635695609\n",
+      "        total_loss: 0.12786801221470037\n",
+      "        vf_explained_var: 0.9988241195678711\n",
+      "        vf_loss: 0.13420082504550615\n",
+      "    num_steps_sampled: 3397632\n",
+      "    num_steps_trained: 3397632\n",
+      "  iterations_since_restore: 21\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.108\n",
+      "    gpu_util_percent0: 0.36239999999999994\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5679999999999996\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1508982454274576\n",
+      "    mean_env_wait_ms: 0.6533685645927871\n",
+      "    mean_inference_ms: 4.196348243483211\n",
+      "    mean_raw_obs_processing_ms: 0.393820825357919\n",
+      "  time_since_restore: 426.77583384513855\n",
+      "  time_this_iter_s: 20.195589542388916\n",
+      "  time_total_s: 426.77583384513855\n",
+      "  timers:\n",
+      "    learn_throughput: 11330.776\n",
+      "    learn_time_ms: 14278.986\n",
+      "    sample_throughput: 28644.617\n",
+      "    sample_time_ms: 5648.251\n",
+      "    update_time_ms: 25.717\n",
+      "  timestamp: 1604233388\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3397632\n",
+      "  training_iteration: 21\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     21 |          426.776 | 3397632 |  45.5536 |              47.6495 |              21.2577 |            103.527 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1188.871339064549\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-23-29\n",
+      "  done: false\n",
+      "  episode_len_mean: 103.37087712148119\n",
+      "  episode_reward_max: 47.64948453608255\n",
+      "  episode_reward_mean: 45.649092584828495\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1619\n",
+      "  episodes_total: 34351\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.5297549913326899\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005221013678237796\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007347211508507219\n",
+      "        total_loss: 0.11089812219142914\n",
+      "        vf_explained_var: 0.9989762306213379\n",
+      "        vf_loss: 0.11746600580712159\n",
+      "    num_steps_sampled: 3559424\n",
+      "    num_steps_trained: 3559424\n",
+      "  iterations_since_restore: 22\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.358333333333334\n",
+      "    gpu_util_percent0: 0.4533333333333333\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.570833333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15069056354724808\n",
+      "    mean_env_wait_ms: 0.6533427688463339\n",
+      "    mean_inference_ms: 4.1868632869880145\n",
+      "    mean_raw_obs_processing_ms: 0.3931430489205958\n",
+      "  time_since_restore: 447.03629064559937\n",
+      "  time_this_iter_s: 20.260456800460815\n",
+      "  time_total_s: 447.03629064559937\n",
+      "  timers:\n",
+      "    learn_throughput: 11328.702\n",
+      "    learn_time_ms: 14281.601\n",
+      "    sample_throughput: 28676.086\n",
+      "    sample_time_ms: 5642.053\n",
+      "    update_time_ms: 25.502\n",
+      "  timestamp: 1604233409\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3559424\n",
+      "  training_iteration: 22\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     22 |          447.036 | 3559424 |  45.6491 |              47.6495 |              21.2577 |            103.371 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1187.1485870048955\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-23-50\n",
+      "  done: false\n",
+      "  episode_len_mean: 103.22507502500834\n",
+      "  episode_reward_max: 47.64948453608255\n",
+      "  episode_reward_mean: 45.737731878552886\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1637\n",
+      "  episodes_total: 35988\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.5043502772847811\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.0051153005721668405\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007804131872641544\n",
+      "        total_loss: 0.08389338354269664\n",
+      "        vf_explained_var: 0.9992172718048096\n",
+      "        vf_loss: 0.09092663104335467\n",
+      "    num_steps_sampled: 3721216\n",
+      "    num_steps_trained: 3721216\n",
+      "  iterations_since_restore: 23\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.10769230769231\n",
+      "    gpu_util_percent0: 0.4111538461538462\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5692307692307685\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1504958593946037\n",
+      "    mean_env_wait_ms: 0.6533264567796601\n",
+      "    mean_inference_ms: 4.177979473432433\n",
+      "    mean_raw_obs_processing_ms: 0.39250620871910297\n",
+      "  time_since_restore: 467.43437933921814\n",
+      "  time_this_iter_s: 20.398088693618774\n",
+      "  time_total_s: 467.43437933921814\n",
+      "  timers:\n",
+      "    learn_throughput: 11352.718\n",
+      "    learn_time_ms: 14251.389\n",
+      "    sample_throughput: 28591.581\n",
+      "    sample_time_ms: 5658.729\n",
+      "    update_time_ms: 26.115\n",
+      "  timestamp: 1604233430\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3721216\n",
+      "  training_iteration: 23\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     23 |          467.434 | 3721216 |  45.7377 |              47.6495 |              21.2577 |            103.225 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1185.5975664953805\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-24-11\n",
+      "  done: false\n",
+      "  episode_len_mean: 103.0935496741588\n",
+      "  episode_reward_max: 47.64948453608255\n",
+      "  episode_reward_mean: 45.817267047191805\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1607\n",
+      "  episodes_total: 37595\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.477857805788517\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005301223369315267\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007187186017593679\n",
+      "        total_loss: 0.0712860906496644\n",
+      "        vf_explained_var: 0.9993272423744202\n",
+      "        vf_loss: 0.07765195891261101\n",
+      "    num_steps_sampled: 3883008\n",
+      "    num_steps_trained: 3883008\n",
+      "  iterations_since_restore: 24\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.808000000000003\n",
+      "    gpu_util_percent0: 0.41159999999999997\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5679999999999996\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1503165502098337\n",
+      "    mean_env_wait_ms: 0.6533168664023659\n",
+      "    mean_inference_ms: 4.1697739229427855\n",
+      "    mean_raw_obs_processing_ms: 0.39192023267055776\n",
+      "  time_since_restore: 487.5962927341461\n",
+      "  time_this_iter_s: 20.16191339492798\n",
+      "  time_total_s: 487.5962927341461\n",
+      "  timers:\n",
+      "    learn_throughput: 11345.276\n",
+      "    learn_time_ms: 14260.737\n",
+      "    sample_throughput: 28572.718\n",
+      "    sample_time_ms: 5662.465\n",
+      "    update_time_ms: 25.82\n",
+      "  timestamp: 1604233451\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3883008\n",
+      "  training_iteration: 24\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     24 |          487.596 | 3883008 |  45.8173 |              47.6495 |              21.2577 |            103.094 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1184.1811960574025\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-24-32\n",
+      "  done: false\n",
+      "  episode_len_mean: 102.9715546711567\n",
+      "  episode_reward_max: 47.64948453608255\n",
+      "  episode_reward_mean: 45.8903373462669\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1603\n",
+      "  episodes_total: 39198\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.4582882300019264\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.004777276888489723\n",
+      "        model: {}\n",
+      "        policy_loss: -0.006818818922814292\n",
+      "        total_loss: 0.06491830727706353\n",
+      "        vf_explained_var: 0.9993811249732971\n",
+      "        vf_loss: 0.07101081249614556\n",
+      "    num_steps_sampled: 4044800\n",
+      "    num_steps_trained: 4044800\n",
+      "  iterations_since_restore: 25\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.5\n",
+      "    gpu_util_percent0: 0.4164\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15014800244823473\n",
+      "    mean_env_wait_ms: 0.6533117275008512\n",
+      "    mean_inference_ms: 4.162086682670796\n",
+      "    mean_raw_obs_processing_ms: 0.3913710326970964\n",
+      "  time_since_restore: 507.939138174057\n",
+      "  time_this_iter_s: 20.34284543991089\n",
+      "  time_total_s: 507.939138174057\n",
+      "  timers:\n",
+      "    learn_throughput: 11324.044\n",
+      "    learn_time_ms: 14287.476\n",
+      "    sample_throughput: 28578.2\n",
+      "    sample_time_ms: 5661.378\n",
+      "    update_time_ms: 26.054\n",
+      "  timestamp: 1604233472\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4044800\n",
+      "  training_iteration: 25\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "2020-11-01 12:24:33,109\tWARNING util.py:136 -- The `process_trial` operation took 0.5145235061645508 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     25 |          507.939 | 4044800 |  45.8903 |              47.6495 |              21.2577 |            102.972 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1182.8508853681267\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-24-53\n",
+      "  done: false\n",
+      "  episode_len_mean: 102.8577064444989\n",
+      "  episode_reward_max: 47.64948453608255\n",
+      "  episode_reward_mean: 45.95893087655392\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1612\n",
+      "  episodes_total: 40810\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.4304437041282654\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005302870219262938\n",
+      "        model: {}\n",
+      "        policy_loss: -0.005320634130233278\n",
+      "        total_loss: 0.04602197107548515\n",
+      "        vf_explained_var: 0.9995622038841248\n",
+      "        vf_loss: 0.05102753918617964\n",
+      "    num_steps_sampled: 4206592\n",
+      "    num_steps_trained: 4206592\n",
+      "  iterations_since_restore: 26\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.031999999999996\n",
+      "    gpu_util_percent0: 0.4016\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.14998848423358552\n",
+      "    mean_env_wait_ms: 0.6533120076712385\n",
+      "    mean_inference_ms: 4.154808738528033\n",
+      "    mean_raw_obs_processing_ms: 0.39085074710802764\n",
+      "  time_since_restore: 528.287171125412\n",
+      "  time_this_iter_s: 20.34803295135498\n",
+      "  time_total_s: 528.287171125412\n",
+      "  timers:\n",
+      "    learn_throughput: 11314.942\n",
+      "    learn_time_ms: 14298.969\n",
+      "    sample_throughput: 28539.444\n",
+      "    sample_time_ms: 5669.066\n",
+      "    update_time_ms: 26.44\n",
+      "  timestamp: 1604233493\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4206592\n",
+      "  training_iteration: 26\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "2020-11-01 12:24:54,161\tWARNING util.py:136 -- The `process_trial` operation took 0.5190365314483643 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     26 |          528.287 | 4206592 |  45.9589 |              47.6495 |              21.2577 |            102.858 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1181.6014053620693\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-25-14\n",
+      "  done: false\n",
+      "  episode_len_mean: 102.75047708799623\n",
+      "  episode_reward_max: 47.64948453608255\n",
+      "  episode_reward_mean: 46.02298669108478\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1635\n",
+      "  episodes_total: 42445\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.40619519104560214\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.004850935540162027\n",
+      "        model: {}\n",
+      "        policy_loss: -0.00712713325143947\n",
+      "        total_loss: 0.04109010814378659\n",
+      "        vf_explained_var: 0.9995940327644348\n",
+      "        vf_loss: 0.047935244316856064\n",
+      "    num_steps_sampled: 4368384\n",
+      "    num_steps_trained: 4368384\n",
+      "  iterations_since_restore: 27\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.9\n",
+      "    gpu_util_percent0: 0.4608\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.14983678273441456\n",
+      "    mean_env_wait_ms: 0.6533202946066505\n",
+      "    mean_inference_ms: 4.147883359756837\n",
+      "    mean_raw_obs_processing_ms: 0.3903567513935103\n",
+      "  time_since_restore: 548.3913764953613\n",
+      "  time_this_iter_s: 20.10420536994934\n",
+      "  time_total_s: 548.3913764953613\n",
+      "  timers:\n",
+      "    learn_throughput: 11320.7\n",
+      "    learn_time_ms: 14291.696\n",
+      "    sample_throughput: 28538.222\n",
+      "    sample_time_ms: 5669.309\n",
+      "    update_time_ms: 25.152\n",
+      "  timestamp: 1604233514\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4368384\n",
+      "  training_iteration: 27\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "2020-11-01 12:25:14,990\tWARNING util.py:136 -- The `process_trial` operation took 0.5334711074829102 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     27 |          548.391 | 4368384 |   46.023 |              47.6495 |              21.2577 |             102.75 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1180.4515455020326\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-25-35\n",
+      "  done: false\n",
+      "  episode_len_mean: 102.6508271495677\n",
+      "  episode_reward_max: 47.64948453608255\n",
+      "  episode_reward_mean: 46.08214646909499\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1622\n",
+      "  episodes_total: 44067\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.05000000000000001\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.380776509642601\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005104163157132764\n",
+      "        model: {}\n",
+      "        policy_loss: -0.008030562166823074\n",
+      "        total_loss: 0.03263539479424556\n",
+      "        vf_explained_var: 0.9996626377105713\n",
+      "        vf_loss: 0.0406011367837588\n",
+      "    num_steps_sampled: 4530176\n",
+      "    num_steps_trained: 4530176\n",
+      "  iterations_since_restore: 28\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.724\n",
+      "    gpu_util_percent0: 0.3708000000000001\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.14969387594042302\n",
+      "    mean_env_wait_ms: 0.6533341674809083\n",
+      "    mean_inference_ms: 4.141387554786562\n",
+      "    mean_raw_obs_processing_ms: 0.3898925942202909\n",
+      "  time_since_restore: 568.5405015945435\n",
+      "  time_this_iter_s: 20.14912509918213\n",
+      "  time_total_s: 568.5405015945435\n",
+      "  timers:\n",
+      "    learn_throughput: 11317.578\n",
+      "    learn_time_ms: 14295.638\n",
+      "    sample_throughput: 28540.327\n",
+      "    sample_time_ms: 5668.891\n",
+      "    update_time_ms: 27.131\n",
+      "  timestamp: 1604233535\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4530176\n",
+      "  training_iteration: 28\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "2020-11-01 12:25:35,895\tWARNING util.py:136 -- The `process_trial` operation took 0.5552034378051758 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     28 |          568.541 | 4530176 |  46.0821 |              47.6495 |              21.2577 |            102.651 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1179.389183503528\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-25-56\n",
+      "  done: false\n",
+      "  episode_len_mean: 102.55971097000219\n",
+      "  episode_reward_max: 47.64948453608255\n",
+      "  episode_reward_mean: 46.136667351393584\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1603\n",
+      "  episodes_total: 45670\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.05000000000000001\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.3589545438687007\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005236083525232971\n",
+      "        model: {}\n",
+      "        policy_loss: -0.005505533023097087\n",
+      "        total_loss: 0.02439635860112806\n",
+      "        vf_explained_var: 0.9997479915618896\n",
+      "        vf_loss: 0.029819565049062174\n",
+      "    num_steps_sampled: 4691968\n",
+      "    num_steps_trained: 4691968\n",
+      "  iterations_since_restore: 29\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.04\n",
+      "    gpu_util_percent0: 0.3832\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.14955992403902243\n",
+      "    mean_env_wait_ms: 0.65334881821503\n",
+      "    mean_inference_ms: 4.135306265563136\n",
+      "    mean_raw_obs_processing_ms: 0.3894575857046042\n",
+      "  time_since_restore: 588.7653107643127\n",
+      "  time_this_iter_s: 20.224809169769287\n",
+      "  time_total_s: 588.7653107643127\n",
+      "  timers:\n",
+      "    learn_throughput: 11315.541\n",
+      "    learn_time_ms: 14298.212\n",
+      "    sample_throughput: 28543.882\n",
+      "    sample_time_ms: 5668.185\n",
+      "    update_time_ms: 27.394\n",
+      "  timestamp: 1604233556\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4691968\n",
+      "  training_iteration: 29\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "2020-11-01 12:25:56,904\tWARNING util.py:136 -- The `process_trial` operation took 0.5792350769042969 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     29 |          588.765 | 4691968 |  46.1367 |              47.6495 |              21.2577 |             102.56 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1178.4016808145811\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-26-17\n",
+      "  done: true\n",
+      "  episode_len_mean: 102.47428873611845\n",
+      "  episode_reward_max: 47.64948453608255\n",
+      "  episode_reward_mean: 46.187587432602626\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1605\n",
+      "  episodes_total: 47275\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.05000000000000001\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.34163280328114826\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005014610709622502\n",
+      "        model: {}\n",
+      "        policy_loss: -0.006093008596508298\n",
+      "        total_loss: 0.02250015801594903\n",
+      "        vf_explained_var: 0.9997627139091492\n",
+      "        vf_loss: 0.028513251959035795\n",
+      "    num_steps_sampled: 4853760\n",
+      "    num_steps_trained: 4853760\n",
+      "  iterations_since_restore: 30\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.592000000000002\n",
+      "    gpu_util_percent0: 0.4032\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.14943275367352743\n",
+      "    mean_env_wait_ms: 0.6533656820836667\n",
+      "    mean_inference_ms: 4.129545135974801\n",
+      "    mean_raw_obs_processing_ms: 0.38904409500028486\n",
+      "  time_since_restore: 608.9674067497253\n",
+      "  time_this_iter_s: 20.202095985412598\n",
+      "  time_total_s: 608.9674067497253\n",
+      "  timers:\n",
+      "    learn_throughput: 11308.582\n",
+      "    learn_time_ms: 14307.01\n",
+      "    sample_throughput: 28493.852\n",
+      "    sample_time_ms: 5678.137\n",
+      "    update_time_ms: 27.445\n",
+      "  timestamp: 1604233577\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4853760\n",
+      "  training_iteration: 30\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "2020-11-01 12:26:18,072\tWARNING util.py:136 -- The `process_trial` operation took 0.6780698299407959 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 24.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | TERMINATED |       |     30 |          608.967 | 4853760 |  46.1876 |              47.6495 |              21.2577 |            102.474 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "== Status ==\n",
+      "Memory usage on this node: 24.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | TERMINATED |       |     30 |          608.967 | 4853760 |  46.1876 |              47.6495 |              21.2577 |            102.474 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 2387\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201013_114553-3qwfavbb/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201013_114553-3qwfavbb/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201101_121542-dcx4y6ut/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201101_121542-dcx4y6ut/logs/debug-internal.log\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:       nb_episodes 4473\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   avg_best_result 261.82891\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_episode 280.71717\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:     time_step_min 3203\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:             _step 0\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:          _runtime 607\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        _timestamp 1602590160\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 1150\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 636\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1604233578\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 1662\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 1178.40168\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 47.64948\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 21.25773\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 46.18759\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 47275\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 30\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:       nb_episodes ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   avg_best_result ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_episode ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:     time_step_min ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:             _step ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:          _runtime ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        _timestamp ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ‚ñÅ\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mrandom\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/3qwfavbb\u001b[0m\n",
-      "2020-10-13 11:56:07,517 - wandb.wandb_agent - INFO - Cleaning up finished run: 3qwfavbb\n",
-      "2020-10-13 11:56:07,847 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-13 11:56:07,847 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tinstance_path: /JSS/JSS/env/instances/ta52\n",
-      "2020-10-13 11:56:07,849 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python RandomGreedy.py --instance_path=/JSS/JSS/env/instances/ta52\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mdaily-sweep-3\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/dcx4y6ut\u001b[0m\n",
+      "2020-11-01 12:26:27,483 - wandb.wandb_agent - INFO - Cleaning up finished run: dcx4y6ut\n",
+      "2020-11-01 12:26:27,816 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-11-01 12:26:27,816 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tinstance_path: /JSS/JSS/env/instances/la/la14.txt\n",
+      "2020-11-01 12:26:27,818 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --instance_path=/JSS/JSS/env/instances/la/la14.txt\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.8 is available!  To upgrade, please run:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
+      "2020-11-01 12:26:32,836 - wandb.wandb_agent - INFO - Running runs: ['fdb3wrbz']\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mrandom\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/1x8v92mc\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/av30c7rd\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201013_115608-av30c7rd\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mpretty-sweep-4\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/sweeps/9xhkl8my\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/fdb3wrbz\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201101_122629-fdb3wrbz\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
-      "2020-10-13 11:56:12,862 - wandb.wandb_agent - INFO - Running runs: ['av30c7rd']\n"
+      "2020-11-01 12:26:33,451\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
+      "== Status ==\n",
+      "Memory usage on this node: 12.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  |       |\n",
+      "+-------------------------+----------+-------+\n",
+      "\n",
+      "\n",
+      "\u001b[2m\u001b[36m(pid=34519)\u001b[0m 2020-11-01 12:26:36,168\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=34570)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34570)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34576)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34576)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34560)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34560)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34533)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34533)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34524)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34524)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34565)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34565)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34446)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34446)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34580)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34580)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34537)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34537)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34514)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34514)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34563)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34563)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34513)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34513)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34574)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34574)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34541)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34541)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34468)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34468)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34562)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34562)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34507)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34507)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34529)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34529)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34531)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34531)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34470)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34470)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34455)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34455)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34456)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34456)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34534)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34534)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34569)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34569)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34471)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34471)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34520)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34520)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34528)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34528)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34530)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34530)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34557)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34557)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34464)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34464)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34526)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34526)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34457)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34457)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34451)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34451)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34559)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34559)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34460)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34460)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34539)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34539)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34555)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34555)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34512)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34512)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34544)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34544)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34572)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34572)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34466)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34466)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34448)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34448)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34467)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34467)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34478)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34478)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34469)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34469)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34449)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34449)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34453)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34453)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34445)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34445)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34462)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34462)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34564)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34564)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34461)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34461)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34452)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34452)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34550)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34550)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34552)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34552)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34454)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34454)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34525)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34525)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34518)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34518)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34472)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34472)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34473)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34473)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34527)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34527)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34447)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34447)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34521)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34521)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34545)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34545)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34474)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34474)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34465)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34465)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34546)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34546)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34444)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34444)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34450)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34450)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34506)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34506)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34509)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34509)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34517)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34517)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34458)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34458)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34504)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34504)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34522)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34522)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34511)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34511)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34532)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34532)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34510)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34510)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34523)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34523)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1454.2822384428223\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-27-04\n",
+      "  done: false\n",
+      "  episode_len_mean: 116.8627760252366\n",
+      "  episode_reward_max: 43.628865979381466\n",
+      "  episode_reward_mean: 35.1516797294221\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1268\n",
+      "  episodes_total: 1268\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1449244519074757\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.007437704674278696\n",
+      "        model: {}\n",
+      "        policy_loss: -0.00946940048985804\n",
+      "        total_loss: 55.00797367095947\n",
+      "        vf_explained_var: 0.7487528324127197\n",
+      "        vf_loss: 55.01652844746908\n",
+      "    num_steps_sampled: 161792\n",
+      "    num_steps_trained: 161792\n",
+      "  iterations_since_restore: 1\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 33.32592592592592\n",
+      "    gpu_util_percent0: 0.37481481481481477\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.4333333333333336\n",
+      "    vram_util_percent0: 0.08172381958869332\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.17352791633057102\n",
+      "    mean_env_wait_ms: 0.6811877523118316\n",
+      "    mean_inference_ms: 5.513942130136428\n",
+      "    mean_raw_obs_processing_ms: 0.46789447756981023\n",
+      "  time_since_restore: 22.46462392807007\n",
+      "  time_this_iter_s: 22.46462392807007\n",
+      "  time_total_s: 22.46462392807007\n",
+      "  timers:\n",
+      "    learn_throughput: 11371.952\n",
+      "    learn_time_ms: 14227.284\n",
+      "    sample_throughput: 19879.837\n",
+      "    sample_time_ms: 8138.497\n",
+      "    update_time_ms: 45.686\n",
+      "  timestamp: 1604233624\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 161792\n",
+      "  training_iteration: 1\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |      1 |          22.4646 | 161792 |  35.1517 |              43.6289 |              15.1237 |            116.863 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1429.8942416258938\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-27-24\n",
+      "  done: false\n",
+      "  episode_len_mean: 115.70282317979198\n",
+      "  episode_reward_max: 43.62886597938149\n",
+      "  episode_reward_mean: 36.47211286591811\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1424\n",
+      "  episodes_total: 2692\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1268550356229146\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.008950442192144692\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011557365185581148\n",
+      "        total_loss: 11.271961530049643\n",
+      "        vf_explained_var: 0.8903374671936035\n",
+      "        vf_loss: 11.282292207082113\n",
+      "    num_steps_sampled: 323584\n",
+      "    num_steps_trained: 323584\n",
+      "  iterations_since_restore: 2\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 28.204166666666666\n",
+      "    gpu_util_percent0: 0.3720833333333333\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5041666666666664\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16745964588212917\n",
+      "    mean_env_wait_ms: 0.6700706773938075\n",
+      "    mean_inference_ms: 5.2198211020760175\n",
+      "    mean_raw_obs_processing_ms: 0.44909095470061955\n",
+      "  time_since_restore: 43.08302044868469\n",
+      "  time_this_iter_s: 20.618396520614624\n",
+      "  time_total_s: 43.08302044868469\n",
+      "  timers:\n",
+      "    learn_throughput: 11459.566\n",
+      "    learn_time_ms: 14118.51\n",
+      "    sample_throughput: 22090.571\n",
+      "    sample_time_ms: 7324.03\n",
+      "    update_time_ms: 43.623\n",
+      "  timestamp: 1604233644\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 323584\n",
+      "  training_iteration: 2\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.5/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |      2 |           43.083 | 323584 |  36.4721 |              43.6289 |              15.1237 |            115.703 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1407.1911728846624\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-27-44\n",
+      "  done: false\n",
+      "  episode_len_mean: 114.6612669245648\n",
+      "  episode_reward_max: 43.62886597938149\n",
+      "  episode_reward_mean: 37.6345041775509\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1444\n",
+      "  episodes_total: 4136\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1022506852944691\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.010415543181200823\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012739738527064523\n",
+      "        total_loss: 7.215804258982341\n",
+      "        vf_explained_var: 0.9305369257926941\n",
+      "        vf_loss: 7.227012077967326\n",
+      "    num_steps_sampled: 485376\n",
+      "    num_steps_trained: 485376\n",
+      "  iterations_since_restore: 3\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.087500000000002\n",
+      "    gpu_util_percent0: 0.37166666666666665\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5083333333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16367371839915396\n",
+      "    mean_env_wait_ms: 0.6634994267663006\n",
+      "    mean_inference_ms: 5.010201052450705\n",
+      "    mean_raw_obs_processing_ms: 0.43679686634070053\n",
+      "  time_since_restore: 63.11474633216858\n",
+      "  time_this_iter_s: 20.031725883483887\n",
+      "  time_total_s: 63.11474633216858\n",
+      "  timers:\n",
+      "    learn_throughput: 11492.021\n",
+      "    learn_time_ms: 14078.638\n",
+      "    sample_throughput: 23568.631\n",
+      "    sample_time_ms: 6864.718\n",
+      "    update_time_ms: 36.686\n",
+      "  timestamp: 1604233664\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 485376\n",
+      "  training_iteration: 3\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.5/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |      3 |          63.1147 | 485376 |  37.6345 |              43.6289 |              15.1237 |            114.661 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1387.3099946552645\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-28-04\n",
+      "  done: false\n",
+      "  episode_len_mean: 113.46689093484419\n",
+      "  episode_reward_max: 43.62886597938149\n",
+      "  episode_reward_mean: 38.66655836570194\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1512\n",
+      "  episodes_total: 5648\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0769410530726116\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.0091951551536719\n",
+      "        model: {}\n",
+      "        policy_loss: -0.014317200764101775\n",
+      "        total_loss: 4.537634372711182\n",
+      "        vf_explained_var: 0.9580438733100891\n",
+      "        vf_loss: 4.550650993982951\n",
+      "    num_steps_sampled: 647168\n",
+      "    num_steps_trained: 647168\n",
+      "  iterations_since_restore: 4\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.513043478260872\n",
+      "    gpu_util_percent0: 0.4282608695652175\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5173913043478255\n",
+      "    vram_util_percent0: 0.10109872089209576\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16103675868646175\n",
+      "    mean_env_wait_ms: 0.6593645086787177\n",
+      "    mean_inference_ms: 4.8577089246646405\n",
+      "    mean_raw_obs_processing_ms: 0.42820753933909217\n",
+      "  time_since_restore: 82.97024512290955\n",
+      "  time_this_iter_s: 19.855498790740967\n",
+      "  time_total_s: 82.97024512290955\n",
+      "  timers:\n",
+      "    learn_throughput: 11507.373\n",
+      "    learn_time_ms: 14059.855\n",
+      "    sample_throughput: 24572.569\n",
+      "    sample_time_ms: 6584.253\n",
+      "    update_time_ms: 36.417\n",
+      "  timestamp: 1604233684\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 647168\n",
+      "  training_iteration: 4\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |      4 |          82.9702 | 647168 |  38.6666 |              43.6289 |              15.1237 |            113.467 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1372.565211247704\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-28-24\n",
+      "  done: false\n",
+      "  episode_len_mean: 112.40185601799774\n",
+      "  episode_reward_max: 43.62886597938149\n",
+      "  episode_reward_mean: 39.44358453260353\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1464\n",
+      "  episodes_total: 7112\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.044628421465556\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.009637930120031038\n",
+      "        model: {}\n",
+      "        policy_loss: -0.015056621322097877\n",
+      "        total_loss: 3.0646530191103616\n",
+      "        vf_explained_var: 0.9720616936683655\n",
+      "        vf_loss: 3.0783043106396994\n",
+      "    num_steps_sampled: 808960\n",
+      "    num_steps_trained: 808960\n",
+      "  iterations_since_restore: 5\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.678260869565225\n",
+      "    gpu_util_percent0: 0.44782608695652176\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.508695652173913\n",
+      "    vram_util_percent0: 0.10109872089209576\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15917782673985395\n",
+      "    mean_env_wait_ms: 0.6566410931470792\n",
+      "    mean_inference_ms: 4.748845539400791\n",
+      "    mean_raw_obs_processing_ms: 0.4219900698653993\n",
+      "  time_since_restore: 102.53243446350098\n",
+      "  time_this_iter_s: 19.56218934059143\n",
+      "  time_total_s: 102.53243446350098\n",
+      "  timers:\n",
+      "    learn_throughput: 11519.656\n",
+      "    learn_time_ms: 14044.863\n",
+      "    sample_throughput: 25439.401\n",
+      "    sample_time_ms: 6359.898\n",
+      "    update_time_ms: 36.623\n",
+      "  timestamp: 1604233704\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 808960\n",
+      "  training_iteration: 5\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |      5 |          102.532 | 808960 |  39.4436 |              43.6289 |              15.1237 |            112.402 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1360.8171568057655\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-28-44\n",
+      "  done: false\n",
+      "  episode_len_mean: 111.4935170178282\n",
+      "  episode_reward_max: 43.628865979381494\n",
+      "  episode_reward_mean: 40.051285019680485\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1526\n",
+      "  episodes_total: 8638\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.008226936062177\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.008314594083155194\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011961210014609\n",
+      "        total_loss: 2.176027218500773\n",
+      "        vf_explained_var: 0.9811684489250183\n",
+      "        vf_loss: 2.1868296464284263\n",
+      "    num_steps_sampled: 970752\n",
+      "    num_steps_trained: 970752\n",
+      "  iterations_since_restore: 6\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.013043478260872\n",
+      "    gpu_util_percent0: 0.3617391304347826\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.526086956521739\n",
+      "    vram_util_percent0: 0.10109872089209576\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1576901249282025\n",
+      "    mean_env_wait_ms: 0.6545619856913595\n",
+      "    mean_inference_ms: 4.661154625197678\n",
+      "    mean_raw_obs_processing_ms: 0.41690510698628513\n",
+      "  time_since_restore: 122.15152668952942\n",
+      "  time_this_iter_s: 19.619092226028442\n",
+      "  time_total_s: 122.15152668952942\n",
+      "  timers:\n",
+      "    learn_throughput: 11527.252\n",
+      "    learn_time_ms: 14035.609\n",
+      "    sample_throughput: 26007.896\n",
+      "    sample_time_ms: 6220.88\n",
+      "    update_time_ms: 34.802\n",
+      "  timestamp: 1604233724\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 970752\n",
+      "  training_iteration: 6\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |      6 |          122.152 | 970752 |  40.0513 |              43.6289 |              15.1237 |            111.494 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1351.9801127931137\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-29-04\n",
+      "  done: false\n",
+      "  episode_len_mean: 110.74748570301716\n",
+      "  episode_reward_max: 43.628865979381494\n",
+      "  episode_reward_mean: 40.50685320002359\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1504\n",
+      "  episodes_total: 10142\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9799897919098536\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.007559017394669354\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013409938372205943\n",
+      "        total_loss: 1.644661049048106\n",
+      "        vf_explained_var: 0.9860979914665222\n",
+      "        vf_loss: 1.657049189011256\n",
+      "    num_steps_sampled: 1132544\n",
+      "    num_steps_trained: 1132544\n",
+      "  iterations_since_restore: 7\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.617391304347827\n",
+      "    gpu_util_percent0: 0.4239130434782608\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5217391304347827\n",
+      "    vram_util_percent0: 0.10109872089209576\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15650830518376826\n",
+      "    mean_env_wait_ms: 0.6530945053208776\n",
+      "    mean_inference_ms: 4.592386951937845\n",
+      "    mean_raw_obs_processing_ms: 0.41293979722789786\n",
+      "  time_since_restore: 141.83420944213867\n",
+      "  time_this_iter_s: 19.682682752609253\n",
+      "  time_total_s: 141.83420944213867\n",
+      "  timers:\n",
+      "    learn_throughput: 11524.629\n",
+      "    learn_time_ms: 14038.804\n",
+      "    sample_throughput: 26444.386\n",
+      "    sample_time_ms: 6118.198\n",
+      "    update_time_ms: 34.8\n",
+      "  timestamp: 1604233744\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1132544\n",
+      "  training_iteration: 7\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |      7 |          141.834 | 1132544 |  40.5069 |              43.6289 |              15.1237 |            110.747 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1344.8585277968427\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-29-24\n",
+      "  done: false\n",
+      "  episode_len_mean: 110.01317252587461\n",
+      "  episode_reward_max: 43.6288659793815\n",
+      "  episode_reward_mean: 40.877048782789124\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1549\n",
+      "  episodes_total: 11691\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9412155350049337\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.007740705274045467\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012592456245329231\n",
+      "        total_loss: 1.2588910659154255\n",
+      "        vf_explained_var: 0.9897112846374512\n",
+      "        vf_loss: 1.2704059382279713\n",
+      "    num_steps_sampled: 1294336\n",
+      "    num_steps_trained: 1294336\n",
+      "  iterations_since_restore: 8\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.641666666666662\n",
+      "    gpu_util_percent0: 0.36375\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.570833333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15552725421090569\n",
+      "    mean_env_wait_ms: 0.6520038178299323\n",
+      "    mean_inference_ms: 4.534700600650504\n",
+      "    mean_raw_obs_processing_ms: 0.4096249844377919\n",
+      "  time_since_restore: 161.7805416584015\n",
+      "  time_this_iter_s: 19.946332216262817\n",
+      "  time_total_s: 161.7805416584015\n",
+      "  timers:\n",
+      "    learn_throughput: 11521.5\n",
+      "    learn_time_ms: 14042.616\n",
+      "    sample_throughput: 26651.946\n",
+      "    sample_time_ms: 6070.551\n",
+      "    update_time_ms: 35.676\n",
+      "  timestamp: 1604233764\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1294336\n",
+      "  training_iteration: 8\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |      8 |          161.781 | 1294336 |   40.877 |              43.6289 |              15.1237 |            110.013 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1339.0663941252176\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-29-44\n",
+      "  done: false\n",
+      "  episode_len_mean: 109.368015705225\n",
+      "  episode_reward_max: 43.6288659793815\n",
+      "  episode_reward_mean: 41.17822892762955\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1553\n",
+      "  episodes_total: 13244\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9079152892033259\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.0072981525445356965\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010131318272518305\n",
+      "        total_loss: 0.949362243215243\n",
+      "        vf_explained_var: 0.9923892021179199\n",
+      "        vf_loss: 0.9584879080454508\n",
+      "    num_steps_sampled: 1456128\n",
+      "    num_steps_trained: 1456128\n",
+      "  iterations_since_restore: 9\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.282608695652176\n",
+      "    gpu_util_percent0: 0.4395652173913045\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5739130434782598\n",
+      "    vram_util_percent0: 0.10109872089209576\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15471153080234437\n",
+      "    mean_env_wait_ms: 0.6512233236906179\n",
+      "    mean_inference_ms: 4.486726941601045\n",
+      "    mean_raw_obs_processing_ms: 0.40688607613554295\n",
+      "  time_since_restore: 181.48901557922363\n",
+      "  time_this_iter_s: 19.708473920822144\n",
+      "  time_total_s: 181.48901557922363\n",
+      "  timers:\n",
+      "    learn_throughput: 11526.677\n",
+      "    learn_time_ms: 14036.31\n",
+      "    sample_throughput: 26886.791\n",
+      "    sample_time_ms: 6017.527\n",
+      "    update_time_ms: 34.242\n",
+      "  timestamp: 1604233784\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1456128\n",
+      "  training_iteration: 9\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |      9 |          181.489 | 1456128 |  41.1782 |              43.6289 |              15.1237 |            109.368 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1334.3752454465434\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-30-04\n",
+      "  done: false\n",
+      "  episode_len_mean: 108.81228046473926\n",
+      "  episode_reward_max: 43.6288659793815\n",
+      "  episode_reward_mean: 41.422618434137334\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1560\n",
+      "  episodes_total: 14804\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.869762510061264\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.0075428458318735165\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009666072980811199\n",
+      "        total_loss: 0.7397742619117101\n",
+      "        vf_explained_var: 0.994184672832489\n",
+      "        vf_loss: 0.7483666588862737\n",
+      "    num_steps_sampled: 1617920\n",
+      "    num_steps_trained: 1617920\n",
+      "  iterations_since_restore: 10\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.833333333333332\n",
+      "    gpu_util_percent0: 0.31916666666666665\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.570833333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15401087755433693\n",
+      "    mean_env_wait_ms: 0.6506167732676298\n",
+      "    mean_inference_ms: 4.4459608456017845\n",
+      "    mean_raw_obs_processing_ms: 0.4045366030538726\n",
+      "  time_since_restore: 201.30298805236816\n",
+      "  time_this_iter_s: 19.81397247314453\n",
+      "  time_total_s: 201.30298805236816\n",
+      "  timers:\n",
+      "    learn_throughput: 11523.296\n",
+      "    learn_time_ms: 14040.428\n",
+      "    sample_throughput: 27081.39\n",
+      "    sample_time_ms: 5974.287\n",
+      "    update_time_ms: 34.416\n",
+      "  timestamp: 1604233804\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1617920\n",
+      "  training_iteration: 10\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     10 |          201.303 | 1617920 |  41.4226 |              43.6289 |              15.1237 |            108.812 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1330.5694061408346\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-30-25\n",
+      "  done: false\n",
+      "  episode_len_mean: 108.33194716242662\n",
+      "  episode_reward_max: 43.6288659793815\n",
+      "  episode_reward_mean: 41.6210186464785\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1548\n",
+      "  episodes_total: 16352\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8340491751829783\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006366107768068711\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009178327105473727\n",
+      "        total_loss: 0.6055479943752289\n",
+      "        vf_explained_var: 0.9953274130821228\n",
+      "        vf_loss: 0.6138701190551122\n",
+      "    num_steps_sampled: 1779712\n",
+      "    num_steps_trained: 1779712\n",
+      "  iterations_since_restore: 11\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.46666666666667\n",
+      "    gpu_util_percent0: 0.37000000000000005\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.570833333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15341006651547073\n",
+      "    mean_env_wait_ms: 0.650181832154063\n",
+      "    mean_inference_ms: 4.4112331201416435\n",
+      "    mean_raw_obs_processing_ms: 0.40254424691393875\n",
+      "  time_since_restore: 221.31696248054504\n",
+      "  time_this_iter_s: 20.01397442817688\n",
+      "  time_total_s: 221.31696248054504\n",
+      "  timers:\n",
+      "    learn_throughput: 11519.218\n",
+      "    learn_time_ms: 14045.398\n",
+      "    sample_throughput: 28288.316\n",
+      "    sample_time_ms: 5719.393\n",
+      "    update_time_ms: 33.239\n",
+      "  timestamp: 1604233825\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1779712\n",
+      "  training_iteration: 11\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     11 |          221.317 | 1779712 |   41.621 |              43.6289 |              15.1237 |            108.332 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1327.2690156599554\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-30-44\n",
+      "  done: false\n",
+      "  episode_len_mean: 107.91024281328495\n",
+      "  episode_reward_max: 43.6288659793815\n",
+      "  episode_reward_mean: 41.79185500832971\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1563\n",
+      "  episodes_total: 17915\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8071108410755793\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006752079119905829\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009787990158656612\n",
+      "        total_loss: 0.4518005351225535\n",
+      "        vf_explained_var: 0.9965425133705139\n",
+      "        vf_loss: 0.46064166476329166\n",
+      "    num_steps_sampled: 1941504\n",
+      "    num_steps_trained: 1941504\n",
+      "  iterations_since_restore: 12\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.460869565217386\n",
+      "    gpu_util_percent0: 0.4491304347826087\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5739130434782598\n",
+      "    vram_util_percent0: 0.10109872089209576\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15287929224510746\n",
+      "    mean_env_wait_ms: 0.649859182584871\n",
+      "    mean_inference_ms: 4.38067919169665\n",
+      "    mean_raw_obs_processing_ms: 0.40078994113897726\n",
+      "  time_since_restore: 240.91183829307556\n",
+      "  time_this_iter_s: 19.594875812530518\n",
+      "  time_total_s: 240.91183829307556\n",
+      "  timers:\n",
+      "    learn_throughput: 11522.834\n",
+      "    learn_time_ms: 14040.99\n",
+      "    sample_throughput: 28801.969\n",
+      "    sample_time_ms: 5617.394\n",
+      "    update_time_ms: 31.109\n",
+      "  timestamp: 1604233844\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1941504\n",
+      "  training_iteration: 12\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     12 |          240.912 | 1941504 |  41.7919 |              43.6289 |              15.1237 |             107.91 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1324.5485464368408\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-31-05\n",
+      "  done: false\n",
+      "  episode_len_mean: 107.57801746276323\n",
+      "  episode_reward_max: 43.6288659793815\n",
+      "  episode_reward_mean: 41.93343711446106\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1555\n",
+      "  episodes_total: 19470\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7690616647402445\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.0065094192589943605\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010228886812304458\n",
+      "        total_loss: 0.3978396902481715\n",
+      "        vf_explained_var: 0.9969910979270935\n",
+      "        vf_loss: 0.4071512247125308\n",
+      "    num_steps_sampled: 2103296\n",
+      "    num_steps_trained: 2103296\n",
+      "  iterations_since_restore: 13\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.712500000000002\n",
+      "    gpu_util_percent0: 0.40458333333333335\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.570833333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15241252197920177\n",
+      "    mean_env_wait_ms: 0.6496173991986937\n",
+      "    mean_inference_ms: 4.353964505075953\n",
+      "    mean_raw_obs_processing_ms: 0.3992612917500714\n",
+      "  time_since_restore: 260.9479441642761\n",
+      "  time_this_iter_s: 20.03610587120056\n",
+      "  time_total_s: 260.9479441642761\n",
+      "  timers:\n",
+      "    learn_throughput: 11495.402\n",
+      "    learn_time_ms: 14074.497\n",
+      "    sample_throughput: 29007.895\n",
+      "    sample_time_ms: 5577.516\n",
+      "    update_time_ms: 31.578\n",
+      "  timestamp: 1604233865\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2103296\n",
+      "  training_iteration: 13\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     13 |          260.948 | 2103296 |  41.9334 |              43.6289 |              15.1237 |            107.578 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1322.226\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-31-25\n",
+      "  done: false\n",
+      "  episode_len_mean: 107.29351081530783\n",
+      "  episode_reward_max: 43.6288659793815\n",
+      "  episode_reward_mean: 42.054489449346825\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1565\n",
+      "  episodes_total: 21035\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7336616019407908\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.0064004862603421015\n",
+      "        model: {}\n",
+      "        policy_loss: -0.008804643754653322\n",
+      "        total_loss: 0.3278699740767479\n",
+      "        vf_explained_var: 0.9975385069847107\n",
+      "        vf_loss: 0.33576134343942005\n",
+      "    num_steps_sampled: 2265088\n",
+      "    num_steps_trained: 2265088\n",
+      "  iterations_since_restore: 14\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.491666666666664\n",
+      "    gpu_util_percent0: 0.32416666666666666\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.570833333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15199672808495696\n",
+      "    mean_env_wait_ms: 0.6494243284753675\n",
+      "    mean_inference_ms: 4.330132256006824\n",
+      "    mean_raw_obs_processing_ms: 0.39788879446265113\n",
+      "  time_since_restore: 280.836660861969\n",
+      "  time_this_iter_s: 19.88871669769287\n",
+      "  time_total_s: 280.836660861969\n",
+      "  timers:\n",
+      "    learn_throughput: 11490.563\n",
+      "    learn_time_ms: 14080.424\n",
+      "    sample_throughput: 29086.085\n",
+      "    sample_time_ms: 5562.523\n",
+      "    update_time_ms: 31.329\n",
+      "  timestamp: 1604233885\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2265088\n",
+      "  training_iteration: 14\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     14 |          280.837 | 2265088 |  42.0545 |              43.6289 |              15.1237 |            107.294 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1320.1891843971632\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-31-45\n",
+      "  done: false\n",
+      "  episode_len_mean: 107.05496791325514\n",
+      "  episode_reward_max: 43.6288659793815\n",
+      "  episode_reward_mean: 42.16018734187611\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1560\n",
+      "  episodes_total: 22595\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7067601482073466\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006438710144720972\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010162829411759352\n",
+      "        total_loss: 0.2576701765259107\n",
+      "        vf_explained_var: 0.9980695843696594\n",
+      "        vf_loss: 0.26689864446719486\n",
+      "    num_steps_sampled: 2426880\n",
+      "    num_steps_trained: 2426880\n",
+      "  iterations_since_restore: 15\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.404347826086955\n",
+      "    gpu_util_percent0: 0.3060869565217391\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5739130434782598\n",
+      "    vram_util_percent0: 0.10109872089209576\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15162840674833306\n",
+      "    mean_env_wait_ms: 0.6492838913939692\n",
+      "    mean_inference_ms: 4.308869472451551\n",
+      "    mean_raw_obs_processing_ms: 0.3966675681414554\n",
+      "  time_since_restore: 300.50964164733887\n",
+      "  time_this_iter_s: 19.672980785369873\n",
+      "  time_total_s: 300.50964164733887\n",
+      "  timers:\n",
+      "    learn_throughput: 11490.394\n",
+      "    learn_time_ms: 14080.631\n",
+      "    sample_throughput: 29052.047\n",
+      "    sample_time_ms: 5569.04\n",
+      "    update_time_ms: 29.544\n",
+      "  timestamp: 1604233905\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2426880\n",
+      "  training_iteration: 15\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     15 |           300.51 | 2426880 |  42.1602 |              43.6289 |              15.1237 |            107.055 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1318.4346780546457\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-32-06\n",
+      "  done: false\n",
+      "  episode_len_mean: 106.84805829262234\n",
+      "  episode_reward_max: 43.6288659793815\n",
+      "  episode_reward_mean: 42.2515568060273\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1559\n",
+      "  episodes_total: 24154\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.6743296881516775\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006636352161876857\n",
+      "        model: {}\n",
+      "        policy_loss: -0.00975274900944593\n",
+      "        total_loss: 0.23658680294950804\n",
+      "        vf_explained_var: 0.9982344508171082\n",
+      "        vf_loss: 0.2453494481742382\n",
+      "    num_steps_sampled: 2588672\n",
+      "    num_steps_trained: 2588672\n",
+      "  iterations_since_restore: 16\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.991666666666664\n",
+      "    gpu_util_percent0: 0.33416666666666667\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.570833333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15129670825904046\n",
+      "    mean_env_wait_ms: 0.6491675546769002\n",
+      "    mean_inference_ms: 4.289756257599939\n",
+      "    mean_raw_obs_processing_ms: 0.39556396298388297\n",
+      "  time_since_restore: 320.2244436740875\n",
+      "  time_this_iter_s: 19.714802026748657\n",
+      "  time_total_s: 320.2244436740875\n",
+      "  timers:\n",
+      "    learn_throughput: 11483.06\n",
+      "    learn_time_ms: 14089.624\n",
+      "    sample_throughput: 29083.807\n",
+      "    sample_time_ms: 5562.958\n",
+      "    update_time_ms: 30.273\n",
+      "  timestamp: 1604233926\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2588672\n",
+      "  training_iteration: 16\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     16 |          320.224 | 2588672 |  42.2516 |              43.6289 |              15.1237 |            106.848 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1316.8612322791712\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-32-26\n",
+      "  done: false\n",
+      "  episode_len_mean: 106.6750029170394\n",
+      "  episode_reward_max: 43.6288659793815\n",
+      "  episode_reward_mean: 42.333070966857214\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1557\n",
+      "  episodes_total: 25711\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.6487419108549753\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006434203319561978\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010461925092386082\n",
+      "        total_loss: 0.18015940859913826\n",
+      "        vf_explained_var: 0.9986326694488525\n",
+      "        vf_loss: 0.1896588665743669\n",
+      "    num_steps_sampled: 2750464\n",
+      "    num_steps_trained: 2750464\n",
+      "  iterations_since_restore: 17\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.604347826086954\n",
+      "    gpu_util_percent0: 0.4843478260869565\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5739130434782598\n",
+      "    vram_util_percent0: 0.10109872089209576\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15099532910883745\n",
+      "    mean_env_wait_ms: 0.6490596721671469\n",
+      "    mean_inference_ms: 4.272450859355698\n",
+      "    mean_raw_obs_processing_ms: 0.3945623850682107\n",
+      "  time_since_restore: 339.8860158920288\n",
+      "  time_this_iter_s: 19.661572217941284\n",
+      "  time_total_s: 339.8860158920288\n",
+      "  timers:\n",
+      "    learn_throughput: 11488.521\n",
+      "    learn_time_ms: 14082.927\n",
+      "    sample_throughput: 29093.385\n",
+      "    sample_time_ms: 5561.127\n",
+      "    update_time_ms: 30.118\n",
+      "  timestamp: 1604233946\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2750464\n",
+      "  training_iteration: 17\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     17 |          339.886 | 2750464 |  42.3331 |              43.6289 |              15.1237 |            106.675 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1315.4772084481176\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-32-46\n",
+      "  done: false\n",
+      "  episode_len_mean: 106.53646368305209\n",
+      "  episode_reward_max: 43.6288659793815\n",
+      "  episode_reward_mean: 42.40514405004122\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1549\n",
+      "  episodes_total: 27260\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.6147788117329279\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006190092225248615\n",
+      "        model: {}\n",
+      "        policy_loss: -0.00844319449000371\n",
+      "        total_loss: 0.15160012369354567\n",
+      "        vf_explained_var: 0.9988699555397034\n",
+      "        vf_loss: 0.15911269187927246\n",
+      "    num_steps_sampled: 2912256\n",
+      "    num_steps_trained: 2912256\n",
+      "  iterations_since_restore: 18\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.108333333333334\n",
+      "    gpu_util_percent0: 0.40958333333333335\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.570833333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15072186700405005\n",
+      "    mean_env_wait_ms: 0.6489589654205459\n",
+      "    mean_inference_ms: 4.256776083733925\n",
+      "    mean_raw_obs_processing_ms: 0.3936520268695803\n",
+      "  time_since_restore: 359.4751284122467\n",
+      "  time_this_iter_s: 19.589112520217896\n",
+      "  time_total_s: 359.4751284122467\n",
+      "  timers:\n",
+      "    learn_throughput: 11502.311\n",
+      "    learn_time_ms: 14066.043\n",
+      "    sample_throughput: 29213.386\n",
+      "    sample_time_ms: 5538.283\n",
+      "    update_time_ms: 28.725\n",
+      "  timestamp: 1604233966\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2912256\n",
+      "  training_iteration: 18\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     18 |          359.475 | 2912256 |  42.4051 |              43.6289 |              15.1237 |            106.536 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1314.2216509171762\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-33-07\n",
+      "  done: false\n",
+      "  episode_len_mean: 106.39508657482911\n",
+      "  episode_reward_max: 43.6288659793815\n",
+      "  episode_reward_mean: 42.47027859269532\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1559\n",
+      "  episodes_total: 28819\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.5793089667956034\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005601404506402711\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009277280846921107\n",
+      "        total_loss: 0.12121031371255715\n",
+      "        vf_explained_var: 0.9990783333778381\n",
+      "        vf_loss: 0.1296569655338923\n",
+      "    num_steps_sampled: 3074048\n",
+      "    num_steps_trained: 3074048\n",
+      "  iterations_since_restore: 19\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.066666666666663\n",
+      "    gpu_util_percent0: 0.3979166666666667\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.570833333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1504690836889304\n",
+      "    mean_env_wait_ms: 0.6488696992500765\n",
+      "    mean_inference_ms: 4.242361495701079\n",
+      "    mean_raw_obs_processing_ms: 0.39280933914753613\n",
+      "  time_since_restore: 379.6264307498932\n",
+      "  time_this_iter_s: 20.151302337646484\n",
+      "  time_total_s: 379.6264307498932\n",
+      "  timers:\n",
+      "    learn_throughput: 11477.051\n",
+      "    learn_time_ms: 14097.001\n",
+      "    sample_throughput: 29213.738\n",
+      "    sample_time_ms: 5538.216\n",
+      "    update_time_ms: 30.107\n",
+      "  timestamp: 1604233987\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3074048\n",
+      "  training_iteration: 19\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     19 |          379.626 | 3074048 |  42.4703 |              43.6289 |              15.1237 |            106.395 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1313.0996867271228\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-33-27\n",
+      "  done: false\n",
+      "  episode_len_mean: 106.30233860342555\n",
+      "  episode_reward_max: 43.6288659793815\n",
+      "  episode_reward_mean: 42.528634054575335\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1541\n",
+      "  episodes_total: 30360\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.5525011867284775\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005483048929211994\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009698755030209819\n",
+      "        total_loss: 0.09727698999146621\n",
+      "        vf_explained_var: 0.9992494583129883\n",
+      "        vf_loss: 0.10615538681546847\n",
+      "    num_steps_sampled: 3235840\n",
+      "    num_steps_trained: 3235840\n",
+      "  iterations_since_restore: 20\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.075\n",
+      "    gpu_util_percent0: 0.43416666666666665\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.570833333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15023976063883285\n",
+      "    mean_env_wait_ms: 0.6487841053204015\n",
+      "    mean_inference_ms: 4.22926206402729\n",
+      "    mean_raw_obs_processing_ms: 0.3920470315060969\n",
+      "  time_since_restore: 399.4815435409546\n",
+      "  time_this_iter_s: 19.8551127910614\n",
+      "  time_total_s: 399.4815435409546\n",
+      "  timers:\n",
+      "    learn_throughput: 11477.093\n",
+      "    learn_time_ms: 14096.949\n",
+      "    sample_throughput: 29223.589\n",
+      "    sample_time_ms: 5536.349\n",
+      "    update_time_ms: 30.052\n",
+      "  timestamp: 1604234007\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3235840\n",
+      "  training_iteration: 20\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     20 |          399.482 | 3235840 |  42.5286 |              43.6289 |              15.1237 |            106.302 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1312.0721969578171\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-33-47\n",
+      "  done: false\n",
+      "  episode_len_mean: 106.19890350877193\n",
+      "  episode_reward_max: 43.6288659793815\n",
+      "  episode_reward_mean: 42.58196716016847\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1560\n",
+      "  episodes_total: 31920\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.5238876193761826\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005134576039078335\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009323944701463915\n",
+      "        total_loss: 0.0834660033384959\n",
+      "        vf_explained_var: 0.9993599057197571\n",
+      "        vf_loss: 0.09202497576673825\n",
+      "    num_steps_sampled: 3397632\n",
+      "    num_steps_trained: 3397632\n",
+      "  iterations_since_restore: 21\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.617391304347823\n",
+      "    gpu_util_percent0: 0.4456521739130434\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5739130434782598\n",
+      "    vram_util_percent0: 0.10109872089209576\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15002456451472287\n",
+      "    mean_env_wait_ms: 0.6487047149986278\n",
+      "    mean_inference_ms: 4.2170315233202755\n",
+      "    mean_raw_obs_processing_ms: 0.3913318433017469\n",
+      "  time_since_restore: 419.1035006046295\n",
+      "  time_this_iter_s: 19.621957063674927\n",
+      "  time_total_s: 419.1035006046295\n",
+      "  timers:\n",
+      "    learn_throughput: 11505.071\n",
+      "    learn_time_ms: 14062.668\n",
+      "    sample_throughput: 29282.333\n",
+      "    sample_time_ms: 5525.243\n",
+      "    update_time_ms: 30.159\n",
+      "  timestamp: 1604234027\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3397632\n",
+      "  training_iteration: 21\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     21 |          419.104 | 3397632 |   42.582 |              43.6289 |              15.1237 |            106.199 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1311.1479420914095\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-34-08\n",
+      "  done: false\n",
+      "  episode_len_mean: 106.12468999312756\n",
+      "  episode_reward_max: 43.6288659793815\n",
+      "  episode_reward_mean: 42.630005430799805\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1547\n",
+      "  episodes_total: 33467\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.49701932817697525\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005340795614756644\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010354490535974037\n",
+      "        total_loss: 0.07194800892223914\n",
+      "        vf_explained_var: 0.9994434714317322\n",
+      "        vf_loss: 0.0814828487734\n",
+      "    num_steps_sampled: 3559424\n",
+      "    num_steps_trained: 3559424\n",
+      "  iterations_since_restore: 22\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.325\n",
+      "    gpu_util_percent0: 0.37458333333333327\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.570833333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.14982882739957487\n",
+      "    mean_env_wait_ms: 0.6486235678612109\n",
+      "    mean_inference_ms: 4.205782708358309\n",
+      "    mean_raw_obs_processing_ms: 0.39066600076646296\n",
+      "  time_since_restore: 438.92495369911194\n",
+      "  time_this_iter_s: 19.821453094482422\n",
+      "  time_total_s: 438.92495369911194\n",
+      "  timers:\n",
+      "    learn_throughput: 11494.245\n",
+      "    learn_time_ms: 14075.914\n",
+      "    sample_throughput: 29271.325\n",
+      "    sample_time_ms: 5527.321\n",
+      "    update_time_ms: 31.246\n",
+      "  timestamp: 1604234048\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3559424\n",
+      "  training_iteration: 22\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     22 |          438.925 | 3559424 |    42.63 |              43.6289 |              15.1237 |            106.125 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1310.3136940853449\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-34-28\n",
+      "  done: false\n",
+      "  episode_len_mean: 106.08285951027172\n",
+      "  episode_reward_max: 43.6288659793815\n",
+      "  episode_reward_mean: 42.67351320494282\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1532\n",
+      "  episodes_total: 34999\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.4672253554066022\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005037993270282944\n",
+      "        model: {}\n",
+      "        policy_loss: -0.00685786875934961\n",
+      "        total_loss: 0.06014314107596874\n",
+      "        vf_explained_var: 0.9995446801185608\n",
+      "        vf_loss: 0.06622702504197757\n",
+      "    num_steps_sampled: 3721216\n",
+      "    num_steps_trained: 3721216\n",
+      "  iterations_since_restore: 23\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.15416666666667\n",
+      "    gpu_util_percent0: 0.3633333333333333\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.570833333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1496488629333257\n",
+      "    mean_env_wait_ms: 0.6485461766268289\n",
+      "    mean_inference_ms: 4.195418444138528\n",
+      "    mean_raw_obs_processing_ms: 0.3900530056382457\n",
+      "  time_since_restore: 458.79926347732544\n",
+      "  time_this_iter_s: 19.8743097782135\n",
+      "  time_total_s: 458.79926347732544\n",
+      "  timers:\n",
+      "    learn_throughput: 11517.323\n",
+      "    learn_time_ms: 14047.709\n",
+      "    sample_throughput: 29258.763\n",
+      "    sample_time_ms: 5529.694\n",
+      "    update_time_ms: 32.041\n",
+      "  timestamp: 1604234068\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3721216\n",
+      "  training_iteration: 23\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     23 |          458.799 | 3721216 |  42.6735 |              43.6289 |              15.1237 |            106.083 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1309.5558966207143\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-34-49\n",
+      "  done: false\n",
+      "  episode_len_mean: 106.0737637588303\n",
+      "  episode_reward_max: 43.6288659793815\n",
+      "  episode_reward_mean: 42.71301353738489\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1523\n",
+      "  episodes_total: 36522\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.4321850041548411\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.0057120353837187094\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009051567967010973\n",
+      "        total_loss: 0.05148738451922933\n",
+      "        vf_explained_var: 0.9995923042297363\n",
+      "        vf_loss: 0.059612637696166836\n",
+      "    num_steps_sampled: 3883008\n",
+      "    num_steps_trained: 3883008\n",
+      "  iterations_since_restore: 24\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.6125\n",
+      "    gpu_util_percent0: 0.35374999999999995\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.570833333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.14948084784143242\n",
+      "    mean_env_wait_ms: 0.6484509328204054\n",
+      "    mean_inference_ms: 4.185812792415693\n",
+      "    mean_raw_obs_processing_ms: 0.38947414275749065\n",
+      "  time_since_restore: 478.84203243255615\n",
+      "  time_this_iter_s: 20.042768955230713\n",
+      "  time_total_s: 478.84203243255615\n",
+      "  timers:\n",
+      "    learn_throughput: 11501.58\n",
+      "    learn_time_ms: 14066.937\n",
+      "    sample_throughput: 29276.676\n",
+      "    sample_time_ms: 5526.31\n",
+      "    update_time_ms: 31.839\n",
+      "  timestamp: 1604234089\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3883008\n",
+      "  training_iteration: 24\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     24 |          478.842 | 3883008 |   42.713 |              43.6289 |              15.1237 |            106.074 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1308.854354630823\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-35-09\n",
+      "  done: false\n",
+      "  episode_len_mean: 106.09423946178913\n",
+      "  episode_reward_max: 43.6288659793815\n",
+      "  episode_reward_mean: 42.74960796999439\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1530\n",
+      "  episodes_total: 38052\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.40411561727523804\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.004467884932334225\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007561299067068224\n",
+      "        total_loss: 0.0415184999195238\n",
+      "        vf_explained_var: 0.9996755123138428\n",
+      "        vf_loss: 0.0483882799744606\n",
+      "    num_steps_sampled: 4044800\n",
+      "    num_steps_trained: 4044800\n",
+      "  iterations_since_restore: 25\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.00833333333333\n",
+      "    gpu_util_percent0: 0.3670833333333334\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.570833333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.14932390485994398\n",
+      "    mean_env_wait_ms: 0.6483514849496743\n",
+      "    mean_inference_ms: 4.176778186793073\n",
+      "    mean_raw_obs_processing_ms: 0.38892542131807273\n",
+      "  time_since_restore: 498.6148178577423\n",
+      "  time_this_iter_s: 19.772785425186157\n",
+      "  time_total_s: 498.6148178577423\n",
+      "  timers:\n",
+      "    learn_throughput: 11493.615\n",
+      "    learn_time_ms: 14076.686\n",
+      "    sample_throughput: 29308.484\n",
+      "    sample_time_ms: 5520.313\n",
+      "    update_time_ms: 31.941\n",
+      "  timestamp: 1604234109\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4044800\n",
+      "  training_iteration: 25\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "2020-11-01 12:35:10,587\tWARNING util.py:136 -- The `process_trial` operation took 0.5158097743988037 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     25 |          498.615 | 4044800 |  42.7496 |              43.6289 |              15.1237 |            106.094 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1308.2223065826438\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-35-30\n",
+      "  done: false\n",
+      "  episode_len_mean: 106.13998179427531\n",
+      "  episode_reward_max: 43.6288659793815\n",
+      "  episode_reward_mean: 42.78251353698859\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1496\n",
+      "  episodes_total: 39548\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.3710899030168851\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005478878777163724\n",
+      "        model: {}\n",
+      "        policy_loss: -0.008370831223146524\n",
+      "        total_loss: 0.03866795807455977\n",
+      "        vf_explained_var: 0.9996917843818665\n",
+      "        vf_loss: 0.04667644730458657\n",
+      "    num_steps_sampled: 4206592\n",
+      "    num_steps_trained: 4206592\n",
+      "  iterations_since_restore: 26\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.104166666666668\n",
+      "    gpu_util_percent0: 0.3454166666666667\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.570833333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.14918014489593562\n",
+      "    mean_env_wait_ms: 0.6482521101593612\n",
+      "    mean_inference_ms: 4.168509263007074\n",
+      "    mean_raw_obs_processing_ms: 0.38842351941405706\n",
+      "  time_since_restore: 518.4228372573853\n",
+      "  time_this_iter_s: 19.808019399642944\n",
+      "  time_total_s: 518.4228372573853\n",
+      "  timers:\n",
+      "    learn_throughput: 11494.237\n",
+      "    learn_time_ms: 14075.924\n",
+      "    sample_throughput: 29292.382\n",
+      "    sample_time_ms: 5523.347\n",
+      "    update_time_ms: 32.345\n",
+      "  timestamp: 1604234130\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4206592\n",
+      "  training_iteration: 26\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "2020-11-01 12:35:31,149\tWARNING util.py:136 -- The `process_trial` operation took 0.5663919448852539 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     26 |          518.423 | 4206592 |  42.7825 |              43.6289 |              15.1237 |             106.14 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1307.6298878595808\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-35-51\n",
+      "  done: false\n",
+      "  episode_len_mean: 106.21381074168798\n",
+      "  episode_reward_max: 43.6288659793815\n",
+      "  episode_reward_mean: 42.81325152203418\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1507\n",
+      "  episodes_total: 41055\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.3422661249836286\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.004864616707588236\n",
+      "        model: {}\n",
+      "        policy_loss: -0.008692707876131559\n",
+      "        total_loss: 0.03158797137439251\n",
+      "        vf_explained_var: 0.9997386336326599\n",
+      "        vf_loss: 0.03996535111218691\n",
+      "    num_steps_sampled: 4368384\n",
+      "    num_steps_trained: 4368384\n",
+      "  iterations_since_restore: 27\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.462500000000002\n",
+      "    gpu_util_percent0: 0.33499999999999996\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.570833333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.14904403737255034\n",
+      "    mean_env_wait_ms: 0.6481460554960611\n",
+      "    mean_inference_ms: 4.160632746558721\n",
+      "    mean_raw_obs_processing_ms: 0.38794815762152746\n",
+      "  time_since_restore: 538.5130481719971\n",
+      "  time_this_iter_s: 20.090210914611816\n",
+      "  time_total_s: 538.5130481719971\n",
+      "  timers:\n",
+      "    learn_throughput: 11475.693\n",
+      "    learn_time_ms: 14098.67\n",
+      "    sample_throughput: 29224.222\n",
+      "    sample_time_ms: 5536.23\n",
+      "    update_time_ms: 32.82\n",
+      "  timestamp: 1604234151\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4368384\n",
+      "  training_iteration: 27\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "2020-11-01 12:35:52,001\tWARNING util.py:136 -- The `process_trial` operation took 0.5398478507995605 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     27 |          538.513 | 4368384 |  42.8133 |              43.6289 |              15.1237 |            106.214 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1307.0917562892712\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-36-11\n",
+      "  done: false\n",
+      "  episode_len_mean: 106.31207674943566\n",
+      "  episode_reward_max: 43.6288659793815\n",
+      "  episode_reward_mean: 42.841272069147415\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1473\n",
+      "  episodes_total: 42528\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.05000000000000001\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.31406934062639874\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.00531899471146365\n",
+      "        model: {}\n",
+      "        policy_loss: -0.006233617905915405\n",
+      "        total_loss: 0.027707914200921852\n",
+      "        vf_explained_var: 0.9997760653495789\n",
+      "        vf_loss: 0.0338326171040535\n",
+      "    num_steps_sampled: 4530176\n",
+      "    num_steps_trained: 4530176\n",
+      "  iterations_since_restore: 28\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.541666666666668\n",
+      "    gpu_util_percent0: 0.38791666666666663\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.570833333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.14891911374014252\n",
+      "    mean_env_wait_ms: 0.6480333835817965\n",
+      "    mean_inference_ms: 4.153395707395419\n",
+      "    mean_raw_obs_processing_ms: 0.38750819763907707\n",
+      "  time_since_restore: 558.2239861488342\n",
+      "  time_this_iter_s: 19.710937976837158\n",
+      "  time_total_s: 558.2239861488342\n",
+      "  timers:\n",
+      "    learn_throughput: 11465.354\n",
+      "    learn_time_ms: 14111.382\n",
+      "    sample_throughput: 29254.98\n",
+      "    sample_time_ms: 5530.409\n",
+      "    update_time_ms: 31.925\n",
+      "  timestamp: 1604234171\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4530176\n",
+      "  training_iteration: 28\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "2020-11-01 12:36:12,490\tWARNING util.py:136 -- The `process_trial` operation took 0.5777196884155273 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     28 |          558.224 | 4530176 |  42.8413 |              43.6289 |              15.1237 |            106.312 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1306.5912378872663\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-36-32\n",
+      "  done: false\n",
+      "  episode_len_mean: 106.44389390185694\n",
+      "  episode_reward_max: 43.6288659793815\n",
+      "  episode_reward_mean: 42.86740122159219\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1469\n",
+      "  episodes_total: 43997\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.05000000000000001\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.2867726534605026\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005043890094384551\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007655571622308344\n",
+      "        total_loss: 0.01982968676990519\n",
+      "        vf_explained_var: 0.999823808670044\n",
+      "        vf_loss: 0.027376449356476467\n",
+      "    num_steps_sampled: 4691968\n",
+      "    num_steps_trained: 4691968\n",
+      "  iterations_since_restore: 29\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.208333333333332\n",
+      "    gpu_util_percent0: 0.3120833333333333\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.570833333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.148801680479015\n",
+      "    mean_env_wait_ms: 0.6479110446105578\n",
+      "    mean_inference_ms: 4.146556745190422\n",
+      "    mean_raw_obs_processing_ms: 0.3870915915108458\n",
+      "  time_since_restore: 578.142192363739\n",
+      "  time_this_iter_s: 19.918206214904785\n",
+      "  time_total_s: 578.142192363739\n",
+      "  timers:\n",
+      "    learn_throughput: 11477.643\n",
+      "    learn_time_ms: 14096.274\n",
+      "    sample_throughput: 29295.707\n",
+      "    sample_time_ms: 5522.72\n",
+      "    update_time_ms: 31.506\n",
+      "  timestamp: 1604234192\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4691968\n",
+      "  training_iteration: 29\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "2020-11-01 12:36:33,192\tWARNING util.py:136 -- The `process_trial` operation took 0.567206621170044 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     29 |          578.142 | 4691968 |  42.8674 |              43.6289 |              15.1237 |            106.444 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1306.1297474625158\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-36-52\n",
+      "  done: false\n",
+      "  episode_len_mean: 106.60159721916663\n",
+      "  episode_reward_max: 43.6288659793815\n",
+      "  episode_reward_mean: 42.89145908926165\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1457\n",
+      "  episodes_total: 45454\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.05000000000000001\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.25657347589731216\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.004977851562822859\n",
+      "        model: {}\n",
+      "        policy_loss: -0.0074265640663118875\n",
+      "        total_loss: 0.020246487848150235\n",
+      "        vf_explained_var: 0.999823272228241\n",
+      "        vf_loss: 0.02755244541913271\n",
+      "    num_steps_sampled: 4853760\n",
+      "    num_steps_trained: 4853760\n",
+      "  iterations_since_restore: 30\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.96666666666667\n",
+      "    gpu_util_percent0: 0.34375\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.570833333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1486911615858267\n",
+      "    mean_env_wait_ms: 0.647780786364401\n",
+      "    mean_inference_ms: 4.140117442125262\n",
+      "    mean_raw_obs_processing_ms: 0.3867002477159633\n",
+      "  time_since_restore: 597.9215953350067\n",
+      "  time_this_iter_s: 19.7794029712677\n",
+      "  time_total_s: 597.9215953350067\n",
+      "  timers:\n",
+      "    learn_throughput: 11482.292\n",
+      "    learn_time_ms: 14090.567\n",
+      "    sample_throughput: 29325.187\n",
+      "    sample_time_ms: 5517.169\n",
+      "    update_time_ms: 29.907\n",
+      "  timestamp: 1604234212\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4853760\n",
+      "  training_iteration: 30\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "2020-11-01 12:36:53,780\tWARNING util.py:136 -- The `process_trial` operation took 0.5981490612030029 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     30 |          597.922 | 4853760 |  42.8915 |              43.6289 |              15.1237 |            106.602 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1305.6988838856996\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-37-13\n",
+      "  done: true\n",
+      "  episode_len_mean: 106.77159124834733\n",
+      "  episode_reward_max: 43.6288659793815\n",
+      "  episode_reward_mean: 42.91394806184951\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1440\n",
+      "  episodes_total: 46894\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.025000000000000005\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.22576802472273508\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.0045362276723608375\n",
+      "        model: {}\n",
+      "        policy_loss: -0.005217552456694345\n",
+      "        total_loss: 0.01427166493764768\n",
+      "        vf_explained_var: 0.9998777508735657\n",
+      "        vf_loss: 0.01948869600892067\n",
+      "    num_steps_sampled: 5015552\n",
+      "    num_steps_trained: 5015552\n",
+      "  iterations_since_restore: 31\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.72083333333333\n",
+      "    gpu_util_percent0: 0.36166666666666664\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.570833333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.14858768250616303\n",
+      "    mean_env_wait_ms: 0.6476419244786176\n",
+      "    mean_inference_ms: 4.134089086382151\n",
+      "    mean_raw_obs_processing_ms: 0.3863330350642181\n",
+      "  time_since_restore: 617.738039970398\n",
+      "  time_this_iter_s: 19.816444635391235\n",
+      "  time_total_s: 617.738039970398\n",
+      "  timers:\n",
+      "    learn_throughput: 11472.012\n",
+      "    learn_time_ms: 14103.193\n",
+      "    sample_throughput: 29323.896\n",
+      "    sample_time_ms: 5517.411\n",
+      "    update_time_ms: 29.881\n",
+      "  timestamp: 1604234233\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 5015552\n",
+      "  training_iteration: 31\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "2020-11-01 12:37:14,609\tWARNING util.py:136 -- The `process_trial` operation took 0.7420144081115723 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 24.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | TERMINATED |       |     31 |          617.738 | 5015552 |  42.9139 |              43.6289 |              15.1237 |            106.772 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1101 12:37:14.976943 34403 34403 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Socket closed\n",
+      "== Status ==\n",
+      "Memory usage on this node: 24.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | TERMINATED |       |     31 |          617.738 | 5015552 |  42.9139 |              43.6289 |              15.1237 |            106.772 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 34338\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201101_122629-fdb3wrbz/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201101_122629-fdb3wrbz/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 1292\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 646\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1604234235\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 1845\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 1305.69888\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 43.62887\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 15.12371\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 42.91395\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 46894\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 31\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mpretty-sweep-4\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/fdb3wrbz\u001b[0m\n",
+      "2020-11-01 12:37:24,612 - wandb.wandb_agent - INFO - Cleaning up finished run: fdb3wrbz\n",
+      "2020-11-01 12:37:24,941 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-11-01 12:37:24,941 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tinstance_path: /JSS/JSS/env/instances/la/la15.txt\n",
+      "2020-11-01 12:37:24,943 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --instance_path=/JSS/JSS/env/instances/la/la15.txt\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.8 is available!  To upgrade, please run:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
+      "2020-11-01 12:37:29,961 - wandb.wandb_agent - INFO - Running runs: ['pq2fv3jo']\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdifferent-sweep-5\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/sweeps/9xhkl8my\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/pq2fv3jo\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201101_123726-pq2fv3jo\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
+      "\n",
+      "2020-11-01 12:37:30,609\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
+      "== Status ==\n",
+      "Memory usage on this node: 12.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  |       |\n",
+      "+-------------------------+----------+-------+\n",
+      "\n",
+      "\n",
+      "\u001b[2m\u001b[36m(pid=67571)\u001b[0m 2020-11-01 12:37:33,413\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=67560)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67560)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67520)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67520)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67567)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67567)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67478)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67478)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67518)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67518)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67536)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67536)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67514)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67514)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67448)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67448)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67564)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67564)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67534)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67534)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67524)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67524)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67529)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67529)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67569)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67569)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67563)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67563)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67445)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67445)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67547)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67547)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67531)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67531)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67540)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67540)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67545)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67545)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67462)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67462)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67447)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67447)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67453)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67453)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67469)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67469)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67452)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67452)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67541)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67541)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67477)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67477)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67446)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67446)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67475)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67475)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67553)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67553)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67472)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67472)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67468)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67468)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67556)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67556)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67450)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67450)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67566)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67566)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67527)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67527)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67455)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67455)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67457)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67457)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67456)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67456)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67466)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67466)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67459)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67459)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67476)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67476)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67467)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67467)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67516)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67516)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67521)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67521)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67515)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67515)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67512)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67512)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67568)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67568)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67551)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67551)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67519)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67519)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67537)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67537)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67525)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67525)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67546)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67546)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67451)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67451)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67581)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67581)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67449)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67449)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67530)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67530)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67562)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67562)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67533)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67533)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67522)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67522)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67464)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67464)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67573)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67573)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67463)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67463)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67506)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67506)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67555)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67555)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67523)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67523)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67544)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67544)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67461)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67461)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67513)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67513)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67479)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67479)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67510)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67510)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67526)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67526)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67473)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67473)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67548)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67548)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67460)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67460)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67552)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67552)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67509)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67509)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67465)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67465)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67517)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67517)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67559)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67559)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1540.9259259259259\n",
+      "    time_step_min: 1302\n",
+      "  date: 2020-11-01_12-38-00\n",
+      "  done: false\n",
+      "  episode_len_mean: 118.22310126582279\n",
+      "  episode_reward_max: 44.242424242424256\n",
+      "  episode_reward_mean: 32.03126997826365\n",
+      "  episode_reward_min: 13.989898989898997\n",
+      "  episodes_this_iter: 1264\n",
+      "  episodes_total: 1264\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1447077592213948\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005619530449621379\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007155387702672063\n",
+      "        total_loss: 40.47618579864502\n",
+      "        vf_explained_var: 0.7891119122505188\n",
+      "        vf_loss: 40.48278999328613\n",
+      "    num_steps_sampled: 161792\n",
+      "    num_steps_trained: 161792\n",
+      "  iterations_since_restore: 1\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 30.218518518518522\n",
+      "    gpu_util_percent0: 0.36629629629629634\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.440740740740741\n",
+      "    vram_util_percent0: 0.08366130971903357\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16496450454226685\n",
+      "    mean_env_wait_ms: 0.6576280720479034\n",
+      "    mean_inference_ms: 4.788716243497749\n",
+      "    mean_raw_obs_processing_ms: 0.4281524023401697\n",
+      "  time_since_restore: 22.09221601486206\n",
+      "  time_this_iter_s: 22.09221601486206\n",
+      "  time_total_s: 22.09221601486206\n",
+      "  timers:\n",
+      "    learn_throughput: 10922.862\n",
+      "    learn_time_ms: 14812.235\n",
+      "    sample_throughput: 22479.319\n",
+      "    sample_time_ms: 7197.371\n",
+      "    update_time_ms: 46.828\n",
+      "  timestamp: 1604234280\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 161792\n",
+      "  training_iteration: 1\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |      1 |          22.0922 | 161792 |  32.0313 |              44.2424 |              13.9899 |            118.223 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1531.6367083807356\n",
+      "    time_step_min: 1302\n",
+      "  date: 2020-11-01_12-38-22\n",
+      "  done: false\n",
+      "  episode_len_mean: 117.54839910647803\n",
+      "  episode_reward_max: 44.242424242424256\n",
+      "  episode_reward_mean: 32.54738374060787\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1422\n",
+      "  episodes_total: 2686\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1255147556463878\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.009991972551991543\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012213830874922374\n",
+      "        total_loss: 10.040241003036499\n",
+      "        vf_explained_var: 0.9008758068084717\n",
+      "        vf_loss: 10.051019430160522\n",
+      "    num_steps_sampled: 323584\n",
+      "    num_steps_trained: 323584\n",
+      "  iterations_since_restore: 2\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.98846153846154\n",
+      "    gpu_util_percent0: 0.4046153846153846\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.511538461538462\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16294808968714042\n",
+      "    mean_env_wait_ms: 0.6564847478917705\n",
+      "    mean_inference_ms: 4.782872969782969\n",
+      "    mean_raw_obs_processing_ms: 0.42698163136099937\n",
+      "  time_since_restore: 43.73459029197693\n",
+      "  time_this_iter_s: 21.642374277114868\n",
+      "  time_total_s: 43.73459029197693\n",
+      "  timers:\n",
+      "    learn_throughput: 10992.045\n",
+      "    learn_time_ms: 14719.008\n",
+      "    sample_throughput: 22905.576\n",
+      "    sample_time_ms: 7063.433\n",
+      "    update_time_ms: 38.41\n",
+      "  timestamp: 1604234302\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 323584\n",
+      "  training_iteration: 2\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.5/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |      2 |          43.7346 | 323584 |  32.5474 |              44.2424 |              13.0808 |            117.548 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1510.1358481262328\n",
+      "    time_step_min: 1302\n",
+      "  date: 2020-11-01_12-38-43\n",
+      "  done: false\n",
+      "  episode_len_mean: 116.32862362971986\n",
+      "  episode_reward_max: 44.79797979797981\n",
+      "  episode_reward_mean: 33.70579116376925\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1419\n",
+      "  episodes_total: 4105\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1123215953509014\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.00993400338726739\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013690461909087995\n",
+      "        total_loss: 6.506547371546428\n",
+      "        vf_explained_var: 0.9344742298126221\n",
+      "        vf_loss: 6.518807013829549\n",
+      "    num_steps_sampled: 485376\n",
+      "    num_steps_trained: 485376\n",
+      "  iterations_since_restore: 3\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 28.468000000000004\n",
+      "    gpu_util_percent0: 0.36560000000000004\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.508\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16101849961752382\n",
+      "    mean_env_wait_ms: 0.6546024350645249\n",
+      "    mean_inference_ms: 4.701779084784631\n",
+      "    mean_raw_obs_processing_ms: 0.4230887594071475\n",
+      "  time_since_restore: 64.32173490524292\n",
+      "  time_this_iter_s: 20.58714461326599\n",
+      "  time_total_s: 64.32173490524292\n",
+      "  timers:\n",
+      "    learn_throughput: 11037.784\n",
+      "    learn_time_ms: 14658.015\n",
+      "    sample_throughput: 24159.746\n",
+      "    sample_time_ms: 6696.759\n",
+      "    update_time_ms: 34.468\n",
+      "  timestamp: 1604234323\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 485376\n",
+      "  training_iteration: 3\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |      3 |          64.3217 | 485376 |  33.7058 |               44.798 |              13.0808 |            116.329 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1488.4381143065161\n",
+      "    time_step_min: 1270\n",
+      "  date: 2020-11-01_12-39-03\n",
+      "  done: false\n",
+      "  episode_len_mean: 114.89247699801551\n",
+      "  episode_reward_max: 46.01010101010102\n",
+      "  episode_reward_mean: 34.80499565381399\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1438\n",
+      "  episodes_total: 5543\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0760109821955364\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.010554853981981674\n",
+      "        model: {}\n",
+      "        policy_loss: -0.017120405255506437\n",
+      "        total_loss: 4.882782578468323\n",
+      "        vf_explained_var: 0.9524574279785156\n",
+      "        vf_loss: 4.898330052693685\n",
+      "    num_steps_sampled: 647168\n",
+      "    num_steps_trained: 647168\n",
+      "  iterations_since_restore: 4\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.83076923076923\n",
+      "    gpu_util_percent0: 0.33230769230769225\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5076923076923077\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15936923843872866\n",
+      "    mean_env_wait_ms: 0.6531312998927246\n",
+      "    mean_inference_ms: 4.622904338928759\n",
+      "    mean_raw_obs_processing_ms: 0.4189887193273442\n",
+      "  time_since_restore: 85.05826711654663\n",
+      "  time_this_iter_s: 20.73653221130371\n",
+      "  time_total_s: 85.05826711654663\n",
+      "  timers:\n",
+      "    learn_throughput: 11028.796\n",
+      "    learn_time_ms: 14669.96\n",
+      "    sample_throughput: 24936.84\n",
+      "    sample_time_ms: 6488.071\n",
+      "    update_time_ms: 46.059\n",
+      "  timestamp: 1604234343\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 647168\n",
+      "  training_iteration: 4\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |      4 |          85.0583 | 647168 |   34.805 |              46.0101 |              13.0808 |            114.892 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1466.4215029231427\n",
+      "    time_step_min: 1237\n",
+      "  date: 2020-11-01_12-39-24\n",
+      "  done: false\n",
+      "  episode_len_mean: 113.48583970546588\n",
+      "  episode_reward_max: 47.52525252525255\n",
+      "  episode_reward_mean: 35.910843066747915\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1519\n",
+      "  episodes_total: 7062\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0269921322663624\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.010993095813319087\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013592622436893484\n",
+      "        total_loss: 3.9119317531585693\n",
+      "        vf_explained_var: 0.9633958339691162\n",
+      "        vf_loss: 3.923839290936788\n",
+      "    num_steps_sampled: 808960\n",
+      "    num_steps_trained: 808960\n",
+      "  iterations_since_restore: 5\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.444000000000006\n",
+      "    gpu_util_percent0: 0.41679999999999995\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.516\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1580018213167273\n",
+      "    mean_env_wait_ms: 0.6519685995559447\n",
+      "    mean_inference_ms: 4.555161635142564\n",
+      "    mean_raw_obs_processing_ms: 0.41520922328594023\n",
+      "  time_since_restore: 105.7582585811615\n",
+      "  time_this_iter_s: 20.699991464614868\n",
+      "  time_total_s: 105.7582585811615\n",
+      "  timers:\n",
+      "    learn_throughput: 11021.266\n",
+      "    learn_time_ms: 14679.983\n",
+      "    sample_throughput: 25435.818\n",
+      "    sample_time_ms: 6360.794\n",
+      "    update_time_ms: 44.668\n",
+      "  timestamp: 1604234364\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 808960\n",
+      "  training_iteration: 5\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |      5 |          105.758 | 808960 |  35.9108 |              47.5253 |              13.0808 |            113.486 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1447.9500235183443\n",
+      "    time_step_min: 1237\n",
+      "  date: 2020-11-01_12-39-45\n",
+      "  done: false\n",
+      "  episode_len_mean: 112.33274874313106\n",
+      "  episode_reward_max: 47.52525252525255\n",
+      "  episode_reward_mean: 36.86168359616273\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1491\n",
+      "  episodes_total: 8553\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.987803190946579\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.010113457528253397\n",
+      "        model: {}\n",
+      "        policy_loss: -0.014161262234362463\n",
+      "        total_loss: 3.0733113487561545\n",
+      "        vf_explained_var: 0.9713076949119568\n",
+      "        vf_loss: 3.0859439174334207\n",
+      "    num_steps_sampled: 970752\n",
+      "    num_steps_trained: 970752\n",
+      "  iterations_since_restore: 6\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.396\n",
+      "    gpu_util_percent0: 0.3632000000000001\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5239999999999996\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15689234927636098\n",
+      "    mean_env_wait_ms: 0.651134098255352\n",
+      "    mean_inference_ms: 4.500464998774646\n",
+      "    mean_raw_obs_processing_ms: 0.4120524597642815\n",
+      "  time_since_restore: 126.29982709884644\n",
+      "  time_this_iter_s: 20.541568517684937\n",
+      "  time_total_s: 126.29982709884644\n",
+      "  timers:\n",
+      "    learn_throughput: 11029.447\n",
+      "    learn_time_ms: 14669.094\n",
+      "    sample_throughput: 25808.454\n",
+      "    sample_time_ms: 6268.954\n",
+      "    update_time_ms: 43.186\n",
+      "  timestamp: 1604234385\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 970752\n",
+      "  training_iteration: 6\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |      6 |            126.3 | 970752 |  36.8617 |              47.5253 |              13.0808 |            112.333 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1430.1320079522864\n",
+      "    time_step_min: 1228\n",
+      "  date: 2020-11-01_12-40-06\n",
+      "  done: false\n",
+      "  episode_len_mean: 111.28944504896627\n",
+      "  episode_reward_max: 48.48484848484849\n",
+      "  episode_reward_mean: 37.7558351344087\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1556\n",
+      "  episodes_total: 10109\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9375320275624593\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.008831425181900462\n",
+      "        model: {}\n",
+      "        policy_loss: -0.014223781297914684\n",
+      "        total_loss: 2.650870760281881\n",
+      "        vf_explained_var: 0.9759369492530823\n",
+      "        vf_loss: 2.6637970407803855\n",
+      "    num_steps_sampled: 1132544\n",
+      "    num_steps_trained: 1132544\n",
+      "  iterations_since_restore: 7\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.449999999999996\n",
+      "    gpu_util_percent0: 0.35692307692307695\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.565384615384615\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15594457790714622\n",
+      "    mean_env_wait_ms: 0.6505920718367179\n",
+      "    mean_inference_ms: 4.453229425218937\n",
+      "    mean_raw_obs_processing_ms: 0.409256308610765\n",
+      "  time_since_restore: 146.91562390327454\n",
+      "  time_this_iter_s: 20.6157968044281\n",
+      "  time_total_s: 146.91562390327454\n",
+      "  timers:\n",
+      "    learn_throughput: 11035.377\n",
+      "    learn_time_ms: 14661.212\n",
+      "    sample_throughput: 26039.628\n",
+      "    sample_time_ms: 6213.299\n",
+      "    update_time_ms: 41.221\n",
+      "  timestamp: 1604234406\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1132544\n",
+      "  training_iteration: 7\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |      7 |          146.916 | 1132544 |  37.7558 |              48.4848 |              13.0808 |            111.289 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1413.9141553297743\n",
+      "    time_step_min: 1219\n",
+      "  date: 2020-11-01_12-40-27\n",
+      "  done: false\n",
+      "  episode_len_mean: 110.37700420132042\n",
+      "  episode_reward_max: 49.040404040404056\n",
+      "  episode_reward_mean: 38.58040665594469\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1554\n",
+      "  episodes_total: 11663\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8849463810523351\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.00801295922913899\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012614224765760204\n",
+      "        total_loss: 2.1787688732147217\n",
+      "        vf_explained_var: 0.9803922772407532\n",
+      "        vf_loss: 2.190222958723704\n",
+      "    num_steps_sampled: 1294336\n",
+      "    num_steps_trained: 1294336\n",
+      "  iterations_since_restore: 8\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.924000000000007\n",
+      "    gpu_util_percent0: 0.3896\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15514960562097774\n",
+      "    mean_env_wait_ms: 0.650196011864452\n",
+      "    mean_inference_ms: 4.41380605191362\n",
+      "    mean_raw_obs_processing_ms: 0.40683273492153127\n",
+      "  time_since_restore: 167.58297491073608\n",
+      "  time_this_iter_s: 20.667351007461548\n",
+      "  time_total_s: 167.58297491073608\n",
+      "  timers:\n",
+      "    learn_throughput: 11046.514\n",
+      "    learn_time_ms: 14646.43\n",
+      "    sample_throughput: 26162.052\n",
+      "    sample_time_ms: 6184.224\n",
+      "    update_time_ms: 41.682\n",
+      "  timestamp: 1604234427\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1294336\n",
+      "  training_iteration: 8\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |      8 |          167.583 | 1294336 |  38.5804 |              49.0404 |              13.0808 |            110.377 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1399.354544764219\n",
+      "    time_step_min: 1207\n",
+      "  date: 2020-11-01_12-40-48\n",
+      "  done: false\n",
+      "  episode_len_mean: 109.57285519745801\n",
+      "  episode_reward_max: 49.04040404040408\n",
+      "  episode_reward_mean: 39.3178455763567\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1555\n",
+      "  episodes_total: 13218\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8404552837212881\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.007818623019071916\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011729774332100837\n",
+      "        total_loss: 1.9283219973246257\n",
+      "        vf_explained_var: 0.9828620553016663\n",
+      "        vf_loss: 1.9389082888762157\n",
+      "    num_steps_sampled: 1456128\n",
+      "    num_steps_trained: 1456128\n",
+      "  iterations_since_restore: 9\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.368000000000002\n",
+      "    gpu_util_percent0: 0.39\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15447110974777709\n",
+      "    mean_env_wait_ms: 0.6499648656278564\n",
+      "    mean_inference_ms: 4.380306434888785\n",
+      "    mean_raw_obs_processing_ms: 0.4047426878747494\n",
+      "  time_since_restore: 188.20489048957825\n",
+      "  time_this_iter_s: 20.621915578842163\n",
+      "  time_total_s: 188.20489048957825\n",
+      "  timers:\n",
+      "    learn_throughput: 11046.003\n",
+      "    learn_time_ms: 14647.108\n",
+      "    sample_throughput: 26334.762\n",
+      "    sample_time_ms: 6143.667\n",
+      "    update_time_ms: 40.969\n",
+      "  timestamp: 1604234448\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1456128\n",
+      "  training_iteration: 9\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |      9 |          188.205 | 1456128 |  39.3178 |              49.0404 |              13.0808 |            109.573 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1385.9825049162541\n",
+      "    time_step_min: 1207\n",
+      "  date: 2020-11-01_12-41-09\n",
+      "  done: false\n",
+      "  episode_len_mean: 108.85056772100567\n",
+      "  episode_reward_max: 49.04040404040408\n",
+      "  episode_reward_mean: 40.00051201389402\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1578\n",
+      "  episodes_total: 14796\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7908046692609787\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.007631780773711701\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011734772803417096\n",
+      "        total_loss: 1.5385288000106812\n",
+      "        vf_explained_var: 0.9865396022796631\n",
+      "        vf_loss: 1.5491326252619426\n",
+      "    num_steps_sampled: 1617920\n",
+      "    num_steps_trained: 1617920\n",
+      "  iterations_since_restore: 10\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.732000000000006\n",
+      "    gpu_util_percent0: 0.38040000000000007\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15388031735599098\n",
+      "    mean_env_wait_ms: 0.6498212598888915\n",
+      "    mean_inference_ms: 4.351027781645246\n",
+      "    mean_raw_obs_processing_ms: 0.40287986554113797\n",
+      "  time_since_restore: 208.505108833313\n",
+      "  time_this_iter_s: 20.30021834373474\n",
+      "  time_total_s: 208.505108833313\n",
+      "  timers:\n",
+      "    learn_throughput: 11056.477\n",
+      "    learn_time_ms: 14633.233\n",
+      "    sample_throughput: 26549.982\n",
+      "    sample_time_ms: 6093.865\n",
+      "    update_time_ms: 40.654\n",
+      "  timestamp: 1604234469\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1617920\n",
+      "  training_iteration: 10\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     10 |          208.505 | 1617920 |  40.0005 |              49.0404 |              13.0808 |            108.851 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1373.7871090163433\n",
+      "    time_step_min: 1207\n",
+      "  date: 2020-11-01_12-41-29\n",
+      "  done: false\n",
+      "  episode_len_mean: 108.19760771390212\n",
+      "  episode_reward_max: 49.040404040404084\n",
+      "  episode_reward_mean: 40.61680826327476\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1590\n",
+      "  episodes_total: 16386\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7443548093239466\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.007289290855017801\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011087999266843932\n",
+      "        total_loss: 1.2828177213668823\n",
+      "        vf_explained_var: 0.9888736605644226\n",
+      "        vf_loss: 1.2928200562795003\n",
+      "    num_steps_sampled: 1779712\n",
+      "    num_steps_trained: 1779712\n",
+      "  iterations_since_restore: 11\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.136\n",
+      "    gpu_util_percent0: 0.3856\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15335957704686504\n",
+      "    mean_env_wait_ms: 0.6497293652386255\n",
+      "    mean_inference_ms: 4.325424204249887\n",
+      "    mean_raw_obs_processing_ms: 0.4011955359649914\n",
+      "  time_since_restore: 229.01598072052002\n",
+      "  time_this_iter_s: 20.51087188720703\n",
+      "  time_total_s: 229.01598072052002\n",
+      "  timers:\n",
+      "    learn_throughput: 11068.877\n",
+      "    learn_time_ms: 14616.84\n",
+      "    sample_throughput: 27216.446\n",
+      "    sample_time_ms: 5944.641\n",
+      "    update_time_ms: 39.857\n",
+      "  timestamp: 1604234489\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1779712\n",
+      "  training_iteration: 11\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     11 |          229.016 | 1779712 |  40.6168 |              49.0404 |              13.0808 |            108.198 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1362.7848496680983\n",
+      "    time_step_min: 1207\n",
+      "  date: 2020-11-01_12-41-50\n",
+      "  done: false\n",
+      "  episode_len_mean: 107.6175456163774\n",
+      "  episode_reward_max: 49.040404040404084\n",
+      "  episode_reward_mean: 41.17096364175804\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1590\n",
+      "  episodes_total: 17976\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7057946672042211\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006505049881525338\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011637478950433433\n",
+      "        total_loss: 1.0556738674640656\n",
+      "        vf_explained_var: 0.9909140467643738\n",
+      "        vf_loss: 1.066363235314687\n",
+      "    num_steps_sampled: 1941504\n",
+      "    num_steps_trained: 1941504\n",
+      "  iterations_since_restore: 12\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.067999999999998\n",
+      "    gpu_util_percent0: 0.38120000000000004\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15290224314841672\n",
+      "    mean_env_wait_ms: 0.6497100863030586\n",
+      "    mean_inference_ms: 4.30291912913981\n",
+      "    mean_raw_obs_processing_ms: 0.3997009547743406\n",
+      "  time_since_restore: 249.53435850143433\n",
+      "  time_this_iter_s: 20.518377780914307\n",
+      "  time_total_s: 249.53435850143433\n",
+      "  timers:\n",
+      "    learn_throughput: 11067.812\n",
+      "    learn_time_ms: 14618.246\n",
+      "    sample_throughput: 27784.289\n",
+      "    sample_time_ms: 5823.147\n",
+      "    update_time_ms: 40.514\n",
+      "  timestamp: 1604234510\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1941504\n",
+      "  training_iteration: 12\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     12 |          249.534 | 1941504 |   41.171 |              49.0404 |              13.0808 |            107.618 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1352.7341357234316\n",
+      "    time_step_min: 1207\n",
+      "  date: 2020-11-01_12-42-11\n",
+      "  done: false\n",
+      "  episode_len_mean: 107.1025339736385\n",
+      "  episode_reward_max: 49.04040404040409\n",
+      "  episode_reward_mean: 41.67515040050036\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1598\n",
+      "  episodes_total: 19574\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.6686889827251434\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.0063633088720962405\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01186193727577726\n",
+      "        total_loss: 0.8905991663535436\n",
+      "        vf_explained_var: 0.9923557639122009\n",
+      "        vf_loss: 0.9015227903922399\n",
+      "    num_steps_sampled: 2103296\n",
+      "    num_steps_trained: 2103296\n",
+      "  iterations_since_restore: 13\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.288461538461544\n",
+      "    gpu_util_percent0: 0.38153846153846155\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5692307692307685\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15249499620405588\n",
+      "    mean_env_wait_ms: 0.6497364450001253\n",
+      "    mean_inference_ms: 4.282874551579647\n",
+      "    mean_raw_obs_processing_ms: 0.39836613551654754\n",
+      "  time_since_restore: 270.1388850212097\n",
+      "  time_this_iter_s: 20.60452651977539\n",
+      "  time_total_s: 270.1388850212097\n",
+      "  timers:\n",
+      "    learn_throughput: 11056.406\n",
+      "    learn_time_ms: 14633.327\n",
+      "    sample_throughput: 27887.324\n",
+      "    sample_time_ms: 5801.632\n",
+      "    update_time_ms: 41.993\n",
+      "  timestamp: 1604234531\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2103296\n",
+      "  training_iteration: 13\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     13 |          270.139 | 2103296 |  41.6752 |              49.0404 |              13.0808 |            107.103 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1343.4148870685165\n",
+      "    time_step_min: 1207\n",
+      "  date: 2020-11-01_12-42-32\n",
+      "  done: false\n",
+      "  episode_len_mean: 106.65310846560847\n",
+      "  episode_reward_max: 49.04040404040409\n",
+      "  episode_reward_mean: 42.142787951319704\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1594\n",
+      "  episodes_total: 21168\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.6273181239763895\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006019947739938895\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009247757125801096\n",
+      "        total_loss: 0.7534371664126714\n",
+      "        vf_explained_var: 0.9935855865478516\n",
+      "        vf_loss: 0.7617945869763693\n",
+      "    num_steps_sampled: 2265088\n",
+      "    num_steps_trained: 2265088\n",
+      "  iterations_since_restore: 14\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.48\n",
+      "    gpu_util_percent0: 0.3504\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5679999999999996\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15213206388671544\n",
+      "    mean_env_wait_ms: 0.6497940000882954\n",
+      "    mean_inference_ms: 4.2649850452281735\n",
+      "    mean_raw_obs_processing_ms: 0.39716794855089166\n",
+      "  time_since_restore: 290.5424859523773\n",
+      "  time_this_iter_s: 20.403600931167603\n",
+      "  time_total_s: 290.5424859523773\n",
+      "  timers:\n",
+      "    learn_throughput: 11072.943\n",
+      "    learn_time_ms: 14611.472\n",
+      "    sample_throughput: 27934.424\n",
+      "    sample_time_ms: 5791.85\n",
+      "    update_time_ms: 35.766\n",
+      "  timestamp: 1604234552\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2265088\n",
+      "  training_iteration: 14\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     14 |          290.542 | 2265088 |  42.1428 |              49.0404 |              13.0808 |            106.653 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1334.9958170049756\n",
+      "    time_step_min: 1207\n",
+      "  date: 2020-11-01_12-42-53\n",
+      "  done: false\n",
+      "  episode_len_mean: 106.25092267135325\n",
+      "  episode_reward_max: 49.04040404040409\n",
+      "  episode_reward_mean: 42.566322273703655\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1592\n",
+      "  episodes_total: 22760\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.593339666724205\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.0052832565270364285\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007287261697153251\n",
+      "        total_loss: 0.6348467022180557\n",
+      "        vf_explained_var: 0.994635820388794\n",
+      "        vf_loss: 0.6413739621639252\n",
+      "    num_steps_sampled: 2426880\n",
+      "    num_steps_trained: 2426880\n",
+      "  iterations_since_restore: 15\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.588\n",
+      "    gpu_util_percent0: 0.3836\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5679999999999996\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1518110809879511\n",
+      "    mean_env_wait_ms: 0.6498897805634568\n",
+      "    mean_inference_ms: 4.248940110401404\n",
+      "    mean_raw_obs_processing_ms: 0.39609601756717205\n",
+      "  time_since_restore: 311.00591683387756\n",
+      "  time_this_iter_s: 20.463430881500244\n",
+      "  time_total_s: 311.00591683387756\n",
+      "  timers:\n",
+      "    learn_throughput: 11097.5\n",
+      "    learn_time_ms: 14579.139\n",
+      "    sample_throughput: 27995.833\n",
+      "    sample_time_ms: 5779.146\n",
+      "    update_time_ms: 35.119\n",
+      "  timestamp: 1604234573\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2426880\n",
+      "  training_iteration: 15\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     15 |          311.006 | 2426880 |  42.5663 |              49.0404 |              13.0808 |            106.251 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1327.4121421520238\n",
+      "    time_step_min: 1207\n",
+      "  date: 2020-11-01_12-43-14\n",
+      "  done: false\n",
+      "  episode_len_mean: 105.89524239563237\n",
+      "  episode_reward_max: 49.04040404040409\n",
+      "  episode_reward_mean: 42.95161292328897\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1601\n",
+      "  episodes_total: 24361\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.5610497693220774\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005239539352866511\n",
+      "        model: {}\n",
+      "        policy_loss: -0.008563858728545407\n",
+      "        total_loss: 0.5433527330557505\n",
+      "        vf_explained_var: 0.9954302906990051\n",
+      "        vf_loss: 0.5511491994063059\n",
+      "    num_steps_sampled: 2588672\n",
+      "    num_steps_trained: 2588672\n",
+      "  iterations_since_restore: 16\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.983999999999995\n",
+      "    gpu_util_percent0: 0.37079999999999996\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15151777280002335\n",
+      "    mean_env_wait_ms: 0.6499960724887209\n",
+      "    mean_inference_ms: 4.234304826550604\n",
+      "    mean_raw_obs_processing_ms: 0.39511468708048586\n",
+      "  time_since_restore: 331.8462426662445\n",
+      "  time_this_iter_s: 20.840325832366943\n",
+      "  time_total_s: 331.8462426662445\n",
+      "  timers:\n",
+      "    learn_throughput: 11077.938\n",
+      "    learn_time_ms: 14604.884\n",
+      "    sample_throughput: 28012.835\n",
+      "    sample_time_ms: 5775.638\n",
+      "    update_time_ms: 35.504\n",
+      "  timestamp: 1604234594\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2588672\n",
+      "  training_iteration: 16\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     16 |          331.846 | 2588672 |  42.9516 |              49.0404 |              13.0808 |            105.895 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1320.4339440694312\n",
+      "    time_step_min: 1207\n",
+      "  date: 2020-11-01_12-43-36\n",
+      "  done: false\n",
+      "  episode_len_mean: 105.57168707168707\n",
+      "  episode_reward_max: 49.04040404040409\n",
+      "  episode_reward_mean: 43.304979416090546\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1613\n",
+      "  episodes_total: 25974\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.5246386776367823\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005194058952232202\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010037654642170915\n",
+      "        total_loss: 0.3729574630657832\n",
+      "        vf_explained_var: 0.9968838095664978\n",
+      "        vf_loss: 0.3822186241547267\n",
+      "    num_steps_sampled: 2750464\n",
+      "    num_steps_trained: 2750464\n",
+      "  iterations_since_restore: 17\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.15\n",
+      "    gpu_util_percent0: 0.34961538461538466\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5692307692307685\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1512500032596141\n",
+      "    mean_env_wait_ms: 0.6501069321395831\n",
+      "    mean_inference_ms: 4.2209558905247935\n",
+      "    mean_raw_obs_processing_ms: 0.3942088287210041\n",
+      "  time_since_restore: 352.6941442489624\n",
+      "  time_this_iter_s: 20.847901582717896\n",
+      "  time_total_s: 352.6941442489624\n",
+      "  timers:\n",
+      "    learn_throughput: 11060.738\n",
+      "    learn_time_ms: 14627.595\n",
+      "    sample_throughput: 28046.143\n",
+      "    sample_time_ms: 5768.779\n",
+      "    update_time_ms: 36.388\n",
+      "  timestamp: 1604234616\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2750464\n",
+      "  training_iteration: 17\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     17 |          352.694 | 2750464 |   43.305 |              49.0404 |              13.0808 |            105.572 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1314.0839173535712\n",
+      "    time_step_min: 1207\n",
+      "  date: 2020-11-01_12-43-57\n",
+      "  done: false\n",
+      "  episode_len_mean: 105.28088299260548\n",
+      "  episode_reward_max: 49.0404040404041\n",
+      "  episode_reward_mean: 43.62569621105941\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1614\n",
+      "  episodes_total: 27588\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.49088098108768463\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.004925240180455148\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007551613341396053\n",
+      "        total_loss: 0.27305928741892177\n",
+      "        vf_explained_var: 0.997745931148529\n",
+      "        vf_loss: 0.27987127751111984\n",
+      "    num_steps_sampled: 2912256\n",
+      "    num_steps_trained: 2912256\n",
+      "  iterations_since_restore: 18\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.076923076923077\n",
+      "    gpu_util_percent0: 0.35576923076923084\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5730769230769224\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1510024924486738\n",
+      "    mean_env_wait_ms: 0.6502222563745731\n",
+      "    mean_inference_ms: 4.208793894567712\n",
+      "    mean_raw_obs_processing_ms: 0.3933811392042326\n",
+      "  time_since_restore: 373.5547993183136\n",
+      "  time_this_iter_s: 20.860655069351196\n",
+      "  time_total_s: 373.5547993183136\n",
+      "  timers:\n",
+      "    learn_throughput: 11035.452\n",
+      "    learn_time_ms: 14661.112\n",
+      "    sample_throughput: 28141.143\n",
+      "    sample_time_ms: 5749.304\n",
+      "    update_time_ms: 34.956\n",
+      "  timestamp: 1604234637\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2912256\n",
+      "  training_iteration: 18\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     18 |          373.555 | 2912256 |  43.6257 |              49.0404 |              13.0808 |            105.281 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1308.3422956891525\n",
+      "    time_step_min: 1207\n",
+      "  date: 2020-11-01_12-44-18\n",
+      "  done: false\n",
+      "  episode_len_mean: 105.01201725554643\n",
+      "  episode_reward_max: 49.0404040404041\n",
+      "  episode_reward_mean: 43.913729876137445\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1620\n",
+      "  episodes_total: 29208\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.4603450372815132\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.0052619769315545755\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007839118620419564\n",
+      "        total_loss: 0.24682058518131575\n",
+      "        vf_explained_var: 0.9979783892631531\n",
+      "        vf_loss: 0.25436367591222125\n",
+      "    num_steps_sampled: 3074048\n",
+      "    num_steps_trained: 3074048\n",
+      "  iterations_since_restore: 19\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.90384615384615\n",
+      "    gpu_util_percent0: 0.3811538461538462\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5692307692307685\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1507749922403882\n",
+      "    mean_env_wait_ms: 0.6503503182530888\n",
+      "    mean_inference_ms: 4.197625625739776\n",
+      "    mean_raw_obs_processing_ms: 0.3926215964880014\n",
+      "  time_since_restore: 394.43259143829346\n",
+      "  time_this_iter_s: 20.87779211997986\n",
+      "  time_total_s: 394.43259143829346\n",
+      "  timers:\n",
+      "    learn_throughput: 11025.644\n",
+      "    learn_time_ms: 14674.154\n",
+      "    sample_throughput: 28102.66\n",
+      "    sample_time_ms: 5757.177\n",
+      "    update_time_ms: 33.741\n",
+      "  timestamp: 1604234658\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3074048\n",
+      "  training_iteration: 19\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     19 |          394.433 | 3074048 |  43.9137 |              49.0404 |              13.0808 |            105.012 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1303.1952154976273\n",
+      "    time_step_min: 1207\n",
+      "  date: 2020-11-01_12-44-40\n",
+      "  done: false\n",
+      "  episode_len_mean: 104.77212396560117\n",
+      "  episode_reward_max: 49.0404040404041\n",
+      "  episode_reward_mean: 44.17383145096922\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1607\n",
+      "  episodes_total: 30815\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.43477704375982285\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.004907564221260448\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007642344086586188\n",
+      "        total_loss: 0.17235680421193442\n",
+      "        vf_explained_var: 0.998579740524292\n",
+      "        vf_loss: 0.17972578232487044\n",
+      "    num_steps_sampled: 3235840\n",
+      "    num_steps_trained: 3235840\n",
+      "  iterations_since_restore: 20\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.568\n",
+      "    gpu_util_percent0: 0.3516\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15056551159545464\n",
+      "    mean_env_wait_ms: 0.650477071010486\n",
+      "    mean_inference_ms: 4.187399168266206\n",
+      "    mean_raw_obs_processing_ms: 0.39192218046315624\n",
+      "  time_since_restore: 415.2149660587311\n",
+      "  time_this_iter_s: 20.782374620437622\n",
+      "  time_total_s: 415.2149660587311\n",
+      "  timers:\n",
+      "    learn_throughput: 11005.002\n",
+      "    learn_time_ms: 14701.678\n",
+      "    sample_throughput: 28031.542\n",
+      "    sample_time_ms: 5771.784\n",
+      "    update_time_ms: 33.384\n",
+      "  timestamp: 1604234680\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3235840\n",
+      "  training_iteration: 20\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     20 |          415.215 | 3235840 |  44.1738 |              49.0404 |              13.0808 |            104.772 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1298.6048573988814\n",
+      "    time_step_min: 1207\n",
+      "  date: 2020-11-01_12-45-01\n",
+      "  done: false\n",
+      "  episode_len_mean: 104.55760212267062\n",
+      "  episode_reward_max: 49.0404040404041\n",
+      "  episode_reward_mean: 44.4073915135559\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1597\n",
+      "  episodes_total: 32412\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.05000000000000001\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.4088049481312434\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.0050367383907238645\n",
+      "        model: {}\n",
+      "        policy_loss: -0.004726681110696518\n",
+      "        total_loss: 0.15046600687007108\n",
+      "        vf_explained_var: 0.9988059401512146\n",
+      "        vf_loss: 0.15514524901906648\n",
+      "    num_steps_sampled: 3397632\n",
+      "    num_steps_trained: 3397632\n",
+      "  iterations_since_restore: 21\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.25769230769231\n",
+      "    gpu_util_percent0: 0.3230769230769231\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5692307692307685\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15037307743519757\n",
+      "    mean_env_wait_ms: 0.6506021265347358\n",
+      "    mean_inference_ms: 4.177989463073186\n",
+      "    mean_raw_obs_processing_ms: 0.39127952344764305\n",
+      "  time_since_restore: 436.0554406642914\n",
+      "  time_this_iter_s: 20.840474605560303\n",
+      "  time_total_s: 436.0554406642914\n",
+      "  timers:\n",
+      "    learn_throughput: 10991.518\n",
+      "    learn_time_ms: 14719.713\n",
+      "    sample_throughput: 27990.599\n",
+      "    sample_time_ms: 5780.226\n",
+      "    update_time_ms: 33.786\n",
+      "  timestamp: 1604234701\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3397632\n",
+      "  training_iteration: 21\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     21 |          436.055 | 3397632 |  44.4074 |              49.0404 |              13.0808 |            104.558 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1294.3254164459356\n",
+      "    time_step_min: 1207\n",
+      "  date: 2020-11-01_12-45-23\n",
+      "  done: false\n",
+      "  episode_len_mean: 104.35706938607576\n",
+      "  episode_reward_max: 49.040404040404106\n",
+      "  episode_reward_mean: 44.62349862987593\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1615\n",
+      "  episodes_total: 34027\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.05000000000000001\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.38861273725827533\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.004962532625844081\n",
+      "        model: {}\n",
+      "        policy_loss: -0.006052409371477552\n",
+      "        total_loss: 0.10335199224452178\n",
+      "        vf_explained_var: 0.9991534352302551\n",
+      "        vf_loss: 0.1093505813429753\n",
+      "    num_steps_sampled: 3559424\n",
+      "    num_steps_trained: 3559424\n",
+      "  iterations_since_restore: 22\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.088461538461537\n",
+      "    gpu_util_percent0: 0.34846153846153843\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.565384615384615\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15019358290939233\n",
+      "    mean_env_wait_ms: 0.6507335363952385\n",
+      "    mean_inference_ms: 4.169147396856916\n",
+      "    mean_raw_obs_processing_ms: 0.39067463008215425\n",
+      "  time_since_restore: 456.7496886253357\n",
+      "  time_this_iter_s: 20.69424796104431\n",
+      "  time_total_s: 456.7496886253357\n",
+      "  timers:\n",
+      "    learn_throughput: 10986.132\n",
+      "    learn_time_ms: 14726.93\n",
+      "    sample_throughput: 28004.762\n",
+      "    sample_time_ms: 5777.303\n",
+      "    update_time_ms: 33.873\n",
+      "  timestamp: 1604234723\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3559424\n",
+      "  training_iteration: 22\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     22 |           456.75 | 3559424 |  44.6235 |              49.0404 |              13.0808 |            104.357 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1290.3840622454425\n",
+      "    time_step_min: 1207\n",
+      "  date: 2020-11-01_12-45-44\n",
+      "  done: false\n",
+      "  episode_len_mean: 104.17307152875175\n",
+      "  episode_reward_max: 49.040404040404106\n",
+      "  episode_reward_mean: 44.82170512983978\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1623\n",
+      "  episodes_total: 35650\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.025000000000000005\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.36651041358709335\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006440783229966958\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007153725775424391\n",
+      "        total_loss: 0.08216805756092072\n",
+      "        vf_explained_var: 0.999314546585083\n",
+      "        vf_loss: 0.0893440234164397\n",
+      "    num_steps_sampled: 3721216\n",
+      "    num_steps_trained: 3721216\n",
+      "  iterations_since_restore: 23\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.088\n",
+      "    gpu_util_percent0: 0.3868\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15002367096031743\n",
+      "    mean_env_wait_ms: 0.6508575565151\n",
+      "    mean_inference_ms: 4.160903003774551\n",
+      "    mean_raw_obs_processing_ms: 0.3901072062383884\n",
+      "  time_since_restore: 477.2431552410126\n",
+      "  time_this_iter_s: 20.49346661567688\n",
+      "  time_total_s: 477.2431552410126\n",
+      "  timers:\n",
+      "    learn_throughput: 11006.978\n",
+      "    learn_time_ms: 14699.039\n",
+      "    sample_throughput: 27941.378\n",
+      "    sample_time_ms: 5790.409\n",
+      "    update_time_ms: 31.7\n",
+      "  timestamp: 1604234744\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3721216\n",
+      "  training_iteration: 23\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     23 |          477.243 | 3721216 |  44.8217 |              49.0404 |              13.0808 |            104.173 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1286.7964535196131\n",
+      "    time_step_min: 1207\n",
+      "  date: 2020-11-01_12-46-04\n",
+      "  done: false\n",
+      "  episode_len_mean: 104.00566154176393\n",
+      "  episode_reward_max: 49.040404040404106\n",
+      "  episode_reward_mean: 45.00310735680616\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1619\n",
+      "  episodes_total: 37269\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.025000000000000005\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.3446768522262573\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006010537773060302\n",
+      "        model: {}\n",
+      "        policy_loss: -0.006810000515542924\n",
+      "        total_loss: 0.05681590953220924\n",
+      "        vf_explained_var: 0.9995128512382507\n",
+      "        vf_loss: 0.06364798328528802\n",
+      "    num_steps_sampled: 3883008\n",
+      "    num_steps_trained: 3883008\n",
+      "  iterations_since_restore: 24\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.616\n",
+      "    gpu_util_percent0: 0.42919999999999997\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5679999999999996\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1498672084151353\n",
+      "    mean_env_wait_ms: 0.6509884510617694\n",
+      "    mean_inference_ms: 4.153243452307446\n",
+      "    mean_raw_obs_processing_ms: 0.38958140467964614\n",
+      "  time_since_restore: 497.40847873687744\n",
+      "  time_this_iter_s: 20.165323495864868\n",
+      "  time_total_s: 497.40847873687744\n",
+      "  timers:\n",
+      "    learn_throughput: 11023.912\n",
+      "    learn_time_ms: 14676.46\n",
+      "    sample_throughput: 27996.068\n",
+      "    sample_time_ms: 5779.097\n",
+      "    update_time_ms: 33.775\n",
+      "  timestamp: 1604234764\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3883008\n",
+      "  training_iteration: 24\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     24 |          497.408 | 3883008 |  45.0031 |              49.0404 |              13.0808 |            104.006 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1283.5285511912427\n",
+      "    time_step_min: 1207\n",
+      "  date: 2020-11-01_12-46-25\n",
+      "  done: false\n",
+      "  episode_len_mean: 103.8526007099861\n",
+      "  episode_reward_max: 49.040404040404106\n",
+      "  episode_reward_mean: 45.16817737492225\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1605\n",
+      "  episodes_total: 38874\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.025000000000000005\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.32262827704350155\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005610594448323051\n",
+      "        model: {}\n",
+      "        policy_loss: -0.004409408691572025\n",
+      "        total_loss: 0.04963509986797968\n",
+      "        vf_explained_var: 0.9995853304862976\n",
+      "        vf_loss: 0.054065559059381485\n",
+      "    num_steps_sampled: 4044800\n",
+      "    num_steps_trained: 4044800\n",
+      "  iterations_since_restore: 25\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.457692307692305\n",
+      "    gpu_util_percent0: 0.4265384615384616\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.565384615384615\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.14972028928263528\n",
+      "    mean_env_wait_ms: 0.6511154433665545\n",
+      "    mean_inference_ms: 4.146093777194914\n",
+      "    mean_raw_obs_processing_ms: 0.3890936155505342\n",
+      "  time_since_restore: 517.5921437740326\n",
+      "  time_this_iter_s: 20.18366503715515\n",
+      "  time_total_s: 517.5921437740326\n",
+      "  timers:\n",
+      "    learn_throughput: 11035.673\n",
+      "    learn_time_ms: 14660.819\n",
+      "    sample_throughput: 28000.79\n",
+      "    sample_time_ms: 5778.123\n",
+      "    update_time_ms: 32.664\n",
+      "  timestamp: 1604234785\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4044800\n",
+      "  training_iteration: 25\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "2020-11-01 12:46:26,652\tWARNING util.py:136 -- The `process_trial` operation took 0.5261285305023193 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     25 |          517.592 | 4044800 |  45.1682 |              49.0404 |              13.0808 |            103.853 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1280.5338148716173\n",
+      "    time_step_min: 1207\n",
+      "  date: 2020-11-01_12-46-46\n",
+      "  done: false\n",
+      "  episode_len_mean: 103.71221741815936\n",
+      "  episode_reward_max: 49.040404040404106\n",
+      "  episode_reward_mean: 45.319422763771136\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1601\n",
+      "  episodes_total: 40475\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.025000000000000005\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.2999122018615405\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.0053110466881965595\n",
+      "        model: {}\n",
+      "        policy_loss: -0.006303349079341085\n",
+      "        total_loss: 0.05139423534274101\n",
+      "        vf_explained_var: 0.9995618462562561\n",
+      "        vf_loss: 0.0577147655809919\n",
+      "    num_steps_sampled: 4206592\n",
+      "    num_steps_trained: 4206592\n",
+      "  iterations_since_restore: 26\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.96\n",
+      "    gpu_util_percent0: 0.4584\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.14958343418475262\n",
+      "    mean_env_wait_ms: 0.6512359147663624\n",
+      "    mean_inference_ms: 4.139411227315708\n",
+      "    mean_raw_obs_processing_ms: 0.38863613088367416\n",
+      "  time_since_restore: 537.769278049469\n",
+      "  time_this_iter_s: 20.1771342754364\n",
+      "  time_total_s: 537.769278049469\n",
+      "  timers:\n",
+      "    learn_throughput: 11085.459\n",
+      "    learn_time_ms: 14594.975\n",
+      "    sample_throughput: 28023.358\n",
+      "    sample_time_ms: 5773.469\n",
+      "    update_time_ms: 30.886\n",
+      "  timestamp: 1604234806\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4206592\n",
+      "  training_iteration: 26\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "2020-11-01 12:46:47,593\tWARNING util.py:136 -- The `process_trial` operation took 0.5515177249908447 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     26 |          537.769 | 4206592 |  45.3194 |              49.0404 |              13.0808 |            103.712 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1277.717564514211\n",
+      "    time_step_min: 1207\n",
+      "  date: 2020-11-01_12-47-07\n",
+      "  done: false\n",
+      "  episode_len_mean: 103.58062906827577\n",
+      "  episode_reward_max: 49.040404040404106\n",
+      "  episode_reward_mean: 45.461481590264796\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1619\n",
+      "  episodes_total: 42094\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.025000000000000005\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.2697679474949837\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005566679639741778\n",
+      "        model: {}\n",
+      "        policy_loss: -0.006809816346503794\n",
+      "        total_loss: 0.03190007215986649\n",
+      "        vf_explained_var: 0.9997119307518005\n",
+      "        vf_loss: 0.038705606323977314\n",
+      "    num_steps_sampled: 4368384\n",
+      "    num_steps_trained: 4368384\n",
+      "  iterations_since_restore: 27\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.436000000000003\n",
+      "    gpu_util_percent0: 0.3812\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.14945344756304582\n",
+      "    mean_env_wait_ms: 0.6513545610993874\n",
+      "    mean_inference_ms: 4.133051412280412\n",
+      "    mean_raw_obs_processing_ms: 0.38819843216626215\n",
+      "  time_since_restore: 557.9500815868378\n",
+      "  time_this_iter_s: 20.180803537368774\n",
+      "  time_total_s: 557.9500815868378\n",
+      "  timers:\n",
+      "    learn_throughput: 11129.942\n",
+      "    learn_time_ms: 14536.644\n",
+      "    sample_throughput: 28097.666\n",
+      "    sample_time_ms: 5758.201\n",
+      "    update_time_ms: 30.627\n",
+      "  timestamp: 1604234827\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4368384\n",
+      "  training_iteration: 27\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "2020-11-01 12:47:08,513\tWARNING util.py:136 -- The `process_trial` operation took 0.5479977130889893 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     27 |           557.95 | 4368384 |  45.4615 |              49.0404 |              13.0808 |            103.581 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1275.0976458734085\n",
+      "    time_step_min: 1207\n",
+      "  date: 2020-11-01_12-47-28\n",
+      "  done: false\n",
+      "  episode_len_mean: 103.45904339273052\n",
+      "  episode_reward_max: 49.040404040404106\n",
+      "  episode_reward_mean: 45.59383551183082\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1623\n",
+      "  episodes_total: 43717\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.025000000000000005\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.23974776516358057\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.004747193811150889\n",
+      "        model: {}\n",
+      "        policy_loss: -0.004243802364120104\n",
+      "        total_loss: 0.02101877443298387\n",
+      "        vf_explained_var: 0.999813973903656\n",
+      "        vf_loss: 0.025263771259536345\n",
+      "    num_steps_sampled: 4530176\n",
+      "    num_steps_trained: 4530176\n",
+      "  iterations_since_restore: 28\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.936\n",
+      "    gpu_util_percent0: 0.364\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5679999999999996\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.14933083667741634\n",
+      "    mean_env_wait_ms: 0.6514677609541502\n",
+      "    mean_inference_ms: 4.127067697966748\n",
+      "    mean_raw_obs_processing_ms: 0.3877881594254328\n",
+      "  time_since_restore: 578.1908588409424\n",
+      "  time_this_iter_s: 20.240777254104614\n",
+      "  time_total_s: 578.1908588409424\n",
+      "  timers:\n",
+      "    learn_throughput: 11182.422\n",
+      "    learn_time_ms: 14468.421\n",
+      "    sample_throughput: 28093.626\n",
+      "    sample_time_ms: 5759.029\n",
+      "    update_time_ms: 30.485\n",
+      "  timestamp: 1604234848\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4530176\n",
+      "  training_iteration: 28\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "2020-11-01 12:47:29,582\tWARNING util.py:136 -- The `process_trial` operation took 0.5904042720794678 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     28 |          578.191 | 4530176 |  45.5938 |              49.0404 |              13.0808 |            103.459 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1272.6863282026368\n",
+      "    time_step_min: 1207\n",
+      "  date: 2020-11-01_12-47-49\n",
+      "  done: false\n",
+      "  episode_len_mean: 103.34723815406335\n",
+      "  episode_reward_max: 49.040404040404106\n",
+      "  episode_reward_mean: 45.71580313859499\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1615\n",
+      "  episodes_total: 45332\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.012500000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.21396022414167723\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.00464061457508554\n",
+      "        model: {}\n",
+      "        policy_loss: -0.003965421337246274\n",
+      "        total_loss: 0.02320340438745916\n",
+      "        vf_explained_var: 0.9998058676719666\n",
+      "        vf_loss: 0.027217798711111147\n",
+      "    num_steps_sampled: 4691968\n",
+      "    num_steps_trained: 4691968\n",
+      "  iterations_since_restore: 29\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.857692307692307\n",
+      "    gpu_util_percent0: 0.34076923076923077\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.565384615384615\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.14921483484635445\n",
+      "    mean_env_wait_ms: 0.6515697684351597\n",
+      "    mean_inference_ms: 4.121446270442373\n",
+      "    mean_raw_obs_processing_ms: 0.38740127780397765\n",
+      "  time_since_restore: 598.5525875091553\n",
+      "  time_this_iter_s: 20.36172866821289\n",
+      "  time_total_s: 598.5525875091553\n",
+      "  timers:\n",
+      "    learn_throughput: 11221.151\n",
+      "    learn_time_ms: 14418.485\n",
+      "    sample_throughput: 28165.983\n",
+      "    sample_time_ms: 5744.234\n",
+      "    update_time_ms: 31.72\n",
+      "  timestamp: 1604234869\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4691968\n",
+      "  training_iteration: 29\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "2020-11-01 12:47:50,804\tWARNING util.py:136 -- The `process_trial` operation took 0.6144161224365234 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     29 |          598.553 | 4691968 |  45.7158 |              49.0404 |              13.0808 |            103.347 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1270.4485656393304\n",
+      "    time_step_min: 1207\n",
+      "  date: 2020-11-01_12-48-10\n",
+      "  done: true\n",
+      "  episode_len_mean: 103.24400221587761\n",
+      "  episode_reward_max: 49.040404040404106\n",
+      "  episode_reward_mean: 45.82882130203902\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1602\n",
+      "  episodes_total: 46934\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.006250000000000001\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.19203581909338632\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.004001018533017486\n",
+      "        model: {}\n",
+      "        policy_loss: -0.0069229137285825955\n",
+      "        total_loss: 0.009018626738300858\n",
+      "        vf_explained_var: 0.9998963475227356\n",
+      "        vf_loss: 0.01601255312561989\n",
+      "    num_steps_sampled: 4853760\n",
+      "    num_steps_trained: 4853760\n",
+      "  iterations_since_restore: 30\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.076000000000004\n",
+      "    gpu_util_percent0: 0.4292\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.14910530030356728\n",
+      "    mean_env_wait_ms: 0.6516595301622415\n",
+      "    mean_inference_ms: 4.116169102966147\n",
+      "    mean_raw_obs_processing_ms: 0.3870328506532899\n",
+      "  time_since_restore: 618.7089035511017\n",
+      "  time_this_iter_s: 20.15631604194641\n",
+      "  time_total_s: 618.7089035511017\n",
+      "  timers:\n",
+      "    learn_throughput: 11261.529\n",
+      "    learn_time_ms: 14366.788\n",
+      "    sample_throughput: 28251.677\n",
+      "    sample_time_ms: 5726.81\n",
+      "    update_time_ms: 31.9\n",
+      "  timestamp: 1604234890\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4853760\n",
+      "  training_iteration: 30\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "2020-11-01 12:48:11,852\tWARNING util.py:136 -- The `process_trial` operation took 0.6959054470062256 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 24.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | TERMINATED |       |     30 |          618.709 | 4853760 |  45.8288 |              49.0404 |              13.0808 |            103.244 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "== Status ==\n",
+      "Memory usage on this node: 24.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | TERMINATED |       |     30 |          618.709 | 4853760 |  45.8288 |              49.0404 |              13.0808 |            103.244 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 67339\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201101_123726-pq2fv3jo/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201101_123726-pq2fv3jo/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 1207\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 646\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1604234892\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 1901\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 1270.44857\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 49.0404\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 13.08081\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 45.82882\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 46934\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 30\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mdifferent-sweep-5\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/pq2fv3jo\u001b[0m\n",
+      "2020-11-01 12:48:21,592 - wandb.wandb_agent - INFO - Cleaning up finished run: pq2fv3jo\n",
+      "2020-11-01 12:48:21,916 - wandb.wandb_agent - INFO - Agent received command: exit\n",
+      "2020-11-01 12:48:21,916 - wandb.wandb_agent - INFO - Received exit command. Killing runs and quitting.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Terminating and syncing runs. Press ctrl-c to kill.\n"
      ]
     }
    ],
    "source": [
-    "!wandb agent 1x8v92mc"
+    "!wandb agent 9xhkl8my"
    ]
   },
   {
diff --git a/JSS/.ipynb_checkpoints/Random-checkpoint.ipynb b/JSS/.ipynb_checkpoints/Random-checkpoint.ipynb
index c3d10c3..6d201e1 100644
--- a/JSS/.ipynb_checkpoints/Random-checkpoint.ipynb
+++ b/JSS/.ipynb_checkpoints/Random-checkpoint.ipynb
@@ -56,7 +56,7 @@
     "    print(\"I have detected {} CPUs here, so I'm going to create {} actors\".format(mp.cpu_count(), mp.cpu_count() - 1))\n",
     "    os.environ[\"WANDB_API_KEY\"] = '3487a01956bf67cc7882bca2a38f70c8c95f8463'\n",
     "    sweep_config = {\n",
-    "        'program': 'random_loop.py',\n",
+    "        'program': 'CP.py',\n",
     "        'method': 'grid',\n",
     "        'metric': {\n",
     "            'name': 'time_step_min',\n",
@@ -64,9 +64,9 @@
     "        },\n",
     "        'parameters': {\n",
     "            'instance_path': {\n",
-    "                'values': ['/JSS/JSS/env/instances/ta51', '/JSS/JSS/env/instances/ta52', '/JSS/JSS/env/instances/ta53', '/JSS/JSS/env/instances/ta54',\n",
-    "                           '/JSS/JSS/env/instances/ta55', '/JSS/JSS/env/instances/ta56', '/JSS/JSS/env/instances/ta57', '/JSS/JSS/env/instances/ta58',\n",
-    "                           '/JSS/JSS/env/instances/ta59', '/JSS/JSS/env/instances/ta60']\n",
+    "                'values': ['/JSS/JSS/env/instances/ta71', '/JSS/JSS/env/instances/ta72', '/JSS/JSS/env/instances/ta73', '/JSS/JSS/env/instances/ta74',\n",
+    "                           '/JSS/JSS/env/instances/ta75', '/JSS/JSS/env/instances/ta76', '/JSS/JSS/env/instances/ta77', '/JSS/JSS/env/instances/ta78',\n",
+    "                           '/JSS/JSS/env/instances/ta79', '/JSS/JSS/env/instances/ta80']\n",
     "            }\n",
     "        }\n",
     "    }"
@@ -81,8 +81,8 @@
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "Create sweep with ID: kitgghxj\n",
-      "Sweep URL: https://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/kitgghxj\n"
+      "Create sweep with ID: kkxvg8te\n",
+      "Sweep URL: https://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/kkxvg8te\n"
      ]
     }
    ],
@@ -92,7 +92,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 3,
+   "execution_count": null,
    "metadata": {},
    "outputs": [
     {
@@ -100,239 +100,102 @@
      "output_type": "stream",
      "text": [
       "\u001b[34m\u001b[1mwandb\u001b[0m: Starting wandb agent üïµÔ∏è\n",
-      "2020-10-13 12:32:48,579 - wandb.wandb_agent - INFO - Running runs: []\n",
-      "2020-10-13 12:32:48,906 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-13 12:32:48,906 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "2020-11-03 17:48:30,968 - wandb.wandb_agent - INFO - Running runs: []\n",
+      "2020-11-03 17:48:31,522 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-11-03 17:48:31,522 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
       "\tinstance_path: /JSS/JSS/env/instances/ta51\n",
-      "2020-10-13 12:32:48,908 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python random_loop.py --instance_path=/JSS/JSS/env/instances/ta51\n",
+      "2020-11-03 17:48:31,524 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python CP.py --instance_path=/JSS/JSS/env/instances/ta51\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.8 is available!  To upgrade, please run:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdrawn-sweep-1\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mCP\u001b[0m\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/kitgghxj\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/7zjyogzl\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201013_123250-7zjyogzl\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/kkxvg8te\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/quk2usr5\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201103_174832-quk2usr5\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
-      "2020-10-13 12:32:53,926 - wandb.wandb_agent - INFO - Running runs: ['7zjyogzl']\n",
-      "2020-10-13 12:32:54,468\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
-      "== Status ==\n",
-      "Memory usage on this node: 11.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 0/3 GPUs, 0.0/558.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+----------------------------------+----------+-------+\n",
-      "| Trial name                       | status   | loc   |\n",
-      "|----------------------------------+----------+-------|\n",
-      "| RandomMasked_jss_env_3851e_00000 | RUNNING  |       |\n",
-      "+----------------------------------+----------+-------+\n",
+      "2020-11-03 17:48:36,541 - wandb.wandb_agent - INFO - Running runs: ['quk2usr5']\n",
+      "\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 24629\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201103_174832-quk2usr5/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201103_174832-quk2usr5/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_timestep 2762.0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step 0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime 603\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp 1604426315\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_timestep ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mCP\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/quk2usr5\u001b[0m\n",
+      "2020-11-03 17:58:41,416 - wandb.wandb_agent - INFO - Cleaning up finished run: quk2usr5\n",
+      "2020-11-03 17:58:41,795 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-11-03 17:58:41,795 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tinstance_path: /JSS/JSS/env/instances/ta52\n",
+      "2020-11-03 17:58:41,799 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python CP.py --instance_path=/JSS/JSS/env/instances/ta52\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.8 is available!  To upgrade, please run:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mCP\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/kkxvg8te\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/l0rsmjin\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201103_175842-l0rsmjin\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
+      "2020-11-03 17:58:46,817 - wandb.wandb_agent - INFO - Running runs: ['l0rsmjin']\n",
+      "\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 24731\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201103_175842-l0rsmjin/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201103_175842-l0rsmjin/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_timestep 2799.0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step 0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime 603\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp 1604426925\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_timestep ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mCP\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/l0rsmjin\u001b[0m\n",
+      "2020-11-03 18:08:52,752 - wandb.wandb_agent - INFO - Cleaning up finished run: l0rsmjin\n",
+      "2020-11-03 18:08:53,460 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-11-03 18:08:53,460 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tinstance_path: /JSS/JSS/env/instances/ta53\n",
+      "2020-11-03 18:08:53,462 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python CP.py --instance_path=/JSS/JSS/env/instances/ta53\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.8 is available!  To upgrade, please run:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mCP\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/kkxvg8te\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/dy77i2y1\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201103_180854-dy77i2y1\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m F1013 12:32:56.746781   308   308 service_based_gcs_client.cc:207] Couldn't reconnect to GCS server. The last attempted GCS server address was 172.17.0.4:35371\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m *** Check failure stack trace: ***\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x7f29941c66ed  google::LogMessage::Fail()\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x7f29941c784c  google::LogMessage::SendToLog()\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x7f29941c63c9  google::LogMessage::Flush()\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x7f29941c65e1  google::LogMessage::~LogMessage()\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x7f299417d789  ray::RayLog::~RayLog()\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x7f2993ec11ea  ray::gcs::ServiceBasedGcsClient::ReconnectGcsServer()\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x7f2993ec12ef  ray::gcs::ServiceBasedGcsClient::GcsServiceFailureDetected()\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x7f2993ec1491  ray::gcs::ServiceBasedGcsClient::PeriodicallyCheckGcsServerAddress()\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x7f2993ec3801  ray::gcs::ServiceBasedGcsClient::Connect()\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m F1013 12:32:56.731905   318   318 service_based_gcs_client.cc:207] Couldn't reconnect to GCS server. The last attempted GCS server address was 172.17.0.4:35371\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m *** Check failure stack trace: ***\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x7f914d8d36ed  google::LogMessage::Fail()\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x7f914d8d484c  google::LogMessage::SendToLog()\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x7f914d8d33c9  google::LogMessage::Flush()\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x7f914d8d35e1  google::LogMessage::~LogMessage()\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x7f914d88a789  ray::RayLog::~RayLog()\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x7f914d5ce1ea  ray::gcs::ServiceBasedGcsClient::ReconnectGcsServer()\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x7f914d5ce2ef  ray::gcs::ServiceBasedGcsClient::GcsServiceFailureDetected()\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x7f914d5ce491  ray::gcs::ServiceBasedGcsClient::PeriodicallyCheckGcsServerAddress()\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x7f914d5d0801  ray::gcs::ServiceBasedGcsClient::Connect()\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x7f914d4df7a8  ray::gcs::GlobalStateAccessor::Connect()\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x7f914d450a2c  __pyx_pw_3ray_7_raylet_19GlobalStateAccessor_3connect()\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x55b7d9dcc98a  method_vectorcall_NOARGS\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x55b7d9d5cb08  _PyEval_EvalFrameDefault.cold.2792\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x55b7d9de76a2  _PyEval_EvalCodeWithName\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x55b7d9de8a20  method_vectorcall\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x55b7d9d5dde6  _PyEval_EvalFrameDefault.cold.2792\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x55b7d9de7baf  _PyEval_EvalCodeWithName\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x55b7d9de8643  _PyFunction_Vectorcall.localalias.353\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x55b7d9d5dde6  _PyEval_EvalFrameDefault.cold.2792\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x55b7d9de76a2  _PyEval_EvalCodeWithName\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x55b7d9de8454  PyEval_EvalCodeEx\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x55b7d9e76bbc  PyEval_EvalCode\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x55b7d9e76c64  run_eval_code_obj\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x55b7d9ea8d14  run_mod\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x55b7d9d71625  PyRun_FileExFlags\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x55b7d9d71a0a  PyRun_SimpleFileExFlags\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x55b7d9d728cf  Py_RunMain.cold.2911\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x55b7d9eab829  Py_BytesMain\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x7f914ebd8840  __libc_start_main\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x55b7d9e3bb33  (unknown)\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m F1013 12:32:56.749399   329   329 service_based_gcs_client.cc:207] Couldn't reconnect to GCS server. The last attempted GCS server address was 172.17.0.4:35371\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m *** Check failure stack trace: ***\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x7f245ddef6ed  google::LogMessage::Fail()\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x7f245ddf084c  google::LogMessage::SendToLog()\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x7f245ddef3c9  google::LogMessage::Flush()\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x7f245ddef5e1  google::LogMessage::~LogMessage()\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x7f245dda6789  ray::RayLog::~RayLog()\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x7f245daea1ea  ray::gcs::ServiceBasedGcsClient::ReconnectGcsServer()\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x7f245daea2ef  ray::gcs::ServiceBasedGcsClient::GcsServiceFailureDetected()\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x7f245daea491  ray::gcs::ServiceBasedGcsClient::PeriodicallyCheckGcsServerAddress()\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x7f245daec801  ray::gcs::ServiceBasedGcsClient::Connect()\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x7f245d9fb7a8  ray::gcs::GlobalStateAccessor::Connect()\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m F1013 12:32:56.749487   437   437 service_based_gcs_client.cc:207] Couldn't reconnect to GCS server. The last attempted GCS server address was 172.17.0.4:35371\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m *** Check failure stack trace: ***\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x7f92f36026ed  google::LogMessage::Fail()\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x7f92f360384c  google::LogMessage::SendToLog()\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x7f92f36023c9  google::LogMessage::Flush()\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x7f92f36025e1  google::LogMessage::~LogMessage()\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x7f92f35b9789  ray::RayLog::~RayLog()\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x7f92f32fd1ea  ray::gcs::ServiceBasedGcsClient::ReconnectGcsServer()\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x7f92f32fd2ef  ray::gcs::ServiceBasedGcsClient::GcsServiceFailureDetected()\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x7f92f32fd491  ray::gcs::ServiceBasedGcsClient::PeriodicallyCheckGcsServerAddress()\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x7f92f32ff801  ray::gcs::ServiceBasedGcsClient::Connect()\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x7f92f3280ed6  ray::CoreWorker::CoreWorker()\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m F1013 12:32:56.749395   401   401 service_based_gcs_client.cc:207] Couldn't reconnect to GCS server. The last attempted GCS server address was 172.17.0.4:35371\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m *** Check failure stack trace: ***\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x7f1253f536ed  google::LogMessage::Fail()\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x7f1253f5484c  google::LogMessage::SendToLog()\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x7f1253f533c9  google::LogMessage::Flush()\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x7f1253f535e1  google::LogMessage::~LogMessage()\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x7f1253f0a789  ray::RayLog::~RayLog()\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x7f1253c4e1ea  ray::gcs::ServiceBasedGcsClient::ReconnectGcsServer()\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x7f1253c4e2ef  ray::gcs::ServiceBasedGcsClient::GcsServiceFailureDetected()\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x7f1253c4e491  ray::gcs::ServiceBasedGcsClient::PeriodicallyCheckGcsServerAddress()\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x7f1253c50801  ray::gcs::ServiceBasedGcsClient::Connect()\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x7f1253bd1ed6  ray::CoreWorker::CoreWorker()\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m F1013 12:32:56.749400   363   363 service_based_gcs_client.cc:207] Couldn't reconnect to GCS server. The last attempted GCS server address was 172.17.0.4:35371\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m *** Check failure stack trace: ***\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x7f42549ba6ed  google::LogMessage::Fail()\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x7f42549bb84c  google::LogMessage::SendToLog()\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x7f42549ba3c9  google::LogMessage::Flush()\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x7f42549ba5e1  google::LogMessage::~LogMessage()\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x7f4254971789  ray::RayLog::~RayLog()\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x7f42546b51ea  ray::gcs::ServiceBasedGcsClient::ReconnectGcsServer()\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x7f42546b52ef  ray::gcs::ServiceBasedGcsClient::GcsServiceFailureDetected()\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x7f42546b5491  ray::gcs::ServiceBasedGcsClient::PeriodicallyCheckGcsServerAddress()\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x7f42546b7801  ray::gcs::ServiceBasedGcsClient::Connect()\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x7f4254638ed6  ray::CoreWorker::CoreWorker()\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x7f2993dd27a8  ray::gcs::GlobalStateAccessor::Connect()\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x7f2993d43a2c  __pyx_pw_3ray_7_raylet_19GlobalStateAccessor_3connect()\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x563b5c48b98a  method_vectorcall_NOARGS\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x563b5c41bb08  _PyEval_EvalFrameDefault.cold.2792\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x563b5c4a66a2  _PyEval_EvalCodeWithName\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x563b5c4a7a20  method_vectorcall\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x563b5c41cde6  _PyEval_EvalFrameDefault.cold.2792\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x563b5c4a6baf  _PyEval_EvalCodeWithName\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x563b5c4a7643  _PyFunction_Vectorcall.localalias.353\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x563b5c41cde6  _PyEval_EvalFrameDefault.cold.2792\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x563b5c4a66a2  _PyEval_EvalCodeWithName\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x563b5c4a7454  PyEval_EvalCodeEx\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x563b5c535bbc  PyEval_EvalCode\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x563b5c535c64  run_eval_code_obj\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x563b5c567d14  run_mod\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x563b5c430625  PyRun_FileExFlags\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x563b5c430a0a  PyRun_SimpleFileExFlags\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x563b5c4318cf  Py_RunMain.cold.2911\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x563b5c56a829  Py_BytesMain\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x7f245d96ca2c  __pyx_pw_3ray_7_raylet_19GlobalStateAccessor_3connect()\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x55d7f167698a  method_vectorcall_NOARGS\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x55d7f1606b08  _PyEval_EvalFrameDefault.cold.2792\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x55d7f16916a2  _PyEval_EvalCodeWithName\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x55d7f1692a20  method_vectorcall\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x55d7f1607de6  _PyEval_EvalFrameDefault.cold.2792\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x55d7f1691baf  _PyEval_EvalCodeWithName\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x55d7f1692643  _PyFunction_Vectorcall.localalias.353\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x55d7f1607de6  _PyEval_EvalFrameDefault.cold.2792\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x55d7f16916a2  _PyEval_EvalCodeWithName\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x55d7f1692454  PyEval_EvalCodeEx\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x55d7f1720bbc  PyEval_EvalCode\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x55d7f1720c64  run_eval_code_obj\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x7f92f3284c14  ray::CoreWorkerProcess::CreateWorker()\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x7f92f3285e82  ray::CoreWorkerProcess::CoreWorkerProcess()\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x7f1253bd5c14  ray::CoreWorkerProcess::CreateWorker()\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x7f1253bd6e82  ray::CoreWorkerProcess::CoreWorkerProcess()\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x7f425463cc14  ray::CoreWorkerProcess::CreateWorker()\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x7f425463de82  ray::CoreWorkerProcess::CoreWorkerProcess()\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x7f29954cb840  __libc_start_main\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x563b5c4fab33  (unknown)\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x55d7f1752d14  run_mod\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x55d7f161b625  PyRun_FileExFlags\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x55d7f161ba0a  PyRun_SimpleFileExFlags\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x55d7f161c8cf  Py_RunMain.cold.2911\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x55d7f1755829  Py_BytesMain\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x7f245f0f4840  __libc_start_main\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x55d7f16e5b33  (unknown)\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x7f92f328684b  ray::CoreWorkerProcess::Initialize()\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x7f92f31c4448  __pyx_pw_3ray_7_raylet_10CoreWorker_1__cinit__()\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x7f92f31c5ba5  __pyx_tp_new_3ray_7_raylet_CoreWorker()\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x7f1253bd784b  ray::CoreWorkerProcess::Initialize()\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x7f1253b15448  __pyx_pw_3ray_7_raylet_10CoreWorker_1__cinit__()\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x7f1253b16ba5  __pyx_tp_new_3ray_7_raylet_CoreWorker()\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x7f425463e84b  ray::CoreWorkerProcess::Initialize()\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x7f425457c448  __pyx_pw_3ray_7_raylet_10CoreWorker_1__cinit__()\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x7f425457dba5  __pyx_tp_new_3ray_7_raylet_CoreWorker()\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x5609fad7337d  _PyObject_MakeTpCall\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x55917d1cb37d  _PyObject_MakeTpCall\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x55917d253d09  _PyEval_EvalFrameDefault\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x55917d218baf  _PyEval_EvalCodeWithName\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x55917d219643  _PyFunction_Vectorcall.localalias.353\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x55917d18ede6  _PyEval_EvalFrameDefault.cold.2792\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x55917d2186a2  _PyEval_EvalCodeWithName\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x55917d219454  PyEval_EvalCodeEx\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x55917d2a7bbc  PyEval_EvalCode\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x55917d2a7c64  run_eval_code_obj\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x55917d2d9d14  run_mod\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x55917d1a2625  PyRun_FileExFlags\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x55917d1a2a0a  PyRun_SimpleFileExFlags\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x55c7f801b37d  _PyObject_MakeTpCall\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x55c7f80a3d09  _PyEval_EvalFrameDefault\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x55c7f8068baf  _PyEval_EvalCodeWithName\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x55c7f8069643  _PyFunction_Vectorcall.localalias.353\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x55c7f7fdede6  _PyEval_EvalFrameDefault.cold.2792\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x55c7f80686a2  _PyEval_EvalCodeWithName\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x55c7f8069454  PyEval_EvalCodeEx\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x55c7f80f7bbc  PyEval_EvalCode\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x55c7f80f7c64  run_eval_code_obj\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x55c7f8129d14  run_mod\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x55c7f7ff2625  PyRun_FileExFlags\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x55c7f7ff2a0a  PyRun_SimpleFileExFlags\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x5609fadfbd09  _PyEval_EvalFrameDefault\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x5609fadc0baf  _PyEval_EvalCodeWithName\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x5609fadc1643  _PyFunction_Vectorcall.localalias.353\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x5609fad36de6  _PyEval_EvalFrameDefault.cold.2792\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x5609fadc06a2  _PyEval_EvalCodeWithName\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x5609fadc1454  PyEval_EvalCodeEx\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x5609fae4fbbc  PyEval_EvalCode\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x5609fae4fc64  run_eval_code_obj\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x5609fae81d14  run_mod\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x5609fad4a625  PyRun_FileExFlags\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x5609fad4aa0a  PyRun_SimpleFileExFlags\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x5609fad4b8cf  Py_RunMain.cold.2911\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x55917d1a38cf  Py_RunMain.cold.2911\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x55917d2dc829  Py_BytesMain\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x7f92f4907840  __libc_start_main\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x55917d26cb33  (unknown)\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x55c7f7ff38cf  Py_RunMain.cold.2911\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x55c7f812c829  Py_BytesMain\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x7f1255258840  __libc_start_main\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x55c7f80bcb33  (unknown)\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x5609fae84829  Py_BytesMain\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x7f4255cbf840  __libc_start_main\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x5609fae14b33  (unknown)\n",
-      "2020-10-13 12:32:56,926\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffffdf5a1a8201000000.\n",
-      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1013 12:32:56.915767   265   265 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Socket closed\n",
-      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1013 12:32:56.929625   265   265 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Socket closed\n",
-      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1013 12:32:56.932425   265   265 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Socket closed\n"
+      "2020-11-03 18:08:58,480 - wandb.wandb_agent - INFO - Running runs: ['dy77i2y1']\n"
      ]
     }
    ],
    "source": [
-    "!wandb agent kitgghxj"
+    "!wandb agent kkxvg8te"
    ]
   },
   {
diff --git a/JSS/.ipynb_checkpoints/default_config-checkpoint.py b/JSS/.ipynb_checkpoints/default_config-checkpoint.py
index 46f4d10..4729210 100644
--- a/JSS/.ipynb_checkpoints/default_config-checkpoint.py
+++ b/JSS/.ipynb_checkpoints/default_config-checkpoint.py
@@ -6,7 +6,7 @@ default_config = {
     'env': 'jss_env',
     'seed': 0,
     'framework': 'torch',
-    'log_level': 'INFO',
+    'log_level': 'WARN',
     'num_gpus': 1,
     'instance_path': '/JSS/JSS/env/instances/ta51',
     'num_envs_per_worker': 2,
diff --git a/JSS/.ipynb_checkpoints/train-checkpoint.py b/JSS/.ipynb_checkpoints/train-checkpoint.py
index d4ac941..0275259 100644
--- a/JSS/.ipynb_checkpoints/train-checkpoint.py
+++ b/JSS/.ipynb_checkpoints/train-checkpoint.py
@@ -47,10 +47,10 @@ def train_func():
     config.pop('layer_size', None)
     config.pop('layer_nb', None)
 
-    ray.init()
+    ray.init(num_gpus=1)
 
     stop = {
-        "time_total_s": 60 * 60,
+        "time_total_s": 10 * 60,
     }
 
     analysis = tune.run(PPOTrainer, config=config, stop=stop, name="ppo-jss")
diff --git a/JSS/MTWR.py b/JSS/MTWR.py
index 1b7b946..37944ef 100644
--- a/JSS/MTWR.py
+++ b/JSS/MTWR.py
@@ -21,11 +21,11 @@ def MTWR_worker(default_config):
         real_state = np.copy(state['real_obs'])
         legal_actions = state['action_mask'][:-1]
         reshaped = np.reshape(real_state, (env.jobs, 7))
-        remaining_time = reshaped[:, 3]
+        remaining_time = (reshaped[:, 3] * env.max_time_jobs) / env.jobs_length
         illegal_actions = np.invert(legal_actions)
-        mask = illegal_actions * -1e8
+        mask = illegal_actions * 1e8
         remaining_time += mask
-        MTWR_action = np.argmax(remaining_time)
+        MTWR_action = np.argmin(remaining_time)
         assert legal_actions[MTWR_action]
         state, reward, done, _ = env.step(MTWR_action)
     env.reset()
diff --git a/JSS/PPO.ipynb b/JSS/PPO.ipynb
index 23b572b..7af21e8 100644
--- a/JSS/PPO.ipynb
+++ b/JSS/PPO.ipynb
@@ -2,7 +2,7 @@
  "cells": [
   {
    "cell_type": "code",
-   "execution_count": 13,
+   "execution_count": 9,
    "metadata": {},
    "outputs": [
     {
@@ -56,7 +56,7 @@
     "    print(\"I have detected {} CPUs here, so I'm going to create {} actors\".format(mp.cpu_count(), mp.cpu_count() - 1))\n",
     "    os.environ[\"WANDB_API_KEY\"] = '3487a01956bf67cc7882bca2a38f70c8c95f8463'\n",
     "    sweep_config = {\n",
-    "        'program': 'MTWR.py',\n",
+    "        'program': 'train.py',\n",
     "        'method': 'grid',\n",
     "        'metric': {\n",
     "            'name': 'time_step_min',\n",
@@ -64,9 +64,9 @@
     "        },\n",
     "        'parameters': {\n",
     "            'instance_path': {\n",
-    "                'values': ['/JSS/JSS/env/instances/ta51', '/JSS/JSS/env/instances/ta52', '/JSS/JSS/env/instances/ta53', '/JSS/JSS/env/instances/ta54',\n",
-    "                           '/JSS/JSS/env/instances/ta55', '/JSS/JSS/env/instances/ta56', '/JSS/JSS/env/instances/ta57', '/JSS/JSS/env/instances/ta58',\n",
-    "                           '/JSS/JSS/env/instances/ta59', '/JSS/JSS/env/instances/ta60']\n",
+    "                'values': ['/JSS/JSS/env/instances/ta40', '/JSS/JSS/env/instances/ta41', '/JSS/JSS/env/instances/ta42', '/JSS/JSS/env/instances/ta43', '/JSS/JSS/env/instances/ta44',\n",
+    "                           '/JSS/JSS/env/instances/ta45', '/JSS/JSS/env/instances/ta46', '/JSS/JSS/env/instances/ta47', '/JSS/JSS/env/instances/ta48',\n",
+    "                           '/JSS/JSS/env/instances/ta49', '/JSS/JSS/env/instances/ta50']\n",
     "            }\n",
     "        }\n",
     "    }"
@@ -74,25 +74,34 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 14,
+   "execution_count": 10,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "!export CUDA_VISIBLE_DEVICES=0"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 11,
    "metadata": {},
    "outputs": [
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "Create sweep with ID: po3ygyxo\n",
-      "Sweep URL: https://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/po3ygyxo\n"
+      "Create sweep with ID: 72qf0qyh\n",
+      "Sweep URL: https://wandb.ai/ingambe/RLLIB_SWEEP_3/sweeps/72qf0qyh\n"
      ]
     }
    ],
    "source": [
-    "sweep_id = wandb.sweep(sweep_config, project=\"RLLIB_SWEEP_2\")"
+    "sweep_id = wandb.sweep(sweep_config, project=\"RLLIB_SWEEP_3\")"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 15,
+   "execution_count": null,
    "metadata": {},
    "outputs": [
     {
@@ -100,425 +109,21416 @@
      "output_type": "stream",
      "text": [
       "\u001b[34m\u001b[1mwandb\u001b[0m: Starting wandb agent üïµÔ∏è\n",
-      "2020-10-14 20:43:27,735 - wandb.wandb_agent - INFO - Running runs: []\n",
-      "2020-10-14 20:43:31,145 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-14 20:43:31,145 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tinstance_path: /JSS/JSS/env/instances/ta51\n",
-      "2020-10-14 20:43:31,147 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python MTWR.py --instance_path=/JSS/JSS/env/instances/ta51\n",
+      "2020-11-05 10:42:45,028 - wandb.wandb_agent - INFO - Running runs: []\n",
+      "2020-11-05 10:42:45,431 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-11-05 10:42:45,431 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tinstance_path: /JSS/JSS/env/instances/ta40\n",
+      "2020-11-05 10:42:45,433 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --instance_path=/JSS/JSS/env/instances/ta40\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.9 is available!  To upgrade, please run:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mMTWR\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/po3ygyxo\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/9bbl2cxc\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201014_204333-9bbl2cxc\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msuper-sweep-1\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/sweeps/72qf0qyh\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/yih09ayf\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201105_104247-yih09ayf\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
+      "2020-11-05 10:42:50,450 - wandb.wandb_agent - INFO - Running runs: ['yih09ayf']\n",
+      "2020-11-05 10:42:50,998\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
+      "== Status ==\n",
+      "Memory usage on this node: 12.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/1 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_a7d07_00000 | RUNNING  |       |\n",
+      "+-------------------------+----------+-------+\n",
       "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 3282\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
-      "2020-10-14 20:43:36,159 - wandb.wandb_agent - INFO - Running runs: ['9bbl2cxc']\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201014_204333-9bbl2cxc/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201014_204333-9bbl2cxc/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:       nb_episodes 1\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   avg_best_result 197.38384\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_episode 197.38384\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:     best_timestep 3753\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:             _step 0\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:          _runtime 1\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        _timestamp 1602708214\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:       nb_episodes ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   avg_best_result ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_episode ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:     best_timestep ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:             _step ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:          _runtime ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        _timestamp ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mMTWR\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/9bbl2cxc\u001b[0m\n",
-      "2020-10-14 20:43:41,380 - wandb.wandb_agent - INFO - Cleaning up finished run: 9bbl2cxc\n",
-      "2020-10-14 20:43:41,772 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-14 20:43:41,772 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tinstance_path: /JSS/JSS/env/instances/ta52\n",
-      "2020-10-14 20:43:41,774 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python MTWR.py --instance_path=/JSS/JSS/env/instances/ta52\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mMTWR\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/po3ygyxo\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/frw3hck3\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201014_204343-frw3hck3\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
+      "\u001b[2m\u001b[36m(pid=39695)\u001b[0m 2020-11-05 10:42:53,832\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=39695)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/torch/cuda/__init__.py:125: UserWarning: \n",
+      "\u001b[2m\u001b[36m(pid=39695)\u001b[0m GeForce RTX 2080 Ti with CUDA capability sm_75 is not compatible with the current PyTorch installation.\n",
+      "\u001b[2m\u001b[36m(pid=39695)\u001b[0m The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 compute_37.\n",
+      "\u001b[2m\u001b[36m(pid=39695)\u001b[0m If you want to use the GeForce RTX 2080 Ti GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
+      "\u001b[2m\u001b[36m(pid=39695)\u001b[0m \n",
+      "\u001b[2m\u001b[36m(pid=39695)\u001b[0m   warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n",
+      "\u001b[2m\u001b[36m(pid=39654)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39654)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39654)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39691)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39691)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39703)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39703)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39703)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39703)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39703)\u001b[0m *** SIGSEGV (@0x0) received by PID 39703 (TID 0x7f757f974700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39703)\u001b[0m     @     0x7f757f54d390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39703)\u001b[0m     @     0x7f467f4eaf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39703)\u001b[0m     @     0x7f467ec157db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39703)\u001b[0m     @     0x7f467ec188f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39659)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39659)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39659)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39659)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39659)\u001b[0m *** SIGSEGV (@0x0) received by PID 39659 (TID 0x7fdf8a412700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39659)\u001b[0m     @     0x7fdf89feb390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39659)\u001b[0m     @     0x7fb089e24f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39659)\u001b[0m     @     0x7fb08954f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39659)\u001b[0m     @     0x7fb0895528f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39659)\u001b[0m     @     0x7fb089552ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39653)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39653)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39661)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39661)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39661)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39590)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39590)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39590)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39615)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39615)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39615)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39694)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39694)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39694)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39669)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39669)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39669)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39669)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39669)\u001b[0m *** SIGSEGV (@0x0) received by PID 39669 (TID 0x7efff0ecc700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39589)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39589)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39589)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39665)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39665)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39665)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39665)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39665)\u001b[0m *** SIGSEGV (@0x0) received by PID 39665 (TID 0x7f858f389700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39665)\u001b[0m     @     0x7f858ef62390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39665)\u001b[0m     @     0x7f568ef13f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39665)\u001b[0m     @     0x7f568e63e7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39665)\u001b[0m     @     0x7f568e6418f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39665)\u001b[0m     @     0x7f568e641ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39665)\u001b[0m     @     0x7f568e641d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39665)\u001b[0m     @     0x7f568ef24b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39665)\u001b[0m     @     0x7f568ef47c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39665)\u001b[0m     @     0x7f568e3e9a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39665)\u001b[0m     @     0x7f568e3e7388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39680)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39680)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39680)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39680)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39680)\u001b[0m *** SIGSEGV (@0x0) received by PID 39680 (TID 0x7f2eedde8700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39680)\u001b[0m     @     0x7f2eed9c1390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39680)\u001b[0m     @     0x7effed7f9f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39680)\u001b[0m     @     0x7effecf247db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39680)\u001b[0m     @     0x7effecf278f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39680)\u001b[0m     @     0x7effecf27ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39680)\u001b[0m     @     0x7effecf27d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39680)\u001b[0m     @     0x7effed80ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39680)\u001b[0m     @     0x7effed82dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39680)\u001b[0m     @     0x7effecccfa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39680)\u001b[0m     @     0x7effecccd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39696)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39696)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39696)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39696)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39696)\u001b[0m *** SIGSEGV (@0x0) received by PID 39696 (TID 0x7f26ff082700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39696)\u001b[0m     @     0x7f26fec5b390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39696)\u001b[0m     @     0x7ef7febcef90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39696)\u001b[0m     @     0x7ef7fe2f97db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39696)\u001b[0m     @     0x7ef7fe2fc8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39696)\u001b[0m     @     0x7ef7fe2fcad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39696)\u001b[0m     @     0x7ef7fe2fcd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39696)\u001b[0m     @     0x7ef7febdfb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39696)\u001b[0m     @     0x7ef7fec02c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39696)\u001b[0m     @     0x7ef7fe0a4a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39696)\u001b[0m     @     0x7ef7fe0a2388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39591)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39591)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39591)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39591)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39591)\u001b[0m *** SIGSEGV (@0x0) received by PID 39591 (TID 0x7fcbcaf6c700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39591)\u001b[0m     @     0x7fcbcab45390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39591)\u001b[0m     @     0x7f9ccaa21f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39687)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39687)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39687)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39687)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39687)\u001b[0m *** SIGSEGV (@0x0) received by PID 39687 (TID 0x7fa23a3ac700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39687)\u001b[0m     @     0x7fa239f85390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39687)\u001b[0m     @     0x7f7339e24f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39687)\u001b[0m     @     0x7f733954f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39687)\u001b[0m     @     0x7f73395528f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39687)\u001b[0m     @     0x7f7339552ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39687)\u001b[0m     @     0x7f7339552d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39687)\u001b[0m     @     0x7f7339e35b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39687)\u001b[0m     @     0x7f7339e58c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39687)\u001b[0m     @     0x7f73392faa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39687)\u001b[0m     @     0x7f73392f8388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39651)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39651)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39651)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39651)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39651)\u001b[0m *** SIGSEGV (@0x0) received by PID 39651 (TID 0x7f01ed5a9700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39651)\u001b[0m     @     0x7f01ed182390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39651)\u001b[0m     @     0x7ed2ed0b5f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39651)\u001b[0m     @     0x7ed2ec7e07db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39651)\u001b[0m     @     0x7ed2ec7e38f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39651)\u001b[0m     @     0x7ed2ec7e3ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39651)\u001b[0m     @     0x7ed2ec7e3d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39651)\u001b[0m     @     0x7ed2ed0c6b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39693)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39693)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39693)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39693)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39693)\u001b[0m *** SIGSEGV (@0x0) received by PID 39693 (TID 0x7f7f1f038700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39693)\u001b[0m     @     0x7f7f1ec11390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39693)\u001b[0m     @     0x7f501ea21f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39693)\u001b[0m     @     0x7f501e14c7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39693)\u001b[0m     @     0x7f501e14f8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39693)\u001b[0m     @     0x7f501e14fad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39693)\u001b[0m     @     0x7f501e14fd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39693)\u001b[0m     @     0x7f501ea32b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39693)\u001b[0m     @     0x7f501ea55c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39693)\u001b[0m     @     0x7f501def7a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39693)\u001b[0m     @     0x7f501def5388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39664)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39664)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39664)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39664)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39664)\u001b[0m *** SIGSEGV (@0x0) received by PID 39664 (TID 0x7f3abbd11700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39664)\u001b[0m     @     0x7f3abb8ea390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39664)\u001b[0m     @     0x7f0bbb89ef90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39655)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39655)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39655)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39655)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39655)\u001b[0m *** SIGSEGV (@0x0) received by PID 39655 (TID 0x7fe85f6e4700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39655)\u001b[0m     @     0x7fe85f2bd390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39655)\u001b[0m     @     0x7fb95f229f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39655)\u001b[0m     @     0x7fb95e9547db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39655)\u001b[0m     @     0x7fb95e9578f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39655)\u001b[0m     @     0x7fb95e957ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39655)\u001b[0m     @     0x7fb95e957d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39655)\u001b[0m     @     0x7fb95f23ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39655)\u001b[0m     @     0x7fb95f25dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39655)\u001b[0m     @     0x7fb95e6ffa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39655)\u001b[0m     @     0x7fb95e6fd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39655)\u001b[0m     @     0x7fb95e6ff5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39655)\u001b[0m     @     0x7fb95edea4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39672)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39672)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39672)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39672)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39672)\u001b[0m *** SIGSEGV (@0x0) received by PID 39672 (TID 0x7f7493e07700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39672)\u001b[0m     @     0x7f74939e0390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39672)\u001b[0m     @     0x7f45938def90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39666)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39666)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39666)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39666)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39666)\u001b[0m *** SIGSEGV (@0x0) received by PID 39666 (TID 0x7f6a2ecee700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39666)\u001b[0m     @     0x7f6a2e8c7390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39666)\u001b[0m     @     0x7f3b2e70af90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39666)\u001b[0m     @     0x7f3b2de357db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39668)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39668)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39668)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39668)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39668)\u001b[0m *** SIGSEGV (@0x0) received by PID 39668 (TID 0x7f20334c0700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39668)\u001b[0m     @     0x7f2033099390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39668)\u001b[0m     @     0x7ef132f13f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39668)\u001b[0m     @     0x7ef13263e7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39668)\u001b[0m     @     0x7ef1326418f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39668)\u001b[0m     @     0x7ef132641ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39668)\u001b[0m     @     0x7ef132641d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39668)\u001b[0m     @     0x7ef132f24b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39668)\u001b[0m     @     0x7ef132f47c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39668)\u001b[0m     @     0x7ef1323e9a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39668)\u001b[0m     @     0x7ef1323e7388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39668)\u001b[0m     @     0x7ef1323e95a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39593)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39593)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39593)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39593)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39593)\u001b[0m *** SIGSEGV (@0x0) received by PID 39593 (TID 0x7f23a2c78700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39670)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39670)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39670)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39670)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39670)\u001b[0m *** SIGSEGV (@0x0) received by PID 39670 (TID 0x7f36818c6700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39670)\u001b[0m     @     0x7f368149f390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39670)\u001b[0m     @     0x7f07813ccf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39658)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39658)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39658)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39658)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39658)\u001b[0m *** SIGSEGV (@0x0) received by PID 39658 (TID 0x7f3f57582700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39658)\u001b[0m     @     0x7f3f5715b390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39658)\u001b[0m     @     0x7f1056f13f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39658)\u001b[0m     @     0x7f105663e7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39658)\u001b[0m     @     0x7f10566418f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39658)\u001b[0m     @     0x7f1056641ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39658)\u001b[0m     @     0x7f1056641d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39658)\u001b[0m     @     0x7f1056f24b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39658)\u001b[0m     @     0x7f1056f47c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39658)\u001b[0m     @     0x7f10563e9a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39658)\u001b[0m     @     0x7f10563e7388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39658)\u001b[0m     @     0x7f10563e95a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39688)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39688)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39688)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39688)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39688)\u001b[0m *** SIGSEGV (@0x0) received by PID 39688 (TID 0x7fc96ea4a700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39688)\u001b[0m     @     0x7fc96e623390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39688)\u001b[0m     @     0x7f9a6e4f9f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39688)\u001b[0m     @     0x7f9a6dc247db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39611)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39611)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39611)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39611)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39611)\u001b[0m *** SIGSEGV (@0x0) received by PID 39611 (TID 0x7fbb98af7700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39611)\u001b[0m     @     0x7fbb986d0390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39602)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39602)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39602)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39602)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39602)\u001b[0m *** SIGSEGV (@0x0) received by PID 39602 (TID 0x7f916f4f3700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39602)\u001b[0m     @     0x7f916f0cc390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39602)\u001b[0m     @     0x7f626f077f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39602)\u001b[0m     @     0x7f626e7a27db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39579)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39579)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39579)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39714)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39714)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39714)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39714)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39714)\u001b[0m *** SIGSEGV (@0x0) received by PID 39714 (TID 0x7f967d0dc700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39714)\u001b[0m     @     0x7f967ccb5390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39606)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39606)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39606)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39606)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39606)\u001b[0m *** SIGSEGV (@0x0) received by PID 39606 (TID 0x7f58c5161700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39606)\u001b[0m     @     0x7f58c4d3a390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39599)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39599)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39599)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39583)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39583)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39583)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39583)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39583)\u001b[0m *** SIGSEGV (@0x0) received by PID 39583 (TID 0x7fe501d71700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39583)\u001b[0m     @     0x7fe50194a390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39594)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39594)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39594)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39594)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39594)\u001b[0m *** SIGSEGV (@0x0) received by PID 39594 (TID 0x7ff2d9c33700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39594)\u001b[0m     @     0x7ff2d980c390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39594)\u001b[0m     @     0x7fc3d96f4f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39598)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39598)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39598)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39598)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39598)\u001b[0m *** SIGSEGV (@0x0) received by PID 39598 (TID 0x7fa224eb1700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39598)\u001b[0m     @     0x7fa224a8a390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39592)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39592)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39592)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39592)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39592)\u001b[0m *** SIGSEGV (@0x0) received by PID 39592 (TID 0x7f3203b4d700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39592)\u001b[0m     @     0x7f3203726390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39647)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39647)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39647)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39647)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39647)\u001b[0m *** SIGSEGV (@0x0) received by PID 39647 (TID 0x7fcd5acb0700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39647)\u001b[0m     @     0x7fcd5a889390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39647)\u001b[0m     @     0x7f9e5a70af90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39581)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39581)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39581)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39581)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39581)\u001b[0m *** SIGSEGV (@0x0) received by PID 39581 (TID 0x7f8bf72f1700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39581)\u001b[0m     @     0x7f8bf6eca390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39581)\u001b[0m     @     0x7f5cf1391f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39581)\u001b[0m     @     0x7f5cf0abc7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39581)\u001b[0m     @     0x7f5cf0abf8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39707)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39707)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39707)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39707)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39707)\u001b[0m *** SIGSEGV (@0x0) received by PID 39707 (TID 0x7fbac50f7700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39707)\u001b[0m     @     0x7fbac4cd0390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39707)\u001b[0m     @     0x7f8bc4bd1f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39707)\u001b[0m     @     0x7f8bc42fc7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39707)\u001b[0m     @     0x7f8bc42ff8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39707)\u001b[0m     @     0x7f8bc42ffad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39707)\u001b[0m     @     0x7f8bc42ffd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39707)\u001b[0m     @     0x7f8bc4be2b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39707)\u001b[0m     @     0x7f8bc4c05c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39707)\u001b[0m     @     0x7f8bc40a7a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39707)\u001b[0m     @     0x7f8bc40a5388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39601)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39601)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39601)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39601)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39601)\u001b[0m *** SIGSEGV (@0x0) received by PID 39601 (TID 0x7fdf35e32700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39601)\u001b[0m     @     0x7fdf35a0b390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39601)\u001b[0m     @     0x7fb0357f9f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39601)\u001b[0m     @     0x7fb034f247db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39710)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39710)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39710)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39710)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39710)\u001b[0m *** SIGSEGV (@0x0) received by PID 39710 (TID 0x7f6a58674700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39710)\u001b[0m     @     0x7f6a5824d390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39710)\u001b[0m     @     0x7f3b580cdf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39710)\u001b[0m     @     0x7f3b577f87db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39710)\u001b[0m     @     0x7f3b577fb8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39710)\u001b[0m     @     0x7f3b577fbad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39710)\u001b[0m     @     0x7f3b577fbd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39710)\u001b[0m     @     0x7f3b580deb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39710)\u001b[0m     @     0x7f3b58101c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39710)\u001b[0m     @     0x7f3b575a3a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39710)\u001b[0m     @     0x7f3b575a1388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39710)\u001b[0m     @     0x7f3b575a35a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39685)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39685)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39685)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39685)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39685)\u001b[0m *** SIGSEGV (@0x0) received by PID 39685 (TID 0x7f3debff5700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39685)\u001b[0m     @     0x7f3debbce390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39685)\u001b[0m     @     0x7f0eebaf5f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39685)\u001b[0m     @     0x7f0eeb2207db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39685)\u001b[0m     @     0x7f0eeb2238f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39685)\u001b[0m     @     0x7f0eeb223ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39685)\u001b[0m     @     0x7f0eeb223d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39685)\u001b[0m     @     0x7f0eebb06b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39685)\u001b[0m     @     0x7f0eebb29c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39685)\u001b[0m     @     0x7f0eeafcba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39685)\u001b[0m     @     0x7f0eeafc9388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39685)\u001b[0m     @     0x7f0eeafcb5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39604)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39604)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39604)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39604)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39604)\u001b[0m *** SIGSEGV (@0x0) received by PID 39604 (TID 0x7f70450c1700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39604)\u001b[0m     @     0x7f7044c9a390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39656)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39656)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39656)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39656)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39656)\u001b[0m *** SIGSEGV (@0x0) received by PID 39656 (TID 0x7f32fb3fa700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39648)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39648)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39648)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39587)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39587)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39587)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39587)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39587)\u001b[0m *** SIGSEGV (@0x0) received by PID 39587 (TID 0x7f6a12e10700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39587)\u001b[0m     @     0x7f6a129e9390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39686)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39686)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39686)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39686)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39686)\u001b[0m *** SIGSEGV (@0x0) received by PID 39686 (TID 0x7f665ebf2700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39686)\u001b[0m     @     0x7f665e7cb390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39686)\u001b[0m     @     0x7f375e4f9f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39686)\u001b[0m     @     0x7f375dc247db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39686)\u001b[0m     @     0x7f375dc278f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39686)\u001b[0m     @     0x7f375dc27ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39686)\u001b[0m     @     0x7f375dc27d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39686)\u001b[0m     @     0x7f375e50ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39686)\u001b[0m     @     0x7f375e52dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39686)\u001b[0m     @     0x7f375d9cfa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39686)\u001b[0m     @     0x7f375d9cd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39686)\u001b[0m     @     0x7f375d9cf5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39677)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39677)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39677)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39677)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39677)\u001b[0m *** SIGSEGV (@0x0) received by PID 39677 (TID 0x7f12776f8700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39677)\u001b[0m     @     0x7f12772d1390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39677)\u001b[0m     @     0x7ee377229f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39677)\u001b[0m     @     0x7ee3769547db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39677)\u001b[0m     @     0x7ee3769578f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39677)\u001b[0m     @     0x7ee376957ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39677)\u001b[0m     @     0x7ee376957d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39677)\u001b[0m     @     0x7ee37723ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39677)\u001b[0m     @     0x7ee37725dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39677)\u001b[0m     @     0x7ee3766ffa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39677)\u001b[0m     @     0x7ee3766fd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39614)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39614)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39614)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39614)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39614)\u001b[0m *** SIGSEGV (@0x0) received by PID 39614 (TID 0x7f2890047700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39614)\u001b[0m     @     0x7f288fc20390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39614)\u001b[0m     @     0x7ef98faf5f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39614)\u001b[0m     @     0x7ef98f2207db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39597)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39597)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39597)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39597)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39597)\u001b[0m *** SIGSEGV (@0x0) received by PID 39597 (TID 0x7f211a5cc700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39597)\u001b[0m     @     0x7f211a1a5390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39597)\u001b[0m     @     0x7ef21a13af90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39597)\u001b[0m     @     0x7ef2198657db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39682)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39682)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39682)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39682)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39682)\u001b[0m *** SIGSEGV (@0x0) received by PID 39682 (TID 0x7fa1394fd700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39682)\u001b[0m     @     0x7fa1390d6390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39682)\u001b[0m     @     0x7f7239083f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39682)\u001b[0m     @     0x7f72387ae7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39580)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39580)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39580)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39580)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39580)\u001b[0m *** SIGSEGV (@0x0) received by PID 39580 (TID 0x7f72b4b0a700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39580)\u001b[0m     @     0x7f72b46e3390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39580)\u001b[0m     @     0x7f43b4507f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39580)\u001b[0m     @     0x7f43b3c327db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39681)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39681)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39681)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39681)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39681)\u001b[0m *** SIGSEGV (@0x0) received by PID 39681 (TID 0x7fc665513700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39681)\u001b[0m     @     0x7fc6650ec390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39681)\u001b[0m     @     0x7f9765088f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39681)\u001b[0m     @     0x7f97647b37db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39681)\u001b[0m     @     0x7f97647b68f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39681)\u001b[0m     @     0x7f97647b6ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39681)\u001b[0m     @     0x7f97647b6d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39681)\u001b[0m     @     0x7f9765099b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39681)\u001b[0m     @     0x7f97650bcc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39681)\u001b[0m     @     0x7f976455ea93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39681)\u001b[0m     @     0x7f976455c388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39681)\u001b[0m     @     0x7f976455e5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39649)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39649)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39649)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39649)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39649)\u001b[0m *** SIGSEGV (@0x0) received by PID 39649 (TID 0x7f9f3ef89700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39657)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39657)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39674)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39674)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39674)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39674)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39674)\u001b[0m *** SIGSEGV (@0x0) received by PID 39674 (TID 0x7fb646eab700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39674)\u001b[0m     @     0x7fb646a84390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39674)\u001b[0m     @     0x7f87469ccf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39674)\u001b[0m     @     0x7f87460f77db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39586)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39586)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39586)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39586)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39586)\u001b[0m *** SIGSEGV (@0x0) received by PID 39586 (TID 0x7f7bf6144700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39586)\u001b[0m     @     0x7f7bf5d1d390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39692)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39692)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39692)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39692)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39692)\u001b[0m *** SIGSEGV (@0x0) received by PID 39692 (TID 0x7f62572c0700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39692)\u001b[0m     @     0x7f6256e99390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39692)\u001b[0m     @     0x7f3356e53f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39692)\u001b[0m     @     0x7f335657e7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39660)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39660)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39660)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39660)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39660)\u001b[0m *** SIGSEGV (@0x0) received by PID 39660 (TID 0x7f8424591700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39612)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39612)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39612)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39585)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39585)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39585)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39585)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39585)\u001b[0m *** SIGSEGV (@0x0) received by PID 39585 (TID 0x7fc504bc1700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39585)\u001b[0m     @     0x7fc50479a390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39585)\u001b[0m     @     0x7f960460ef90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39585)\u001b[0m     @     0x7f9603d397db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39646)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39646)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39646)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39662)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39662)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39662)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39662)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39662)\u001b[0m *** SIGSEGV (@0x0) received by PID 39662 (TID 0x7fc275814700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39662)\u001b[0m     @     0x7fc2753ed390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39662)\u001b[0m     @     0x7f937535ff90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39662)\u001b[0m     @     0x7f9374a8a7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39697)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39697)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39697)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39697)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39697)\u001b[0m *** SIGSEGV (@0x0) received by PID 39697 (TID 0x7f28ebb32700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39582)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39582)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39582)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39582)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39582)\u001b[0m *** SIGSEGV (@0x0) received by PID 39582 (TID 0x7f93458eb700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39582)\u001b[0m     @     0x7f93454c4390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39582)\u001b[0m     @     0x7f6445476f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39582)\u001b[0m     @     0x7f6444ba17db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39582)\u001b[0m     @     0x7f6444ba48f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39584)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39584)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39584)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39584)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39584)\u001b[0m *** SIGSEGV (@0x0) received by PID 39584 (TID 0x7f9ab01c6700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39584)\u001b[0m     @     0x7f9aafd9f390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39584)\u001b[0m     @     0x7f6bafd39f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39584)\u001b[0m     @     0x7f6baf4647db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39704)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39704)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39704)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39704)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39704)\u001b[0m *** SIGSEGV (@0x0) received by PID 39704 (TID 0x7f7ae497d700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39704)\u001b[0m     @     0x7f7ae4556390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39704)\u001b[0m     @     0x7f4be44d1f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39704)\u001b[0m     @     0x7f4be3bfc7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39704)\u001b[0m     @     0x7f4be3bff8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39645)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39645)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39645)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39645)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39645)\u001b[0m *** SIGSEGV (@0x0) received by PID 39645 (TID 0x7f4e4cb95700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39645)\u001b[0m     @     0x7f4e4c76e390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39645)\u001b[0m     @     0x7f1f4c60ef90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39645)\u001b[0m     @     0x7f1f4bd397db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39654)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39654)\u001b[0m *** SIGSEGV (@0x0) received by PID 39654 (TID 0x7f139d570700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39654)\u001b[0m     @     0x7f139d149390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39654)\u001b[0m     @     0x7ee49d0b5f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39654)\u001b[0m     @     0x7ee49c7e07db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39654)\u001b[0m     @     0x7ee49c7e38f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39654)\u001b[0m     @     0x7ee49c7e3ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39691)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39691)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39691)\u001b[0m *** SIGSEGV (@0x0) received by PID 39691 (TID 0x7f2661a8a700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39691)\u001b[0m     @     0x7f2661663390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39691)\u001b[0m     @     0x7ef7615e2f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39691)\u001b[0m     @     0x7ef760d0d7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39691)\u001b[0m     @     0x7ef760d108f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39691)\u001b[0m     @     0x7ef760d10ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39703)\u001b[0m     @     0x7f467ec18ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39703)\u001b[0m     @     0x7f467ec18d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39703)\u001b[0m     @     0x7f467f4fbb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39703)\u001b[0m     @     0x7f467f51ec1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39703)\u001b[0m     @     0x7f467e9c0a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39703)\u001b[0m     @     0x7f467e9be388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39703)\u001b[0m     @     0x7f467e9c05a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39659)\u001b[0m     @     0x7fb089552d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39659)\u001b[0m     @     0x7fb089e35b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39659)\u001b[0m     @     0x7fb089e58c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39659)\u001b[0m     @     0x7fb0892faa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39659)\u001b[0m     @     0x7fb0892f8388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39659)\u001b[0m     @     0x7fb0892fa5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39659)\u001b[0m     @     0x7fb0899e54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39659)\u001b[0m     @     0x7fb08beb88de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39610)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39610)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39610)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39610)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39610)\u001b[0m *** SIGSEGV (@0x0) received by PID 39610 (TID 0x7f5d39678700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39610)\u001b[0m     @     0x7f5d39251390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39610)\u001b[0m     @     0x7f2e390b5f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39610)\u001b[0m     @     0x7f2e387e07db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39610)\u001b[0m     @     0x7f2e387e38f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39652)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39652)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39652)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39652)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39652)\u001b[0m *** SIGSEGV (@0x0) received by PID 39652 (TID 0x7f872bb27700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39652)\u001b[0m     @     0x7f872b700390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39652)\u001b[0m     @     0x7f582b61ff90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39652)\u001b[0m     @     0x7f582ad4a7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39652)\u001b[0m     @     0x7f582ad4d8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39699)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39699)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39699)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39699)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39699)\u001b[0m *** SIGSEGV (@0x0) received by PID 39699 (TID 0x7f5deb7f5700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39699)\u001b[0m     @     0x7f5deb3ce390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39699)\u001b[0m     @     0x7f2eeac15f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39699)\u001b[0m     @     0x7f2eea3407db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39650)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39650)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39650)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39650)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39650)\u001b[0m *** SIGSEGV (@0x0) received by PID 39650 (TID 0x7f6fc5e87700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39600)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39600)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39600)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39600)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39600)\u001b[0m *** SIGSEGV (@0x0) received by PID 39600 (TID 0x7f5b34362700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39653)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39653)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39653)\u001b[0m *** SIGSEGV (@0x0) received by PID 39653 (TID 0x7f815544d700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39653)\u001b[0m     @     0x7f8155026390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39653)\u001b[0m     @     0x7f5254b85f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39653)\u001b[0m     @     0x7f52542b07db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39653)\u001b[0m     @     0x7f52542b38f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39663)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39663)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39663)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39663)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39663)\u001b[0m *** SIGSEGV (@0x0) received by PID 39663 (TID 0x7f52713d2700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39663)\u001b[0m     @     0x7f5270fab390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39596)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39596)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39596)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39596)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39596)\u001b[0m *** SIGSEGV (@0x0) received by PID 39596 (TID 0x7fd147109700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39596)\u001b[0m     @     0x7fd146ce2390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39596)\u001b[0m     @     0x7fa246c8ff90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39596)\u001b[0m     @     0x7fa2463ba7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39613)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39613)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39613)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39613)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39613)\u001b[0m *** SIGSEGV (@0x0) received by PID 39613 (TID 0x7f7aa2719700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39661)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39661)\u001b[0m *** SIGSEGV (@0x0) received by PID 39661 (TID 0x7fe7aa179700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39661)\u001b[0m     @     0x7fe7a9d52390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39661)\u001b[0m     @     0x7fb8a9ceff90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39661)\u001b[0m     @     0x7fb8a941a7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39661)\u001b[0m     @     0x7fb8a941d8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39590)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39590)\u001b[0m *** SIGSEGV (@0x0) received by PID 39590 (TID 0x7fb6baee3700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39590)\u001b[0m     @     0x7fb6baabc390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39590)\u001b[0m     @     0x7f87baa21f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39590)\u001b[0m     @     0x7f87ba14c7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39590)\u001b[0m     @     0x7f87ba14f8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39615)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39615)\u001b[0m *** SIGSEGV (@0x0) received by PID 39615 (TID 0x7fecc0bbd700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39615)\u001b[0m     @     0x7fecc0796390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39615)\u001b[0m     @     0x7fbdc071ff90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39615)\u001b[0m     @     0x7fbdbfe4a7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39615)\u001b[0m     @     0x7fbdbfe4d8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39694)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39694)\u001b[0m *** SIGSEGV (@0x0) received by PID 39694 (TID 0x7fb8ed531700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39694)\u001b[0m     @     0x7fb8ed10a390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39694)\u001b[0m     @     0x7f89ed088f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39694)\u001b[0m     @     0x7f89ec7b37db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39669)\u001b[0m     @     0x7efff0aa5390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39669)\u001b[0m     @     0x7ed0f097ff90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39669)\u001b[0m     @     0x7ed0f00aa7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39669)\u001b[0m     @     0x7ed0f00ad8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39669)\u001b[0m     @     0x7ed0f00adad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39589)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39589)\u001b[0m *** SIGSEGV (@0x0) received by PID 39589 (TID 0x7ff9cc2e5700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39589)\u001b[0m     @     0x7ff9cbebe390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39589)\u001b[0m     @     0x7fcacbdf0f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39589)\u001b[0m     @     0x7fcacb51b7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39589)\u001b[0m     @     0x7fcacb51e8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39665)\u001b[0m     @     0x7f568e3e95a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39665)\u001b[0m     @     0x7f568ead44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39665)\u001b[0m     @     0x7f5690fa78de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39680)\u001b[0m     @     0x7effecccf5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39680)\u001b[0m     @     0x7effed3ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39680)\u001b[0m     @     0x7effef88d8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39680)\u001b[0m     @     0x7effed3ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39680)\u001b[0m     @     0x7efff346579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39680)\u001b[0m     @     0x563724d60fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39680)\u001b[0m     @     0x563724cbbb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39680)\u001b[0m     @     0x563724d46baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39680)\u001b[0m     @     0x563724d47a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39680)\u001b[0m     @     0x563724cbbbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39680)\u001b[0m     @     0x563724d46baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39680)\u001b[0m     @     0x563724d47643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39680)\u001b[0m     @     0x563724cbc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39680)\u001b[0m     @     0x563724d46baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39680)\u001b[0m     @     0x563724d47643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39680)\u001b[0m     @     0x563724cbc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39680)\u001b[0m     @     0x563724d46baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39680)\u001b[0m     @     0x563724d47643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39696)\u001b[0m     @     0x7ef7fe0a45a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39696)\u001b[0m     @     0x7ef7fe78f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39696)\u001b[0m     @     0x7ef800c628de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39696)\u001b[0m     @     0x7ef7fe78f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39696)\u001b[0m     @     0x7ef80483a79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39696)\u001b[0m     @     0x561dce30bfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39696)\u001b[0m     @     0x561dce266b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39696)\u001b[0m     @     0x561dce2f1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39696)\u001b[0m     @     0x561dce2f2a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39696)\u001b[0m     @     0x561dce266bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39696)\u001b[0m     @     0x561dce2f1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39696)\u001b[0m     @     0x561dce2f2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39696)\u001b[0m     @     0x561dce267689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39696)\u001b[0m     @     0x561dce2f1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39696)\u001b[0m     @     0x561dce2f2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39696)\u001b[0m     @     0x561dce267689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39591)\u001b[0m     @     0x7f9cca14c7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39591)\u001b[0m     @     0x7f9cca14f8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39591)\u001b[0m     @     0x7f9cca14fad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39591)\u001b[0m     @     0x7f9cca14fd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39591)\u001b[0m     @     0x7f9ccaa32b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39687)\u001b[0m     @     0x7f73392fa5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39687)\u001b[0m     @     0x7f73399e54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39687)\u001b[0m     @     0x7f733beb88de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39687)\u001b[0m     @     0x7f73399e54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39687)\u001b[0m     @     0x7f733fa9079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39687)\u001b[0m     @     0x55981eccffd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39687)\u001b[0m     @     0x55981ec2ab08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39687)\u001b[0m     @     0x55981ecb5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39687)\u001b[0m     @     0x55981ecb6a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39687)\u001b[0m     @     0x55981ec2abfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39687)\u001b[0m     @     0x55981ecb5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39687)\u001b[0m     @     0x55981ecb6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39687)\u001b[0m     @     0x55981ec2b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39687)\u001b[0m     @     0x55981ecb5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39687)\u001b[0m     @     0x55981ecb6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39687)\u001b[0m     @     0x55981ec2b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39687)\u001b[0m     @     0x55981ecb5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39687)\u001b[0m     @     0x55981ecb6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39687)\u001b[0m     @     0x55981ec2b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39687)\u001b[0m     @     0x55981ecb5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39687)\u001b[0m     @     0x55981ecb6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39687)\u001b[0m     @     0x55981ec2b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39651)\u001b[0m     @     0x7ed2ed0e9c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39651)\u001b[0m     @     0x7ed2ec58ba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39651)\u001b[0m     @     0x7ed2ec589388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39651)\u001b[0m     @     0x7ed2ec58b5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39693)\u001b[0m     @     0x7f501def75a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39693)\u001b[0m     @     0x7f501e5e24f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39693)\u001b[0m     @     0x7f5020ab58de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39693)\u001b[0m     @     0x7f501e5e24f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39693)\u001b[0m     @     0x7f502468d79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39693)\u001b[0m     @     0x564e3c3dffd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39693)\u001b[0m     @     0x564e3c33ab08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39693)\u001b[0m     @     0x564e3c3c5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39693)\u001b[0m     @     0x564e3c3c6a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39693)\u001b[0m     @     0x564e3c33abfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39693)\u001b[0m     @     0x564e3c3c5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39693)\u001b[0m     @     0x564e3c3c6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39664)\u001b[0m     @     0x7f0bbafc97db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39664)\u001b[0m     @     0x7f0bbafcc8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39664)\u001b[0m     @     0x7f0bbafccad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39664)\u001b[0m     @     0x7f0bbafccd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39664)\u001b[0m     @     0x7f0bbb8afb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39655)\u001b[0m     @     0x7fb9612bd8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39655)\u001b[0m     @     0x7fb95edea4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39655)\u001b[0m     @     0x7fb964e9579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39655)\u001b[0m     @     0x5602dea7afd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39655)\u001b[0m     @     0x5602de9d5b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39655)\u001b[0m     @     0x5602dea60baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39655)\u001b[0m     @     0x5602dea61a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39655)\u001b[0m     @     0x5602de9d5bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39655)\u001b[0m     @     0x5602dea60baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39655)\u001b[0m     @     0x5602dea61643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39655)\u001b[0m     @     0x5602de9d6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39655)\u001b[0m     @     0x5602dea60baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39655)\u001b[0m     @     0x5602dea61643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39655)\u001b[0m     @     0x5602de9d6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39655)\u001b[0m     @     0x5602dea60baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39655)\u001b[0m     @     0x5602dea61643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39655)\u001b[0m     @     0x5602de9d6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39655)\u001b[0m     @     0x5602dea60baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39655)\u001b[0m     @     0x5602dea61643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39655)\u001b[0m     @     0x5602de9d6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39672)\u001b[0m     @     0x7f45930097db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39672)\u001b[0m     @     0x7f459300c8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39672)\u001b[0m     @     0x7f459300cad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39672)\u001b[0m     @     0x7f459300cd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39666)\u001b[0m     @     0x7f3b2de388f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39666)\u001b[0m     @     0x7f3b2de38ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39666)\u001b[0m     @     0x7f3b2de38d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39666)\u001b[0m     @     0x7f3b2e71bb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39668)\u001b[0m     @     0x7ef132ad44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39668)\u001b[0m     @     0x7ef134fa78de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39668)\u001b[0m     @     0x7ef132ad44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39668)\u001b[0m     @     0x7ef138b7f79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39668)\u001b[0m     @     0x558b0f789fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39668)\u001b[0m     @     0x558b0f6e4b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39668)\u001b[0m     @     0x558b0f76fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39668)\u001b[0m     @     0x558b0f770a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39668)\u001b[0m     @     0x558b0f6e4bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39668)\u001b[0m     @     0x558b0f76fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39668)\u001b[0m     @     0x558b0f770643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39668)\u001b[0m     @     0x558b0f6e5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39668)\u001b[0m     @     0x558b0f76fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39668)\u001b[0m     @     0x558b0f770643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39668)\u001b[0m     @     0x558b0f6e5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39668)\u001b[0m     @     0x558b0f76fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39668)\u001b[0m     @     0x558b0f770643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39668)\u001b[0m     @     0x558b0f6e5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39668)\u001b[0m     @     0x558b0f76fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39668)\u001b[0m     @     0x558b0f770643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39668)\u001b[0m     @     0x558b0f6e5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39593)\u001b[0m     @     0x7f23a2851390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39593)\u001b[0m     @     0x7ef4a27bbf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39593)\u001b[0m     @     0x7ef4a1ee67db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39593)\u001b[0m     @     0x7ef4a1ee98f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39593)\u001b[0m     @     0x7ef4a1ee9ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39670)\u001b[0m     @     0x7f0780af77db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39670)\u001b[0m     @     0x7f0780afa8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39670)\u001b[0m     @     0x7f0780afaad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39658)\u001b[0m     @     0x7f1056ad44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39658)\u001b[0m     @     0x7f1058fa78de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39658)\u001b[0m     @     0x7f1056ad44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39658)\u001b[0m     @     0x7f105cb7f79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39658)\u001b[0m     @     0x56453a033fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39658)\u001b[0m     @     0x564539f8eb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39658)\u001b[0m     @     0x56453a019baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39658)\u001b[0m     @     0x56453a01aa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39658)\u001b[0m     @     0x564539f8ebfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39658)\u001b[0m     @     0x56453a019baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39658)\u001b[0m     @     0x56453a01a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39658)\u001b[0m     @     0x564539f8f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39658)\u001b[0m     @     0x56453a019baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39658)\u001b[0m     @     0x56453a01a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39658)\u001b[0m     @     0x564539f8f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39658)\u001b[0m     @     0x56453a019baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39658)\u001b[0m     @     0x56453a01a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39658)\u001b[0m     @     0x564539f8f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39658)\u001b[0m     @     0x56453a019baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39658)\u001b[0m     @     0x56453a01a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39658)\u001b[0m     @     0x564539f8f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39688)\u001b[0m     @     0x7f9a6dc278f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39688)\u001b[0m     @     0x7f9a6dc27ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39688)\u001b[0m     @     0x7f9a6dc27d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39611)\u001b[0m     @     0x7f8c98563f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39611)\u001b[0m     @     0x7f8c97c8e7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39611)\u001b[0m     @     0x7f8c97c918f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39611)\u001b[0m     @     0x7f8c97c91ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39611)\u001b[0m     @     0x7f8c97c91d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39611)\u001b[0m     @     0x7f8c98574b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39611)\u001b[0m     @     0x7f8c98597c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39602)\u001b[0m     @     0x7f626e7a58f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39602)\u001b[0m     @     0x7f626e7a5ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39602)\u001b[0m     @     0x7f626e7a5d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39602)\u001b[0m     @     0x7f626f088b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39579)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39579)\u001b[0m *** SIGSEGV (@0x0) received by PID 39579 (TID 0x7f8488118700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39579)\u001b[0m     @     0x7f8487cf1390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39579)\u001b[0m     @     0x7f5587bc7f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39579)\u001b[0m     @     0x7f55872f27db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39579)\u001b[0m     @     0x7f55872f58f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39714)\u001b[0m     @     0x7f677cbd1f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39714)\u001b[0m     @     0x7f677c2fc7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39714)\u001b[0m     @     0x7f677c2ff8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39714)\u001b[0m     @     0x7f677c2ffad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39606)\u001b[0m     @     0x7f29c4c74f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39606)\u001b[0m     @     0x7f29c439f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39606)\u001b[0m     @     0x7f29c43a28f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39606)\u001b[0m     @     0x7f29c43a2ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39599)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39599)\u001b[0m *** SIGSEGV (@0x0) received by PID 39599 (TID 0x7fde6c781700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39599)\u001b[0m     @     0x7fde6c35a390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39599)\u001b[0m     @     0x7faf6c290f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39599)\u001b[0m     @     0x7faf6b9bb7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39599)\u001b[0m     @     0x7faf6b9be8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39583)\u001b[0m     @     0x7fb6018f9f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39583)\u001b[0m     @     0x7fb6010247db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39583)\u001b[0m     @     0x7fb6010278f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39583)\u001b[0m     @     0x7fb601027ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39594)\u001b[0m     @     0x7fc3d8e1f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39594)\u001b[0m     @     0x7fc3d8e228f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39594)\u001b[0m     @     0x7fc3d8e22ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39598)\u001b[0m     @     0x7f73249e8f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39598)\u001b[0m     @     0x7f73241137db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39598)\u001b[0m     @     0x7f73241168f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39598)\u001b[0m     @     0x7f7324116ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39592)\u001b[0m     @     0x7f030361ff90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39592)\u001b[0m     @     0x7f0302d4a7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39592)\u001b[0m     @     0x7f0302d4d8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39592)\u001b[0m     @     0x7f0302d4dad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39647)\u001b[0m     @     0x7f9e59e357db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39647)\u001b[0m     @     0x7f9e59e388f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39647)\u001b[0m     @     0x7f9e59e38ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39581)\u001b[0m     @     0x7f5cf0abfad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39581)\u001b[0m     @     0x7f5cf0abfd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39581)\u001b[0m     @     0x7f5cf13a2b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39581)\u001b[0m     @     0x7f5cf13c5c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39581)\u001b[0m     @     0x7f5cf0867a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39581)\u001b[0m     @     0x7f5cf0865388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39707)\u001b[0m     @     0x7f8bc40a75a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39707)\u001b[0m     @     0x7f8bc47924f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39707)\u001b[0m     @     0x7f8bc6c658de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39707)\u001b[0m     @     0x7f8bc47924f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39707)\u001b[0m     @     0x7f8bca83d79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39707)\u001b[0m     @     0x56516020bfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39707)\u001b[0m     @     0x565160166b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39707)\u001b[0m     @     0x5651601f1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39707)\u001b[0m     @     0x5651601f2a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39707)\u001b[0m     @     0x565160166bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39707)\u001b[0m     @     0x5651601f1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39707)\u001b[0m     @     0x5651601f2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39707)\u001b[0m     @     0x565160167689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39707)\u001b[0m     @     0x5651601f1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39707)\u001b[0m     @     0x5651601f2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39707)\u001b[0m     @     0x565160167689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39707)\u001b[0m     @     0x5651601f1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39707)\u001b[0m     @     0x5651601f2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39707)\u001b[0m     @     0x565160167689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39707)\u001b[0m     @     0x5651601f1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39601)\u001b[0m     @     0x7fb034f278f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39601)\u001b[0m     @     0x7fb034f27ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39601)\u001b[0m     @     0x7fb034f27d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39601)\u001b[0m     @     0x7fb03580ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39601)\u001b[0m     @     0x7fb03582dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39710)\u001b[0m     @     0x7f3b57c8e4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39710)\u001b[0m     @     0x7f3b5a1618de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39710)\u001b[0m     @     0x7f3b57c8e4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39710)\u001b[0m     @     0x7f3b5dd3979f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39710)\u001b[0m     @     0x55ac66925fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39710)\u001b[0m     @     0x55ac66880b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39710)\u001b[0m     @     0x55ac6690bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39710)\u001b[0m     @     0x55ac6690ca20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39710)\u001b[0m     @     0x55ac66880bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39710)\u001b[0m     @     0x55ac6690bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39710)\u001b[0m     @     0x55ac6690c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39710)\u001b[0m     @     0x55ac66881689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39710)\u001b[0m     @     0x55ac6690bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39710)\u001b[0m     @     0x55ac6690c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39710)\u001b[0m     @     0x55ac66881689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39710)\u001b[0m     @     0x55ac6690bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39710)\u001b[0m     @     0x55ac6690c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39710)\u001b[0m     @     0x55ac66881689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39710)\u001b[0m     @     0x55ac6690bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39710)\u001b[0m     @     0x55ac6690c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39710)\u001b[0m     @     0x55ac66881689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39685)\u001b[0m     @     0x7f0eeb6b64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39685)\u001b[0m     @     0x7f0eedb898de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39685)\u001b[0m     @     0x7f0eeb6b64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39685)\u001b[0m     @     0x7f0ef176179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39685)\u001b[0m     @     0x55f296271fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39685)\u001b[0m     @     0x55f2961ccb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39685)\u001b[0m     @     0x55f296257baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39685)\u001b[0m     @     0x55f296258a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39685)\u001b[0m     @     0x55f2961ccbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39685)\u001b[0m     @     0x55f296257baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39685)\u001b[0m     @     0x55f296258643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39685)\u001b[0m     @     0x55f2961cd689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39685)\u001b[0m     @     0x55f296257baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39685)\u001b[0m     @     0x55f296258643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39685)\u001b[0m     @     0x55f2961cd689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39685)\u001b[0m     @     0x55f296257baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39685)\u001b[0m     @     0x55f296258643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39685)\u001b[0m     @     0x55f2961cd689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39685)\u001b[0m     @     0x55f296257baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39685)\u001b[0m     @     0x55f296258643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39685)\u001b[0m     @     0x55f2961cd689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39604)\u001b[0m     @     0x7f4144a8bf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39604)\u001b[0m     @     0x7f41441b67db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39604)\u001b[0m     @     0x7f41441b98f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39604)\u001b[0m     @     0x7f41441b9ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39604)\u001b[0m     @     0x7f41441b9d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39604)\u001b[0m     @     0x7f4144a9cb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39604)\u001b[0m     @     0x7f4144abfc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39656)\u001b[0m     @     0x7f32fafd3390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39656)\u001b[0m     @     0x7f03faf13f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39656)\u001b[0m     @     0x7f03fa63e7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39656)\u001b[0m     @     0x7f03fa6418f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39656)\u001b[0m     @     0x7f03fa641ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39656)\u001b[0m     @     0x7f03fa641d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39656)\u001b[0m     @     0x7f03faf24b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39643)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39643)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39643)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39643)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39643)\u001b[0m *** SIGSEGV (@0x0) received by PID 39643 (TID 0x7f13de920700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39643)\u001b[0m     @     0x7f13de4f9390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39643)\u001b[0m     @     0x7ee4de467f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39643)\u001b[0m     @     0x7ee4ddb927db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39648)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39648)\u001b[0m *** SIGSEGV (@0x0) received by PID 39648 (TID 0x7fe928ade700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39648)\u001b[0m     @     0x7fe9286b7390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39648)\u001b[0m     @     0x7fba2860ef90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39648)\u001b[0m     @     0x7fba27d397db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39648)\u001b[0m     @     0x7fba27d3c8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39648)\u001b[0m     @     0x7fba27d3cad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39587)\u001b[0m     @     0x7f3b1270af90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39587)\u001b[0m     @     0x7f3b11e357db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39587)\u001b[0m     @     0x7f3b11e388f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39587)\u001b[0m     @     0x7f3b11e38ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39587)\u001b[0m     @     0x7f3b11e38d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39587)\u001b[0m     @     0x7f3b1271bb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39587)\u001b[0m     @     0x7f3b1273ec1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39686)\u001b[0m     @     0x7f375e0ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39686)\u001b[0m     @     0x7f376058d8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39686)\u001b[0m     @     0x7f375e0ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39686)\u001b[0m     @     0x7f376416579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39686)\u001b[0m     @     0x55c1a78defd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39686)\u001b[0m     @     0x55c1a7839b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39686)\u001b[0m     @     0x55c1a78c4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39686)\u001b[0m     @     0x55c1a78c5a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39686)\u001b[0m     @     0x55c1a7839bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39686)\u001b[0m     @     0x55c1a78c4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39686)\u001b[0m     @     0x55c1a78c5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39686)\u001b[0m     @     0x55c1a783a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39686)\u001b[0m     @     0x55c1a78c4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39686)\u001b[0m     @     0x55c1a78c5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39686)\u001b[0m     @     0x55c1a783a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39686)\u001b[0m     @     0x55c1a78c4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39686)\u001b[0m     @     0x55c1a78c5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39686)\u001b[0m     @     0x55c1a783a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39686)\u001b[0m     @     0x55c1a78c4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39686)\u001b[0m     @     0x55c1a78c5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39686)\u001b[0m     @     0x55c1a783a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39677)\u001b[0m     @     0x7ee3766ff5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39677)\u001b[0m     @     0x7ee376dea4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39677)\u001b[0m     @     0x7ee3792bd8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39677)\u001b[0m     @     0x7ee376dea4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39677)\u001b[0m     @     0x7ee37ce9579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39677)\u001b[0m     @     0x55653c02ffd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39677)\u001b[0m     @     0x55653bf8ab08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39677)\u001b[0m     @     0x55653c015baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39677)\u001b[0m     @     0x55653c016a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39677)\u001b[0m     @     0x55653bf8abfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39677)\u001b[0m     @     0x55653c015baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39677)\u001b[0m     @     0x55653c016643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39677)\u001b[0m     @     0x55653bf8b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39677)\u001b[0m     @     0x55653c015baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39677)\u001b[0m     @     0x55653c016643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39677)\u001b[0m     @     0x55653bf8b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39677)\u001b[0m     @     0x55653c015baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39677)\u001b[0m     @     0x55653c016643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39677)\u001b[0m     @     0x55653bf8b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39677)\u001b[0m     @     0x55653c015baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39677)\u001b[0m     @     0x55653c016643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39677)\u001b[0m     @     0x55653bf8b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39614)\u001b[0m     @     0x7ef98f2238f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39614)\u001b[0m     @     0x7ef98f223ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39614)\u001b[0m     @     0x7ef98f223d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39614)\u001b[0m     @     0x7ef98fb06b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39614)\u001b[0m     @     0x7ef98fb29c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39597)\u001b[0m     @     0x7ef2198688f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39597)\u001b[0m     @     0x7ef219868ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39597)\u001b[0m     @     0x7ef219868d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39597)\u001b[0m     @     0x7ef21a14bb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39597)\u001b[0m     @     0x7ef21a16ec1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39597)\u001b[0m     @     0x7ef219610a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39597)\u001b[0m     @     0x7ef21960e388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39682)\u001b[0m     @     0x7f72387b18f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39682)\u001b[0m     @     0x7f72387b1ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39682)\u001b[0m     @     0x7f72387b1d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39682)\u001b[0m     @     0x7f7239094b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39682)\u001b[0m     @     0x7f72390b7c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39580)\u001b[0m     @     0x7f43b3c358f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39580)\u001b[0m     @     0x7f43b3c35ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39580)\u001b[0m     @     0x7f43b3c35d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39580)\u001b[0m     @     0x7f43b4518b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39580)\u001b[0m     @     0x7f43b453bc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39580)\u001b[0m     @     0x7f43b39dda93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39580)\u001b[0m     @     0x7f43b39db388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39681)\u001b[0m     @     0x7f9764c494f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39681)\u001b[0m     @     0x7f976711c8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39681)\u001b[0m     @     0x7f9764c494f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39681)\u001b[0m     @     0x7f976acf479f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39681)\u001b[0m     @     0x55a84f83afd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39681)\u001b[0m     @     0x55a84f795b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39681)\u001b[0m     @     0x55a84f820baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39681)\u001b[0m     @     0x55a84f821a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39681)\u001b[0m     @     0x55a84f795bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39681)\u001b[0m     @     0x55a84f820baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39681)\u001b[0m     @     0x55a84f821643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39681)\u001b[0m     @     0x55a84f796689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39681)\u001b[0m     @     0x55a84f820baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39681)\u001b[0m     @     0x55a84f821643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39681)\u001b[0m     @     0x55a84f796689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39681)\u001b[0m     @     0x55a84f820baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39681)\u001b[0m     @     0x55a84f821643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39681)\u001b[0m     @     0x55a84f796689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39681)\u001b[0m     @     0x55a84f820baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39681)\u001b[0m     @     0x55a84f821643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39681)\u001b[0m     @     0x55a84f796689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39649)\u001b[0m     @     0x7f9f3eb62390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39649)\u001b[0m     @     0x7f703ea21f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39649)\u001b[0m     @     0x7f703e14c7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39649)\u001b[0m     @     0x7f703e14f8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39649)\u001b[0m     @     0x7f703e14fad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39649)\u001b[0m     @     0x7f703e14fd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39657)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39657)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39657)\u001b[0m *** SIGSEGV (@0x0) received by PID 39657 (TID 0x7fc0f2feb700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39657)\u001b[0m     @     0x7fc0f2bc4390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39657)\u001b[0m     @     0x7f91f2ad1f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39657)\u001b[0m     @     0x7f91f21fc7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39657)\u001b[0m     @     0x7f91f21ff8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39644)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39644)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39644)\u001b[0m *** Aborted at 1604572979 (unix time) try \"date -d @1604572979\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39644)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39644)\u001b[0m *** SIGSEGV (@0x0) received by PID 39644 (TID 0x7f19f9966700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39644)\u001b[0m     @     0x7f19f953f390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39644)\u001b[0m     @     0x7eeaf94e3f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39644)\u001b[0m     @     0x7eeaf8c0e7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39674)\u001b[0m     @     0x7f87460fa8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39674)\u001b[0m     @     0x7f87460faad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39674)\u001b[0m     @     0x7f87460fad91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39674)\u001b[0m     @     0x7f87469ddb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39674)\u001b[0m     @     0x7f8746a00c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39674)\u001b[0m     @     0x7f8745ea2a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39674)\u001b[0m     @     0x7f8745ea0388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39586)\u001b[0m     @     0x7f4cf5c0df90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39586)\u001b[0m     @     0x7f4cf53387db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39586)\u001b[0m     @     0x7f4cf533b8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39586)\u001b[0m     @     0x7f4cf533bad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39586)\u001b[0m     @     0x7f4cf533bd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39586)\u001b[0m     @     0x7f4cf5c1eb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39586)\u001b[0m     @     0x7f4cf5c41c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39692)\u001b[0m     @     0x7f33565818f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39692)\u001b[0m     @     0x7f3356581ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39692)\u001b[0m     @     0x7f3356581d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39692)\u001b[0m     @     0x7f3356e64b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39660)\u001b[0m     @     0x7f842416a390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39660)\u001b[0m     @     0x7f5523eb6f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39660)\u001b[0m     @     0x7f55235e17db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39612)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39612)\u001b[0m *** SIGSEGV (@0x0) received by PID 39612 (TID 0x7fe82cf20700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39612)\u001b[0m     @     0x7fe82caf9390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39612)\u001b[0m     @     0x7fb92ca36f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39585)\u001b[0m     @     0x7f9603d3c8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39585)\u001b[0m     @     0x7f9603d3cad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39585)\u001b[0m     @     0x7f9603d3cd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39585)\u001b[0m     @     0x7f960461fb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39646)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39646)\u001b[0m *** SIGSEGV (@0x0) received by PID 39646 (TID 0x7f7febe10700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39646)\u001b[0m     @     0x7f7feb9e9390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39646)\u001b[0m     @     0x7f50eb8def90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39646)\u001b[0m     @     0x7f50eb0097db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39646)\u001b[0m     @     0x7f50eb00c8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39662)\u001b[0m     @     0x7f9374a8d8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39662)\u001b[0m     @     0x7f9374a8dad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39662)\u001b[0m     @     0x7f9374a8dd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39662)\u001b[0m     @     0x7f9375370b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39662)\u001b[0m     @     0x7f9375393c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39697)\u001b[0m     @     0x7f28eb70b390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39697)\u001b[0m     @     0x7ef9eb6aef90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39697)\u001b[0m     @     0x7ef9eadd97db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39697)\u001b[0m     @     0x7ef9eaddc8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39697)\u001b[0m     @     0x7ef9eaddcad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39582)\u001b[0m     @     0x7f6444ba4ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39582)\u001b[0m     @     0x7f6444ba4d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39582)\u001b[0m     @     0x7f6445487b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39582)\u001b[0m     @     0x7f64454aac1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39584)\u001b[0m     @     0x7f6baf4678f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39584)\u001b[0m     @     0x7f6baf467ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39584)\u001b[0m     @     0x7f6baf467d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39584)\u001b[0m     @     0x7f6bafd4ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39584)\u001b[0m     @     0x7f6bafd6dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39704)\u001b[0m     @     0x7f4be3bffad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39704)\u001b[0m     @     0x7f4be3bffd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39704)\u001b[0m     @     0x7f4be44e2b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39704)\u001b[0m     @     0x7f4be4505c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39704)\u001b[0m     @     0x7f4be39a7a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39704)\u001b[0m     @     0x7f4be39a5388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39645)\u001b[0m     @     0x7f1f4bd3c8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39645)\u001b[0m     @     0x7f1f4bd3cad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39645)\u001b[0m     @     0x7f1f4bd3cd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39645)\u001b[0m     @     0x7f1f4c61fb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39645)\u001b[0m     @     0x7f1f4c642c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39654)\u001b[0m     @     0x7ee49c7e3d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39654)\u001b[0m     @     0x7ee49d0c6b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39654)\u001b[0m     @     0x7ee49d0e9c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39654)\u001b[0m     @     0x7ee49c58ba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39654)\u001b[0m     @     0x7ee49c589388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39654)\u001b[0m     @     0x7ee49c58b5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39654)\u001b[0m     @     0x7ee49cc764f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39691)\u001b[0m     @     0x7ef760d10d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39691)\u001b[0m     @     0x7ef7615f3b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39691)\u001b[0m     @     0x7ef761616c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39691)\u001b[0m     @     0x7ef760ab8a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39691)\u001b[0m     @     0x7ef760ab6388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39691)\u001b[0m     @     0x7ef760ab85a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39703)\u001b[0m     @     0x7f467f0ab4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39703)\u001b[0m     @     0x7f468157e8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39703)\u001b[0m     @     0x7f467f0ab4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39703)\u001b[0m     @     0x7f468515679f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39703)\u001b[0m     @     0x55cf22e13fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39703)\u001b[0m     @     0x55cf22d6eb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39703)\u001b[0m     @     0x55cf22df9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39703)\u001b[0m     @     0x55cf22dfaa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39703)\u001b[0m     @     0x55cf22d6ebfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39703)\u001b[0m     @     0x55cf22df9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39703)\u001b[0m     @     0x55cf22dfa643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39703)\u001b[0m     @     0x55cf22d6f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39703)\u001b[0m     @     0x55cf22df9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39703)\u001b[0m     @     0x55cf22dfa643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39703)\u001b[0m     @     0x55cf22d6f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39703)\u001b[0m     @     0x55cf22df9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39703)\u001b[0m     @     0x55cf22dfa643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39703)\u001b[0m     @     0x55cf22d6f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39703)\u001b[0m     @     0x55cf22df9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39703)\u001b[0m     @     0x55cf22dfa643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39703)\u001b[0m     @     0x55cf22d6f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39659)\u001b[0m     @     0x7fb0899e54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39659)\u001b[0m     @     0x7fb08fa9079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39659)\u001b[0m     @     0x55e9b9eeefd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39659)\u001b[0m     @     0x55e9b9e49b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39659)\u001b[0m     @     0x55e9b9ed4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39659)\u001b[0m     @     0x55e9b9ed5a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39659)\u001b[0m     @     0x55e9b9e49bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39659)\u001b[0m     @     0x55e9b9ed4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39659)\u001b[0m     @     0x55e9b9ed5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39659)\u001b[0m     @     0x55e9b9e4a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39659)\u001b[0m     @     0x55e9b9ed4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39659)\u001b[0m     @     0x55e9b9ed5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39659)\u001b[0m     @     0x55e9b9e4a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39659)\u001b[0m     @     0x55e9b9ed4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39659)\u001b[0m     @     0x55e9b9ed5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39659)\u001b[0m     @     0x55e9b9e4a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39659)\u001b[0m     @     0x55e9b9ed4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39659)\u001b[0m     @     0x55e9b9ed5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39659)\u001b[0m     @     0x55e9b9e4a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39610)\u001b[0m     @     0x7f2e387e3ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39610)\u001b[0m     @     0x7f2e387e3d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39610)\u001b[0m     @     0x7f2e390c6b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39610)\u001b[0m     @     0x7f2e390e9c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39610)\u001b[0m     @     0x7f2e3858ba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39610)\u001b[0m     @     0x7f2e38589388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39610)\u001b[0m     @     0x7f2e3858b5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39652)\u001b[0m     @     0x7f582ad4dad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39652)\u001b[0m     @     0x7f582ad4dd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39652)\u001b[0m     @     0x7f582b630b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39652)\u001b[0m     @     0x7f582b653c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39652)\u001b[0m     @     0x7f582aaf5a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39652)\u001b[0m     @     0x7f582aaf3388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39652)\u001b[0m     @     0x7f582aaf55a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39699)\u001b[0m     @     0x7f2eea3438f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39699)\u001b[0m     @     0x7f2eea343ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39699)\u001b[0m     @     0x7f2eea343d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39699)\u001b[0m     @     0x7f2eeac26b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39699)\u001b[0m     @     0x7f2eeac49c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39699)\u001b[0m     @     0x7f2eea0eba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39699)\u001b[0m     @     0x7f2eea0e9388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39650)\u001b[0m     @     0x7f6fc5a60390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39650)\u001b[0m     @     0x7f40c57f9f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39650)\u001b[0m     @     0x7f40c4f247db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39650)\u001b[0m     @     0x7f40c4f278f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39600)\u001b[0m     @     0x7f5b33f3b390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39600)\u001b[0m     @     0x7f2c33e0bf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39600)\u001b[0m     @     0x7f2c335367db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39600)\u001b[0m     @     0x7f2c335398f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39600)\u001b[0m     @     0x7f2c33539ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39600)\u001b[0m     @     0x7f2c33539d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39600)\u001b[0m     @     0x7f2c33e1cb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39653)\u001b[0m     @     0x7f52542b3ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39653)\u001b[0m     @     0x7f52542b3d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39653)\u001b[0m     @     0x7f5254b96b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39653)\u001b[0m     @     0x7f5254bb9c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39653)\u001b[0m     @     0x7f525405ba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39653)\u001b[0m     @     0x7f5254059388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39663)\u001b[0m     @     0x7f2370ea4f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39663)\u001b[0m     @     0x7f23705cf7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39663)\u001b[0m     @     0x7f23705d28f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39663)\u001b[0m     @     0x7f23705d2ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39663)\u001b[0m     @     0x7f23705d2d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39663)\u001b[0m     @     0x7f2370eb5b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39663)\u001b[0m     @     0x7f2370ed8c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39596)\u001b[0m     @     0x7fa2463bd8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39596)\u001b[0m     @     0x7fa2463bdad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39596)\u001b[0m     @     0x7fa2463bdd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39596)\u001b[0m     @     0x7fa246ca0b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39596)\u001b[0m     @     0x7fa246cc3c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39613)\u001b[0m     @     0x7f7aa22f2390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39613)\u001b[0m     @     0x7f4ba2279f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39613)\u001b[0m     @     0x7f4ba19a47db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39613)\u001b[0m     @     0x7f4ba19a78f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39661)\u001b[0m     @     0x7fb8a941dad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39661)\u001b[0m     @     0x7fb8a941dd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39661)\u001b[0m     @     0x7fb8a9d00b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39661)\u001b[0m     @     0x7fb8a9d23c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39661)\u001b[0m     @     0x7fb8a91c5a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39661)\u001b[0m     @     0x7fb8a91c3388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39590)\u001b[0m     @     0x7f87ba14fad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39590)\u001b[0m     @     0x7f87ba14fd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39590)\u001b[0m     @     0x7f87baa32b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39590)\u001b[0m     @     0x7f87baa55c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39590)\u001b[0m     @     0x7f87b9ef7a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39590)\u001b[0m     @     0x7f87b9ef5388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39615)\u001b[0m     @     0x7fbdbfe4dad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39615)\u001b[0m     @     0x7fbdbfe4dd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39615)\u001b[0m     @     0x7fbdc0730b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39615)\u001b[0m     @     0x7fbdc0753c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39615)\u001b[0m     @     0x7fbdbfbf5a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39615)\u001b[0m     @     0x7fbdbfbf3388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39694)\u001b[0m     @     0x7f89ec7b68f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39694)\u001b[0m     @     0x7f89ec7b6ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39669)\u001b[0m     @     0x7ed0f00add91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39669)\u001b[0m     @     0x7ed0f0990b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39669)\u001b[0m     @     0x7ed0f09b3c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39669)\u001b[0m     @     0x7ed0efe55a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39669)\u001b[0m     @     0x7ed0efe53388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39669)\u001b[0m     @     0x7ed0efe555a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39589)\u001b[0m     @     0x7fcacb51ead3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39589)\u001b[0m     @     0x7fcacb51ed91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39589)\u001b[0m     @     0x7fcacbe01b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39589)\u001b[0m     @     0x7fcacbe24c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39589)\u001b[0m     @     0x7fcacb2c6a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39589)\u001b[0m     @     0x7fcacb2c4388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39589)\u001b[0m     @     0x7fcacb2c65a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39665)\u001b[0m     @     0x7f568ead44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39665)\u001b[0m     @     0x7f5694b7f79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39665)\u001b[0m     @     0x5596c59cefd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39665)\u001b[0m     @     0x5596c5929b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39665)\u001b[0m     @     0x5596c59b4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39665)\u001b[0m     @     0x5596c59b5a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39665)\u001b[0m     @     0x5596c5929bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39665)\u001b[0m     @     0x5596c59b4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39665)\u001b[0m     @     0x5596c59b5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39665)\u001b[0m     @     0x5596c592a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39665)\u001b[0m     @     0x5596c59b4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39665)\u001b[0m     @     0x5596c59b5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39665)\u001b[0m     @     0x5596c592a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39665)\u001b[0m     @     0x5596c59b4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39665)\u001b[0m     @     0x5596c59b5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39665)\u001b[0m     @     0x5596c592a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39665)\u001b[0m     @     0x5596c59b4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39665)\u001b[0m     @     0x5596c59b5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39665)\u001b[0m     @     0x5596c592a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39680)\u001b[0m     @     0x563724cbc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39680)\u001b[0m     @     0x563724d46baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39680)\u001b[0m     @     0x563724d47643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39680)\u001b[0m     @     0x563724cbc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39696)\u001b[0m     @     0x561dce2f1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39696)\u001b[0m     @     0x561dce2f2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39696)\u001b[0m     @     0x561dce267689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39696)\u001b[0m     @     0x561dce2f1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39696)\u001b[0m     @     0x561dce2f2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39696)\u001b[0m     @     0x561dce267689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39591)\u001b[0m     @     0x7f9ccaa55c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39591)\u001b[0m     @     0x7f9cc9ef7a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39591)\u001b[0m     @     0x7f9cc9ef5388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39591)\u001b[0m     @     0x7f9cc9ef75a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39591)\u001b[0m     @     0x7f9cca5e24f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39591)\u001b[0m     @     0x7f9cccab58de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39651)\u001b[0m     @     0x7ed2ecc764f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39651)\u001b[0m     @     0x7ed2ef1498de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39651)\u001b[0m     @     0x7ed2ecc764f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39651)\u001b[0m     @     0x7ed2f2d2179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39651)\u001b[0m     @     0x5611abe8afd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39651)\u001b[0m     @     0x5611abde5b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39651)\u001b[0m     @     0x5611abe70baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39651)\u001b[0m     @     0x5611abe71a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39651)\u001b[0m     @     0x5611abde5bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39651)\u001b[0m     @     0x5611abe70baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39651)\u001b[0m     @     0x5611abe71643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39651)\u001b[0m     @     0x5611abde6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39651)\u001b[0m     @     0x5611abe70baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39651)\u001b[0m     @     0x5611abe71643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39651)\u001b[0m     @     0x5611abde6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39651)\u001b[0m     @     0x5611abe70baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39651)\u001b[0m     @     0x5611abe71643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39651)\u001b[0m     @     0x5611abde6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39651)\u001b[0m     @     0x5611abe70baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39651)\u001b[0m     @     0x5611abe71643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39651)\u001b[0m     @     0x5611abde6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39693)\u001b[0m     @     0x564e3c33b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39693)\u001b[0m     @     0x564e3c3c5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39693)\u001b[0m     @     0x564e3c3c6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39693)\u001b[0m     @     0x564e3c33b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39693)\u001b[0m     @     0x564e3c3c5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39693)\u001b[0m     @     0x564e3c3c6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39693)\u001b[0m     @     0x564e3c33b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39693)\u001b[0m     @     0x564e3c3c5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39693)\u001b[0m     @     0x564e3c3c6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39693)\u001b[0m     @     0x564e3c33b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39664)\u001b[0m     @     0x7f0bbb8d2c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39664)\u001b[0m     @     0x7f0bbad74a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39664)\u001b[0m     @     0x7f0bbad72388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39664)\u001b[0m     @     0x7f0bbad745a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39664)\u001b[0m     @     0x7f0bbb45f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39664)\u001b[0m     @     0x7f0bbd9328de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39672)\u001b[0m     @     0x7f45938efb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39672)\u001b[0m     @     0x7f4593912c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39672)\u001b[0m     @     0x7f4592db4a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39672)\u001b[0m     @     0x7f4592db2388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39672)\u001b[0m     @     0x7f4592db45a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39672)\u001b[0m     @     0x7f459349f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39666)\u001b[0m     @     0x7f3b2e73ec1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39666)\u001b[0m     @     0x7f3b2dbe0a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39666)\u001b[0m     @     0x7f3b2dbde388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39666)\u001b[0m     @     0x7f3b2dbe05a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39666)\u001b[0m     @     0x7f3b2e2cb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39666)\u001b[0m     @     0x7f3b3079e8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39593)\u001b[0m     @     0x7ef4a1ee9d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39593)\u001b[0m     @     0x7ef4a27ccb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39593)\u001b[0m     @     0x7ef4a27efc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39593)\u001b[0m     @     0x7ef4a1c91a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39593)\u001b[0m     @     0x7ef4a1c8f388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39593)\u001b[0m     @     0x7ef4a1c915a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39670)\u001b[0m     @     0x7f0780afad91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39670)\u001b[0m     @     0x7f07813ddb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39670)\u001b[0m     @     0x7f0781400c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39670)\u001b[0m     @     0x7f07808a2a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39670)\u001b[0m     @     0x7f07808a0388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39670)\u001b[0m     @     0x7f07808a25a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39670)\u001b[0m     @     0x7f0780f8d4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39688)\u001b[0m     @     0x7f9a6e50ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39688)\u001b[0m     @     0x7f9a6e52dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39688)\u001b[0m     @     0x7f9a6d9cfa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39688)\u001b[0m     @     0x7f9a6d9cd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39688)\u001b[0m     @     0x7f9a6d9cf5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39688)\u001b[0m     @     0x7f9a6e0ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39688)\u001b[0m     @     0x7f9a7058d8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39611)\u001b[0m     @     0x7f8c97a39a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39611)\u001b[0m     @     0x7f8c97a37388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39611)\u001b[0m     @     0x7f8c97a395a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39611)\u001b[0m     @     0x7f8c981244f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39611)\u001b[0m     @     0x7f8c9a5f78de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39611)\u001b[0m     @     0x7f8c981244f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39602)\u001b[0m     @     0x7f626f0abc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39602)\u001b[0m     @     0x7f626e54da93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39602)\u001b[0m     @     0x7f626e54b388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39602)\u001b[0m     @     0x7f626e54d5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39602)\u001b[0m     @     0x7f626ec384f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39602)\u001b[0m     @     0x7f627110b8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39579)\u001b[0m     @     0x7f55872f5ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39579)\u001b[0m     @     0x7f55872f5d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39579)\u001b[0m     @     0x7f5587bd8b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39579)\u001b[0m     @     0x7f5587bfbc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39579)\u001b[0m     @     0x7f558709da93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39579)\u001b[0m     @     0x7f558709b388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39714)\u001b[0m     @     0x7f677c2ffd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39714)\u001b[0m     @     0x7f677cbe2b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39714)\u001b[0m     @     0x7f677cc05c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39714)\u001b[0m     @     0x7f677c0a7a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39714)\u001b[0m     @     0x7f677c0a5388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39714)\u001b[0m     @     0x7f677c0a75a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39714)\u001b[0m     @     0x7f677c7924f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39606)\u001b[0m     @     0x7f29c43a2d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39606)\u001b[0m     @     0x7f29c4c85b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39606)\u001b[0m     @     0x7f29c4ca8c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39606)\u001b[0m     @     0x7f29c414aa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39606)\u001b[0m     @     0x7f29c4148388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39606)\u001b[0m     @     0x7f29c414a5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39599)\u001b[0m     @     0x7faf6b9bead3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39599)\u001b[0m     @     0x7faf6b9bed91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39599)\u001b[0m     @     0x7faf6c2a1b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39599)\u001b[0m     @     0x7faf6c2c4c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39599)\u001b[0m     @     0x7faf6b766a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39599)\u001b[0m     @     0x7faf6b764388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39599)\u001b[0m     @     0x7faf6b7665a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39583)\u001b[0m     @     0x7fb601027d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39583)\u001b[0m     @     0x7fb60190ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39583)\u001b[0m     @     0x7fb60192dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39583)\u001b[0m     @     0x7fb600dcfa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39583)\u001b[0m     @     0x7fb600dcd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39583)\u001b[0m     @     0x7fb600dcf5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39583)\u001b[0m     @     0x7fb6014ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39594)\u001b[0m     @     0x7fc3d8e22d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39594)\u001b[0m     @     0x7fc3d9705b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39594)\u001b[0m     @     0x7fc3d9728c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39594)\u001b[0m     @     0x7fc3d8bcaa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39594)\u001b[0m     @     0x7fc3d8bc8388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39594)\u001b[0m     @     0x7fc3d8bca5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39598)\u001b[0m     @     0x7f7324116d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39598)\u001b[0m     @     0x7f73249f9b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39598)\u001b[0m     @     0x7f7324a1cc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39598)\u001b[0m     @     0x7f7323ebea93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39598)\u001b[0m     @     0x7f7323ebc388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39598)\u001b[0m     @     0x7f7323ebe5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39592)\u001b[0m     @     0x7f0302d4dd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39592)\u001b[0m     @     0x7f0303630b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39592)\u001b[0m     @     0x7f0303653c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39592)\u001b[0m     @     0x7f0302af5a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39592)\u001b[0m     @     0x7f0302af3388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39592)\u001b[0m     @     0x7f0302af55a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39647)\u001b[0m     @     0x7f9e59e38d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39647)\u001b[0m     @     0x7f9e5a71bb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39647)\u001b[0m     @     0x7f9e5a73ec1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39647)\u001b[0m     @     0x7f9e59be0a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39647)\u001b[0m     @     0x7f9e59bde388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39647)\u001b[0m     @     0x7f9e59be05a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39647)\u001b[0m     @     0x7f9e5a2cb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39581)\u001b[0m     @     0x7f5cf08675a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39581)\u001b[0m     @     0x7f5cf0f524f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39581)\u001b[0m     @     0x7f5cf34258de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39581)\u001b[0m     @     0x7f5cf0f524f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39707)\u001b[0m     @     0x5651601f2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39707)\u001b[0m     @     0x565160167689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39601)\u001b[0m     @     0x7fb034ccfa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39601)\u001b[0m     @     0x7fb034ccd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39601)\u001b[0m     @     0x7fb034ccf5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39601)\u001b[0m     @     0x7fb0353ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39604)\u001b[0m     @     0x7f4143f61a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39604)\u001b[0m     @     0x7f4143f5f388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39604)\u001b[0m     @     0x7f4143f615a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39656)\u001b[0m     @     0x7f03faf47c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39656)\u001b[0m     @     0x7f03fa3e9a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39656)\u001b[0m     @     0x7f03fa3e7388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39643)\u001b[0m     @     0x7ee4ddb958f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39648)\u001b[0m     @     0x7fba27d3cd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39648)\u001b[0m     @     0x7fba2861fb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39648)\u001b[0m     @     0x7fba28642c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39648)\u001b[0m     @     0x7fba27ae4a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39648)\u001b[0m     @     0x7fba27ae2388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39587)\u001b[0m     @     0x7f3b11be0a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39587)\u001b[0m     @     0x7f3b11bde388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39587)\u001b[0m     @     0x7f3b11be05a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39614)\u001b[0m     @     0x7ef98efcba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39614)\u001b[0m     @     0x7ef98efc9388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39614)\u001b[0m     @     0x7ef98efcb5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39597)\u001b[0m     @     0x7ef2196105a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39597)\u001b[0m     @     0x7ef219cfb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39597)\u001b[0m     @     0x7ef21c1ce8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39682)\u001b[0m     @     0x7f7238559a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39682)\u001b[0m     @     0x7f7238557388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39682)\u001b[0m     @     0x7f72385595a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39580)\u001b[0m     @     0x7f43b39dd5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39580)\u001b[0m     @     0x7f43b40c84f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39580)\u001b[0m     @     0x7f43b659b8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39649)\u001b[0m     @     0x7f703ea32b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39649)\u001b[0m     @     0x7f703ea55c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39649)\u001b[0m     @     0x7f703def7a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39649)\u001b[0m     @     0x7f703def5388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39657)\u001b[0m     @     0x7f91f21ffad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39657)\u001b[0m     @     0x7f91f21ffd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39657)\u001b[0m     @     0x7f91f2ae2b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39644)\u001b[0m     @     0x7eeaf8c118f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39674)\u001b[0m     @     0x7f8745ea25a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39674)\u001b[0m     @     0x7f874658d4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39674)\u001b[0m     @     0x7f8748a608de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39586)\u001b[0m     @     0x7f4cf50e3a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39586)\u001b[0m     @     0x7f4cf50e1388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39586)\u001b[0m     @     0x7f4cf50e35a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39586)\u001b[0m     @     0x7f4cf57ce4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39692)\u001b[0m     @     0x7f3356e87c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39692)\u001b[0m     @     0x7f3356329a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39692)\u001b[0m     @     0x7f3356327388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39692)\u001b[0m     @     0x7f33563295a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39660)\u001b[0m     @     0x7f55235e48f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39660)\u001b[0m     @     0x7f55235e4ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39660)\u001b[0m     @     0x7f55235e4d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39660)\u001b[0m     @     0x7f5523ec7b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39660)\u001b[0m     @     0x7f5523eeac1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39612)\u001b[0m     @     0x7fb92c1617db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39612)\u001b[0m     @     0x7fb92c1648f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39612)\u001b[0m     @     0x7fb92c164ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39585)\u001b[0m     @     0x7f9604642c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39585)\u001b[0m     @     0x7f9603ae4a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39585)\u001b[0m     @     0x7f9603ae2388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39585)\u001b[0m     @     0x7f9603ae45a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39646)\u001b[0m     @     0x7f50eb00cad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39646)\u001b[0m     @     0x7f50eb00cd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39646)\u001b[0m     @     0x7f50eb8efb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39646)\u001b[0m     @     0x7f50eb912c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39646)\u001b[0m     @     0x7f50eadb4a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39646)\u001b[0m     @     0x7f50eadb2388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39662)\u001b[0m     @     0x7f9374835a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39662)\u001b[0m     @     0x7f9374833388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39662)\u001b[0m     @     0x7f93748355a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39662)\u001b[0m     @     0x7f9374f204f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39662)\u001b[0m     @     0x7f93773f38de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39697)\u001b[0m     @     0x7ef9eaddcd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39697)\u001b[0m     @     0x7ef9eb6bfb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39697)\u001b[0m     @     0x7ef9eb6e2c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39697)\u001b[0m     @     0x7ef9eab84a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39697)\u001b[0m     @     0x7ef9eab82388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39582)\u001b[0m     @     0x7f644494ca93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39582)\u001b[0m     @     0x7f644494a388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39582)\u001b[0m     @     0x7f644494c5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39582)\u001b[0m     @     0x7f64450374f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39582)\u001b[0m     @     0x7f644750a8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39584)\u001b[0m     @     0x7f6baf20fa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39584)\u001b[0m     @     0x7f6baf20d388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39584)\u001b[0m     @     0x7f6baf20f5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39584)\u001b[0m     @     0x7f6baf8fa4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39584)\u001b[0m     @     0x7f6bb1dcd8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39704)\u001b[0m     @     0x7f4be39a75a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39704)\u001b[0m     @     0x7f4be40924f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39704)\u001b[0m     @     0x7f4be65658de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39645)\u001b[0m     @     0x7f1f4bae4a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39645)\u001b[0m     @     0x7f1f4bae2388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39645)\u001b[0m     @     0x7f1f4bae45a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39645)\u001b[0m     @     0x7f1f4c1cf4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39654)\u001b[0m     @     0x7ee49f1498de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39654)\u001b[0m     @     0x7ee49cc764f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39654)\u001b[0m     @     0x7ee4a2d2179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39654)\u001b[0m     @     0x558e8c401fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39654)\u001b[0m     @     0x558e8c35cb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39654)\u001b[0m     @     0x558e8c3e7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39654)\u001b[0m     @     0x558e8c3e8a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39654)\u001b[0m     @     0x558e8c35cbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39654)\u001b[0m     @     0x558e8c3e7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39654)\u001b[0m     @     0x558e8c3e8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39654)\u001b[0m     @     0x558e8c35d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39654)\u001b[0m     @     0x558e8c3e7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39654)\u001b[0m     @     0x558e8c3e8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39654)\u001b[0m     @     0x558e8c35d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39654)\u001b[0m     @     0x558e8c3e7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39654)\u001b[0m     @     0x558e8c3e8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39654)\u001b[0m     @     0x558e8c35d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39654)\u001b[0m     @     0x558e8c3e7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39654)\u001b[0m     @     0x558e8c3e8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39654)\u001b[0m     @     0x558e8c35d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39691)\u001b[0m     @     0x7ef7611a34f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39691)\u001b[0m     @     0x7ef7636768de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39610)\u001b[0m     @     0x7f2e38c764f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39610)\u001b[0m     @     0x7f2e3b1498de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39652)\u001b[0m     @     0x7f582b1e04f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39652)\u001b[0m     @     0x7f582d6b38de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39652)\u001b[0m     @     0x7f582b1e04f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39652)\u001b[0m     @     0x7f583128b79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39652)\u001b[0m     @     0x55833646dfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39652)\u001b[0m     @     0x5583363c8b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39652)\u001b[0m     @     0x558336453baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39652)\u001b[0m     @     0x558336454a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39652)\u001b[0m     @     0x5583363c8bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39652)\u001b[0m     @     0x558336453baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39652)\u001b[0m     @     0x558336454643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39652)\u001b[0m     @     0x5583363c9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39652)\u001b[0m     @     0x558336453baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39652)\u001b[0m     @     0x558336454643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39652)\u001b[0m     @     0x5583363c9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39652)\u001b[0m     @     0x558336453baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39652)\u001b[0m     @     0x558336454643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39652)\u001b[0m     @     0x5583363c9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39699)\u001b[0m     @     0x7f2eea0eb5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39699)\u001b[0m     @     0x7f2eea7d64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39650)\u001b[0m     @     0x7f40c4f27ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39600)\u001b[0m     @     0x7f2c33e3fc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39600)\u001b[0m     @     0x7f2c332e1a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39600)\u001b[0m     @     0x7f2c332df388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39600)\u001b[0m     @     0x7f2c332e15a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39653)\u001b[0m     @     0x7f525405b5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39653)\u001b[0m     @     0x7f52547464f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39653)\u001b[0m     @     0x7f5256c198de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39663)\u001b[0m     @     0x7f237037aa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39663)\u001b[0m     @     0x7f2370378388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39663)\u001b[0m     @     0x7f237037a5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39596)\u001b[0m     @     0x7fa246165a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39596)\u001b[0m     @     0x7fa246163388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39596)\u001b[0m     @     0x7fa2461655a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39613)\u001b[0m     @     0x7f4ba19a7ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39613)\u001b[0m     @     0x7f4ba19a7d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39661)\u001b[0m     @     0x7fb8a91c55a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39661)\u001b[0m     @     0x7fb8a98b04f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39661)\u001b[0m     @     0x7fb8abd838de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39590)\u001b[0m     @     0x7f87b9ef75a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39590)\u001b[0m     @     0x7f87ba5e24f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39590)\u001b[0m     @     0x7f87bcab58de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39615)\u001b[0m     @     0x7fbdbfbf55a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39615)\u001b[0m     @     0x7fbdc02e04f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39615)\u001b[0m     @     0x7fbdc27b38de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39694)\u001b[0m     @     0x7f89ec7b6d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39694)\u001b[0m     @     0x7f89ed099b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39694)\u001b[0m     @     0x7f89ed0bcc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39669)\u001b[0m     @     0x7ed0f05404f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39669)\u001b[0m     @     0x7ed0f2a138de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39669)\u001b[0m     @     0x7ed0f05404f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39669)\u001b[0m     @     0x7ed0f65eb79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39669)\u001b[0m     @     0x560bbb6a5fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39589)\u001b[0m     @     0x7fcacb9b14f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39589)\u001b[0m     @     0x7fcacde848de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39591)\u001b[0m     @     0x7f9cca5e24f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39591)\u001b[0m     @     0x7f9cd068d79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39591)\u001b[0m     @     0x55583b013fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39591)\u001b[0m     @     0x55583af6eb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39591)\u001b[0m     @     0x55583aff9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39591)\u001b[0m     @     0x55583affaa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39591)\u001b[0m     @     0x55583af6ebfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39591)\u001b[0m     @     0x55583aff9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39591)\u001b[0m     @     0x55583affa643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39591)\u001b[0m     @     0x55583af6f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39591)\u001b[0m     @     0x55583aff9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39591)\u001b[0m     @     0x55583affa643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39591)\u001b[0m     @     0x55583af6f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39591)\u001b[0m     @     0x55583aff9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39591)\u001b[0m     @     0x55583affa643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39591)\u001b[0m     @     0x55583af6f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39591)\u001b[0m     @     0x55583aff9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39591)\u001b[0m     @     0x55583affa643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39591)\u001b[0m     @     0x55583af6f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39664)\u001b[0m     @     0x7f0bbb45f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39664)\u001b[0m     @     0x7f0bc150a79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39664)\u001b[0m     @     0x55a2d40c0fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39664)\u001b[0m     @     0x55a2d401bb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39664)\u001b[0m     @     0x55a2d40a6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39664)\u001b[0m     @     0x55a2d40a7a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39664)\u001b[0m     @     0x55a2d401bbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39664)\u001b[0m     @     0x55a2d40a6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39664)\u001b[0m     @     0x55a2d40a7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39664)\u001b[0m     @     0x55a2d401c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39664)\u001b[0m     @     0x55a2d40a6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39664)\u001b[0m     @     0x55a2d40a7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39664)\u001b[0m     @     0x55a2d401c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39664)\u001b[0m     @     0x55a2d40a6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39664)\u001b[0m     @     0x55a2d40a7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39664)\u001b[0m     @     0x55a2d401c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39664)\u001b[0m     @     0x55a2d40a6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39664)\u001b[0m     @     0x55a2d40a7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39664)\u001b[0m     @     0x55a2d401c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39672)\u001b[0m     @     0x7f45959728de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39672)\u001b[0m     @     0x7f459349f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39672)\u001b[0m     @     0x7f459954a79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39672)\u001b[0m     @     0x562bd4301fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39672)\u001b[0m     @     0x562bd425cb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39672)\u001b[0m     @     0x562bd42e7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39672)\u001b[0m     @     0x562bd42e8a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39672)\u001b[0m     @     0x562bd425cbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39672)\u001b[0m     @     0x562bd42e7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39672)\u001b[0m     @     0x562bd42e8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39672)\u001b[0m     @     0x562bd425d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39672)\u001b[0m     @     0x562bd42e7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39672)\u001b[0m     @     0x562bd42e8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39672)\u001b[0m     @     0x562bd425d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39672)\u001b[0m     @     0x562bd42e7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39672)\u001b[0m     @     0x562bd42e8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39672)\u001b[0m     @     0x562bd425d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39672)\u001b[0m     @     0x562bd42e7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39672)\u001b[0m     @     0x562bd42e8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39672)\u001b[0m     @     0x562bd425d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39666)\u001b[0m     @     0x7f3b2e2cb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39666)\u001b[0m     @     0x7f3b3437679f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39666)\u001b[0m     @     0x55e50f9befd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39666)\u001b[0m     @     0x55e50f919b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39666)\u001b[0m     @     0x55e50f9a4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39666)\u001b[0m     @     0x55e50f9a5a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39666)\u001b[0m     @     0x55e50f919bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39666)\u001b[0m     @     0x55e50f9a4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39666)\u001b[0m     @     0x55e50f9a5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39666)\u001b[0m     @     0x55e50f91a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39666)\u001b[0m     @     0x55e50f9a4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39666)\u001b[0m     @     0x55e50f9a5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39666)\u001b[0m     @     0x55e50f91a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39666)\u001b[0m     @     0x55e50f9a4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39666)\u001b[0m     @     0x55e50f9a5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39666)\u001b[0m     @     0x55e50f91a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39666)\u001b[0m     @     0x55e50f9a4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39666)\u001b[0m     @     0x55e50f9a5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39666)\u001b[0m     @     0x55e50f91a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39593)\u001b[0m     @     0x7ef4a237c4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39593)\u001b[0m     @     0x7ef4a484f8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39593)\u001b[0m     @     0x7ef4a237c4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39593)\u001b[0m     @     0x7ef4a842779f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39593)\u001b[0m     @     0x55b3c1f0cfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39593)\u001b[0m     @     0x55b3c1e67b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39593)\u001b[0m     @     0x55b3c1ef2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39593)\u001b[0m     @     0x55b3c1ef3a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39593)\u001b[0m     @     0x55b3c1e67bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39593)\u001b[0m     @     0x55b3c1ef2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39593)\u001b[0m     @     0x55b3c1ef3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39593)\u001b[0m     @     0x55b3c1e68689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39593)\u001b[0m     @     0x55b3c1ef2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39593)\u001b[0m     @     0x55b3c1ef3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39593)\u001b[0m     @     0x55b3c1e68689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39593)\u001b[0m     @     0x55b3c1ef2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39593)\u001b[0m     @     0x55b3c1ef3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39593)\u001b[0m     @     0x55b3c1e68689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39593)\u001b[0m     @     0x55b3c1ef2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39593)\u001b[0m     @     0x55b3c1ef3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39593)\u001b[0m     @     0x55b3c1e68689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39670)\u001b[0m     @     0x7f07834608de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39670)\u001b[0m     @     0x7f0780f8d4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39670)\u001b[0m     @     0x7f078703879f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39670)\u001b[0m     @     0x5577b97c8fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39670)\u001b[0m     @     0x5577b9723b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39670)\u001b[0m     @     0x5577b97aebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39670)\u001b[0m     @     0x5577b97afa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39670)\u001b[0m     @     0x5577b9723bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39670)\u001b[0m     @     0x5577b97aebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39670)\u001b[0m     @     0x5577b97af643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39670)\u001b[0m     @     0x5577b9724689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39670)\u001b[0m     @     0x5577b97aebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39670)\u001b[0m     @     0x5577b97af643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39670)\u001b[0m     @     0x5577b9724689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39670)\u001b[0m     @     0x5577b97aebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39670)\u001b[0m     @     0x5577b97af643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39670)\u001b[0m     @     0x5577b9724689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39670)\u001b[0m     @     0x5577b97aebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39670)\u001b[0m     @     0x5577b97af643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39670)\u001b[0m     @     0x5577b9724689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39688)\u001b[0m     @     0x7f9a6e0ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39688)\u001b[0m     @     0x7f9a7416579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39688)\u001b[0m     @     0x5609194ccfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39688)\u001b[0m     @     0x560919427b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39688)\u001b[0m     @     0x5609194b2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39688)\u001b[0m     @     0x5609194b3a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39688)\u001b[0m     @     0x560919427bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39688)\u001b[0m     @     0x5609194b2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39688)\u001b[0m     @     0x5609194b3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39688)\u001b[0m     @     0x560919428689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39688)\u001b[0m     @     0x5609194b2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39688)\u001b[0m     @     0x5609194b3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39688)\u001b[0m     @     0x560919428689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39688)\u001b[0m     @     0x5609194b2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39688)\u001b[0m     @     0x5609194b3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39688)\u001b[0m     @     0x560919428689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39688)\u001b[0m     @     0x5609194b2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39688)\u001b[0m     @     0x5609194b3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39688)\u001b[0m     @     0x560919428689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39611)\u001b[0m     @     0x7f8c9e1cf79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39611)\u001b[0m     @     0x55e02f8d0fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39611)\u001b[0m     @     0x55e02f82bb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39611)\u001b[0m     @     0x55e02f8b6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39611)\u001b[0m     @     0x55e02f8b7a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39611)\u001b[0m     @     0x55e02f82bbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39611)\u001b[0m     @     0x55e02f8b6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39611)\u001b[0m     @     0x55e02f8b7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39611)\u001b[0m     @     0x55e02f82c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39611)\u001b[0m     @     0x55e02f8b6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39611)\u001b[0m     @     0x55e02f8b7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39611)\u001b[0m     @     0x55e02f82c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39611)\u001b[0m     @     0x55e02f8b6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39611)\u001b[0m     @     0x55e02f8b7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39611)\u001b[0m     @     0x55e02f82c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39611)\u001b[0m     @     0x55e02f8b6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39611)\u001b[0m     @     0x55e02f8b7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39611)\u001b[0m     @     0x55e02f82c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39602)\u001b[0m     @     0x7f626ec384f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39602)\u001b[0m     @     0x7f6274ce379f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39602)\u001b[0m     @     0x558d3b9f6fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39602)\u001b[0m     @     0x558d3b951b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39602)\u001b[0m     @     0x558d3b9dcbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39602)\u001b[0m     @     0x558d3b9dda20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39602)\u001b[0m     @     0x558d3b951bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39602)\u001b[0m     @     0x558d3b9dcbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39602)\u001b[0m     @     0x558d3b9dd643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39602)\u001b[0m     @     0x558d3b952689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39602)\u001b[0m     @     0x558d3b9dcbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39602)\u001b[0m     @     0x558d3b9dd643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39602)\u001b[0m     @     0x558d3b952689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39602)\u001b[0m     @     0x558d3b9dcbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39602)\u001b[0m     @     0x558d3b9dd643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39602)\u001b[0m     @     0x558d3b952689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39602)\u001b[0m     @     0x558d3b9dcbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39602)\u001b[0m     @     0x558d3b9dd643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39602)\u001b[0m     @     0x558d3b952689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39579)\u001b[0m     @     0x7f558709d5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39579)\u001b[0m     @     0x7f55877884f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39579)\u001b[0m     @     0x7f5589c5b8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39579)\u001b[0m     @     0x7f55877884f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39579)\u001b[0m     @     0x7f558d83379f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39579)\u001b[0m     @     0x55b3b1500fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39579)\u001b[0m     @     0x55b3b145bb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39579)\u001b[0m     @     0x55b3b14e6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39579)\u001b[0m     @     0x55b3b14e7a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39579)\u001b[0m     @     0x55b3b145bbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39579)\u001b[0m     @     0x55b3b14e6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39579)\u001b[0m     @     0x55b3b14e7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39579)\u001b[0m     @     0x55b3b145c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39579)\u001b[0m     @     0x55b3b14e6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39579)\u001b[0m     @     0x55b3b14e7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39579)\u001b[0m     @     0x55b3b145c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39579)\u001b[0m     @     0x55b3b14e6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39579)\u001b[0m     @     0x55b3b14e7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39579)\u001b[0m     @     0x55b3b145c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39579)\u001b[0m     @     0x55b3b14e6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39579)\u001b[0m     @     0x55b3b14e7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39579)\u001b[0m     @     0x55b3b145c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39714)\u001b[0m     @     0x7f677ec658de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39714)\u001b[0m     @     0x7f677c7924f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39714)\u001b[0m     @     0x7f678283d79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39714)\u001b[0m     @     0x5620585eafd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39714)\u001b[0m     @     0x562058545b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39714)\u001b[0m     @     0x5620585d0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39714)\u001b[0m     @     0x5620585d1a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39714)\u001b[0m     @     0x562058545bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39714)\u001b[0m     @     0x5620585d0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39714)\u001b[0m     @     0x5620585d1643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39714)\u001b[0m     @     0x562058546689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39714)\u001b[0m     @     0x5620585d0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39714)\u001b[0m     @     0x5620585d1643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39714)\u001b[0m     @     0x562058546689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39714)\u001b[0m     @     0x5620585d0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39714)\u001b[0m     @     0x5620585d1643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39714)\u001b[0m     @     0x562058546689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39714)\u001b[0m     @     0x5620585d0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39714)\u001b[0m     @     0x5620585d1643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39714)\u001b[0m     @     0x562058546689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39606)\u001b[0m     @     0x7f29c48354f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39606)\u001b[0m     @     0x7f29c6d088de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39606)\u001b[0m     @     0x7f29c48354f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39606)\u001b[0m     @     0x7f29ca8e079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39606)\u001b[0m     @     0x564f6bc36fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39606)\u001b[0m     @     0x564f6bb91b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39606)\u001b[0m     @     0x564f6bc1cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39606)\u001b[0m     @     0x564f6bc1da20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39606)\u001b[0m     @     0x564f6bb91bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39606)\u001b[0m     @     0x564f6bc1cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39606)\u001b[0m     @     0x564f6bc1d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39599)\u001b[0m     @     0x7faf6be514f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39599)\u001b[0m     @     0x7faf6e3248de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39599)\u001b[0m     @     0x7faf6be514f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39599)\u001b[0m     @     0x7faf71efc79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39599)\u001b[0m     @     0x559b800abfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39599)\u001b[0m     @     0x559b80006b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39599)\u001b[0m     @     0x559b80091baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39599)\u001b[0m     @     0x559b80092a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39599)\u001b[0m     @     0x559b80006bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39599)\u001b[0m     @     0x559b80091baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39599)\u001b[0m     @     0x559b80092643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39599)\u001b[0m     @     0x559b80007689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39599)\u001b[0m     @     0x559b80091baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39599)\u001b[0m     @     0x559b80092643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39599)\u001b[0m     @     0x559b80007689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39599)\u001b[0m     @     0x559b80091baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39599)\u001b[0m     @     0x559b80092643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39599)\u001b[0m     @     0x559b80007689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39599)\u001b[0m     @     0x559b80091baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39599)\u001b[0m     @     0x559b80092643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39599)\u001b[0m     @     0x559b80007689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39583)\u001b[0m     @     0x7fb60398d8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39583)\u001b[0m     @     0x7fb6014ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39583)\u001b[0m     @     0x7fb60756579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39583)\u001b[0m     @     0x5622ed0dffd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39583)\u001b[0m     @     0x5622ed03ab08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39583)\u001b[0m     @     0x5622ed0c5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39583)\u001b[0m     @     0x5622ed0c6a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39583)\u001b[0m     @     0x5622ed03abfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39583)\u001b[0m     @     0x5622ed0c5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39583)\u001b[0m     @     0x5622ed0c6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39583)\u001b[0m     @     0x5622ed03b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39583)\u001b[0m     @     0x5622ed0c5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39583)\u001b[0m     @     0x5622ed0c6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39583)\u001b[0m     @     0x5622ed03b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39583)\u001b[0m     @     0x5622ed0c5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39583)\u001b[0m     @     0x5622ed0c6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39583)\u001b[0m     @     0x5622ed03b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39583)\u001b[0m     @     0x5622ed0c5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39583)\u001b[0m     @     0x5622ed0c6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39583)\u001b[0m     @     0x5622ed03b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39594)\u001b[0m     @     0x7fc3d92b54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39594)\u001b[0m     @     0x7fc3db7888de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39594)\u001b[0m     @     0x7fc3d92b54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39594)\u001b[0m     @     0x7fc3df36079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39594)\u001b[0m     @     0x55746d648fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39594)\u001b[0m     @     0x55746d5a3b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39594)\u001b[0m     @     0x55746d62ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39594)\u001b[0m     @     0x55746d62fa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39594)\u001b[0m     @     0x55746d5a3bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39594)\u001b[0m     @     0x55746d62ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39594)\u001b[0m     @     0x55746d62f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39594)\u001b[0m     @     0x55746d5a4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39594)\u001b[0m     @     0x55746d62ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39594)\u001b[0m     @     0x55746d62f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39594)\u001b[0m     @     0x55746d5a4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39594)\u001b[0m     @     0x55746d62ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39594)\u001b[0m     @     0x55746d62f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39594)\u001b[0m     @     0x55746d5a4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39594)\u001b[0m     @     0x55746d62ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39594)\u001b[0m     @     0x55746d62f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39594)\u001b[0m     @     0x55746d5a4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39598)\u001b[0m     @     0x7f73245a94f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39598)\u001b[0m     @     0x7f7326a7c8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39598)\u001b[0m     @     0x7f73245a94f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39598)\u001b[0m     @     0x7f732a65479f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39598)\u001b[0m     @     0x55c22d27ffd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39598)\u001b[0m     @     0x55c22d1dab08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39598)\u001b[0m     @     0x55c22d265baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39598)\u001b[0m     @     0x55c22d266a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39598)\u001b[0m     @     0x55c22d1dabfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39598)\u001b[0m     @     0x55c22d265baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39598)\u001b[0m     @     0x55c22d266643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39598)\u001b[0m     @     0x55c22d1db689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39598)\u001b[0m     @     0x55c22d265baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39598)\u001b[0m     @     0x55c22d266643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39598)\u001b[0m     @     0x55c22d1db689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39598)\u001b[0m     @     0x55c22d265baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39598)\u001b[0m     @     0x55c22d266643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39598)\u001b[0m     @     0x55c22d1db689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39598)\u001b[0m     @     0x55c22d265baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39598)\u001b[0m     @     0x55c22d266643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39598)\u001b[0m     @     0x55c22d1db689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39592)\u001b[0m     @     0x7f03031e04f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39592)\u001b[0m     @     0x7f03056b38de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39592)\u001b[0m     @     0x7f03031e04f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39592)\u001b[0m     @     0x7f030928b79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39592)\u001b[0m     @     0x5603aa463fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39592)\u001b[0m     @     0x5603aa3beb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39592)\u001b[0m     @     0x5603aa449baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39592)\u001b[0m     @     0x5603aa44aa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39592)\u001b[0m     @     0x5603aa3bebfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39592)\u001b[0m     @     0x5603aa449baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39592)\u001b[0m     @     0x5603aa44a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39592)\u001b[0m     @     0x5603aa3bf689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39592)\u001b[0m     @     0x5603aa449baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39592)\u001b[0m     @     0x5603aa44a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39592)\u001b[0m     @     0x5603aa3bf689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39592)\u001b[0m     @     0x5603aa449baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39592)\u001b[0m     @     0x5603aa44a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39592)\u001b[0m     @     0x5603aa3bf689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39592)\u001b[0m     @     0x5603aa449baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39592)\u001b[0m     @     0x5603aa44a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39592)\u001b[0m     @     0x5603aa3bf689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39647)\u001b[0m     @     0x7f9e5c79e8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39647)\u001b[0m     @     0x7f9e5a2cb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39647)\u001b[0m     @     0x7f9e6037679f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39647)\u001b[0m     @     0x55a75cf81fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39647)\u001b[0m     @     0x55a75cedcb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39647)\u001b[0m     @     0x55a75cf67baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39647)\u001b[0m     @     0x55a75cf68a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39647)\u001b[0m     @     0x55a75cedcbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39647)\u001b[0m     @     0x55a75cf67baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39647)\u001b[0m     @     0x55a75cf68643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39647)\u001b[0m     @     0x55a75cedd689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39647)\u001b[0m     @     0x55a75cf67baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39647)\u001b[0m     @     0x55a75cf68643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39647)\u001b[0m     @     0x55a75cedd689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39647)\u001b[0m     @     0x55a75cf67baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39647)\u001b[0m     @     0x55a75cf68643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39647)\u001b[0m     @     0x55a75cedd689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39647)\u001b[0m     @     0x55a75cf67baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39647)\u001b[0m     @     0x55a75cf68643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39647)\u001b[0m     @     0x55a75cedd689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39581)\u001b[0m     @     0x7f5d2946379f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39581)\u001b[0m     @     0x556d71deafd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39581)\u001b[0m     @     0x556d71d45b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39581)\u001b[0m     @     0x556d71dd0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39581)\u001b[0m     @     0x556d71dd1a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39581)\u001b[0m     @     0x556d71d45bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39581)\u001b[0m     @     0x556d71dd0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39581)\u001b[0m     @     0x556d71dd1643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39581)\u001b[0m     @     0x556d71d46689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39581)\u001b[0m     @     0x556d71dd0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39581)\u001b[0m     @     0x556d71dd1643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39581)\u001b[0m     @     0x556d71d46689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39581)\u001b[0m     @     0x556d71dd0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39581)\u001b[0m     @     0x556d71dd1643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39581)\u001b[0m     @     0x556d71d46689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39581)\u001b[0m     @     0x556d71dd0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39581)\u001b[0m     @     0x556d71dd1643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39581)\u001b[0m     @     0x556d71d46689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39601)\u001b[0m     @     0x7fb03788d8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39601)\u001b[0m     @     0x7fb0353ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39601)\u001b[0m     @     0x7fb03b46579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39601)\u001b[0m     @     0x55658d7ddfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39601)\u001b[0m     @     0x55658d738b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39601)\u001b[0m     @     0x55658d7c3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39601)\u001b[0m     @     0x55658d7c4a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39601)\u001b[0m     @     0x55658d738bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39601)\u001b[0m     @     0x55658d7c3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39601)\u001b[0m     @     0x55658d7c4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39601)\u001b[0m     @     0x55658d739689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39601)\u001b[0m     @     0x55658d7c3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39601)\u001b[0m     @     0x55658d7c4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39601)\u001b[0m     @     0x55658d739689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39601)\u001b[0m     @     0x55658d7c3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39601)\u001b[0m     @     0x55658d7c4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39601)\u001b[0m     @     0x55658d739689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39601)\u001b[0m     @     0x55658d7c3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39601)\u001b[0m     @     0x55658d7c4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39601)\u001b[0m     @     0x55658d739689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39604)\u001b[0m     @     0x7f414464c4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39604)\u001b[0m     @     0x7f4146b1f8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39604)\u001b[0m     @     0x7f414464c4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39604)\u001b[0m     @     0x7f414a6f779f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39604)\u001b[0m     @     0x5637280affd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39604)\u001b[0m     @     0x56372800ab08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39604)\u001b[0m     @     0x563728095baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39604)\u001b[0m     @     0x563728096a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39604)\u001b[0m     @     0x56372800abfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39604)\u001b[0m     @     0x563728095baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39604)\u001b[0m     @     0x563728096643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39604)\u001b[0m     @     0x56372800b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39604)\u001b[0m     @     0x563728095baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39604)\u001b[0m     @     0x563728096643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39604)\u001b[0m     @     0x56372800b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39604)\u001b[0m     @     0x563728095baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39604)\u001b[0m     @     0x563728096643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39604)\u001b[0m     @     0x56372800b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39604)\u001b[0m     @     0x563728095baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39604)\u001b[0m     @     0x563728096643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39604)\u001b[0m     @     0x56372800b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39656)\u001b[0m     @     0x7f03fa3e95a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39656)\u001b[0m     @     0x7f03faad44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39656)\u001b[0m     @     0x7f03fcfa78de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39656)\u001b[0m     @     0x7f03faad44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39656)\u001b[0m     @     0x7f0400b7f79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39656)\u001b[0m     @     0x55563b32dfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39656)\u001b[0m     @     0x55563b288b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39656)\u001b[0m     @     0x55563b313baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39656)\u001b[0m     @     0x55563b314a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39656)\u001b[0m     @     0x55563b288bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39656)\u001b[0m     @     0x55563b313baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39656)\u001b[0m     @     0x55563b314643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39656)\u001b[0m     @     0x55563b289689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39656)\u001b[0m     @     0x55563b313baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39656)\u001b[0m     @     0x55563b314643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39656)\u001b[0m     @     0x55563b289689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39656)\u001b[0m     @     0x55563b313baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39656)\u001b[0m     @     0x55563b314643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39656)\u001b[0m     @     0x55563b289689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39656)\u001b[0m     @     0x55563b313baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39656)\u001b[0m     @     0x55563b314643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39656)\u001b[0m     @     0x55563b289689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39643)\u001b[0m     @     0x7ee4ddb95ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39643)\u001b[0m     @     0x7ee4ddb95d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39643)\u001b[0m     @     0x7ee4de478b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39643)\u001b[0m     @     0x7ee4de49bc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39648)\u001b[0m     @     0x7fba27ae45a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39648)\u001b[0m     @     0x7fba281cf4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39648)\u001b[0m     @     0x7fba2a6a28de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39648)\u001b[0m     @     0x7fba281cf4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39648)\u001b[0m     @     0x7fba2e27a79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39648)\u001b[0m     @     0x5559cd921fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39648)\u001b[0m     @     0x5559cd87cb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39648)\u001b[0m     @     0x5559cd907baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39648)\u001b[0m     @     0x5559cd908a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39648)\u001b[0m     @     0x5559cd87cbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39648)\u001b[0m     @     0x5559cd907baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39648)\u001b[0m     @     0x5559cd908643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39648)\u001b[0m     @     0x5559cd87d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39648)\u001b[0m     @     0x5559cd907baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39648)\u001b[0m     @     0x5559cd908643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39648)\u001b[0m     @     0x5559cd87d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39648)\u001b[0m     @     0x5559cd907baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39587)\u001b[0m     @     0x7f3b122cb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39587)\u001b[0m     @     0x7f3b1479e8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39587)\u001b[0m     @     0x7f3b122cb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39587)\u001b[0m     @     0x7f3b1837679f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39587)\u001b[0m     @     0x56307f10efd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39587)\u001b[0m     @     0x56307f069b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39587)\u001b[0m     @     0x56307f0f4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39587)\u001b[0m     @     0x56307f0f5a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39587)\u001b[0m     @     0x56307f069bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39587)\u001b[0m     @     0x56307f0f4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39587)\u001b[0m     @     0x56307f0f5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39587)\u001b[0m     @     0x56307f06a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39587)\u001b[0m     @     0x56307f0f4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39587)\u001b[0m     @     0x56307f0f5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39587)\u001b[0m     @     0x56307f06a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39587)\u001b[0m     @     0x56307f0f4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39587)\u001b[0m     @     0x56307f0f5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39587)\u001b[0m     @     0x56307f06a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39587)\u001b[0m     @     0x56307f0f4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39587)\u001b[0m     @     0x56307f0f5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39587)\u001b[0m     @     0x56307f06a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39614)\u001b[0m     @     0x7ef98f6b64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39614)\u001b[0m     @     0x7ef991b898de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39614)\u001b[0m     @     0x7ef98f6b64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39614)\u001b[0m     @     0x7ef99576179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39614)\u001b[0m     @     0x561af97f9fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39614)\u001b[0m     @     0x561af9754b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39614)\u001b[0m     @     0x561af97dfbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39614)\u001b[0m     @     0x561af97e0a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39614)\u001b[0m     @     0x561af9754bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39614)\u001b[0m     @     0x561af97dfbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39614)\u001b[0m     @     0x561af97e0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39614)\u001b[0m     @     0x561af9755689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39614)\u001b[0m     @     0x561af97dfbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39614)\u001b[0m     @     0x561af97e0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39614)\u001b[0m     @     0x561af9755689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39614)\u001b[0m     @     0x561af97dfbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39614)\u001b[0m     @     0x561af97e0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39614)\u001b[0m     @     0x561af9755689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39614)\u001b[0m     @     0x561af97dfbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39614)\u001b[0m     @     0x561af97e0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39614)\u001b[0m     @     0x561af9755689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39597)\u001b[0m     @     0x7ef219cfb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39597)\u001b[0m     @     0x7ef21fda679f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39597)\u001b[0m     @     0x55d68a66bfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39597)\u001b[0m     @     0x55d68a5c6b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39597)\u001b[0m     @     0x55d68a651baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39597)\u001b[0m     @     0x55d68a652a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39597)\u001b[0m     @     0x55d68a5c6bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39597)\u001b[0m     @     0x55d68a651baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39597)\u001b[0m     @     0x55d68a652643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39597)\u001b[0m     @     0x55d68a5c7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39597)\u001b[0m     @     0x55d68a651baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39597)\u001b[0m     @     0x55d68a652643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39597)\u001b[0m     @     0x55d68a5c7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39597)\u001b[0m     @     0x55d68a651baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39597)\u001b[0m     @     0x55d68a652643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39597)\u001b[0m     @     0x55d68a5c7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39597)\u001b[0m     @     0x55d68a651baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39597)\u001b[0m     @     0x55d68a652643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39597)\u001b[0m     @     0x55d68a5c7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39682)\u001b[0m     @     0x7f7238c444f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39682)\u001b[0m     @     0x7f723b1178de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39682)\u001b[0m     @     0x7f7238c444f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39682)\u001b[0m     @     0x7f723ecef79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39682)\u001b[0m     @     0x55bc222ebfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39682)\u001b[0m     @     0x55bc22246b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39682)\u001b[0m     @     0x55bc222d1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39682)\u001b[0m     @     0x55bc222d2a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39682)\u001b[0m     @     0x55bc22246bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39682)\u001b[0m     @     0x55bc222d1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39682)\u001b[0m     @     0x55bc222d2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39682)\u001b[0m     @     0x55bc22247689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39682)\u001b[0m     @     0x55bc222d1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39682)\u001b[0m     @     0x55bc222d2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39682)\u001b[0m     @     0x55bc22247689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39682)\u001b[0m     @     0x55bc222d1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39682)\u001b[0m     @     0x55bc222d2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39682)\u001b[0m     @     0x55bc22247689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39682)\u001b[0m     @     0x55bc222d1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39682)\u001b[0m     @     0x55bc222d2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39682)\u001b[0m     @     0x55bc22247689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39580)\u001b[0m     @     0x7f43b40c84f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39580)\u001b[0m     @     0x7f43ba17379f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39580)\u001b[0m     @     0x55a6ef5cbfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39580)\u001b[0m     @     0x55a6ef526b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39580)\u001b[0m     @     0x55a6ef5b1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39580)\u001b[0m     @     0x55a6ef5b2a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39580)\u001b[0m     @     0x55a6ef526bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39580)\u001b[0m     @     0x55a6ef5b1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39580)\u001b[0m     @     0x55a6ef5b2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39580)\u001b[0m     @     0x55a6ef527689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39580)\u001b[0m     @     0x55a6ef5b1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39580)\u001b[0m     @     0x55a6ef5b2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39580)\u001b[0m     @     0x55a6ef527689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39580)\u001b[0m     @     0x55a6ef5b1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39580)\u001b[0m     @     0x55a6ef5b2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39580)\u001b[0m     @     0x55a6ef527689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39580)\u001b[0m     @     0x55a6ef5b1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39580)\u001b[0m     @     0x55a6ef5b2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39580)\u001b[0m     @     0x55a6ef527689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39649)\u001b[0m     @     0x7f703def75a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39649)\u001b[0m     @     0x7f703e5e24f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39649)\u001b[0m     @     0x7f7040ab58de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39649)\u001b[0m     @     0x7f703e5e24f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39649)\u001b[0m     @     0x7f704468d79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39649)\u001b[0m     @     0x563c4a629fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39649)\u001b[0m     @     0x563c4a584b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39649)\u001b[0m     @     0x563c4a60fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39649)\u001b[0m     @     0x563c4a610a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39649)\u001b[0m     @     0x563c4a584bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39649)\u001b[0m     @     0x563c4a60fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39649)\u001b[0m     @     0x563c4a610643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39649)\u001b[0m     @     0x563c4a585689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39649)\u001b[0m     @     0x563c4a60fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39649)\u001b[0m     @     0x563c4a610643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39649)\u001b[0m     @     0x563c4a585689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39649)\u001b[0m     @     0x563c4a60fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39649)\u001b[0m     @     0x563c4a610643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39649)\u001b[0m     @     0x563c4a585689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39649)\u001b[0m     @     0x563c4a60fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39649)\u001b[0m     @     0x563c4a610643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39649)\u001b[0m     @     0x563c4a585689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39657)\u001b[0m     @     0x7f91f2b05c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39657)\u001b[0m     @     0x7f91f1fa7a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39657)\u001b[0m     @     0x7f91f1fa5388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39657)\u001b[0m     @     0x7f91f1fa75a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39657)\u001b[0m     @     0x7f91f26924f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39657)\u001b[0m     @     0x7f91f4b658de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39644)\u001b[0m     @     0x7eeaf8c11ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39674)\u001b[0m     @     0x7f874658d4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39674)\u001b[0m     @     0x7f874c63879f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39674)\u001b[0m     @     0x55b4180e7fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39674)\u001b[0m     @     0x55b418042b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39674)\u001b[0m     @     0x55b4180cdbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39674)\u001b[0m     @     0x55b4180cea20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39674)\u001b[0m     @     0x55b418042bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39674)\u001b[0m     @     0x55b4180cdbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39674)\u001b[0m     @     0x55b4180ce643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39674)\u001b[0m     @     0x55b418043689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39674)\u001b[0m     @     0x55b4180cdbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39674)\u001b[0m     @     0x55b4180ce643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39674)\u001b[0m     @     0x55b418043689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39674)\u001b[0m     @     0x55b4180cdbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39674)\u001b[0m     @     0x55b4180ce643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39674)\u001b[0m     @     0x55b418043689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39674)\u001b[0m     @     0x55b4180cdbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39674)\u001b[0m     @     0x55b4180ce643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39674)\u001b[0m     @     0x55b418043689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39586)\u001b[0m     @     0x7f4cf7ca18de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39586)\u001b[0m     @     0x7f4cf57ce4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39586)\u001b[0m     @     0x7f4cfb87979f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39586)\u001b[0m     @     0x561d4c924fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39586)\u001b[0m     @     0x561d4c87fb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39586)\u001b[0m     @     0x561d4c90abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39586)\u001b[0m     @     0x561d4c90ba20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39586)\u001b[0m     @     0x561d4c87fbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39586)\u001b[0m     @     0x561d4c90abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39586)\u001b[0m     @     0x561d4c90b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39586)\u001b[0m     @     0x561d4c880689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39586)\u001b[0m     @     0x561d4c90abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39586)\u001b[0m     @     0x561d4c90b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39586)\u001b[0m     @     0x561d4c880689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39586)\u001b[0m     @     0x561d4c90abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39586)\u001b[0m     @     0x561d4c90b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39586)\u001b[0m     @     0x561d4c880689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39586)\u001b[0m     @     0x561d4c90abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39586)\u001b[0m     @     0x561d4c90b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39586)\u001b[0m     @     0x561d4c880689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39692)\u001b[0m     @     0x7f3356a144f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39692)\u001b[0m     @     0x7f3358ee78de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39692)\u001b[0m     @     0x7f3356a144f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39692)\u001b[0m     @     0x7f335cabf79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39692)\u001b[0m     @     0x55e4e73defd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39692)\u001b[0m     @     0x55e4e7339b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39692)\u001b[0m     @     0x55e4e73c4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39692)\u001b[0m     @     0x55e4e73c5a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39692)\u001b[0m     @     0x55e4e7339bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39692)\u001b[0m     @     0x55e4e73c4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39692)\u001b[0m     @     0x55e4e73c5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39692)\u001b[0m     @     0x55e4e733a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39692)\u001b[0m     @     0x55e4e73c4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39692)\u001b[0m     @     0x55e4e73c5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39692)\u001b[0m     @     0x55e4e733a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39692)\u001b[0m     @     0x55e4e73c4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39692)\u001b[0m     @     0x55e4e73c5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39692)\u001b[0m     @     0x55e4e733a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39692)\u001b[0m     @     0x55e4e73c4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39692)\u001b[0m     @     0x55e4e73c5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39692)\u001b[0m     @     0x55e4e733a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39660)\u001b[0m     @     0x7f552338ca93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39660)\u001b[0m     @     0x7f552338a388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39660)\u001b[0m     @     0x7f552338c5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39612)\u001b[0m     @     0x7fb92c164d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39612)\u001b[0m     @     0x7fb92ca47b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39612)\u001b[0m     @     0x7fb92ca6ac1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39585)\u001b[0m     @     0x7f96041cf4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39585)\u001b[0m     @     0x7f96066a28de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39585)\u001b[0m     @     0x7f96041cf4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39585)\u001b[0m     @     0x7f960a27a79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39585)\u001b[0m     @     0x55bc8d3e1fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39585)\u001b[0m     @     0x55bc8d33cb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39585)\u001b[0m     @     0x55bc8d3c7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39585)\u001b[0m     @     0x55bc8d3c8a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39585)\u001b[0m     @     0x55bc8d33cbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39585)\u001b[0m     @     0x55bc8d3c7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39585)\u001b[0m     @     0x55bc8d3c8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39585)\u001b[0m     @     0x55bc8d33d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39585)\u001b[0m     @     0x55bc8d3c7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39585)\u001b[0m     @     0x55bc8d3c8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39585)\u001b[0m     @     0x55bc8d33d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39585)\u001b[0m     @     0x55bc8d3c7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39585)\u001b[0m     @     0x55bc8d3c8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39585)\u001b[0m     @     0x55bc8d33d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39585)\u001b[0m     @     0x55bc8d3c7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39585)\u001b[0m     @     0x55bc8d3c8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39585)\u001b[0m     @     0x55bc8d33d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39646)\u001b[0m     @     0x7f50eadb45a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39646)\u001b[0m     @     0x7f50eb49f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39646)\u001b[0m     @     0x7f50ed9728de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39662)\u001b[0m     @     0x7f9374f204f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39662)\u001b[0m     @     0x7f937afcb79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39662)\u001b[0m     @     0x55722d419fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39662)\u001b[0m     @     0x55722d374b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39662)\u001b[0m     @     0x55722d3ffbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39662)\u001b[0m     @     0x55722d400a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39662)\u001b[0m     @     0x55722d374bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39662)\u001b[0m     @     0x55722d3ffbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39662)\u001b[0m     @     0x55722d400643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39662)\u001b[0m     @     0x55722d375689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39662)\u001b[0m     @     0x55722d3ffbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39662)\u001b[0m     @     0x55722d400643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39662)\u001b[0m     @     0x55722d375689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39662)\u001b[0m     @     0x55722d3ffbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39662)\u001b[0m     @     0x55722d400643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39662)\u001b[0m     @     0x55722d375689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39662)\u001b[0m     @     0x55722d3ffbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39662)\u001b[0m     @     0x55722d400643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39662)\u001b[0m     @     0x55722d375689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39697)\u001b[0m     @     0x7ef9eab845a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39697)\u001b[0m     @     0x7ef9eb26f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39697)\u001b[0m     @     0x7ef9ed7428de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39697)\u001b[0m     @     0x7ef9eb26f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39582)\u001b[0m     @     0x7f64450374f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39582)\u001b[0m     @     0x7f644b0e279f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39582)\u001b[0m     @     0x561f481bffd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39582)\u001b[0m     @     0x561f4811ab08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39582)\u001b[0m     @     0x561f481a5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39582)\u001b[0m     @     0x561f481a6a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39582)\u001b[0m     @     0x561f4811abfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39582)\u001b[0m     @     0x561f481a5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39582)\u001b[0m     @     0x561f481a6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39582)\u001b[0m     @     0x561f4811b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39582)\u001b[0m     @     0x561f481a5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39582)\u001b[0m     @     0x561f481a6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39582)\u001b[0m     @     0x561f4811b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39582)\u001b[0m     @     0x561f481a5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39582)\u001b[0m     @     0x561f481a6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39582)\u001b[0m     @     0x561f4811b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39582)\u001b[0m     @     0x561f481a5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39582)\u001b[0m     @     0x561f481a6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39582)\u001b[0m     @     0x561f4811b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39584)\u001b[0m     @     0x7f6baf8fa4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39584)\u001b[0m     @     0x7f6bb59a579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39584)\u001b[0m     @     0x55c53d7effd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39584)\u001b[0m     @     0x55c53d74ab08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39584)\u001b[0m     @     0x55c53d7d5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39584)\u001b[0m     @     0x55c53d7d6a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39584)\u001b[0m     @     0x55c53d74abfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39584)\u001b[0m     @     0x55c53d7d5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39584)\u001b[0m     @     0x55c53d7d6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39584)\u001b[0m     @     0x55c53d74b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39584)\u001b[0m     @     0x55c53d7d5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39584)\u001b[0m     @     0x55c53d7d6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39584)\u001b[0m     @     0x55c53d74b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39584)\u001b[0m     @     0x55c53d7d5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39584)\u001b[0m     @     0x55c53d7d6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39584)\u001b[0m     @     0x55c53d74b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39584)\u001b[0m     @     0x55c53d7d5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39584)\u001b[0m     @     0x55c53d7d6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39584)\u001b[0m     @     0x55c53d74b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39704)\u001b[0m     @     0x7f4be40924f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39704)\u001b[0m     @     0x7f4bea13d79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39704)\u001b[0m     @     0x555e2fbc8fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39704)\u001b[0m     @     0x555e2fb23b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39704)\u001b[0m     @     0x555e2fbaebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39704)\u001b[0m     @     0x555e2fbafa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39704)\u001b[0m     @     0x555e2fb23bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39704)\u001b[0m     @     0x555e2fbaebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39704)\u001b[0m     @     0x555e2fbaf643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39704)\u001b[0m     @     0x555e2fb24689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39704)\u001b[0m     @     0x555e2fbaebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39704)\u001b[0m     @     0x555e2fbaf643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39704)\u001b[0m     @     0x555e2fb24689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39704)\u001b[0m     @     0x555e2fbaebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39704)\u001b[0m     @     0x555e2fbaf643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39704)\u001b[0m     @     0x555e2fb24689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39704)\u001b[0m     @     0x555e2fbaebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39704)\u001b[0m     @     0x555e2fbaf643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39704)\u001b[0m     @     0x555e2fb24689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39645)\u001b[0m     @     0x7f1f4e6a28de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39645)\u001b[0m     @     0x7f1f4c1cf4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39645)\u001b[0m     @     0x7f1f5227a79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39645)\u001b[0m     @     0x5633d33bffd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39645)\u001b[0m     @     0x5633d331ab08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39645)\u001b[0m     @     0x5633d33a5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39645)\u001b[0m     @     0x5633d33a6a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39645)\u001b[0m     @     0x5633d331abfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39645)\u001b[0m     @     0x5633d33a5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39645)\u001b[0m     @     0x5633d33a6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39645)\u001b[0m     @     0x5633d331b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39645)\u001b[0m     @     0x5633d33a5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39645)\u001b[0m     @     0x5633d33a6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39645)\u001b[0m     @     0x5633d331b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39645)\u001b[0m     @     0x5633d33a5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39645)\u001b[0m     @     0x5633d33a6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39645)\u001b[0m     @     0x5633d331b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39645)\u001b[0m     @     0x5633d33a5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39645)\u001b[0m     @     0x5633d33a6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39645)\u001b[0m     @     0x5633d331b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39691)\u001b[0m     @     0x7ef7611a34f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39691)\u001b[0m     @     0x7ef76724e79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39691)\u001b[0m     @     0x55b1c3859fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39691)\u001b[0m     @     0x55b1c37b4b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39691)\u001b[0m     @     0x55b1c383fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39691)\u001b[0m     @     0x55b1c3840a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39691)\u001b[0m     @     0x55b1c37b4bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39691)\u001b[0m     @     0x55b1c383fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39691)\u001b[0m     @     0x55b1c3840643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39691)\u001b[0m     @     0x55b1c37b5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39691)\u001b[0m     @     0x55b1c383fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39691)\u001b[0m     @     0x55b1c3840643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39691)\u001b[0m     @     0x55b1c37b5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39691)\u001b[0m     @     0x55b1c383fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39691)\u001b[0m     @     0x55b1c3840643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39691)\u001b[0m     @     0x55b1c37b5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39691)\u001b[0m     @     0x55b1c383fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39691)\u001b[0m     @     0x55b1c3840643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39691)\u001b[0m     @     0x55b1c37b5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39610)\u001b[0m     @     0x7f2e38c764f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39610)\u001b[0m     @     0x7f2e3ed2179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39610)\u001b[0m     @     0x55f0a18b9fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39610)\u001b[0m     @     0x55f0a1814b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39610)\u001b[0m     @     0x55f0a189fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39610)\u001b[0m     @     0x55f0a18a0a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39610)\u001b[0m     @     0x55f0a1814bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39610)\u001b[0m     @     0x55f0a189fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39610)\u001b[0m     @     0x55f0a18a0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39610)\u001b[0m     @     0x55f0a1815689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39610)\u001b[0m     @     0x55f0a189fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39610)\u001b[0m     @     0x55f0a18a0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39610)\u001b[0m     @     0x55f0a1815689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39610)\u001b[0m     @     0x55f0a189fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39610)\u001b[0m     @     0x55f0a18a0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39610)\u001b[0m     @     0x55f0a1815689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39610)\u001b[0m     @     0x55f0a189fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39610)\u001b[0m     @     0x55f0a18a0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39610)\u001b[0m     @     0x55f0a1815689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39652)\u001b[0m     @     0x558336453baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39652)\u001b[0m     @     0x558336454643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39652)\u001b[0m     @     0x5583363c9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39699)\u001b[0m     @     0x7f2eecca98de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39699)\u001b[0m     @     0x7f2eea7d64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39699)\u001b[0m     @     0x7f2ef047779f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39699)\u001b[0m     @     0x55926bdfdfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39699)\u001b[0m     @     0x55926bd58b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39699)\u001b[0m     @     0x55926bde3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39699)\u001b[0m     @     0x55926bde4a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39699)\u001b[0m     @     0x55926bd58bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39699)\u001b[0m     @     0x55926bde3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39699)\u001b[0m     @     0x55926bde4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39699)\u001b[0m     @     0x55926bd59689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39699)\u001b[0m     @     0x55926bde3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39699)\u001b[0m     @     0x55926bde4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39699)\u001b[0m     @     0x55926bd59689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39699)\u001b[0m     @     0x55926bde3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39699)\u001b[0m     @     0x55926bde4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39699)\u001b[0m     @     0x55926bd59689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39699)\u001b[0m     @     0x55926bde3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39699)\u001b[0m     @     0x55926bde4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39699)\u001b[0m     @     0x55926bd59689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39650)\u001b[0m     @     0x7f40c4f27d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39650)\u001b[0m     @     0x7f40c580ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39650)\u001b[0m     @     0x7f40c582dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39650)\u001b[0m     @     0x7f40c4ccfa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39650)\u001b[0m     @     0x7f40c4ccd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39600)\u001b[0m     @     0x7f2c339cc4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39600)\u001b[0m     @     0x7f2c35e9f8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39600)\u001b[0m     @     0x7f2c339cc4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39600)\u001b[0m     @     0x7f2c39a7779f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39600)\u001b[0m     @     0x5642650ccfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39600)\u001b[0m     @     0x564265027b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39600)\u001b[0m     @     0x5642650b2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39600)\u001b[0m     @     0x5642650b3a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39600)\u001b[0m     @     0x564265027bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39600)\u001b[0m     @     0x5642650b2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39600)\u001b[0m     @     0x5642650b3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39600)\u001b[0m     @     0x564265028689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39600)\u001b[0m     @     0x5642650b2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39600)\u001b[0m     @     0x5642650b3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39600)\u001b[0m     @     0x564265028689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39600)\u001b[0m     @     0x5642650b2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39600)\u001b[0m     @     0x5642650b3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39600)\u001b[0m     @     0x564265028689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39600)\u001b[0m     @     0x5642650b2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39600)\u001b[0m     @     0x5642650b3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39600)\u001b[0m     @     0x564265028689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39653)\u001b[0m     @     0x7f52547464f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39653)\u001b[0m     @     0x7f525a7f179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39653)\u001b[0m     @     0x55a467952fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39653)\u001b[0m     @     0x55a4678adb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39653)\u001b[0m     @     0x55a467938baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39653)\u001b[0m     @     0x55a467939a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39653)\u001b[0m     @     0x55a4678adbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39653)\u001b[0m     @     0x55a467938baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39653)\u001b[0m     @     0x55a467939643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39653)\u001b[0m     @     0x55a4678ae689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39653)\u001b[0m     @     0x55a467938baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39653)\u001b[0m     @     0x55a467939643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39653)\u001b[0m     @     0x55a4678ae689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39653)\u001b[0m     @     0x55a467938baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39653)\u001b[0m     @     0x55a467939643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39653)\u001b[0m     @     0x55a4678ae689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39653)\u001b[0m     @     0x55a467938baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39653)\u001b[0m     @     0x55a467939643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39653)\u001b[0m     @     0x55a4678ae689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39663)\u001b[0m     @     0x7f2370a654f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39663)\u001b[0m     @     0x7f2372f388de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39663)\u001b[0m     @     0x7f2370a654f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39663)\u001b[0m     @     0x7f2376b1079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39663)\u001b[0m     @     0x5615bf25cfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39663)\u001b[0m     @     0x5615bf1b7b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39663)\u001b[0m     @     0x5615bf242baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39663)\u001b[0m     @     0x5615bf243a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39663)\u001b[0m     @     0x5615bf1b7bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39663)\u001b[0m     @     0x5615bf242baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39663)\u001b[0m     @     0x5615bf243643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39663)\u001b[0m     @     0x5615bf1b8689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39663)\u001b[0m     @     0x5615bf242baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39663)\u001b[0m     @     0x5615bf243643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39663)\u001b[0m     @     0x5615bf1b8689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39663)\u001b[0m     @     0x5615bf242baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39663)\u001b[0m     @     0x5615bf243643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39663)\u001b[0m     @     0x5615bf1b8689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39663)\u001b[0m     @     0x5615bf242baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39663)\u001b[0m     @     0x5615bf243643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39663)\u001b[0m     @     0x5615bf1b8689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39596)\u001b[0m     @     0x7fa2468504f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39596)\u001b[0m     @     0x7fa248d238de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39596)\u001b[0m     @     0x7fa2468504f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39596)\u001b[0m     @     0x7fa24c8fb79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39596)\u001b[0m     @     0x564406a70fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39596)\u001b[0m     @     0x5644069cbb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39596)\u001b[0m     @     0x564406a56baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39596)\u001b[0m     @     0x564406a57a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39596)\u001b[0m     @     0x5644069cbbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39596)\u001b[0m     @     0x564406a56baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39596)\u001b[0m     @     0x564406a57643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39596)\u001b[0m     @     0x5644069cc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39596)\u001b[0m     @     0x564406a56baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39596)\u001b[0m     @     0x564406a57643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39596)\u001b[0m     @     0x5644069cc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39596)\u001b[0m     @     0x564406a56baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39596)\u001b[0m     @     0x564406a57643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39596)\u001b[0m     @     0x5644069cc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39596)\u001b[0m     @     0x564406a56baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39596)\u001b[0m     @     0x564406a57643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39596)\u001b[0m     @     0x5644069cc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39613)\u001b[0m     @     0x7f4ba228ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39613)\u001b[0m     @     0x7f4ba22adc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39613)\u001b[0m     @     0x7f4ba174fa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39613)\u001b[0m     @     0x7f4ba174d388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39613)\u001b[0m     @     0x7f4ba174f5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39661)\u001b[0m     @     0x7fb8a98b04f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39661)\u001b[0m     @     0x7fb8af95b79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39661)\u001b[0m     @     0x55b921d95fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39661)\u001b[0m     @     0x55b921cf0b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39661)\u001b[0m     @     0x55b921d7bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39661)\u001b[0m     @     0x55b921d7ca20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39661)\u001b[0m     @     0x55b921cf0bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39661)\u001b[0m     @     0x55b921d7bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39661)\u001b[0m     @     0x55b921d7c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39661)\u001b[0m     @     0x55b921cf1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39661)\u001b[0m     @     0x55b921d7bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39661)\u001b[0m     @     0x55b921d7c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39661)\u001b[0m     @     0x55b921cf1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39661)\u001b[0m     @     0x55b921d7bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39661)\u001b[0m     @     0x55b921d7c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39661)\u001b[0m     @     0x55b921cf1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39661)\u001b[0m     @     0x55b921d7bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39661)\u001b[0m     @     0x55b921d7c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39661)\u001b[0m     @     0x55b921cf1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39590)\u001b[0m     @     0x7f87ba5e24f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39590)\u001b[0m     @     0x7f87c068d79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39590)\u001b[0m     @     0x55ed9bd87fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39590)\u001b[0m     @     0x55ed9bce2b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39590)\u001b[0m     @     0x55ed9bd6dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39590)\u001b[0m     @     0x55ed9bd6ea20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39590)\u001b[0m     @     0x55ed9bce2bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39590)\u001b[0m     @     0x55ed9bd6dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39590)\u001b[0m     @     0x55ed9bd6e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39590)\u001b[0m     @     0x55ed9bce3689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39590)\u001b[0m     @     0x55ed9bd6dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39590)\u001b[0m     @     0x55ed9bd6e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39590)\u001b[0m     @     0x55ed9bce3689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39590)\u001b[0m     @     0x55ed9bd6dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39590)\u001b[0m     @     0x55ed9bd6e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39590)\u001b[0m     @     0x55ed9bce3689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39590)\u001b[0m     @     0x55ed9bd6dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39590)\u001b[0m     @     0x55ed9bd6e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39590)\u001b[0m     @     0x55ed9bce3689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39615)\u001b[0m     @     0x7fbdc02e04f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39615)\u001b[0m     @     0x7fbdc638b79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39615)\u001b[0m     @     0x5650c674efd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39615)\u001b[0m     @     0x5650c66a9b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39615)\u001b[0m     @     0x5650c6734baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39615)\u001b[0m     @     0x5650c6735a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39615)\u001b[0m     @     0x5650c66a9bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39615)\u001b[0m     @     0x5650c6734baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39615)\u001b[0m     @     0x5650c6735643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39615)\u001b[0m     @     0x5650c66aa689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39615)\u001b[0m     @     0x5650c6734baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39615)\u001b[0m     @     0x5650c6735643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39615)\u001b[0m     @     0x5650c66aa689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39615)\u001b[0m     @     0x5650c6734baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39615)\u001b[0m     @     0x5650c6735643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39615)\u001b[0m     @     0x5650c66aa689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39615)\u001b[0m     @     0x5650c6734baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39615)\u001b[0m     @     0x5650c6735643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39615)\u001b[0m     @     0x5650c66aa689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39694)\u001b[0m     @     0x7f89ec55ea93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39694)\u001b[0m     @     0x7f89ec55c388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39694)\u001b[0m     @     0x7f89ec55e5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39694)\u001b[0m     @     0x7f89ecc494f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39669)\u001b[0m     @     0x560bbb600b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39669)\u001b[0m     @     0x560bbb68bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39669)\u001b[0m     @     0x560bbb68ca20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39669)\u001b[0m     @     0x560bbb600bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39669)\u001b[0m     @     0x560bbb68bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39669)\u001b[0m     @     0x560bbb68c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39669)\u001b[0m     @     0x560bbb601689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39669)\u001b[0m     @     0x560bbb68bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39669)\u001b[0m     @     0x560bbb68c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39669)\u001b[0m     @     0x560bbb601689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39669)\u001b[0m     @     0x560bbb68bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39669)\u001b[0m     @     0x560bbb68c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39669)\u001b[0m     @     0x560bbb601689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39669)\u001b[0m     @     0x560bbb68bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39669)\u001b[0m     @     0x560bbb68c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39669)\u001b[0m     @     0x560bbb601689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39589)\u001b[0m     @     0x7fcacb9b14f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39589)\u001b[0m     @     0x7fcad1a5c79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39589)\u001b[0m     @     0x55b819f48fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39589)\u001b[0m     @     0x55b819ea3b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39589)\u001b[0m     @     0x55b819f2ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39589)\u001b[0m     @     0x55b819f2fa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39589)\u001b[0m     @     0x55b819ea3bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39589)\u001b[0m     @     0x55b819f2ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39589)\u001b[0m     @     0x55b819f2f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39589)\u001b[0m     @     0x55b819ea4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39589)\u001b[0m     @     0x55b819f2ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39589)\u001b[0m     @     0x55b819f2f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39589)\u001b[0m     @     0x55b819ea4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39589)\u001b[0m     @     0x55b819f2ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39589)\u001b[0m     @     0x55b819f2f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39589)\u001b[0m     @     0x55b819ea4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39589)\u001b[0m     @     0x55b819f2ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39589)\u001b[0m     @     0x55b819f2f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39589)\u001b[0m     @     0x55b819ea4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39606)\u001b[0m     @     0x564f6bb92689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39606)\u001b[0m     @     0x564f6bc1cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39606)\u001b[0m     @     0x564f6bc1d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39606)\u001b[0m     @     0x564f6bb92689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39606)\u001b[0m     @     0x564f6bc1cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39606)\u001b[0m     @     0x564f6bc1d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39606)\u001b[0m     @     0x564f6bb92689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39606)\u001b[0m     @     0x564f6bc1cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39606)\u001b[0m     @     0x564f6bc1d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39606)\u001b[0m     @     0x564f6bb92689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39643)\u001b[0m     @     0x7ee4dd93da93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39643)\u001b[0m     @     0x7ee4dd93b388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39648)\u001b[0m     @     0x5559cd908643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39648)\u001b[0m     @     0x5559cd87d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39648)\u001b[0m     @     0x5559cd907baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39648)\u001b[0m     @     0x5559cd908643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39648)\u001b[0m     @     0x5559cd87d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39657)\u001b[0m     @     0x7f91f26924f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39657)\u001b[0m     @     0x7f91f873d79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39657)\u001b[0m     @     0x55c372e82fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39657)\u001b[0m     @     0x55c372dddb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39657)\u001b[0m     @     0x55c372e68baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39657)\u001b[0m     @     0x55c372e69a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39657)\u001b[0m     @     0x55c372dddbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39657)\u001b[0m     @     0x55c372e68baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39657)\u001b[0m     @     0x55c372e69643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39657)\u001b[0m     @     0x55c372dde689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39657)\u001b[0m     @     0x55c372e68baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39657)\u001b[0m     @     0x55c372e69643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39657)\u001b[0m     @     0x55c372dde689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39657)\u001b[0m     @     0x55c372e68baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39657)\u001b[0m     @     0x55c372e69643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39657)\u001b[0m     @     0x55c372dde689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39657)\u001b[0m     @     0x55c372e68baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39657)\u001b[0m     @     0x55c372e69643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39657)\u001b[0m     @     0x55c372dde689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39660)\u001b[0m     @     0x7f5523a774f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39660)\u001b[0m     @     0x7f5525f4a8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39660)\u001b[0m     @     0x7f5523a774f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39660)\u001b[0m     @     0x7f5529b2279f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39660)\u001b[0m     @     0x56496968ffd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39660)\u001b[0m     @     0x5649695eab08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39660)\u001b[0m     @     0x564969675baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39660)\u001b[0m     @     0x564969676a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39660)\u001b[0m     @     0x5649695eabfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39660)\u001b[0m     @     0x564969675baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39660)\u001b[0m     @     0x564969676643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39660)\u001b[0m     @     0x5649695eb689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39660)\u001b[0m     @     0x564969675baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39660)\u001b[0m     @     0x564969676643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39660)\u001b[0m     @     0x5649695eb689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39660)\u001b[0m     @     0x564969675baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39660)\u001b[0m     @     0x564969676643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39660)\u001b[0m     @     0x5649695eb689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39660)\u001b[0m     @     0x564969675baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39660)\u001b[0m     @     0x564969676643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39660)\u001b[0m     @     0x5649695eb689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39612)\u001b[0m     @     0x7fb92bf0ca93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39612)\u001b[0m     @     0x7fb92bf0a388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39612)\u001b[0m     @     0x7fb92bf0c5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39612)\u001b[0m     @     0x7fb92c5f74f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39646)\u001b[0m     @     0x7f50eb49f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39646)\u001b[0m     @     0x7f50f154a79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39646)\u001b[0m     @     0x564076c3afd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39646)\u001b[0m     @     0x564076b95b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39646)\u001b[0m     @     0x564076c20baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39646)\u001b[0m     @     0x564076c21a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39646)\u001b[0m     @     0x564076b95bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39646)\u001b[0m     @     0x564076c20baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39646)\u001b[0m     @     0x564076c21643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39646)\u001b[0m     @     0x564076b96689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39646)\u001b[0m     @     0x564076c20baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39646)\u001b[0m     @     0x564076c21643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39646)\u001b[0m     @     0x564076b96689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39646)\u001b[0m     @     0x564076c20baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39646)\u001b[0m     @     0x564076c21643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39646)\u001b[0m     @     0x564076b96689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39646)\u001b[0m     @     0x564076c20baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39646)\u001b[0m     @     0x564076c21643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39646)\u001b[0m     @     0x564076b96689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39697)\u001b[0m     @     0x7ef9f131a79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39697)\u001b[0m     @     0x56521660efd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39697)\u001b[0m     @     0x565216569b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39697)\u001b[0m     @     0x5652165f4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39697)\u001b[0m     @     0x5652165f5a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39697)\u001b[0m     @     0x565216569bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39697)\u001b[0m     @     0x5652165f4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39697)\u001b[0m     @     0x5652165f5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39697)\u001b[0m     @     0x56521656a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39697)\u001b[0m     @     0x5652165f4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39697)\u001b[0m     @     0x5652165f5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39697)\u001b[0m     @     0x56521656a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39697)\u001b[0m     @     0x5652165f4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39697)\u001b[0m     @     0x5652165f5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39697)\u001b[0m     @     0x56521656a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39697)\u001b[0m     @     0x5652165f4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39697)\u001b[0m     @     0x5652165f5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39697)\u001b[0m     @     0x56521656a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39650)\u001b[0m     @     0x7f40c4ccf5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39650)\u001b[0m     @     0x7f40c53ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39650)\u001b[0m     @     0x7f40c788d8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39613)\u001b[0m     @     0x7f4ba1e3a4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39613)\u001b[0m     @     0x7f4ba430d8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39613)\u001b[0m     @     0x7f4ba1e3a4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39694)\u001b[0m     @     0x7f89ef11c8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39694)\u001b[0m     @     0x7f89ecc494f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39694)\u001b[0m     @     0x7f89f2cf479f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39694)\u001b[0m     @     0x5569a0ccdfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39694)\u001b[0m     @     0x5569a0c28b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39694)\u001b[0m     @     0x5569a0cb3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39694)\u001b[0m     @     0x5569a0cb4a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39694)\u001b[0m     @     0x5569a0c28bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39694)\u001b[0m     @     0x5569a0cb3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39694)\u001b[0m     @     0x5569a0cb4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39694)\u001b[0m     @     0x5569a0c29689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39643)\u001b[0m     @     0x7ee4dd93d5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39643)\u001b[0m     @     0x7ee4de0284f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39643)\u001b[0m     @     0x7ee4e04fb8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39644)\u001b[0m     @     0x7eeaf8c11d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39612)\u001b[0m     @     0x7fb92eaca8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39612)\u001b[0m     @     0x7fb92c5f74f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39612)\u001b[0m     @     0x7fb9326a279f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39612)\u001b[0m     @     0x558995beffd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39612)\u001b[0m     @     0x558995b4ab08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39650)\u001b[0m     @     0x7f40c53ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39650)\u001b[0m     @     0x7f40cb46579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39650)\u001b[0m     @     0x559b2d024fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39613)\u001b[0m     @     0x7f4ba7ee579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39613)\u001b[0m     @     0x55ede64d0fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39613)\u001b[0m     @     0x55ede642bb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39613)\u001b[0m     @     0x55ede64b6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39613)\u001b[0m     @     0x55ede64b7a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39613)\u001b[0m     @     0x55ede642bbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39613)\u001b[0m     @     0x55ede64b6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39613)\u001b[0m     @     0x55ede64b7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39613)\u001b[0m     @     0x55ede642c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39613)\u001b[0m     @     0x55ede64b6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39613)\u001b[0m     @     0x55ede64b7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39613)\u001b[0m     @     0x55ede642c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39613)\u001b[0m     @     0x55ede64b6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39613)\u001b[0m     @     0x55ede64b7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39613)\u001b[0m     @     0x55ede642c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39613)\u001b[0m     @     0x55ede64b6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39613)\u001b[0m     @     0x55ede64b7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39613)\u001b[0m     @     0x55ede642c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39694)\u001b[0m     @     0x5569a0cb3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39694)\u001b[0m     @     0x5569a0cb4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39694)\u001b[0m     @     0x5569a0c29689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39694)\u001b[0m     @     0x5569a0cb3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39694)\u001b[0m     @     0x5569a0cb4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39694)\u001b[0m     @     0x5569a0c29689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39694)\u001b[0m     @     0x5569a0cb3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39694)\u001b[0m     @     0x5569a0cb4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39694)\u001b[0m     @     0x5569a0c29689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39643)\u001b[0m     @     0x7ee4de0284f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39643)\u001b[0m     @     0x7ee4e40d379f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39643)\u001b[0m     @     0x556f33a99fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39643)\u001b[0m     @     0x556f339f4b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39643)\u001b[0m     @     0x556f33a7fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39643)\u001b[0m     @     0x556f33a80a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39643)\u001b[0m     @     0x556f339f4bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39643)\u001b[0m     @     0x556f33a7fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39643)\u001b[0m     @     0x556f33a80643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39643)\u001b[0m     @     0x556f339f5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39643)\u001b[0m     @     0x556f33a7fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39643)\u001b[0m     @     0x556f33a80643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39643)\u001b[0m     @     0x556f339f5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39643)\u001b[0m     @     0x556f33a7fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39643)\u001b[0m     @     0x556f33a80643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39643)\u001b[0m     @     0x556f339f5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39643)\u001b[0m     @     0x556f33a7fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39643)\u001b[0m     @     0x556f33a80643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39643)\u001b[0m     @     0x556f339f5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39644)\u001b[0m     @     0x7eeaf94f4b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39644)\u001b[0m     @     0x7eeaf9517c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39644)\u001b[0m     @     0x7eeaf89b9a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39612)\u001b[0m     @     0x558995bd5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39612)\u001b[0m     @     0x558995bd6a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39612)\u001b[0m     @     0x558995b4abfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39612)\u001b[0m     @     0x558995bd5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39612)\u001b[0m     @     0x558995bd6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39612)\u001b[0m     @     0x558995b4b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39612)\u001b[0m     @     0x558995bd5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39612)\u001b[0m     @     0x558995bd6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39612)\u001b[0m     @     0x558995b4b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39612)\u001b[0m     @     0x558995bd5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39612)\u001b[0m     @     0x558995bd6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39612)\u001b[0m     @     0x558995b4b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39612)\u001b[0m     @     0x558995bd5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39612)\u001b[0m     @     0x558995bd6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39612)\u001b[0m     @     0x558995b4b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39650)\u001b[0m     @     0x559b2cf7fb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39650)\u001b[0m     @     0x559b2d00abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39650)\u001b[0m     @     0x559b2d00ba20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39650)\u001b[0m     @     0x559b2cf7fbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39650)\u001b[0m     @     0x559b2d00abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39650)\u001b[0m     @     0x559b2d00b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39650)\u001b[0m     @     0x559b2cf80689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39650)\u001b[0m     @     0x559b2d00abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39650)\u001b[0m     @     0x559b2d00b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39650)\u001b[0m     @     0x559b2cf80689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39650)\u001b[0m     @     0x559b2d00abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39650)\u001b[0m     @     0x559b2d00b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39650)\u001b[0m     @     0x559b2cf80689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39650)\u001b[0m     @     0x559b2d00abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39650)\u001b[0m     @     0x559b2d00b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39650)\u001b[0m     @     0x559b2cf80689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39644)\u001b[0m     @     0x7eeaf89b7388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39644)\u001b[0m     @     0x7eeaf89b95a4 at::native::copy_()\n",
+      "2020-11-05 10:42:59,824\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff091d563401000000.\n",
+      "2020-11-05 10:42:59,827\tERROR trial_runner.py:567 -- Trial PPO_jss_env_a7d07_00000: Error processing event.\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/trial_runner.py\", line 515, in _process_trial\n",
+      "    result = self.trial_executor.fetch_result(trial)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/ray_trial_executor.py\", line 488, in fetch_result\n",
+      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1428, in get\n",
+      "    raise value.as_instanceof_cause()\n",
+      "ray.exceptions.RayTaskError: \u001b[36mray::PPO.train()\u001b[39m (pid=39695, ip=172.17.0.4)\n",
+      "  File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
+      "  File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\", line 516, in train\n",
+      "    raise e\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\", line 505, in train\n",
+      "    result = Trainable.train(self)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/trainable.py\", line 336, in train\n",
+      "    result = self.step()\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer_template.py\", line 134, in step\n",
+      "    res = next(self.train_exec_impl)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 756, in __next__\n",
+      "    return next(self.built_iterator)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 843, in apply_filter\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 843, in apply_filter\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  [Previous line repeated 1 more time]\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 876, in apply_flatten\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 828, in add_wait_hooks\n",
+      "    item = next(it)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  [Previous line repeated 1 more time]\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 466, in base_iterator\n",
+      "    actor_set.init_actors()\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 1238, in init_actors\n",
+      "    ray.get([a.par_iter_init.remote(self.transforms) for a in self.actors])\n",
+      "ray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 24.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/1 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 ERROR)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_a7d07_00000 | ERROR    |       |\n",
+      "+-------------------------+----------+-------+\n",
+      "Number of errored trials: 1\n",
+      "+-------------------------+--------------+-----------------------------------------------------------------------------------+\n",
+      "| Trial name              |   # failures | error file                                                                        |\n",
+      "|-------------------------+--------------+-----------------------------------------------------------------------------------|\n",
+      "| PPO_jss_env_a7d07_00000 |            1 | /root/ray_results/ppo-jss/PPO_jss_env_a7d07_00000_0_2020-11-05_10-42-52/error.txt |\n",
+      "+-------------------------+--------------+-----------------------------------------------------------------------------------+\n",
       "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 3372\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
-      "2020-10-14 20:43:46,790 - wandb.wandb_agent - INFO - Running runs: ['frw3hck3']\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201014_204343-frw3hck3/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201014_204343-frw3hck3/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:       nb_episodes 1\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   avg_best_result 163.86869\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_episode 163.86869\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:     best_timestep 3871\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:             _step 0\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:          _runtime 2\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        _timestamp 1602708225\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:       nb_episodes ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   avg_best_result ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_episode ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:     best_timestep ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:             _step ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:          _runtime ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        _timestamp ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mMTWR\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/frw3hck3\u001b[0m\n",
-      "2020-10-14 20:43:52,006 - wandb.wandb_agent - INFO - Cleaning up finished run: frw3hck3\n",
-      "2020-10-14 20:43:52,326 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-14 20:43:52,327 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tinstance_path: /JSS/JSS/env/instances/ta53\n",
-      "2020-10-14 20:43:52,329 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python MTWR.py --instance_path=/JSS/JSS/env/instances/ta53\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mMTWR\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/po3ygyxo\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/o0hyb863\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201014_204354-o0hyb863\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
+      "2020-11-05 10:42:59,835\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffffbdff035801000000.\n",
+      "2020-11-05 10:42:59,835\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffffe0497dac01000000.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 24.0/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/1 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 ERROR)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_a7d07_00000 | ERROR    |       |\n",
+      "+-------------------------+----------+-------+\n",
+      "Number of errored trials: 1\n",
+      "+-------------------------+--------------+-----------------------------------------------------------------------------------+\n",
+      "| Trial name              |   # failures | error file                                                                        |\n",
+      "|-------------------------+--------------+-----------------------------------------------------------------------------------|\n",
+      "| PPO_jss_env_a7d07_00000 |            1 | /root/ray_results/ppo-jss/PPO_jss_env_a7d07_00000_0_2020-11-05_10-42-52/error.txt |\n",
+      "+-------------------------+--------------+-----------------------------------------------------------------------------------+\n",
       "\n",
+      "2020-11-05 10:42:59,846\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff821ddf4301000000.\n",
+      "2020-11-05 10:42:59,846\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff4e242e9f01000000.\n",
+      "2020-11-05 10:42:59,846\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff9f3cc57a01000000.\n",
+      "2020-11-05 10:42:59,846\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff0314ce3001000000.\n",
+      "2020-11-05 10:42:59,846\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff43fb47bd01000000.\n",
+      "2020-11-05 10:42:59,846\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff252160a301000000.\n",
+      "2020-11-05 10:42:59,846\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff56c9ec1501000000.\n",
+      "2020-11-05 10:42:59,846\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffffa97540c201000000.\n",
+      "Traceback (most recent call last):\n",
+      "  File \"train.py\", line 74, in <module>\n",
+      "    train_func()\n",
+      "  File \"train.py\", line 56, in train_func\n",
+      "    analysis = tune.run(PPOTrainer, config=config, stop=stop, name=\"ppo-jss\")\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/tune.py\", line 427, in run\n",
+      "    raise TuneError(\"Trials did not complete\", incomplete_trials)\n",
+      "ray.tune.error.TuneError: ('Trials did not complete', [PPO_jss_env_a7d07_00000])\n",
       "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 3461\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
-      "2020-10-14 20:43:57,342 - wandb.wandb_agent - INFO - Running runs: ['o0hyb863']\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 39473\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 1.  Press ctrl-c to abort syncing.\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff59d91ef301000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffc2621d1401000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff4100f4fd01000000.'\n",
+      "Arguments: ()\n",
+      "\u001b[2m\u001b[36m(pid=39644)\u001b[0m     @     0x7eeaf90a44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39644)\u001b[0m     @     0x7eeafb5778de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39644)\u001b[0m     @     0x7eeaf90a44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39644)\u001b[0m     @     0x7eeaff14f79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39644)\u001b[0m     @     0x55f37e51bfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39644)\u001b[0m     @     0x55f37e476b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39644)\u001b[0m     @     0x55f37e501baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39644)\u001b[0m     @     0x55f37e502a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39644)\u001b[0m     @     0x55f37e476bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39644)\u001b[0m     @     0x55f37e501baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39644)\u001b[0m     @     0x55f37e502643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39644)\u001b[0m     @     0x55f37e477689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39644)\u001b[0m     @     0x55f37e501baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39644)\u001b[0m     @     0x55f37e502643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39644)\u001b[0m     @     0x55f37e477689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39644)\u001b[0m     @     0x55f37e501baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39644)\u001b[0m     @     0x55f37e502643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39644)\u001b[0m     @     0x55f37e477689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39644)\u001b[0m     @     0x55f37e501baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39644)\u001b[0m     @     0x55f37e502643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39644)\u001b[0m     @     0x55f37e477689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff90aded9101000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff31c3fed901000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff9d526f0201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff8168b55d01000000.'\n",
+      "Arguments: ()\n",
+      "\u001b[2m\u001b[36m(pid=39695)\u001b[0m E1105 10:42:59.820183 39695 40824 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=1f6f5417a7b065f9091d563401000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=091d563401000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=39695)\u001b[0m E1105 10:42:59.820341 39695 40824 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=e76b5820fbdeb0f2091d563401000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=091d563401000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=39695)\u001b[0m E1105 10:42:59.826892 39695 40824 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=137dbd5547ea6deabdff035801000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=bdff035801000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=39695)\u001b[0m E1105 10:42:59.827015 39695 40824 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=3f75a43fb9f70f24bdff035801000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=bdff035801000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=39695)\u001b[0m E1105 10:42:59.827437 39695 40824 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=170fdfd5d34985a7e0497dac01000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=e0497dac01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=39695)\u001b[0m E1105 10:42:59.827528 39695 40824 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=89f63fee54d6858ee0497dac01000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=e0497dac01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=39695)\u001b[0m E1105 10:42:59.831127 39695 40824 task_manager.cc:323] Task failed: IOError: cancelling all pending tasks of dead actor: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=150a9d56b40e3700bdff035801000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=bdff035801000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=39695)\u001b[0m E1105 10:42:59.832722 39695 40824 task_manager.cc:323] Task failed: IOError: cancelling all pending tasks of dead actor: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=c6f8a2750fad0b0de0497dac01000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=e0497dac01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=39695)\u001b[0m E1105 10:42:59.834437 39695 40824 task_manager.cc:323] Task failed: IOError: cancelling all pending tasks of dead actor: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=7249131d8582b825091d563401000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=091d563401000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=39695)\u001b[0m E1105 10:42:59.836563 39695 40824 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=8e79ac7e91b36714821ddf4301000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=821ddf4301000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=39695)\u001b[0m E1105 10:42:59.836680 39695 40824 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=428a4b4025d91890821ddf4301000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=821ddf4301000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=39695)\u001b[0m E1105 10:42:59.836827 39695 40824 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=38e2d2d27b716bfb821ddf4301000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=821ddf4301000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=39695)\u001b[0m E1105 10:42:59.837761 39695 40824 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=bf6cd9795b8b23124e242e9f01000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=4e242e9f01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=39695)\u001b[0m E1105 10:42:59.837864 39695 40824 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=c5da4173a1c517cf4e242e9f01000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=4e242e9f01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=39695)\u001b[0m E1105 10:42:59.837927 39695 40824 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=626c71df3976eafd4e242e9f01000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=4e242e9f01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=39695)\u001b[0m E1105 10:42:59.839777 39695 40824 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=efaf5dbfabc208739f3cc57a01000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=9f3cc57a01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=39695)\u001b[0m E1105 10:42:59.839887 39695 40824 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=b3b45bae970c41729f3cc57a01000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=9f3cc57a01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=39695)\u001b[0m E1105 10:42:59.839951 39695 40824 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=4f22c19b5f703db99f3cc57a01000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=9f3cc57a01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=39695)\u001b[0m E1105 10:42:59.840917 39695 40824 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=f4d9d8a5e202b0910314ce3001000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=0314ce3001000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=39695)\u001b[0m E1105 10:42:59.841089 39695 40824 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=8b0b449b9f08d0430314ce3001000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=0314ce3001000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=39695)\u001b[0m E1105 10:42:59.841166 39695 40824 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=ad47e6e6a1a1660b0314ce3001000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=0314ce3001000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=39695)\u001b[0m E1105 10:42:59.841842 39695 40824 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=1e9c16c25b494a4a43fb47bd01000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=43fb47bd01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=39695)\u001b[0m E1105 10:42:59.841972 39695 40824 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=61afdfe40390d0a343fb47bd01000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=43fb47bd01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=39695)\u001b[0m E1105 10:42:59.842051 39695 40824 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=10a4a4113c6c36ea43fb47bd01000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=43fb47bd01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=39695)\u001b[0m E1105 10:42:59.842756 39695 40824 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=3e4916e36cb3ce60252160a301000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=252160a301000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=39695)\u001b[0m E1105 10:42:59.842847 39695 40824 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=c2d663ba592886f5252160a301000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=252160a301000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=39695)\u001b[0m E1105 10:42:59.842905 39695 40824 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=457f03c785986c89252160a301000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=252160a301000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=39695)\u001b[0m E1105 10:42:59.843530 39695 40824 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=4db1cba171d56c3356c9ec1501000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=56c9ec1501000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=39695)\u001b[0m E1105 10:42:59.843609 39695 40824 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=5cf29c5b7b7ed08d56c9ec1501000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=56c9ec1501000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=39695)\u001b[0m E1105 10:42:59.843677 39695 40824 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=9d0a2db204e8f81056c9ec1501000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=56c9ec1501000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=39695)\u001b[0m E1105 10:42:59.845927 39695 40824 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=fde3d5eda9f525d7a97540c201000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=a97540c201000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=39695)\u001b[0m E1105 10:42:59.846031 39695 40824 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=d16c21eef3935840a97540c201000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=a97540c201000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=39695)\u001b[0m E1105 10:42:59.846101 39695 40824 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=d88ec84d5baca957a97540c201000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=a97540c201000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=39695)\u001b[0m E1105 10:42:59.848564 39695 40824 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=8b485cbbeaa005a559d91ef301000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=59d91ef301000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=39695)\u001b[0m E1105 10:42:59.848660 39695 40824 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=ca546fa1af7e507159d91ef301000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=59d91ef301000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=39695)\u001b[0m E1105 10:42:59.848716 39695 40824 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=fd2b07e19848a86a59d91ef301000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=59d91ef301000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=39695)\u001b[0m E1105 10:42:59.850143 39695 40824 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=9ecf84e34eb8e61dc2621d1401000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=c2621d1401000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=39695)\u001b[0m E1105 10:42:59.850251 39695 40824 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=f3cba62d4c01820bc2621d1401000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=c2621d1401000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=39695)\u001b[0m E1105 10:42:59.850349 39695 40824 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=8fbf1bd7de98d288c2621d1401000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=c2621d1401000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffb2413f7201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff58dd50c101000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff3a9488b101000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff99d0343201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffdd5654aa01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff7ef9157101000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff3166f9e301000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff7f7c936001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff018c9dac01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff51728d3301000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffa4f7314201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff5843697701000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task fffffffffffffffff257d30801000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffee8852f401000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff1e7ae67b01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff20d842ad01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff19fd5b4901000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff75f329e601000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff0aeae6a301000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff50168bc201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff310e963d01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff04668d8f01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffc3083e0c01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff80993fa801000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff32335d4e01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffeca600ef01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffef1af81501000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffda2cd21f01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff4f9bfece01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task fffffffffffffffff120020c01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff452e714401000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff8edbbd3001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task fffffffffffffffff392716d01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff2d1a71ea01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff8f9a5fc701000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff34cbbac201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffa7ad1db301000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff71ca01c001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff0d557f6601000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffe9f6a7cf01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff5cc87e2501000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff302122d001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task fffffffffffffffff0f72e3901000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffd989d1f001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffd8f83c3801000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff702ed69e01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff41e0fbff01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffffefbd9801000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffb3cace0801000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffd784bf0601000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff8d06128001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff0fae11b201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff10f667b001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff61dc472601000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff244a7d1001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffccf343cc01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff358dd45601000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff8cd168e101000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff7b2861ac01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff14da135201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff7a508a7a01000000.'\n",
+      "Arguments: ()\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201014_204354-o0hyb863/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201014_204354-o0hyb863/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:       nb_episodes 1\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   avg_best_result 180.92929\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_episode 180.92929\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:     best_timestep 3790\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:             _step 0\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:          _runtime 1\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        _timestamp 1602708235\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:       nb_episodes ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   avg_best_result ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_episode ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:     best_timestep ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:             _step ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:          _runtime ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        _timestamp ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201105_104247-yih09ayf/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201105_104247-yih09ayf/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mMTWR\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/o0hyb863\u001b[0m\n",
-      "2020-10-14 20:44:02,563 - wandb.wandb_agent - INFO - Cleaning up finished run: o0hyb863\n",
-      "2020-10-14 20:44:02,910 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-14 20:44:02,911 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tinstance_path: /JSS/JSS/env/instances/ta54\n",
-      "2020-10-14 20:44:02,913 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python MTWR.py --instance_path=/JSS/JSS/env/instances/ta54\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33msuper-sweep-1\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/yih09ayf\u001b[0m\n",
+      "2020-11-05 10:43:11,297 - wandb.wandb_agent - INFO - Cleaning up finished run: yih09ayf\n",
+      "2020-11-05 10:43:11,603 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-11-05 10:43:11,603 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tinstance_path: /JSS/JSS/env/instances/ta41\n",
+      "2020-11-05 10:43:11,605 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --instance_path=/JSS/JSS/env/instances/ta41\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.9 is available!  To upgrade, please run:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
+      "2020-11-05 10:43:16,623 - wandb.wandb_agent - INFO - Running runs: ['1kkcunv8']\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mMTWR\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/po3ygyxo\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/802owiob\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201014_204405-802owiob\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33matomic-sweep-2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/sweeps/72qf0qyh\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/1kkcunv8\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201105_104313-1kkcunv8\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
+      "2020-11-05 10:43:17,282\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
+      "== Status ==\n",
+      "Memory usage on this node: 12.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/1 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_b77b2_00000 | RUNNING  |       |\n",
+      "+-------------------------+----------+-------+\n",
       "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 3552\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
-      "2020-10-14 20:44:07,929 - wandb.wandb_agent - INFO - Running runs: ['802owiob']\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201014_204405-802owiob/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201014_204405-802owiob/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:       nb_episodes 1\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   avg_best_result 201.68687\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_episode 201.68687\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:     best_timestep 3601\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:             _step 0\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:          _runtime 1\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        _timestamp 1602708246\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:       nb_episodes ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   avg_best_result ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_episode ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:     best_timestep ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:             _step ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:          _runtime ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        _timestamp ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mMTWR\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/802owiob\u001b[0m\n",
-      "2020-10-14 20:44:13,147 - wandb.wandb_agent - INFO - Cleaning up finished run: 802owiob\n",
-      "2020-10-14 20:44:13,451 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-14 20:44:13,451 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tinstance_path: /JSS/JSS/env/instances/ta55\n",
-      "2020-10-14 20:44:13,453 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python MTWR.py --instance_path=/JSS/JSS/env/instances/ta55\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mMTWR\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/po3ygyxo\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/ix8moovg\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201014_204415-ix8moovg\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
+      "\u001b[2m\u001b[36m(pid=41234)\u001b[0m 2020-11-05 10:43:20,090\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=41234)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/torch/cuda/__init__.py:125: UserWarning: \n",
+      "\u001b[2m\u001b[36m(pid=41234)\u001b[0m GeForce RTX 2080 Ti with CUDA capability sm_75 is not compatible with the current PyTorch installation.\n",
+      "\u001b[2m\u001b[36m(pid=41234)\u001b[0m The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 compute_37.\n",
+      "\u001b[2m\u001b[36m(pid=41234)\u001b[0m If you want to use the GeForce RTX 2080 Ti GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
+      "\u001b[2m\u001b[36m(pid=41234)\u001b[0m \n",
+      "\u001b[2m\u001b[36m(pid=41234)\u001b[0m   warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n",
+      "\u001b[2m\u001b[36m(pid=41148)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41148)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41148)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41183)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41183)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41183)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41212)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41212)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41212)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41212)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41212)\u001b[0m *** SIGSEGV (@0x0) received by PID 41212 (TID 0x7f05183d3700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41212)\u001b[0m     @     0x7f0517fac390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41212)\u001b[0m     @     0x7ed617eb6f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41212)\u001b[0m     @     0x7ed6175e17db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41212)\u001b[0m     @     0x7ed6175e48f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41212)\u001b[0m     @     0x7ed6175e4ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41212)\u001b[0m     @     0x7ed6175e4d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41212)\u001b[0m     @     0x7ed617ec7b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41212)\u001b[0m     @     0x7ed617eeac1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41212)\u001b[0m     @     0x7ed61738ca93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41212)\u001b[0m     @     0x7ed61738a388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41273)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41273)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41273)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41273)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41273)\u001b[0m *** SIGSEGV (@0x0) received by PID 41273 (TID 0x7fd16e7ef700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41273)\u001b[0m     @     0x7fd16e3c8390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41273)\u001b[0m     @     0x7fa26e34bf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41273)\u001b[0m     @     0x7fa26da767db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41273)\u001b[0m     @     0x7fa26da798f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41273)\u001b[0m     @     0x7fa26da79ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41273)\u001b[0m     @     0x7fa26da79d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41273)\u001b[0m     @     0x7fa26e35cb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41273)\u001b[0m     @     0x7fa26e37fc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41273)\u001b[0m     @     0x7fa26d821a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41273)\u001b[0m     @     0x7fa26d81f388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41207)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41207)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41207)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41250)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41250)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41250)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41250)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41250)\u001b[0m *** SIGSEGV (@0x0) received by PID 41250 (TID 0x7f04e2340700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41250)\u001b[0m     @     0x7f04e1f19390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41250)\u001b[0m     @     0x7ed5e1e24f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41250)\u001b[0m     @     0x7ed5e154f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41250)\u001b[0m     @     0x7ed5e15528f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41250)\u001b[0m     @     0x7ed5e1552ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41250)\u001b[0m     @     0x7ed5e1552d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41250)\u001b[0m     @     0x7ed5e1e35b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41250)\u001b[0m     @     0x7ed5e1e58c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41250)\u001b[0m     @     0x7ed5e12faa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41250)\u001b[0m     @     0x7ed5e12f8388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41214)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41214)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41214)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41214)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41214)\u001b[0m *** SIGSEGV (@0x0) received by PID 41214 (TID 0x7f97110b3700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41149)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41149)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41149)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41149)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41149)\u001b[0m *** SIGSEGV (@0x0) received by PID 41149 (TID 0x7f4c08910700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41239)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41239)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41239)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41239)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41239)\u001b[0m *** SIGSEGV (@0x0) received by PID 41239 (TID 0x7fe17016e700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41239)\u001b[0m     @     0x7fe16fd47390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41239)\u001b[0m     @     0x7fb26fbf7f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41239)\u001b[0m     @     0x7fb26f3227db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41239)\u001b[0m     @     0x7fb26f3258f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41239)\u001b[0m     @     0x7fb26f325ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41239)\u001b[0m     @     0x7fb26f325d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41239)\u001b[0m     @     0x7fb26fc08b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41239)\u001b[0m     @     0x7fb26fc2bc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41239)\u001b[0m     @     0x7fb26f0cda93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41239)\u001b[0m     @     0x7fb26f0cb388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41237)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41237)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41237)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41237)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41237)\u001b[0m *** SIGSEGV (@0x0) received by PID 41237 (TID 0x7f0c97298700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41237)\u001b[0m     @     0x7f0c96e71390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41237)\u001b[0m     @     0x7edd96e26f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41237)\u001b[0m     @     0x7edd965517db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41237)\u001b[0m     @     0x7edd965548f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41237)\u001b[0m     @     0x7edd96554ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41237)\u001b[0m     @     0x7edd96554d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41184)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41184)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41184)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41184)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41184)\u001b[0m *** SIGSEGV (@0x0) received by PID 41184 (TID 0x7f019c440700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41150)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41150)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41150)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41150)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41227)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41227)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41227)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41174)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41174)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41174)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41226)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41226)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41226)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41226)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41226)\u001b[0m *** SIGSEGV (@0x0) received by PID 41226 (TID 0x7f1c32c83700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41226)\u001b[0m     @     0x7f1c3285c390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41226)\u001b[0m     @     0x7eed3270af90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41226)\u001b[0m     @     0x7eed31e357db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41226)\u001b[0m     @     0x7eed31e388f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41226)\u001b[0m     @     0x7eed31e38ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41226)\u001b[0m     @     0x7eed31e38d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41226)\u001b[0m     @     0x7eed3271bb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41215)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41215)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41215)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41215)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41215)\u001b[0m *** SIGSEGV (@0x0) received by PID 41215 (TID 0x7f0e4dfee700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41215)\u001b[0m     @     0x7f0e4dbc7390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41215)\u001b[0m     @     0x7edf4db5ff90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41162)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41162)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41162)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41162)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41162)\u001b[0m *** SIGSEGV (@0x0) received by PID 41162 (TID 0x7fdcf2c09700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41253)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41253)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41253)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41253)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41253)\u001b[0m *** SIGSEGV (@0x0) received by PID 41253 (TID 0x7f201efec700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41253)\u001b[0m     @     0x7f201ebc5390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41253)\u001b[0m     @     0x7ef11ea21f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41253)\u001b[0m     @     0x7ef11e14c7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41253)\u001b[0m     @     0x7ef11e14f8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41253)\u001b[0m     @     0x7ef11e14fad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41253)\u001b[0m     @     0x7ef11e14fd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41253)\u001b[0m     @     0x7ef11ea32b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41253)\u001b[0m     @     0x7ef11ea55c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41253)\u001b[0m     @     0x7ef11def7a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41253)\u001b[0m     @     0x7ef11def5388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41253)\u001b[0m     @     0x7ef11def75a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41225)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41225)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41225)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41225)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41225)\u001b[0m *** SIGSEGV (@0x0) received by PID 41225 (TID 0x7fab27c0c700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41225)\u001b[0m     @     0x7fab277e5390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41225)\u001b[0m     @     0x7f7c2761ff90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41225)\u001b[0m     @     0x7f7c26d4a7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41225)\u001b[0m     @     0x7f7c26d4d8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41225)\u001b[0m     @     0x7f7c26d4dad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41225)\u001b[0m     @     0x7f7c26d4dd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41225)\u001b[0m     @     0x7f7c27630b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41225)\u001b[0m     @     0x7f7c27653c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41225)\u001b[0m     @     0x7f7c26af5a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41225)\u001b[0m     @     0x7f7c26af3388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41225)\u001b[0m     @     0x7f7c26af55a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41270)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41270)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41270)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41270)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41270)\u001b[0m *** SIGSEGV (@0x0) received by PID 41270 (TID 0x7fbf915d9700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41270)\u001b[0m     @     0x7fbf911b2390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41270)\u001b[0m     @     0x7f9091166f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41270)\u001b[0m     @     0x7f90908917db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41270)\u001b[0m     @     0x7f90908948f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41270)\u001b[0m     @     0x7f9090894ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41270)\u001b[0m     @     0x7f9090894d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41270)\u001b[0m     @     0x7f9091177b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41270)\u001b[0m     @     0x7f909119ac1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41270)\u001b[0m     @     0x7f909063ca93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41270)\u001b[0m     @     0x7f909063a388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41270)\u001b[0m     @     0x7f909063c5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41166)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41166)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41166)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41166)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41166)\u001b[0m *** SIGSEGV (@0x0) received by PID 41166 (TID 0x7fd8fff6d700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41267)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41267)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41267)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41267)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41267)\u001b[0m *** SIGSEGV (@0x0) received by PID 41267 (TID 0x7f77b8e5a700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41267)\u001b[0m     @     0x7f77b8a33390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41267)\u001b[0m     @     0x7f48b8774f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41267)\u001b[0m     @     0x7f48b7e9f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41267)\u001b[0m     @     0x7f48b7ea28f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41267)\u001b[0m     @     0x7f48b7ea2ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41267)\u001b[0m     @     0x7f48b7ea2d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41267)\u001b[0m     @     0x7f48b8785b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41267)\u001b[0m     @     0x7f48b87a8c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41267)\u001b[0m     @     0x7f48b7c4aa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41267)\u001b[0m     @     0x7f48b7c48388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41267)\u001b[0m     @     0x7f48b7c4a5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41147)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41147)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41147)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41147)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41147)\u001b[0m *** SIGSEGV (@0x0) received by PID 41147 (TID 0x7ff87cdad700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41147)\u001b[0m     @     0x7ff87c986390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41144)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41144)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41144)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41236)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41236)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41236)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41210)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41210)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41210)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41217)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41217)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41217)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41247)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41247)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41247)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41247)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41247)\u001b[0m *** SIGSEGV (@0x0) received by PID 41247 (TID 0x7fef6f0d1700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41247)\u001b[0m     @     0x7fef6ecaa390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41247)\u001b[0m     @     0x7fc06ea21f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41247)\u001b[0m     @     0x7fc06e14c7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41231)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41231)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41231)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41231)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41231)\u001b[0m *** SIGSEGV (@0x0) received by PID 41231 (TID 0x7f083a125700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41159)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41159)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41159)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41159)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41159)\u001b[0m *** SIGSEGV (@0x0) received by PID 41159 (TID 0x7fe65c20a700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41159)\u001b[0m     @     0x7fe65bde3390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41233)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41233)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41233)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41233)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41233)\u001b[0m *** SIGSEGV (@0x0) received by PID 41233 (TID 0x7fe8e1a8f700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41233)\u001b[0m     @     0x7fe8e1668390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41233)\u001b[0m     @     0x7fb9e15e2f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41233)\u001b[0m     @     0x7fb9e0d0d7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41233)\u001b[0m     @     0x7fb9e0d108f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41233)\u001b[0m     @     0x7fb9e0d10ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41233)\u001b[0m     @     0x7fb9e0d10d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41233)\u001b[0m     @     0x7fb9e15f3b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41233)\u001b[0m     @     0x7fb9e1616c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41233)\u001b[0m     @     0x7fb9e0ab8a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41233)\u001b[0m     @     0x7fb9e0ab6388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41233)\u001b[0m     @     0x7fb9e0ab85a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41160)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41160)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41160)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41160)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41160)\u001b[0m *** SIGSEGV (@0x0) received by PID 41160 (TID 0x7fa7d8755700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41160)\u001b[0m     @     0x7fa7d832e390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41151)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41151)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41151)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41151)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41151)\u001b[0m *** SIGSEGV (@0x0) received by PID 41151 (TID 0x7f283f504700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41216)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41216)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41216)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41216)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41216)\u001b[0m *** SIGSEGV (@0x0) received by PID 41216 (TID 0x7fec9fadd700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41216)\u001b[0m     @     0x7fec9f6b6390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41265)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41265)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41265)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41265)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41265)\u001b[0m *** SIGSEGV (@0x0) received by PID 41265 (TID 0x7fa4765f9700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41265)\u001b[0m     @     0x7fa4761d2390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41265)\u001b[0m     @     0x7f757613af90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41265)\u001b[0m     @     0x7f75758657db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41265)\u001b[0m     @     0x7f75758688f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41265)\u001b[0m     @     0x7f7575868ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41265)\u001b[0m     @     0x7f7575868d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41265)\u001b[0m     @     0x7f757614bb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41265)\u001b[0m     @     0x7f757616ec1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41265)\u001b[0m     @     0x7f7575610a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41265)\u001b[0m     @     0x7f757560e388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41265)\u001b[0m     @     0x7f75756105a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41265)\u001b[0m     @     0x7f7575cfb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41277)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41277)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41277)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41277)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41277)\u001b[0m *** SIGSEGV (@0x0) received by PID 41277 (TID 0x7f12f59f6700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41277)\u001b[0m     @     0x7f12f55cf390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41277)\u001b[0m     @     0x7ee3f5564f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41277)\u001b[0m     @     0x7ee3f4c8f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41277)\u001b[0m     @     0x7ee3f4c928f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41277)\u001b[0m     @     0x7ee3f4c92ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41277)\u001b[0m     @     0x7ee3f4c92d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41277)\u001b[0m     @     0x7ee3f5575b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41277)\u001b[0m     @     0x7ee3f5598c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41277)\u001b[0m     @     0x7ee3f4a3aa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41277)\u001b[0m     @     0x7ee3f4a38388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41277)\u001b[0m     @     0x7ee3f4a3a5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41277)\u001b[0m     @     0x7ee3f51254f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41281)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41281)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41281)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41281)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41281)\u001b[0m *** SIGSEGV (@0x0) received by PID 41281 (TID 0x7f4335908700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41281)\u001b[0m     @     0x7f43354e1390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41281)\u001b[0m     @     0x7f14354a3f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41281)\u001b[0m     @     0x7f1434bce7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41281)\u001b[0m     @     0x7f1434bd18f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41281)\u001b[0m     @     0x7f1434bd1ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41281)\u001b[0m     @     0x7f1434bd1d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41281)\u001b[0m     @     0x7f14354b4b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41281)\u001b[0m     @     0x7f14354d7c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41281)\u001b[0m     @     0x7f1434979a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41281)\u001b[0m     @     0x7f1434977388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41272)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41272)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41272)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41272)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41272)\u001b[0m *** SIGSEGV (@0x0) received by PID 41272 (TID 0x7ff268a6e700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41272)\u001b[0m     @     0x7ff268647390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41272)\u001b[0m     @     0x7fc3683e3f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41272)\u001b[0m     @     0x7fc367b0e7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41272)\u001b[0m     @     0x7fc367b118f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41272)\u001b[0m     @     0x7fc367b11ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41272)\u001b[0m     @     0x7fc367b11d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41272)\u001b[0m     @     0x7fc3683f4b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41272)\u001b[0m     @     0x7fc368417c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41272)\u001b[0m     @     0x7fc3678b9a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41272)\u001b[0m     @     0x7fc3678b7388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41272)\u001b[0m     @     0x7fc3678b95a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41260)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41260)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41260)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41260)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41260)\u001b[0m *** SIGSEGV (@0x0) received by PID 41260 (TID 0x7f0feec7c700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41260)\u001b[0m     @     0x7f0fee855390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41260)\u001b[0m     @     0x7ee0ee70af90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41260)\u001b[0m     @     0x7ee0ede357db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41260)\u001b[0m     @     0x7ee0ede388f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41260)\u001b[0m     @     0x7ee0ede38ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41260)\u001b[0m     @     0x7ee0ede38d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41260)\u001b[0m     @     0x7ee0ee71bb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41260)\u001b[0m     @     0x7ee0ee73ec1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41260)\u001b[0m     @     0x7ee0edbe0a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41260)\u001b[0m     @     0x7ee0edbde388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41260)\u001b[0m     @     0x7ee0edbe05a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41157)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41157)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41157)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41157)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41157)\u001b[0m *** SIGSEGV (@0x0) received by PID 41157 (TID 0x7f02a1791700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41157)\u001b[0m     @     0x7f02a136a390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41256)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41256)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41256)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41256)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41232)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41232)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41232)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41206)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41206)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41206)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41206)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41206)\u001b[0m *** SIGSEGV (@0x0) received by PID 41206 (TID 0x7fa472259700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41171)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41171)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41171)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41158)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41158)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41158)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41158)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41158)\u001b[0m *** SIGSEGV (@0x0) received by PID 41158 (TID 0x7f57008a7700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41152)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41152)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41152)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41152)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41152)\u001b[0m *** SIGSEGV (@0x0) received by PID 41152 (TID 0x7fa4fd67c700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41152)\u001b[0m     @     0x7fa4fd255390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41153)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41153)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41153)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41153)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41153)\u001b[0m *** SIGSEGV (@0x0) received by PID 41153 (TID 0x7f3e82244700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41222)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41222)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41222)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41155)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41155)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41155)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41155)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41155)\u001b[0m *** SIGSEGV (@0x0) received by PID 41155 (TID 0x7fe7c9e0d700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41155)\u001b[0m     @     0x7fe7c99e6390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41155)\u001b[0m     @     0x7fb8c9701f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41145)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41145)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41145)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41145)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41145)\u001b[0m *** SIGSEGV (@0x0) received by PID 41145 (TID 0x7f5a39ec6700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41145)\u001b[0m     @     0x7f5a39a9f390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41145)\u001b[0m     @     0x7f2b39a0af90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41145)\u001b[0m     @     0x7f2b391357db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41220)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41220)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41220)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41220)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41220)\u001b[0m *** SIGSEGV (@0x0) received by PID 41220 (TID 0x7f156d911700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41220)\u001b[0m     @     0x7f156d4ea390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41284)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41284)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41284)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41229)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41229)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41229)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41229)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41229)\u001b[0m *** SIGSEGV (@0x0) received by PID 41229 (TID 0x7faf23f41700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41229)\u001b[0m     @     0x7faf23b1a390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41229)\u001b[0m     @     0x7f8023ab5f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41235)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41235)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41235)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41235)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41235)\u001b[0m *** SIGSEGV (@0x0) received by PID 41235 (TID 0x7ffaf18d6700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41187)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41187)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41187)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41187)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41187)\u001b[0m *** SIGSEGV (@0x0) received by PID 41187 (TID 0x7f7cb2bc2700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41187)\u001b[0m     @     0x7f7cb279b390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41228)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41228)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41228)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41228)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41228)\u001b[0m *** SIGSEGV (@0x0) received by PID 41228 (TID 0x7f5d957d1700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41228)\u001b[0m     @     0x7f5d953aa390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41228)\u001b[0m     @     0x7f2e9533af90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41228)\u001b[0m     @     0x7f2e94a657db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41240)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41240)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41240)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41240)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41240)\u001b[0m *** SIGSEGV (@0x0) received by PID 41240 (TID 0x7f7313c8e700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41240)\u001b[0m     @     0x7f7313867390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41240)\u001b[0m     @     0x7f4413751f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41224)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41224)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41224)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41224)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41224)\u001b[0m *** SIGSEGV (@0x0) received by PID 41224 (TID 0x7fb0d726f700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41177)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41177)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41177)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41177)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41177)\u001b[0m *** SIGSEGV (@0x0) received by PID 41177 (TID 0x7f82415b9700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41177)\u001b[0m     @     0x7f8241192390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41249)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41249)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41249)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41249)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41249)\u001b[0m *** SIGSEGV (@0x0) received by PID 41249 (TID 0x7fae97f98700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41249)\u001b[0m     @     0x7fae97b71390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41249)\u001b[0m     @     0x7f7f97af5f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41249)\u001b[0m     @     0x7f7f972207db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41161)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41161)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41161)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41161)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41161)\u001b[0m *** SIGSEGV (@0x0) received by PID 41161 (TID 0x7f4f273ee700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41161)\u001b[0m     @     0x7f4f26fc7390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41161)\u001b[0m     @     0x7f2026f13f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41161)\u001b[0m     @     0x7f202663e7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41163)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41163)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41163)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41163)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41163)\u001b[0m *** SIGSEGV (@0x0) received by PID 41163 (TID 0x7f72036b8700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41163)\u001b[0m     @     0x7f7203291390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41241)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41241)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41241)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41213)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41213)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41213)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41213)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41213)\u001b[0m *** SIGSEGV (@0x0) received by PID 41213 (TID 0x7f8db612f700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41246)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41246)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41246)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41246)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41246)\u001b[0m *** SIGSEGV (@0x0) received by PID 41246 (TID 0x7f163ffaf700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41279)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41279)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41279)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41279)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41279)\u001b[0m *** SIGSEGV (@0x0) received by PID 41279 (TID 0x7f72466a0700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41279)\u001b[0m     @     0x7f7246279390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41279)\u001b[0m     @     0x7f434613af90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41279)\u001b[0m     @     0x7f43458657db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41209)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41209)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41209)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41178)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41178)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41178)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41178)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41178)\u001b[0m *** SIGSEGV (@0x0) received by PID 41178 (TID 0x7f2773545700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41178)\u001b[0m     @     0x7f277311e390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41218)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41218)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41218)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41218)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41218)\u001b[0m *** SIGSEGV (@0x0) received by PID 41218 (TID 0x7f57c2e50700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41218)\u001b[0m     @     0x7f57c2a29390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41218)\u001b[0m     @     0x7f28c299ff90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41218)\u001b[0m     @     0x7f28c20ca7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41262)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41262)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41262)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41262)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41262)\u001b[0m *** SIGSEGV (@0x0) received by PID 41262 (TID 0x7fc8f378b700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41262)\u001b[0m     @     0x7fc8f3364390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41262)\u001b[0m     @     0x7f99f3229f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41262)\u001b[0m     @     0x7f99f29547db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41148)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41148)\u001b[0m *** SIGSEGV (@0x0) received by PID 41148 (TID 0x7f6378d28700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41148)\u001b[0m     @     0x7f6378901390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41148)\u001b[0m     @     0x7f3475940f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41148)\u001b[0m     @     0x7f347506b7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41148)\u001b[0m     @     0x7f347506e8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41183)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41183)\u001b[0m *** SIGSEGV (@0x0) received by PID 41183 (TID 0x7fd74b8d1700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41183)\u001b[0m     @     0x7fd74b4aa390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41183)\u001b[0m     @     0x7fa84b43af90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41183)\u001b[0m     @     0x7fa84ab657db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41212)\u001b[0m     @     0x7ed61738c5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41212)\u001b[0m     @     0x7ed617a774f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41212)\u001b[0m     @     0x7ed619f4a8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41273)\u001b[0m     @     0x7fa26d8215a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41273)\u001b[0m     @     0x7fa26df0c4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41273)\u001b[0m     @     0x7fa2703df8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41207)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41207)\u001b[0m *** SIGSEGV (@0x0) received by PID 41207 (TID 0x7fac48681700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41207)\u001b[0m     @     0x7fac4825a390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41207)\u001b[0m     @     0x7f7d48101f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41207)\u001b[0m     @     0x7f7d4782c7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41207)\u001b[0m     @     0x7f7d4782f8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41250)\u001b[0m     @     0x7ed5e12fa5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41250)\u001b[0m     @     0x7ed5e19e54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41250)\u001b[0m     @     0x7ed5e3eb88de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41250)\u001b[0m     @     0x7ed5e19e54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41250)\u001b[0m     @     0x7ed5e7a9079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41250)\u001b[0m     @     0x564bb7b8afd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41250)\u001b[0m     @     0x564bb7ae5b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41250)\u001b[0m     @     0x564bb7b70baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41250)\u001b[0m     @     0x564bb7b71a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41250)\u001b[0m     @     0x564bb7ae5bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41250)\u001b[0m     @     0x564bb7b70baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41250)\u001b[0m     @     0x564bb7b71643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41214)\u001b[0m     @     0x7f9710c8c390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41214)\u001b[0m     @     0x7f681097ff90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41214)\u001b[0m     @     0x7f68100aa7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41214)\u001b[0m     @     0x7f68100ad8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41149)\u001b[0m     @     0x7f4c084e9390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41149)\u001b[0m     @     0x7f1d08475f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41149)\u001b[0m     @     0x7f1d07ba07db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41149)\u001b[0m     @     0x7f1d07ba38f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41239)\u001b[0m     @     0x7fb26f0cd5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41239)\u001b[0m     @     0x7fb26f7b84f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41239)\u001b[0m     @     0x7fb271c8b8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41237)\u001b[0m     @     0x7edd96e37b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41237)\u001b[0m     @     0x7edd96e5ac1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41237)\u001b[0m     @     0x7edd962fca93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41237)\u001b[0m     @     0x7edd962fa388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41184)\u001b[0m     @     0x7f019c019390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41184)\u001b[0m     @     0x7ed29be0bf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41184)\u001b[0m     @     0x7ed29b5367db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41184)\u001b[0m     @     0x7ed29b5398f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41150)\u001b[0m *** SIGSEGV (@0x0) received by PID 41150 (TID 0x7fd5231c9700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41150)\u001b[0m     @     0x7fd522da2390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41150)\u001b[0m     @     0x7fa622cfcf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41150)\u001b[0m     @     0x7fa6224277db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41150)\u001b[0m     @     0x7fa62242a8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41227)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41227)\u001b[0m *** SIGSEGV (@0x0) received by PID 41227 (TID 0x7ffad5657700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41227)\u001b[0m     @     0x7ffad5230390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41227)\u001b[0m     @     0x7fcbd50b5f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41227)\u001b[0m     @     0x7fcbd47e07db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41174)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41174)\u001b[0m *** SIGSEGV (@0x0) received by PID 41174 (TID 0x7f65448c1700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41174)\u001b[0m     @     0x7f654449a390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41174)\u001b[0m     @     0x7f36443e3f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41174)\u001b[0m     @     0x7f3643b0e7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41226)\u001b[0m     @     0x7eed3273ec1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41226)\u001b[0m     @     0x7eed31be0a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41226)\u001b[0m     @     0x7eed31bde388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41226)\u001b[0m     @     0x7eed31be05a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41215)\u001b[0m     @     0x7edf4d28a7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41215)\u001b[0m     @     0x7edf4d28d8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41215)\u001b[0m     @     0x7edf4d28dad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41162)\u001b[0m     @     0x7fdcf27e2390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41162)\u001b[0m     @     0x7fadf257cf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41162)\u001b[0m     @     0x7fadf1ca77db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41162)\u001b[0m     @     0x7fadf1caa8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41253)\u001b[0m     @     0x7ef11e5e24f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41253)\u001b[0m     @     0x7ef120ab58de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41253)\u001b[0m     @     0x7ef11e5e24f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41253)\u001b[0m     @     0x7ef12468d79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41253)\u001b[0m     @     0x564073bf8fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41253)\u001b[0m     @     0x564073b53b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41253)\u001b[0m     @     0x564073bdebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41253)\u001b[0m     @     0x564073bdfa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41253)\u001b[0m     @     0x564073b53bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41253)\u001b[0m     @     0x564073bdebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41253)\u001b[0m     @     0x564073bdf643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41253)\u001b[0m     @     0x564073b54689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41253)\u001b[0m     @     0x564073bdebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41253)\u001b[0m     @     0x564073bdf643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41253)\u001b[0m     @     0x564073b54689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41253)\u001b[0m     @     0x564073bdebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41253)\u001b[0m     @     0x564073bdf643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41253)\u001b[0m     @     0x564073b54689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41253)\u001b[0m     @     0x564073bdebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41253)\u001b[0m     @     0x564073bdf643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41253)\u001b[0m     @     0x564073b54689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41225)\u001b[0m     @     0x7f7c271e04f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41225)\u001b[0m     @     0x7f7c296b38de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41225)\u001b[0m     @     0x7f7c271e04f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41225)\u001b[0m     @     0x7f7c2d28b79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41225)\u001b[0m     @     0x55c486a92fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41225)\u001b[0m     @     0x55c4869edb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41225)\u001b[0m     @     0x55c486a78baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41225)\u001b[0m     @     0x55c486a79a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41225)\u001b[0m     @     0x55c4869edbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41270)\u001b[0m     @     0x7f9090d274f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41270)\u001b[0m     @     0x7f90931fa8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41270)\u001b[0m     @     0x7f9090d274f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41270)\u001b[0m     @     0x7f9096dd279f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41270)\u001b[0m     @     0x55f4a9204fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41270)\u001b[0m     @     0x55f4a915fb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41270)\u001b[0m     @     0x55f4a91eabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41270)\u001b[0m     @     0x55f4a91eba20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41270)\u001b[0m     @     0x55f4a915fbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41270)\u001b[0m     @     0x55f4a91eabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41270)\u001b[0m     @     0x55f4a91eb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41270)\u001b[0m     @     0x55f4a9160689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41270)\u001b[0m     @     0x55f4a91eabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41270)\u001b[0m     @     0x55f4a91eb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41270)\u001b[0m     @     0x55f4a9160689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41270)\u001b[0m     @     0x55f4a91eabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41270)\u001b[0m     @     0x55f4a91eb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41270)\u001b[0m     @     0x55f4a9160689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41270)\u001b[0m     @     0x55f4a91eabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41270)\u001b[0m     @     0x55f4a91eb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41270)\u001b[0m     @     0x55f4a9160689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41166)\u001b[0m     @     0x7fd8ffb46390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41166)\u001b[0m     @     0x7fa9ffaf5f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41166)\u001b[0m     @     0x7fa9ff2207db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41166)\u001b[0m     @     0x7fa9ff2238f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41166)\u001b[0m     @     0x7fa9ff223ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41267)\u001b[0m     @     0x7f48b83354f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41267)\u001b[0m     @     0x7f48ba8088de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41267)\u001b[0m     @     0x7f48b83354f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41267)\u001b[0m     @     0x7f48be3e079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41267)\u001b[0m     @     0x564463565fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41267)\u001b[0m     @     0x5644634c0b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41267)\u001b[0m     @     0x56446354bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41267)\u001b[0m     @     0x56446354ca20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41267)\u001b[0m     @     0x5644634c0bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41267)\u001b[0m     @     0x56446354bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41267)\u001b[0m     @     0x56446354c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41267)\u001b[0m     @     0x5644634c1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41267)\u001b[0m     @     0x56446354bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41267)\u001b[0m     @     0x56446354c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41267)\u001b[0m     @     0x5644634c1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41267)\u001b[0m     @     0x56446354bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41267)\u001b[0m     @     0x56446354c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41267)\u001b[0m     @     0x5644634c1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41267)\u001b[0m     @     0x56446354bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41267)\u001b[0m     @     0x56446354c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41267)\u001b[0m     @     0x5644634c1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41147)\u001b[0m     @     0x7fc97c774f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41147)\u001b[0m     @     0x7fc97be9f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41147)\u001b[0m     @     0x7fc97bea28f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41147)\u001b[0m     @     0x7fc97bea2ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41147)\u001b[0m     @     0x7fc97bea2d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41147)\u001b[0m     @     0x7fc97c785b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41144)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41144)\u001b[0m *** SIGSEGV (@0x0) received by PID 41144 (TID 0x7ff8619b8700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41144)\u001b[0m     @     0x7ff861591390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41144)\u001b[0m     @     0x7fc9614e3f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41144)\u001b[0m     @     0x7fc960c0e7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41144)\u001b[0m     @     0x7fc960c118f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41144)\u001b[0m     @     0x7fc960c11ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41230)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41230)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41230)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41230)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41230)\u001b[0m *** SIGSEGV (@0x0) received by PID 41230 (TID 0x7fd58cd34700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41230)\u001b[0m     @     0x7fd58c90d390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41230)\u001b[0m     @     0x7fa68c825f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41230)\u001b[0m     @     0x7fa68bf507db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41230)\u001b[0m     @     0x7fa68bf538f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41146)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41146)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41146)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41146)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41146)\u001b[0m *** SIGSEGV (@0x0) received by PID 41146 (TID 0x7f8f116e1700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41146)\u001b[0m     @     0x7f8f112ba390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41146)\u001b[0m     @     0x7f60110c1f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41146)\u001b[0m     @     0x7f60107ec7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41146)\u001b[0m     @     0x7f60107ef8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41219)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41219)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41219)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41219)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41219)\u001b[0m *** SIGSEGV (@0x0) received by PID 41219 (TID 0x7f98a08a1700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41219)\u001b[0m     @     0x7f98a047a390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41219)\u001b[0m     @     0x7f69a00acf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41219)\u001b[0m     @     0x7f699f7d77db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41219)\u001b[0m     @     0x7f699f7da8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41236)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41236)\u001b[0m *** SIGSEGV (@0x0) received by PID 41236 (TID 0x7f215ff8c700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41236)\u001b[0m     @     0x7f215fb65390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41236)\u001b[0m     @     0x7ef25faf5f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41236)\u001b[0m     @     0x7ef25f2207db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41236)\u001b[0m     @     0x7ef25f2238f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41236)\u001b[0m     @     0x7ef25f223ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41236)\u001b[0m     @     0x7ef25f223d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41210)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41210)\u001b[0m *** SIGSEGV (@0x0) received by PID 41210 (TID 0x7f48965f7700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41210)\u001b[0m     @     0x7f48961d0390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41210)\u001b[0m     @     0x7f199613af90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41210)\u001b[0m     @     0x7f19958657db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41164)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41164)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41164)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41164)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41164)\u001b[0m *** SIGSEGV (@0x0) received by PID 41164 (TID 0x7fdab3b21700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41164)\u001b[0m     @     0x7fdab36fa390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41164)\u001b[0m     @     0x7fabb3681f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41164)\u001b[0m     @     0x7fabb2dac7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41164)\u001b[0m     @     0x7fabb2daf8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41164)\u001b[0m     @     0x7fabb2dafad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41176)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41176)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41176)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41176)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41176)\u001b[0m *** SIGSEGV (@0x0) received by PID 41176 (TID 0x7f1f0fd09700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41176)\u001b[0m     @     0x7f1f0f8e2390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41176)\u001b[0m     @     0x7ef00f5eff90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41176)\u001b[0m     @     0x7ef00ed1a7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41176)\u001b[0m     @     0x7ef00ed1d8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41176)\u001b[0m     @     0x7ef00ed1dad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41180)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41180)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41180)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41180)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41180)\u001b[0m *** SIGSEGV (@0x0) received by PID 41180 (TID 0x7f36da177700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41180)\u001b[0m     @     0x7f36d9d50390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41180)\u001b[0m     @     0x7f07d9ceff90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41180)\u001b[0m     @     0x7f07d941a7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41180)\u001b[0m     @     0x7f07d941d8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41221)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41221)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41221)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41221)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41221)\u001b[0m *** SIGSEGV (@0x0) received by PID 41221 (TID 0x7f4e7b115700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41221)\u001b[0m     @     0x7f4e7acee390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41221)\u001b[0m     @     0x7f1f7ac50f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41221)\u001b[0m     @     0x7f1f7a37b7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41221)\u001b[0m     @     0x7f1f7a37e8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41217)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41217)\u001b[0m *** SIGSEGV (@0x0) received by PID 41217 (TID 0x7fdb56d66700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41217)\u001b[0m     @     0x7fdb5693f390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41217)\u001b[0m     @     0x7fac567bbf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41217)\u001b[0m     @     0x7fac55ee67db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41217)\u001b[0m     @     0x7fac55ee98f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41217)\u001b[0m     @     0x7fac55ee9ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41217)\u001b[0m     @     0x7fac55ee9d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41217)\u001b[0m     @     0x7fac567ccb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41247)\u001b[0m     @     0x7fc06e14f8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41247)\u001b[0m     @     0x7fc06e14fad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41247)\u001b[0m     @     0x7fc06e14fd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41247)\u001b[0m     @     0x7fc06ea32b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41247)\u001b[0m     @     0x7fc06ea55c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41247)\u001b[0m     @     0x7fc06def7a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41247)\u001b[0m     @     0x7fc06def5388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41247)\u001b[0m     @     0x7fc06def75a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41231)\u001b[0m     @     0x7f0839cfe390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41231)\u001b[0m     @     0x7ed939c0df90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41231)\u001b[0m     @     0x7ed9393387db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41231)\u001b[0m     @     0x7ed93933b8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41231)\u001b[0m     @     0x7ed93933bad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41231)\u001b[0m     @     0x7ed93933bd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41231)\u001b[0m     @     0x7ed939c1eb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41231)\u001b[0m     @     0x7ed939c41c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41159)\u001b[0m     @     0x7fb75bd79f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41159)\u001b[0m     @     0x7fb75b4a47db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41159)\u001b[0m     @     0x7fb75b4a78f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41159)\u001b[0m     @     0x7fb75b4a7ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41159)\u001b[0m     @     0x7fb75b4a7d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41159)\u001b[0m     @     0x7fb75bd8ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41159)\u001b[0m     @     0x7fb75bdadc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41233)\u001b[0m     @     0x7fb9e11a34f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41233)\u001b[0m     @     0x7fb9e36768de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41233)\u001b[0m     @     0x7fb9e11a34f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41233)\u001b[0m     @     0x7fb9e724e79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41233)\u001b[0m     @     0x55c6662d4fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41233)\u001b[0m     @     0x55c66622fb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41233)\u001b[0m     @     0x55c6662babaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41233)\u001b[0m     @     0x55c6662bba20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41233)\u001b[0m     @     0x55c66622fbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41233)\u001b[0m     @     0x55c6662babaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41233)\u001b[0m     @     0x55c6662bb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41233)\u001b[0m     @     0x55c666230689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41233)\u001b[0m     @     0x55c6662babaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41233)\u001b[0m     @     0x55c6662bb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41233)\u001b[0m     @     0x55c666230689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41233)\u001b[0m     @     0x55c6662babaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41233)\u001b[0m     @     0x55c6662bb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41233)\u001b[0m     @     0x55c666230689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41233)\u001b[0m     @     0x55c6662babaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41233)\u001b[0m     @     0x55c6662bb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41233)\u001b[0m     @     0x55c666230689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41160)\u001b[0m     @     0x7f78d82c6f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41160)\u001b[0m     @     0x7f78d79f17db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41160)\u001b[0m     @     0x7f78d79f48f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41160)\u001b[0m     @     0x7f78d79f4ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41160)\u001b[0m     @     0x7f78d79f4d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41160)\u001b[0m     @     0x7f78d82d7b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41160)\u001b[0m     @     0x7f78d82fac1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41151)\u001b[0m     @     0x7f283f0dd390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41151)\u001b[0m     @     0x7ef93f077f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41151)\u001b[0m     @     0x7ef93e7a27db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41151)\u001b[0m     @     0x7ef93e7a58f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41151)\u001b[0m     @     0x7ef93e7a5ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41151)\u001b[0m     @     0x7ef93e7a5d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41151)\u001b[0m     @     0x7ef93f088b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41151)\u001b[0m     @     0x7ef93f0abc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41216)\u001b[0m     @     0x7fbd9f641f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41216)\u001b[0m     @     0x7fbd9ed6c7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41216)\u001b[0m     @     0x7fbd9ed6f8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41216)\u001b[0m     @     0x7fbd9ed6fad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41216)\u001b[0m     @     0x7fbd9ed6fd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41216)\u001b[0m     @     0x7fbd9f652b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41265)\u001b[0m     @     0x7f75781ce8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41265)\u001b[0m     @     0x7f7575cfb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41265)\u001b[0m     @     0x7f757bda679f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41265)\u001b[0m     @     0x55dfba993fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41265)\u001b[0m     @     0x55dfba8eeb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41265)\u001b[0m     @     0x55dfba979baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41265)\u001b[0m     @     0x55dfba97aa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41265)\u001b[0m     @     0x55dfba8eebfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41265)\u001b[0m     @     0x55dfba979baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41265)\u001b[0m     @     0x55dfba97a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41265)\u001b[0m     @     0x55dfba8ef689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41265)\u001b[0m     @     0x55dfba979baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41265)\u001b[0m     @     0x55dfba97a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41265)\u001b[0m     @     0x55dfba8ef689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41265)\u001b[0m     @     0x55dfba979baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41265)\u001b[0m     @     0x55dfba97a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41265)\u001b[0m     @     0x55dfba8ef689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41265)\u001b[0m     @     0x55dfba979baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41265)\u001b[0m     @     0x55dfba97a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41265)\u001b[0m     @     0x55dfba8ef689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41277)\u001b[0m     @     0x7ee3f75f88de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41277)\u001b[0m     @     0x7ee3f51254f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41277)\u001b[0m     @     0x7ee3fb1d079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41277)\u001b[0m     @     0x55c722451fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41277)\u001b[0m     @     0x55c7223acb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41277)\u001b[0m     @     0x55c722437baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41277)\u001b[0m     @     0x55c722438a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41277)\u001b[0m     @     0x55c7223acbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41277)\u001b[0m     @     0x55c722437baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41277)\u001b[0m     @     0x55c722438643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41277)\u001b[0m     @     0x55c7223ad689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41277)\u001b[0m     @     0x55c722437baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41277)\u001b[0m     @     0x55c722438643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41277)\u001b[0m     @     0x55c7223ad689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41277)\u001b[0m     @     0x55c722437baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41277)\u001b[0m     @     0x55c722438643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41277)\u001b[0m     @     0x55c7223ad689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41277)\u001b[0m     @     0x55c722437baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41277)\u001b[0m     @     0x55c722438643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41277)\u001b[0m     @     0x55c7223ad689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41281)\u001b[0m     @     0x7f14349795a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41281)\u001b[0m     @     0x7f14350644f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41281)\u001b[0m     @     0x7f14375378de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41281)\u001b[0m     @     0x7f14350644f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41281)\u001b[0m     @     0x7f143b10f79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41281)\u001b[0m     @     0x5581c903afd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41281)\u001b[0m     @     0x5581c8f95b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41281)\u001b[0m     @     0x5581c9020baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41281)\u001b[0m     @     0x5581c9021a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41281)\u001b[0m     @     0x5581c8f95bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41281)\u001b[0m     @     0x5581c9020baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41281)\u001b[0m     @     0x5581c9021643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41281)\u001b[0m     @     0x5581c8f96689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41281)\u001b[0m     @     0x5581c9020baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41281)\u001b[0m     @     0x5581c9021643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41281)\u001b[0m     @     0x5581c8f96689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41281)\u001b[0m     @     0x5581c9020baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41281)\u001b[0m     @     0x5581c9021643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41281)\u001b[0m     @     0x5581c8f96689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41281)\u001b[0m     @     0x5581c9020baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41281)\u001b[0m     @     0x5581c9021643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41281)\u001b[0m     @     0x5581c8f96689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41272)\u001b[0m     @     0x7fc367fa44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41272)\u001b[0m     @     0x7fc36a4778de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41272)\u001b[0m     @     0x7fc367fa44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41272)\u001b[0m     @     0x7fc36e04f79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41272)\u001b[0m     @     0x555b43060fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41272)\u001b[0m     @     0x555b42fbbb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41272)\u001b[0m     @     0x555b43046baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41272)\u001b[0m     @     0x555b43047a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41272)\u001b[0m     @     0x555b42fbbbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41272)\u001b[0m     @     0x555b43046baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41272)\u001b[0m     @     0x555b43047643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41272)\u001b[0m     @     0x555b42fbc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41272)\u001b[0m     @     0x555b43046baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41272)\u001b[0m     @     0x555b43047643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41272)\u001b[0m     @     0x555b42fbc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41272)\u001b[0m     @     0x555b43046baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41272)\u001b[0m     @     0x555b43047643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41272)\u001b[0m     @     0x555b42fbc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41272)\u001b[0m     @     0x555b43046baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41272)\u001b[0m     @     0x555b43047643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41272)\u001b[0m     @     0x555b42fbc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41260)\u001b[0m     @     0x7ee0ee2cb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41260)\u001b[0m     @     0x7ee0f079e8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41260)\u001b[0m     @     0x7ee0ee2cb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41260)\u001b[0m     @     0x7ee0f437679f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41260)\u001b[0m     @     0x55bf4901afd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41260)\u001b[0m     @     0x55bf48f75b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41260)\u001b[0m     @     0x55bf49000baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41260)\u001b[0m     @     0x55bf49001a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41260)\u001b[0m     @     0x55bf48f75bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41260)\u001b[0m     @     0x55bf49000baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41260)\u001b[0m     @     0x55bf49001643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41260)\u001b[0m     @     0x55bf48f76689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41260)\u001b[0m     @     0x55bf49000baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41260)\u001b[0m     @     0x55bf49001643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41260)\u001b[0m     @     0x55bf48f76689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41260)\u001b[0m     @     0x55bf49000baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41260)\u001b[0m     @     0x55bf49001643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41260)\u001b[0m     @     0x55bf48f76689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41260)\u001b[0m     @     0x55bf49000baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41260)\u001b[0m     @     0x55bf49001643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41260)\u001b[0m     @     0x55bf48f76689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41157)\u001b[0m     @     0x7ed3a12fcf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41157)\u001b[0m     @     0x7ed3a0a277db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41157)\u001b[0m     @     0x7ed3a0a2a8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41157)\u001b[0m     @     0x7ed3a0a2aad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41157)\u001b[0m     @     0x7ed3a0a2ad91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41157)\u001b[0m     @     0x7ed3a130db22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41157)\u001b[0m     @     0x7ed3a1330c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41256)\u001b[0m *** SIGSEGV (@0x0) received by PID 41256 (TID 0x7f1391eba700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41256)\u001b[0m     @     0x7f1391a93390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41256)\u001b[0m     @     0x7ee491a0af90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41256)\u001b[0m     @     0x7ee4911357db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41256)\u001b[0m     @     0x7ee4911388f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41256)\u001b[0m     @     0x7ee491138ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41256)\u001b[0m     @     0x7ee491138d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41256)\u001b[0m     @     0x7ee491a1bb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41232)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41232)\u001b[0m *** SIGSEGV (@0x0) received by PID 41232 (TID 0x7f16dbdd9700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41232)\u001b[0m     @     0x7f16db9b2390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41232)\u001b[0m     @     0x7ee7db8def90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41232)\u001b[0m     @     0x7ee7db0097db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41206)\u001b[0m     @     0x7fa471e32390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41206)\u001b[0m     @     0x7f7571de4f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41206)\u001b[0m     @     0x7f757150f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41206)\u001b[0m     @     0x7f75715128f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41206)\u001b[0m     @     0x7f7571512ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41206)\u001b[0m     @     0x7f7571512d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41206)\u001b[0m     @     0x7f7571df5b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41206)\u001b[0m     @     0x7f7571e18c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41171)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41171)\u001b[0m *** SIGSEGV (@0x0) received by PID 41171 (TID 0x7f515ad98700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41171)\u001b[0m     @     0x7f515a971390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41171)\u001b[0m     @     0x7f225a7bbf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41171)\u001b[0m     @     0x7f2259ee67db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41171)\u001b[0m     @     0x7f2259ee98f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41171)\u001b[0m     @     0x7f2259ee9ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41171)\u001b[0m     @     0x7f2259ee9d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41171)\u001b[0m     @     0x7f225a7ccb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41223)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41223)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41223)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41223)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41223)\u001b[0m *** SIGSEGV (@0x0) received by PID 41223 (TID 0x7f898adfa700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41223)\u001b[0m     @     0x7f898a9d3390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41223)\u001b[0m     @     0x7f5a8a7bbf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41223)\u001b[0m     @     0x7f5a89ee67db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41158)\u001b[0m     @     0x7f5700480390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41158)\u001b[0m     @     0x7f2800304f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41158)\u001b[0m     @     0x7f27ffa2f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41158)\u001b[0m     @     0x7f27ffa328f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41158)\u001b[0m     @     0x7f27ffa32ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41158)\u001b[0m     @     0x7f27ffa32d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41158)\u001b[0m     @     0x7f2800315b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41158)\u001b[0m     @     0x7f2800338c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41152)\u001b[0m     @     0x7f75fd0b5f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41152)\u001b[0m     @     0x7f75fc7e07db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41152)\u001b[0m     @     0x7f75fc7e38f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41152)\u001b[0m     @     0x7f75fc7e3ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41152)\u001b[0m     @     0x7f75fc7e3d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41152)\u001b[0m     @     0x7f75fd0c6b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41152)\u001b[0m     @     0x7f75fd0e9c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41152)\u001b[0m     @     0x7f75fc58ba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41152)\u001b[0m     @     0x7f75fc589388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41153)\u001b[0m     @     0x7f3e81e1d390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41153)\u001b[0m     @     0x7f0f81d1df90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41153)\u001b[0m     @     0x7f0f814487db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41153)\u001b[0m     @     0x7f0f8144b8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41153)\u001b[0m     @     0x7f0f8144bad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41153)\u001b[0m     @     0x7f0f8144bd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41153)\u001b[0m     @     0x7f0f81d2eb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41153)\u001b[0m     @     0x7f0f81d51c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41222)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41222)\u001b[0m *** SIGSEGV (@0x0) received by PID 41222 (TID 0x7fd2e9c93700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41222)\u001b[0m     @     0x7fd2e986c390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41222)\u001b[0m     @     0x7fa3e97f9f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41222)\u001b[0m     @     0x7fa3e8f247db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41222)\u001b[0m     @     0x7fa3e8f278f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41222)\u001b[0m     @     0x7fa3e8f27ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41222)\u001b[0m     @     0x7fa3e8f27d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41222)\u001b[0m     @     0x7fa3e980ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41170)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=41170)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=41170)\u001b[0m *** Aborted at 1604573005 (unix time) try \"date -d @1604573005\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=41170)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41170)\u001b[0m *** SIGSEGV (@0x0) received by PID 41170 (TID 0x7f006e371700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41170)\u001b[0m     @     0x7f006df4a390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41170)\u001b[0m     @     0x7ed16de24f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41170)\u001b[0m     @     0x7ed16d54f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41170)\u001b[0m     @     0x7ed16d5528f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41170)\u001b[0m     @     0x7ed16d552ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41170)\u001b[0m     @     0x7ed16d552d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41170)\u001b[0m     @     0x7ed16de35b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41155)\u001b[0m     @     0x7fb8c8e2c7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41155)\u001b[0m     @     0x7fb8c8e2f8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41155)\u001b[0m     @     0x7fb8c8e2fad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41155)\u001b[0m     @     0x7fb8c8e2fd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41155)\u001b[0m     @     0x7fb8c9712b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41155)\u001b[0m     @     0x7fb8c9735c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41145)\u001b[0m     @     0x7f2b391388f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41145)\u001b[0m     @     0x7f2b39138ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41145)\u001b[0m     @     0x7f2b39138d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41145)\u001b[0m     @     0x7f2b39a1bb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41145)\u001b[0m     @     0x7f2b39a3ec1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41145)\u001b[0m     @     0x7f2b38ee0a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41145)\u001b[0m     @     0x7f2b38ede388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41220)\u001b[0m     @     0x7ee66d4a3f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41220)\u001b[0m     @     0x7ee66cbce7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41220)\u001b[0m     @     0x7ee66cbd18f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41220)\u001b[0m     @     0x7ee66cbd1ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41220)\u001b[0m     @     0x7ee66cbd1d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41220)\u001b[0m     @     0x7ee66d4b4b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41284)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41284)\u001b[0m *** SIGSEGV (@0x0) received by PID 41284 (TID 0x7f23d5ad2700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41284)\u001b[0m     @     0x7f23d56ab390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41284)\u001b[0m     @     0x7ef4d5626f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41284)\u001b[0m     @     0x7ef4d4d517db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41284)\u001b[0m     @     0x7ef4d4d548f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41284)\u001b[0m     @     0x7ef4d4d54ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41229)\u001b[0m     @     0x7f80231e07db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41229)\u001b[0m     @     0x7f80231e38f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41229)\u001b[0m     @     0x7f80231e3ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41229)\u001b[0m     @     0x7f80231e3d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41229)\u001b[0m     @     0x7f8023ac6b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41229)\u001b[0m     @     0x7f8023ae9c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41235)\u001b[0m     @     0x7ffaf14af390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41235)\u001b[0m     @     0x7fcbf13ccf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41235)\u001b[0m     @     0x7fcbf0af77db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41235)\u001b[0m     @     0x7fcbf0afa8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41235)\u001b[0m     @     0x7fcbf0afaad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41187)\u001b[0m     @     0x7f4db2601f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41187)\u001b[0m     @     0x7f4db1d2c7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41187)\u001b[0m     @     0x7f4db1d2f8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41187)\u001b[0m     @     0x7f4db1d2fad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41187)\u001b[0m     @     0x7f4db1d2fd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41187)\u001b[0m     @     0x7f4db2612b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41187)\u001b[0m     @     0x7f4db2635c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41228)\u001b[0m     @     0x7f2e94a688f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41228)\u001b[0m     @     0x7f2e94a68ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41228)\u001b[0m     @     0x7f2e94a68d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41228)\u001b[0m     @     0x7f2e9534bb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41228)\u001b[0m     @     0x7f2e9536ec1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41228)\u001b[0m     @     0x7f2e94810a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41240)\u001b[0m     @     0x7f4412e7c7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41240)\u001b[0m     @     0x7f4412e7f8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41240)\u001b[0m     @     0x7f4412e7fad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41240)\u001b[0m     @     0x7f4412e7fd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41240)\u001b[0m     @     0x7f4413762b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41240)\u001b[0m     @     0x7f4413785c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41224)\u001b[0m     @     0x7fb0d6e48390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41224)\u001b[0m     @     0x7f81d6df0f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41224)\u001b[0m     @     0x7f81d651b7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41224)\u001b[0m     @     0x7f81d651e8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41224)\u001b[0m     @     0x7f81d651ead3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41177)\u001b[0m     @     0x7f53410b5f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41177)\u001b[0m     @     0x7f53407e07db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41177)\u001b[0m     @     0x7f53407e38f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41177)\u001b[0m     @     0x7f53407e3ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41177)\u001b[0m     @     0x7f53407e3d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41177)\u001b[0m     @     0x7f53410c6b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41249)\u001b[0m     @     0x7f7f972238f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41249)\u001b[0m     @     0x7f7f97223ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41249)\u001b[0m     @     0x7f7f97223d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41249)\u001b[0m     @     0x7f7f97b06b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41249)\u001b[0m     @     0x7f7f97b29c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41249)\u001b[0m     @     0x7f7f96fcba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41249)\u001b[0m     @     0x7f7f96fc9388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41161)\u001b[0m     @     0x7f20266418f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41161)\u001b[0m     @     0x7f2026641ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41161)\u001b[0m     @     0x7f2026641d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41161)\u001b[0m     @     0x7f2026f24b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41161)\u001b[0m     @     0x7f2026f47c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41161)\u001b[0m     @     0x7f20263e9a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41161)\u001b[0m     @     0x7f20263e7388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41161)\u001b[0m     @     0x7f20263e95a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41163)\u001b[0m     @     0x7f4303229f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41163)\u001b[0m     @     0x7f43029547db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41163)\u001b[0m     @     0x7f43029578f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41163)\u001b[0m     @     0x7f4302957ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41163)\u001b[0m     @     0x7f4302957d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41241)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41241)\u001b[0m *** SIGSEGV (@0x0) received by PID 41241 (TID 0x7ff798085700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41241)\u001b[0m     @     0x7ff797c5e390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41241)\u001b[0m     @     0x7fc897af5f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41241)\u001b[0m     @     0x7fc8972207db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41241)\u001b[0m     @     0x7fc8972238f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41213)\u001b[0m     @     0x7f8db5d08390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41213)\u001b[0m     @     0x7f5eb5c0df90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41213)\u001b[0m     @     0x7f5eb53387db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41213)\u001b[0m     @     0x7f5eb533b8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41213)\u001b[0m     @     0x7f5eb533bad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41213)\u001b[0m     @     0x7f5eb533bd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41213)\u001b[0m     @     0x7f5eb5c1eb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41213)\u001b[0m     @     0x7f5eb5c41c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41246)\u001b[0m     @     0x7f163fb88390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41246)\u001b[0m     @     0x7ee73f9c5f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41246)\u001b[0m     @     0x7ee73f0f07db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41246)\u001b[0m     @     0x7ee73f0f38f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41246)\u001b[0m     @     0x7ee73f0f3ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41246)\u001b[0m     @     0x7ee73f0f3d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41246)\u001b[0m     @     0x7ee73f9d6b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41246)\u001b[0m     @     0x7ee73f9f9c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41279)\u001b[0m     @     0x7f43458688f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41279)\u001b[0m     @     0x7f4345868ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41279)\u001b[0m     @     0x7f4345868d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41279)\u001b[0m     @     0x7f434614bb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41279)\u001b[0m     @     0x7f434616ec1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41279)\u001b[0m     @     0x7f4345610a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41279)\u001b[0m     @     0x7f434560e388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41209)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41209)\u001b[0m *** SIGSEGV (@0x0) received by PID 41209 (TID 0x7fe8d5a20700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=41209)\u001b[0m     @     0x7fe8d55f9390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=41209)\u001b[0m     @     0x7fb9d557ff90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41209)\u001b[0m     @     0x7fb9d4caa7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41209)\u001b[0m     @     0x7fb9d4cad8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41178)\u001b[0m     @     0x7ef872f13f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=41178)\u001b[0m     @     0x7ef87263e7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=41178)\u001b[0m     @     0x7ef8726418f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41178)\u001b[0m     @     0x7ef872641ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41178)\u001b[0m     @     0x7ef872641d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41178)\u001b[0m     @     0x7ef872f24b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41178)\u001b[0m     @     0x7ef872f47c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41218)\u001b[0m     @     0x7f28c20cd8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41218)\u001b[0m     @     0x7f28c20cdad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41218)\u001b[0m     @     0x7f28c20cdd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41218)\u001b[0m     @     0x7f28c29b0b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41218)\u001b[0m     @     0x7f28c29d3c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41218)\u001b[0m     @     0x7f28c1e75a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41218)\u001b[0m     @     0x7f28c1e73388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41218)\u001b[0m     @     0x7f28c1e755a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41262)\u001b[0m     @     0x7f99f29578f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41262)\u001b[0m     @     0x7f99f2957ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41262)\u001b[0m     @     0x7f99f2957d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41262)\u001b[0m     @     0x7f99f323ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41262)\u001b[0m     @     0x7f99f325dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41262)\u001b[0m     @     0x7f99f26ffa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41262)\u001b[0m     @     0x7f99f26fd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41262)\u001b[0m     @     0x7f99f26ff5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41148)\u001b[0m     @     0x7f347506ead3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41148)\u001b[0m     @     0x7f347506ed91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41148)\u001b[0m     @     0x7f3475951b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41148)\u001b[0m     @     0x7f3475974c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41183)\u001b[0m     @     0x7fa84ab688f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41183)\u001b[0m     @     0x7fa84ab68ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41183)\u001b[0m     @     0x7fa84ab68d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41183)\u001b[0m     @     0x7fa84b44bb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41183)\u001b[0m     @     0x7fa84b46ec1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41183)\u001b[0m     @     0x7fa84a910a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41183)\u001b[0m     @     0x7fa84a90e388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41183)\u001b[0m     @     0x7fa84a9105a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41212)\u001b[0m     @     0x7ed617a774f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41212)\u001b[0m     @     0x7ed61db2279f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41212)\u001b[0m     @     0x55624b8cbfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41212)\u001b[0m     @     0x55624b826b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41212)\u001b[0m     @     0x55624b8b1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41212)\u001b[0m     @     0x55624b8b2a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41212)\u001b[0m     @     0x55624b826bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41212)\u001b[0m     @     0x55624b8b1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41212)\u001b[0m     @     0x55624b8b2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41212)\u001b[0m     @     0x55624b827689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41212)\u001b[0m     @     0x55624b8b1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41212)\u001b[0m     @     0x55624b8b2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41212)\u001b[0m     @     0x55624b827689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41212)\u001b[0m     @     0x55624b8b1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41212)\u001b[0m     @     0x55624b8b2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41212)\u001b[0m     @     0x55624b827689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41212)\u001b[0m     @     0x55624b8b1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41212)\u001b[0m     @     0x55624b8b2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41212)\u001b[0m     @     0x55624b827689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41273)\u001b[0m     @     0x7fa26df0c4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41273)\u001b[0m     @     0x7fa273fb779f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41273)\u001b[0m     @     0x56222e77bfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41273)\u001b[0m     @     0x56222e6d6b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41273)\u001b[0m     @     0x56222e761baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41273)\u001b[0m     @     0x56222e762a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41273)\u001b[0m     @     0x56222e6d6bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41273)\u001b[0m     @     0x56222e761baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41273)\u001b[0m     @     0x56222e762643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41273)\u001b[0m     @     0x56222e6d7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41273)\u001b[0m     @     0x56222e761baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41273)\u001b[0m     @     0x56222e762643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41273)\u001b[0m     @     0x56222e6d7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41273)\u001b[0m     @     0x56222e761baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41273)\u001b[0m     @     0x56222e762643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41273)\u001b[0m     @     0x56222e6d7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41273)\u001b[0m     @     0x56222e761baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41273)\u001b[0m     @     0x56222e762643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41273)\u001b[0m     @     0x56222e6d7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41207)\u001b[0m     @     0x7f7d4782fad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41207)\u001b[0m     @     0x7f7d4782fd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41207)\u001b[0m     @     0x7f7d48112b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41207)\u001b[0m     @     0x7f7d48135c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41207)\u001b[0m     @     0x7f7d475d7a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41207)\u001b[0m     @     0x7f7d475d5388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41207)\u001b[0m     @     0x7f7d475d75a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41250)\u001b[0m     @     0x564bb7ae6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41250)\u001b[0m     @     0x564bb7b70baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41250)\u001b[0m     @     0x564bb7b71643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41250)\u001b[0m     @     0x564bb7ae6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41250)\u001b[0m     @     0x564bb7b70baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41250)\u001b[0m     @     0x564bb7b71643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41250)\u001b[0m     @     0x564bb7ae6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41250)\u001b[0m     @     0x564bb7b70baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41250)\u001b[0m     @     0x564bb7b71643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41250)\u001b[0m     @     0x564bb7ae6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41214)\u001b[0m     @     0x7f68100adad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41214)\u001b[0m     @     0x7f68100add91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41214)\u001b[0m     @     0x7f6810990b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41214)\u001b[0m     @     0x7f68109b3c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41214)\u001b[0m     @     0x7f680fe55a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41214)\u001b[0m     @     0x7f680fe53388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41214)\u001b[0m     @     0x7f680fe555a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41214)\u001b[0m     @     0x7f68105404f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41214)\u001b[0m     @     0x7f6812a138de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41149)\u001b[0m     @     0x7f1d07ba3ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41149)\u001b[0m     @     0x7f1d07ba3d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41149)\u001b[0m     @     0x7f1d08486b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41149)\u001b[0m     @     0x7f1d084a9c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41149)\u001b[0m     @     0x7f1d0794ba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41149)\u001b[0m     @     0x7f1d07949388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41149)\u001b[0m     @     0x7f1d0794b5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41149)\u001b[0m     @     0x7f1d080364f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41239)\u001b[0m     @     0x7fb26f7b84f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41239)\u001b[0m     @     0x7fb27586379f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41239)\u001b[0m     @     0x564211237fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41239)\u001b[0m     @     0x564211192b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41239)\u001b[0m     @     0x56421121dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41239)\u001b[0m     @     0x56421121ea20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41239)\u001b[0m     @     0x564211192bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41239)\u001b[0m     @     0x56421121dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41239)\u001b[0m     @     0x56421121e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41239)\u001b[0m     @     0x564211193689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41239)\u001b[0m     @     0x56421121dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41239)\u001b[0m     @     0x56421121e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41239)\u001b[0m     @     0x564211193689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41239)\u001b[0m     @     0x56421121dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41239)\u001b[0m     @     0x56421121e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41239)\u001b[0m     @     0x564211193689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41239)\u001b[0m     @     0x56421121dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41239)\u001b[0m     @     0x56421121e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41239)\u001b[0m     @     0x564211193689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41237)\u001b[0m     @     0x7edd962fc5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41237)\u001b[0m     @     0x7edd969e74f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41237)\u001b[0m     @     0x7edd98eba8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41237)\u001b[0m     @     0x7edd969e74f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41237)\u001b[0m     @     0x7edd9ca9279f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41237)\u001b[0m     @     0x560a29f26fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41237)\u001b[0m     @     0x560a29e81b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41237)\u001b[0m     @     0x560a29f0cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41237)\u001b[0m     @     0x560a29f0da20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41237)\u001b[0m     @     0x560a29e81bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41237)\u001b[0m     @     0x560a29f0cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41237)\u001b[0m     @     0x560a29f0d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41237)\u001b[0m     @     0x560a29e82689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41237)\u001b[0m     @     0x560a29f0cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41237)\u001b[0m     @     0x560a29f0d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41237)\u001b[0m     @     0x560a29e82689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41237)\u001b[0m     @     0x560a29f0cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41237)\u001b[0m     @     0x560a29f0d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41237)\u001b[0m     @     0x560a29e82689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41237)\u001b[0m     @     0x560a29f0cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41237)\u001b[0m     @     0x560a29f0d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41237)\u001b[0m     @     0x560a29e82689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41184)\u001b[0m     @     0x7ed29b539ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41184)\u001b[0m     @     0x7ed29b539d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41184)\u001b[0m     @     0x7ed29be1cb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41184)\u001b[0m     @     0x7ed29be3fc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41184)\u001b[0m     @     0x7ed29b2e1a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41184)\u001b[0m     @     0x7ed29b2df388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41184)\u001b[0m     @     0x7ed29b2e15a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41150)\u001b[0m     @     0x7fa62242aad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41150)\u001b[0m     @     0x7fa62242ad91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41150)\u001b[0m     @     0x7fa622d0db22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41150)\u001b[0m     @     0x7fa622d30c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41150)\u001b[0m     @     0x7fa6221d2a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41150)\u001b[0m     @     0x7fa6221d0388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41150)\u001b[0m     @     0x7fa6221d25a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41227)\u001b[0m     @     0x7fcbd47e38f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41227)\u001b[0m     @     0x7fcbd47e3ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41227)\u001b[0m     @     0x7fcbd47e3d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41227)\u001b[0m     @     0x7fcbd50c6b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41227)\u001b[0m     @     0x7fcbd50e9c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41227)\u001b[0m     @     0x7fcbd458ba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41227)\u001b[0m     @     0x7fcbd4589388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41227)\u001b[0m     @     0x7fcbd458b5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41174)\u001b[0m     @     0x7f3643b118f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41174)\u001b[0m     @     0x7f3643b11ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41174)\u001b[0m     @     0x7f3643b11d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41174)\u001b[0m     @     0x7f36443f4b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41174)\u001b[0m     @     0x7f3644417c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41174)\u001b[0m     @     0x7f36438b9a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41174)\u001b[0m     @     0x7f36438b7388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41226)\u001b[0m     @     0x7eed322cb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41226)\u001b[0m     @     0x7eed3479e8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41226)\u001b[0m     @     0x7eed322cb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41226)\u001b[0m     @     0x7eed3837679f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41226)\u001b[0m     @     0x55a8ca3b1fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41226)\u001b[0m     @     0x55a8ca30cb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41226)\u001b[0m     @     0x55a8ca397baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41226)\u001b[0m     @     0x55a8ca398a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41226)\u001b[0m     @     0x55a8ca30cbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41226)\u001b[0m     @     0x55a8ca397baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41226)\u001b[0m     @     0x55a8ca398643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41226)\u001b[0m     @     0x55a8ca30d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41226)\u001b[0m     @     0x55a8ca397baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41226)\u001b[0m     @     0x55a8ca398643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41226)\u001b[0m     @     0x55a8ca30d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41226)\u001b[0m     @     0x55a8ca397baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41226)\u001b[0m     @     0x55a8ca398643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41226)\u001b[0m     @     0x55a8ca30d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41226)\u001b[0m     @     0x55a8ca397baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41226)\u001b[0m     @     0x55a8ca398643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41226)\u001b[0m     @     0x55a8ca30d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41215)\u001b[0m     @     0x7edf4d28dd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41215)\u001b[0m     @     0x7edf4db70b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41215)\u001b[0m     @     0x7edf4db93c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41215)\u001b[0m     @     0x7edf4d035a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41215)\u001b[0m     @     0x7edf4d033388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41215)\u001b[0m     @     0x7edf4d0355a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41215)\u001b[0m     @     0x7edf4d7204f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41215)\u001b[0m     @     0x7edf4fbf38de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41215)\u001b[0m     @     0x7edf4d7204f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41215)\u001b[0m     @     0x7edf537cb79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41215)\u001b[0m     @     0x55de5f073fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41215)\u001b[0m     @     0x55de5efceb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41215)\u001b[0m     @     0x55de5f059baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41215)\u001b[0m     @     0x55de5f05aa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41215)\u001b[0m     @     0x55de5efcebfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41215)\u001b[0m     @     0x55de5f059baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41215)\u001b[0m     @     0x55de5f05a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41162)\u001b[0m     @     0x7fadf1caaad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41162)\u001b[0m     @     0x7fadf1caad91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41162)\u001b[0m     @     0x7fadf258db22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41162)\u001b[0m     @     0x7fadf25b0c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41162)\u001b[0m     @     0x7fadf1a52a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41162)\u001b[0m     @     0x7fadf1a50388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41162)\u001b[0m     @     0x7fadf1a525a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41162)\u001b[0m     @     0x7fadf213d4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41225)\u001b[0m     @     0x55c486a78baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41225)\u001b[0m     @     0x55c486a79643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41225)\u001b[0m     @     0x55c4869ee689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41225)\u001b[0m     @     0x55c486a78baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41225)\u001b[0m     @     0x55c486a79643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41225)\u001b[0m     @     0x55c4869ee689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41225)\u001b[0m     @     0x55c486a78baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41225)\u001b[0m     @     0x55c486a79643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41225)\u001b[0m     @     0x55c4869ee689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41225)\u001b[0m     @     0x55c486a78baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41225)\u001b[0m     @     0x55c486a79643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41225)\u001b[0m     @     0x55c4869ee689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41166)\u001b[0m     @     0x7fa9ff223d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41166)\u001b[0m     @     0x7fa9ffb06b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41166)\u001b[0m     @     0x7fa9ffb29c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41166)\u001b[0m     @     0x7fa9fefcba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41166)\u001b[0m     @     0x7fa9fefc9388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41166)\u001b[0m     @     0x7fa9fefcb5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41147)\u001b[0m     @     0x7fc97c7a8c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41147)\u001b[0m     @     0x7fc97bc4aa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41147)\u001b[0m     @     0x7fc97bc48388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41147)\u001b[0m     @     0x7fc97bc4a5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41147)\u001b[0m     @     0x7fc97c3354f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41147)\u001b[0m     @     0x7fc97e8088de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41144)\u001b[0m     @     0x7fc960c11d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41144)\u001b[0m     @     0x7fc9614f4b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41144)\u001b[0m     @     0x7fc961517c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41144)\u001b[0m     @     0x7fc9609b9a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41144)\u001b[0m     @     0x7fc9609b7388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41144)\u001b[0m     @     0x7fc9609b95a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41230)\u001b[0m     @     0x7fa68bf53ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41230)\u001b[0m     @     0x7fa68bf53d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41230)\u001b[0m     @     0x7fa68c836b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41230)\u001b[0m     @     0x7fa68c859c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41230)\u001b[0m     @     0x7fa68bcfba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41230)\u001b[0m     @     0x7fa68bcf9388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41146)\u001b[0m     @     0x7f60107efad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41146)\u001b[0m     @     0x7f60107efd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41146)\u001b[0m     @     0x7f60110d2b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41146)\u001b[0m     @     0x7f60110f5c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41219)\u001b[0m     @     0x7f699f7daad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41219)\u001b[0m     @     0x7f699f7dad91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41219)\u001b[0m     @     0x7f69a00bdb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41219)\u001b[0m     @     0x7f69a00e0c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41236)\u001b[0m     @     0x7ef25fb06b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41236)\u001b[0m     @     0x7ef25fb29c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41236)\u001b[0m     @     0x7ef25efcba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41236)\u001b[0m     @     0x7ef25efc9388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41236)\u001b[0m     @     0x7ef25efcb5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41210)\u001b[0m     @     0x7f19958688f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41210)\u001b[0m     @     0x7f1995868ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41210)\u001b[0m     @     0x7f1995868d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41210)\u001b[0m     @     0x7f199614bb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41164)\u001b[0m     @     0x7fabb2dafd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41164)\u001b[0m     @     0x7fabb3692b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41164)\u001b[0m     @     0x7fabb36b5c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41164)\u001b[0m     @     0x7fabb2b57a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41164)\u001b[0m     @     0x7fabb2b55388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41176)\u001b[0m     @     0x7ef00ed1dd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41176)\u001b[0m     @     0x7ef00f600b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41176)\u001b[0m     @     0x7ef00f623c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41176)\u001b[0m     @     0x7ef00eac5a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41176)\u001b[0m     @     0x7ef00eac3388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41180)\u001b[0m     @     0x7f07d941dad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41180)\u001b[0m     @     0x7f07d941dd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41180)\u001b[0m     @     0x7f07d9d00b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41180)\u001b[0m     @     0x7f07d9d23c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41221)\u001b[0m     @     0x7f1f7a37ead3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41221)\u001b[0m     @     0x7f1f7a37ed91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41221)\u001b[0m     @     0x7f1f7ac61b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41221)\u001b[0m     @     0x7f1f7ac84c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41221)\u001b[0m     @     0x7f1f7a126a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41221)\u001b[0m     @     0x7f1f7a124388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41217)\u001b[0m     @     0x7fac567efc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41217)\u001b[0m     @     0x7fac55c91a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41217)\u001b[0m     @     0x7fac55c8f388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41217)\u001b[0m     @     0x7fac55c915a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41247)\u001b[0m     @     0x7fc06e5e24f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41247)\u001b[0m     @     0x7fc070ab58de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41247)\u001b[0m     @     0x7fc06e5e24f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41247)\u001b[0m     @     0x7fc07468d79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41247)\u001b[0m     @     0x55aeea249fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41247)\u001b[0m     @     0x55aeea1a4b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41247)\u001b[0m     @     0x55aeea22fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41247)\u001b[0m     @     0x55aeea230a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41247)\u001b[0m     @     0x55aeea1a4bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41247)\u001b[0m     @     0x55aeea22fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41247)\u001b[0m     @     0x55aeea230643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41247)\u001b[0m     @     0x55aeea1a5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41247)\u001b[0m     @     0x55aeea22fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41247)\u001b[0m     @     0x55aeea230643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41247)\u001b[0m     @     0x55aeea1a5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41247)\u001b[0m     @     0x55aeea22fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41231)\u001b[0m     @     0x7ed9390e3a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41231)\u001b[0m     @     0x7ed9390e1388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41231)\u001b[0m     @     0x7ed9390e35a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41231)\u001b[0m     @     0x7ed9397ce4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41159)\u001b[0m     @     0x7fb75b24fa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41159)\u001b[0m     @     0x7fb75b24d388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41159)\u001b[0m     @     0x7fb75b24f5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41159)\u001b[0m     @     0x7fb75b93a4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41159)\u001b[0m     @     0x7fb75de0d8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41160)\u001b[0m     @     0x7f78d779ca93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41160)\u001b[0m     @     0x7f78d779a388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41160)\u001b[0m     @     0x7f78d779c5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41160)\u001b[0m     @     0x7f78d7e874f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41151)\u001b[0m     @     0x7ef93e54da93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41151)\u001b[0m     @     0x7ef93e54b388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41151)\u001b[0m     @     0x7ef93e54d5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41151)\u001b[0m     @     0x7ef93ec384f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41216)\u001b[0m     @     0x7fbd9f675c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41216)\u001b[0m     @     0x7fbd9eb17a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41216)\u001b[0m     @     0x7fbd9eb15388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41157)\u001b[0m     @     0x7ed3a07d2a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41157)\u001b[0m     @     0x7ed3a07d0388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41157)\u001b[0m     @     0x7ed3a07d25a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41157)\u001b[0m     @     0x7ed3a0ebd4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41157)\u001b[0m     @     0x7ed3a33908de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41256)\u001b[0m     @     0x7ee491a3ec1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41256)\u001b[0m     @     0x7ee490ee0a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41256)\u001b[0m     @     0x7ee490ede388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41256)\u001b[0m     @     0x7ee490ee05a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41256)\u001b[0m     @     0x7ee4915cb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41232)\u001b[0m     @     0x7ee7db00c8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41232)\u001b[0m     @     0x7ee7db00cad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41206)\u001b[0m     @     0x7f75712baa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41206)\u001b[0m     @     0x7f75712b8388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41206)\u001b[0m     @     0x7f75712ba5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41206)\u001b[0m     @     0x7f75719a54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41171)\u001b[0m     @     0x7f225a7efc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41171)\u001b[0m     @     0x7f2259c91a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41171)\u001b[0m     @     0x7f2259c8f388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41171)\u001b[0m     @     0x7f2259c915a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41171)\u001b[0m     @     0x7f225a37c4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41223)\u001b[0m     @     0x7f5a89ee98f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41158)\u001b[0m     @     0x7f27ff7daa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41158)\u001b[0m     @     0x7f27ff7d8388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41158)\u001b[0m     @     0x7f27ff7da5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41158)\u001b[0m     @     0x7f27ffec54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41152)\u001b[0m     @     0x7f75fc58b5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41152)\u001b[0m     @     0x7f75fcc764f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41152)\u001b[0m     @     0x7f75ff1498de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41152)\u001b[0m     @     0x7f75fcc764f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41153)\u001b[0m     @     0x7f0f811f3a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41153)\u001b[0m     @     0x7f0f811f1388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41153)\u001b[0m     @     0x7f0f811f35a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41153)\u001b[0m     @     0x7f0f818de4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41222)\u001b[0m     @     0x7fa3e982dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41222)\u001b[0m     @     0x7fa3e8ccfa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41222)\u001b[0m     @     0x7fa3e8ccd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41222)\u001b[0m     @     0x7fa3e8ccf5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41170)\u001b[0m     @     0x7ed16de58c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41170)\u001b[0m     @     0x7ed16d2faa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41170)\u001b[0m     @     0x7ed16d2f8388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41170)\u001b[0m     @     0x7ed16d2fa5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41170)\u001b[0m     @     0x7ed16d9e54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41155)\u001b[0m     @     0x7fb8c8bd7a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41155)\u001b[0m     @     0x7fb8c8bd5388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41155)\u001b[0m     @     0x7fb8c8bd75a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41155)\u001b[0m     @     0x7fb8c92c24f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41145)\u001b[0m     @     0x7f2b38ee05a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41145)\u001b[0m     @     0x7f2b395cb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41145)\u001b[0m     @     0x7f2b3ba9e8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41220)\u001b[0m     @     0x7ee66d4d7c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41220)\u001b[0m     @     0x7ee66c979a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41220)\u001b[0m     @     0x7ee66c977388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41220)\u001b[0m     @     0x7ee66c9795a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41284)\u001b[0m     @     0x7ef4d4d54d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41284)\u001b[0m     @     0x7ef4d5637b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41284)\u001b[0m     @     0x7ef4d565ac1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41284)\u001b[0m     @     0x7ef4d4afca93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41284)\u001b[0m     @     0x7ef4d4afa388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41284)\u001b[0m     @     0x7ef4d4afc5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41229)\u001b[0m     @     0x7f8022f8ba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41229)\u001b[0m     @     0x7f8022f89388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41229)\u001b[0m     @     0x7f8022f8b5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41229)\u001b[0m     @     0x7f80236764f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41235)\u001b[0m     @     0x7fcbf0afad91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41235)\u001b[0m     @     0x7fcbf13ddb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41235)\u001b[0m     @     0x7fcbf1400c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41235)\u001b[0m     @     0x7fcbf08a2a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41235)\u001b[0m     @     0x7fcbf08a0388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41235)\u001b[0m     @     0x7fcbf08a25a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41187)\u001b[0m     @     0x7f4db1ad7a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41187)\u001b[0m     @     0x7f4db1ad5388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41187)\u001b[0m     @     0x7f4db1ad75a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41187)\u001b[0m     @     0x7f4db21c24f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41228)\u001b[0m     @     0x7f2e9480e388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41228)\u001b[0m     @     0x7f2e948105a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41228)\u001b[0m     @     0x7f2e94efb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41228)\u001b[0m     @     0x7f2e973ce8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41240)\u001b[0m     @     0x7f4412c27a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41240)\u001b[0m     @     0x7f4412c25388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41240)\u001b[0m     @     0x7f4412c275a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41240)\u001b[0m     @     0x7f44133124f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41224)\u001b[0m     @     0x7f81d651ed91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41224)\u001b[0m     @     0x7f81d6e01b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41224)\u001b[0m     @     0x7f81d6e24c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41224)\u001b[0m     @     0x7f81d62c6a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41224)\u001b[0m     @     0x7f81d62c4388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41224)\u001b[0m     @     0x7f81d62c65a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41177)\u001b[0m     @     0x7f53410e9c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41177)\u001b[0m     @     0x7f534058ba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41177)\u001b[0m     @     0x7f5340589388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41177)\u001b[0m     @     0x7f534058b5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41249)\u001b[0m     @     0x7f7f96fcb5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41249)\u001b[0m     @     0x7f7f976b64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41249)\u001b[0m     @     0x7f7f99b898de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41161)\u001b[0m     @     0x7f2026ad44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41161)\u001b[0m     @     0x7f2028fa78de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41163)\u001b[0m     @     0x7f430323ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41163)\u001b[0m     @     0x7f430325dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41163)\u001b[0m     @     0x7f43026ffa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41241)\u001b[0m     @     0x7fc897223ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41213)\u001b[0m     @     0x7f5eb50e3a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41213)\u001b[0m     @     0x7f5eb50e1388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41213)\u001b[0m     @     0x7f5eb50e35a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41246)\u001b[0m     @     0x7ee73ee9ba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41246)\u001b[0m     @     0x7ee73ee99388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41279)\u001b[0m     @     0x7f43456105a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41279)\u001b[0m     @     0x7f4345cfb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41279)\u001b[0m     @     0x7f43481ce8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41178)\u001b[0m     @     0x7ef8723e9a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41178)\u001b[0m     @     0x7ef8723e7388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41178)\u001b[0m     @     0x7ef8723e95a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41218)\u001b[0m     @     0x7f28c25604f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41218)\u001b[0m     @     0x7f28c4a338de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41262)\u001b[0m     @     0x7f99f2dea4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41262)\u001b[0m     @     0x7f99f52bd8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41148)\u001b[0m     @     0x7f3474e16a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41148)\u001b[0m     @     0x7f3474e14388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41183)\u001b[0m     @     0x7fa84affb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41183)\u001b[0m     @     0x7fa84d4ce8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41207)\u001b[0m     @     0x7f7d47cc24f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41207)\u001b[0m     @     0x7f7d4a1958de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41207)\u001b[0m     @     0x7f7d47cc24f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41207)\u001b[0m     @     0x7f7d4dd6d79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41207)\u001b[0m     @     0x5619dca21fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41207)\u001b[0m     @     0x5619dc97cb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41207)\u001b[0m     @     0x5619dca07baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41207)\u001b[0m     @     0x5619dca08a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41207)\u001b[0m     @     0x5619dc97cbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41207)\u001b[0m     @     0x5619dca07baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41207)\u001b[0m     @     0x5619dca08643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41207)\u001b[0m     @     0x5619dc97d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41207)\u001b[0m     @     0x5619dca07baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41207)\u001b[0m     @     0x5619dca08643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41207)\u001b[0m     @     0x5619dc97d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41207)\u001b[0m     @     0x5619dca07baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41207)\u001b[0m     @     0x5619dca08643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41214)\u001b[0m     @     0x7f68105404f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41214)\u001b[0m     @     0x7f68165eb79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41214)\u001b[0m     @     0x557b9523bfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41214)\u001b[0m     @     0x557b95196b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41214)\u001b[0m     @     0x557b95221baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41214)\u001b[0m     @     0x557b95222a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41214)\u001b[0m     @     0x557b95196bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41214)\u001b[0m     @     0x557b95221baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41214)\u001b[0m     @     0x557b95222643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41214)\u001b[0m     @     0x557b95197689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41214)\u001b[0m     @     0x557b95221baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41214)\u001b[0m     @     0x557b95222643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41214)\u001b[0m     @     0x557b95197689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41214)\u001b[0m     @     0x557b95221baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41214)\u001b[0m     @     0x557b95222643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41214)\u001b[0m     @     0x557b95197689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41214)\u001b[0m     @     0x557b95221baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41149)\u001b[0m     @     0x7f1d0a5098de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41149)\u001b[0m     @     0x7f1d080364f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41149)\u001b[0m     @     0x7f1d0e0e179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41149)\u001b[0m     @     0x55ab0b6e5fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41149)\u001b[0m     @     0x55ab0b640b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41149)\u001b[0m     @     0x55ab0b6cbbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41149)\u001b[0m     @     0x55ab0b6cca20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41149)\u001b[0m     @     0x55ab0b640bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41149)\u001b[0m     @     0x55ab0b6cbbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41149)\u001b[0m     @     0x55ab0b6cc643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41149)\u001b[0m     @     0x55ab0b641689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41149)\u001b[0m     @     0x55ab0b6cbbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41149)\u001b[0m     @     0x55ab0b6cc643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41149)\u001b[0m     @     0x55ab0b641689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41149)\u001b[0m     @     0x55ab0b6cbbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41149)\u001b[0m     @     0x55ab0b6cc643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41149)\u001b[0m     @     0x55ab0b641689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41149)\u001b[0m     @     0x55ab0b6cbbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41149)\u001b[0m     @     0x55ab0b6cc643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41184)\u001b[0m     @     0x7ed29b9cc4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41184)\u001b[0m     @     0x7ed29de9f8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41184)\u001b[0m     @     0x7ed29b9cc4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41184)\u001b[0m     @     0x7ed2a1a7779f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41184)\u001b[0m     @     0x56369b21afd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41184)\u001b[0m     @     0x56369b175b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41184)\u001b[0m     @     0x56369b200baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41184)\u001b[0m     @     0x56369b201a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41184)\u001b[0m     @     0x56369b175bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41184)\u001b[0m     @     0x56369b200baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41184)\u001b[0m     @     0x56369b201643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41184)\u001b[0m     @     0x56369b176689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41150)\u001b[0m     @     0x7fa6228bd4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41150)\u001b[0m     @     0x7fa624d908de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41150)\u001b[0m     @     0x7fa6228bd4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41227)\u001b[0m     @     0x7fcbd4c764f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41227)\u001b[0m     @     0x7fcbd71498de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41227)\u001b[0m     @     0x7fcbd4c764f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41174)\u001b[0m     @     0x7f36438b95a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41174)\u001b[0m     @     0x7f3643fa44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41174)\u001b[0m     @     0x7f36464778de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41215)\u001b[0m     @     0x55de5efcf689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41215)\u001b[0m     @     0x55de5f059baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41215)\u001b[0m     @     0x55de5f05a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41215)\u001b[0m     @     0x55de5efcf689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41215)\u001b[0m     @     0x55de5f059baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41215)\u001b[0m     @     0x55de5f05a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41215)\u001b[0m     @     0x55de5efcf689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41215)\u001b[0m     @     0x55de5f059baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41215)\u001b[0m     @     0x55de5f05a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41215)\u001b[0m     @     0x55de5efcf689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41162)\u001b[0m     @     0x7fadf46108de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41162)\u001b[0m     @     0x7fadf213d4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41162)\u001b[0m     @     0x7fadf81e879f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41162)\u001b[0m     @     0x5629851a8fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41162)\u001b[0m     @     0x562985103b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41162)\u001b[0m     @     0x56298518ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41162)\u001b[0m     @     0x56298518fa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41162)\u001b[0m     @     0x562985103bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41162)\u001b[0m     @     0x56298518ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41162)\u001b[0m     @     0x56298518f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41162)\u001b[0m     @     0x562985104689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41162)\u001b[0m     @     0x56298518ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41162)\u001b[0m     @     0x56298518f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41162)\u001b[0m     @     0x562985104689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41162)\u001b[0m     @     0x56298518ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41162)\u001b[0m     @     0x56298518f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41162)\u001b[0m     @     0x562985104689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41162)\u001b[0m     @     0x56298518ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41162)\u001b[0m     @     0x56298518f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41162)\u001b[0m     @     0x562985104689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41166)\u001b[0m     @     0x7fa9ff6b64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41166)\u001b[0m     @     0x7faa01b898de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41166)\u001b[0m     @     0x7fa9ff6b64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41166)\u001b[0m     @     0x7faa0576179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41166)\u001b[0m     @     0x5560d934ffd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41166)\u001b[0m     @     0x5560d92aab08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41166)\u001b[0m     @     0x5560d9335baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41166)\u001b[0m     @     0x5560d9336a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41166)\u001b[0m     @     0x5560d92aabfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41166)\u001b[0m     @     0x5560d9335baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41166)\u001b[0m     @     0x5560d9336643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41166)\u001b[0m     @     0x5560d92ab689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41166)\u001b[0m     @     0x5560d9335baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41166)\u001b[0m     @     0x5560d9336643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41147)\u001b[0m     @     0x7fc97c3354f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41147)\u001b[0m     @     0x7fc9823e079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41147)\u001b[0m     @     0x5606c1b67fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41147)\u001b[0m     @     0x5606c1ac2b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41147)\u001b[0m     @     0x5606c1b4dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41147)\u001b[0m     @     0x5606c1b4ea20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41147)\u001b[0m     @     0x5606c1ac2bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41147)\u001b[0m     @     0x5606c1b4dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41147)\u001b[0m     @     0x5606c1b4e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41147)\u001b[0m     @     0x5606c1ac3689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41147)\u001b[0m     @     0x5606c1b4dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41147)\u001b[0m     @     0x5606c1b4e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41147)\u001b[0m     @     0x5606c1ac3689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41147)\u001b[0m     @     0x5606c1b4dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41147)\u001b[0m     @     0x5606c1b4e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41147)\u001b[0m     @     0x5606c1ac3689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41147)\u001b[0m     @     0x5606c1b4dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41147)\u001b[0m     @     0x5606c1b4e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41147)\u001b[0m     @     0x5606c1ac3689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41144)\u001b[0m     @     0x7fc9610a44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41144)\u001b[0m     @     0x7fc9635778de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41144)\u001b[0m     @     0x7fc9610a44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41230)\u001b[0m     @     0x7fa68bcfb5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41230)\u001b[0m     @     0x7fa68c3e64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41230)\u001b[0m     @     0x7fa68e8b98de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41146)\u001b[0m     @     0x7f6010597a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41146)\u001b[0m     @     0x7f6010595388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41219)\u001b[0m     @     0x7f699f582a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41219)\u001b[0m     @     0x7f699f580388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41219)\u001b[0m     @     0x7f699f5825a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41236)\u001b[0m     @     0x7ef25f6b64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41236)\u001b[0m     @     0x7ef261b898de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41236)\u001b[0m     @     0x7ef25f6b64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41210)\u001b[0m     @     0x7f199616ec1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41210)\u001b[0m     @     0x7f1995610a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41210)\u001b[0m     @     0x7f199560e388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41210)\u001b[0m     @     0x7f19956105a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41164)\u001b[0m     @     0x7fabb2b575a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41164)\u001b[0m     @     0x7fabb32424f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41164)\u001b[0m     @     0x7fabb57158de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41176)\u001b[0m     @     0x7ef00eac55a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41176)\u001b[0m     @     0x7ef00f1b04f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41176)\u001b[0m     @     0x7ef0116838de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41180)\u001b[0m     @     0x7f07d91c5a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41180)\u001b[0m     @     0x7f07d91c3388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41180)\u001b[0m     @     0x7f07d91c55a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41221)\u001b[0m     @     0x7f1f7a1265a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41221)\u001b[0m     @     0x7f1f7a8114f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41217)\u001b[0m     @     0x7fac5637c4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41217)\u001b[0m     @     0x7fac5884f8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41217)\u001b[0m     @     0x7fac5637c4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41217)\u001b[0m     @     0x7fac5c42779f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41217)\u001b[0m     @     0x5627aae29fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41217)\u001b[0m     @     0x5627aad84b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41247)\u001b[0m     @     0x55aeea230643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41247)\u001b[0m     @     0x55aeea1a5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41247)\u001b[0m     @     0x55aeea22fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41247)\u001b[0m     @     0x55aeea230643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41247)\u001b[0m     @     0x55aeea1a5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41231)\u001b[0m     @     0x7ed93bca18de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41231)\u001b[0m     @     0x7ed9397ce4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41231)\u001b[0m     @     0x7ed93f87979f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41231)\u001b[0m     @     0x5639106fdfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41231)\u001b[0m     @     0x563910658b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41231)\u001b[0m     @     0x5639106e3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41231)\u001b[0m     @     0x5639106e4a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41231)\u001b[0m     @     0x563910658bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41231)\u001b[0m     @     0x5639106e3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41231)\u001b[0m     @     0x5639106e4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41231)\u001b[0m     @     0x563910659689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41231)\u001b[0m     @     0x5639106e3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41231)\u001b[0m     @     0x5639106e4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41231)\u001b[0m     @     0x563910659689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41231)\u001b[0m     @     0x5639106e3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41231)\u001b[0m     @     0x5639106e4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41231)\u001b[0m     @     0x563910659689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41231)\u001b[0m     @     0x5639106e3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41231)\u001b[0m     @     0x5639106e4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41231)\u001b[0m     @     0x563910659689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41159)\u001b[0m     @     0x7fb75b93a4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41159)\u001b[0m     @     0x7fb7619e579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41159)\u001b[0m     @     0x55980f2d1fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41159)\u001b[0m     @     0x55980f22cb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41159)\u001b[0m     @     0x55980f2b7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41159)\u001b[0m     @     0x55980f2b8a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41159)\u001b[0m     @     0x55980f22cbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41159)\u001b[0m     @     0x55980f2b7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41159)\u001b[0m     @     0x55980f2b8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41159)\u001b[0m     @     0x55980f22d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41159)\u001b[0m     @     0x55980f2b7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41159)\u001b[0m     @     0x55980f2b8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41159)\u001b[0m     @     0x55980f22d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41159)\u001b[0m     @     0x55980f2b7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41159)\u001b[0m     @     0x55980f2b8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41159)\u001b[0m     @     0x55980f22d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41159)\u001b[0m     @     0x55980f2b7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41159)\u001b[0m     @     0x55980f2b8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41159)\u001b[0m     @     0x55980f22d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41160)\u001b[0m     @     0x7f78da35a8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41160)\u001b[0m     @     0x7f78d7e874f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41160)\u001b[0m     @     0x7f78ddf3279f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41160)\u001b[0m     @     0x564586fa0fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41160)\u001b[0m     @     0x564586efbb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41160)\u001b[0m     @     0x564586f86baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41160)\u001b[0m     @     0x564586f87a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41160)\u001b[0m     @     0x564586efbbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41160)\u001b[0m     @     0x564586f86baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41160)\u001b[0m     @     0x564586f87643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41160)\u001b[0m     @     0x564586efc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41160)\u001b[0m     @     0x564586f86baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41160)\u001b[0m     @     0x564586f87643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41160)\u001b[0m     @     0x564586efc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41160)\u001b[0m     @     0x564586f86baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41160)\u001b[0m     @     0x564586f87643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41160)\u001b[0m     @     0x564586efc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41160)\u001b[0m     @     0x564586f86baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41160)\u001b[0m     @     0x564586f87643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41160)\u001b[0m     @     0x564586efc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41151)\u001b[0m     @     0x7ef94110b8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41151)\u001b[0m     @     0x7ef93ec384f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41151)\u001b[0m     @     0x7ef944ce379f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41151)\u001b[0m     @     0x561038359fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41151)\u001b[0m     @     0x5610382b4b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41151)\u001b[0m     @     0x56103833fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41151)\u001b[0m     @     0x561038340a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41151)\u001b[0m     @     0x5610382b4bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41151)\u001b[0m     @     0x56103833fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41151)\u001b[0m     @     0x561038340643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41151)\u001b[0m     @     0x5610382b5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41151)\u001b[0m     @     0x56103833fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41151)\u001b[0m     @     0x561038340643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41151)\u001b[0m     @     0x5610382b5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41151)\u001b[0m     @     0x56103833fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41151)\u001b[0m     @     0x561038340643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41151)\u001b[0m     @     0x5610382b5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41151)\u001b[0m     @     0x56103833fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41151)\u001b[0m     @     0x561038340643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41151)\u001b[0m     @     0x5610382b5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41216)\u001b[0m     @     0x7fbd9eb175a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41216)\u001b[0m     @     0x7fbd9f2024f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41216)\u001b[0m     @     0x7fbda16d58de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41157)\u001b[0m     @     0x7ed3a0ebd4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41157)\u001b[0m     @     0x7ed3a6f6879f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41157)\u001b[0m     @     0x559478469fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41157)\u001b[0m     @     0x5594783c4b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41157)\u001b[0m     @     0x55947844fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41157)\u001b[0m     @     0x559478450a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41157)\u001b[0m     @     0x5594783c4bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41157)\u001b[0m     @     0x55947844fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41157)\u001b[0m     @     0x559478450643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41157)\u001b[0m     @     0x5594783c5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41157)\u001b[0m     @     0x55947844fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41157)\u001b[0m     @     0x559478450643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41157)\u001b[0m     @     0x5594783c5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41157)\u001b[0m     @     0x55947844fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41157)\u001b[0m     @     0x559478450643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41157)\u001b[0m     @     0x5594783c5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41157)\u001b[0m     @     0x55947844fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41157)\u001b[0m     @     0x559478450643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41157)\u001b[0m     @     0x5594783c5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41256)\u001b[0m     @     0x7ee493a9e8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41256)\u001b[0m     @     0x7ee4915cb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41232)\u001b[0m     @     0x7ee7db00cd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41206)\u001b[0m     @     0x7f7573e788de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41171)\u001b[0m     @     0x7f225c84f8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41171)\u001b[0m     @     0x7f225a37c4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41171)\u001b[0m     @     0x7f226042779f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41171)\u001b[0m     @     0x564ea45fbfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41171)\u001b[0m     @     0x564ea4556b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41223)\u001b[0m     @     0x7f5a89ee9ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41223)\u001b[0m     @     0x7f5a89ee9d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41158)\u001b[0m     @     0x7f28023988de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41158)\u001b[0m     @     0x7f27ffec54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41152)\u001b[0m     @     0x7f7602d2179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41152)\u001b[0m     @     0x55fe8e8bbfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41152)\u001b[0m     @     0x55fe8e816b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41152)\u001b[0m     @     0x55fe8e8a1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41152)\u001b[0m     @     0x55fe8e8a2a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41152)\u001b[0m     @     0x55fe8e816bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41152)\u001b[0m     @     0x55fe8e8a1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41152)\u001b[0m     @     0x55fe8e8a2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41152)\u001b[0m     @     0x55fe8e817689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41152)\u001b[0m     @     0x55fe8e8a1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41152)\u001b[0m     @     0x55fe8e8a2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41152)\u001b[0m     @     0x55fe8e817689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41152)\u001b[0m     @     0x55fe8e8a1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41152)\u001b[0m     @     0x55fe8e8a2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41152)\u001b[0m     @     0x55fe8e817689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41152)\u001b[0m     @     0x55fe8e8a1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41152)\u001b[0m     @     0x55fe8e8a2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41152)\u001b[0m     @     0x55fe8e817689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41153)\u001b[0m     @     0x7f0f83db18de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41153)\u001b[0m     @     0x7f0f818de4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41153)\u001b[0m     @     0x7f0f8798979f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41153)\u001b[0m     @     0x55d772b2afd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41153)\u001b[0m     @     0x55d772a85b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41153)\u001b[0m     @     0x55d772b10baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41153)\u001b[0m     @     0x55d772b11a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41153)\u001b[0m     @     0x55d772a85bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41222)\u001b[0m     @     0x7fa3e93ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41222)\u001b[0m     @     0x7fa3eb88d8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41170)\u001b[0m     @     0x7ed16feb88de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41170)\u001b[0m     @     0x7ed16d9e54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41170)\u001b[0m     @     0x7ed173a9079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41170)\u001b[0m     @     0x559cee89afd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41170)\u001b[0m     @     0x559cee7f5b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41170)\u001b[0m     @     0x559cee880baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41170)\u001b[0m     @     0x559cee881a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41170)\u001b[0m     @     0x559cee7f5bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41170)\u001b[0m     @     0x559cee880baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41170)\u001b[0m     @     0x559cee881643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41170)\u001b[0m     @     0x559cee7f6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41170)\u001b[0m     @     0x559cee880baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41170)\u001b[0m     @     0x559cee881643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41170)\u001b[0m     @     0x559cee7f6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41170)\u001b[0m     @     0x559cee880baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41170)\u001b[0m     @     0x559cee881643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41170)\u001b[0m     @     0x559cee7f6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41170)\u001b[0m     @     0x559cee880baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41170)\u001b[0m     @     0x559cee881643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41170)\u001b[0m     @     0x559cee7f6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41155)\u001b[0m     @     0x7fb8cb7958de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41155)\u001b[0m     @     0x7fb8c92c24f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41155)\u001b[0m     @     0x7fb8cf36d79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41155)\u001b[0m     @     0x55f6e9abdfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41155)\u001b[0m     @     0x55f6e9a18b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41155)\u001b[0m     @     0x55f6e9aa3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41155)\u001b[0m     @     0x55f6e9aa4a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41155)\u001b[0m     @     0x55f6e9a18bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41155)\u001b[0m     @     0x55f6e9aa3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41155)\u001b[0m     @     0x55f6e9aa4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41155)\u001b[0m     @     0x55f6e9a19689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41155)\u001b[0m     @     0x55f6e9aa3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41155)\u001b[0m     @     0x55f6e9aa4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41155)\u001b[0m     @     0x55f6e9a19689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41155)\u001b[0m     @     0x55f6e9aa3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41155)\u001b[0m     @     0x55f6e9aa4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41155)\u001b[0m     @     0x55f6e9a19689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41155)\u001b[0m     @     0x55f6e9aa3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41155)\u001b[0m     @     0x55f6e9aa4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41155)\u001b[0m     @     0x55f6e9a19689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41145)\u001b[0m     @     0x7f2b395cb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41145)\u001b[0m     @     0x7f2b3f67679f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41145)\u001b[0m     @     0x561adeab9fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41145)\u001b[0m     @     0x561adea14b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41145)\u001b[0m     @     0x561adea9fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41145)\u001b[0m     @     0x561adeaa0a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41145)\u001b[0m     @     0x561adea14bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41145)\u001b[0m     @     0x561adea9fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41145)\u001b[0m     @     0x561adeaa0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41145)\u001b[0m     @     0x561adea15689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41145)\u001b[0m     @     0x561adea9fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41145)\u001b[0m     @     0x561adeaa0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41145)\u001b[0m     @     0x561adea15689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41145)\u001b[0m     @     0x561adea9fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41145)\u001b[0m     @     0x561adeaa0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41145)\u001b[0m     @     0x561adea15689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41145)\u001b[0m     @     0x561adea9fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41145)\u001b[0m     @     0x561adeaa0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41145)\u001b[0m     @     0x561adea15689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41220)\u001b[0m     @     0x7ee66d0644f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41220)\u001b[0m     @     0x7ee66f5378de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41220)\u001b[0m     @     0x7ee66d0644f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41220)\u001b[0m     @     0x7ee67310f79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41220)\u001b[0m     @     0x5637809ebfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41220)\u001b[0m     @     0x563780946b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41220)\u001b[0m     @     0x5637809d1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41220)\u001b[0m     @     0x5637809d2a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41220)\u001b[0m     @     0x563780946bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41220)\u001b[0m     @     0x5637809d1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41220)\u001b[0m     @     0x5637809d2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41220)\u001b[0m     @     0x563780947689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41220)\u001b[0m     @     0x5637809d1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41220)\u001b[0m     @     0x5637809d2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41220)\u001b[0m     @     0x563780947689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41220)\u001b[0m     @     0x5637809d1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41220)\u001b[0m     @     0x5637809d2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41220)\u001b[0m     @     0x563780947689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41220)\u001b[0m     @     0x5637809d1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41220)\u001b[0m     @     0x5637809d2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41220)\u001b[0m     @     0x563780947689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41284)\u001b[0m     @     0x7ef4d51e74f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41284)\u001b[0m     @     0x7ef4d76ba8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41284)\u001b[0m     @     0x7ef4d51e74f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41284)\u001b[0m     @     0x7ef4db29279f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41284)\u001b[0m     @     0x55eb3daebfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41284)\u001b[0m     @     0x55eb3da46b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41284)\u001b[0m     @     0x55eb3dad1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41284)\u001b[0m     @     0x55eb3dad2a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41284)\u001b[0m     @     0x55eb3da46bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41284)\u001b[0m     @     0x55eb3dad1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41284)\u001b[0m     @     0x55eb3dad2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41284)\u001b[0m     @     0x55eb3da47689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41284)\u001b[0m     @     0x55eb3dad1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41284)\u001b[0m     @     0x55eb3dad2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41284)\u001b[0m     @     0x55eb3da47689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41284)\u001b[0m     @     0x55eb3dad1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41284)\u001b[0m     @     0x55eb3dad2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41284)\u001b[0m     @     0x55eb3da47689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41284)\u001b[0m     @     0x55eb3dad1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41284)\u001b[0m     @     0x55eb3dad2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41284)\u001b[0m     @     0x55eb3da47689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41229)\u001b[0m     @     0x7f8025b498de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41229)\u001b[0m     @     0x7f80236764f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41229)\u001b[0m     @     0x7f802972179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41229)\u001b[0m     @     0x55e497473fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41229)\u001b[0m     @     0x55e4973ceb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41229)\u001b[0m     @     0x55e497459baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41229)\u001b[0m     @     0x55e49745aa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41229)\u001b[0m     @     0x55e4973cebfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41229)\u001b[0m     @     0x55e497459baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41229)\u001b[0m     @     0x55e49745a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41229)\u001b[0m     @     0x55e4973cf689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41229)\u001b[0m     @     0x55e497459baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41229)\u001b[0m     @     0x55e49745a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41229)\u001b[0m     @     0x55e4973cf689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41229)\u001b[0m     @     0x55e497459baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41229)\u001b[0m     @     0x55e49745a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41229)\u001b[0m     @     0x55e4973cf689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41229)\u001b[0m     @     0x55e497459baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41229)\u001b[0m     @     0x55e49745a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41229)\u001b[0m     @     0x55e4973cf689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41235)\u001b[0m     @     0x7fcbf0f8d4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41235)\u001b[0m     @     0x7fcbf34608de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41235)\u001b[0m     @     0x7fcbf0f8d4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41187)\u001b[0m     @     0x7f4db46958de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41187)\u001b[0m     @     0x7f4db21c24f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41187)\u001b[0m     @     0x7f4db826d79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41187)\u001b[0m     @     0x55d8f7df2fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41187)\u001b[0m     @     0x55d8f7d4db08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41187)\u001b[0m     @     0x55d8f7dd8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41187)\u001b[0m     @     0x55d8f7dd9a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41187)\u001b[0m     @     0x55d8f7d4dbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41187)\u001b[0m     @     0x55d8f7dd8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41187)\u001b[0m     @     0x55d8f7dd9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41187)\u001b[0m     @     0x55d8f7d4e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41187)\u001b[0m     @     0x55d8f7dd8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41187)\u001b[0m     @     0x55d8f7dd9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41187)\u001b[0m     @     0x55d8f7d4e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41187)\u001b[0m     @     0x55d8f7dd8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41187)\u001b[0m     @     0x55d8f7dd9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41187)\u001b[0m     @     0x55d8f7d4e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41187)\u001b[0m     @     0x55d8f7dd8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41187)\u001b[0m     @     0x55d8f7dd9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41187)\u001b[0m     @     0x55d8f7d4e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41228)\u001b[0m     @     0x7f2e94efb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41228)\u001b[0m     @     0x7f2e9afa679f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41228)\u001b[0m     @     0x562582a8bfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41228)\u001b[0m     @     0x5625829e6b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41228)\u001b[0m     @     0x562582a71baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41228)\u001b[0m     @     0x562582a72a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41228)\u001b[0m     @     0x5625829e6bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41228)\u001b[0m     @     0x562582a71baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41228)\u001b[0m     @     0x562582a72643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41228)\u001b[0m     @     0x5625829e7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41228)\u001b[0m     @     0x562582a71baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41228)\u001b[0m     @     0x562582a72643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41228)\u001b[0m     @     0x5625829e7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41228)\u001b[0m     @     0x562582a71baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41228)\u001b[0m     @     0x562582a72643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41228)\u001b[0m     @     0x5625829e7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41228)\u001b[0m     @     0x562582a71baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41228)\u001b[0m     @     0x562582a72643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41228)\u001b[0m     @     0x5625829e7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41240)\u001b[0m     @     0x7f44157e58de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41240)\u001b[0m     @     0x7f44133124f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41240)\u001b[0m     @     0x7f44193bd79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41240)\u001b[0m     @     0x562fbd121fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41240)\u001b[0m     @     0x562fbd07cb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41240)\u001b[0m     @     0x562fbd107baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41240)\u001b[0m     @     0x562fbd108a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41240)\u001b[0m     @     0x562fbd07cbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41240)\u001b[0m     @     0x562fbd107baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41240)\u001b[0m     @     0x562fbd108643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41240)\u001b[0m     @     0x562fbd07d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41240)\u001b[0m     @     0x562fbd107baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41240)\u001b[0m     @     0x562fbd108643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41240)\u001b[0m     @     0x562fbd07d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41240)\u001b[0m     @     0x562fbd107baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41240)\u001b[0m     @     0x562fbd108643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41240)\u001b[0m     @     0x562fbd07d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41240)\u001b[0m     @     0x562fbd107baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41240)\u001b[0m     @     0x562fbd108643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41240)\u001b[0m     @     0x562fbd07d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41224)\u001b[0m     @     0x7f81d69b14f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41224)\u001b[0m     @     0x7f81d8e848de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41224)\u001b[0m     @     0x7f81d69b14f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41177)\u001b[0m     @     0x7f5340c764f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41177)\u001b[0m     @     0x7f53431498de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41177)\u001b[0m     @     0x7f5340c764f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41177)\u001b[0m     @     0x7f5346d2179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41177)\u001b[0m     @     0x55eeb973cfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41177)\u001b[0m     @     0x55eeb9697b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41177)\u001b[0m     @     0x55eeb9722baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41177)\u001b[0m     @     0x55eeb9723a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41177)\u001b[0m     @     0x55eeb9697bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41177)\u001b[0m     @     0x55eeb9722baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41177)\u001b[0m     @     0x55eeb9723643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41177)\u001b[0m     @     0x55eeb9698689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41177)\u001b[0m     @     0x55eeb9722baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41177)\u001b[0m     @     0x55eeb9723643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41177)\u001b[0m     @     0x55eeb9698689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41177)\u001b[0m     @     0x55eeb9722baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41177)\u001b[0m     @     0x55eeb9723643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41177)\u001b[0m     @     0x55eeb9698689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41177)\u001b[0m     @     0x55eeb9722baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41177)\u001b[0m     @     0x55eeb9723643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41177)\u001b[0m     @     0x55eeb9698689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41249)\u001b[0m     @     0x7f7f976b64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41249)\u001b[0m     @     0x7f7f9d76179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41249)\u001b[0m     @     0x55ba22540fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41249)\u001b[0m     @     0x55ba2249bb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41249)\u001b[0m     @     0x55ba22526baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41249)\u001b[0m     @     0x55ba22527a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41249)\u001b[0m     @     0x55ba2249bbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41249)\u001b[0m     @     0x55ba22526baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41249)\u001b[0m     @     0x55ba22527643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41249)\u001b[0m     @     0x55ba2249c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41249)\u001b[0m     @     0x55ba22526baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41249)\u001b[0m     @     0x55ba22527643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41249)\u001b[0m     @     0x55ba2249c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41249)\u001b[0m     @     0x55ba22526baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41249)\u001b[0m     @     0x55ba22527643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41249)\u001b[0m     @     0x55ba2249c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41249)\u001b[0m     @     0x55ba22526baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41249)\u001b[0m     @     0x55ba22527643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41249)\u001b[0m     @     0x55ba2249c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41161)\u001b[0m     @     0x7f2026ad44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41161)\u001b[0m     @     0x7f202cb7f79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41161)\u001b[0m     @     0x562ed0bcbfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41161)\u001b[0m     @     0x562ed0b26b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41161)\u001b[0m     @     0x562ed0bb1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41161)\u001b[0m     @     0x562ed0bb2a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41161)\u001b[0m     @     0x562ed0b26bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41161)\u001b[0m     @     0x562ed0bb1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41161)\u001b[0m     @     0x562ed0bb2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41161)\u001b[0m     @     0x562ed0b27689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41161)\u001b[0m     @     0x562ed0bb1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41161)\u001b[0m     @     0x562ed0bb2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41161)\u001b[0m     @     0x562ed0b27689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41161)\u001b[0m     @     0x562ed0bb1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41161)\u001b[0m     @     0x562ed0bb2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41161)\u001b[0m     @     0x562ed0b27689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41161)\u001b[0m     @     0x562ed0bb1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41161)\u001b[0m     @     0x562ed0bb2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41161)\u001b[0m     @     0x562ed0b27689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41163)\u001b[0m     @     0x7f43026fd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41163)\u001b[0m     @     0x7f43026ff5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41163)\u001b[0m     @     0x7f4302dea4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41241)\u001b[0m     @     0x7fc897223d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41241)\u001b[0m     @     0x7fc897b06b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41241)\u001b[0m     @     0x7fc897b29c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41241)\u001b[0m     @     0x7fc896fcba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41241)\u001b[0m     @     0x7fc896fc9388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41213)\u001b[0m     @     0x7f5eb57ce4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41213)\u001b[0m     @     0x7f5eb7ca18de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41213)\u001b[0m     @     0x7f5eb57ce4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41213)\u001b[0m     @     0x7f5ebb87979f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41213)\u001b[0m     @     0x558f5544afd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41213)\u001b[0m     @     0x558f553a5b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41213)\u001b[0m     @     0x558f55430baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41213)\u001b[0m     @     0x558f55431a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41213)\u001b[0m     @     0x558f553a5bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41213)\u001b[0m     @     0x558f55430baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41246)\u001b[0m     @     0x7ee73ee9b5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41246)\u001b[0m     @     0x7ee73f5864f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41246)\u001b[0m     @     0x7ee741a598de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41246)\u001b[0m     @     0x7ee73f5864f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41279)\u001b[0m     @     0x7f4345cfb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41279)\u001b[0m     @     0x7f434bda679f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41279)\u001b[0m     @     0x560dab015fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41279)\u001b[0m     @     0x560daaf70b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41279)\u001b[0m     @     0x560daaffbbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41279)\u001b[0m     @     0x560daaffca20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41279)\u001b[0m     @     0x560daaf70bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41279)\u001b[0m     @     0x560daaffbbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41279)\u001b[0m     @     0x560daaffc643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41279)\u001b[0m     @     0x560daaf71689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41279)\u001b[0m     @     0x560daaffbbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41279)\u001b[0m     @     0x560daaffc643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41279)\u001b[0m     @     0x560daaf71689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41279)\u001b[0m     @     0x560daaffbbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41279)\u001b[0m     @     0x560daaffc643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41279)\u001b[0m     @     0x560daaf71689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41279)\u001b[0m     @     0x560daaffbbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41279)\u001b[0m     @     0x560daaffc643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41279)\u001b[0m     @     0x560daaf71689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41209)\u001b[0m     @     0x7fb9d4cadad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41209)\u001b[0m     @     0x7fb9d4cadd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=41209)\u001b[0m     @     0x7fb9d5590b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41209)\u001b[0m     @     0x7fb9d55b3c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41178)\u001b[0m     @     0x7ef872ad44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41178)\u001b[0m     @     0x7ef874fa78de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41178)\u001b[0m     @     0x7ef872ad44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41218)\u001b[0m     @     0x7f28c25604f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41218)\u001b[0m     @     0x7f28c860b79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41218)\u001b[0m     @     0x555f67092fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41218)\u001b[0m     @     0x555f66fedb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41218)\u001b[0m     @     0x555f67078baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41218)\u001b[0m     @     0x555f67079a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41218)\u001b[0m     @     0x555f66fedbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41218)\u001b[0m     @     0x555f67078baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41218)\u001b[0m     @     0x555f67079643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41218)\u001b[0m     @     0x555f66fee689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41218)\u001b[0m     @     0x555f67078baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41218)\u001b[0m     @     0x555f67079643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41218)\u001b[0m     @     0x555f66fee689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41218)\u001b[0m     @     0x555f67078baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41218)\u001b[0m     @     0x555f67079643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41218)\u001b[0m     @     0x555f66fee689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41218)\u001b[0m     @     0x555f67078baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41218)\u001b[0m     @     0x555f67079643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41218)\u001b[0m     @     0x555f66fee689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41262)\u001b[0m     @     0x7f99f2dea4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41262)\u001b[0m     @     0x7f99f8e9579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41262)\u001b[0m     @     0x55ef48766fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41262)\u001b[0m     @     0x55ef486c1b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41262)\u001b[0m     @     0x55ef4874cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41262)\u001b[0m     @     0x55ef4874da20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41262)\u001b[0m     @     0x55ef486c1bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41262)\u001b[0m     @     0x55ef4874cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41262)\u001b[0m     @     0x55ef4874d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41262)\u001b[0m     @     0x55ef486c2689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41262)\u001b[0m     @     0x55ef4874cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41262)\u001b[0m     @     0x55ef4874d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41262)\u001b[0m     @     0x55ef486c2689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41262)\u001b[0m     @     0x55ef4874cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41262)\u001b[0m     @     0x55ef4874d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41262)\u001b[0m     @     0x55ef486c2689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41262)\u001b[0m     @     0x55ef4874cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41262)\u001b[0m     @     0x55ef4874d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41262)\u001b[0m     @     0x55ef486c2689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41148)\u001b[0m     @     0x7f3474e165a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41148)\u001b[0m     @     0x7f34755014f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41183)\u001b[0m     @     0x7fa84affb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41183)\u001b[0m     @     0x7fa8510a679f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41183)\u001b[0m     @     0x55b377b5cfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41183)\u001b[0m     @     0x55b377ab7b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41183)\u001b[0m     @     0x55b377b42baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41183)\u001b[0m     @     0x55b377b43a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41183)\u001b[0m     @     0x55b377ab7bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41183)\u001b[0m     @     0x55b377b42baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41183)\u001b[0m     @     0x55b377b43643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41183)\u001b[0m     @     0x55b377ab8689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41183)\u001b[0m     @     0x55b377b42baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41183)\u001b[0m     @     0x55b377b43643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41183)\u001b[0m     @     0x55b377ab8689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41183)\u001b[0m     @     0x55b377b42baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41183)\u001b[0m     @     0x55b377b43643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41183)\u001b[0m     @     0x55b377ab8689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41183)\u001b[0m     @     0x55b377b42baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41183)\u001b[0m     @     0x55b377b43643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41183)\u001b[0m     @     0x55b377ab8689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41207)\u001b[0m     @     0x5619dc97d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41207)\u001b[0m     @     0x5619dca07baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41207)\u001b[0m     @     0x5619dca08643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41207)\u001b[0m     @     0x5619dc97d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41214)\u001b[0m     @     0x557b95222643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41214)\u001b[0m     @     0x557b95197689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41149)\u001b[0m     @     0x55ab0b641689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41184)\u001b[0m     @     0x56369b200baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41184)\u001b[0m     @     0x56369b201643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41184)\u001b[0m     @     0x56369b176689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41184)\u001b[0m     @     0x56369b200baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41184)\u001b[0m     @     0x56369b201643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41184)\u001b[0m     @     0x56369b176689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41184)\u001b[0m     @     0x56369b200baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41184)\u001b[0m     @     0x56369b201643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41184)\u001b[0m     @     0x56369b176689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41150)\u001b[0m     @     0x7fa62896879f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41150)\u001b[0m     @     0x55a384d0cfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41150)\u001b[0m     @     0x55a384c67b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41150)\u001b[0m     @     0x55a384cf2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41150)\u001b[0m     @     0x55a384cf3a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41150)\u001b[0m     @     0x55a384c67bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41150)\u001b[0m     @     0x55a384cf2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41150)\u001b[0m     @     0x55a384cf3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41150)\u001b[0m     @     0x55a384c68689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41150)\u001b[0m     @     0x55a384cf2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41150)\u001b[0m     @     0x55a384cf3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41150)\u001b[0m     @     0x55a384c68689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41150)\u001b[0m     @     0x55a384cf2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41150)\u001b[0m     @     0x55a384cf3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41150)\u001b[0m     @     0x55a384c68689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41150)\u001b[0m     @     0x55a384cf2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41150)\u001b[0m     @     0x55a384cf3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41150)\u001b[0m     @     0x55a384c68689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41227)\u001b[0m     @     0x7fcbdad2179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41227)\u001b[0m     @     0x55a5f52bcfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41227)\u001b[0m     @     0x55a5f5217b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41227)\u001b[0m     @     0x55a5f52a2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41227)\u001b[0m     @     0x55a5f52a3a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41227)\u001b[0m     @     0x55a5f5217bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41227)\u001b[0m     @     0x55a5f52a2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41227)\u001b[0m     @     0x55a5f52a3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41227)\u001b[0m     @     0x55a5f5218689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41227)\u001b[0m     @     0x55a5f52a2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41227)\u001b[0m     @     0x55a5f52a3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41227)\u001b[0m     @     0x55a5f5218689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41227)\u001b[0m     @     0x55a5f52a2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41227)\u001b[0m     @     0x55a5f52a3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41227)\u001b[0m     @     0x55a5f5218689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41227)\u001b[0m     @     0x55a5f52a2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41227)\u001b[0m     @     0x55a5f52a3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41227)\u001b[0m     @     0x55a5f5218689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41174)\u001b[0m     @     0x7f3643fa44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41174)\u001b[0m     @     0x7f364a04f79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41174)\u001b[0m     @     0x556d5e618fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41174)\u001b[0m     @     0x556d5e573b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41174)\u001b[0m     @     0x556d5e5febaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41174)\u001b[0m     @     0x556d5e5ffa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41174)\u001b[0m     @     0x556d5e573bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41174)\u001b[0m     @     0x556d5e5febaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41174)\u001b[0m     @     0x556d5e5ff643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41174)\u001b[0m     @     0x556d5e574689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41174)\u001b[0m     @     0x556d5e5febaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41174)\u001b[0m     @     0x556d5e5ff643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41174)\u001b[0m     @     0x556d5e574689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41174)\u001b[0m     @     0x556d5e5febaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41174)\u001b[0m     @     0x556d5e5ff643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41174)\u001b[0m     @     0x556d5e574689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41174)\u001b[0m     @     0x556d5e5febaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41174)\u001b[0m     @     0x556d5e5ff643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41174)\u001b[0m     @     0x556d5e574689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41166)\u001b[0m     @     0x5560d92ab689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41166)\u001b[0m     @     0x5560d9335baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41166)\u001b[0m     @     0x5560d9336643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41166)\u001b[0m     @     0x5560d92ab689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41166)\u001b[0m     @     0x5560d9335baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41166)\u001b[0m     @     0x5560d9336643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41166)\u001b[0m     @     0x5560d92ab689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41144)\u001b[0m     @     0x7fc96714f79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41144)\u001b[0m     @     0x55d9a5822fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41144)\u001b[0m     @     0x55d9a577db08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41144)\u001b[0m     @     0x55d9a5808baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41144)\u001b[0m     @     0x55d9a5809a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41144)\u001b[0m     @     0x55d9a577dbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41144)\u001b[0m     @     0x55d9a5808baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41144)\u001b[0m     @     0x55d9a5809643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41144)\u001b[0m     @     0x55d9a577e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41144)\u001b[0m     @     0x55d9a5808baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41144)\u001b[0m     @     0x55d9a5809643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41144)\u001b[0m     @     0x55d9a577e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41144)\u001b[0m     @     0x55d9a5808baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41144)\u001b[0m     @     0x55d9a5809643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41144)\u001b[0m     @     0x55d9a577e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41144)\u001b[0m     @     0x55d9a5808baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41144)\u001b[0m     @     0x55d9a5809643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41144)\u001b[0m     @     0x55d9a577e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41230)\u001b[0m     @     0x7fa68c3e64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41230)\u001b[0m     @     0x7fa69249179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41230)\u001b[0m     @     0x55780a0a5fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41230)\u001b[0m     @     0x55780a000b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41230)\u001b[0m     @     0x55780a08bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41230)\u001b[0m     @     0x55780a08ca20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41230)\u001b[0m     @     0x55780a000bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41230)\u001b[0m     @     0x55780a08bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41230)\u001b[0m     @     0x55780a08c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41230)\u001b[0m     @     0x55780a001689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41230)\u001b[0m     @     0x55780a08bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41230)\u001b[0m     @     0x55780a08c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41230)\u001b[0m     @     0x55780a001689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41230)\u001b[0m     @     0x55780a08bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41230)\u001b[0m     @     0x55780a08c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41230)\u001b[0m     @     0x55780a001689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41230)\u001b[0m     @     0x55780a08bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41230)\u001b[0m     @     0x55780a08c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41230)\u001b[0m     @     0x55780a001689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41146)\u001b[0m     @     0x7f60105975a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41146)\u001b[0m     @     0x7f6010c824f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41146)\u001b[0m     @     0x7f60131558de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41219)\u001b[0m     @     0x7f699fc6d4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41219)\u001b[0m     @     0x7f69a21408de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41219)\u001b[0m     @     0x7f699fc6d4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41219)\u001b[0m     @     0x7f69d462879f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41219)\u001b[0m     @     0x562adf5f0fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41219)\u001b[0m     @     0x562adf54bb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41219)\u001b[0m     @     0x562adf5d6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41219)\u001b[0m     @     0x562adf5d7a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41236)\u001b[0m     @     0x7ef26576179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41236)\u001b[0m     @     0x5555bdac6fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41236)\u001b[0m     @     0x5555bda21b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41236)\u001b[0m     @     0x5555bdaacbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41236)\u001b[0m     @     0x5555bdaada20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41236)\u001b[0m     @     0x5555bda21bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41236)\u001b[0m     @     0x5555bdaacbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41236)\u001b[0m     @     0x5555bdaad643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41236)\u001b[0m     @     0x5555bda22689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41236)\u001b[0m     @     0x5555bdaacbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41236)\u001b[0m     @     0x5555bdaad643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41236)\u001b[0m     @     0x5555bda22689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41236)\u001b[0m     @     0x5555bdaacbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41236)\u001b[0m     @     0x5555bdaad643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41236)\u001b[0m     @     0x5555bda22689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41236)\u001b[0m     @     0x5555bdaacbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41236)\u001b[0m     @     0x5555bdaad643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41236)\u001b[0m     @     0x5555bda22689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41210)\u001b[0m     @     0x7f1995cfb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41210)\u001b[0m     @     0x7f19981ce8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41164)\u001b[0m     @     0x7fabb32424f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41164)\u001b[0m     @     0x7fabb92ed79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41164)\u001b[0m     @     0x564d4cfa4fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41164)\u001b[0m     @     0x564d4ceffb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41164)\u001b[0m     @     0x564d4cf8abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41164)\u001b[0m     @     0x564d4cf8ba20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41164)\u001b[0m     @     0x564d4ceffbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41164)\u001b[0m     @     0x564d4cf8abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41164)\u001b[0m     @     0x564d4cf8b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41164)\u001b[0m     @     0x564d4cf00689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41164)\u001b[0m     @     0x564d4cf8abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41164)\u001b[0m     @     0x564d4cf8b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41164)\u001b[0m     @     0x564d4cf00689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41164)\u001b[0m     @     0x564d4cf8abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41164)\u001b[0m     @     0x564d4cf8b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41164)\u001b[0m     @     0x564d4cf00689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41164)\u001b[0m     @     0x564d4cf8abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41164)\u001b[0m     @     0x564d4cf8b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41164)\u001b[0m     @     0x564d4cf00689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41176)\u001b[0m     @     0x7ef00f1b04f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41176)\u001b[0m     @     0x7ef01525b79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41176)\u001b[0m     @     0x5637d741cfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41176)\u001b[0m     @     0x5637d7377b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41176)\u001b[0m     @     0x5637d7402baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41176)\u001b[0m     @     0x5637d7403a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41176)\u001b[0m     @     0x5637d7377bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41176)\u001b[0m     @     0x5637d7402baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41176)\u001b[0m     @     0x5637d7403643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41176)\u001b[0m     @     0x5637d7378689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41176)\u001b[0m     @     0x5637d7402baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41176)\u001b[0m     @     0x5637d7403643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41176)\u001b[0m     @     0x5637d7378689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41176)\u001b[0m     @     0x5637d7402baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41176)\u001b[0m     @     0x5637d7403643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41176)\u001b[0m     @     0x5637d7378689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41176)\u001b[0m     @     0x5637d7402baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41176)\u001b[0m     @     0x5637d7403643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41176)\u001b[0m     @     0x5637d7378689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41180)\u001b[0m     @     0x7f07d98b04f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41180)\u001b[0m     @     0x7f07dbd838de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41180)\u001b[0m     @     0x7f07d98b04f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41180)\u001b[0m     @     0x7f07df95b79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41180)\u001b[0m     @     0x55e3ed451fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41180)\u001b[0m     @     0x55e3ed3acb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41180)\u001b[0m     @     0x55e3ed437baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41180)\u001b[0m     @     0x55e3ed438a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41180)\u001b[0m     @     0x55e3ed3acbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41180)\u001b[0m     @     0x55e3ed437baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41180)\u001b[0m     @     0x55e3ed438643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41180)\u001b[0m     @     0x55e3ed3ad689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41180)\u001b[0m     @     0x55e3ed437baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41180)\u001b[0m     @     0x55e3ed438643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41180)\u001b[0m     @     0x55e3ed3ad689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41221)\u001b[0m     @     0x7f1f7cce48de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41221)\u001b[0m     @     0x7f1f7a8114f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41221)\u001b[0m     @     0x7f1f808bc79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41221)\u001b[0m     @     0x56007274afd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41221)\u001b[0m     @     0x5600726a5b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41221)\u001b[0m     @     0x560072730baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41221)\u001b[0m     @     0x560072731a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41221)\u001b[0m     @     0x5600726a5bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41221)\u001b[0m     @     0x560072730baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41221)\u001b[0m     @     0x560072731643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41221)\u001b[0m     @     0x5600726a6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41221)\u001b[0m     @     0x560072730baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41221)\u001b[0m     @     0x560072731643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41221)\u001b[0m     @     0x5600726a6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41221)\u001b[0m     @     0x560072730baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41221)\u001b[0m     @     0x560072731643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41221)\u001b[0m     @     0x5600726a6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41221)\u001b[0m     @     0x560072730baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41221)\u001b[0m     @     0x560072731643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41217)\u001b[0m     @     0x5627aae0fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41217)\u001b[0m     @     0x5627aae10a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41217)\u001b[0m     @     0x5627aad84bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41217)\u001b[0m     @     0x5627aae0fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41217)\u001b[0m     @     0x5627aae10643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41217)\u001b[0m     @     0x5627aad85689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41217)\u001b[0m     @     0x5627aae0fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41217)\u001b[0m     @     0x5627aae10643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41217)\u001b[0m     @     0x5627aad85689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41217)\u001b[0m     @     0x5627aae0fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41217)\u001b[0m     @     0x5627aae10643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41217)\u001b[0m     @     0x5627aad85689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41217)\u001b[0m     @     0x5627aae0fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41217)\u001b[0m     @     0x5627aae10643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41217)\u001b[0m     @     0x5627aad85689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41216)\u001b[0m     @     0x7fbd9f2024f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41216)\u001b[0m     @     0x7fbda52ad79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41216)\u001b[0m     @     0x557837b6bfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41216)\u001b[0m     @     0x557837ac6b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41216)\u001b[0m     @     0x557837b51baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41216)\u001b[0m     @     0x557837b52a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41216)\u001b[0m     @     0x557837ac6bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41216)\u001b[0m     @     0x557837b51baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41216)\u001b[0m     @     0x557837b52643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41216)\u001b[0m     @     0x557837ac7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41216)\u001b[0m     @     0x557837b51baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41216)\u001b[0m     @     0x557837b52643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41216)\u001b[0m     @     0x557837ac7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41216)\u001b[0m     @     0x557837b51baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41216)\u001b[0m     @     0x557837b52643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41216)\u001b[0m     @     0x557837ac7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41216)\u001b[0m     @     0x557837b51baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41216)\u001b[0m     @     0x557837b52643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41216)\u001b[0m     @     0x557837ac7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41256)\u001b[0m     @     0x7ee49767679f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41256)\u001b[0m     @     0x561187f3bfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41256)\u001b[0m     @     0x561187e96b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41256)\u001b[0m     @     0x561187f21baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41256)\u001b[0m     @     0x561187f22a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41256)\u001b[0m     @     0x561187e96bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41256)\u001b[0m     @     0x561187f21baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41256)\u001b[0m     @     0x561187f22643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41256)\u001b[0m     @     0x561187e97689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41256)\u001b[0m     @     0x561187f21baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41256)\u001b[0m     @     0x561187f22643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41256)\u001b[0m     @     0x561187e97689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41256)\u001b[0m     @     0x561187f21baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41256)\u001b[0m     @     0x561187f22643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41256)\u001b[0m     @     0x561187e97689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41256)\u001b[0m     @     0x561187f21baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41256)\u001b[0m     @     0x561187f22643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41256)\u001b[0m     @     0x561187e97689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41232)\u001b[0m     @     0x7ee7db8efb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41232)\u001b[0m     @     0x7ee7db912c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41232)\u001b[0m     @     0x7ee7dadb4a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41232)\u001b[0m     @     0x7ee7dadb2388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41206)\u001b[0m     @     0x7f75719a54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41206)\u001b[0m     @     0x7f7577a5079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41206)\u001b[0m     @     0x5563d58a3fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41206)\u001b[0m     @     0x5563d57feb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41206)\u001b[0m     @     0x5563d5889baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41206)\u001b[0m     @     0x5563d588aa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41206)\u001b[0m     @     0x5563d57febfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41206)\u001b[0m     @     0x5563d5889baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41206)\u001b[0m     @     0x5563d588a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41206)\u001b[0m     @     0x5563d57ff689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41206)\u001b[0m     @     0x5563d5889baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41206)\u001b[0m     @     0x5563d588a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41206)\u001b[0m     @     0x5563d57ff689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41206)\u001b[0m     @     0x5563d5889baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41206)\u001b[0m     @     0x5563d588a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41206)\u001b[0m     @     0x5563d57ff689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41171)\u001b[0m     @     0x564ea45e1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41171)\u001b[0m     @     0x564ea45e2a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41171)\u001b[0m     @     0x564ea4556bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41171)\u001b[0m     @     0x564ea45e1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41171)\u001b[0m     @     0x564ea45e2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41171)\u001b[0m     @     0x564ea4557689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41171)\u001b[0m     @     0x564ea45e1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41171)\u001b[0m     @     0x564ea45e2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41171)\u001b[0m     @     0x564ea4557689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41171)\u001b[0m     @     0x564ea45e1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41171)\u001b[0m     @     0x564ea45e2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41171)\u001b[0m     @     0x564ea4557689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41171)\u001b[0m     @     0x564ea45e1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41171)\u001b[0m     @     0x564ea45e2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41171)\u001b[0m     @     0x564ea4557689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41223)\u001b[0m     @     0x7f5a8a7ccb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=41223)\u001b[0m     @     0x7f5a8a7efc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=41223)\u001b[0m     @     0x7f5a89c91a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41158)\u001b[0m     @     0x7f2805f7079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41158)\u001b[0m     @     0x55c9798e6fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41158)\u001b[0m     @     0x55c979841b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41158)\u001b[0m     @     0x55c9798ccbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41158)\u001b[0m     @     0x55c9798cda20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41158)\u001b[0m     @     0x55c979841bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41158)\u001b[0m     @     0x55c9798ccbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41158)\u001b[0m     @     0x55c9798cd643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41158)\u001b[0m     @     0x55c979842689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41158)\u001b[0m     @     0x55c9798ccbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41158)\u001b[0m     @     0x55c9798cd643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41158)\u001b[0m     @     0x55c979842689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41158)\u001b[0m     @     0x55c9798ccbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41158)\u001b[0m     @     0x55c9798cd643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41158)\u001b[0m     @     0x55c979842689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41158)\u001b[0m     @     0x55c9798ccbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41158)\u001b[0m     @     0x55c9798cd643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41158)\u001b[0m     @     0x55c979842689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41153)\u001b[0m     @     0x55d772b10baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41153)\u001b[0m     @     0x55d772b11643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41153)\u001b[0m     @     0x55d772a86689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41153)\u001b[0m     @     0x55d772b10baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41153)\u001b[0m     @     0x55d772b11643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41153)\u001b[0m     @     0x55d772a86689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41153)\u001b[0m     @     0x55d772b10baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41153)\u001b[0m     @     0x55d772b11643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41153)\u001b[0m     @     0x55d772a86689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41153)\u001b[0m     @     0x55d772b10baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41153)\u001b[0m     @     0x55d772b11643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41153)\u001b[0m     @     0x55d772a86689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41222)\u001b[0m     @     0x7fa3e93ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41222)\u001b[0m     @     0x7fa3ef46579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41222)\u001b[0m     @     0x55b40e083fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41222)\u001b[0m     @     0x55b40dfdeb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41222)\u001b[0m     @     0x55b40e069baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41222)\u001b[0m     @     0x55b40e06aa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41222)\u001b[0m     @     0x55b40dfdebfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41222)\u001b[0m     @     0x55b40e069baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41222)\u001b[0m     @     0x55b40e06a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41222)\u001b[0m     @     0x55b40dfdf689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41222)\u001b[0m     @     0x55b40e069baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41222)\u001b[0m     @     0x55b40e06a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41222)\u001b[0m     @     0x55b40dfdf689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41222)\u001b[0m     @     0x55b40e069baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41222)\u001b[0m     @     0x55b40e06a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41222)\u001b[0m     @     0x55b40dfdf689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41222)\u001b[0m     @     0x55b40e069baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41222)\u001b[0m     @     0x55b40e06a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41222)\u001b[0m     @     0x55b40dfdf689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41235)\u001b[0m     @     0x7fcbf703879f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41235)\u001b[0m     @     0x56535bb2bfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41235)\u001b[0m     @     0x56535ba86b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41235)\u001b[0m     @     0x56535bb11baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41235)\u001b[0m     @     0x56535bb12a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41235)\u001b[0m     @     0x56535ba86bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41235)\u001b[0m     @     0x56535bb11baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41235)\u001b[0m     @     0x56535bb12643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41235)\u001b[0m     @     0x56535ba87689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41235)\u001b[0m     @     0x56535bb11baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41235)\u001b[0m     @     0x56535bb12643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41235)\u001b[0m     @     0x56535ba87689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41235)\u001b[0m     @     0x56535bb11baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41235)\u001b[0m     @     0x56535bb12643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41235)\u001b[0m     @     0x56535ba87689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41235)\u001b[0m     @     0x56535bb11baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41235)\u001b[0m     @     0x56535bb12643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41235)\u001b[0m     @     0x56535ba87689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41224)\u001b[0m     @     0x7f81dca5c79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41224)\u001b[0m     @     0x557887cf2fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41224)\u001b[0m     @     0x557887c4db08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41224)\u001b[0m     @     0x557887cd8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41224)\u001b[0m     @     0x557887cd9a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41224)\u001b[0m     @     0x557887c4dbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41224)\u001b[0m     @     0x557887cd8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41224)\u001b[0m     @     0x557887cd9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41224)\u001b[0m     @     0x557887c4e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41224)\u001b[0m     @     0x557887cd8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41224)\u001b[0m     @     0x557887cd9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41224)\u001b[0m     @     0x557887c4e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41224)\u001b[0m     @     0x557887cd8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41224)\u001b[0m     @     0x557887cd9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41224)\u001b[0m     @     0x557887c4e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41224)\u001b[0m     @     0x557887cd8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41224)\u001b[0m     @     0x557887cd9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41224)\u001b[0m     @     0x557887c4e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41163)\u001b[0m     @     0x7f43052bd8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41163)\u001b[0m     @     0x7f4302dea4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41163)\u001b[0m     @     0x7f4308e9579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41163)\u001b[0m     @     0x56074cf16fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41163)\u001b[0m     @     0x56074ce71b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41163)\u001b[0m     @     0x56074cefcbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41163)\u001b[0m     @     0x56074cefda20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41163)\u001b[0m     @     0x56074ce71bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41163)\u001b[0m     @     0x56074cefcbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41163)\u001b[0m     @     0x56074cefd643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41163)\u001b[0m     @     0x56074ce72689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41163)\u001b[0m     @     0x56074cefcbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41163)\u001b[0m     @     0x56074cefd643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41163)\u001b[0m     @     0x56074ce72689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41163)\u001b[0m     @     0x56074cefcbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41163)\u001b[0m     @     0x56074cefd643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41163)\u001b[0m     @     0x56074ce72689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41163)\u001b[0m     @     0x56074cefcbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41163)\u001b[0m     @     0x56074cefd643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41163)\u001b[0m     @     0x56074ce72689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41241)\u001b[0m     @     0x7fc896fcb5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41241)\u001b[0m     @     0x7fc8976b64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41241)\u001b[0m     @     0x7fc899b898de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41213)\u001b[0m     @     0x558f55431643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41213)\u001b[0m     @     0x558f553a6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41213)\u001b[0m     @     0x558f55430baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41213)\u001b[0m     @     0x558f55431643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41213)\u001b[0m     @     0x558f553a6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41213)\u001b[0m     @     0x558f55430baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41213)\u001b[0m     @     0x558f55431643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41213)\u001b[0m     @     0x558f553a6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41213)\u001b[0m     @     0x558f55430baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41213)\u001b[0m     @     0x558f55431643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41213)\u001b[0m     @     0x558f553a6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41246)\u001b[0m     @     0x7ee74563179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41246)\u001b[0m     @     0x562922bd4fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41246)\u001b[0m     @     0x562922b2fb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41246)\u001b[0m     @     0x562922bbabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41246)\u001b[0m     @     0x562922bbba20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41246)\u001b[0m     @     0x562922b2fbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41246)\u001b[0m     @     0x562922bbabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41246)\u001b[0m     @     0x562922bbb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41246)\u001b[0m     @     0x562922b30689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41246)\u001b[0m     @     0x562922bbabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41246)\u001b[0m     @     0x562922bbb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41246)\u001b[0m     @     0x562922b30689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41246)\u001b[0m     @     0x562922bbabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41246)\u001b[0m     @     0x562922bbb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41246)\u001b[0m     @     0x562922b30689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41246)\u001b[0m     @     0x562922bbabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41246)\u001b[0m     @     0x562922bbb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41246)\u001b[0m     @     0x562922b30689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41209)\u001b[0m     @     0x7fb9d4a55a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=41209)\u001b[0m     @     0x7fb9d4a53388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41209)\u001b[0m     @     0x7fb9d4a555a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41178)\u001b[0m     @     0x7ef878b7f79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41178)\u001b[0m     @     0x559f7cb02fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41178)\u001b[0m     @     0x559f7ca5db08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41178)\u001b[0m     @     0x559f7cae8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41178)\u001b[0m     @     0x559f7cae9a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41178)\u001b[0m     @     0x559f7ca5dbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41178)\u001b[0m     @     0x559f7cae8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41178)\u001b[0m     @     0x559f7cae9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41178)\u001b[0m     @     0x559f7ca5e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41178)\u001b[0m     @     0x559f7cae8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41178)\u001b[0m     @     0x559f7cae9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41178)\u001b[0m     @     0x559f7ca5e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41178)\u001b[0m     @     0x559f7cae8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41178)\u001b[0m     @     0x559f7cae9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41178)\u001b[0m     @     0x559f7ca5e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41178)\u001b[0m     @     0x559f7cae8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41178)\u001b[0m     @     0x559f7cae9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41178)\u001b[0m     @     0x559f7ca5e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41148)\u001b[0m     @     0x7f34779d48de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41148)\u001b[0m     @     0x7f34755014f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41148)\u001b[0m     @     0x7f634035979f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41148)\u001b[0m     @     0x560972a9cfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41148)\u001b[0m     @     0x5609729f7b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41148)\u001b[0m     @     0x560972a82baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41148)\u001b[0m     @     0x560972a83a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41148)\u001b[0m     @     0x5609729f7bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41148)\u001b[0m     @     0x560972a82baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41148)\u001b[0m     @     0x560972a83643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41148)\u001b[0m     @     0x5609729f8689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41148)\u001b[0m     @     0x560972a82baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41148)\u001b[0m     @     0x560972a83643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41148)\u001b[0m     @     0x5609729f8689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41148)\u001b[0m     @     0x560972a82baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41148)\u001b[0m     @     0x560972a83643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41148)\u001b[0m     @     0x5609729f8689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41148)\u001b[0m     @     0x560972a82baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41148)\u001b[0m     @     0x560972a83643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41148)\u001b[0m     @     0x5609729f8689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41146)\u001b[0m     @     0x7f6010c824f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41146)\u001b[0m     @     0x7f6016d2d79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41146)\u001b[0m     @     0x5592a1f20fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41146)\u001b[0m     @     0x5592a1e7bb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41146)\u001b[0m     @     0x5592a1f06baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41146)\u001b[0m     @     0x5592a1f07a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41146)\u001b[0m     @     0x5592a1e7bbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41146)\u001b[0m     @     0x5592a1f06baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41146)\u001b[0m     @     0x5592a1f07643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41146)\u001b[0m     @     0x5592a1e7c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41146)\u001b[0m     @     0x5592a1f06baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41146)\u001b[0m     @     0x5592a1f07643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41146)\u001b[0m     @     0x5592a1e7c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41146)\u001b[0m     @     0x5592a1f06baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41146)\u001b[0m     @     0x5592a1f07643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41146)\u001b[0m     @     0x5592a1e7c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41146)\u001b[0m     @     0x5592a1f06baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41146)\u001b[0m     @     0x5592a1f07643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41146)\u001b[0m     @     0x5592a1e7c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41219)\u001b[0m     @     0x562adf54bbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41219)\u001b[0m     @     0x562adf5d6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41219)\u001b[0m     @     0x562adf5d7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41219)\u001b[0m     @     0x562adf54c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41219)\u001b[0m     @     0x562adf5d6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41219)\u001b[0m     @     0x562adf5d7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41219)\u001b[0m     @     0x562adf54c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41219)\u001b[0m     @     0x562adf5d6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41219)\u001b[0m     @     0x562adf5d7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41219)\u001b[0m     @     0x562adf54c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41219)\u001b[0m     @     0x562adf5d6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41219)\u001b[0m     @     0x562adf5d7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41219)\u001b[0m     @     0x562adf54c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41210)\u001b[0m     @     0x7f1995cfb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41210)\u001b[0m     @     0x7f199bda679f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41210)\u001b[0m     @     0x5608cc0bafd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41210)\u001b[0m     @     0x5608cc015b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41210)\u001b[0m     @     0x5608cc0a0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41210)\u001b[0m     @     0x5608cc0a1a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41210)\u001b[0m     @     0x5608cc015bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41210)\u001b[0m     @     0x5608cc0a0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41210)\u001b[0m     @     0x5608cc0a1643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41210)\u001b[0m     @     0x5608cc016689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41210)\u001b[0m     @     0x5608cc0a0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41210)\u001b[0m     @     0x5608cc0a1643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41210)\u001b[0m     @     0x5608cc016689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41210)\u001b[0m     @     0x5608cc0a0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41210)\u001b[0m     @     0x5608cc0a1643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41210)\u001b[0m     @     0x5608cc016689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41210)\u001b[0m     @     0x5608cc0a0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41210)\u001b[0m     @     0x5608cc0a1643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41210)\u001b[0m     @     0x5608cc016689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41180)\u001b[0m     @     0x55e3ed437baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41180)\u001b[0m     @     0x55e3ed438643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41180)\u001b[0m     @     0x55e3ed3ad689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41180)\u001b[0m     @     0x55e3ed437baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41180)\u001b[0m     @     0x55e3ed438643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41180)\u001b[0m     @     0x55e3ed3ad689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41221)\u001b[0m     @     0x5600726a6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41232)\u001b[0m     @     0x7ee7dadb45a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41206)\u001b[0m     @     0x5563d5889baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41206)\u001b[0m     @     0x5563d588a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41206)\u001b[0m     @     0x5563d57ff689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41223)\u001b[0m     @     0x7f5a89c8f388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=41223)\u001b[0m     @     0x7f5a89c915a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41241)\u001b[0m     @     0x7fc8976b64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41241)\u001b[0m     @     0x7fc89d76179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41241)\u001b[0m     @     0x555f6d7d0fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41241)\u001b[0m     @     0x555f6d72bb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41241)\u001b[0m     @     0x555f6d7b6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41241)\u001b[0m     @     0x555f6d7b7a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41241)\u001b[0m     @     0x555f6d72bbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41241)\u001b[0m     @     0x555f6d7b6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41241)\u001b[0m     @     0x555f6d7b7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41241)\u001b[0m     @     0x555f6d72c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41241)\u001b[0m     @     0x555f6d7b6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41241)\u001b[0m     @     0x555f6d7b7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41241)\u001b[0m     @     0x555f6d72c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41241)\u001b[0m     @     0x555f6d7b6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41241)\u001b[0m     @     0x555f6d7b7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41241)\u001b[0m     @     0x555f6d72c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41241)\u001b[0m     @     0x555f6d7b6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41241)\u001b[0m     @     0x555f6d7b7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41241)\u001b[0m     @     0x555f6d72c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41209)\u001b[0m     @     0x7fb9d51404f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41209)\u001b[0m     @     0x7fb9d76138de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41209)\u001b[0m     @     0x7fb9d51404f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41209)\u001b[0m     @     0x7fb9db1eb79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41209)\u001b[0m     @     0x55bca636cfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41209)\u001b[0m     @     0x55bca62c7b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41209)\u001b[0m     @     0x55bca6352baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41209)\u001b[0m     @     0x55bca6353a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41232)\u001b[0m     @     0x7ee7db49f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41232)\u001b[0m     @     0x7ee7dd9728de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41223)\u001b[0m     @     0x7f5a8a37c4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41223)\u001b[0m     @     0x7f5a8c84f8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41223)\u001b[0m     @     0x7f5a8a37c4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41209)\u001b[0m     @     0x55bca62c7bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41209)\u001b[0m     @     0x55bca6352baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41209)\u001b[0m     @     0x55bca6353643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41209)\u001b[0m     @     0x55bca62c8689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41209)\u001b[0m     @     0x55bca6352baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41209)\u001b[0m     @     0x55bca6353643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41209)\u001b[0m     @     0x55bca62c8689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41209)\u001b[0m     @     0x55bca6352baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41209)\u001b[0m     @     0x55bca6353643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41209)\u001b[0m     @     0x55bca62c8689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41209)\u001b[0m     @     0x55bca6352baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41209)\u001b[0m     @     0x55bca6353643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41209)\u001b[0m     @     0x55bca62c8689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41232)\u001b[0m     @     0x7ee7db49f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41232)\u001b[0m     @     0x7ee7e154a79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41232)\u001b[0m     @     0x558040779fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41232)\u001b[0m     @     0x5580406d4b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41232)\u001b[0m     @     0x55804075fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41232)\u001b[0m     @     0x558040760a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41232)\u001b[0m     @     0x5580406d4bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41232)\u001b[0m     @     0x55804075fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41232)\u001b[0m     @     0x558040760643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41232)\u001b[0m     @     0x5580406d5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41232)\u001b[0m     @     0x55804075fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41232)\u001b[0m     @     0x558040760643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41232)\u001b[0m     @     0x5580406d5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41232)\u001b[0m     @     0x55804075fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41232)\u001b[0m     @     0x558040760643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41232)\u001b[0m     @     0x5580406d5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41232)\u001b[0m     @     0x55804075fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41232)\u001b[0m     @     0x558040760643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41232)\u001b[0m     @     0x5580406d5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41223)\u001b[0m     @     0x7f5a9042779f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=41223)\u001b[0m     @     0x56116e213fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=41223)\u001b[0m     @     0x56116e16eb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41223)\u001b[0m     @     0x56116e1f9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41223)\u001b[0m     @     0x56116e1faa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=41223)\u001b[0m     @     0x56116e16ebfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41223)\u001b[0m     @     0x56116e1f9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41223)\u001b[0m     @     0x56116e1fa643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41223)\u001b[0m     @     0x56116e16f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41223)\u001b[0m     @     0x56116e1f9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41223)\u001b[0m     @     0x56116e1fa643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41223)\u001b[0m     @     0x56116e16f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41223)\u001b[0m     @     0x56116e1f9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41223)\u001b[0m     @     0x56116e1fa643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41223)\u001b[0m     @     0x56116e16f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=41223)\u001b[0m     @     0x56116e1f9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=41223)\u001b[0m     @     0x56116e1fa643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=41223)\u001b[0m     @     0x56116e16f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "2020-11-05 10:43:26,017\tERROR trial_runner.py:567 -- Trial PPO_jss_env_b77b2_00000: Error processing event.\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/trial_runner.py\", line 515, in _process_trial\n",
+      "    result = self.trial_executor.fetch_result(trial)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/ray_trial_executor.py\", line 488, in fetch_result\n",
+      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1428, in get\n",
+      "    raise value.as_instanceof_cause()\n",
+      "ray.exceptions.RayTaskError: \u001b[36mray::PPO.train()\u001b[39m (pid=41234, ip=172.17.0.4)\n",
+      "  File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
+      "  File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\", line 516, in train\n",
+      "    raise e\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\", line 505, in train\n",
+      "    result = Trainable.train(self)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/trainable.py\", line 336, in train\n",
+      "    result = self.step()\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer_template.py\", line 134, in step\n",
+      "    res = next(self.train_exec_impl)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 756, in __next__\n",
+      "    return next(self.built_iterator)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 843, in apply_filter\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 843, in apply_filter\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  [Previous line repeated 1 more time]\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 876, in apply_flatten\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 828, in add_wait_hooks\n",
+      "    item = next(it)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  [Previous line repeated 1 more time]\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 466, in base_iterator\n",
+      "    actor_set.init_actors()\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 1238, in init_actors\n",
+      "    ray.get([a.par_iter_init.remote(self.transforms) for a in self.actors])\n",
+      "ray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.\n",
+      "2020-11-05 10:43:26,021\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffffe0497dac01000000.\n",
+      "2020-11-05 10:43:26,022\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff9f3cc57a01000000.\n",
+      "2020-11-05 10:43:26,022\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff252160a301000000.\n",
+      "2020-11-05 10:43:26,022\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffffa97540c201000000.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 24.5/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/1 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 ERROR)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_b77b2_00000 | ERROR    |       |\n",
+      "+-------------------------+----------+-------+\n",
+      "Number of errored trials: 1\n",
+      "+-------------------------+--------------+-----------------------------------------------------------------------------------+\n",
+      "| Trial name              |   # failures | error file                                                                        |\n",
+      "|-------------------------+--------------+-----------------------------------------------------------------------------------|\n",
+      "| PPO_jss_env_b77b2_00000 |            1 | /root/ray_results/ppo-jss/PPO_jss_env_b77b2_00000_0_2020-11-05_10-43-18/error.txt |\n",
+      "+-------------------------+--------------+-----------------------------------------------------------------------------------+\n",
       "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 3642\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
-      "2020-10-14 20:44:18,469 - wandb.wandb_agent - INFO - Running runs: ['ix8moovg']\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201014_204415-ix8moovg/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201014_204415-ix8moovg/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:       nb_episodes 1\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   avg_best_result 224.37374\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_episode 224.37374\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:     best_timestep 3435\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:             _step 0\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:          _runtime 1\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        _timestamp 1602708256\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:       nb_episodes ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   avg_best_result ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_episode ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:     best_timestep ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:             _step ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:          _runtime ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        _timestamp ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mMTWR\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/ix8moovg\u001b[0m\n",
-      "2020-10-14 20:44:23,694 - wandb.wandb_agent - INFO - Cleaning up finished run: ix8moovg\n",
-      "2020-10-14 20:44:24,023 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-14 20:44:24,023 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tinstance_path: /JSS/JSS/env/instances/ta56\n",
-      "2020-10-14 20:44:24,025 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python MTWR.py --instance_path=/JSS/JSS/env/instances/ta56\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mMTWR\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/po3ygyxo\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/zda8eskt\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201014_204426-zda8eskt\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 24.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/1 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 ERROR)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_b77b2_00000 | ERROR    |       |\n",
+      "+-------------------------+----------+-------+\n",
+      "Number of errored trials: 1\n",
+      "+-------------------------+--------------+-----------------------------------------------------------------------------------+\n",
+      "| Trial name              |   # failures | error file                                                                        |\n",
+      "|-------------------------+--------------+-----------------------------------------------------------------------------------|\n",
+      "| PPO_jss_env_b77b2_00000 |            1 | /root/ray_results/ppo-jss/PPO_jss_env_b77b2_00000_0_2020-11-05_10-43-18/error.txt |\n",
+      "+-------------------------+--------------+-----------------------------------------------------------------------------------+\n",
+      "2020-11-05 10:43:26,032\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff4100f4fd01000000.\n",
       "\n",
+      "Traceback (most recent call last):\n",
+      "  File \"train.py\", line 74, in <module>\n",
+      "    train_func()\n",
+      "  File \"train.py\", line 56, in train_func\n",
+      "    analysis = tune.run(PPOTrainer, config=config, stop=stop, name=\"ppo-jss\")\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/tune.py\", line 427, in run\n",
+      "    raise TuneError(\"Trials did not complete\", incomplete_trials)\n",
+      "ray.tune.error.TuneError: ('Trials did not complete', [PPO_jss_env_b77b2_00000])\n",
       "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 3726\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
-      "2020-10-14 20:44:29,037 - wandb.wandb_agent - INFO - Running runs: ['zda8eskt']\n",
+      "--- Logging error ---\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 41044\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 1.  Press ctrl-c to abort syncing.\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff56c9ec1501000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffbdff035801000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff091d563401000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff31c3fed901000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff4e242e9f01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff59d91ef301000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff821ddf4301000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff0314ce3001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff90aded9101000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error --- 4.84MB of 4.84MB uploaded (0.00MB deduped)\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff8168b55d01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff43fb47bd01000000.'\n",
+      "Arguments: ()\n",
+      "\u001b[2m\u001b[36m(pid=41234)\u001b[0m E1105 10:43:26.005928 41234 42401 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=170fdfd5d34985a7e0497dac01000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=e0497dac01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=41234)\u001b[0m E1105 10:43:26.006095 41234 42401 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=89f63fee54d6858ee0497dac01000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=e0497dac01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=41234)\u001b[0m E1105 10:43:26.017379 41234 42401 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=efaf5dbfabc208739f3cc57a01000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=9f3cc57a01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=41234)\u001b[0m E1105 10:43:26.017535 41234 42401 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=b3b45bae970c41729f3cc57a01000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=9f3cc57a01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=41234)\u001b[0m E1105 10:43:26.020622 41234 42401 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=fde3d5eda9f525d7a97540c201000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=a97540c201000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=41234)\u001b[0m E1105 10:43:26.020771 41234 42401 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=d16c21eef3935840a97540c201000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=a97540c201000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=41234)\u001b[0m E1105 10:43:26.020889 41234 42401 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=3e4916e36cb3ce60252160a301000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=252160a301000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=41234)\u001b[0m E1105 10:43:26.020995 41234 42401 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=c2d663ba592886f5252160a301000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=252160a301000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=41234)\u001b[0m E1105 10:43:26.024302 41234 42401 task_manager.cc:323] Task failed: IOError: cancelling all pending tasks of dead actor: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=d88ec84d5baca957a97540c201000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=a97540c201000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=41234)\u001b[0m E1105 10:43:26.024636 41234 42401 task_manager.cc:323] Task failed: IOError: cancelling all pending tasks of dead actor: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=c6f8a2750fad0b0de0497dac01000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=e0497dac01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=41234)\u001b[0m E1105 10:43:26.025038 41234 42401 task_manager.cc:323] Task failed: IOError: cancelling all pending tasks of dead actor: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=457f03c785986c89252160a301000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=252160a301000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=41234)\u001b[0m E1105 10:43:26.025228 41234 42401 task_manager.cc:323] Task failed: IOError: cancelling all pending tasks of dead actor: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=4f22c19b5f703db99f3cc57a01000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=9f3cc57a01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=41234)\u001b[0m E1105 10:43:26.029387 41234 42401 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=d984ee9d41b92c534100f4fd01000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=4100f4fd01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=41234)\u001b[0m E1105 10:43:26.030124 41234 42401 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=6c41da4ee8b0b4d04100f4fd01000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=4100f4fd01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=41234)\u001b[0m E1105 10:43:26.030354 41234 42401 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=37f711ca0d66f5bd4100f4fd01000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=4100f4fd01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=41234)\u001b[0m E1105 10:43:26.039201 41234 42401 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=4db1cba171d56c3356c9ec1501000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=56c9ec1501000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=41234)\u001b[0m E1105 10:43:26.039352 41234 42401 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=5cf29c5b7b7ed08d56c9ec1501000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=56c9ec1501000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=41234)\u001b[0m E1105 10:43:26.039463 41234 42401 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=9d0a2db204e8f81056c9ec1501000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=56c9ec1501000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=41234)\u001b[0m E1105 10:43:26.040454 41234 42401 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=137dbd5547ea6deabdff035801000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=bdff035801000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=41234)\u001b[0m E1105 10:43:26.040555 41234 42401 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=3f75a43fb9f70f24bdff035801000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=bdff035801000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=41234)\u001b[0m E1105 10:43:26.040625 41234 42401 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=150a9d56b40e3700bdff035801000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=bdff035801000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff75f329e601000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff9d526f0201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffc2621d1401000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff0d557f6601000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff7f7c936001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task fffffffffffffffff257d30801000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task fffffffffffffffff120020c01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff7ef9157101000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff8cd168e101000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffda2cd21f01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff51728d3301000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff80993fa801000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff14da135201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffd784bf0601000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff4f9bfece01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffd989d1f001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff0fae11b201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffffefbd9801000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffee8852f401000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffdd5654aa01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffb3cace0801000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff32335d4e01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffeca600ef01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff41e0fbff01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffb2413f7201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffe9f6a7cf01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff018c9dac01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff19fd5b4901000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff5843697701000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffa4f7314201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffa7ad1db301000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff5cc87e2501000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff7a508a7a01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff61dc472601000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff244a7d1001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff310e963d01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff20d842ad01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff04668d8f01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff358dd45601000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff7b2861ac01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff34cbbac201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff99d0343201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff3a9488b101000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff10f667b001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff50168bc201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff302122d001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffc3083e0c01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff702ed69e01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffd8f83c3801000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff3166f9e301000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff452e714401000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff71ca01c001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff1e7ae67b01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task fffffffffffffffff0f72e3901000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff8edbbd3001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffef1af81501000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffccf343cc01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task fffffffffffffffff392716d01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff8f9a5fc701000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff58dd50c101000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff2d1a71ea01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff8d06128001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff0aeae6a301000000.'\n",
+      "Arguments: ()\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201014_204426-zda8eskt/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201014_204426-zda8eskt/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:       nb_episodes 1\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   avg_best_result 178.59596\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_episode 178.59596\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:     best_timestep 3881\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:             _step 0\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:          _runtime 1\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        _timestamp 1602708267\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:       nb_episodes ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   avg_best_result ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_episode ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:     best_timestep ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:             _step ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:          _runtime ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        _timestamp ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201105_104313-1kkcunv8/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201105_104313-1kkcunv8/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mMTWR\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/zda8eskt\u001b[0m\n",
-      "2020-10-14 20:44:34,252 - wandb.wandb_agent - INFO - Cleaning up finished run: zda8eskt\n",
-      "2020-10-14 20:44:36,273 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-14 20:44:36,273 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tinstance_path: /JSS/JSS/env/instances/ta57\n",
-      "2020-10-14 20:44:36,275 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python MTWR.py --instance_path=/JSS/JSS/env/instances/ta57\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33matomic-sweep-2\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/1kkcunv8\u001b[0m\n",
+      "2020-11-05 10:43:37,502 - wandb.wandb_agent - INFO - Cleaning up finished run: 1kkcunv8\n",
+      "2020-11-05 10:43:37,842 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-11-05 10:43:37,842 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tinstance_path: /JSS/JSS/env/instances/ta42\n",
+      "2020-11-05 10:43:37,845 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --instance_path=/JSS/JSS/env/instances/ta42\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.9 is available!  To upgrade, please run:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mMTWR\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/po3ygyxo\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/uz9lk4hk\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201014_204438-uz9lk4hk\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msmooth-sweep-3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/sweeps/72qf0qyh\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/sf5shxxc\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201105_104339-sf5shxxc\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
+      "2020-11-05 10:43:42,862 - wandb.wandb_agent - INFO - Running runs: ['sf5shxxc']\n",
+      "2020-11-05 10:43:43,399\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
+      "== Status ==\n",
+      "Memory usage on this node: 12.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/1 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_c70fc_00000 | RUNNING  |       |\n",
+      "+-------------------------+----------+-------+\n",
+      "\n",
       "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 3824\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
-      "2020-10-14 20:44:41,292 - wandb.wandb_agent - INFO - Running runs: ['uz9lk4hk']\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m 2020-11-05 10:43:46,213\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/torch/cuda/__init__.py:125: UserWarning: \n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m GeForce RTX 2080 Ti with CUDA capability sm_75 is not compatible with the current PyTorch installation.\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 compute_37.\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m If you want to use the GeForce RTX 2080 Ti GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m \n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m   warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n",
+      "\u001b[2m\u001b[36m(pid=42785)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42785)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42785)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42785)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42785)\u001b[0m *** SIGSEGV (@0x0) received by PID 42785 (TID 0x7fe024cc2700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42785)\u001b[0m     @     0x7fe02489b390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42785)\u001b[0m     @     0x7fb12460ef90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42785)\u001b[0m     @     0x7fb123d397db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42785)\u001b[0m     @     0x7fb123d3c8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42771)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42771)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42771)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42771)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42771)\u001b[0m *** SIGSEGV (@0x0) received by PID 42771 (TID 0x7feb6833a700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42771)\u001b[0m     @     0x7feb67f13390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42771)\u001b[0m     @     0x7fbc67e0ef90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42771)\u001b[0m     @     0x7fbc675397db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42794)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42794)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42794)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42794)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42794)\u001b[0m *** SIGSEGV (@0x0) received by PID 42794 (TID 0x7f268d77f700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42794)\u001b[0m     @     0x7f268d358390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42794)\u001b[0m     @     0x7ef78d2b7f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42794)\u001b[0m     @     0x7ef78c9e27db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42794)\u001b[0m     @     0x7ef78c9e58f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42794)\u001b[0m     @     0x7ef78c9e5ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42794)\u001b[0m     @     0x7ef78c9e5d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42821)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42821)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42821)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42821)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42821)\u001b[0m *** SIGSEGV (@0x0) received by PID 42821 (TID 0x7ff763ea1700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42821)\u001b[0m     @     0x7ff763a7a390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42821)\u001b[0m     @     0x7fc863a08f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42821)\u001b[0m     @     0x7fc8631337db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42821)\u001b[0m     @     0x7fc8631368f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42821)\u001b[0m     @     0x7fc863136ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42821)\u001b[0m     @     0x7fc863136d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42821)\u001b[0m     @     0x7fc863a19b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42802)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42802)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42802)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42802)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42802)\u001b[0m *** SIGSEGV (@0x0) received by PID 42802 (TID 0x7f19c8b39700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42802)\u001b[0m     @     0x7f19c8712390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42802)\u001b[0m     @     0x7eeac860ef90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42802)\u001b[0m     @     0x7eeac7d397db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42802)\u001b[0m     @     0x7eeac7d3c8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42810)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42810)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42810)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42810)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42810)\u001b[0m *** SIGSEGV (@0x0) received by PID 42810 (TID 0x7fa34be52700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42810)\u001b[0m     @     0x7fa34ba2b390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42810)\u001b[0m     @     0x7f744b751f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42810)\u001b[0m     @     0x7f744ae7c7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42810)\u001b[0m     @     0x7f744ae7f8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42810)\u001b[0m     @     0x7f744ae7fad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42784)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42784)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42784)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42784)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42784)\u001b[0m *** SIGSEGV (@0x0) received by PID 42784 (TID 0x7f3a72be7700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42784)\u001b[0m     @     0x7f3a727c0390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42784)\u001b[0m     @     0x7f0b7274ef90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42784)\u001b[0m     @     0x7f0b71e797db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42788)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42788)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42788)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42788)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42788)\u001b[0m *** SIGSEGV (@0x0) received by PID 42788 (TID 0x7f80cfb7d700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42788)\u001b[0m     @     0x7f80cf756390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42788)\u001b[0m     @     0x7f51cf61ff90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42788)\u001b[0m     @     0x7f51ced4a7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42788)\u001b[0m     @     0x7f51ced4d8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42779)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42779)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42779)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42779)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42779)\u001b[0m *** SIGSEGV (@0x0) received by PID 42779 (TID 0x7f414a1ac700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42779)\u001b[0m     @     0x7f4149d85390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42779)\u001b[0m     @     0x7f1249c0df90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42779)\u001b[0m     @     0x7f12493387db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42779)\u001b[0m     @     0x7f124933b8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42746)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42746)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42746)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42746)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42746)\u001b[0m *** SIGSEGV (@0x0) received by PID 42746 (TID 0x7f87f2324700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42746)\u001b[0m     @     0x7f87f1efd390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42746)\u001b[0m     @     0x7f58f1e24f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42746)\u001b[0m     @     0x7f58f154f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42772)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42772)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42772)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42772)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42772)\u001b[0m *** SIGSEGV (@0x0) received by PID 42772 (TID 0x7f38c6de4700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42772)\u001b[0m     @     0x7f38c69bd390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42772)\u001b[0m     @     0x7f09c67bbf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42772)\u001b[0m     @     0x7f09c5ee67db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42812)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42812)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42812)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42812)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42812)\u001b[0m *** SIGSEGV (@0x0) received by PID 42812 (TID 0x7f2d905e7700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42812)\u001b[0m     @     0x7f2d901c0390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42812)\u001b[0m     @     0x7efe9001cf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42812)\u001b[0m     @     0x7efe8f7477db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42812)\u001b[0m     @     0x7efe8f74a8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42800)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42800)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42800)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42800)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42800)\u001b[0m *** SIGSEGV (@0x0) received by PID 42800 (TID 0x7fca413d2700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42800)\u001b[0m     @     0x7fca40fab390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42800)\u001b[0m     @     0x7f9b40ea4f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42800)\u001b[0m     @     0x7f9b405cf7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42800)\u001b[0m     @     0x7f9b405d28f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42769)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42769)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42769)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42769)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42769)\u001b[0m *** SIGSEGV (@0x0) received by PID 42769 (TID 0x7f9685f43700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42769)\u001b[0m     @     0x7f9685b1c390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42769)\u001b[0m     @     0x7f6785a0af90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42769)\u001b[0m     @     0x7f67851357db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42769)\u001b[0m     @     0x7f67851388f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42769)\u001b[0m     @     0x7f6785138ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42769)\u001b[0m     @     0x7f6785138d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42769)\u001b[0m     @     0x7f6785a1bb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42769)\u001b[0m     @     0x7f6785a3ec1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42705)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42705)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42705)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42705)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42705)\u001b[0m *** SIGSEGV (@0x0) received by PID 42705 (TID 0x7f1066760700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42705)\u001b[0m     @     0x7f1066339390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42705)\u001b[0m     @     0x7ee1662b9f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42705)\u001b[0m     @     0x7ee1659e47db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42787)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42787)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42787)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42787)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42787)\u001b[0m *** SIGSEGV (@0x0) received by PID 42787 (TID 0x7fdcf9410700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42787)\u001b[0m     @     0x7fdcf8fe9390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42787)\u001b[0m     @     0x7fadf8ea4f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42787)\u001b[0m     @     0x7fadf85cf7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42787)\u001b[0m     @     0x7fadf85d28f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42781)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42781)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42781)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42781)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42781)\u001b[0m *** SIGSEGV (@0x0) received by PID 42781 (TID 0x7fa3c92e6700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42781)\u001b[0m     @     0x7fa3c8ebf390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42781)\u001b[0m     @     0x7f74c8e77f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42781)\u001b[0m     @     0x7f74c85a27db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42762)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42762)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42762)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42762)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42762)\u001b[0m *** SIGSEGV (@0x0) received by PID 42762 (TID 0x7fd71c2aa700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42762)\u001b[0m     @     0x7fd71be83390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42762)\u001b[0m     @     0x7fa81be0bf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42762)\u001b[0m     @     0x7fa81b5367db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42762)\u001b[0m     @     0x7fa81b5398f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42798)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42798)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42798)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42798)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42798)\u001b[0m *** SIGSEGV (@0x0) received by PID 42798 (TID 0x7f275fcd2700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42798)\u001b[0m     @     0x7f275f8ab390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42798)\u001b[0m     @     0x7ef85f84cf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42798)\u001b[0m     @     0x7ef85ef777db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42798)\u001b[0m     @     0x7ef85ef7a8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42797)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42797)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42797)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42797)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42797)\u001b[0m *** SIGSEGV (@0x0) received by PID 42797 (TID 0x7fdb1b34b700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42797)\u001b[0m     @     0x7fdb1af24390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42797)\u001b[0m     @     0x7fac1aed3f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42797)\u001b[0m     @     0x7fac1a5fe7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42797)\u001b[0m     @     0x7fac1a6018f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42797)\u001b[0m     @     0x7fac1a601ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42778)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42778)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42778)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42778)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42778)\u001b[0m *** SIGSEGV (@0x0) received by PID 42778 (TID 0x7f32724c7700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42778)\u001b[0m     @     0x7f32720a0390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42778)\u001b[0m     @     0x7f037204df90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42778)\u001b[0m     @     0x7f03717787db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42790)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42790)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42790)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42790)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42790)\u001b[0m *** SIGSEGV (@0x0) received by PID 42790 (TID 0x7f4409ae2700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42790)\u001b[0m     @     0x7f44096bb390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42790)\u001b[0m     @     0x7f1509665f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42790)\u001b[0m     @     0x7f1508d907db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42790)\u001b[0m     @     0x7f1508d938f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42706)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42706)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42706)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42706)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42706)\u001b[0m *** SIGSEGV (@0x0) received by PID 42706 (TID 0x7f6b25334700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42706)\u001b[0m     @     0x7f6b24f0d390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42706)\u001b[0m     @     0x7f3c24ea4f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42706)\u001b[0m     @     0x7f3c245cf7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42706)\u001b[0m     @     0x7f3c245d28f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42775)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42775)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42775)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42775)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42775)\u001b[0m *** SIGSEGV (@0x0) received by PID 42775 (TID 0x7f7b160af700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42775)\u001b[0m     @     0x7f7b15c88390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42775)\u001b[0m     @     0x7f4c15c11f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42775)\u001b[0m     @     0x7f4c1533c7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42775)\u001b[0m     @     0x7f4c1533f8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42775)\u001b[0m     @     0x7f4c1533fad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42805)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42805)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42805)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42805)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42805)\u001b[0m *** SIGSEGV (@0x0) received by PID 42805 (TID 0x7f83464a3700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42805)\u001b[0m     @     0x7f834607c390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42805)\u001b[0m     @     0x7f5446028f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42805)\u001b[0m     @     0x7f54457537db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42805)\u001b[0m     @     0x7f54457568f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42805)\u001b[0m     @     0x7f5445756ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42774)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42774)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42774)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42774)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42774)\u001b[0m *** SIGSEGV (@0x0) received by PID 42774 (TID 0x7f4382258700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42774)\u001b[0m     @     0x7f4381e31390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42774)\u001b[0m     @     0x7f1481de4f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42774)\u001b[0m     @     0x7f148150f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42774)\u001b[0m     @     0x7f14815128f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42774)\u001b[0m     @     0x7f1481512ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42818)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42818)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42818)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42818)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42818)\u001b[0m *** SIGSEGV (@0x0) received by PID 42818 (TID 0x7f48949fa700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42818)\u001b[0m     @     0x7f48945d3390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42818)\u001b[0m     @     0x7f1994536f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42818)\u001b[0m     @     0x7f1993c617db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42818)\u001b[0m     @     0x7f1993c648f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42818)\u001b[0m     @     0x7f1993c64ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42763)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42763)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42763)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42763)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42763)\u001b[0m *** SIGSEGV (@0x0) received by PID 42763 (TID 0x7fb154d87700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42763)\u001b[0m     @     0x7fb154960390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42763)\u001b[0m     @     0x7f8254825f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42763)\u001b[0m     @     0x7f8253f507db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42764)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42764)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42764)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42764)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42764)\u001b[0m *** SIGSEGV (@0x0) received by PID 42764 (TID 0x7fa1ad78b700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42764)\u001b[0m     @     0x7fa1ad364390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42764)\u001b[0m     @     0x7f72ad2b7f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42764)\u001b[0m     @     0x7f72ac9e27db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42764)\u001b[0m     @     0x7f72ac9e58f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42760)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42760)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42760)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42698)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42698)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42698)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42756)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42756)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42756)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42712)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42712)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42712)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42694)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42694)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42694)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42710)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42710)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42710)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42714)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42714)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42714)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42714)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42714)\u001b[0m *** SIGSEGV (@0x0) received by PID 42714 (TID 0x7f12c3a2e700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42754)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42754)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42754)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42695)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42695)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42695)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42695)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42695)\u001b[0m *** SIGSEGV (@0x0) received by PID 42695 (TID 0x7f4827808700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42744)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42744)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42744)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42744)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42744)\u001b[0m *** SIGSEGV (@0x0) received by PID 42744 (TID 0x7f8e4d1f5700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42744)\u001b[0m     @     0x7f8e4cdce390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42730)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42730)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42730)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42718)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42718)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42718)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42747)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42747)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42747)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42747)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42747)\u001b[0m *** SIGSEGV (@0x0) received by PID 42747 (TID 0x7efdcdd7a700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42747)\u001b[0m     @     0x7efdcd953390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42747)\u001b[0m     @     0x7ececd7f9f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42807)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42807)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42807)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42807)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42807)\u001b[0m *** SIGSEGV (@0x0) received by PID 42807 (TID 0x7fce38aa0700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42807)\u001b[0m     @     0x7fce38679390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42807)\u001b[0m     @     0x7f9f38536f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42767)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42767)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42767)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42803)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42803)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42803)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42803)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42803)\u001b[0m *** SIGSEGV (@0x0) received by PID 42803 (TID 0x7f5b3b78b700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42803)\u001b[0m     @     0x7f5b3b364390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42803)\u001b[0m     @     0x7f2c3b124f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42697)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42697)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42697)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42780)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42780)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42780)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42780)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42780)\u001b[0m *** SIGSEGV (@0x0) received by PID 42780 (TID 0x7f027b71e700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42816)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42816)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42816)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42816)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42816)\u001b[0m *** SIGSEGV (@0x0) received by PID 42816 (TID 0x7f76cad09700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42816)\u001b[0m     @     0x7f76ca8e2390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42816)\u001b[0m     @     0x7f47ca7bbf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42816)\u001b[0m     @     0x7f47c9ee67db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42700)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42700)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42700)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42700)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42700)\u001b[0m *** SIGSEGV (@0x0) received by PID 42700 (TID 0x7f3450b73700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42700)\u001b[0m     @     0x7f345074c390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42700)\u001b[0m     @     0x7f055070cf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42700)\u001b[0m     @     0x7f054fe377db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42693)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42693)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42693)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42693)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42693)\u001b[0m *** SIGSEGV (@0x0) received by PID 42693 (TID 0x7fa6db9ff700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42693)\u001b[0m     @     0x7fa6db5d8390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42693)\u001b[0m     @     0x7f77db572f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42693)\u001b[0m     @     0x7f77dac9d7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42699)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42699)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42699)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42699)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42699)\u001b[0m *** SIGSEGV (@0x0) received by PID 42699 (TID 0x7f8e7a492700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42699)\u001b[0m     @     0x7f8e7a06b390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42699)\u001b[0m     @     0x7f5f7a005f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42699)\u001b[0m     @     0x7f5f797307db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42785)\u001b[0m     @     0x7fb123d3cad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42785)\u001b[0m     @     0x7fb123d3cd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42785)\u001b[0m     @     0x7fb12461fb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42785)\u001b[0m     @     0x7fb124642c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42785)\u001b[0m     @     0x7fb123ae4a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42785)\u001b[0m     @     0x7fb123ae2388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42771)\u001b[0m     @     0x7fbc6753c8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42771)\u001b[0m     @     0x7fbc6753cad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42771)\u001b[0m     @     0x7fbc6753cd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42771)\u001b[0m     @     0x7fbc67e1fb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42771)\u001b[0m     @     0x7fbc67e42c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42794)\u001b[0m     @     0x7ef78d2c8b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42794)\u001b[0m     @     0x7ef78d2ebc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42794)\u001b[0m     @     0x7ef78c78da93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42794)\u001b[0m     @     0x7ef78c78b388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42794)\u001b[0m     @     0x7ef78c78d5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42794)\u001b[0m     @     0x7ef78ce784f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42794)\u001b[0m     @     0x7ef78f34b8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42821)\u001b[0m     @     0x7fc863a3cc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42821)\u001b[0m     @     0x7fc862edea93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42821)\u001b[0m     @     0x7fc862edc388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42821)\u001b[0m     @     0x7fc862ede5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42821)\u001b[0m     @     0x7fc8635c94f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42821)\u001b[0m     @     0x7fc865a9c8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42821)\u001b[0m     @     0x7fc8635c94f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42821)\u001b[0m     @     0x7fc86967479f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42821)\u001b[0m     @     0x564067de7fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42821)\u001b[0m     @     0x564067d42b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42821)\u001b[0m     @     0x564067dcdbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42821)\u001b[0m     @     0x564067dcea20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42821)\u001b[0m     @     0x564067d42bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42821)\u001b[0m     @     0x564067dcdbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42821)\u001b[0m     @     0x564067dce643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42821)\u001b[0m     @     0x564067d43689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42821)\u001b[0m     @     0x564067dcdbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42821)\u001b[0m     @     0x564067dce643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42821)\u001b[0m     @     0x564067d43689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42821)\u001b[0m     @     0x564067dcdbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42821)\u001b[0m     @     0x564067dce643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42821)\u001b[0m     @     0x564067d43689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42821)\u001b[0m     @     0x564067dcdbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42821)\u001b[0m     @     0x564067dce643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42821)\u001b[0m     @     0x564067d43689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42802)\u001b[0m     @     0x7eeac7d3cad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42802)\u001b[0m     @     0x7eeac7d3cd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42802)\u001b[0m     @     0x7eeac861fb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42802)\u001b[0m     @     0x7eeac8642c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42802)\u001b[0m     @     0x7eeac7ae4a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42802)\u001b[0m     @     0x7eeac7ae2388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42810)\u001b[0m     @     0x7f744ae7fd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42810)\u001b[0m     @     0x7f744b762b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42810)\u001b[0m     @     0x7f744b785c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42810)\u001b[0m     @     0x7f744ac27a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42810)\u001b[0m     @     0x7f744ac25388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42810)\u001b[0m     @     0x7f744ac275a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42810)\u001b[0m     @     0x7f744b3124f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42784)\u001b[0m     @     0x7f0b71e7c8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42784)\u001b[0m     @     0x7f0b71e7cad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42784)\u001b[0m     @     0x7f0b71e7cd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42784)\u001b[0m     @     0x7f0b7275fb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42784)\u001b[0m     @     0x7f0b72782c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42784)\u001b[0m     @     0x7f0b71c24a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42784)\u001b[0m     @     0x7f0b71c22388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42788)\u001b[0m     @     0x7f51ced4dad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42788)\u001b[0m     @     0x7f51ced4dd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42788)\u001b[0m     @     0x7f51cf630b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42788)\u001b[0m     @     0x7f51cf653c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42788)\u001b[0m     @     0x7f51ceaf5a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42788)\u001b[0m     @     0x7f51ceaf3388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42793)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42793)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42793)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42793)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42793)\u001b[0m *** SIGSEGV (@0x0) received by PID 42793 (TID 0x7fcf3a89b700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42793)\u001b[0m     @     0x7fcf3a474390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42776)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42776)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42776)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42776)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42776)\u001b[0m *** SIGSEGV (@0x0) received by PID 42776 (TID 0x7f380084a700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42776)\u001b[0m     @     0x7f3800423390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42776)\u001b[0m     @     0x7f09000acf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42776)\u001b[0m     @     0x7f08ff7d77db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42696)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42696)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42696)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42696)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42696)\u001b[0m *** SIGSEGV (@0x0) received by PID 42696 (TID 0x7f20bc637700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42696)\u001b[0m     @     0x7f20bc210390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42696)\u001b[0m     @     0x7ef1bc01cf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42696)\u001b[0m     @     0x7ef1bb7477db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42696)\u001b[0m     @     0x7ef1bb74a8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42777)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42777)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42777)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42777)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42777)\u001b[0m *** SIGSEGV (@0x0) received by PID 42777 (TID 0x7effe5474700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42777)\u001b[0m     @     0x7effe504d390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42777)\u001b[0m     @     0x7ed0e4ea4f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42777)\u001b[0m     @     0x7ed0e45cf7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42777)\u001b[0m     @     0x7ed0e45d28f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42770)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42770)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42770)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42770)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42770)\u001b[0m *** SIGSEGV (@0x0) received by PID 42770 (TID 0x7f87699a6700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42770)\u001b[0m     @     0x7f876957f390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42770)\u001b[0m     @     0x7f58694e3f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42770)\u001b[0m     @     0x7f5868c0e7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42770)\u001b[0m     @     0x7f5868c118f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42770)\u001b[0m     @     0x7f5868c11ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42691)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42691)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42691)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42691)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42691)\u001b[0m *** SIGSEGV (@0x0) received by PID 42691 (TID 0x7f8751f5f700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42691)\u001b[0m     @     0x7f8751b38390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42691)\u001b[0m     @     0x7f5851a0af90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42691)\u001b[0m     @     0x7f58511357db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42691)\u001b[0m     @     0x7f58511388f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42691)\u001b[0m     @     0x7f5851138ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42713)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42713)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42713)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42713)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42713)\u001b[0m *** SIGSEGV (@0x0) received by PID 42713 (TID 0x7fc897270700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42713)\u001b[0m     @     0x7fc896e49390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42713)\u001b[0m     @     0x7f9996df0f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42713)\u001b[0m     @     0x7f999651b7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42713)\u001b[0m     @     0x7f999651e8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42713)\u001b[0m     @     0x7f999651ead3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42779)\u001b[0m     @     0x7f124933bad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42779)\u001b[0m     @     0x7f124933bd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42779)\u001b[0m     @     0x7f1249c1eb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42779)\u001b[0m     @     0x7f1249c41c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42779)\u001b[0m     @     0x7f12490e3a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42779)\u001b[0m     @     0x7f12490e1388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42779)\u001b[0m     @     0x7f12490e35a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42779)\u001b[0m     @     0x7f12497ce4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42779)\u001b[0m     @     0x7f124bca18de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42746)\u001b[0m     @     0x7f58f15528f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42746)\u001b[0m     @     0x7f58f1552ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42746)\u001b[0m     @     0x7f58f1552d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42746)\u001b[0m     @     0x7f58f1e35b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42746)\u001b[0m     @     0x7f58f1e58c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42746)\u001b[0m     @     0x7f58f12faa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42746)\u001b[0m     @     0x7f58f12f8388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42746)\u001b[0m     @     0x7f58f12fa5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42731)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42731)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42731)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42731)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42731)\u001b[0m *** SIGSEGV (@0x0) received by PID 42731 (TID 0x7f868f0f5700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42731)\u001b[0m     @     0x7f868ecce390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42731)\u001b[0m     @     0x7f578ec6af90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42731)\u001b[0m     @     0x7f578e3957db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42731)\u001b[0m     @     0x7f578e3988f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42731)\u001b[0m     @     0x7f578e398ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42772)\u001b[0m     @     0x7f09c5ee98f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42772)\u001b[0m     @     0x7f09c5ee9ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42772)\u001b[0m     @     0x7f09c5ee9d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42772)\u001b[0m     @     0x7f09c67ccb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42772)\u001b[0m     @     0x7f09c67efc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42772)\u001b[0m     @     0x7f09c5c91a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42772)\u001b[0m     @     0x7f09c5c8f388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42772)\u001b[0m     @     0x7f09c5c915a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42711)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42711)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42711)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42711)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42711)\u001b[0m *** SIGSEGV (@0x0) received by PID 42711 (TID 0x7fa80e736700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42711)\u001b[0m     @     0x7fa80e30f390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42711)\u001b[0m     @     0x7f790e2b9f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42711)\u001b[0m     @     0x7f790d9e47db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42711)\u001b[0m     @     0x7f790d9e78f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42711)\u001b[0m     @     0x7f790d9e7ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42812)\u001b[0m     @     0x7efe8f74aad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42812)\u001b[0m     @     0x7efe8f74ad91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42812)\u001b[0m     @     0x7efe9002db22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42812)\u001b[0m     @     0x7efe90050c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42812)\u001b[0m     @     0x7efe8f4f2a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42812)\u001b[0m     @     0x7efe8f4f0388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42812)\u001b[0m     @     0x7efe8f4f25a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42812)\u001b[0m     @     0x7efe8fbdd4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42812)\u001b[0m     @     0x7efe920b08de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42800)\u001b[0m     @     0x7f9b405d2ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42800)\u001b[0m     @     0x7f9b405d2d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42800)\u001b[0m     @     0x7f9b40eb5b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42800)\u001b[0m     @     0x7f9b40ed8c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42800)\u001b[0m     @     0x7f9b4037aa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42800)\u001b[0m     @     0x7f9b40378388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42800)\u001b[0m     @     0x7f9b4037a5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42800)\u001b[0m     @     0x7f9b40a654f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42800)\u001b[0m     @     0x7f9b42f388de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42769)\u001b[0m     @     0x7f6784ee0a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42769)\u001b[0m     @     0x7f6784ede388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42769)\u001b[0m     @     0x7f6784ee05a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42769)\u001b[0m     @     0x7f67855cb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42769)\u001b[0m     @     0x7f6787a9e8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42769)\u001b[0m     @     0x7f67855cb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42769)\u001b[0m     @     0x7f678b67679f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42769)\u001b[0m     @     0x556f8a1cffd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42769)\u001b[0m     @     0x556f8a12ab08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42769)\u001b[0m     @     0x556f8a1b5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42769)\u001b[0m     @     0x556f8a1b6a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42769)\u001b[0m     @     0x556f8a12abfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42769)\u001b[0m     @     0x556f8a1b5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42769)\u001b[0m     @     0x556f8a1b6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42769)\u001b[0m     @     0x556f8a12b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42769)\u001b[0m     @     0x556f8a1b5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42769)\u001b[0m     @     0x556f8a1b6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42769)\u001b[0m     @     0x556f8a12b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42769)\u001b[0m     @     0x556f8a1b5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42769)\u001b[0m     @     0x556f8a1b6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42769)\u001b[0m     @     0x556f8a12b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42769)\u001b[0m     @     0x556f8a1b5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42769)\u001b[0m     @     0x556f8a1b6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42769)\u001b[0m     @     0x556f8a12b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42728)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42728)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42728)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42728)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42728)\u001b[0m *** SIGSEGV (@0x0) received by PID 42728 (TID 0x7f2a20260700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42728)\u001b[0m     @     0x7f2a1fe39390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42728)\u001b[0m     @     0x7efb1fddef90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42728)\u001b[0m     @     0x7efb1f5097db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42728)\u001b[0m     @     0x7efb1f50c8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42728)\u001b[0m     @     0x7efb1f50cad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42728)\u001b[0m     @     0x7efb1f50cd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42705)\u001b[0m     @     0x7ee1659e78f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42705)\u001b[0m     @     0x7ee1659e7ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42705)\u001b[0m     @     0x7ee1659e7d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42705)\u001b[0m     @     0x7ee1662cab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42705)\u001b[0m     @     0x7ee1662edc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42705)\u001b[0m     @     0x7ee16578fa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42705)\u001b[0m     @     0x7ee16578d388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42705)\u001b[0m     @     0x7ee16578f5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42705)\u001b[0m     @     0x7ee165e7a4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42716)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42716)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42716)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42716)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42716)\u001b[0m *** SIGSEGV (@0x0) received by PID 42716 (TID 0x7fce6e1a5700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42716)\u001b[0m     @     0x7fce6dd7e390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42716)\u001b[0m     @     0x7f9f6dc0df90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42716)\u001b[0m     @     0x7f9f6d3387db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42716)\u001b[0m     @     0x7f9f6d33b8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42716)\u001b[0m     @     0x7f9f6d33bad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42716)\u001b[0m     @     0x7f9f6d33bd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42787)\u001b[0m     @     0x7fadf85d2ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42787)\u001b[0m     @     0x7fadf85d2d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42787)\u001b[0m     @     0x7fadf8eb5b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42787)\u001b[0m     @     0x7fadf8ed8c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42787)\u001b[0m     @     0x7fadf837aa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42787)\u001b[0m     @     0x7fadf8378388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42787)\u001b[0m     @     0x7fadf837a5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42787)\u001b[0m     @     0x7fadf8a654f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42787)\u001b[0m     @     0x7fadfaf388de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42787)\u001b[0m     @     0x7fadf8a654f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42787)\u001b[0m     @     0x7fadfeb1079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42787)\u001b[0m     @     0x55dbe4932fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42781)\u001b[0m     @     0x7f74c85a58f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42781)\u001b[0m     @     0x7f74c85a5ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42781)\u001b[0m     @     0x7f74c85a5d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42781)\u001b[0m     @     0x7f74c8e88b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42781)\u001b[0m     @     0x7f74c8eabc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42781)\u001b[0m     @     0x7f74c834da93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42781)\u001b[0m     @     0x7f74c834b388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42781)\u001b[0m     @     0x7f74c834d5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42781)\u001b[0m     @     0x7f74c8a384f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42762)\u001b[0m     @     0x7fa81b539ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42762)\u001b[0m     @     0x7fa81b539d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42762)\u001b[0m     @     0x7fa81be1cb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42762)\u001b[0m     @     0x7fa81be3fc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42762)\u001b[0m     @     0x7fa81b2e1a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42762)\u001b[0m     @     0x7fa81b2df388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42762)\u001b[0m     @     0x7fa81b2e15a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42762)\u001b[0m     @     0x7fa81b9cc4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42762)\u001b[0m     @     0x7fa81de9f8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42798)\u001b[0m     @     0x7ef85ef7aad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42798)\u001b[0m     @     0x7ef85ef7ad91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42798)\u001b[0m     @     0x7ef85f85db22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42798)\u001b[0m     @     0x7ef85f880c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42798)\u001b[0m     @     0x7ef85ed22a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42798)\u001b[0m     @     0x7ef85ed20388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42798)\u001b[0m     @     0x7ef85ed225a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42798)\u001b[0m     @     0x7ef85f40d4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42798)\u001b[0m     @     0x7ef8618e08de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42798)\u001b[0m     @     0x7ef85f40d4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42798)\u001b[0m     @     0x7ef8654b879f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42798)\u001b[0m     @     0x55719f163fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42798)\u001b[0m     @     0x55719f0beb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42798)\u001b[0m     @     0x55719f149baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42798)\u001b[0m     @     0x55719f14aa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42798)\u001b[0m     @     0x55719f0bebfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42798)\u001b[0m     @     0x55719f149baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42798)\u001b[0m     @     0x55719f14a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42798)\u001b[0m     @     0x55719f0bf689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42798)\u001b[0m     @     0x55719f149baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42798)\u001b[0m     @     0x55719f14a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42798)\u001b[0m     @     0x55719f0bf689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42798)\u001b[0m     @     0x55719f149baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42798)\u001b[0m     @     0x55719f14a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42798)\u001b[0m     @     0x55719f0bf689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42798)\u001b[0m     @     0x55719f149baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42798)\u001b[0m     @     0x55719f14a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42798)\u001b[0m     @     0x55719f0bf689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42797)\u001b[0m     @     0x7fac1a601d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42797)\u001b[0m     @     0x7fac1aee4b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42797)\u001b[0m     @     0x7fac1af07c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42797)\u001b[0m     @     0x7fac1a3a9a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42797)\u001b[0m     @     0x7fac1a3a7388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42797)\u001b[0m     @     0x7fac1a3a95a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42797)\u001b[0m     @     0x7fac1aa944f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42797)\u001b[0m     @     0x7fac1cf678de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42797)\u001b[0m     @     0x7fac1aa944f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42797)\u001b[0m     @     0x7fac20b3f79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42797)\u001b[0m     @     0x55b762073fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42797)\u001b[0m     @     0x55b761fceb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42797)\u001b[0m     @     0x55b762059baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42797)\u001b[0m     @     0x55b76205aa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42797)\u001b[0m     @     0x55b761fcebfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42797)\u001b[0m     @     0x55b762059baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42797)\u001b[0m     @     0x55b76205a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42797)\u001b[0m     @     0x55b761fcf689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42797)\u001b[0m     @     0x55b762059baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42797)\u001b[0m     @     0x55b76205a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42797)\u001b[0m     @     0x55b761fcf689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42797)\u001b[0m     @     0x55b762059baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42797)\u001b[0m     @     0x55b76205a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42797)\u001b[0m     @     0x55b761fcf689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42797)\u001b[0m     @     0x55b762059baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42797)\u001b[0m     @     0x55b76205a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42797)\u001b[0m     @     0x55b761fcf689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42811)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42811)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42811)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42811)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42811)\u001b[0m *** SIGSEGV (@0x0) received by PID 42811 (TID 0x7f7b34255700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42811)\u001b[0m     @     0x7f7b33e2e390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42811)\u001b[0m     @     0x7f4c33dc3f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42811)\u001b[0m     @     0x7f4c334ee7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42811)\u001b[0m     @     0x7f4c334f18f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42811)\u001b[0m     @     0x7f4c334f1ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42778)\u001b[0m     @     0x7f037177b8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42778)\u001b[0m     @     0x7f037177bad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42778)\u001b[0m     @     0x7f037177bd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42778)\u001b[0m     @     0x7f037205eb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42778)\u001b[0m     @     0x7f0372081c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42778)\u001b[0m     @     0x7f0371523a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42778)\u001b[0m     @     0x7f0371521388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42778)\u001b[0m     @     0x7f03715235a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42778)\u001b[0m     @     0x7f0371c0e4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42790)\u001b[0m     @     0x7f1508d93ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42790)\u001b[0m     @     0x7f1508d93d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42790)\u001b[0m     @     0x7f1509676b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42790)\u001b[0m     @     0x7f1509699c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42790)\u001b[0m     @     0x7f1508b3ba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42790)\u001b[0m     @     0x7f1508b39388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42790)\u001b[0m     @     0x7f1508b3b5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42790)\u001b[0m     @     0x7f15092264f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42790)\u001b[0m     @     0x7f150b6f98de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42819)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42819)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42819)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42819)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42819)\u001b[0m *** SIGSEGV (@0x0) received by PID 42819 (TID 0x7f10726c6700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42819)\u001b[0m     @     0x7f107229f390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42819)\u001b[0m     @     0x7ee172239f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42819)\u001b[0m     @     0x7ee1719647db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42819)\u001b[0m     @     0x7ee1719678f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42819)\u001b[0m     @     0x7ee171967ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42819)\u001b[0m     @     0x7ee171967d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42819)\u001b[0m     @     0x7ee17224ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42819)\u001b[0m     @     0x7ee17226dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42706)\u001b[0m     @     0x7f3c245d2ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42706)\u001b[0m     @     0x7f3c245d2d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42706)\u001b[0m     @     0x7f3c24eb5b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42706)\u001b[0m     @     0x7f3c24ed8c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42706)\u001b[0m     @     0x7f3c2437aa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42706)\u001b[0m     @     0x7f3c24378388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42706)\u001b[0m     @     0x7f3c2437a5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42706)\u001b[0m     @     0x7f3c24a654f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42706)\u001b[0m     @     0x7f3c26f388de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42775)\u001b[0m     @     0x7f4c1533fd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42775)\u001b[0m     @     0x7f4c15c22b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42775)\u001b[0m     @     0x7f4c15c45c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42775)\u001b[0m     @     0x7f4c150e7a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42775)\u001b[0m     @     0x7f4c150e5388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42775)\u001b[0m     @     0x7f4c150e75a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42775)\u001b[0m     @     0x7f4c157d24f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42775)\u001b[0m     @     0x7f4c17ca58de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42775)\u001b[0m     @     0x7f4c157d24f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42775)\u001b[0m     @     0x7f4c1b87d79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42775)\u001b[0m     @     0x557b45906fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42775)\u001b[0m     @     0x557b45861b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42775)\u001b[0m     @     0x557b458ecbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42775)\u001b[0m     @     0x557b458eda20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42775)\u001b[0m     @     0x557b45861bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42775)\u001b[0m     @     0x557b458ecbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42775)\u001b[0m     @     0x557b458ed643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42775)\u001b[0m     @     0x557b45862689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42775)\u001b[0m     @     0x557b458ecbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42775)\u001b[0m     @     0x557b458ed643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42775)\u001b[0m     @     0x557b45862689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42775)\u001b[0m     @     0x557b458ecbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42775)\u001b[0m     @     0x557b458ed643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42775)\u001b[0m     @     0x557b45862689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42775)\u001b[0m     @     0x557b458ecbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42775)\u001b[0m     @     0x557b458ed643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42775)\u001b[0m     @     0x557b45862689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42805)\u001b[0m     @     0x7f5445756d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42805)\u001b[0m     @     0x7f5446039b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42805)\u001b[0m     @     0x7f544605cc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42805)\u001b[0m     @     0x7f54454fea93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42805)\u001b[0m     @     0x7f54454fc388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42805)\u001b[0m     @     0x7f54454fe5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42805)\u001b[0m     @     0x7f5445be94f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42805)\u001b[0m     @     0x7f54480bc8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42805)\u001b[0m     @     0x7f5445be94f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42805)\u001b[0m     @     0x7f544bc9479f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42805)\u001b[0m     @     0x5607e5bbdfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42805)\u001b[0m     @     0x5607e5b18b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42805)\u001b[0m     @     0x5607e5ba3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42805)\u001b[0m     @     0x5607e5ba4a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42805)\u001b[0m     @     0x5607e5b18bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42805)\u001b[0m     @     0x5607e5ba3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42805)\u001b[0m     @     0x5607e5ba4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42805)\u001b[0m     @     0x5607e5b19689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42805)\u001b[0m     @     0x5607e5ba3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42805)\u001b[0m     @     0x5607e5ba4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42805)\u001b[0m     @     0x5607e5b19689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42805)\u001b[0m     @     0x5607e5ba3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42805)\u001b[0m     @     0x5607e5ba4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42805)\u001b[0m     @     0x5607e5b19689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42805)\u001b[0m     @     0x5607e5ba3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42805)\u001b[0m     @     0x5607e5ba4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42805)\u001b[0m     @     0x5607e5b19689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42774)\u001b[0m     @     0x7f1481512d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42774)\u001b[0m     @     0x7f1481df5b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42774)\u001b[0m     @     0x7f1481e18c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42774)\u001b[0m     @     0x7f14812baa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42774)\u001b[0m     @     0x7f14812b8388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42774)\u001b[0m     @     0x7f14812ba5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42774)\u001b[0m     @     0x7f14819a54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42774)\u001b[0m     @     0x7f1483e788de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42774)\u001b[0m     @     0x7f14819a54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42774)\u001b[0m     @     0x7f1487a5079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42774)\u001b[0m     @     0x55691ddeffd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42774)\u001b[0m     @     0x55691dd4ab08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42774)\u001b[0m     @     0x55691ddd5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42774)\u001b[0m     @     0x55691ddd6a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42774)\u001b[0m     @     0x55691dd4abfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42774)\u001b[0m     @     0x55691ddd5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42774)\u001b[0m     @     0x55691ddd6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42774)\u001b[0m     @     0x55691dd4b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42774)\u001b[0m     @     0x55691ddd5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42774)\u001b[0m     @     0x55691ddd6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42774)\u001b[0m     @     0x55691dd4b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42774)\u001b[0m     @     0x55691ddd5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42774)\u001b[0m     @     0x55691ddd6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42774)\u001b[0m     @     0x55691dd4b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42774)\u001b[0m     @     0x55691ddd5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42774)\u001b[0m     @     0x55691ddd6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42774)\u001b[0m     @     0x55691dd4b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42704)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42704)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42704)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42704)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42704)\u001b[0m *** SIGSEGV (@0x0) received by PID 42704 (TID 0x7f870fdc8700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42704)\u001b[0m     @     0x7f870f9a1390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42704)\u001b[0m     @     0x7f580f8def90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42704)\u001b[0m     @     0x7f580f0097db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42704)\u001b[0m     @     0x7f580f00c8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42704)\u001b[0m     @     0x7f580f00cad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42708)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42708)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42708)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42708)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42708)\u001b[0m *** SIGSEGV (@0x0) received by PID 42708 (TID 0x7f5aa1c7b700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42708)\u001b[0m     @     0x7f5aa1854390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42708)\u001b[0m     @     0x7f2ba16f4f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42708)\u001b[0m     @     0x7f2ba0e1f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42708)\u001b[0m     @     0x7f2ba0e228f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42708)\u001b[0m     @     0x7f2ba0e22ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42818)\u001b[0m     @     0x7f1993c64d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42818)\u001b[0m     @     0x7f1994547b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42818)\u001b[0m     @     0x7f199456ac1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42818)\u001b[0m     @     0x7f1993a0ca93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42818)\u001b[0m     @     0x7f1993a0a388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42818)\u001b[0m     @     0x7f1993a0c5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42818)\u001b[0m     @     0x7f19940f74f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42818)\u001b[0m     @     0x7f19965ca8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42818)\u001b[0m     @     0x7f19940f74f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42818)\u001b[0m     @     0x7f199a1a279f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42818)\u001b[0m     @     0x558d1617dfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42818)\u001b[0m     @     0x558d160d8b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42818)\u001b[0m     @     0x558d16163baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42818)\u001b[0m     @     0x558d16164a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42818)\u001b[0m     @     0x558d160d8bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42818)\u001b[0m     @     0x558d16163baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42818)\u001b[0m     @     0x558d16164643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42818)\u001b[0m     @     0x558d160d9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42818)\u001b[0m     @     0x558d16163baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42818)\u001b[0m     @     0x558d16164643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42818)\u001b[0m     @     0x558d160d9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42818)\u001b[0m     @     0x558d16163baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42818)\u001b[0m     @     0x558d16164643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42818)\u001b[0m     @     0x558d160d9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42818)\u001b[0m     @     0x558d16163baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42818)\u001b[0m     @     0x558d16164643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42818)\u001b[0m     @     0x558d160d9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42763)\u001b[0m     @     0x7f8253f538f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42763)\u001b[0m     @     0x7f8253f53ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42763)\u001b[0m     @     0x7f8253f53d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42763)\u001b[0m     @     0x7f8254836b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42763)\u001b[0m     @     0x7f8254859c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42763)\u001b[0m     @     0x7f8253cfba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42763)\u001b[0m     @     0x7f8253cf9388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42763)\u001b[0m     @     0x7f8253cfb5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42763)\u001b[0m     @     0x7f82543e64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42758)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42758)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42758)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42758)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42758)\u001b[0m *** SIGSEGV (@0x0) received by PID 42758 (TID 0x7f6304e77700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42758)\u001b[0m     @     0x7f6304a50390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42758)\u001b[0m     @     0x7f3404911f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42758)\u001b[0m     @     0x7f340403c7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42758)\u001b[0m     @     0x7f340403f8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42758)\u001b[0m     @     0x7f340403fad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42758)\u001b[0m     @     0x7f340403fd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42764)\u001b[0m     @     0x7f72ac9e5ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42764)\u001b[0m     @     0x7f72ac9e5d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42764)\u001b[0m     @     0x7f72ad2c8b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42764)\u001b[0m     @     0x7f72ad2ebc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42764)\u001b[0m     @     0x7f72ac78da93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42764)\u001b[0m     @     0x7f72ac78b388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42764)\u001b[0m     @     0x7f72ac78d5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42764)\u001b[0m     @     0x7f72ace784f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42764)\u001b[0m     @     0x7f72af34b8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42692)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42692)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42692)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42692)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42692)\u001b[0m *** SIGSEGV (@0x0) received by PID 42692 (TID 0x7fce938ef700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42692)\u001b[0m     @     0x7fce934c8390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42692)\u001b[0m     @     0x7f9f9346af90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42692)\u001b[0m     @     0x7f9f92b957db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42692)\u001b[0m     @     0x7f9f92b988f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42692)\u001b[0m     @     0x7f9f92b98ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42748)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42748)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42748)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42748)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42748)\u001b[0m *** SIGSEGV (@0x0) received by PID 42748 (TID 0x7f514ef30700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42748)\u001b[0m     @     0x7f514eb09390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42748)\u001b[0m     @     0x7f224e97ef90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42748)\u001b[0m     @     0x7f224e0a97db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42748)\u001b[0m     @     0x7f224e0ac8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42748)\u001b[0m     @     0x7f224e0acad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42709)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42709)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42709)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42709)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42709)\u001b[0m *** SIGSEGV (@0x0) received by PID 42709 (TID 0x7f9669dd1700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42709)\u001b[0m     @     0x7f96699aa390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42709)\u001b[0m     @     0x7f6769749f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42709)\u001b[0m     @     0x7f6768e747db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42709)\u001b[0m     @     0x7f6768e778f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42709)\u001b[0m     @     0x7f6768e77ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42709)\u001b[0m     @     0x7f6768e77d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42702)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42702)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42702)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42702)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42702)\u001b[0m *** SIGSEGV (@0x0) received by PID 42702 (TID 0x7f0ed52b7700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42702)\u001b[0m     @     0x7f0ed4e90390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42702)\u001b[0m     @     0x7edfd4e12f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42702)\u001b[0m     @     0x7edfd453d7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42702)\u001b[0m     @     0x7edfd45408f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42702)\u001b[0m     @     0x7edfd4540ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42702)\u001b[0m     @     0x7edfd4540d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42702)\u001b[0m     @     0x7edfd4e23b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42702)\u001b[0m     @     0x7edfd4e46c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42701)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42701)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42701)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42701)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42701)\u001b[0m *** SIGSEGV (@0x0) received by PID 42701 (TID 0x7f1ed88d4700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42701)\u001b[0m     @     0x7f1ed84ad390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42701)\u001b[0m     @     0x7eefd83e3f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42701)\u001b[0m     @     0x7eefd7b0e7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42701)\u001b[0m     @     0x7eefd7b118f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42701)\u001b[0m     @     0x7eefd7b11ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42721)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42721)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42721)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42721)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42721)\u001b[0m *** SIGSEGV (@0x0) received by PID 42721 (TID 0x7f3ff2b0c700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42721)\u001b[0m     @     0x7f3ff26e5390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42721)\u001b[0m     @     0x7f10f24f9f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42721)\u001b[0m     @     0x7f10f1c247db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42721)\u001b[0m     @     0x7f10f1c278f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42721)\u001b[0m     @     0x7f10f1c27ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42783)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42783)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42783)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42783)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42783)\u001b[0m *** SIGSEGV (@0x0) received by PID 42783 (TID 0x7f1d48909700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42783)\u001b[0m     @     0x7f1d484e2390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42783)\u001b[0m     @     0x7eee483e3f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42783)\u001b[0m     @     0x7eee47b0e7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42783)\u001b[0m     @     0x7eee47b118f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42753)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42753)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42753)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42753)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42753)\u001b[0m *** SIGSEGV (@0x0) received by PID 42753 (TID 0x7fa3aefdd700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42753)\u001b[0m     @     0x7fa3aebb6390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42753)\u001b[0m     @     0x7f74aea21f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42753)\u001b[0m     @     0x7f74ae14c7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42753)\u001b[0m     @     0x7f74ae14f8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42753)\u001b[0m     @     0x7f74ae14fad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42751)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42751)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42751)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42751)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42751)\u001b[0m *** SIGSEGV (@0x0) received by PID 42751 (TID 0x7f6c4c172700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42751)\u001b[0m     @     0x7f6c4bd4b390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42751)\u001b[0m     @     0x7f3d4bce0f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42751)\u001b[0m     @     0x7f3d4b40b7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42751)\u001b[0m     @     0x7f3d4b40e8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42751)\u001b[0m     @     0x7f3d4b40ead3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42751)\u001b[0m     @     0x7f3d4b40ed91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42773)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42773)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42773)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42773)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42773)\u001b[0m *** SIGSEGV (@0x0) received by PID 42773 (TID 0x7fd218374700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42773)\u001b[0m     @     0x7fd217f4d390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42773)\u001b[0m     @     0x7fa317df0f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42773)\u001b[0m     @     0x7fa31751b7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42760)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42760)\u001b[0m *** SIGSEGV (@0x0) received by PID 42760 (TID 0x7f473254f700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42760)\u001b[0m     @     0x7f4732128390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42760)\u001b[0m     @     0x7f18320cdf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42760)\u001b[0m     @     0x7f18317f87db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42760)\u001b[0m     @     0x7f18317fb8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42760)\u001b[0m     @     0x7f18317fbad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42760)\u001b[0m     @     0x7f18317fbd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42760)\u001b[0m     @     0x7f18320deb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42698)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42698)\u001b[0m *** SIGSEGV (@0x0) received by PID 42698 (TID 0x7f8bdb474700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42698)\u001b[0m     @     0x7f8bdb04d390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42698)\u001b[0m     @     0x7f5cdaf13f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42698)\u001b[0m     @     0x7f5cda63e7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42698)\u001b[0m     @     0x7f5cda6418f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42698)\u001b[0m     @     0x7f5cda641ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42698)\u001b[0m     @     0x7f5cda641d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42756)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42756)\u001b[0m *** SIGSEGV (@0x0) received by PID 42756 (TID 0x7f350ed12700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42756)\u001b[0m     @     0x7f350e8eb390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42756)\u001b[0m     @     0x7f060e70af90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42756)\u001b[0m     @     0x7f060de357db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42756)\u001b[0m     @     0x7f060de388f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42756)\u001b[0m     @     0x7f060de38ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42712)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42712)\u001b[0m *** SIGSEGV (@0x0) received by PID 42712 (TID 0x7f5c30361700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42712)\u001b[0m     @     0x7f5c2ff3a390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42712)\u001b[0m     @     0x7f2d2fe0bf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42712)\u001b[0m     @     0x7f2d2f5367db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42712)\u001b[0m     @     0x7f2d2f5398f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42712)\u001b[0m     @     0x7f2d2f539ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42712)\u001b[0m     @     0x7f2d2f539d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42694)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42694)\u001b[0m *** SIGSEGV (@0x0) received by PID 42694 (TID 0x7fd19526a700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42694)\u001b[0m     @     0x7fd194e43390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42694)\u001b[0m     @     0x7fa294b85f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42694)\u001b[0m     @     0x7fa2942b07db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42694)\u001b[0m     @     0x7fa2942b38f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42694)\u001b[0m     @     0x7fa2942b3ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42694)\u001b[0m     @     0x7fa2942b3d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42694)\u001b[0m     @     0x7fa294b96b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42710)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42710)\u001b[0m *** SIGSEGV (@0x0) received by PID 42710 (TID 0x7fc291182700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42710)\u001b[0m     @     0x7fc290d5b390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42710)\u001b[0m     @     0x7f9390c74f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42710)\u001b[0m     @     0x7f939039f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42710)\u001b[0m     @     0x7f93903a28f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42710)\u001b[0m     @     0x7f93903a2ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42710)\u001b[0m     @     0x7f93903a2d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42714)\u001b[0m     @     0x7f12c3607390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42714)\u001b[0m     @     0x7ee3c35b2f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42714)\u001b[0m     @     0x7ee3c2cdd7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42714)\u001b[0m     @     0x7ee3c2ce08f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42714)\u001b[0m     @     0x7ee3c2ce0ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42714)\u001b[0m     @     0x7ee3c2ce0d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42714)\u001b[0m     @     0x7ee3c35c3b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42714)\u001b[0m     @     0x7ee3c35e6c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42754)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42754)\u001b[0m *** SIGSEGV (@0x0) received by PID 42754 (TID 0x7f213ab87700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42754)\u001b[0m     @     0x7f213a760390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42754)\u001b[0m     @     0x7ef23a6ddf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42754)\u001b[0m     @     0x7ef239e087db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42754)\u001b[0m     @     0x7ef239e0b8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42754)\u001b[0m     @     0x7ef239e0bad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42754)\u001b[0m     @     0x7ef239e0bd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42754)\u001b[0m     @     0x7ef23a6eeb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42754)\u001b[0m     @     0x7ef23a711c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42754)\u001b[0m     @     0x7ef239bb3a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42695)\u001b[0m     @     0x7f48273e1390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42695)\u001b[0m     @     0x7f1926c15f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42695)\u001b[0m     @     0x7f19263407db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42695)\u001b[0m     @     0x7f19263438f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42695)\u001b[0m     @     0x7f1926343ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42695)\u001b[0m     @     0x7f1926343d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42695)\u001b[0m     @     0x7f1926c26b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42744)\u001b[0m     @     0x7f5f4cd24f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42744)\u001b[0m     @     0x7f5f4c44f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42744)\u001b[0m     @     0x7f5f4c4528f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42744)\u001b[0m     @     0x7f5f4c452ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42744)\u001b[0m     @     0x7f5f4c452d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42744)\u001b[0m     @     0x7f5f4cd35b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42744)\u001b[0m     @     0x7f5f4cd58c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42730)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42730)\u001b[0m *** SIGSEGV (@0x0) received by PID 42730 (TID 0x7f8878719700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42730)\u001b[0m     @     0x7f88782f2390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42718)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42718)\u001b[0m *** SIGSEGV (@0x0) received by PID 42718 (TID 0x7fe3411d9700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42718)\u001b[0m     @     0x7fe340db2390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42747)\u001b[0m     @     0x7ececcf247db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42747)\u001b[0m     @     0x7ececcf278f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42747)\u001b[0m     @     0x7ececcf27ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42747)\u001b[0m     @     0x7ececcf27d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42747)\u001b[0m     @     0x7ececd80ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42747)\u001b[0m     @     0x7ececd82dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42807)\u001b[0m     @     0x7f9f37c617db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42807)\u001b[0m     @     0x7f9f37c648f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42807)\u001b[0m     @     0x7f9f37c64ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42807)\u001b[0m     @     0x7f9f37c64d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42807)\u001b[0m     @     0x7f9f38547b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42807)\u001b[0m     @     0x7f9f3856ac1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42767)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42767)\u001b[0m *** SIGSEGV (@0x0) received by PID 42767 (TID 0x7f16cd3e9700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42767)\u001b[0m     @     0x7f16ccfc2390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42767)\u001b[0m     @     0x7ee7ccf4ff90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42767)\u001b[0m     @     0x7ee7cc67a7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42767)\u001b[0m     @     0x7ee7cc67d8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42767)\u001b[0m     @     0x7ee7cc67dad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42803)\u001b[0m     @     0x7f2c3a84f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42803)\u001b[0m     @     0x7f2c3a8528f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42803)\u001b[0m     @     0x7f2c3a852ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42803)\u001b[0m     @     0x7f2c3a852d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42803)\u001b[0m     @     0x7f2c3b135b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42803)\u001b[0m     @     0x7f2c3b158c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42715)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42715)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42715)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42715)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42715)\u001b[0m *** SIGSEGV (@0x0) received by PID 42715 (TID 0x7f5929b15700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42715)\u001b[0m     @     0x7f59296ee390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42715)\u001b[0m     @     0x7f2a29687f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42715)\u001b[0m     @     0x7f2a28db27db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42715)\u001b[0m     @     0x7f2a28db58f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42715)\u001b[0m     @     0x7f2a28db5ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42697)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42697)\u001b[0m *** SIGSEGV (@0x0) received by PID 42697 (TID 0x7fa7e6f43700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42697)\u001b[0m     @     0x7fa7e6b1c390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42697)\u001b[0m     @     0x7f78e6aa4f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42697)\u001b[0m     @     0x7f78e61cf7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42780)\u001b[0m     @     0x7f027b2f7390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42780)\u001b[0m     @     0x7ed37b229f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42780)\u001b[0m     @     0x7ed37a9547db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42726)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=42726)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=42726)\u001b[0m *** Aborted at 1604573031 (unix time) try \"date -d @1604573031\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=42726)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42726)\u001b[0m *** SIGSEGV (@0x0) received by PID 42726 (TID 0x7f805b3e9700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=42726)\u001b[0m     @     0x7f805afc2390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=42726)\u001b[0m     @     0x7f515af13f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42816)\u001b[0m     @     0x7f47c9ee98f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42816)\u001b[0m     @     0x7f47c9ee9ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42816)\u001b[0m     @     0x7f47c9ee9d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42816)\u001b[0m     @     0x7f47ca7ccb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42816)\u001b[0m     @     0x7f47ca7efc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42816)\u001b[0m     @     0x7f47c9c91a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42816)\u001b[0m     @     0x7f47c9c8f388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42700)\u001b[0m     @     0x7f054fe3a8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42700)\u001b[0m     @     0x7f054fe3aad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42700)\u001b[0m     @     0x7f054fe3ad91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42700)\u001b[0m     @     0x7f055071db22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42700)\u001b[0m     @     0x7f0550740c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42700)\u001b[0m     @     0x7f054fbe2a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42700)\u001b[0m     @     0x7f054fbe0388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42693)\u001b[0m     @     0x7f77daca08f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42693)\u001b[0m     @     0x7f77daca0ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42693)\u001b[0m     @     0x7f77daca0d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42693)\u001b[0m     @     0x7f77db583b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42693)\u001b[0m     @     0x7f77db5a6c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42693)\u001b[0m     @     0x7f77daa48a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42693)\u001b[0m     @     0x7f77daa46388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42699)\u001b[0m     @     0x7f5f797338f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42699)\u001b[0m     @     0x7f5f79733ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42699)\u001b[0m     @     0x7f5f79733d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42699)\u001b[0m     @     0x7f5f7a016b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42699)\u001b[0m     @     0x7f5f7a039c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42699)\u001b[0m     @     0x7f5f794dba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42699)\u001b[0m     @     0x7f5f794d9388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42785)\u001b[0m     @     0x7fb123ae45a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42785)\u001b[0m     @     0x7fb1241cf4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42785)\u001b[0m     @     0x7fb1266a28de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42785)\u001b[0m     @     0x7fb1241cf4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42785)\u001b[0m     @     0x7fb12a27a79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42785)\u001b[0m     @     0x55a1d4776fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42785)\u001b[0m     @     0x55a1d46d1b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42785)\u001b[0m     @     0x55a1d475cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42785)\u001b[0m     @     0x55a1d475da20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42785)\u001b[0m     @     0x55a1d46d1bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42785)\u001b[0m     @     0x55a1d475cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42785)\u001b[0m     @     0x55a1d475d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42785)\u001b[0m     @     0x55a1d46d2689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42785)\u001b[0m     @     0x55a1d475cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42785)\u001b[0m     @     0x55a1d475d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42785)\u001b[0m     @     0x55a1d46d2689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42785)\u001b[0m     @     0x55a1d475cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42785)\u001b[0m     @     0x55a1d475d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42785)\u001b[0m     @     0x55a1d46d2689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42785)\u001b[0m     @     0x55a1d475cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42785)\u001b[0m     @     0x55a1d475d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42785)\u001b[0m     @     0x55a1d46d2689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42771)\u001b[0m     @     0x7fbc672e4a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42771)\u001b[0m     @     0x7fbc672e2388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42771)\u001b[0m     @     0x7fbc672e45a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42771)\u001b[0m     @     0x7fbc679cf4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42771)\u001b[0m     @     0x7fbc69ea28de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42771)\u001b[0m     @     0x7fbc679cf4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42771)\u001b[0m     @     0x7fbc6da7a79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42771)\u001b[0m     @     0x56381550afd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42771)\u001b[0m     @     0x563815465b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42771)\u001b[0m     @     0x5638154f0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42771)\u001b[0m     @     0x5638154f1a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42771)\u001b[0m     @     0x563815465bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42771)\u001b[0m     @     0x5638154f0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42771)\u001b[0m     @     0x5638154f1643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42771)\u001b[0m     @     0x563815466689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42771)\u001b[0m     @     0x5638154f0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42771)\u001b[0m     @     0x5638154f1643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42771)\u001b[0m     @     0x563815466689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42771)\u001b[0m     @     0x5638154f0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42771)\u001b[0m     @     0x5638154f1643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42794)\u001b[0m     @     0x7ef78ce784f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42794)\u001b[0m     @     0x7ef792f2379f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42794)\u001b[0m     @     0x55b8faa11fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42794)\u001b[0m     @     0x55b8fa96cb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42794)\u001b[0m     @     0x55b8fa9f7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42794)\u001b[0m     @     0x55b8fa9f8a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42794)\u001b[0m     @     0x55b8fa96cbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42794)\u001b[0m     @     0x55b8fa9f7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42794)\u001b[0m     @     0x55b8fa9f8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42794)\u001b[0m     @     0x55b8fa96d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42794)\u001b[0m     @     0x55b8fa9f7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42794)\u001b[0m     @     0x55b8fa9f8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42794)\u001b[0m     @     0x55b8fa96d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42794)\u001b[0m     @     0x55b8fa9f7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42794)\u001b[0m     @     0x55b8fa9f8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42794)\u001b[0m     @     0x55b8fa96d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42794)\u001b[0m     @     0x55b8fa9f7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42794)\u001b[0m     @     0x55b8fa9f8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42794)\u001b[0m     @     0x55b8fa96d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42802)\u001b[0m     @     0x7eeac7ae45a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42802)\u001b[0m     @     0x7eeac81cf4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42802)\u001b[0m     @     0x7eeaca6a28de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42802)\u001b[0m     @     0x7eeac81cf4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42802)\u001b[0m     @     0x7eeace27a79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42802)\u001b[0m     @     0x55e9f2554fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42802)\u001b[0m     @     0x55e9f24afb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42802)\u001b[0m     @     0x55e9f253abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42802)\u001b[0m     @     0x55e9f253ba20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42802)\u001b[0m     @     0x55e9f24afbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42802)\u001b[0m     @     0x55e9f253abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42802)\u001b[0m     @     0x55e9f253b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42802)\u001b[0m     @     0x55e9f24b0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42802)\u001b[0m     @     0x55e9f253abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42802)\u001b[0m     @     0x55e9f253b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42802)\u001b[0m     @     0x55e9f24b0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42802)\u001b[0m     @     0x55e9f253abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42802)\u001b[0m     @     0x55e9f253b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42802)\u001b[0m     @     0x55e9f24b0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42802)\u001b[0m     @     0x55e9f253abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42802)\u001b[0m     @     0x55e9f253b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42802)\u001b[0m     @     0x55e9f24b0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42810)\u001b[0m     @     0x7f744d7e58de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42810)\u001b[0m     @     0x7f744b3124f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42810)\u001b[0m     @     0x7f74513bd79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42810)\u001b[0m     @     0x560193ad7fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42810)\u001b[0m     @     0x560193a32b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42810)\u001b[0m     @     0x560193abdbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42810)\u001b[0m     @     0x560193abea20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42810)\u001b[0m     @     0x560193a32bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42810)\u001b[0m     @     0x560193abdbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42810)\u001b[0m     @     0x560193abe643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42810)\u001b[0m     @     0x560193a33689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42810)\u001b[0m     @     0x560193abdbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42810)\u001b[0m     @     0x560193abe643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42810)\u001b[0m     @     0x560193a33689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42810)\u001b[0m     @     0x560193abdbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42810)\u001b[0m     @     0x560193abe643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42810)\u001b[0m     @     0x560193a33689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42810)\u001b[0m     @     0x560193abdbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42810)\u001b[0m     @     0x560193abe643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42810)\u001b[0m     @     0x560193a33689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42784)\u001b[0m     @     0x7f0b71c245a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42784)\u001b[0m     @     0x7f0b7230f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42784)\u001b[0m     @     0x7f0b747e28de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42784)\u001b[0m     @     0x7f0b7230f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42784)\u001b[0m     @     0x7f0b783ba79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42784)\u001b[0m     @     0x55a196e08fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42784)\u001b[0m     @     0x55a196d63b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42784)\u001b[0m     @     0x55a196deebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42784)\u001b[0m     @     0x55a196defa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42784)\u001b[0m     @     0x55a196d63bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42784)\u001b[0m     @     0x55a196deebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42784)\u001b[0m     @     0x55a196def643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42784)\u001b[0m     @     0x55a196d64689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42784)\u001b[0m     @     0x55a196deebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42784)\u001b[0m     @     0x55a196def643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42784)\u001b[0m     @     0x55a196d64689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42784)\u001b[0m     @     0x55a196deebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42784)\u001b[0m     @     0x55a196def643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42784)\u001b[0m     @     0x55a196d64689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42784)\u001b[0m     @     0x55a196deebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42784)\u001b[0m     @     0x55a196def643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42784)\u001b[0m     @     0x55a196d64689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42788)\u001b[0m     @     0x7f51ceaf55a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42788)\u001b[0m     @     0x7f51cf1e04f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42788)\u001b[0m     @     0x7f51d16b38de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42788)\u001b[0m     @     0x7f51cf1e04f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42788)\u001b[0m     @     0x7f51d528b79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42788)\u001b[0m     @     0x561218f70fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42788)\u001b[0m     @     0x561218ecbb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42788)\u001b[0m     @     0x561218f56baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42788)\u001b[0m     @     0x561218f57a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42788)\u001b[0m     @     0x561218ecbbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42788)\u001b[0m     @     0x561218f56baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42788)\u001b[0m     @     0x561218f57643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42788)\u001b[0m     @     0x561218ecc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42788)\u001b[0m     @     0x561218f56baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42788)\u001b[0m     @     0x561218f57643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42788)\u001b[0m     @     0x561218ecc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42788)\u001b[0m     @     0x561218f56baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42788)\u001b[0m     @     0x561218f57643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42788)\u001b[0m     @     0x561218ecc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42788)\u001b[0m     @     0x561218f56baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42788)\u001b[0m     @     0x561218f57643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42788)\u001b[0m     @     0x561218ecc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42793)\u001b[0m     @     0x7fa03a34bf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42793)\u001b[0m     @     0x7fa039a767db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42793)\u001b[0m     @     0x7fa039a798f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42793)\u001b[0m     @     0x7fa039a79ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42793)\u001b[0m     @     0x7fa039a79d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42793)\u001b[0m     @     0x7fa03a35cb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42776)\u001b[0m     @     0x7f08ff7da8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42776)\u001b[0m     @     0x7f08ff7daad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42776)\u001b[0m     @     0x7f08ff7dad91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42776)\u001b[0m     @     0x7f09000bdb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42776)\u001b[0m     @     0x7f09000e0c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42776)\u001b[0m     @     0x7f08ff582a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42776)\u001b[0m     @     0x7f08ff580388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42696)\u001b[0m     @     0x7ef1bb74aad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42696)\u001b[0m     @     0x7ef1bb74ad91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42696)\u001b[0m     @     0x7ef1bc02db22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42696)\u001b[0m     @     0x7ef1bc050c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42696)\u001b[0m     @     0x7ef1bb4f2a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42696)\u001b[0m     @     0x7ef1bb4f0388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42696)\u001b[0m     @     0x7ef1bb4f25a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42777)\u001b[0m     @     0x7ed0e45d2ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42777)\u001b[0m     @     0x7ed0e45d2d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42777)\u001b[0m     @     0x7ed0e4eb5b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42777)\u001b[0m     @     0x7ed0e4ed8c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42777)\u001b[0m     @     0x7ed0e437aa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42777)\u001b[0m     @     0x7ed0e4378388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42777)\u001b[0m     @     0x7ed0e437a5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42770)\u001b[0m     @     0x7f5868c11d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42770)\u001b[0m     @     0x7f58694f4b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42770)\u001b[0m     @     0x7f5869517c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42770)\u001b[0m     @     0x7f58689b9a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42770)\u001b[0m     @     0x7f58689b7388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42770)\u001b[0m     @     0x7f58689b95a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42691)\u001b[0m     @     0x7f5851138d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42691)\u001b[0m     @     0x7f5851a1bb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42691)\u001b[0m     @     0x7f5851a3ec1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42691)\u001b[0m     @     0x7f5850ee0a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42691)\u001b[0m     @     0x7f5850ede388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42691)\u001b[0m     @     0x7f5850ee05a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42713)\u001b[0m     @     0x7f999651ed91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42713)\u001b[0m     @     0x7f9996e01b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42713)\u001b[0m     @     0x7f9996e24c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42713)\u001b[0m     @     0x7f99962c6a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42713)\u001b[0m     @     0x7f99962c4388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42779)\u001b[0m     @     0x7f12497ce4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42779)\u001b[0m     @     0x7f124f87979f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42779)\u001b[0m     @     0x5632ca4c4fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42779)\u001b[0m     @     0x5632ca41fb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42779)\u001b[0m     @     0x5632ca4aabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42779)\u001b[0m     @     0x5632ca4aba20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42779)\u001b[0m     @     0x5632ca41fbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42779)\u001b[0m     @     0x5632ca4aabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42779)\u001b[0m     @     0x5632ca4ab643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42779)\u001b[0m     @     0x5632ca420689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42779)\u001b[0m     @     0x5632ca4aabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42779)\u001b[0m     @     0x5632ca4ab643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42779)\u001b[0m     @     0x5632ca420689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42779)\u001b[0m     @     0x5632ca4aabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42779)\u001b[0m     @     0x5632ca4ab643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42779)\u001b[0m     @     0x5632ca420689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42779)\u001b[0m     @     0x5632ca4aabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42779)\u001b[0m     @     0x5632ca4ab643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42779)\u001b[0m     @     0x5632ca420689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42746)\u001b[0m     @     0x7f58f19e54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42746)\u001b[0m     @     0x7f58f3eb88de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42746)\u001b[0m     @     0x7f58f19e54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42746)\u001b[0m     @     0x7f58f7a9079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42746)\u001b[0m     @     0x562283ec3fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42746)\u001b[0m     @     0x562283e1eb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42746)\u001b[0m     @     0x562283ea9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42746)\u001b[0m     @     0x562283eaaa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42746)\u001b[0m     @     0x562283e1ebfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42746)\u001b[0m     @     0x562283ea9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42746)\u001b[0m     @     0x562283eaa643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42746)\u001b[0m     @     0x562283e1f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42746)\u001b[0m     @     0x562283ea9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42746)\u001b[0m     @     0x562283eaa643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42746)\u001b[0m     @     0x562283e1f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42746)\u001b[0m     @     0x562283ea9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42746)\u001b[0m     @     0x562283eaa643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42746)\u001b[0m     @     0x562283e1f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42746)\u001b[0m     @     0x562283ea9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42746)\u001b[0m     @     0x562283eaa643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42746)\u001b[0m     @     0x562283e1f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42731)\u001b[0m     @     0x7f578e398d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42731)\u001b[0m     @     0x7f578ec7bb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42731)\u001b[0m     @     0x7f578ec9ec1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42731)\u001b[0m     @     0x7f578e140a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42731)\u001b[0m     @     0x7f578e13e388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42772)\u001b[0m     @     0x7f09c637c4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42772)\u001b[0m     @     0x7f09c884f8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42772)\u001b[0m     @     0x7f09c637c4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42772)\u001b[0m     @     0x7f09cc42779f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42772)\u001b[0m     @     0x55a60c269fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42772)\u001b[0m     @     0x55a60c1c4b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42772)\u001b[0m     @     0x55a60c24fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42772)\u001b[0m     @     0x55a60c250a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42772)\u001b[0m     @     0x55a60c1c4bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42772)\u001b[0m     @     0x55a60c24fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42772)\u001b[0m     @     0x55a60c250643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42772)\u001b[0m     @     0x55a60c1c5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42772)\u001b[0m     @     0x55a60c24fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42772)\u001b[0m     @     0x55a60c250643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42772)\u001b[0m     @     0x55a60c1c5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42772)\u001b[0m     @     0x55a60c24fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42772)\u001b[0m     @     0x55a60c250643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42772)\u001b[0m     @     0x55a60c1c5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42772)\u001b[0m     @     0x55a60c24fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42772)\u001b[0m     @     0x55a60c250643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42772)\u001b[0m     @     0x55a60c1c5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42711)\u001b[0m     @     0x7f790d9e7d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42711)\u001b[0m     @     0x7f790e2cab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42711)\u001b[0m     @     0x7f790e2edc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42711)\u001b[0m     @     0x7f790d78fa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42711)\u001b[0m     @     0x7f790d78d388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42812)\u001b[0m     @     0x7efe8fbdd4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42812)\u001b[0m     @     0x7efe95c8879f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42812)\u001b[0m     @     0x55f98c63dfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42812)\u001b[0m     @     0x55f98c598b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42812)\u001b[0m     @     0x55f98c623baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42812)\u001b[0m     @     0x55f98c624a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42812)\u001b[0m     @     0x55f98c598bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42812)\u001b[0m     @     0x55f98c623baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42812)\u001b[0m     @     0x55f98c624643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42812)\u001b[0m     @     0x55f98c599689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42812)\u001b[0m     @     0x55f98c623baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42812)\u001b[0m     @     0x55f98c624643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42812)\u001b[0m     @     0x55f98c599689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42812)\u001b[0m     @     0x55f98c623baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42812)\u001b[0m     @     0x55f98c624643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42812)\u001b[0m     @     0x55f98c599689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42812)\u001b[0m     @     0x55f98c623baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42812)\u001b[0m     @     0x55f98c624643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42812)\u001b[0m     @     0x55f98c599689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42800)\u001b[0m     @     0x7f9b40a654f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42800)\u001b[0m     @     0x7f9b46b1079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42800)\u001b[0m     @     0x563c79df6fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42800)\u001b[0m     @     0x563c79d51b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42800)\u001b[0m     @     0x563c79ddcbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42800)\u001b[0m     @     0x563c79ddda20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42800)\u001b[0m     @     0x563c79d51bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42800)\u001b[0m     @     0x563c79ddcbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42800)\u001b[0m     @     0x563c79ddd643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42800)\u001b[0m     @     0x563c79d52689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42800)\u001b[0m     @     0x563c79ddcbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42800)\u001b[0m     @     0x563c79ddd643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42800)\u001b[0m     @     0x563c79d52689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42800)\u001b[0m     @     0x563c79ddcbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42800)\u001b[0m     @     0x563c79ddd643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42800)\u001b[0m     @     0x563c79d52689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42800)\u001b[0m     @     0x563c79ddcbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42800)\u001b[0m     @     0x563c79ddd643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42800)\u001b[0m     @     0x563c79d52689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42728)\u001b[0m     @     0x7efb1fdefb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42728)\u001b[0m     @     0x7efb1fe12c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42728)\u001b[0m     @     0x7efb1f2b4a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42728)\u001b[0m     @     0x7efb1f2b2388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42728)\u001b[0m     @     0x7efb1f2b45a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42705)\u001b[0m     @     0x7ee16834d8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42705)\u001b[0m     @     0x7ee165e7a4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42705)\u001b[0m     @     0x7ee16bf2579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42705)\u001b[0m     @     0x5570baab9fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42705)\u001b[0m     @     0x5570baa14b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42705)\u001b[0m     @     0x5570baa9fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42705)\u001b[0m     @     0x5570baaa0a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42705)\u001b[0m     @     0x5570baa14bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42705)\u001b[0m     @     0x5570baa9fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42705)\u001b[0m     @     0x5570baaa0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42705)\u001b[0m     @     0x5570baa15689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42705)\u001b[0m     @     0x5570baa9fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42705)\u001b[0m     @     0x5570baaa0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42705)\u001b[0m     @     0x5570baa15689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42705)\u001b[0m     @     0x5570baa9fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42705)\u001b[0m     @     0x5570baaa0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42705)\u001b[0m     @     0x5570baa15689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42705)\u001b[0m     @     0x5570baa9fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42705)\u001b[0m     @     0x5570baaa0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42705)\u001b[0m     @     0x5570baa15689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42716)\u001b[0m     @     0x7f9f6dc1eb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42716)\u001b[0m     @     0x7f9f6dc41c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42716)\u001b[0m     @     0x7f9f6d0e3a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42716)\u001b[0m     @     0x7f9f6d0e1388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42716)\u001b[0m     @     0x7f9f6d0e35a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42787)\u001b[0m     @     0x55dbe488db08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42787)\u001b[0m     @     0x55dbe4918baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42787)\u001b[0m     @     0x55dbe4919a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42787)\u001b[0m     @     0x55dbe488dbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42787)\u001b[0m     @     0x55dbe4918baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42787)\u001b[0m     @     0x55dbe4919643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42787)\u001b[0m     @     0x55dbe488e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42787)\u001b[0m     @     0x55dbe4918baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42787)\u001b[0m     @     0x55dbe4919643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42787)\u001b[0m     @     0x55dbe488e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42787)\u001b[0m     @     0x55dbe4918baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42787)\u001b[0m     @     0x55dbe4919643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42787)\u001b[0m     @     0x55dbe488e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42787)\u001b[0m     @     0x55dbe4918baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42787)\u001b[0m     @     0x55dbe4919643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42787)\u001b[0m     @     0x55dbe488e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42781)\u001b[0m     @     0x7f74caf0b8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42781)\u001b[0m     @     0x7f74c8a384f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42781)\u001b[0m     @     0x7f74ceae379f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42781)\u001b[0m     @     0x556ec4d2dfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42781)\u001b[0m     @     0x556ec4c88b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42781)\u001b[0m     @     0x556ec4d13baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42781)\u001b[0m     @     0x556ec4d14a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42781)\u001b[0m     @     0x556ec4c88bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42781)\u001b[0m     @     0x556ec4d13baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42781)\u001b[0m     @     0x556ec4d14643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42781)\u001b[0m     @     0x556ec4c89689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42781)\u001b[0m     @     0x556ec4d13baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42781)\u001b[0m     @     0x556ec4d14643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42781)\u001b[0m     @     0x556ec4c89689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42781)\u001b[0m     @     0x556ec4d13baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42781)\u001b[0m     @     0x556ec4d14643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42781)\u001b[0m     @     0x556ec4c89689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42781)\u001b[0m     @     0x556ec4d13baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42781)\u001b[0m     @     0x556ec4d14643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42781)\u001b[0m     @     0x556ec4c89689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42762)\u001b[0m     @     0x7fa81b9cc4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42762)\u001b[0m     @     0x7fa821a7779f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42762)\u001b[0m     @     0x5612e7acdfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42762)\u001b[0m     @     0x5612e7a28b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42762)\u001b[0m     @     0x5612e7ab3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42762)\u001b[0m     @     0x5612e7ab4a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42762)\u001b[0m     @     0x5612e7a28bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42762)\u001b[0m     @     0x5612e7ab3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42762)\u001b[0m     @     0x5612e7ab4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42762)\u001b[0m     @     0x5612e7a29689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42762)\u001b[0m     @     0x5612e7ab3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42762)\u001b[0m     @     0x5612e7ab4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42762)\u001b[0m     @     0x5612e7a29689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42762)\u001b[0m     @     0x5612e7ab3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42762)\u001b[0m     @     0x5612e7ab4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42762)\u001b[0m     @     0x5612e7a29689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42762)\u001b[0m     @     0x5612e7ab3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42762)\u001b[0m     @     0x5612e7ab4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42762)\u001b[0m     @     0x5612e7a29689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42811)\u001b[0m     @     0x7f4c334f1d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42811)\u001b[0m     @     0x7f4c33dd4b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42811)\u001b[0m     @     0x7f4c33df7c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42811)\u001b[0m     @     0x7f4c33299a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42811)\u001b[0m     @     0x7f4c33297388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42778)\u001b[0m     @     0x7f03740e18de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42778)\u001b[0m     @     0x7f0371c0e4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42778)\u001b[0m     @     0x7f0377cb979f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42778)\u001b[0m     @     0x56110e18bfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42778)\u001b[0m     @     0x56110e0e6b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42778)\u001b[0m     @     0x56110e171baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42778)\u001b[0m     @     0x56110e172a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42778)\u001b[0m     @     0x56110e0e6bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42778)\u001b[0m     @     0x56110e171baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42778)\u001b[0m     @     0x56110e172643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42778)\u001b[0m     @     0x56110e0e7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42778)\u001b[0m     @     0x56110e171baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42778)\u001b[0m     @     0x56110e172643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42778)\u001b[0m     @     0x56110e0e7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42778)\u001b[0m     @     0x56110e171baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42778)\u001b[0m     @     0x56110e172643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42778)\u001b[0m     @     0x56110e0e7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42778)\u001b[0m     @     0x56110e171baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42778)\u001b[0m     @     0x56110e172643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42778)\u001b[0m     @     0x56110e0e7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42790)\u001b[0m     @     0x7f15092264f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42790)\u001b[0m     @     0x7f150f2d179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42790)\u001b[0m     @     0x55ebd3fd2fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42790)\u001b[0m     @     0x55ebd3f2db08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42790)\u001b[0m     @     0x55ebd3fb8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42790)\u001b[0m     @     0x55ebd3fb9a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42790)\u001b[0m     @     0x55ebd3f2dbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42790)\u001b[0m     @     0x55ebd3fb8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42790)\u001b[0m     @     0x55ebd3fb9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42790)\u001b[0m     @     0x55ebd3f2e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42790)\u001b[0m     @     0x55ebd3fb8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42790)\u001b[0m     @     0x55ebd3fb9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42790)\u001b[0m     @     0x55ebd3f2e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42790)\u001b[0m     @     0x55ebd3fb8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42790)\u001b[0m     @     0x55ebd3fb9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42790)\u001b[0m     @     0x55ebd3f2e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42790)\u001b[0m     @     0x55ebd3fb8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42790)\u001b[0m     @     0x55ebd3fb9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42790)\u001b[0m     @     0x55ebd3f2e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42819)\u001b[0m     @     0x7ee17170fa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42819)\u001b[0m     @     0x7ee17170d388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42819)\u001b[0m     @     0x7ee17170f5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42819)\u001b[0m     @     0x7ee171dfa4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42706)\u001b[0m     @     0x7f3c24a654f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42706)\u001b[0m     @     0x7f3c2ab1079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42706)\u001b[0m     @     0x557643fcafd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42706)\u001b[0m     @     0x557643f25b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42706)\u001b[0m     @     0x557643fb0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42706)\u001b[0m     @     0x557643fb1a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42706)\u001b[0m     @     0x557643f25bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42706)\u001b[0m     @     0x557643fb0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42706)\u001b[0m     @     0x557643fb1643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42706)\u001b[0m     @     0x557643f26689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42706)\u001b[0m     @     0x557643fb0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42706)\u001b[0m     @     0x557643fb1643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42706)\u001b[0m     @     0x557643f26689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42706)\u001b[0m     @     0x557643fb0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42706)\u001b[0m     @     0x557643fb1643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42706)\u001b[0m     @     0x557643f26689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42706)\u001b[0m     @     0x557643fb0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42706)\u001b[0m     @     0x557643fb1643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42706)\u001b[0m     @     0x557643f26689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42704)\u001b[0m     @     0x7f580f00cd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42704)\u001b[0m     @     0x7f580f8efb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42704)\u001b[0m     @     0x7f580f912c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42704)\u001b[0m     @     0x7f580edb4a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42704)\u001b[0m     @     0x7f580edb2388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42704)\u001b[0m     @     0x7f580edb45a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42708)\u001b[0m     @     0x7f2ba0e22d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42708)\u001b[0m     @     0x7f2ba1705b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42708)\u001b[0m     @     0x7f2ba1728c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42708)\u001b[0m     @     0x7f2ba0bcaa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42708)\u001b[0m     @     0x7f2ba0bc8388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42708)\u001b[0m     @     0x7f2ba0bca5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42763)\u001b[0m     @     0x7f82568b98de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42763)\u001b[0m     @     0x7f82543e64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42763)\u001b[0m     @     0x7f825a49179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42763)\u001b[0m     @     0x556015b71fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42763)\u001b[0m     @     0x556015accb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42763)\u001b[0m     @     0x556015b57baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42763)\u001b[0m     @     0x556015b58a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42763)\u001b[0m     @     0x556015accbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42763)\u001b[0m     @     0x556015b57baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42763)\u001b[0m     @     0x556015b58643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42763)\u001b[0m     @     0x556015acd689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42763)\u001b[0m     @     0x556015b57baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42763)\u001b[0m     @     0x556015b58643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42763)\u001b[0m     @     0x556015acd689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42763)\u001b[0m     @     0x556015b57baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42763)\u001b[0m     @     0x556015b58643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42763)\u001b[0m     @     0x556015acd689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42763)\u001b[0m     @     0x556015b57baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42763)\u001b[0m     @     0x556015b58643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42763)\u001b[0m     @     0x556015acd689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42758)\u001b[0m     @     0x7f3404922b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42758)\u001b[0m     @     0x7f3404945c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42758)\u001b[0m     @     0x7f3403de7a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42758)\u001b[0m     @     0x7f3403de5388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42764)\u001b[0m     @     0x7f72ace784f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42764)\u001b[0m     @     0x7f72b2f2379f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42764)\u001b[0m     @     0x557dffae1fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42764)\u001b[0m     @     0x557dffa3cb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42764)\u001b[0m     @     0x557dffac7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42764)\u001b[0m     @     0x557dffac8a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42764)\u001b[0m     @     0x557dffa3cbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42764)\u001b[0m     @     0x557dffac7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42764)\u001b[0m     @     0x557dffac8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42764)\u001b[0m     @     0x557dffa3d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42764)\u001b[0m     @     0x557dffac7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42764)\u001b[0m     @     0x557dffac8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42764)\u001b[0m     @     0x557dffa3d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42764)\u001b[0m     @     0x557dffac7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42764)\u001b[0m     @     0x557dffac8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42764)\u001b[0m     @     0x557dffa3d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42764)\u001b[0m     @     0x557dffac7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42764)\u001b[0m     @     0x557dffac8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42764)\u001b[0m     @     0x557dffa3d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42692)\u001b[0m     @     0x7f9f92b98d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42692)\u001b[0m     @     0x7f9f9347bb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42692)\u001b[0m     @     0x7f9f9349ec1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42692)\u001b[0m     @     0x7f9f92940a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42692)\u001b[0m     @     0x7f9f9293e388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42748)\u001b[0m     @     0x7f224e0acd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42748)\u001b[0m     @     0x7f224e98fb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42748)\u001b[0m     @     0x7f224e9b2c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42748)\u001b[0m     @     0x7f224de54a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42748)\u001b[0m     @     0x7f224de52388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42709)\u001b[0m     @     0x7f676975ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42709)\u001b[0m     @     0x7f676977dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42709)\u001b[0m     @     0x7f6768c1fa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42709)\u001b[0m     @     0x7f6768c1d388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42709)\u001b[0m     @     0x7f6768c1f5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42702)\u001b[0m     @     0x7edfd42e8a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42702)\u001b[0m     @     0x7edfd42e6388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42702)\u001b[0m     @     0x7edfd42e85a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42701)\u001b[0m     @     0x7eefd7b11d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42701)\u001b[0m     @     0x7eefd83f4b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42701)\u001b[0m     @     0x7eefd8417c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42701)\u001b[0m     @     0x7eefd78b9a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42701)\u001b[0m     @     0x7eefd78b7388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42721)\u001b[0m     @     0x7f10f1c27d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42721)\u001b[0m     @     0x7f10f250ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42721)\u001b[0m     @     0x7f10f252dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42721)\u001b[0m     @     0x7f10f19cfa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42721)\u001b[0m     @     0x7f10f19cd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42721)\u001b[0m     @     0x7f10f19cf5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42783)\u001b[0m     @     0x7eee47b11ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42783)\u001b[0m     @     0x7eee47b11d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42783)\u001b[0m     @     0x7eee483f4b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42753)\u001b[0m     @     0x7f74ae14fd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42753)\u001b[0m     @     0x7f74aea32b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42753)\u001b[0m     @     0x7f74aea55c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42753)\u001b[0m     @     0x7f74adef7a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42753)\u001b[0m     @     0x7f74adef5388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42753)\u001b[0m     @     0x7f74adef75a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42751)\u001b[0m     @     0x7f3d4bcf1b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42751)\u001b[0m     @     0x7f3d4bd14c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42751)\u001b[0m     @     0x7f3d4b1b6a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42751)\u001b[0m     @     0x7f3d4b1b4388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42751)\u001b[0m     @     0x7f3d4b1b65a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42751)\u001b[0m     @     0x7f3d4b8a14f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42751)\u001b[0m     @     0x7f3d4dd748de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42773)\u001b[0m     @     0x7fa31751e8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42773)\u001b[0m     @     0x7fa31751ead3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42773)\u001b[0m     @     0x7fa31751ed91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42773)\u001b[0m     @     0x7fa317e01b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42773)\u001b[0m     @     0x7fa317e24c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42760)\u001b[0m     @     0x7f1832101c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42760)\u001b[0m     @     0x7f18315a3a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42760)\u001b[0m     @     0x7f18315a1388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42760)\u001b[0m     @     0x7f18315a35a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42760)\u001b[0m     @     0x7f1831c8e4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42698)\u001b[0m     @     0x7f5cdaf24b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42698)\u001b[0m     @     0x7f5cdaf47c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42698)\u001b[0m     @     0x7f5cda3e9a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42698)\u001b[0m     @     0x7f5cda3e7388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42698)\u001b[0m     @     0x7f5cda3e95a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42698)\u001b[0m     @     0x7f5cdaad44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42756)\u001b[0m     @     0x7f060de38d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42756)\u001b[0m     @     0x7f060e71bb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42756)\u001b[0m     @     0x7f060e73ec1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42756)\u001b[0m     @     0x7f060dbe0a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42756)\u001b[0m     @     0x7f060dbde388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42756)\u001b[0m     @     0x7f060dbe05a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42712)\u001b[0m     @     0x7f2d2fe1cb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42712)\u001b[0m     @     0x7f2d2fe3fc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42712)\u001b[0m     @     0x7f2d2f2e1a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42712)\u001b[0m     @     0x7f2d2f2df388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42712)\u001b[0m     @     0x7f2d2f2e15a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42712)\u001b[0m     @     0x7f2d2f9cc4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42694)\u001b[0m     @     0x7fa294bb9c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42694)\u001b[0m     @     0x7fa29405ba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42694)\u001b[0m     @     0x7fa294059388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42694)\u001b[0m     @     0x7fa29405b5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42694)\u001b[0m     @     0x7fa2947464f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42710)\u001b[0m     @     0x7f9390c85b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42710)\u001b[0m     @     0x7f9390ca8c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42710)\u001b[0m     @     0x7f939014aa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42710)\u001b[0m     @     0x7f9390148388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42710)\u001b[0m     @     0x7f939014a5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42710)\u001b[0m     @     0x7f93908354f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42714)\u001b[0m     @     0x7ee3c2a88a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42714)\u001b[0m     @     0x7ee3c2a86388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42714)\u001b[0m     @     0x7ee3c2a885a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42714)\u001b[0m     @     0x7ee3c31734f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42714)\u001b[0m     @     0x7ee3c56468de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42754)\u001b[0m     @     0x7ef239bb1388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42754)\u001b[0m     @     0x7ef239bb35a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42754)\u001b[0m     @     0x7ef23a29e4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42754)\u001b[0m     @     0x7ef23c7718de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42754)\u001b[0m     @     0x7ef23a29e4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42695)\u001b[0m     @     0x7f1926c49c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42695)\u001b[0m     @     0x7f19260eba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42695)\u001b[0m     @     0x7f19260e9388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42695)\u001b[0m     @     0x7f19260eb5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42695)\u001b[0m     @     0x7f19267d64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42744)\u001b[0m     @     0x7f5f4c1faa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42744)\u001b[0m     @     0x7f5f4c1f8388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42744)\u001b[0m     @     0x7f5f4c1fa5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42744)\u001b[0m     @     0x7f5f4c8e54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42730)\u001b[0m     @     0x7f5978263f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42730)\u001b[0m     @     0x7f597798e7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42718)\u001b[0m     @     0x7fb440d24f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=42718)\u001b[0m     @     0x7fb44044f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42747)\u001b[0m     @     0x7ececcccfa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42747)\u001b[0m     @     0x7ececcccd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42747)\u001b[0m     @     0x7ececcccf5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42747)\u001b[0m     @     0x7ececd3ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42807)\u001b[0m     @     0x7f9f37a0ca93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42807)\u001b[0m     @     0x7f9f37a0a388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42807)\u001b[0m     @     0x7f9f37a0c5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42807)\u001b[0m     @     0x7f9f380f74f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42767)\u001b[0m     @     0x7ee7cc67dd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42767)\u001b[0m     @     0x7ee7ccf60b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42767)\u001b[0m     @     0x7ee7ccf83c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42767)\u001b[0m     @     0x7ee7cc425a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42767)\u001b[0m     @     0x7ee7cc423388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42803)\u001b[0m     @     0x7f2c3a5faa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42803)\u001b[0m     @     0x7f2c3a5f8388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42803)\u001b[0m     @     0x7f2c3a5fa5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42803)\u001b[0m     @     0x7f2c3ace54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42715)\u001b[0m     @     0x7f2a28db5d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42715)\u001b[0m     @     0x7f2a29698b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42715)\u001b[0m     @     0x7f2a296bbc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42715)\u001b[0m     @     0x7f2a28b5da93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42715)\u001b[0m     @     0x7f2a28b5b388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42697)\u001b[0m     @     0x7f78e61d28f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42780)\u001b[0m     @     0x7ed37a9578f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42780)\u001b[0m     @     0x7ed37a957ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42726)\u001b[0m     @     0x7f515a63e7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=42816)\u001b[0m     @     0x7f47c9c915a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42816)\u001b[0m     @     0x7f47ca37c4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42816)\u001b[0m     @     0x7f47cc84f8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42700)\u001b[0m     @     0x7f054fbe25a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42700)\u001b[0m     @     0x7f05502cd4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42700)\u001b[0m     @     0x7f05527a08de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42700)\u001b[0m     @     0x7f05502cd4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42693)\u001b[0m     @     0x7f77daa485a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42693)\u001b[0m     @     0x7f77db1334f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42693)\u001b[0m     @     0x7f77dd6068de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42699)\u001b[0m     @     0x7f5f794db5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42699)\u001b[0m     @     0x7f5f79bc64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42699)\u001b[0m     @     0x7f5f7c0998de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42699)\u001b[0m     @     0x7f5f79bc64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42699)\u001b[0m     @     0x7f5f7fc7179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42699)\u001b[0m     @     0x55e81a0acfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42699)\u001b[0m     @     0x55e81a007b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42699)\u001b[0m     @     0x55e81a092baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42699)\u001b[0m     @     0x55e81a093a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42699)\u001b[0m     @     0x55e81a007bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42699)\u001b[0m     @     0x55e81a092baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42699)\u001b[0m     @     0x55e81a093643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42699)\u001b[0m     @     0x55e81a008689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42771)\u001b[0m     @     0x563815466689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42771)\u001b[0m     @     0x5638154f0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42771)\u001b[0m     @     0x5638154f1643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42771)\u001b[0m     @     0x563815466689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42793)\u001b[0m     @     0x7fa03a37fc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42793)\u001b[0m     @     0x7fa039821a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42793)\u001b[0m     @     0x7fa03981f388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42793)\u001b[0m     @     0x7fa0398215a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42776)\u001b[0m     @     0x7f08ff5825a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42776)\u001b[0m     @     0x7f08ffc6d4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42776)\u001b[0m     @     0x7f09021408de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42776)\u001b[0m     @     0x7f08ffc6d4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42696)\u001b[0m     @     0x7ef1bbbdd4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42696)\u001b[0m     @     0x7ef1be0b08de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42696)\u001b[0m     @     0x7ef1bbbdd4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42696)\u001b[0m     @     0x7ef1c1c8879f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42696)\u001b[0m     @     0x560aef712fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42696)\u001b[0m     @     0x560aef66db08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42696)\u001b[0m     @     0x560aef6f8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42696)\u001b[0m     @     0x560aef6f9a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42696)\u001b[0m     @     0x560aef66dbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42696)\u001b[0m     @     0x560aef6f8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42696)\u001b[0m     @     0x560aef6f9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42696)\u001b[0m     @     0x560aef66e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42696)\u001b[0m     @     0x560aef6f8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42696)\u001b[0m     @     0x560aef6f9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42696)\u001b[0m     @     0x560aef66e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42696)\u001b[0m     @     0x560aef6f8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42696)\u001b[0m     @     0x560aef6f9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42696)\u001b[0m     @     0x560aef66e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42696)\u001b[0m     @     0x560aef6f8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42696)\u001b[0m     @     0x560aef6f9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42696)\u001b[0m     @     0x560aef66e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42777)\u001b[0m     @     0x7ed0e4a654f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42777)\u001b[0m     @     0x7ed0e6f388de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42777)\u001b[0m     @     0x7ed0e4a654f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42777)\u001b[0m     @     0x7ed0eab1079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42777)\u001b[0m     @     0x55ffc8e9cfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42777)\u001b[0m     @     0x55ffc8df7b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42777)\u001b[0m     @     0x55ffc8e82baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42777)\u001b[0m     @     0x55ffc8e83a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42777)\u001b[0m     @     0x55ffc8df7bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42777)\u001b[0m     @     0x55ffc8e82baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42777)\u001b[0m     @     0x55ffc8e83643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42777)\u001b[0m     @     0x55ffc8df8689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42777)\u001b[0m     @     0x55ffc8e82baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42777)\u001b[0m     @     0x55ffc8e83643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42777)\u001b[0m     @     0x55ffc8df8689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42777)\u001b[0m     @     0x55ffc8e82baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42777)\u001b[0m     @     0x55ffc8e83643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42777)\u001b[0m     @     0x55ffc8df8689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42777)\u001b[0m     @     0x55ffc8e82baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42777)\u001b[0m     @     0x55ffc8e83643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42777)\u001b[0m     @     0x55ffc8df8689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42770)\u001b[0m     @     0x7f58690a44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42770)\u001b[0m     @     0x7f586b5778de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42770)\u001b[0m     @     0x7f58690a44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42770)\u001b[0m     @     0x7f586f14f79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42770)\u001b[0m     @     0x557a85d0bfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42770)\u001b[0m     @     0x557a85c66b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42770)\u001b[0m     @     0x557a85cf1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42770)\u001b[0m     @     0x557a85cf2a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42770)\u001b[0m     @     0x557a85c66bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42770)\u001b[0m     @     0x557a85cf1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42770)\u001b[0m     @     0x557a85cf2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42770)\u001b[0m     @     0x557a85c67689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42770)\u001b[0m     @     0x557a85cf1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42770)\u001b[0m     @     0x557a85cf2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42770)\u001b[0m     @     0x557a85c67689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42770)\u001b[0m     @     0x557a85cf1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42770)\u001b[0m     @     0x557a85cf2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42770)\u001b[0m     @     0x557a85c67689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42770)\u001b[0m     @     0x557a85cf1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42770)\u001b[0m     @     0x557a85cf2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42770)\u001b[0m     @     0x557a85c67689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42691)\u001b[0m     @     0x7f58515cb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42691)\u001b[0m     @     0x7f5853a9e8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42691)\u001b[0m     @     0x7f58515cb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42691)\u001b[0m     @     0x7f585767679f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42691)\u001b[0m     @     0x5644869a1fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42691)\u001b[0m     @     0x5644868fcb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42691)\u001b[0m     @     0x564486987baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42691)\u001b[0m     @     0x564486988a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42691)\u001b[0m     @     0x5644868fcbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42691)\u001b[0m     @     0x564486987baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42691)\u001b[0m     @     0x564486988643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42691)\u001b[0m     @     0x5644868fd689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42691)\u001b[0m     @     0x564486987baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42691)\u001b[0m     @     0x564486988643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42691)\u001b[0m     @     0x5644868fd689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42691)\u001b[0m     @     0x564486987baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42691)\u001b[0m     @     0x564486988643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42691)\u001b[0m     @     0x5644868fd689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42691)\u001b[0m     @     0x564486987baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42691)\u001b[0m     @     0x564486988643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42691)\u001b[0m     @     0x5644868fd689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42713)\u001b[0m     @     0x7f99962c65a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42713)\u001b[0m     @     0x7f99969b14f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42713)\u001b[0m     @     0x7f9998e848de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42713)\u001b[0m     @     0x7f99969b14f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42713)\u001b[0m     @     0x7f999ca5c79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42713)\u001b[0m     @     0x55f15b35bfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42713)\u001b[0m     @     0x55f15b2b6b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42713)\u001b[0m     @     0x55f15b341baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42713)\u001b[0m     @     0x55f15b342a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42713)\u001b[0m     @     0x55f15b2b6bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42713)\u001b[0m     @     0x55f15b341baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42713)\u001b[0m     @     0x55f15b342643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42713)\u001b[0m     @     0x55f15b2b7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42713)\u001b[0m     @     0x55f15b341baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42713)\u001b[0m     @     0x55f15b342643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42713)\u001b[0m     @     0x55f15b2b7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42731)\u001b[0m     @     0x7f578e1405a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42731)\u001b[0m     @     0x7f578e82b4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42731)\u001b[0m     @     0x7f5790cfe8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42731)\u001b[0m     @     0x7f578e82b4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42731)\u001b[0m     @     0x7f57948d679f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42731)\u001b[0m     @     0x55b2a5bb3fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42731)\u001b[0m     @     0x55b2a5b0eb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42731)\u001b[0m     @     0x55b2a5b99baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42731)\u001b[0m     @     0x55b2a5b9aa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42731)\u001b[0m     @     0x55b2a5b0ebfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42731)\u001b[0m     @     0x55b2a5b99baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42731)\u001b[0m     @     0x55b2a5b9a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42731)\u001b[0m     @     0x55b2a5b0f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42711)\u001b[0m     @     0x7f790d78f5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42711)\u001b[0m     @     0x7f790de7a4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42711)\u001b[0m     @     0x7f791034d8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42711)\u001b[0m     @     0x7f790de7a4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42728)\u001b[0m     @     0x7efb1f99f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42728)\u001b[0m     @     0x7efb21e728de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42728)\u001b[0m     @     0x7efb1f99f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42728)\u001b[0m     @     0x7efb25a4a79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42728)\u001b[0m     @     0x55856a327fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42728)\u001b[0m     @     0x55856a282b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42728)\u001b[0m     @     0x55856a30dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42728)\u001b[0m     @     0x55856a30ea20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42728)\u001b[0m     @     0x55856a282bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42728)\u001b[0m     @     0x55856a30dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42728)\u001b[0m     @     0x55856a30e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42728)\u001b[0m     @     0x55856a283689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42728)\u001b[0m     @     0x55856a30dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42728)\u001b[0m     @     0x55856a30e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42728)\u001b[0m     @     0x55856a283689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42728)\u001b[0m     @     0x55856a30dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42728)\u001b[0m     @     0x55856a30e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42728)\u001b[0m     @     0x55856a283689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42728)\u001b[0m     @     0x55856a30dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42728)\u001b[0m     @     0x55856a30e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42728)\u001b[0m     @     0x55856a283689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42716)\u001b[0m     @     0x7f9f6d7ce4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42716)\u001b[0m     @     0x7f9f6fca18de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42716)\u001b[0m     @     0x7f9f6d7ce4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42716)\u001b[0m     @     0x7f9f7387979f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42716)\u001b[0m     @     0x55b585c39fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42716)\u001b[0m     @     0x55b585b94b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42716)\u001b[0m     @     0x55b585c1fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42716)\u001b[0m     @     0x55b585c20a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42716)\u001b[0m     @     0x55b585b94bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42716)\u001b[0m     @     0x55b585c1fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42716)\u001b[0m     @     0x55b585c20643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42716)\u001b[0m     @     0x55b585b95689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42716)\u001b[0m     @     0x55b585c1fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42716)\u001b[0m     @     0x55b585c20643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42716)\u001b[0m     @     0x55b585b95689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42716)\u001b[0m     @     0x55b585c1fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42716)\u001b[0m     @     0x55b585c20643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42716)\u001b[0m     @     0x55b585b95689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42716)\u001b[0m     @     0x55b585c1fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42716)\u001b[0m     @     0x55b585c20643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42716)\u001b[0m     @     0x55b585b95689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42811)\u001b[0m     @     0x7f4c332995a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42811)\u001b[0m     @     0x7f4c339844f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42811)\u001b[0m     @     0x7f4c35e578de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42811)\u001b[0m     @     0x7f4c339844f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42811)\u001b[0m     @     0x7f4c39a2f79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42811)\u001b[0m     @     0x562778433fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42811)\u001b[0m     @     0x56277838eb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42811)\u001b[0m     @     0x562778419baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42811)\u001b[0m     @     0x56277841aa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42811)\u001b[0m     @     0x56277838ebfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42811)\u001b[0m     @     0x562778419baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42811)\u001b[0m     @     0x56277841a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42819)\u001b[0m     @     0x7ee1742cd8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42819)\u001b[0m     @     0x7ee171dfa4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42819)\u001b[0m     @     0x7ee177ea579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42819)\u001b[0m     @     0x562e63b5efd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42819)\u001b[0m     @     0x562e63ab9b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42819)\u001b[0m     @     0x562e63b44baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42819)\u001b[0m     @     0x562e63b45a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42819)\u001b[0m     @     0x562e63ab9bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42819)\u001b[0m     @     0x562e63b44baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42819)\u001b[0m     @     0x562e63b45643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42819)\u001b[0m     @     0x562e63aba689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42819)\u001b[0m     @     0x562e63b44baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42819)\u001b[0m     @     0x562e63b45643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42819)\u001b[0m     @     0x562e63aba689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42819)\u001b[0m     @     0x562e63b44baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42819)\u001b[0m     @     0x562e63b45643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42819)\u001b[0m     @     0x562e63aba689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42819)\u001b[0m     @     0x562e63b44baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42819)\u001b[0m     @     0x562e63b45643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42819)\u001b[0m     @     0x562e63aba689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42704)\u001b[0m     @     0x7f580f49f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42704)\u001b[0m     @     0x7f58119728de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42704)\u001b[0m     @     0x7f580f49f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42708)\u001b[0m     @     0x7f2ba12b54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42708)\u001b[0m     @     0x7f2ba37888de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42708)\u001b[0m     @     0x7f2ba12b54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42708)\u001b[0m     @     0x7f2ba736079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42708)\u001b[0m     @     0x5638955e2fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42708)\u001b[0m     @     0x56389553db08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42708)\u001b[0m     @     0x5638955c8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42708)\u001b[0m     @     0x5638955c9a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42708)\u001b[0m     @     0x56389553dbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42708)\u001b[0m     @     0x5638955c8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42708)\u001b[0m     @     0x5638955c9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42708)\u001b[0m     @     0x56389553e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42708)\u001b[0m     @     0x5638955c8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42708)\u001b[0m     @     0x5638955c9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42708)\u001b[0m     @     0x56389553e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42708)\u001b[0m     @     0x5638955c8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42708)\u001b[0m     @     0x5638955c9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42708)\u001b[0m     @     0x56389553e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42692)\u001b[0m     @     0x7f9f929405a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42692)\u001b[0m     @     0x7f9f9302b4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42692)\u001b[0m     @     0x7f9f954fe8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42692)\u001b[0m     @     0x7f9f9302b4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42748)\u001b[0m     @     0x7f224de545a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42748)\u001b[0m     @     0x7f224e53f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42748)\u001b[0m     @     0x7f2250a128de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42748)\u001b[0m     @     0x7f224e53f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42709)\u001b[0m     @     0x7f676930a4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42709)\u001b[0m     @     0x7f676b7dd8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42709)\u001b[0m     @     0x7f676930a4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42709)\u001b[0m     @     0x7f676f3b579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42709)\u001b[0m     @     0x556cb1c75fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42709)\u001b[0m     @     0x556cb1bd0b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42709)\u001b[0m     @     0x556cb1c5bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42709)\u001b[0m     @     0x556cb1c5ca20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42709)\u001b[0m     @     0x556cb1bd0bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42709)\u001b[0m     @     0x556cb1c5bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42709)\u001b[0m     @     0x556cb1c5c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42709)\u001b[0m     @     0x556cb1bd1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42709)\u001b[0m     @     0x556cb1c5bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42709)\u001b[0m     @     0x556cb1c5c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42709)\u001b[0m     @     0x556cb1bd1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42709)\u001b[0m     @     0x556cb1c5bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42709)\u001b[0m     @     0x556cb1c5c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42702)\u001b[0m     @     0x7edfd49d34f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42702)\u001b[0m     @     0x7edfd6ea68de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42702)\u001b[0m     @     0x7edfd49d34f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42702)\u001b[0m     @     0x7edfdaa7e79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42702)\u001b[0m     @     0x563b9a42afd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42702)\u001b[0m     @     0x563b9a385b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42702)\u001b[0m     @     0x563b9a410baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42702)\u001b[0m     @     0x563b9a411a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42702)\u001b[0m     @     0x563b9a385bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42702)\u001b[0m     @     0x563b9a410baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42702)\u001b[0m     @     0x563b9a411643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42702)\u001b[0m     @     0x563b9a386689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42702)\u001b[0m     @     0x563b9a410baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42702)\u001b[0m     @     0x563b9a411643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42702)\u001b[0m     @     0x563b9a386689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42702)\u001b[0m     @     0x563b9a410baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42702)\u001b[0m     @     0x563b9a411643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42702)\u001b[0m     @     0x563b9a386689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42702)\u001b[0m     @     0x563b9a410baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42702)\u001b[0m     @     0x563b9a411643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42702)\u001b[0m     @     0x563b9a386689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42701)\u001b[0m     @     0x7eefd78b95a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42701)\u001b[0m     @     0x7eefd7fa44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42701)\u001b[0m     @     0x7eefda4778de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42701)\u001b[0m     @     0x7eefd7fa44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42701)\u001b[0m     @     0x7eefde04f79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42701)\u001b[0m     @     0x556ef1955fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42701)\u001b[0m     @     0x556ef18b0b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42701)\u001b[0m     @     0x556ef193bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42701)\u001b[0m     @     0x556ef193ca20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42701)\u001b[0m     @     0x556ef18b0bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42701)\u001b[0m     @     0x556ef193bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42721)\u001b[0m     @     0x7f10f20ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42721)\u001b[0m     @     0x7f10f458d8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42783)\u001b[0m     @     0x7eee48417c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42783)\u001b[0m     @     0x7eee478b9a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42753)\u001b[0m     @     0x7f74ae5e24f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42753)\u001b[0m     @     0x7f74b0ab58de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42751)\u001b[0m     @     0x7f3d4b8a14f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42751)\u001b[0m     @     0x7f3d5194c79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42751)\u001b[0m     @     0x55b8d698bfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42751)\u001b[0m     @     0x55b8d68e6b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42751)\u001b[0m     @     0x55b8d6971baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42751)\u001b[0m     @     0x55b8d6972a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42751)\u001b[0m     @     0x55b8d68e6bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42751)\u001b[0m     @     0x55b8d6971baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42751)\u001b[0m     @     0x55b8d6972643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42751)\u001b[0m     @     0x55b8d68e7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42751)\u001b[0m     @     0x55b8d6971baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42751)\u001b[0m     @     0x55b8d6972643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42751)\u001b[0m     @     0x55b8d68e7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42751)\u001b[0m     @     0x55b8d6971baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42751)\u001b[0m     @     0x55b8d6972643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42751)\u001b[0m     @     0x55b8d68e7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42751)\u001b[0m     @     0x55b8d6971baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42751)\u001b[0m     @     0x55b8d6972643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42751)\u001b[0m     @     0x55b8d68e7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42773)\u001b[0m     @     0x7fa3172c6a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42773)\u001b[0m     @     0x7fa3172c4388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42773)\u001b[0m     @     0x7fa3172c65a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42760)\u001b[0m     @     0x7f18341618de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42760)\u001b[0m     @     0x7f1831c8e4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42760)\u001b[0m     @     0x7f1837d3979f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42760)\u001b[0m     @     0x5558cdc01fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42760)\u001b[0m     @     0x5558cdb5cb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42760)\u001b[0m     @     0x5558cdbe7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42760)\u001b[0m     @     0x5558cdbe8a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42760)\u001b[0m     @     0x5558cdb5cbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42760)\u001b[0m     @     0x5558cdbe7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42760)\u001b[0m     @     0x5558cdbe8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42760)\u001b[0m     @     0x5558cdb5d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42760)\u001b[0m     @     0x5558cdbe7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42760)\u001b[0m     @     0x5558cdbe8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42760)\u001b[0m     @     0x5558cdb5d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42760)\u001b[0m     @     0x5558cdbe7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42760)\u001b[0m     @     0x5558cdbe8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42760)\u001b[0m     @     0x5558cdb5d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42760)\u001b[0m     @     0x5558cdbe7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42760)\u001b[0m     @     0x5558cdbe8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42760)\u001b[0m     @     0x5558cdb5d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42698)\u001b[0m     @     0x7f5cdcfa78de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42698)\u001b[0m     @     0x7f5cdaad44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42698)\u001b[0m     @     0x7f5ce0b7f79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42698)\u001b[0m     @     0x5625479f6fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42698)\u001b[0m     @     0x562547951b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42698)\u001b[0m     @     0x5625479dcbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42698)\u001b[0m     @     0x5625479dda20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42698)\u001b[0m     @     0x562547951bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42698)\u001b[0m     @     0x5625479dcbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42698)\u001b[0m     @     0x5625479dd643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42698)\u001b[0m     @     0x562547952689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42698)\u001b[0m     @     0x5625479dcbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42698)\u001b[0m     @     0x5625479dd643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42698)\u001b[0m     @     0x562547952689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42698)\u001b[0m     @     0x5625479dcbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42698)\u001b[0m     @     0x5625479dd643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42698)\u001b[0m     @     0x562547952689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42698)\u001b[0m     @     0x5625479dcbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42698)\u001b[0m     @     0x5625479dd643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42698)\u001b[0m     @     0x562547952689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42756)\u001b[0m     @     0x7f060e2cb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42756)\u001b[0m     @     0x7f061079e8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42756)\u001b[0m     @     0x7f060e2cb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42756)\u001b[0m     @     0x7f061437679f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42756)\u001b[0m     @     0x562e2a25cfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42712)\u001b[0m     @     0x7f2d31e9f8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42712)\u001b[0m     @     0x7f2d2f9cc4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42712)\u001b[0m     @     0x7f2d35a7779f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42712)\u001b[0m     @     0x55b1bd634fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42712)\u001b[0m     @     0x55b1bd58fb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42712)\u001b[0m     @     0x55b1bd61abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42712)\u001b[0m     @     0x55b1bd61ba20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42712)\u001b[0m     @     0x55b1bd58fbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42712)\u001b[0m     @     0x55b1bd61abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42712)\u001b[0m     @     0x55b1bd61b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42712)\u001b[0m     @     0x55b1bd590689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42712)\u001b[0m     @     0x55b1bd61abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42712)\u001b[0m     @     0x55b1bd61b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42712)\u001b[0m     @     0x55b1bd590689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42712)\u001b[0m     @     0x55b1bd61abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42712)\u001b[0m     @     0x55b1bd61b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42712)\u001b[0m     @     0x55b1bd590689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42712)\u001b[0m     @     0x55b1bd61abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42712)\u001b[0m     @     0x55b1bd61b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42712)\u001b[0m     @     0x55b1bd590689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42694)\u001b[0m     @     0x7fa296c198de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42694)\u001b[0m     @     0x7fa2947464f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42694)\u001b[0m     @     0x7fa29a7f179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42694)\u001b[0m     @     0x560a9b3d8fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42694)\u001b[0m     @     0x560a9b333b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42694)\u001b[0m     @     0x560a9b3bebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42694)\u001b[0m     @     0x560a9b3bfa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42694)\u001b[0m     @     0x560a9b333bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42694)\u001b[0m     @     0x560a9b3bebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42694)\u001b[0m     @     0x560a9b3bf643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42694)\u001b[0m     @     0x560a9b334689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42694)\u001b[0m     @     0x560a9b3bebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42694)\u001b[0m     @     0x560a9b3bf643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42694)\u001b[0m     @     0x560a9b334689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42694)\u001b[0m     @     0x560a9b3bebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42694)\u001b[0m     @     0x560a9b3bf643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42694)\u001b[0m     @     0x560a9b334689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42694)\u001b[0m     @     0x560a9b3bebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42694)\u001b[0m     @     0x560a9b3bf643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42694)\u001b[0m     @     0x560a9b334689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42710)\u001b[0m     @     0x7f9392d088de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42710)\u001b[0m     @     0x7f93908354f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42710)\u001b[0m     @     0x7f93968e079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42710)\u001b[0m     @     0x556486d59fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42710)\u001b[0m     @     0x556486cb4b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42710)\u001b[0m     @     0x556486d3fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42710)\u001b[0m     @     0x556486d40a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42710)\u001b[0m     @     0x556486cb4bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42710)\u001b[0m     @     0x556486d3fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42710)\u001b[0m     @     0x556486d40643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42710)\u001b[0m     @     0x556486cb5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42710)\u001b[0m     @     0x556486d3fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42710)\u001b[0m     @     0x556486d40643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42710)\u001b[0m     @     0x556486cb5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42710)\u001b[0m     @     0x556486d3fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42710)\u001b[0m     @     0x556486d40643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42710)\u001b[0m     @     0x556486cb5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42710)\u001b[0m     @     0x556486d3fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42710)\u001b[0m     @     0x556486d40643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42710)\u001b[0m     @     0x556486cb5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42714)\u001b[0m     @     0x7ee3c31734f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42714)\u001b[0m     @     0x7ee3c921e79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42714)\u001b[0m     @     0x55b5b30e0fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42714)\u001b[0m     @     0x55b5b303bb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42714)\u001b[0m     @     0x55b5b30c6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42714)\u001b[0m     @     0x55b5b30c7a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42714)\u001b[0m     @     0x55b5b303bbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42714)\u001b[0m     @     0x55b5b30c6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42714)\u001b[0m     @     0x55b5b30c7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42714)\u001b[0m     @     0x55b5b303c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42714)\u001b[0m     @     0x55b5b30c6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42714)\u001b[0m     @     0x55b5b30c7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42714)\u001b[0m     @     0x55b5b303c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42714)\u001b[0m     @     0x55b5b30c6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42714)\u001b[0m     @     0x55b5b30c7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42714)\u001b[0m     @     0x55b5b303c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42714)\u001b[0m     @     0x55b5b30c6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42714)\u001b[0m     @     0x55b5b30c7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42714)\u001b[0m     @     0x55b5b303c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42754)\u001b[0m     @     0x7ef24034979f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42754)\u001b[0m     @     0x5650cf290fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42754)\u001b[0m     @     0x5650cf1ebb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42754)\u001b[0m     @     0x5650cf276baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42754)\u001b[0m     @     0x5650cf277a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42754)\u001b[0m     @     0x5650cf1ebbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42754)\u001b[0m     @     0x5650cf276baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42754)\u001b[0m     @     0x5650cf277643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42754)\u001b[0m     @     0x5650cf1ec689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42754)\u001b[0m     @     0x5650cf276baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42754)\u001b[0m     @     0x5650cf277643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42754)\u001b[0m     @     0x5650cf1ec689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42754)\u001b[0m     @     0x5650cf276baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42754)\u001b[0m     @     0x5650cf277643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42754)\u001b[0m     @     0x5650cf1ec689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42754)\u001b[0m     @     0x5650cf276baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42754)\u001b[0m     @     0x5650cf277643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42754)\u001b[0m     @     0x5650cf1ec689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42695)\u001b[0m     @     0x7f1928ca98de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42695)\u001b[0m     @     0x7f19267d64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42695)\u001b[0m     @     0x7f192c47779f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42695)\u001b[0m     @     0x556aa9626fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42695)\u001b[0m     @     0x556aa9581b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42695)\u001b[0m     @     0x556aa960cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42695)\u001b[0m     @     0x556aa960da20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42695)\u001b[0m     @     0x556aa9581bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42695)\u001b[0m     @     0x556aa960cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42695)\u001b[0m     @     0x556aa960d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42695)\u001b[0m     @     0x556aa9582689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42695)\u001b[0m     @     0x556aa960cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42695)\u001b[0m     @     0x556aa960d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42695)\u001b[0m     @     0x556aa9582689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42695)\u001b[0m     @     0x556aa960cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42695)\u001b[0m     @     0x556aa960d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42695)\u001b[0m     @     0x556aa9582689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42695)\u001b[0m     @     0x556aa960cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42695)\u001b[0m     @     0x556aa960d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42695)\u001b[0m     @     0x556aa9582689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42744)\u001b[0m     @     0x7f5f4edb88de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42744)\u001b[0m     @     0x7f5f4c8e54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42744)\u001b[0m     @     0x7f5f5299079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42744)\u001b[0m     @     0x564208f4bfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42744)\u001b[0m     @     0x564208ea6b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42744)\u001b[0m     @     0x564208f31baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42744)\u001b[0m     @     0x564208f32a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42744)\u001b[0m     @     0x564208ea6bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42744)\u001b[0m     @     0x564208f31baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42744)\u001b[0m     @     0x564208f32643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42744)\u001b[0m     @     0x564208ea7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42744)\u001b[0m     @     0x564208f31baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42744)\u001b[0m     @     0x564208f32643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42744)\u001b[0m     @     0x564208ea7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42744)\u001b[0m     @     0x564208f31baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42744)\u001b[0m     @     0x564208f32643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42744)\u001b[0m     @     0x564208ea7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42744)\u001b[0m     @     0x564208f31baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42744)\u001b[0m     @     0x564208f32643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42744)\u001b[0m     @     0x564208ea7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42730)\u001b[0m     @     0x7f59779918f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42718)\u001b[0m     @     0x7fb4404528f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42718)\u001b[0m     @     0x7fb440452ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42718)\u001b[0m     @     0x7fb440452d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42747)\u001b[0m     @     0x7ececf88d8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42747)\u001b[0m     @     0x7ececd3ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42747)\u001b[0m     @     0x7eced346579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42747)\u001b[0m     @     0x562fb671efd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42747)\u001b[0m     @     0x562fb6679b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42747)\u001b[0m     @     0x562fb6704baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42747)\u001b[0m     @     0x562fb6705a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42747)\u001b[0m     @     0x562fb6679bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42747)\u001b[0m     @     0x562fb6704baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42747)\u001b[0m     @     0x562fb6705643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42747)\u001b[0m     @     0x562fb667a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42747)\u001b[0m     @     0x562fb6704baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42747)\u001b[0m     @     0x562fb6705643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42747)\u001b[0m     @     0x562fb667a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42747)\u001b[0m     @     0x562fb6704baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42747)\u001b[0m     @     0x562fb6705643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42747)\u001b[0m     @     0x562fb667a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42747)\u001b[0m     @     0x562fb6704baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42747)\u001b[0m     @     0x562fb6705643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42747)\u001b[0m     @     0x562fb667a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42807)\u001b[0m     @     0x7f9f3a5ca8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42807)\u001b[0m     @     0x7f9f380f74f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42807)\u001b[0m     @     0x7f9f3e1a279f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42807)\u001b[0m     @     0x5654c34e7fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42807)\u001b[0m     @     0x5654c3442b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42807)\u001b[0m     @     0x5654c34cdbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42807)\u001b[0m     @     0x5654c34cea20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42807)\u001b[0m     @     0x5654c3442bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42807)\u001b[0m     @     0x5654c34cdbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42807)\u001b[0m     @     0x5654c34ce643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42807)\u001b[0m     @     0x5654c3443689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42807)\u001b[0m     @     0x5654c34cdbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42807)\u001b[0m     @     0x5654c34ce643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42807)\u001b[0m     @     0x5654c3443689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42807)\u001b[0m     @     0x5654c34cdbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42807)\u001b[0m     @     0x5654c34ce643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42807)\u001b[0m     @     0x5654c3443689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42807)\u001b[0m     @     0x5654c34cdbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42807)\u001b[0m     @     0x5654c34ce643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42807)\u001b[0m     @     0x5654c3443689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42767)\u001b[0m     @     0x7ee7cc4255a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42767)\u001b[0m     @     0x7ee7ccb104f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42767)\u001b[0m     @     0x7ee7cefe38de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42767)\u001b[0m     @     0x7ee7ccb104f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42767)\u001b[0m     @     0x7ee7d2bbb79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42803)\u001b[0m     @     0x7f2c3d1b88de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42803)\u001b[0m     @     0x7f2c3ace54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42803)\u001b[0m     @     0x7f2c40d9079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42803)\u001b[0m     @     0x55cb5a6ecfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42803)\u001b[0m     @     0x55cb5a647b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42803)\u001b[0m     @     0x55cb5a6d2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42803)\u001b[0m     @     0x55cb5a6d3a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42803)\u001b[0m     @     0x55cb5a647bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42803)\u001b[0m     @     0x55cb5a6d2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42803)\u001b[0m     @     0x55cb5a6d3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42803)\u001b[0m     @     0x55cb5a648689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42803)\u001b[0m     @     0x55cb5a6d2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42803)\u001b[0m     @     0x55cb5a6d3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42803)\u001b[0m     @     0x55cb5a648689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42803)\u001b[0m     @     0x55cb5a6d2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42803)\u001b[0m     @     0x55cb5a6d3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42803)\u001b[0m     @     0x55cb5a648689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42803)\u001b[0m     @     0x55cb5a6d2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42803)\u001b[0m     @     0x55cb5a6d3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42803)\u001b[0m     @     0x55cb5a648689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42715)\u001b[0m     @     0x7f2a28b5d5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42715)\u001b[0m     @     0x7f2a292484f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42715)\u001b[0m     @     0x7f2a2b71b8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42697)\u001b[0m     @     0x7f78e61d2ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42697)\u001b[0m     @     0x7f78e61d2d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42697)\u001b[0m     @     0x7f78e6ab5b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42697)\u001b[0m     @     0x7f78e6ad8c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42780)\u001b[0m     @     0x7ed37a957d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42780)\u001b[0m     @     0x7ed37b23ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42780)\u001b[0m     @     0x7ed37b25dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42780)\u001b[0m     @     0x7ed37a6ffa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42780)\u001b[0m     @     0x7ed37a6fd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42726)\u001b[0m     @     0x7f515a6418f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42726)\u001b[0m     @     0x7f515a641ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42816)\u001b[0m     @     0x7f47ca37c4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42816)\u001b[0m     @     0x7f47d042779f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42816)\u001b[0m     @     0x5574eae39fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42816)\u001b[0m     @     0x5574ead94b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42816)\u001b[0m     @     0x5574eae1fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42816)\u001b[0m     @     0x5574eae20a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42816)\u001b[0m     @     0x5574ead94bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42816)\u001b[0m     @     0x5574eae1fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42816)\u001b[0m     @     0x5574eae20643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42816)\u001b[0m     @     0x5574ead95689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42816)\u001b[0m     @     0x5574eae1fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42816)\u001b[0m     @     0x5574eae20643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42816)\u001b[0m     @     0x5574ead95689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42816)\u001b[0m     @     0x5574eae1fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42816)\u001b[0m     @     0x5574eae20643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42816)\u001b[0m     @     0x5574ead95689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42816)\u001b[0m     @     0x5574eae1fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42816)\u001b[0m     @     0x5574eae20643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42816)\u001b[0m     @     0x5574ead95689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42700)\u001b[0m     @     0x7f055637879f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42700)\u001b[0m     @     0x55dde892efd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42700)\u001b[0m     @     0x55dde8889b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42700)\u001b[0m     @     0x55dde8914baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42700)\u001b[0m     @     0x55dde8915a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42700)\u001b[0m     @     0x55dde8889bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42700)\u001b[0m     @     0x55dde8914baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42700)\u001b[0m     @     0x55dde8915643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42700)\u001b[0m     @     0x55dde888a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42700)\u001b[0m     @     0x55dde8914baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42700)\u001b[0m     @     0x55dde8915643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42700)\u001b[0m     @     0x55dde888a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42700)\u001b[0m     @     0x55dde8914baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42700)\u001b[0m     @     0x55dde8915643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42700)\u001b[0m     @     0x55dde888a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42700)\u001b[0m     @     0x55dde8914baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42700)\u001b[0m     @     0x55dde8915643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42700)\u001b[0m     @     0x55dde888a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42693)\u001b[0m     @     0x7f77db1334f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42699)\u001b[0m     @     0x55e81a092baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42699)\u001b[0m     @     0x55e81a093643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42699)\u001b[0m     @     0x55e81a008689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42699)\u001b[0m     @     0x55e81a092baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42699)\u001b[0m     @     0x55e81a093643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42699)\u001b[0m     @     0x55e81a008689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42699)\u001b[0m     @     0x55e81a092baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42699)\u001b[0m     @     0x55e81a093643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42699)\u001b[0m     @     0x55e81a008689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42793)\u001b[0m     @     0x7fa039f0c4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42793)\u001b[0m     @     0x7fa03c3df8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42776)\u001b[0m     @     0x7f093462879f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42776)\u001b[0m     @     0x56108786afd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42776)\u001b[0m     @     0x5610877c5b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42776)\u001b[0m     @     0x561087850baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42776)\u001b[0m     @     0x561087851a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42776)\u001b[0m     @     0x5610877c5bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42776)\u001b[0m     @     0x561087850baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42776)\u001b[0m     @     0x561087851643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42776)\u001b[0m     @     0x5610877c6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42776)\u001b[0m     @     0x561087850baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42776)\u001b[0m     @     0x561087851643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42776)\u001b[0m     @     0x5610877c6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42776)\u001b[0m     @     0x561087850baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42776)\u001b[0m     @     0x561087851643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42776)\u001b[0m     @     0x5610877c6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42776)\u001b[0m     @     0x561087850baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42776)\u001b[0m     @     0x561087851643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42776)\u001b[0m     @     0x5610877c6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42713)\u001b[0m     @     0x55f15b341baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42713)\u001b[0m     @     0x55f15b342643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42713)\u001b[0m     @     0x55f15b2b7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42713)\u001b[0m     @     0x55f15b341baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42713)\u001b[0m     @     0x55f15b342643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42713)\u001b[0m     @     0x55f15b2b7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42731)\u001b[0m     @     0x55b2a5b99baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42731)\u001b[0m     @     0x55b2a5b9a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42731)\u001b[0m     @     0x55b2a5b0f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42731)\u001b[0m     @     0x55b2a5b99baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42731)\u001b[0m     @     0x55b2a5b9a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42731)\u001b[0m     @     0x55b2a5b0f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42731)\u001b[0m     @     0x55b2a5b99baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42731)\u001b[0m     @     0x55b2a5b9a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42731)\u001b[0m     @     0x55b2a5b0f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42711)\u001b[0m     @     0x7f7913f2579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42711)\u001b[0m     @     0x563709956fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42711)\u001b[0m     @     0x5637098b1b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42711)\u001b[0m     @     0x56370993cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42711)\u001b[0m     @     0x56370993da20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42711)\u001b[0m     @     0x5637098b1bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42711)\u001b[0m     @     0x56370993cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42711)\u001b[0m     @     0x56370993d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42711)\u001b[0m     @     0x5637098b2689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42711)\u001b[0m     @     0x56370993cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42711)\u001b[0m     @     0x56370993d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42711)\u001b[0m     @     0x5637098b2689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42711)\u001b[0m     @     0x56370993cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42711)\u001b[0m     @     0x56370993d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42711)\u001b[0m     @     0x5637098b2689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42711)\u001b[0m     @     0x56370993cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42711)\u001b[0m     @     0x56370993d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42711)\u001b[0m     @     0x5637098b2689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42811)\u001b[0m     @     0x56277838f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42811)\u001b[0m     @     0x562778419baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42811)\u001b[0m     @     0x56277841a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42811)\u001b[0m     @     0x56277838f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42811)\u001b[0m     @     0x562778419baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42811)\u001b[0m     @     0x56277841a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42811)\u001b[0m     @     0x56277838f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42811)\u001b[0m     @     0x562778419baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42811)\u001b[0m     @     0x56277841a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42811)\u001b[0m     @     0x56277838f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42704)\u001b[0m     @     0x7f581554a79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42704)\u001b[0m     @     0x55f381b6dfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42704)\u001b[0m     @     0x55f381ac8b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42704)\u001b[0m     @     0x55f381b53baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42704)\u001b[0m     @     0x55f381b54a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42704)\u001b[0m     @     0x55f381ac8bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42704)\u001b[0m     @     0x55f381b53baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42704)\u001b[0m     @     0x55f381b54643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42704)\u001b[0m     @     0x55f381ac9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42704)\u001b[0m     @     0x55f381b53baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42704)\u001b[0m     @     0x55f381b54643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42704)\u001b[0m     @     0x55f381ac9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42704)\u001b[0m     @     0x55f381b53baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42704)\u001b[0m     @     0x55f381b54643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42704)\u001b[0m     @     0x55f381ac9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42704)\u001b[0m     @     0x55f381b53baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42704)\u001b[0m     @     0x55f381b54643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42704)\u001b[0m     @     0x55f381ac9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42708)\u001b[0m     @     0x5638955c8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42708)\u001b[0m     @     0x5638955c9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42708)\u001b[0m     @     0x56389553e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42758)\u001b[0m     @     0x7f3403de75a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42758)\u001b[0m     @     0x7f34044d24f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42692)\u001b[0m     @     0x7f9f990d679f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42692)\u001b[0m     @     0x55e2f6eb8fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42692)\u001b[0m     @     0x55e2f6e13b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42692)\u001b[0m     @     0x55e2f6e9ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42692)\u001b[0m     @     0x55e2f6e9fa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42692)\u001b[0m     @     0x55e2f6e13bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42692)\u001b[0m     @     0x55e2f6e9ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42692)\u001b[0m     @     0x55e2f6e9f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42692)\u001b[0m     @     0x55e2f6e14689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42692)\u001b[0m     @     0x55e2f6e9ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42692)\u001b[0m     @     0x55e2f6e9f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42692)\u001b[0m     @     0x55e2f6e14689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42692)\u001b[0m     @     0x55e2f6e9ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42692)\u001b[0m     @     0x55e2f6e9f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42692)\u001b[0m     @     0x55e2f6e14689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42692)\u001b[0m     @     0x55e2f6e9ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42692)\u001b[0m     @     0x55e2f6e9f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42692)\u001b[0m     @     0x55e2f6e14689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42748)\u001b[0m     @     0x7f22545ea79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42748)\u001b[0m     @     0x55f7992aefd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42748)\u001b[0m     @     0x55f799209b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42748)\u001b[0m     @     0x55f799294baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42748)\u001b[0m     @     0x55f799295a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42748)\u001b[0m     @     0x55f799209bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42748)\u001b[0m     @     0x55f799294baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42748)\u001b[0m     @     0x55f799295643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42748)\u001b[0m     @     0x55f79920a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42748)\u001b[0m     @     0x55f799294baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42748)\u001b[0m     @     0x55f799295643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42748)\u001b[0m     @     0x55f79920a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42748)\u001b[0m     @     0x55f799294baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42748)\u001b[0m     @     0x55f799295643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42748)\u001b[0m     @     0x55f79920a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42748)\u001b[0m     @     0x55f799294baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42748)\u001b[0m     @     0x55f799295643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42748)\u001b[0m     @     0x55f79920a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42709)\u001b[0m     @     0x556cb1bd1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42709)\u001b[0m     @     0x556cb1c5bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42709)\u001b[0m     @     0x556cb1c5c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42709)\u001b[0m     @     0x556cb1bd1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42701)\u001b[0m     @     0x556ef193c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42701)\u001b[0m     @     0x556ef18b1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42701)\u001b[0m     @     0x556ef193bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42701)\u001b[0m     @     0x556ef193c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42701)\u001b[0m     @     0x556ef18b1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42701)\u001b[0m     @     0x556ef193bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42701)\u001b[0m     @     0x556ef193c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42701)\u001b[0m     @     0x556ef18b1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42701)\u001b[0m     @     0x556ef193bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42701)\u001b[0m     @     0x556ef193c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42701)\u001b[0m     @     0x556ef18b1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42721)\u001b[0m     @     0x7f10f20ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42721)\u001b[0m     @     0x7f10f816579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42721)\u001b[0m     @     0x55b85849bfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42721)\u001b[0m     @     0x55b8583f6b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42721)\u001b[0m     @     0x55b858481baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42721)\u001b[0m     @     0x55b858482a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42721)\u001b[0m     @     0x55b8583f6bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42721)\u001b[0m     @     0x55b858481baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42721)\u001b[0m     @     0x55b858482643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42721)\u001b[0m     @     0x55b8583f7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42721)\u001b[0m     @     0x55b858481baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42721)\u001b[0m     @     0x55b858482643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42721)\u001b[0m     @     0x55b8583f7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42721)\u001b[0m     @     0x55b858481baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42721)\u001b[0m     @     0x55b858482643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42721)\u001b[0m     @     0x55b8583f7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42721)\u001b[0m     @     0x55b858481baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42721)\u001b[0m     @     0x55b858482643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42721)\u001b[0m     @     0x55b8583f7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42783)\u001b[0m     @     0x7eee478b7388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42783)\u001b[0m     @     0x7eee478b95a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42783)\u001b[0m     @     0x7eee47fa44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42783)\u001b[0m     @     0x7eee4a4778de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42753)\u001b[0m     @     0x7f74ae5e24f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42753)\u001b[0m     @     0x7f74b468d79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42753)\u001b[0m     @     0x55bfb25d9fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42753)\u001b[0m     @     0x55bfb2534b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42753)\u001b[0m     @     0x55bfb25bfbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42753)\u001b[0m     @     0x55bfb25c0a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42753)\u001b[0m     @     0x55bfb2534bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42753)\u001b[0m     @     0x55bfb25bfbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42753)\u001b[0m     @     0x55bfb25c0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42753)\u001b[0m     @     0x55bfb2535689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42753)\u001b[0m     @     0x55bfb25bfbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42753)\u001b[0m     @     0x55bfb25c0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42753)\u001b[0m     @     0x55bfb2535689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42753)\u001b[0m     @     0x55bfb25bfbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42753)\u001b[0m     @     0x55bfb25c0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42753)\u001b[0m     @     0x55bfb2535689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42753)\u001b[0m     @     0x55bfb25bfbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42753)\u001b[0m     @     0x55bfb25c0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42753)\u001b[0m     @     0x55bfb2535689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42773)\u001b[0m     @     0x7fa3179b14f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42773)\u001b[0m     @     0x7fa319e848de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42773)\u001b[0m     @     0x7fa3179b14f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42773)\u001b[0m     @     0x7fa31da5c79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42773)\u001b[0m     @     0x558625c46fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42773)\u001b[0m     @     0x558625ba1b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42773)\u001b[0m     @     0x558625c2cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42773)\u001b[0m     @     0x558625c2da20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42773)\u001b[0m     @     0x558625ba1bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42773)\u001b[0m     @     0x558625c2cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42773)\u001b[0m     @     0x558625c2d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42773)\u001b[0m     @     0x558625ba2689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42773)\u001b[0m     @     0x558625c2cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42773)\u001b[0m     @     0x558625c2d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42773)\u001b[0m     @     0x558625ba2689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42773)\u001b[0m     @     0x558625c2cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42773)\u001b[0m     @     0x558625c2d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42773)\u001b[0m     @     0x558625ba2689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42773)\u001b[0m     @     0x558625c2cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42773)\u001b[0m     @     0x558625c2d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42773)\u001b[0m     @     0x558625ba2689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42756)\u001b[0m     @     0x562e2a1b7b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42756)\u001b[0m     @     0x562e2a242baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42756)\u001b[0m     @     0x562e2a243a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42756)\u001b[0m     @     0x562e2a1b7bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42756)\u001b[0m     @     0x562e2a242baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42756)\u001b[0m     @     0x562e2a243643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42756)\u001b[0m     @     0x562e2a1b8689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42756)\u001b[0m     @     0x562e2a242baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42756)\u001b[0m     @     0x562e2a243643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42756)\u001b[0m     @     0x562e2a1b8689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42756)\u001b[0m     @     0x562e2a242baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42756)\u001b[0m     @     0x562e2a243643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42756)\u001b[0m     @     0x562e2a1b8689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42756)\u001b[0m     @     0x562e2a242baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42756)\u001b[0m     @     0x562e2a243643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42756)\u001b[0m     @     0x562e2a1b8689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42730)\u001b[0m     @     0x7f5977991ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42718)\u001b[0m     @     0x7fb440d35b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42718)\u001b[0m     @     0x7fb440d58c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42718)\u001b[0m     @     0x7fb4401faa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42718)\u001b[0m     @     0x7fb4401f8388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42767)\u001b[0m     @     0x559933213fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42767)\u001b[0m     @     0x55993316eb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42767)\u001b[0m     @     0x5599331f9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42767)\u001b[0m     @     0x5599331faa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42767)\u001b[0m     @     0x55993316ebfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42767)\u001b[0m     @     0x5599331f9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42767)\u001b[0m     @     0x5599331fa643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42767)\u001b[0m     @     0x55993316f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42767)\u001b[0m     @     0x5599331f9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42767)\u001b[0m     @     0x5599331fa643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42767)\u001b[0m     @     0x55993316f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42767)\u001b[0m     @     0x5599331f9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42767)\u001b[0m     @     0x5599331fa643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42767)\u001b[0m     @     0x55993316f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42767)\u001b[0m     @     0x5599331f9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42767)\u001b[0m     @     0x5599331fa643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42767)\u001b[0m     @     0x55993316f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42715)\u001b[0m     @     0x7f2a292484f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42715)\u001b[0m     @     0x7f2a2f2f379f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42715)\u001b[0m     @     0x5644d0f37fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42715)\u001b[0m     @     0x5644d0e92b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42715)\u001b[0m     @     0x5644d0f1dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42715)\u001b[0m     @     0x5644d0f1ea20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42715)\u001b[0m     @     0x5644d0e92bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42715)\u001b[0m     @     0x5644d0f1dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42715)\u001b[0m     @     0x5644d0f1e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42715)\u001b[0m     @     0x5644d0e93689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42715)\u001b[0m     @     0x5644d0f1dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42715)\u001b[0m     @     0x5644d0f1e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42715)\u001b[0m     @     0x5644d0e93689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42715)\u001b[0m     @     0x5644d0f1dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42715)\u001b[0m     @     0x5644d0f1e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42715)\u001b[0m     @     0x5644d0e93689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42715)\u001b[0m     @     0x5644d0f1dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42715)\u001b[0m     @     0x5644d0f1e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42715)\u001b[0m     @     0x5644d0e93689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42697)\u001b[0m     @     0x7f78e5f7aa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42697)\u001b[0m     @     0x7f78e5f78388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42697)\u001b[0m     @     0x7f78e5f7a5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42780)\u001b[0m     @     0x7ed37a6ff5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42726)\u001b[0m     @     0x7f515a641d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42693)\u001b[0m     @     0x7f77e11de79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42693)\u001b[0m     @     0x55cdc0505fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42693)\u001b[0m     @     0x55cdc0460b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42693)\u001b[0m     @     0x55cdc04ebbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42693)\u001b[0m     @     0x55cdc04eca20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42693)\u001b[0m     @     0x55cdc0460bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42693)\u001b[0m     @     0x55cdc04ebbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42693)\u001b[0m     @     0x55cdc04ec643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42693)\u001b[0m     @     0x55cdc0461689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42693)\u001b[0m     @     0x55cdc04ebbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42693)\u001b[0m     @     0x55cdc04ec643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42693)\u001b[0m     @     0x55cdc0461689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42693)\u001b[0m     @     0x55cdc04ebbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42693)\u001b[0m     @     0x55cdc04ec643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42693)\u001b[0m     @     0x55cdc0461689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42693)\u001b[0m     @     0x55cdc04ebbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42693)\u001b[0m     @     0x55cdc04ec643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42693)\u001b[0m     @     0x55cdc0461689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42793)\u001b[0m     @     0x7fa039f0c4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42793)\u001b[0m     @     0x7fa03ffb779f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42793)\u001b[0m     @     0x5606d0b84fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42793)\u001b[0m     @     0x5606d0adfb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42793)\u001b[0m     @     0x5606d0b6abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42793)\u001b[0m     @     0x5606d0b6ba20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42793)\u001b[0m     @     0x5606d0adfbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42793)\u001b[0m     @     0x5606d0b6abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42793)\u001b[0m     @     0x5606d0b6b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42793)\u001b[0m     @     0x5606d0ae0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42793)\u001b[0m     @     0x5606d0b6abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42793)\u001b[0m     @     0x5606d0b6b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42793)\u001b[0m     @     0x5606d0ae0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42793)\u001b[0m     @     0x5606d0b6abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42793)\u001b[0m     @     0x5606d0b6b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42793)\u001b[0m     @     0x5606d0ae0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42793)\u001b[0m     @     0x5606d0b6abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42793)\u001b[0m     @     0x5606d0b6b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42793)\u001b[0m     @     0x5606d0ae0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42758)\u001b[0m     @     0x7f34069a58de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42758)\u001b[0m     @     0x7f34044d24f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42783)\u001b[0m     @     0x7eee47fa44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42783)\u001b[0m     @     0x7eee4e04f79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42783)\u001b[0m     @     0x55be780f9fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42783)\u001b[0m     @     0x55be78054b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42783)\u001b[0m     @     0x55be780dfbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42783)\u001b[0m     @     0x55be780e0a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42783)\u001b[0m     @     0x55be78054bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42783)\u001b[0m     @     0x55be780dfbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42783)\u001b[0m     @     0x55be780e0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42783)\u001b[0m     @     0x55be78055689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42783)\u001b[0m     @     0x55be780dfbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42783)\u001b[0m     @     0x55be780e0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42783)\u001b[0m     @     0x55be78055689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42783)\u001b[0m     @     0x55be780dfbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42783)\u001b[0m     @     0x55be780e0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42783)\u001b[0m     @     0x55be78055689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42783)\u001b[0m     @     0x55be780dfbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42783)\u001b[0m     @     0x55be780e0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42783)\u001b[0m     @     0x55be78055689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42730)\u001b[0m     @     0x7f5977991d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=42730)\u001b[0m     @     0x7f5978274b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42718)\u001b[0m     @     0x7fb4401fa5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42697)\u001b[0m     @     0x7f78e66654f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42697)\u001b[0m     @     0x7f78e8b388de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42780)\u001b[0m     @     0x7ed37adea4f5 at::Tensor::copy_()\n",
+      "== Status ==\n",
+      "Memory usage on this node: 25.1/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/1 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 ERROR)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_c70fc_00000 | ERROR    |       |\n",
+      "+-------------------------+----------+-------+\n",
+      "Number of errored trials: 1\n",
+      "+-------------------------+--------------+-----------------------------------------------------------------------------------+\n",
+      "| Trial name              |   # failures | error file                                                                        |\n",
+      "|-------------------------+--------------+-----------------------------------------------------------------------------------|\n",
+      "| PPO_jss_env_c70fc_00000 |            1 | /root/ray_results/ppo-jss/PPO_jss_env_c70fc_00000_0_2020-11-05_10-43-44/error.txt |\n",
+      "+-------------------------+--------------+-----------------------------------------------------------------------------------+\n",
+      "\u001b[2m\u001b[36m(pid=42780)\u001b[0m     @     0x7ed37d2bd8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42780)\u001b[0m     @     0x7ed37adea4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42726)\u001b[0m     @     0x7f515af24b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=42726)\u001b[0m     @     0x7f515af47c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42726)\u001b[0m     @     0x7f515a3e9a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42726)\u001b[0m     @     0x7f515a3e7388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42758)\u001b[0m     @     0x7f340a57d79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42758)\u001b[0m     @     0x56111f50dfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42758)\u001b[0m     @     0x56111f468b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42758)\u001b[0m     @     0x56111f4f3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42758)\u001b[0m     @     0x56111f4f4a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42758)\u001b[0m     @     0x56111f468bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42758)\u001b[0m     @     0x56111f4f3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42758)\u001b[0m     @     0x56111f4f4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42758)\u001b[0m     @     0x56111f469689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42758)\u001b[0m     @     0x56111f4f3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42758)\u001b[0m     @     0x56111f4f4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42758)\u001b[0m     @     0x56111f469689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42758)\u001b[0m     @     0x56111f4f3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42758)\u001b[0m     @     0x56111f4f4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42758)\u001b[0m     @     0x56111f469689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42758)\u001b[0m     @     0x56111f4f3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42758)\u001b[0m     @     0x56111f4f4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42758)\u001b[0m     @     0x56111f469689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42730)\u001b[0m     @     0x7f5978297c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=42730)\u001b[0m     @     0x7f5977739a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=42730)\u001b[0m     @     0x7f5977737388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=42718)\u001b[0m     @     0x7fb4408e54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42697)\u001b[0m     @     0x7f78e66654f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42697)\u001b[0m     @     0x7f78ec71079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42697)\u001b[0m     @     0x55bc69ab6fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42697)\u001b[0m     @     0x55bc69a11b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42697)\u001b[0m     @     0x55bc69a9cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42697)\u001b[0m     @     0x55bc69a9da20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42697)\u001b[0m     @     0x55bc69a11bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42697)\u001b[0m     @     0x55bc69a9cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42697)\u001b[0m     @     0x55bc69a9d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42697)\u001b[0m     @     0x55bc69a12689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42697)\u001b[0m     @     0x55bc69a9cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42697)\u001b[0m     @     0x55bc69a9d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42697)\u001b[0m     @     0x55bc69a12689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42697)\u001b[0m     @     0x55bc69a9cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42697)\u001b[0m     @     0x55bc69a9d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42697)\u001b[0m     @     0x55bc69a12689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42697)\u001b[0m     @     0x55bc69a9cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42697)\u001b[0m     @     0x55bc69a9d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42697)\u001b[0m     @     0x55bc69a12689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42780)\u001b[0m     @     0x7ed380e9579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42780)\u001b[0m     @     0x5645560f7fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42780)\u001b[0m     @     0x564556052b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42780)\u001b[0m     @     0x5645560ddbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42780)\u001b[0m     @     0x5645560dea20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42780)\u001b[0m     @     0x564556052bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42780)\u001b[0m     @     0x5645560ddbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42780)\u001b[0m     @     0x5645560de643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42780)\u001b[0m     @     0x564556053689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42780)\u001b[0m     @     0x5645560ddbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42780)\u001b[0m     @     0x5645560de643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42780)\u001b[0m     @     0x564556053689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42780)\u001b[0m     @     0x5645560ddbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42780)\u001b[0m     @     0x5645560de643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42780)\u001b[0m     @     0x564556053689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42780)\u001b[0m     @     0x5645560ddbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42780)\u001b[0m     @     0x5645560de643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42780)\u001b[0m     @     0x564556053689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42726)\u001b[0m     @     0x7f515a3e95a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42726)\u001b[0m     @     0x7f515aad44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42730)\u001b[0m     @     0x7f59777395a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42718)\u001b[0m     @     0x7fb442db88de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42726)\u001b[0m     @     0x7f515cfa78de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "2020-11-05 10:43:52,127\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffffbdff035801000000.\n",
+      "2020-11-05 10:43:52,127\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff4100f4fd01000000.\n",
+      "2020-11-05 10:43:52,129\tERROR trial_runner.py:567 -- Trial PPO_jss_env_c70fc_00000: Error processing event.\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/trial_runner.py\", line 515, in _process_trial\n",
+      "    result = self.trial_executor.fetch_result(trial)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/ray_trial_executor.py\", line 488, in fetch_result\n",
+      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1428, in get\n",
+      "    raise value.as_instanceof_cause()\n",
+      "ray.exceptions.RayTaskError: \u001b[36mray::PPO.train()\u001b[39m (pid=42827, ip=172.17.0.4)\n",
+      "  File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
+      "  File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\", line 516, in train\n",
+      "    raise e\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\", line 505, in train\n",
+      "    result = Trainable.train(self)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/trainable.py\", line 336, in train\n",
+      "    result = self.step()\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer_template.py\", line 134, in step\n",
+      "    res = next(self.train_exec_impl)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 756, in __next__\n",
+      "    return next(self.built_iterator)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 843, in apply_filter\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 843, in apply_filter\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  [Previous line repeated 1 more time]\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 876, in apply_flatten\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 828, in add_wait_hooks\n",
+      "    item = next(it)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  [Previous line repeated 1 more time]\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 466, in base_iterator\n",
+      "    actor_set.init_actors()\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 1238, in init_actors\n",
+      "    ray.get([a.par_iter_init.remote(self.transforms) for a in self.actors])\n",
+      "ray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.\n",
+      "2020-11-05 10:43:52,138\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff821ddf4301000000.\n",
+      "2020-11-05 10:43:52,138\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff31c3fed901000000.\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m E1105 10:43:52.122043 42827 43997 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=d984ee9d41b92c534100f4fd01000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=4100f4fd01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m E1105 10:43:52.122201 42827 43997 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=6c41da4ee8b0b4d04100f4fd01000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=4100f4fd01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m E1105 10:43:52.122334 42827 43997 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=137dbd5547ea6deabdff035801000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=bdff035801000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m E1105 10:43:52.122416 42827 43997 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=3f75a43fb9f70f24bdff035801000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=bdff035801000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "Traceback (most recent call last):\n",
+      "  File \"train.py\", line 74, in <module>\n",
+      "    train_func()\n",
+      "  File \"train.py\", line 56, in train_func\n",
+      "    analysis = tune.run(PPOTrainer, config=config, stop=stop, name=\"ppo-jss\")\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/tune.py\", line 427, in run\n",
+      "    raise TuneError(\"Trials did not complete\", incomplete_trials)\n",
+      "ray.tune.error.TuneError: ('Trials did not complete', [PPO_jss_env_c70fc_00000])\n",
+      "2020-11-05 10:43:52,149\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffffb2413f7201000000.\n",
+      "\u001b[2m\u001b[36m(pid=42730)\u001b[0m     @     0x7f5977e244f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42730)\u001b[0m     @     0x7f597a2f78de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42730)\u001b[0m     @     0x7f5977e244f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42718)\u001b[0m     @     0x7fb4408e54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42718)\u001b[0m     @     0x7fb44699079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42718)\u001b[0m     @     0x557d85168fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42718)\u001b[0m     @     0x557d850c3b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42718)\u001b[0m     @     0x557d8514ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42718)\u001b[0m     @     0x557d8514fa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42718)\u001b[0m     @     0x557d850c3bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42726)\u001b[0m     @     0x7f515aad44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42726)\u001b[0m     @     0x7f5160b7f79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42726)\u001b[0m     @     0x55c8d9548fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42726)\u001b[0m     @     0x55c8d94a3b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42726)\u001b[0m     @     0x55c8d952ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42726)\u001b[0m     @     0x55c8d952fa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42726)\u001b[0m     @     0x55c8d94a3bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42726)\u001b[0m     @     0x55c8d952ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42726)\u001b[0m     @     0x55c8d952f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42726)\u001b[0m     @     0x55c8d94a4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42726)\u001b[0m     @     0x55c8d952ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42726)\u001b[0m     @     0x55c8d952f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42726)\u001b[0m     @     0x55c8d94a4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42726)\u001b[0m     @     0x55c8d952ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42726)\u001b[0m     @     0x55c8d952f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42726)\u001b[0m     @     0x55c8d94a4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m E1105 10:43:52.131191 42827 43997 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=8e79ac7e91b36714821ddf4301000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=821ddf4301000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m E1105 10:43:52.131316 42827 43997 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=428a4b4025d91890821ddf4301000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=821ddf4301000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m E1105 10:43:52.135623 42827 43997 task_manager.cc:323] Task failed: IOError: cancelling all pending tasks of dead actor: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=150a9d56b40e3700bdff035801000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=bdff035801000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m E1105 10:43:52.135962 42827 43997 task_manager.cc:323] Task failed: IOError: cancelling all pending tasks of dead actor: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=37f711ca0d66f5bd4100f4fd01000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=4100f4fd01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m E1105 10:43:52.138876 42827 43997 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=7dd3b2683d323ffd31c3fed901000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=31c3fed901000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m E1105 10:43:52.139031 42827 43997 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=0a51bbe8b791810831c3fed901000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=31c3fed901000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m E1105 10:43:52.140166 42827 43997 task_manager.cc:323] Task failed: IOError: 14: failed to connect to all addresses: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=d7b1ed864d13e17f31c3fed901000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=31c3fed901000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m E1105 10:43:52.140849 42827 43997 task_manager.cc:323] Task failed: IOError: 14: failed to connect to all addresses: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=38e2d2d27b716bfb821ddf4301000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=821ddf4301000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "2020-11-05 10:43:52,159\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff3a9488b101000000.\n",
+      "\u001b[2m\u001b[36m(pid=42730)\u001b[0m     @     0x7f597decf79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=42730)\u001b[0m     @     0x55dd107ddfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=42730)\u001b[0m     @     0x55dd10738b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42730)\u001b[0m     @     0x55dd107c3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42730)\u001b[0m     @     0x55dd107c4a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=42730)\u001b[0m     @     0x55dd10738bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42730)\u001b[0m     @     0x55dd107c3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42730)\u001b[0m     @     0x55dd107c4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42730)\u001b[0m     @     0x55dd10739689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42730)\u001b[0m     @     0x55dd107c3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42730)\u001b[0m     @     0x55dd107c4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42730)\u001b[0m     @     0x55dd10739689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42730)\u001b[0m     @     0x55dd107c3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42730)\u001b[0m     @     0x55dd107c4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42730)\u001b[0m     @     0x55dd10739689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42730)\u001b[0m     @     0x55dd107c3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42730)\u001b[0m     @     0x55dd107c4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42730)\u001b[0m     @     0x55dd10739689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42718)\u001b[0m     @     0x557d8514ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42718)\u001b[0m     @     0x557d8514f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42718)\u001b[0m     @     0x557d850c4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42718)\u001b[0m     @     0x557d8514ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42718)\u001b[0m     @     0x557d8514f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42718)\u001b[0m     @     0x557d850c4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42718)\u001b[0m     @     0x557d8514ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42718)\u001b[0m     @     0x557d8514f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42718)\u001b[0m     @     0x557d850c4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42718)\u001b[0m     @     0x557d8514ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42718)\u001b[0m     @     0x557d8514f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42718)\u001b[0m     @     0x557d850c4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=42726)\u001b[0m     @     0x55c8d952ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=42726)\u001b[0m     @     0x55c8d952f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=42726)\u001b[0m     @     0x55c8d94a4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "2020-11-05 10:43:52,170\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff9d526f0201000000.\n",
+      "2020-11-05 10:43:52,170\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff0d557f6601000000.\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m E1105 10:43:52.146086 42827 43997 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=9e78156cc0f1c18db2413f7201000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=b2413f7201000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m E1105 10:43:52.146219 42827 43997 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=99a573b913884b0db2413f7201000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=b2413f7201000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m E1105 10:43:52.146291 42827 43997 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=716ad7ba0ea412bfb2413f7201000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=b2413f7201000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m E1105 10:43:52.153694 42827 43997 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=a9f882a9e9e6260d3a9488b101000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=3a9488b101000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m E1105 10:43:52.153825 42827 43997 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=ce06aecb2528476b3a9488b101000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=3a9488b101000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m E1105 10:43:52.153877 42827 43997 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=09b335db300897a83a9488b101000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=3a9488b101000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m E1105 10:43:52.162228 42827 43997 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=f26c08df806c9b079d526f0201000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=9d526f0201000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m E1105 10:43:52.162354 42827 43997 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=3501fe38550fe14a9d526f0201000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=9d526f0201000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m E1105 10:43:52.162431 42827 43997 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=d9b69b81196304409d526f0201000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=9d526f0201000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "2020-11-05 10:43:52,180\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff0314ce3001000000.\n",
+      "2020-11-05 10:43:52,181\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffffa97540c201000000.\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m E1105 10:43:52.168531 42827 43997 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=559b33aa5754ccdd0d557f6601000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=0d557f6601000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m E1105 10:43:52.168661 42827 43997 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=40900fb9361f40170d557f6601000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=0d557f6601000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m E1105 10:43:52.168709 42827 43997 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=63b211a4d40ef39a0d557f6601000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=0d557f6601000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m E1105 10:43:52.176146 42827 43997 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=f4d9d8a5e202b0910314ce3001000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=0314ce3001000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m E1105 10:43:52.176282 42827 43997 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=8b0b449b9f08d0430314ce3001000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=0314ce3001000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m E1105 10:43:52.176343 42827 43997 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=ad47e6e6a1a1660b0314ce3001000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=0314ce3001000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "2020-11-05 10:43:52,191\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffffc2621d1401000000.\n",
+      "2020-11-05 10:43:52,191\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff56c9ec1501000000.\n",
+      "2020-11-05 10:43:52,191\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff59d91ef301000000.\n",
+      "2020-11-05 10:43:52,191\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff091d563401000000.\n",
+      "2020-11-05 10:43:52,202\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff51728d3301000000.\n",
+      "2020-11-05 10:43:52,202\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff252160a301000000.\n",
+      "2020-11-05 10:43:52,202\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff0fae11b201000000.\n",
+      "2020-11-05 10:43:52,202\tWARNING worker.py:1072 -- A worker died or was killed while executing task fff\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 42591\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 1.  Press ctrl-c to abort syncing.\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m E1105 10:43:52.179581 42827 43997 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=fde3d5eda9f525d7a97540c201000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=a97540c201000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m E1105 10:43:52.179695 42827 43997 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=d16c21eef3935840a97540c201000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=a97540c201000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m E1105 10:43:52.179769 42827 43997 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=d88ec84d5baca957a97540c201000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=a97540c201000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m E1105 10:43:52.181165 42827 43997 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=9ecf84e34eb8e61dc2621d1401000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=c2621d1401000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m E1105 10:43:52.181260 42827 43997 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=f3cba62d4c01820bc2621d1401000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=c2621d1401000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m E1105 10:43:52.181308 42827 43997 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=8fbf1bd7de98d288c2621d1401000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=c2621d1401000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m E1105 10:43:52.181586 42827 43997 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=4db1cba171d56c3356c9ec1501000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=56c9ec1501000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m E1105 10:43:52.181689 42827 43997 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=5cf29c5b7b7ed08d56c9ec1501000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=56c9ec1501000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m E1105 10:43:52.181751 42827 43997 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=9d0a2db204e8f81056c9ec1501000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=56c9ec1501000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m E1105 10:43:52.185117 42827 43997 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=8b485cbbeaa005a559d91ef301000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=59d91ef301000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m E1105 10:43:52.185215 42827 43997 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=ca546fa1af7e507159d91ef301000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=59d91ef301000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m E1105 10:43:52.185288 42827 43997 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=fd2b07e19848a86a59d91ef301000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=59d91ef301000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m E1105 10:43:52.187753 42827 43997 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=1f6f5417a7b065f9091d563401000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=091d563401000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m E1105 10:43:52.187860 42827 43997 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=e76b5820fbdeb0f2091d563401000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=091d563401000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m E1105 10:43:52.187924 42827 43997 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=7249131d8582b825091d563401000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=091d563401000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m E1105 10:43:52.196015 42827 43997 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=8c81fa2ead7f32de51728d3301000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=51728d3301000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m E1105 10:43:52.196144 42827 43997 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=5321c0509e8700a351728d3301000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=51728d3301000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m E1105 10:43:52.196199 42827 43997 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=0f7e69c998e8670f51728d3301000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=51728d3301000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m E1105 10:43:52.196313 42827 43997 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=3e4916e36cb3ce60252160a301000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=252160a301000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m E1105 10:43:52.196365 42827 43997 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=c2d663ba592886f5252160a301000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=252160a301000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m E1105 10:43:52.196416 42827 43997 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=457f03c785986c89252160a301000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=252160a301000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m E1105 10:43:52.196516 42827 43997 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=e0a4e1197307fa860fae11b201000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=0fae11b201000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=42827)\u001b[0m E1105 10:43:52.196569 42827 43997 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=f6c24b3589e6e9eb0fae11b201000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=0fae11b201000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff1e7ae67b01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffa4f7314201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffef1af81501000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffe9f6a7cf01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffc3083e0c01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task fffffffffffffffff392716d01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff19fd5b4901000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffd8f83c3801000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff244a7d1001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff7f7c936001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffa7ad1db301000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff14da135201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff32335d4e01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff5843697701000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff8f9a5fc701000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff99d0343201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task fffffffffffffffff0f72e3901000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffdd5654aa01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff310e963d01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff8cd168e101000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff018c9dac01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff34cbbac201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff20d842ad01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff71ca01c001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff80993fa801000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffeca600ef01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff2d1a71ea01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff0aeae6a301000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff452e714401000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffccf343cc01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff358dd45601000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff7b2861ac01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff58dd50c101000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffd989d1f001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff41e0fbff01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffffefbd9801000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff302122d001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff3166f9e301000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff4f9bfece01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff702ed69e01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffb3cace0801000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff10f667b001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff8d06128001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff5cc87e2501000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff61dc472601000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffd784bf0601000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffda2cd21f01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff7a508a7a01000000.'\n",
+      "Arguments: ()\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201014_204438-uz9lk4hk/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201014_204438-uz9lk4hk/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:       nb_episodes 1\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   avg_best_result 209.43434\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_episode 209.43434\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:     best_timestep 3742\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:             _step 0\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:          _runtime 1\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        _timestamp 1602708279\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:       nb_episodes ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   avg_best_result ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_episode ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:     best_timestep ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:             _step ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:          _runtime ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        _timestamp ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201105_104339-sf5shxxc/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201105_104339-sf5shxxc/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mMTWR\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/uz9lk4hk\u001b[0m\n",
-      "2020-10-14 20:44:46,515 - wandb.wandb_agent - INFO - Cleaning up finished run: uz9lk4hk\n",
-      "2020-10-14 20:44:46,834 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-14 20:44:46,834 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tinstance_path: /JSS/JSS/env/instances/ta58\n",
-      "2020-10-14 20:44:46,836 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python MTWR.py --instance_path=/JSS/JSS/env/instances/ta58\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33msmooth-sweep-3\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/sf5shxxc\u001b[0m\n",
+      "2020-11-05 10:44:03,709 - wandb.wandb_agent - INFO - Cleaning up finished run: sf5shxxc\n",
+      "2020-11-05 10:44:04,015 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-11-05 10:44:04,015 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tinstance_path: /JSS/JSS/env/instances/ta43\n",
+      "2020-11-05 10:44:04,017 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --instance_path=/JSS/JSS/env/instances/ta43\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.9 is available!  To upgrade, please run:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mMTWR\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/po3ygyxo\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/i1pzxngg\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201014_204448-i1pzxngg\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mhonest-sweep-4\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/sweeps/72qf0qyh\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/ed9sd7in\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201105_104405-ed9sd7in\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
+      "2020-11-05 10:44:09,035 - wandb.wandb_agent - INFO - Running runs: ['ed9sd7in']\n",
+      "2020-11-05 10:44:09,619\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
+      "== Status ==\n",
+      "Memory usage on this node: 12.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/1 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_d6abc_00000 | RUNNING  |       |\n",
+      "+-------------------------+----------+-------+\n",
       "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 3912\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
-      "2020-10-14 20:44:51,849 - wandb.wandb_agent - INFO - Running runs: ['i1pzxngg']\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201014_204448-i1pzxngg/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201014_204448-i1pzxngg/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:       nb_episodes 1\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   avg_best_result 209.89899\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_episode 209.89899\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:     best_timestep 3826\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:             _step 0\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:          _runtime 1\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        _timestamp 1602708290\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:       nb_episodes ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   avg_best_result ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_episode ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:     best_timestep ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:             _step ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:          _runtime ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        _timestamp ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mMTWR\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/i1pzxngg\u001b[0m\n",
-      "2020-10-14 20:44:57,073 - wandb.wandb_agent - INFO - Cleaning up finished run: i1pzxngg\n",
-      "2020-10-14 20:44:57,383 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-14 20:44:57,384 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tinstance_path: /JSS/JSS/env/instances/ta59\n",
-      "2020-10-14 20:44:57,386 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python MTWR.py --instance_path=/JSS/JSS/env/instances/ta59\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mMTWR\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/po3ygyxo\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/3kcee9dt\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201014_204459-3kcee9dt\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
+      "\u001b[2m\u001b[36m(pid=44367)\u001b[0m 2020-11-05 10:44:12,434\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=44367)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/torch/cuda/__init__.py:125: UserWarning: \n",
+      "\u001b[2m\u001b[36m(pid=44367)\u001b[0m GeForce RTX 2080 Ti with CUDA capability sm_75 is not compatible with the current PyTorch installation.\n",
+      "\u001b[2m\u001b[36m(pid=44367)\u001b[0m The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 compute_37.\n",
+      "\u001b[2m\u001b[36m(pid=44367)\u001b[0m If you want to use the GeForce RTX 2080 Ti GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
+      "\u001b[2m\u001b[36m(pid=44367)\u001b[0m \n",
+      "\u001b[2m\u001b[36m(pid=44367)\u001b[0m   warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n",
+      "\u001b[2m\u001b[36m(pid=44341)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44341)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44341)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44341)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44341)\u001b[0m *** SIGSEGV (@0x0) received by PID 44341 (TID 0x7fc22287e700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44341)\u001b[0m     @     0x7fc222457390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44341)\u001b[0m     @     0x7f932234bf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44372)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44372)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44372)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44372)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44372)\u001b[0m *** SIGSEGV (@0x0) received by PID 44372 (TID 0x7f20a31b4700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44372)\u001b[0m     @     0x7f20a2d8d390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44372)\u001b[0m     @     0x7ef1a2cfcf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m *** SIGSEGV (@0x0) received by PID 44332 (TID 0x7f4af2469700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m     @     0x7f4af2042390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44363)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44363)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44363)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44363)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44363)\u001b[0m *** SIGSEGV (@0x0) received by PID 44363 (TID 0x7f7e63e2f700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44363)\u001b[0m     @     0x7f7e63a08390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44363)\u001b[0m     @     0x7f4f63751f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44363)\u001b[0m     @     0x7f4f62e7c7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44363)\u001b[0m     @     0x7f4f62e7f8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44315)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44315)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44315)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44315)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44315)\u001b[0m *** SIGSEGV (@0x0) received by PID 44315 (TID 0x7f0ac67fc700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44315)\u001b[0m     @     0x7f0ac63d5390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44315)\u001b[0m     @     0x7edbc634bf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44361)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44361)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44361)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44361)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44361)\u001b[0m *** SIGSEGV (@0x0) received by PID 44361 (TID 0x7fd614ffe700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44361)\u001b[0m     @     0x7fd614bd7390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44362)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44362)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44362)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44362)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44362)\u001b[0m *** SIGSEGV (@0x0) received by PID 44362 (TID 0x7f558aa0f700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44362)\u001b[0m     @     0x7f558a5e8390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44362)\u001b[0m     @     0x7f268a4f9f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44362)\u001b[0m     @     0x7f2689c247db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44362)\u001b[0m     @     0x7f2689c278f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44329)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44329)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44329)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44329)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44329)\u001b[0m *** SIGSEGV (@0x0) received by PID 44329 (TID 0x7f1ef9091700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44329)\u001b[0m     @     0x7f1ef8c6a390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44329)\u001b[0m     @     0x7eeff8b3bf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44329)\u001b[0m     @     0x7eeff82667db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44343)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44343)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44343)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44343)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44343)\u001b[0m *** SIGSEGV (@0x0) received by PID 44343 (TID 0x7f7bd8b8f700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44343)\u001b[0m     @     0x7f7bd8768390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44343)\u001b[0m     @     0x7f4cd8563f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44343)\u001b[0m     @     0x7f4cd7c8e7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44343)\u001b[0m     @     0x7f4cd7c918f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44310)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44310)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44310)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44310)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44310)\u001b[0m *** SIGSEGV (@0x0) received by PID 44310 (TID 0x7f8464abf700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44310)\u001b[0m     @     0x7f8464698390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44310)\u001b[0m     @     0x7f5564339f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44310)\u001b[0m     @     0x7f5563a647db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44348)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44348)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44348)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44348)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44348)\u001b[0m *** SIGSEGV (@0x0) received by PID 44348 (TID 0x7fedb70b8700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44348)\u001b[0m     @     0x7fedb6c91390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44348)\u001b[0m     @     0x7fbeb6ad1f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44348)\u001b[0m     @     0x7fbeb61fc7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44346)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44346)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44346)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44346)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44346)\u001b[0m *** SIGSEGV (@0x0) received by PID 44346 (TID 0x7f11aab93700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44346)\u001b[0m     @     0x7f11aa76c390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44346)\u001b[0m     @     0x7ee2aa4f9f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44321)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44321)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44321)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44321)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44321)\u001b[0m *** SIGSEGV (@0x0) received by PID 44321 (TID 0x7fa1bd08d700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44321)\u001b[0m     @     0x7fa1bcc66390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44321)\u001b[0m     @     0x7f72bca8bf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44321)\u001b[0m     @     0x7f72bc1b67db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44325)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44325)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44325)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44325)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44325)\u001b[0m *** SIGSEGV (@0x0) received by PID 44325 (TID 0x7f7d5be1f700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44325)\u001b[0m     @     0x7f7d5b9f8390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44325)\u001b[0m     @     0x7f4e5b8def90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44325)\u001b[0m     @     0x7f4e5b0097db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44325)\u001b[0m     @     0x7f4e5b00c8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44325)\u001b[0m     @     0x7f4e5b00cad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44345)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44345)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44345)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44345)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44345)\u001b[0m *** SIGSEGV (@0x0) received by PID 44345 (TID 0x7f37305df700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44345)\u001b[0m     @     0x7f37301b8390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44345)\u001b[0m     @     0x7f08300cdf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44345)\u001b[0m     @     0x7f082f7f87db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44349)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44349)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44349)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44349)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44349)\u001b[0m *** SIGSEGV (@0x0) received by PID 44349 (TID 0x7f9ac132b700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44349)\u001b[0m     @     0x7f9ac0f04390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44349)\u001b[0m     @     0x7f6bc0ea4f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44349)\u001b[0m     @     0x7f6bc05cf7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44330)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44330)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44330)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44330)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44330)\u001b[0m *** SIGSEGV (@0x0) received by PID 44330 (TID 0x7fb596584700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44330)\u001b[0m     @     0x7fb59615d390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44330)\u001b[0m     @     0x7f8695e24f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44330)\u001b[0m     @     0x7f869554f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44355)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44355)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44355)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44355)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44355)\u001b[0m *** SIGSEGV (@0x0) received by PID 44355 (TID 0x7f98e56dd700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44355)\u001b[0m     @     0x7f98e52b6390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44355)\u001b[0m     @     0x7f69e524af90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44355)\u001b[0m     @     0x7f69e49757db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44338)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44338)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44338)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44338)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44338)\u001b[0m *** SIGSEGV (@0x0) received by PID 44338 (TID 0x7f4b0c8be700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44338)\u001b[0m     @     0x7f4b0c497390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44338)\u001b[0m     @     0x7f1c0c3e3f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44339)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44339)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44339)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44339)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44339)\u001b[0m *** SIGSEGV (@0x0) received by PID 44339 (TID 0x7f34eb4fd700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44339)\u001b[0m     @     0x7f34eb0d6390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44339)\u001b[0m     @     0x7f05eb068f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44339)\u001b[0m     @     0x7f05ea7937db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44341)\u001b[0m     @     0x7f9321a767db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44341)\u001b[0m     @     0x7f9321a798f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44341)\u001b[0m     @     0x7f9321a79ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44372)\u001b[0m     @     0x7ef1a24277db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44372)\u001b[0m     @     0x7ef1a242a8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44372)\u001b[0m     @     0x7ef1a242aad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m     @     0x7f1bf1e24f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m     @     0x7f1bf154f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m     @     0x7f1bf15528f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m     @     0x7f1bf1552ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44363)\u001b[0m     @     0x7f4f62e7fad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44363)\u001b[0m     @     0x7f4f62e7fd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44363)\u001b[0m     @     0x7f4f63762b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44315)\u001b[0m     @     0x7edbc5a767db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44315)\u001b[0m     @     0x7edbc5a798f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44361)\u001b[0m     @     0x7fa714a8bf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44361)\u001b[0m     @     0x7fa7141b67db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44361)\u001b[0m     @     0x7fa7141b98f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44362)\u001b[0m     @     0x7f2689c27ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44362)\u001b[0m     @     0x7f2689c27d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44362)\u001b[0m     @     0x7f268a50ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44362)\u001b[0m     @     0x7f268a52dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44329)\u001b[0m     @     0x7eeff82698f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44329)\u001b[0m     @     0x7eeff8269ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44343)\u001b[0m     @     0x7f4cd7c91ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44343)\u001b[0m     @     0x7f4cd7c91d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44343)\u001b[0m     @     0x7f4cd8574b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44310)\u001b[0m     @     0x7f5563a678f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44310)\u001b[0m     @     0x7f5563a67ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44348)\u001b[0m     @     0x7fbeb61ff8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44348)\u001b[0m     @     0x7fbeb61ffad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44346)\u001b[0m     @     0x7ee2a9c247db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44346)\u001b[0m     @     0x7ee2a9c278f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44321)\u001b[0m     @     0x7f72bc1b98f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44321)\u001b[0m     @     0x7f72bc1b9ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44321)\u001b[0m     @     0x7f72bc1b9d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44325)\u001b[0m     @     0x7f4e5b00cd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44325)\u001b[0m     @     0x7f4e5b8efb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44325)\u001b[0m     @     0x7f4e5b912c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44345)\u001b[0m     @     0x7f082f7fb8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44345)\u001b[0m     @     0x7f082f7fbad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44349)\u001b[0m     @     0x7f6bc05d28f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44330)\u001b[0m     @     0x7f86955528f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44330)\u001b[0m     @     0x7f8695552ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44355)\u001b[0m     @     0x7f69e49788f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44355)\u001b[0m     @     0x7f69e4978ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44338)\u001b[0m     @     0x7f1c0bb0e7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44338)\u001b[0m     @     0x7f1c0bb118f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44338)\u001b[0m     @     0x7f1c0bb11ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44258)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44258)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44258)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44258)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44258)\u001b[0m *** SIGSEGV (@0x0) received by PID 44258 (TID 0x7fbe3009c700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44258)\u001b[0m     @     0x7fbe2fc75390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44366)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44366)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44366)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44366)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44366)\u001b[0m *** SIGSEGV (@0x0) received by PID 44366 (TID 0x7fb737c55700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44247)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44247)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44247)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44247)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44247)\u001b[0m *** SIGSEGV (@0x0) received by PID 44247 (TID 0x7fa3ddfa6700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44238)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44238)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44238)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44238)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44238)\u001b[0m *** SIGSEGV (@0x0) received by PID 44238 (TID 0x7f45a34e6700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44339)\u001b[0m     @     0x7f05ea7968f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44339)\u001b[0m     @     0x7f05ea796ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44339)\u001b[0m     @     0x7f05ea796d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44339)\u001b[0m     @     0x7f05eb079b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44339)\u001b[0m     @     0x7f05eb09cc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44250)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44250)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44250)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44254)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44254)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44254)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44249)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44249)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44249)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44242)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44242)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44242)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44331)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44331)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44331)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44260)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44260)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44260)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44314)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44314)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44314)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44322)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44322)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44322)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44322)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44322)\u001b[0m *** SIGSEGV (@0x0) received by PID 44322 (TID 0x7fce44644700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44307)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44307)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44307)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44307)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44307)\u001b[0m *** SIGSEGV (@0x0) received by PID 44307 (TID 0x7fa9d9272700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44257)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44257)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44257)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44257)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44257)\u001b[0m *** SIGSEGV (@0x0) received by PID 44257 (TID 0x7f48a30b4700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44257)\u001b[0m     @     0x7f48a2c8d390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44257)\u001b[0m     @     0x7f19a2c10f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44257)\u001b[0m     @     0x7f19a233b7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44311)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44311)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44311)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44311)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44311)\u001b[0m *** SIGSEGV (@0x0) received by PID 44311 (TID 0x7fc246bd1700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44311)\u001b[0m     @     0x7fc2467aa390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44311)\u001b[0m     @     0x7f934674ef90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44311)\u001b[0m     @     0x7f9345e797db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44243)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44243)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44243)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44243)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44243)\u001b[0m *** SIGSEGV (@0x0) received by PID 44243 (TID 0x7fad19182700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44243)\u001b[0m     @     0x7fad18d5b390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44243)\u001b[0m     @     0x7f7e18c74f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44243)\u001b[0m     @     0x7f7e1839f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44304)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44304)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44304)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44304)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44304)\u001b[0m *** SIGSEGV (@0x0) received by PID 44304 (TID 0x7f9d5eddc700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44266)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44266)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44266)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44266)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44266)\u001b[0m *** SIGSEGV (@0x0) received by PID 44266 (TID 0x7f4a710a1700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44266)\u001b[0m     @     0x7f4a70c7a390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44266)\u001b[0m     @     0x7f1b70bd1f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44266)\u001b[0m     @     0x7f1b702fc7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44352)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44352)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44352)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44352)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44352)\u001b[0m *** SIGSEGV (@0x0) received by PID 44352 (TID 0x7f75362f1700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44352)\u001b[0m     @     0x7f7535eca390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44317)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44317)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44317)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44317)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44354)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44354)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44354)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44274)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44274)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44274)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44274)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44274)\u001b[0m *** SIGSEGV (@0x0) received by PID 44274 (TID 0x7ff977b67700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44274)\u001b[0m     @     0x7ff977740390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44274)\u001b[0m     @     0x7fca776aef90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44296)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44296)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44296)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44296)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44296)\u001b[0m *** SIGSEGV (@0x0) received by PID 44296 (TID 0x7f7f3578d700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44296)\u001b[0m     @     0x7f7f35366390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44296)\u001b[0m     @     0x7f5035166f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44296)\u001b[0m     @     0x7f50348917db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44341)\u001b[0m     @     0x7f9321a79d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44341)\u001b[0m     @     0x7f932235cb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44341)\u001b[0m     @     0x7f932237fc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44341)\u001b[0m     @     0x7f9321821a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44341)\u001b[0m     @     0x7f932181f388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44341)\u001b[0m     @     0x7f93218215a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44341)\u001b[0m     @     0x7f9321f0c4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44372)\u001b[0m     @     0x7ef1a242ad91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44372)\u001b[0m     @     0x7ef1a2d0db22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44372)\u001b[0m     @     0x7ef1a2d30c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44372)\u001b[0m     @     0x7ef1a21d2a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44372)\u001b[0m     @     0x7ef1a21d0388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44372)\u001b[0m     @     0x7ef1a21d25a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44241)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44241)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44241)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44241)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44241)\u001b[0m *** SIGSEGV (@0x0) received by PID 44241 (TID 0x7f1f98dbf700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44241)\u001b[0m     @     0x7f1f98998390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44241)\u001b[0m     @     0x7ef098825f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44241)\u001b[0m     @     0x7ef097f507db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44241)\u001b[0m     @     0x7ef097f538f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m     @     0x7f1bf1552d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m     @     0x7f1bf1e35b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m     @     0x7f1bf1e58c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m     @     0x7f1bf12faa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m     @     0x7f1bf12f8388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m     @     0x7f1bf12fa5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m     @     0x7f1bf19e54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44363)\u001b[0m     @     0x7f4f63785c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44363)\u001b[0m     @     0x7f4f62c27a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44363)\u001b[0m     @     0x7f4f62c25388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44363)\u001b[0m     @     0x7f4f62c275a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44363)\u001b[0m     @     0x7f4f633124f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44363)\u001b[0m     @     0x7f4f657e58de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44363)\u001b[0m     @     0x7f4f633124f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44315)\u001b[0m     @     0x7edbc5a79ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44315)\u001b[0m     @     0x7edbc5a79d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44315)\u001b[0m     @     0x7edbc635cb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44315)\u001b[0m     @     0x7edbc637fc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44315)\u001b[0m     @     0x7edbc5821a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44315)\u001b[0m     @     0x7edbc581f388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44269)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44269)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44269)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44269)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44269)\u001b[0m *** SIGSEGV (@0x0) received by PID 44269 (TID 0x7fea06671700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44269)\u001b[0m     @     0x7fea0624a390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44269)\u001b[0m     @     0x7fbb0613af90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44269)\u001b[0m     @     0x7fbb058657db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44269)\u001b[0m     @     0x7fbb058688f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44361)\u001b[0m     @     0x7fa7141b9ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44361)\u001b[0m     @     0x7fa7141b9d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44361)\u001b[0m     @     0x7fa714a9cb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44361)\u001b[0m     @     0x7fa714abfc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44361)\u001b[0m     @     0x7fa713f61a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44361)\u001b[0m     @     0x7fa713f5f388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44334)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44334)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44334)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44334)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44334)\u001b[0m *** SIGSEGV (@0x0) received by PID 44334 (TID 0x7f24d3f2e700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44334)\u001b[0m     @     0x7f24d3b07390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44334)\u001b[0m     @     0x7ef5d38ccf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44334)\u001b[0m     @     0x7ef5d2ff77db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44334)\u001b[0m     @     0x7ef5d2ffa8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44362)\u001b[0m     @     0x7f26899cfa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44362)\u001b[0m     @     0x7f26899cd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44362)\u001b[0m     @     0x7f26899cf5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44362)\u001b[0m     @     0x7f268a0ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44362)\u001b[0m     @     0x7f268c58d8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44362)\u001b[0m     @     0x7f268a0ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44329)\u001b[0m     @     0x7eeff8269d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44329)\u001b[0m     @     0x7eeff8b4cb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44329)\u001b[0m     @     0x7eeff8b6fc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44329)\u001b[0m     @     0x7eeff8011a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44329)\u001b[0m     @     0x7eeff800f388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44329)\u001b[0m     @     0x7eeff80115a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44343)\u001b[0m     @     0x7f4cd8597c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44343)\u001b[0m     @     0x7f4cd7a39a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44343)\u001b[0m     @     0x7f4cd7a37388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44343)\u001b[0m     @     0x7f4cd7a395a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44343)\u001b[0m     @     0x7f4cd81244f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44343)\u001b[0m     @     0x7f4cda5f78de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44246)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44246)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44246)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44246)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44246)\u001b[0m *** SIGSEGV (@0x0) received by PID 44246 (TID 0x7fe58242a700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44246)\u001b[0m     @     0x7fe582003390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44246)\u001b[0m     @     0x7fb681e24f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44246)\u001b[0m     @     0x7fb68154f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44246)\u001b[0m     @     0x7fb6815528f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44246)\u001b[0m     @     0x7fb681552ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44310)\u001b[0m     @     0x7f5563a67d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44310)\u001b[0m     @     0x7f556434ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44310)\u001b[0m     @     0x7f556436dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44310)\u001b[0m     @     0x7f556380fa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44310)\u001b[0m     @     0x7f556380d388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44310)\u001b[0m     @     0x7f556380f5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44310)\u001b[0m     @     0x7f5563efa4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44297)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44297)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44297)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44297)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44297)\u001b[0m *** SIGSEGV (@0x0) received by PID 44297 (TID 0x7f7165769700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44297)\u001b[0m     @     0x7f7165342390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44297)\u001b[0m     @     0x7f42652b7f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44297)\u001b[0m     @     0x7f42649e27db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44318)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44318)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44318)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44318)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44318)\u001b[0m *** SIGSEGV (@0x0) received by PID 44318 (TID 0x7f166fca7700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44318)\u001b[0m     @     0x7f166f880390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44318)\u001b[0m     @     0x7ee76f83bf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44318)\u001b[0m     @     0x7ee76ef667db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44318)\u001b[0m     @     0x7ee76ef698f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44320)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44320)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44320)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44320)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44320)\u001b[0m *** SIGSEGV (@0x0) received by PID 44320 (TID 0x7f5966f61700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44320)\u001b[0m     @     0x7f5966b3a390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44320)\u001b[0m     @     0x7f2a66aa4f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44320)\u001b[0m     @     0x7f2a661cf7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44320)\u001b[0m     @     0x7f2a661d28f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44320)\u001b[0m     @     0x7f2a661d2ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44259)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44259)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44259)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44259)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44259)\u001b[0m *** SIGSEGV (@0x0) received by PID 44259 (TID 0x7f054b822700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44259)\u001b[0m     @     0x7f054b3fb390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44259)\u001b[0m     @     0x7ed64b229f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44259)\u001b[0m     @     0x7ed64a9547db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44259)\u001b[0m     @     0x7ed64a9578f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44251)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44251)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44251)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44251)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44251)\u001b[0m *** SIGSEGV (@0x0) received by PID 44251 (TID 0x7f5d0e7e6700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44251)\u001b[0m     @     0x7f5d0e3bf390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44251)\u001b[0m     @     0x7f2e0e34bf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44251)\u001b[0m     @     0x7f2e0da767db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44348)\u001b[0m     @     0x7fbeb61ffd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44348)\u001b[0m     @     0x7fbeb6ae2b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44348)\u001b[0m     @     0x7fbeb6b05c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44348)\u001b[0m     @     0x7fbeb5fa7a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44348)\u001b[0m     @     0x7fbeb5fa5388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44348)\u001b[0m     @     0x7fbeb5fa75a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44348)\u001b[0m     @     0x7fbeb66924f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44348)\u001b[0m     @     0x7fbeb8b658de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44346)\u001b[0m     @     0x7ee2a9c27ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44346)\u001b[0m     @     0x7ee2a9c27d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44346)\u001b[0m     @     0x7ee2aa50ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44346)\u001b[0m     @     0x7ee2aa52dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44346)\u001b[0m     @     0x7ee2a99cfa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44346)\u001b[0m     @     0x7ee2a99cd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44321)\u001b[0m     @     0x7f72bca9cb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44321)\u001b[0m     @     0x7f72bcabfc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44321)\u001b[0m     @     0x7f72bbf61a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44321)\u001b[0m     @     0x7f72bbf5f388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44321)\u001b[0m     @     0x7f72bbf615a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44321)\u001b[0m     @     0x7f72bc64c4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44321)\u001b[0m     @     0x7f72beb1f8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44252)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44252)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44252)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44252)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44252)\u001b[0m *** SIGSEGV (@0x0) received by PID 44252 (TID 0x7f987b338700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44252)\u001b[0m     @     0x7f987af11390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44252)\u001b[0m     @     0x7f697ae93f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44252)\u001b[0m     @     0x7f697a5be7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44252)\u001b[0m     @     0x7f697a5c18f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44325)\u001b[0m     @     0x7f4e5adb4a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44325)\u001b[0m     @     0x7f4e5adb2388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44325)\u001b[0m     @     0x7f4e5adb45a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44325)\u001b[0m     @     0x7f4e5b49f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44325)\u001b[0m     @     0x7f4e5d9728de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44325)\u001b[0m     @     0x7f4e5b49f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44325)\u001b[0m     @     0x7f4e6154a79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44325)\u001b[0m     @     0x55c06ec4afd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44325)\u001b[0m     @     0x55c06eba5b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44325)\u001b[0m     @     0x55c06ec30baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44325)\u001b[0m     @     0x55c06ec31a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44325)\u001b[0m     @     0x55c06eba5bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44325)\u001b[0m     @     0x55c06ec30baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44325)\u001b[0m     @     0x55c06ec31643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44325)\u001b[0m     @     0x55c06eba6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44325)\u001b[0m     @     0x55c06ec30baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44345)\u001b[0m     @     0x7f082f7fbd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44345)\u001b[0m     @     0x7f08300deb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44345)\u001b[0m     @     0x7f0830101c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44345)\u001b[0m     @     0x7f082f5a3a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44345)\u001b[0m     @     0x7f082f5a1388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44345)\u001b[0m     @     0x7f082f5a35a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44345)\u001b[0m     @     0x7f082fc8e4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44345)\u001b[0m     @     0x7f08321618de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44349)\u001b[0m     @     0x7f6bc05d2ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44349)\u001b[0m     @     0x7f6bc05d2d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44349)\u001b[0m     @     0x7f6bc0eb5b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44349)\u001b[0m     @     0x7f6bc0ed8c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44349)\u001b[0m     @     0x7f6bc037aa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44349)\u001b[0m     @     0x7f6bc0378388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44349)\u001b[0m     @     0x7f6bc037a5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44330)\u001b[0m     @     0x7f8695552d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44330)\u001b[0m     @     0x7f8695e35b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44330)\u001b[0m     @     0x7f8695e58c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44330)\u001b[0m     @     0x7f86952faa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44330)\u001b[0m     @     0x7f86952f8388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44330)\u001b[0m     @     0x7f86952fa5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44330)\u001b[0m     @     0x7f86959e54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44330)\u001b[0m     @     0x7f8697eb88de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44355)\u001b[0m     @     0x7f69e4978d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44355)\u001b[0m     @     0x7f69e525bb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44355)\u001b[0m     @     0x7f69e527ec1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44355)\u001b[0m     @     0x7f69e4720a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44355)\u001b[0m     @     0x7f69e471e388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44355)\u001b[0m     @     0x7f69e47205a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44245)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44245)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44245)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44245)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44245)\u001b[0m *** SIGSEGV (@0x0) received by PID 44245 (TID 0x7fd24bb18700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44245)\u001b[0m     @     0x7fd24b6f1390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44245)\u001b[0m     @     0x7fa34b5eff90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44245)\u001b[0m     @     0x7fa34ad1a7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44245)\u001b[0m     @     0x7fa34ad1d8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44302)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44302)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44302)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44302)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44302)\u001b[0m *** SIGSEGV (@0x0) received by PID 44302 (TID 0x7f5ad0cfa700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44302)\u001b[0m     @     0x7f5ad08d3390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44302)\u001b[0m     @     0x7f2bd0825f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44302)\u001b[0m     @     0x7f2bcff507db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44302)\u001b[0m     @     0x7f2bcff538f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44302)\u001b[0m     @     0x7f2bcff53ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44313)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44313)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44313)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44313)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44313)\u001b[0m *** SIGSEGV (@0x0) received by PID 44313 (TID 0x7f4c94351700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44313)\u001b[0m     @     0x7f4c93f2a390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44313)\u001b[0m     @     0x7f1d93eb6f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44313)\u001b[0m     @     0x7f1d935e17db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44313)\u001b[0m     @     0x7f1d935e48f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44309)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44309)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44309)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44309)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44309)\u001b[0m *** SIGSEGV (@0x0) received by PID 44309 (TID 0x7fc3af201700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44265)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44265)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44265)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44265)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44265)\u001b[0m *** SIGSEGV (@0x0) received by PID 44265 (TID 0x7f3abb733700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44265)\u001b[0m     @     0x7f3abb30c390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44265)\u001b[0m     @     0x7f0bbb229f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44265)\u001b[0m     @     0x7f0bba9547db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44240)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44240)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44240)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44240)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44240)\u001b[0m *** SIGSEGV (@0x0) received by PID 44240 (TID 0x7feb68de4700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44240)\u001b[0m     @     0x7feb689bd390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44240)\u001b[0m     @     0x7fbc68774f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44240)\u001b[0m     @     0x7fbc67e9f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44312)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44312)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44312)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44312)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44312)\u001b[0m *** SIGSEGV (@0x0) received by PID 44312 (TID 0x7efe56de6700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44312)\u001b[0m     @     0x7efe569bf390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44312)\u001b[0m     @     0x7ecf5694cf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44312)\u001b[0m     @     0x7ecf560777db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44324)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44324)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44324)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44324)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44324)\u001b[0m *** SIGSEGV (@0x0) received by PID 44324 (TID 0x7fe364941700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44324)\u001b[0m     @     0x7fe36451a390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44324)\u001b[0m     @     0x7fb4643e3f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44324)\u001b[0m     @     0x7fb463b0e7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44353)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44353)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44353)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44276)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44276)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44276)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44276)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44276)\u001b[0m *** SIGSEGV (@0x0) received by PID 44276 (TID 0x7fae68b3b700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44276)\u001b[0m     @     0x7fae68714390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44276)\u001b[0m     @     0x7f7f68563f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44276)\u001b[0m     @     0x7f7f67c8e7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44267)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44267)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44267)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44255)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44255)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44255)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44255)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44255)\u001b[0m *** SIGSEGV (@0x0) received by PID 44255 (TID 0x7f6d7f531700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44255)\u001b[0m     @     0x7f6d7f10a390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44255)\u001b[0m     @     0x7f3e7f083f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44255)\u001b[0m     @     0x7f3e7e7ae7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44326)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44326)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44326)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44326)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44262)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44262)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44262)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44262)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44262)\u001b[0m *** SIGSEGV (@0x0) received by PID 44262 (TID 0x7f388f232700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44262)\u001b[0m     @     0x7f388ee0b390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44262)\u001b[0m     @     0x7f098edb0f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44262)\u001b[0m     @     0x7f098e4db7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44300)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44300)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44300)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44300)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44300)\u001b[0m *** SIGSEGV (@0x0) received by PID 44300 (TID 0x7f0f353c0700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44300)\u001b[0m     @     0x7f0f34f99390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44300)\u001b[0m     @     0x7ee034ea4f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44300)\u001b[0m     @     0x7ee0345cf7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44350)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44350)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44350)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44350)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44350)\u001b[0m *** SIGSEGV (@0x0) received by PID 44350 (TID 0x7fca2849b700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44256)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44256)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44256)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44256)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44256)\u001b[0m *** SIGSEGV (@0x0) received by PID 44256 (TID 0x7f43143cd700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44256)\u001b[0m     @     0x7f4313fa6390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44256)\u001b[0m     @     0x7f1413e0bf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44256)\u001b[0m     @     0x7f14135367db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44338)\u001b[0m     @     0x7f1c0bb11d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44338)\u001b[0m     @     0x7f1c0c3f4b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44338)\u001b[0m     @     0x7f1c0c417c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44338)\u001b[0m     @     0x7f1c0b8b9a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44338)\u001b[0m     @     0x7f1c0b8b7388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44258)\u001b[0m     @     0x7f8f2faf5f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44258)\u001b[0m     @     0x7f8f2f2207db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44258)\u001b[0m     @     0x7f8f2f2238f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44258)\u001b[0m     @     0x7f8f2f223ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44366)\u001b[0m     @     0x7fb73782e390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44366)\u001b[0m     @     0x7f88377a9f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44366)\u001b[0m     @     0x7f8836ed47db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44366)\u001b[0m     @     0x7f8836ed78f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44366)\u001b[0m     @     0x7f8836ed7ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44247)\u001b[0m     @     0x7fa3ddb7f390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44247)\u001b[0m     @     0x7f74dda0af90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44247)\u001b[0m     @     0x7f74dd1357db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44247)\u001b[0m     @     0x7f74dd1388f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44238)\u001b[0m     @     0x7f45a30bf390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44238)\u001b[0m     @     0x7f16a3052f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44238)\u001b[0m     @     0x7f16a277d7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44238)\u001b[0m     @     0x7f16a27808f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44339)\u001b[0m     @     0x7f05ea53ea93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44339)\u001b[0m     @     0x7f05ea53c388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44339)\u001b[0m     @     0x7f05ea53e5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44339)\u001b[0m     @     0x7f05eac294f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44339)\u001b[0m     @     0x7f05ed0fc8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44335)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44335)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44335)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44335)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44335)\u001b[0m *** SIGSEGV (@0x0) received by PID 44335 (TID 0x7f6ba8848700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44335)\u001b[0m     @     0x7f6ba8421390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44335)\u001b[0m     @     0x7f3ca82def90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44335)\u001b[0m     @     0x7f3ca7a097db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44264)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44264)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44264)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44264)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44264)\u001b[0m *** SIGSEGV (@0x0) received by PID 44264 (TID 0x7f77b9294700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44264)\u001b[0m     @     0x7f77b8e6d390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44264)\u001b[0m     @     0x7f48b8e12f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44264)\u001b[0m     @     0x7f48b853d7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44308)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44308)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44308)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44308)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44308)\u001b[0m *** SIGSEGV (@0x0) received by PID 44308 (TID 0x7f401238e700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44308)\u001b[0m     @     0x7f4011f67390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44308)\u001b[0m     @     0x7f1111e24f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44308)\u001b[0m     @     0x7f111154f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44316)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44316)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44316)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44316)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44316)\u001b[0m *** SIGSEGV (@0x0) received by PID 44316 (TID 0x7f2cf64e6700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44316)\u001b[0m     @     0x7f2cf60bf390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44316)\u001b[0m     @     0x7efdf604df90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44250)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44250)\u001b[0m *** SIGSEGV (@0x0) received by PID 44250 (TID 0x7f0edb8b4700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44250)\u001b[0m     @     0x7f0edb48d390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44250)\u001b[0m     @     0x7edfdb229f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44250)\u001b[0m     @     0x7edfda9547db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44250)\u001b[0m     @     0x7edfda9578f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44250)\u001b[0m     @     0x7edfda957ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44319)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44319)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44319)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44319)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44319)\u001b[0m *** SIGSEGV (@0x0) received by PID 44319 (TID 0x7f7c23691700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44244)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44244)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44244)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44244)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44244)\u001b[0m *** SIGSEGV (@0x0) received by PID 44244 (TID 0x7fb914550700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44244)\u001b[0m     @     0x7fb914129390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44275)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44275)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44275)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44275)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44275)\u001b[0m *** SIGSEGV (@0x0) received by PID 44275 (TID 0x7f8e13001700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44275)\u001b[0m     @     0x7f8e12bda390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44275)\u001b[0m     @     0x7f5f12a21f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44275)\u001b[0m     @     0x7f5f1214c7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44275)\u001b[0m     @     0x7f5f1214f8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44358)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44358)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44358)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44358)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44358)\u001b[0m *** SIGSEGV (@0x0) received by PID 44358 (TID 0x7fdc6c709700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44358)\u001b[0m     @     0x7fdc6c2e2390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44358)\u001b[0m     @     0x7fad6c263f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44358)\u001b[0m     @     0x7fad6b98e7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44358)\u001b[0m     @     0x7fad6b9918f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44254)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44254)\u001b[0m *** SIGSEGV (@0x0) received by PID 44254 (TID 0x7f8f73ac2700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44254)\u001b[0m     @     0x7f8f7369b390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44254)\u001b[0m     @     0x7f607361ff90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44254)\u001b[0m     @     0x7f6072d4a7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44254)\u001b[0m     @     0x7f6072d4d8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44254)\u001b[0m     @     0x7f6072d4dad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44239)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44239)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44239)\u001b[0m *** Aborted at 1604573058 (unix time) try \"date -d @1604573058\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=44239)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44239)\u001b[0m *** SIGSEGV (@0x0) received by PID 44239 (TID 0x7fae86616700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44239)\u001b[0m     @     0x7fae861ef390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44239)\u001b[0m     @     0x7f7f8613af90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44239)\u001b[0m     @     0x7f7f858657db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44249)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44249)\u001b[0m *** SIGSEGV (@0x0) received by PID 44249 (TID 0x7f1f70b97700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44249)\u001b[0m     @     0x7f1f70770390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44249)\u001b[0m     @     0x7ef07071ff90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44249)\u001b[0m     @     0x7ef06fe4a7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44249)\u001b[0m     @     0x7ef06fe4d8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44249)\u001b[0m     @     0x7ef06fe4dad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44242)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44242)\u001b[0m *** SIGSEGV (@0x0) received by PID 44242 (TID 0x7f3cb90fb700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44242)\u001b[0m     @     0x7f3cb8cd4390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44242)\u001b[0m     @     0x7f0db8bd1f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44242)\u001b[0m     @     0x7f0db82fc7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44242)\u001b[0m     @     0x7f0db82ff8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44242)\u001b[0m     @     0x7f0db82ffad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44331)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44331)\u001b[0m *** SIGSEGV (@0x0) received by PID 44331 (TID 0x7f3464fcb700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44331)\u001b[0m     @     0x7f3464ba4390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44331)\u001b[0m     @     0x7f0564b3bf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44331)\u001b[0m     @     0x7f05642667db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44331)\u001b[0m     @     0x7f05642698f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44331)\u001b[0m     @     0x7f0564269ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44260)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44260)\u001b[0m *** SIGSEGV (@0x0) received by PID 44260 (TID 0x7f5b4b85d700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44260)\u001b[0m     @     0x7f5b4b436390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44260)\u001b[0m     @     0x7f2c4b229f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44260)\u001b[0m     @     0x7f2c4a9547db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44260)\u001b[0m     @     0x7f2c4a9578f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44260)\u001b[0m     @     0x7f2c4a957ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44314)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44314)\u001b[0m *** SIGSEGV (@0x0) received by PID 44314 (TID 0x7f0203dac700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44314)\u001b[0m     @     0x7f0203985390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44314)\u001b[0m     @     0x7ed3038def90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44314)\u001b[0m     @     0x7ed3030097db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44314)\u001b[0m     @     0x7ed30300c8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44322)\u001b[0m     @     0x7fce4421d390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44322)\u001b[0m     @     0x7f9f4401cf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44322)\u001b[0m     @     0x7f9f437477db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44322)\u001b[0m     @     0x7f9f4374a8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44322)\u001b[0m     @     0x7f9f4374aad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44307)\u001b[0m     @     0x7fa9d8e4b390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44307)\u001b[0m     @     0x7f7ad8de4f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44307)\u001b[0m     @     0x7f7ad850f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44307)\u001b[0m     @     0x7f7ad85128f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44307)\u001b[0m     @     0x7f7ad8512ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44257)\u001b[0m     @     0x7f19a233e8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44257)\u001b[0m     @     0x7f19a233ead3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44257)\u001b[0m     @     0x7f19a233ed91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44311)\u001b[0m     @     0x7f9345e7c8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44311)\u001b[0m     @     0x7f9345e7cad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44243)\u001b[0m     @     0x7f7e183a28f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44243)\u001b[0m     @     0x7f7e183a2ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44304)\u001b[0m     @     0x7f9d5e9b5390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44304)\u001b[0m     @     0x7f6e5e70af90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44304)\u001b[0m     @     0x7f6e5de357db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44304)\u001b[0m     @     0x7f6e5de388f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44266)\u001b[0m     @     0x7f1b702ff8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44266)\u001b[0m     @     0x7f1b702ffad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44352)\u001b[0m     @     0x7f4635e24f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44352)\u001b[0m     @     0x7f463554f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44352)\u001b[0m     @     0x7f46355528f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44317)\u001b[0m *** SIGSEGV (@0x0) received by PID 44317 (TID 0x7f4f47005700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44317)\u001b[0m     @     0x7f4f46bde390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44317)\u001b[0m     @     0x7f2046a21f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44317)\u001b[0m     @     0x7f204614c7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44354)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44354)\u001b[0m *** SIGSEGV (@0x0) received by PID 44354 (TID 0x7f3d6d78f700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44354)\u001b[0m     @     0x7f3d6d368390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44354)\u001b[0m     @     0x7f0e6d2fcf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44354)\u001b[0m     @     0x7f0e6ca277db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44274)\u001b[0m     @     0x7fca76dd97db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44274)\u001b[0m     @     0x7fca76ddc8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44274)\u001b[0m     @     0x7fca76ddcad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44296)\u001b[0m     @     0x7f50348948f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44296)\u001b[0m     @     0x7f5034894ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44341)\u001b[0m     @     0x7f93243df8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44341)\u001b[0m     @     0x7f9321f0c4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44341)\u001b[0m     @     0x7f9327fb779f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44341)\u001b[0m     @     0x5645fbaeffd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44341)\u001b[0m     @     0x5645fba4ab08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44341)\u001b[0m     @     0x5645fbad5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44341)\u001b[0m     @     0x5645fbad6a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44341)\u001b[0m     @     0x5645fba4abfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44341)\u001b[0m     @     0x5645fbad5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44341)\u001b[0m     @     0x5645fbad6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44341)\u001b[0m     @     0x5645fba4b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44341)\u001b[0m     @     0x5645fbad5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44341)\u001b[0m     @     0x5645fbad6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44341)\u001b[0m     @     0x5645fba4b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44341)\u001b[0m     @     0x5645fbad5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44341)\u001b[0m     @     0x5645fbad6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44341)\u001b[0m     @     0x5645fba4b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44341)\u001b[0m     @     0x5645fbad5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44341)\u001b[0m     @     0x5645fbad6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44341)\u001b[0m     @     0x5645fba4b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44372)\u001b[0m     @     0x7ef1a28bd4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44372)\u001b[0m     @     0x7ef1a4d908de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44372)\u001b[0m     @     0x7ef1a28bd4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44372)\u001b[0m     @     0x7ef1a896879f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44372)\u001b[0m     @     0x55a67ea74fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44372)\u001b[0m     @     0x55a67e9cfb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44372)\u001b[0m     @     0x55a67ea5abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44372)\u001b[0m     @     0x55a67ea5ba20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44372)\u001b[0m     @     0x55a67e9cfbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44372)\u001b[0m     @     0x55a67ea5abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44372)\u001b[0m     @     0x55a67ea5b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44372)\u001b[0m     @     0x55a67e9d0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44241)\u001b[0m     @     0x7ef097f53ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44241)\u001b[0m     @     0x7ef097f53d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44241)\u001b[0m     @     0x7ef098836b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m     @     0x7f1bf3eb88de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m     @     0x7f1bf19e54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m     @     0x7f1bf7a9079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m     @     0x562632c6efd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m     @     0x562632bc9b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m     @     0x562632c54baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m     @     0x562632c55a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m     @     0x562632bc9bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m     @     0x562632c54baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m     @     0x562632c55643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44363)\u001b[0m     @     0x7f4f693bd79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44363)\u001b[0m     @     0x56446f881fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44363)\u001b[0m     @     0x56446f7dcb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44363)\u001b[0m     @     0x56446f867baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44363)\u001b[0m     @     0x56446f868a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44363)\u001b[0m     @     0x56446f7dcbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44363)\u001b[0m     @     0x56446f867baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44363)\u001b[0m     @     0x56446f868643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44363)\u001b[0m     @     0x56446f7dd689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44363)\u001b[0m     @     0x56446f867baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44363)\u001b[0m     @     0x56446f868643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44363)\u001b[0m     @     0x56446f7dd689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44363)\u001b[0m     @     0x56446f867baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44363)\u001b[0m     @     0x56446f868643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44363)\u001b[0m     @     0x56446f7dd689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44363)\u001b[0m     @     0x56446f867baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44363)\u001b[0m     @     0x56446f868643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44363)\u001b[0m     @     0x56446f7dd689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44315)\u001b[0m     @     0x7edbc58215a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44315)\u001b[0m     @     0x7edbc5f0c4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44315)\u001b[0m     @     0x7edbc83df8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44269)\u001b[0m     @     0x7fbb05868ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44269)\u001b[0m     @     0x7fbb05868d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44269)\u001b[0m     @     0x7fbb0614bb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44361)\u001b[0m     @     0x7fa713f615a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44361)\u001b[0m     @     0x7fa71464c4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44361)\u001b[0m     @     0x7fa716b1f8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44334)\u001b[0m     @     0x7ef5d2ffaad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44334)\u001b[0m     @     0x7ef5d2ffad91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44334)\u001b[0m     @     0x7ef5d38ddb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44334)\u001b[0m     @     0x7ef5d3900c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44362)\u001b[0m     @     0x7f269016579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44362)\u001b[0m     @     0x5586f3daefd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44362)\u001b[0m     @     0x5586f3d09b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44362)\u001b[0m     @     0x5586f3d94baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44362)\u001b[0m     @     0x5586f3d95a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44362)\u001b[0m     @     0x5586f3d09bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44362)\u001b[0m     @     0x5586f3d94baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44362)\u001b[0m     @     0x5586f3d95643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44362)\u001b[0m     @     0x5586f3d0a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44362)\u001b[0m     @     0x5586f3d94baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44362)\u001b[0m     @     0x5586f3d95643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44362)\u001b[0m     @     0x5586f3d0a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44362)\u001b[0m     @     0x5586f3d94baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44362)\u001b[0m     @     0x5586f3d95643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44362)\u001b[0m     @     0x5586f3d0a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44362)\u001b[0m     @     0x5586f3d94baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44362)\u001b[0m     @     0x5586f3d95643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44362)\u001b[0m     @     0x5586f3d0a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "2020-11-05 10:44:18,158\tWARNING worker.py:945 -- The driver may not be able to keep up with the stdout/stderr of the workers. To avoid forwarding logs to the driver, use 'ray.init(log_to_driver=False)'.\n",
+      "\u001b[2m\u001b[36m(pid=44329)\u001b[0m     @     0x7eeff86fc4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44329)\u001b[0m     @     0x7eeffabcf8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44329)\u001b[0m     @     0x7eeff86fc4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44329)\u001b[0m     @     0x7eeffe7a779f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44329)\u001b[0m     @     0x5614b6335fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44329)\u001b[0m     @     0x5614b6290b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44329)\u001b[0m     @     0x5614b631bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44329)\u001b[0m     @     0x5614b631ca20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44329)\u001b[0m     @     0x5614b6290bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44329)\u001b[0m     @     0x5614b631bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44329)\u001b[0m     @     0x5614b631c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44329)\u001b[0m     @     0x5614b6291689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44329)\u001b[0m     @     0x5614b631bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44329)\u001b[0m     @     0x5614b631c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44329)\u001b[0m     @     0x5614b6291689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44329)\u001b[0m     @     0x5614b631bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44343)\u001b[0m     @     0x7f4cd81244f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44343)\u001b[0m     @     0x7f4cde1cf79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44343)\u001b[0m     @     0x5570b67e2fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44343)\u001b[0m     @     0x5570b673db08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44343)\u001b[0m     @     0x5570b67c8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44343)\u001b[0m     @     0x5570b67c9a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44343)\u001b[0m     @     0x5570b673dbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44343)\u001b[0m     @     0x5570b67c8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44343)\u001b[0m     @     0x5570b67c9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44343)\u001b[0m     @     0x5570b673e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44343)\u001b[0m     @     0x5570b67c8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44343)\u001b[0m     @     0x5570b67c9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44343)\u001b[0m     @     0x5570b673e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44343)\u001b[0m     @     0x5570b67c8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44343)\u001b[0m     @     0x5570b67c9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44343)\u001b[0m     @     0x5570b673e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44343)\u001b[0m     @     0x5570b67c8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44343)\u001b[0m     @     0x5570b67c9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44343)\u001b[0m     @     0x5570b673e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44246)\u001b[0m     @     0x7fb681552d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44246)\u001b[0m     @     0x7fb681e35b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44246)\u001b[0m     @     0x7fb681e58c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44246)\u001b[0m     @     0x7fb6812faa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44246)\u001b[0m     @     0x7fb6812f8388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44310)\u001b[0m     @     0x7f55663cd8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44310)\u001b[0m     @     0x7f5563efa4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44310)\u001b[0m     @     0x7f5569fa579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44310)\u001b[0m     @     0x5605474d5fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44310)\u001b[0m     @     0x560547430b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44310)\u001b[0m     @     0x5605474bbbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44310)\u001b[0m     @     0x5605474bca20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44310)\u001b[0m     @     0x560547430bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44310)\u001b[0m     @     0x5605474bbbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44310)\u001b[0m     @     0x5605474bc643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44310)\u001b[0m     @     0x560547431689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44310)\u001b[0m     @     0x5605474bbbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44310)\u001b[0m     @     0x5605474bc643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44310)\u001b[0m     @     0x560547431689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44310)\u001b[0m     @     0x5605474bbbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44310)\u001b[0m     @     0x5605474bc643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44310)\u001b[0m     @     0x560547431689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44310)\u001b[0m     @     0x5605474bbbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44310)\u001b[0m     @     0x5605474bc643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44310)\u001b[0m     @     0x560547431689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44297)\u001b[0m     @     0x7f42649e58f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44297)\u001b[0m     @     0x7f42649e5ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44297)\u001b[0m     @     0x7f42649e5d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44297)\u001b[0m     @     0x7f42652c8b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44297)\u001b[0m     @     0x7f42652ebc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44318)\u001b[0m     @     0x7ee76ef69ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44318)\u001b[0m     @     0x7ee76ef69d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44318)\u001b[0m     @     0x7ee76f84cb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44318)\u001b[0m     @     0x7ee76f86fc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44320)\u001b[0m     @     0x7f2a661d2d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44320)\u001b[0m     @     0x7f2a66ab5b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44320)\u001b[0m     @     0x7f2a66ad8c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44320)\u001b[0m     @     0x7f2a65f7aa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44320)\u001b[0m     @     0x7f2a65f78388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44320)\u001b[0m     @     0x7f2a65f7a5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44259)\u001b[0m     @     0x7ed64a957ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44259)\u001b[0m     @     0x7ed64a957d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44259)\u001b[0m     @     0x7ed64b23ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44259)\u001b[0m     @     0x7ed64b25dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44259)\u001b[0m     @     0x7ed64a6ffa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44251)\u001b[0m     @     0x7f2e0da798f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44251)\u001b[0m     @     0x7f2e0da79ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44251)\u001b[0m     @     0x7f2e0da79d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44251)\u001b[0m     @     0x7f2e0e35cb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44251)\u001b[0m     @     0x7f2e0e37fc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44348)\u001b[0m     @     0x7fbeb66924f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44348)\u001b[0m     @     0x7fbebc73d79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44348)\u001b[0m     @     0x555e01d07fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44348)\u001b[0m     @     0x555e01c62b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44348)\u001b[0m     @     0x555e01cedbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44348)\u001b[0m     @     0x555e01ceea20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44348)\u001b[0m     @     0x555e01c62bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44348)\u001b[0m     @     0x555e01cedbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44348)\u001b[0m     @     0x555e01cee643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44348)\u001b[0m     @     0x555e01c63689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44348)\u001b[0m     @     0x555e01cedbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44348)\u001b[0m     @     0x555e01cee643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44348)\u001b[0m     @     0x555e01c63689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44348)\u001b[0m     @     0x555e01cedbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44348)\u001b[0m     @     0x555e01cee643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44348)\u001b[0m     @     0x555e01c63689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44348)\u001b[0m     @     0x555e01cedbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44348)\u001b[0m     @     0x555e01cee643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44348)\u001b[0m     @     0x555e01c63689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44346)\u001b[0m     @     0x7ee2a99cf5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44346)\u001b[0m     @     0x7ee2aa0ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44346)\u001b[0m     @     0x7ee2ac58d8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44346)\u001b[0m     @     0x7ee2aa0ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44346)\u001b[0m     @     0x7ee2b016579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44346)\u001b[0m     @     0x55e93fc84fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44346)\u001b[0m     @     0x55e93fbdfb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44346)\u001b[0m     @     0x55e93fc6abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44346)\u001b[0m     @     0x55e93fc6ba20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44346)\u001b[0m     @     0x55e93fbdfbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44346)\u001b[0m     @     0x55e93fc6abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44346)\u001b[0m     @     0x55e93fc6b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44346)\u001b[0m     @     0x55e93fbe0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44346)\u001b[0m     @     0x55e93fc6abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44346)\u001b[0m     @     0x55e93fc6b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44346)\u001b[0m     @     0x55e93fbe0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44346)\u001b[0m     @     0x55e93fc6abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44321)\u001b[0m     @     0x7f72bc64c4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44321)\u001b[0m     @     0x7f72c26f779f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44321)\u001b[0m     @     0x5639f1a98fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44321)\u001b[0m     @     0x5639f19f3b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44321)\u001b[0m     @     0x5639f1a7ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44321)\u001b[0m     @     0x5639f1a7fa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44321)\u001b[0m     @     0x5639f19f3bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44321)\u001b[0m     @     0x5639f1a7ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44321)\u001b[0m     @     0x5639f1a7f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44321)\u001b[0m     @     0x5639f19f4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44321)\u001b[0m     @     0x5639f1a7ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44321)\u001b[0m     @     0x5639f1a7f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44321)\u001b[0m     @     0x5639f19f4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44321)\u001b[0m     @     0x5639f1a7ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44321)\u001b[0m     @     0x5639f1a7f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44321)\u001b[0m     @     0x5639f19f4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44321)\u001b[0m     @     0x5639f1a7ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44321)\u001b[0m     @     0x5639f1a7f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44321)\u001b[0m     @     0x5639f19f4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44252)\u001b[0m     @     0x7f697a5c1ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44252)\u001b[0m     @     0x7f697a5c1d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44252)\u001b[0m     @     0x7f697aea4b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44252)\u001b[0m     @     0x7f697aec7c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44252)\u001b[0m     @     0x7f697a369a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44252)\u001b[0m     @     0x7f697a367388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44325)\u001b[0m     @     0x55c06ec31643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44325)\u001b[0m     @     0x55c06eba6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44325)\u001b[0m     @     0x55c06ec30baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44325)\u001b[0m     @     0x55c06ec31643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44325)\u001b[0m     @     0x55c06eba6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44325)\u001b[0m     @     0x55c06ec30baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44325)\u001b[0m     @     0x55c06ec31643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44325)\u001b[0m     @     0x55c06eba6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44345)\u001b[0m     @     0x7f082fc8e4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44345)\u001b[0m     @     0x7f0835d3979f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44345)\u001b[0m     @     0x557a1e24dfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44345)\u001b[0m     @     0x557a1e1a8b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44345)\u001b[0m     @     0x557a1e233baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44345)\u001b[0m     @     0x557a1e234a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44345)\u001b[0m     @     0x557a1e1a8bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44345)\u001b[0m     @     0x557a1e233baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44345)\u001b[0m     @     0x557a1e234643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44345)\u001b[0m     @     0x557a1e1a9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44345)\u001b[0m     @     0x557a1e233baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44345)\u001b[0m     @     0x557a1e234643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44345)\u001b[0m     @     0x557a1e1a9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44345)\u001b[0m     @     0x557a1e233baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44345)\u001b[0m     @     0x557a1e234643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44345)\u001b[0m     @     0x557a1e1a9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44345)\u001b[0m     @     0x557a1e233baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44345)\u001b[0m     @     0x557a1e234643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44345)\u001b[0m     @     0x557a1e1a9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44349)\u001b[0m     @     0x7f6bc0a654f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44349)\u001b[0m     @     0x7f6bc2f388de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44349)\u001b[0m     @     0x7f6bc0a654f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44349)\u001b[0m     @     0x7f6bc6b1079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44349)\u001b[0m     @     0x558c4d54bfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44349)\u001b[0m     @     0x558c4d4a6b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44349)\u001b[0m     @     0x558c4d531baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44349)\u001b[0m     @     0x558c4d532a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44349)\u001b[0m     @     0x558c4d4a6bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44349)\u001b[0m     @     0x558c4d531baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44349)\u001b[0m     @     0x558c4d532643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44349)\u001b[0m     @     0x558c4d4a7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44349)\u001b[0m     @     0x558c4d531baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44349)\u001b[0m     @     0x558c4d532643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44349)\u001b[0m     @     0x558c4d4a7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44349)\u001b[0m     @     0x558c4d531baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44349)\u001b[0m     @     0x558c4d532643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44349)\u001b[0m     @     0x558c4d4a7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44349)\u001b[0m     @     0x558c4d531baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44349)\u001b[0m     @     0x558c4d532643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44349)\u001b[0m     @     0x558c4d4a7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44330)\u001b[0m     @     0x7f86959e54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44330)\u001b[0m     @     0x7f869ba9079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44330)\u001b[0m     @     0x55dcdb33dfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44330)\u001b[0m     @     0x55dcdb298b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44330)\u001b[0m     @     0x55dcdb323baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44330)\u001b[0m     @     0x55dcdb324a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44330)\u001b[0m     @     0x55dcdb298bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44330)\u001b[0m     @     0x55dcdb323baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44330)\u001b[0m     @     0x55dcdb324643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44330)\u001b[0m     @     0x55dcdb299689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44330)\u001b[0m     @     0x55dcdb323baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44330)\u001b[0m     @     0x55dcdb324643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44330)\u001b[0m     @     0x55dcdb299689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44330)\u001b[0m     @     0x55dcdb323baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44330)\u001b[0m     @     0x55dcdb324643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44330)\u001b[0m     @     0x55dcdb299689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44330)\u001b[0m     @     0x55dcdb323baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44330)\u001b[0m     @     0x55dcdb324643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44330)\u001b[0m     @     0x55dcdb299689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44355)\u001b[0m     @     0x7f69e4e0b4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44355)\u001b[0m     @     0x7f69e72de8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44355)\u001b[0m     @     0x7f69e4e0b4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44355)\u001b[0m     @     0x7f69eaeb679f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44355)\u001b[0m     @     0x55cca6ed8fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44355)\u001b[0m     @     0x55cca6e33b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44355)\u001b[0m     @     0x55cca6ebebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44355)\u001b[0m     @     0x55cca6ebfa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44355)\u001b[0m     @     0x55cca6e33bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44355)\u001b[0m     @     0x55cca6ebebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44355)\u001b[0m     @     0x55cca6ebf643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44355)\u001b[0m     @     0x55cca6e34689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44355)\u001b[0m     @     0x55cca6ebebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44355)\u001b[0m     @     0x55cca6ebf643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44355)\u001b[0m     @     0x55cca6e34689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44355)\u001b[0m     @     0x55cca6ebebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44355)\u001b[0m     @     0x55cca6ebf643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44355)\u001b[0m     @     0x55cca6e34689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44355)\u001b[0m     @     0x55cca6ebebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44355)\u001b[0m     @     0x55cca6ebf643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44355)\u001b[0m     @     0x55cca6e34689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44245)\u001b[0m     @     0x7fa34ad1dad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44245)\u001b[0m     @     0x7fa34ad1dd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44245)\u001b[0m     @     0x7fa34b600b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44245)\u001b[0m     @     0x7fa34b623c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44245)\u001b[0m     @     0x7fa34aac5a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44302)\u001b[0m     @     0x7f2bcff53d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44302)\u001b[0m     @     0x7f2bd0836b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44302)\u001b[0m     @     0x7f2bd0859c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44302)\u001b[0m     @     0x7f2bcfcfba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44302)\u001b[0m     @     0x7f2bcfcf9388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44313)\u001b[0m     @     0x7f1d935e4ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44313)\u001b[0m     @     0x7f1d935e4d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44313)\u001b[0m     @     0x7f1d93ec7b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44313)\u001b[0m     @     0x7f1d93eeac1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44313)\u001b[0m     @     0x7f1d9338ca93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44313)\u001b[0m     @     0x7f1d9338a388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44309)\u001b[0m     @     0x7fc3aedda390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44309)\u001b[0m     @     0x7f94aed5ef90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44309)\u001b[0m     @     0x7f94ae4897db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44309)\u001b[0m     @     0x7f94ae48c8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44309)\u001b[0m     @     0x7f94ae48cad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44265)\u001b[0m     @     0x7f0bba9578f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44265)\u001b[0m     @     0x7f0bba957ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44265)\u001b[0m     @     0x7f0bba957d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44265)\u001b[0m     @     0x7f0bbb23ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44265)\u001b[0m     @     0x7f0bbb25dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44240)\u001b[0m     @     0x7fbc67ea28f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44240)\u001b[0m     @     0x7fbc67ea2ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44240)\u001b[0m     @     0x7fbc67ea2d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44240)\u001b[0m     @     0x7fbc68785b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44312)\u001b[0m     @     0x7ecf5607a8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44312)\u001b[0m     @     0x7ecf5607aad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44312)\u001b[0m     @     0x7ecf5607ad91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44312)\u001b[0m     @     0x7ecf5695db22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44312)\u001b[0m     @     0x7ecf56980c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44324)\u001b[0m     @     0x7fb463b118f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44324)\u001b[0m     @     0x7fb463b11ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44324)\u001b[0m     @     0x7fb463b11d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44324)\u001b[0m     @     0x7fb4643f4b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44324)\u001b[0m     @     0x7fb464417c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44353)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44353)\u001b[0m *** SIGSEGV (@0x0) received by PID 44353 (TID 0x7fb4ad9aa700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44353)\u001b[0m     @     0x7fb4ad583390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44353)\u001b[0m     @     0x7f85ad4e3f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44353)\u001b[0m     @     0x7f85acc0e7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44353)\u001b[0m     @     0x7f85acc118f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44276)\u001b[0m     @     0x7f7f67c918f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44276)\u001b[0m     @     0x7f7f67c91ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44276)\u001b[0m     @     0x7f7f67c91d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44276)\u001b[0m     @     0x7f7f68574b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44276)\u001b[0m     @     0x7f7f68597c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44267)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44267)\u001b[0m *** SIGSEGV (@0x0) received by PID 44267 (TID 0x7ff4a1367700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44267)\u001b[0m     @     0x7ff4a0f40390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44267)\u001b[0m     @     0x7fc5a0ea4f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44267)\u001b[0m     @     0x7fc5a05cf7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44267)\u001b[0m     @     0x7fc5a05d28f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44255)\u001b[0m     @     0x7f3e7e7b18f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44255)\u001b[0m     @     0x7f3e7e7b1ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44255)\u001b[0m     @     0x7f3e7e7b1d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44255)\u001b[0m     @     0x7f3e7f094b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44255)\u001b[0m     @     0x7f3e7f0b7c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44326)\u001b[0m *** SIGSEGV (@0x0) received by PID 44326 (TID 0x7f9bfb0d7700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=44326)\u001b[0m     @     0x7f9bfacb0390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44326)\u001b[0m     @     0x7f6cfaad1f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44262)\u001b[0m     @     0x7f098e4de8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44262)\u001b[0m     @     0x7f098e4dead3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44262)\u001b[0m     @     0x7f098e4ded91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44262)\u001b[0m     @     0x7f098edc1b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44262)\u001b[0m     @     0x7f098ede4c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44300)\u001b[0m     @     0x7ee0345d28f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44300)\u001b[0m     @     0x7ee0345d2ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44300)\u001b[0m     @     0x7ee0345d2d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44300)\u001b[0m     @     0x7ee034eb5b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44300)\u001b[0m     @     0x7ee034ed8c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44350)\u001b[0m     @     0x7fca28074390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44350)\u001b[0m     @     0x7f9b28014f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44350)\u001b[0m     @     0x7f9b2773f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44256)\u001b[0m     @     0x7f14135398f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44256)\u001b[0m     @     0x7f1413539ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44256)\u001b[0m     @     0x7f1413539d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44256)\u001b[0m     @     0x7f1413e1cb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44256)\u001b[0m     @     0x7f1413e3fc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44256)\u001b[0m     @     0x7f14132e1a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44256)\u001b[0m     @     0x7f14132df388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44338)\u001b[0m     @     0x7f1c0b8b95a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44338)\u001b[0m     @     0x7f1c0bfa44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44338)\u001b[0m     @     0x7f1c0e4778de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44338)\u001b[0m     @     0x7f1c0bfa44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44338)\u001b[0m     @     0x7f1c1204f79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44338)\u001b[0m     @     0x55c778bbffd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44338)\u001b[0m     @     0x55c778b1ab08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44338)\u001b[0m     @     0x55c778ba5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44338)\u001b[0m     @     0x55c778ba6a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44338)\u001b[0m     @     0x55c778b1abfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44338)\u001b[0m     @     0x55c778ba5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44338)\u001b[0m     @     0x55c778ba6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44338)\u001b[0m     @     0x55c778b1b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44338)\u001b[0m     @     0x55c778ba5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44338)\u001b[0m     @     0x55c778ba6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44338)\u001b[0m     @     0x55c778b1b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44338)\u001b[0m     @     0x55c778ba5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44338)\u001b[0m     @     0x55c778ba6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44338)\u001b[0m     @     0x55c778b1b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44338)\u001b[0m     @     0x55c778ba5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44338)\u001b[0m     @     0x55c778ba6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44338)\u001b[0m     @     0x55c778b1b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44258)\u001b[0m     @     0x7f8f2f223d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44258)\u001b[0m     @     0x7f8f2fb06b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44258)\u001b[0m     @     0x7f8f2fb29c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44258)\u001b[0m     @     0x7f8f2efcba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44258)\u001b[0m     @     0x7f8f2efc9388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44258)\u001b[0m     @     0x7f8f2efcb5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44366)\u001b[0m     @     0x7f8836ed7d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44366)\u001b[0m     @     0x7f88377bab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44366)\u001b[0m     @     0x7f88377ddc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44366)\u001b[0m     @     0x7f8836c7fa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44366)\u001b[0m     @     0x7f8836c7d388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44366)\u001b[0m     @     0x7f8836c7f5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44247)\u001b[0m     @     0x7f74dd138ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44247)\u001b[0m     @     0x7f74dd138d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44247)\u001b[0m     @     0x7f74dda1bb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44247)\u001b[0m     @     0x7f74dda3ec1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44247)\u001b[0m     @     0x7f74dcee0a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44247)\u001b[0m     @     0x7f74dcede388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44238)\u001b[0m     @     0x7f16a2780ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44238)\u001b[0m     @     0x7f16a2780d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44238)\u001b[0m     @     0x7f16a3063b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44238)\u001b[0m     @     0x7f16a3086c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44238)\u001b[0m     @     0x7f16a2528a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44238)\u001b[0m     @     0x7f16a2526388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44238)\u001b[0m     @     0x7f16a25285a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44339)\u001b[0m     @     0x7f05eac294f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44339)\u001b[0m     @     0x7f05f0cd479f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44339)\u001b[0m     @     0x562f8fac1fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44339)\u001b[0m     @     0x562f8fa1cb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44339)\u001b[0m     @     0x562f8faa7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44339)\u001b[0m     @     0x562f8faa8a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44339)\u001b[0m     @     0x562f8fa1cbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44339)\u001b[0m     @     0x562f8faa7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44339)\u001b[0m     @     0x562f8faa8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44339)\u001b[0m     @     0x562f8fa1d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44339)\u001b[0m     @     0x562f8faa7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44339)\u001b[0m     @     0x562f8faa8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44339)\u001b[0m     @     0x562f8fa1d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44339)\u001b[0m     @     0x562f8faa7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44339)\u001b[0m     @     0x562f8faa8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44339)\u001b[0m     @     0x562f8fa1d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44339)\u001b[0m     @     0x562f8faa7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44339)\u001b[0m     @     0x562f8faa8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44339)\u001b[0m     @     0x562f8fa1d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44335)\u001b[0m     @     0x7f3ca7a0c8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44335)\u001b[0m     @     0x7f3ca7a0cad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44335)\u001b[0m     @     0x7f3ca7a0cd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44335)\u001b[0m     @     0x7f3ca82efb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44335)\u001b[0m     @     0x7f3ca8312c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44264)\u001b[0m     @     0x7f48b85408f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44264)\u001b[0m     @     0x7f48b8540ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44264)\u001b[0m     @     0x7f48b8540d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44264)\u001b[0m     @     0x7f48b8e23b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44264)\u001b[0m     @     0x7f48b8e46c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44264)\u001b[0m     @     0x7f48b82e8a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44308)\u001b[0m     @     0x7f11115528f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44308)\u001b[0m     @     0x7f1111552ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44308)\u001b[0m     @     0x7f1111552d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44308)\u001b[0m     @     0x7f1111e35b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44308)\u001b[0m     @     0x7f1111e58c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44308)\u001b[0m     @     0x7f11112faa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44316)\u001b[0m     @     0x7efdf57787db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44250)\u001b[0m     @     0x7edfda957d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44250)\u001b[0m     @     0x7edfdb23ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44250)\u001b[0m     @     0x7edfdb25dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44250)\u001b[0m     @     0x7edfda6ffa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44250)\u001b[0m     @     0x7edfda6fd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44319)\u001b[0m     @     0x7f7c2326a390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=44319)\u001b[0m     @     0x7f4d231fcf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44319)\u001b[0m     @     0x7f4d229277db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44244)\u001b[0m     @     0x7f8a1401cf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=44244)\u001b[0m     @     0x7f8a137477db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44244)\u001b[0m     @     0x7f8a1374a8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44275)\u001b[0m     @     0x7f5f1214fad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44275)\u001b[0m     @     0x7f5f1214fd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44275)\u001b[0m     @     0x7f5f12a32b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44275)\u001b[0m     @     0x7f5f12a55c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44275)\u001b[0m     @     0x7f5f11ef7a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44358)\u001b[0m     @     0x7fad6b991ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44358)\u001b[0m     @     0x7fad6b991d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44358)\u001b[0m     @     0x7fad6c274b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44358)\u001b[0m     @     0x7fad6c297c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44358)\u001b[0m     @     0x7fad6b739a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44358)\u001b[0m     @     0x7fad6b737388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44254)\u001b[0m     @     0x7f6072d4dd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44254)\u001b[0m     @     0x7f6073630b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44254)\u001b[0m     @     0x7f6073653c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44254)\u001b[0m     @     0x7f6072af5a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44254)\u001b[0m     @     0x7f6072af3388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44239)\u001b[0m     @     0x7f7f858688f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44239)\u001b[0m     @     0x7f7f85868ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44239)\u001b[0m     @     0x7f7f85868d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44239)\u001b[0m     @     0x7f7f8614bb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44249)\u001b[0m     @     0x7ef06fe4dd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44249)\u001b[0m     @     0x7ef070730b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44249)\u001b[0m     @     0x7ef070753c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44249)\u001b[0m     @     0x7ef06fbf5a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44242)\u001b[0m     @     0x7f0db82ffd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44242)\u001b[0m     @     0x7f0db8be2b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44242)\u001b[0m     @     0x7f0db8c05c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44242)\u001b[0m     @     0x7f0db80a7a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44242)\u001b[0m     @     0x7f0db80a5388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44331)\u001b[0m     @     0x7f0564269d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44331)\u001b[0m     @     0x7f0564b4cb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44331)\u001b[0m     @     0x7f0564b6fc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44331)\u001b[0m     @     0x7f0564011a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44331)\u001b[0m     @     0x7f056400f388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44331)\u001b[0m     @     0x7f05640115a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44260)\u001b[0m     @     0x7f2c4a957d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44260)\u001b[0m     @     0x7f2c4b23ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44260)\u001b[0m     @     0x7f2c4b25dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44260)\u001b[0m     @     0x7f2c4a6ffa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44260)\u001b[0m     @     0x7f2c4a6fd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44260)\u001b[0m     @     0x7f2c4a6ff5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44314)\u001b[0m     @     0x7ed30300cad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44314)\u001b[0m     @     0x7ed30300cd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44314)\u001b[0m     @     0x7ed3038efb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44314)\u001b[0m     @     0x7ed303912c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44314)\u001b[0m     @     0x7ed302db4a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44314)\u001b[0m     @     0x7ed302db2388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44322)\u001b[0m     @     0x7f9f4374ad91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44322)\u001b[0m     @     0x7f9f4402db22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44322)\u001b[0m     @     0x7f9f44050c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44322)\u001b[0m     @     0x7f9f434f2a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44322)\u001b[0m     @     0x7f9f434f0388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44322)\u001b[0m     @     0x7f9f434f25a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44307)\u001b[0m     @     0x7f7ad8512d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44307)\u001b[0m     @     0x7f7ad8df5b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44307)\u001b[0m     @     0x7f7ad8e18c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44307)\u001b[0m     @     0x7f7ad82baa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44307)\u001b[0m     @     0x7f7ad82b8388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44307)\u001b[0m     @     0x7f7ad82ba5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44257)\u001b[0m     @     0x7f19a2c21b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44257)\u001b[0m     @     0x7f19a2c44c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44257)\u001b[0m     @     0x7f19a20e6a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44257)\u001b[0m     @     0x7f19a20e4388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44257)\u001b[0m     @     0x7f19a20e65a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44257)\u001b[0m     @     0x7f19a27d14f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44311)\u001b[0m     @     0x7f9345e7cd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44311)\u001b[0m     @     0x7f934675fb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44311)\u001b[0m     @     0x7f9346782c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44311)\u001b[0m     @     0x7f9345c24a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44311)\u001b[0m     @     0x7f9345c22388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44311)\u001b[0m     @     0x7f9345c245a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44243)\u001b[0m     @     0x7f7e183a2d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44243)\u001b[0m     @     0x7f7e18c85b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44243)\u001b[0m     @     0x7f7e18ca8c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44304)\u001b[0m     @     0x7f6e5de38ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44304)\u001b[0m     @     0x7f6e5de38d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44304)\u001b[0m     @     0x7f6e5e71bb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44304)\u001b[0m     @     0x7f6e5e73ec1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44304)\u001b[0m     @     0x7f6e5dbe0a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44304)\u001b[0m     @     0x7f6e5dbde388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44266)\u001b[0m     @     0x7f1b702ffd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44266)\u001b[0m     @     0x7f1b70be2b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44266)\u001b[0m     @     0x7f1b70c05c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44266)\u001b[0m     @     0x7f1b700a7a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44266)\u001b[0m     @     0x7f1b700a5388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44266)\u001b[0m     @     0x7f1b700a75a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44266)\u001b[0m     @     0x7f1b707924f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44352)\u001b[0m     @     0x7f4635552ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44352)\u001b[0m     @     0x7f4635552d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44352)\u001b[0m     @     0x7f4635e35b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44352)\u001b[0m     @     0x7f4635e58c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44352)\u001b[0m     @     0x7f46352faa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44352)\u001b[0m     @     0x7f46352f8388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44317)\u001b[0m     @     0x7f204614f8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44317)\u001b[0m     @     0x7f204614fad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44317)\u001b[0m     @     0x7f204614fd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44317)\u001b[0m     @     0x7f2046a32b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44317)\u001b[0m     @     0x7f2046a55c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44317)\u001b[0m     @     0x7f2045ef7a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44317)\u001b[0m     @     0x7f2045ef5388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44354)\u001b[0m     @     0x7f0e6ca2a8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44354)\u001b[0m     @     0x7f0e6ca2aad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44354)\u001b[0m     @     0x7f0e6ca2ad91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44354)\u001b[0m     @     0x7f0e6d30db22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44354)\u001b[0m     @     0x7f0e6d330c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44354)\u001b[0m     @     0x7f0e6c7d2a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44274)\u001b[0m     @     0x7fca76ddcd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44274)\u001b[0m     @     0x7fca776bfb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44274)\u001b[0m     @     0x7fca776e2c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44274)\u001b[0m     @     0x7fca76b84a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44274)\u001b[0m     @     0x7fca76b82388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44274)\u001b[0m     @     0x7fca76b845a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44274)\u001b[0m     @     0x7fca7726f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44296)\u001b[0m     @     0x7f5034894d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44296)\u001b[0m     @     0x7f5035177b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44296)\u001b[0m     @     0x7f503519ac1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44296)\u001b[0m     @     0x7f503463ca93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44296)\u001b[0m     @     0x7f503463a388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44296)\u001b[0m     @     0x7f503463c5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44372)\u001b[0m     @     0x55a67ea5abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44372)\u001b[0m     @     0x55a67ea5b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44372)\u001b[0m     @     0x55a67e9d0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44372)\u001b[0m     @     0x55a67ea5abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44372)\u001b[0m     @     0x55a67ea5b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44372)\u001b[0m     @     0x55a67e9d0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44372)\u001b[0m     @     0x55a67ea5abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44372)\u001b[0m     @     0x55a67ea5b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44372)\u001b[0m     @     0x55a67e9d0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44241)\u001b[0m     @     0x7ef098859c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44241)\u001b[0m     @     0x7ef097cfba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44241)\u001b[0m     @     0x7ef097cf9388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44241)\u001b[0m     @     0x7ef097cfb5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44241)\u001b[0m     @     0x7ef0983e64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m     @     0x562632bca689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m     @     0x562632c54baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m     @     0x562632c55643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m     @     0x562632bca689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m     @     0x562632c54baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m     @     0x562632c55643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m     @     0x562632bca689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m     @     0x562632c54baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m     @     0x562632c55643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m     @     0x562632bca689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44315)\u001b[0m     @     0x7edbc5f0c4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44315)\u001b[0m     @     0x7edbcbfb779f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44315)\u001b[0m     @     0x564d0da77fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44315)\u001b[0m     @     0x564d0d9d2b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44315)\u001b[0m     @     0x564d0da5dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44315)\u001b[0m     @     0x564d0da5ea20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44315)\u001b[0m     @     0x564d0d9d2bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44315)\u001b[0m     @     0x564d0da5dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44315)\u001b[0m     @     0x564d0da5e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44315)\u001b[0m     @     0x564d0d9d3689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44315)\u001b[0m     @     0x564d0da5dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44315)\u001b[0m     @     0x564d0da5e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44315)\u001b[0m     @     0x564d0d9d3689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44315)\u001b[0m     @     0x564d0da5dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44315)\u001b[0m     @     0x564d0da5e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44315)\u001b[0m     @     0x564d0d9d3689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44315)\u001b[0m     @     0x564d0da5dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44315)\u001b[0m     @     0x564d0da5e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44315)\u001b[0m     @     0x564d0d9d3689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44269)\u001b[0m     @     0x7fbb0616ec1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44269)\u001b[0m     @     0x7fbb05610a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44269)\u001b[0m     @     0x7fbb0560e388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44269)\u001b[0m     @     0x7fbb056105a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44269)\u001b[0m     @     0x7fbb05cfb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44361)\u001b[0m     @     0x7fa71464c4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44361)\u001b[0m     @     0x7fa71a6f779f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44361)\u001b[0m     @     0x563b41c44fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44361)\u001b[0m     @     0x563b41b9fb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44361)\u001b[0m     @     0x563b41c2abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44361)\u001b[0m     @     0x563b41c2ba20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44361)\u001b[0m     @     0x563b41b9fbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44361)\u001b[0m     @     0x563b41c2abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44361)\u001b[0m     @     0x563b41c2b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44361)\u001b[0m     @     0x563b41ba0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44361)\u001b[0m     @     0x563b41c2abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44361)\u001b[0m     @     0x563b41c2b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44361)\u001b[0m     @     0x563b41ba0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44361)\u001b[0m     @     0x563b41c2abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44361)\u001b[0m     @     0x563b41c2b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44361)\u001b[0m     @     0x563b41ba0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44361)\u001b[0m     @     0x563b41c2abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44361)\u001b[0m     @     0x563b41c2b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44361)\u001b[0m     @     0x563b41ba0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44334)\u001b[0m     @     0x7ef5d2da2a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44334)\u001b[0m     @     0x7ef5d2da0388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44334)\u001b[0m     @     0x7ef5d2da25a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44334)\u001b[0m     @     0x7ef5d348d4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44334)\u001b[0m     @     0x7ef5d59608de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44329)\u001b[0m     @     0x5614b631c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44329)\u001b[0m     @     0x5614b6291689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44329)\u001b[0m     @     0x5614b631bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44329)\u001b[0m     @     0x5614b631c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44329)\u001b[0m     @     0x5614b6291689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44246)\u001b[0m     @     0x7fb6812fa5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44246)\u001b[0m     @     0x7fb6819e54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44246)\u001b[0m     @     0x7fb683eb88de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44246)\u001b[0m     @     0x7fb6819e54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44297)\u001b[0m     @     0x7f426478da93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44297)\u001b[0m     @     0x7f426478b388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44297)\u001b[0m     @     0x7f426478d5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44297)\u001b[0m     @     0x7f4264e784f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44318)\u001b[0m     @     0x7ee76ed11a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44318)\u001b[0m     @     0x7ee76ed0f388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44318)\u001b[0m     @     0x7ee76ed115a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44318)\u001b[0m     @     0x7ee76f3fc4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44320)\u001b[0m     @     0x7f2a666654f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44320)\u001b[0m     @     0x7f2a68b388de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44320)\u001b[0m     @     0x7f2a666654f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44320)\u001b[0m     @     0x7f2a6c71079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44320)\u001b[0m     @     0x561bbf56dfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44320)\u001b[0m     @     0x561bbf4c8b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44320)\u001b[0m     @     0x561bbf553baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44320)\u001b[0m     @     0x561bbf554a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44320)\u001b[0m     @     0x561bbf4c8bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44320)\u001b[0m     @     0x561bbf553baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44320)\u001b[0m     @     0x561bbf554643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44320)\u001b[0m     @     0x561bbf4c9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44320)\u001b[0m     @     0x561bbf553baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44320)\u001b[0m     @     0x561bbf554643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44320)\u001b[0m     @     0x561bbf4c9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44320)\u001b[0m     @     0x561bbf553baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44320)\u001b[0m     @     0x561bbf554643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44320)\u001b[0m     @     0x561bbf4c9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44320)\u001b[0m     @     0x561bbf553baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44320)\u001b[0m     @     0x561bbf554643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44320)\u001b[0m     @     0x561bbf4c9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44259)\u001b[0m     @     0x7ed64a6fd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44259)\u001b[0m     @     0x7ed64a6ff5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44259)\u001b[0m     @     0x7ed64adea4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44259)\u001b[0m     @     0x7ed64d2bd8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44251)\u001b[0m     @     0x7f2e0d821a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44251)\u001b[0m     @     0x7f2e0d81f388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44251)\u001b[0m     @     0x7f2e0d8215a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44251)\u001b[0m     @     0x7f2e0df0c4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44251)\u001b[0m     @     0x7f2e103df8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44346)\u001b[0m     @     0x55e93fc6b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44346)\u001b[0m     @     0x55e93fbe0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44346)\u001b[0m     @     0x55e93fc6abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44346)\u001b[0m     @     0x55e93fc6b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44346)\u001b[0m     @     0x55e93fbe0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44252)\u001b[0m     @     0x7f697a3695a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44252)\u001b[0m     @     0x7f697aa544f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44252)\u001b[0m     @     0x7f697cf278de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44252)\u001b[0m     @     0x7f697aa544f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44245)\u001b[0m     @     0x7fa34aac3388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44245)\u001b[0m     @     0x7fa34aac55a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44245)\u001b[0m     @     0x7fa34b1b04f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44302)\u001b[0m     @     0x7f2bcfcfb5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44302)\u001b[0m     @     0x7f2bd03e64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44302)\u001b[0m     @     0x7f2bd28b98de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44313)\u001b[0m     @     0x7f1d9338c5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44313)\u001b[0m     @     0x7f1d93a774f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44313)\u001b[0m     @     0x7f1d95f4a8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44309)\u001b[0m     @     0x7f94ae48cd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44309)\u001b[0m     @     0x7f94aed6fb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44309)\u001b[0m     @     0x7f94aed92c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44309)\u001b[0m     @     0x7f94ae234a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44265)\u001b[0m     @     0x7f0bba6ffa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44265)\u001b[0m     @     0x7f0bba6fd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44265)\u001b[0m     @     0x7f0bba6ff5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44240)\u001b[0m     @     0x7fbc687a8c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44240)\u001b[0m     @     0x7fbc67c4aa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44240)\u001b[0m     @     0x7fbc67c48388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44240)\u001b[0m     @     0x7fbc67c4a5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44312)\u001b[0m     @     0x7ecf55e22a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44312)\u001b[0m     @     0x7ecf55e20388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44312)\u001b[0m     @     0x7ecf55e225a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44324)\u001b[0m     @     0x7fb4638b9a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44324)\u001b[0m     @     0x7fb4638b7388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44324)\u001b[0m     @     0x7fb4638b95a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44353)\u001b[0m     @     0x7f85acc11ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44353)\u001b[0m     @     0x7f85acc11d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44353)\u001b[0m     @     0x7f85ad4f4b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44276)\u001b[0m     @     0x7f7f67a39a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44276)\u001b[0m     @     0x7f7f67a37388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44276)\u001b[0m     @     0x7f7f67a395a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44276)\u001b[0m     @     0x7f7f681244f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44267)\u001b[0m     @     0x7fc5a05d2ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44267)\u001b[0m     @     0x7fc5a05d2d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44267)\u001b[0m     @     0x7fc5a0eb5b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44267)\u001b[0m     @     0x7fc5a0ed8c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44255)\u001b[0m     @     0x7f3e7e559a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44255)\u001b[0m     @     0x7f3e7e557388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44255)\u001b[0m     @     0x7f3e7e5595a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44326)\u001b[0m     @     0x7f6cfa1fc7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=44326)\u001b[0m     @     0x7f6cfa1ff8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44262)\u001b[0m     @     0x7f098e286a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44262)\u001b[0m     @     0x7f098e284388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44262)\u001b[0m     @     0x7f098e2865a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44300)\u001b[0m     @     0x7ee03437aa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44300)\u001b[0m     @     0x7ee034378388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44300)\u001b[0m     @     0x7ee03437a5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44350)\u001b[0m     @     0x7f9b277428f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44256)\u001b[0m     @     0x7f14132e15a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44256)\u001b[0m     @     0x7f14139cc4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44256)\u001b[0m     @     0x7f1415e9f8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44258)\u001b[0m     @     0x7f8f2f6b64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44258)\u001b[0m     @     0x7f8f31b898de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44366)\u001b[0m     @     0x7f883736a4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44366)\u001b[0m     @     0x7f883983d8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44247)\u001b[0m     @     0x7f74dcee05a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44247)\u001b[0m     @     0x7f74dd5cb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44247)\u001b[0m     @     0x7f74dfa9e8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44238)\u001b[0m     @     0x7f16a2c134f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44238)\u001b[0m     @     0x7f16a50e68de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44335)\u001b[0m     @     0x7f3ca77b4a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44335)\u001b[0m     @     0x7f3ca77b2388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44335)\u001b[0m     @     0x7f3ca77b45a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44335)\u001b[0m     @     0x7f3ca7e9f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44264)\u001b[0m     @     0x7f48b82e6388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44264)\u001b[0m     @     0x7f48b82e85a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44264)\u001b[0m     @     0x7f48b89d34f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44264)\u001b[0m     @     0x7f48baea68de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44308)\u001b[0m     @     0x7f11112f8388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44308)\u001b[0m     @     0x7f11112fa5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44308)\u001b[0m     @     0x7f11119e54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44308)\u001b[0m     @     0x7f1113eb88de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44316)\u001b[0m     @     0x7efdf577b8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44250)\u001b[0m     @     0x7edfda6ff5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44250)\u001b[0m     @     0x7edfdadea4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44250)\u001b[0m     @     0x7edfdd2bd8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44250)\u001b[0m     @     0x7edfdadea4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44319)\u001b[0m     @     0x7f4d2292a8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44319)\u001b[0m     @     0x7f4d2292aad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44244)\u001b[0m     @     0x7f8a1374aad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44244)\u001b[0m     @     0x7f8a1374ad91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44244)\u001b[0m     @     0x7f8a1402db22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44244)\u001b[0m     @     0x7f8a14050c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44275)\u001b[0m     @     0x7f5f11ef5388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44275)\u001b[0m     @     0x7f5f11ef75a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44275)\u001b[0m     @     0x7f5f125e24f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44275)\u001b[0m     @     0x7f5f14ab58de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44358)\u001b[0m     @     0x7fad6b7395a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44358)\u001b[0m     @     0x7fad6be244f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44358)\u001b[0m     @     0x7fad6e2f78de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44254)\u001b[0m     @     0x7f6072af55a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44254)\u001b[0m     @     0x7f60731e04f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44254)\u001b[0m     @     0x7f60756b38de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44254)\u001b[0m     @     0x7f60731e04f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44239)\u001b[0m     @     0x7f7f8616ec1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44239)\u001b[0m     @     0x7f7f85610a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44239)\u001b[0m     @     0x7f7f8560e388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44239)\u001b[0m     @     0x7f7f856105a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44249)\u001b[0m     @     0x7ef06fbf3388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44249)\u001b[0m     @     0x7ef06fbf55a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44249)\u001b[0m     @     0x7ef0702e04f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44249)\u001b[0m     @     0x7ef0727b38de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44242)\u001b[0m     @     0x7f0db80a75a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44242)\u001b[0m     @     0x7f0db87924f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44242)\u001b[0m     @     0x7f0dbac658de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44331)\u001b[0m     @     0x7f05646fc4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44331)\u001b[0m     @     0x7f0566bcf8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44260)\u001b[0m     @     0x7f2c4adea4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44260)\u001b[0m     @     0x7f2c4d2bd8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44314)\u001b[0m     @     0x7ed302db45a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44314)\u001b[0m     @     0x7ed30349f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44314)\u001b[0m     @     0x7ed3059728de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44322)\u001b[0m     @     0x7f9f43bdd4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44322)\u001b[0m     @     0x7f9f460b08de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44307)\u001b[0m     @     0x7f7ad89a54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44307)\u001b[0m     @     0x7f7adae788de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44257)\u001b[0m     @     0x7f19a4ca48de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44257)\u001b[0m     @     0x7f19a27d14f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44257)\u001b[0m     @     0x7f19a887c79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44257)\u001b[0m     @     0x5653e1aeffd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44257)\u001b[0m     @     0x5653e1a4ab08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44257)\u001b[0m     @     0x5653e1ad5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44257)\u001b[0m     @     0x5653e1ad6a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44257)\u001b[0m     @     0x5653e1a4abfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44257)\u001b[0m     @     0x5653e1ad5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44257)\u001b[0m     @     0x5653e1ad6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44257)\u001b[0m     @     0x5653e1a4b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44257)\u001b[0m     @     0x5653e1ad5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44257)\u001b[0m     @     0x5653e1ad6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44257)\u001b[0m     @     0x5653e1a4b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44257)\u001b[0m     @     0x5653e1ad5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44257)\u001b[0m     @     0x5653e1ad6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44257)\u001b[0m     @     0x5653e1a4b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44257)\u001b[0m     @     0x5653e1ad5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44257)\u001b[0m     @     0x5653e1ad6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44257)\u001b[0m     @     0x5653e1a4b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44311)\u001b[0m     @     0x7f934630f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44311)\u001b[0m     @     0x7f93487e28de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44311)\u001b[0m     @     0x7f934630f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44311)\u001b[0m     @     0x7f934c3ba79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44311)\u001b[0m     @     0x55bbd8a8bfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44311)\u001b[0m     @     0x55bbd89e6b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44243)\u001b[0m     @     0x7f7e1814aa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44243)\u001b[0m     @     0x7f7e18148388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44304)\u001b[0m     @     0x7f6e5dbe05a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44304)\u001b[0m     @     0x7f6e5e2cb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44304)\u001b[0m     @     0x7f6e6079e8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44266)\u001b[0m     @     0x7f1b72c658de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44266)\u001b[0m     @     0x7f1b707924f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44266)\u001b[0m     @     0x7f1b7683d79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44266)\u001b[0m     @     0x556373dbefd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44266)\u001b[0m     @     0x556373d19b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44266)\u001b[0m     @     0x556373da4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44266)\u001b[0m     @     0x556373da5a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44266)\u001b[0m     @     0x556373d19bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44266)\u001b[0m     @     0x556373da4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44266)\u001b[0m     @     0x556373da5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44266)\u001b[0m     @     0x556373d1a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44266)\u001b[0m     @     0x556373da4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44266)\u001b[0m     @     0x556373da5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44266)\u001b[0m     @     0x556373d1a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44266)\u001b[0m     @     0x556373da4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44266)\u001b[0m     @     0x556373da5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44266)\u001b[0m     @     0x556373d1a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44266)\u001b[0m     @     0x556373da4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44352)\u001b[0m     @     0x7f46352fa5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44352)\u001b[0m     @     0x7f46359e54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44317)\u001b[0m     @     0x7f2045ef75a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44354)\u001b[0m     @     0x7f0e6c7d0388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44354)\u001b[0m     @     0x7f0e6c7d25a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44274)\u001b[0m     @     0x7fca797428de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44274)\u001b[0m     @     0x7fca7726f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44274)\u001b[0m     @     0x7fca7d31a79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44274)\u001b[0m     @     0x55a80351afd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44274)\u001b[0m     @     0x55a803475b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44274)\u001b[0m     @     0x55a803500baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44274)\u001b[0m     @     0x55a803501a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44274)\u001b[0m     @     0x55a803475bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44274)\u001b[0m     @     0x55a803500baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44274)\u001b[0m     @     0x55a803501643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44274)\u001b[0m     @     0x55a803476689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44274)\u001b[0m     @     0x55a803500baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44274)\u001b[0m     @     0x55a803501643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44274)\u001b[0m     @     0x55a803476689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44274)\u001b[0m     @     0x55a803500baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44274)\u001b[0m     @     0x55a803501643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44274)\u001b[0m     @     0x55a803476689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44274)\u001b[0m     @     0x55a803500baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44274)\u001b[0m     @     0x55a803501643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44274)\u001b[0m     @     0x55a803476689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44296)\u001b[0m     @     0x7f5034d274f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44296)\u001b[0m     @     0x7f50371fa8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44296)\u001b[0m     @     0x7f5034d274f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44241)\u001b[0m     @     0x7ef09a8b98de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44241)\u001b[0m     @     0x7ef0983e64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44241)\u001b[0m     @     0x7ef09e49179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44241)\u001b[0m     @     0x55adad7b6fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44241)\u001b[0m     @     0x55adad711b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44241)\u001b[0m     @     0x55adad79cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44241)\u001b[0m     @     0x55adad79da20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44241)\u001b[0m     @     0x55adad711bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44241)\u001b[0m     @     0x55adad79cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44241)\u001b[0m     @     0x55adad79d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44241)\u001b[0m     @     0x55adad712689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44241)\u001b[0m     @     0x55adad79cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44241)\u001b[0m     @     0x55adad79d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44241)\u001b[0m     @     0x55adad712689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44241)\u001b[0m     @     0x55adad79cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44241)\u001b[0m     @     0x55adad79d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44241)\u001b[0m     @     0x55adad712689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44241)\u001b[0m     @     0x55adad79cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44241)\u001b[0m     @     0x55adad79d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44241)\u001b[0m     @     0x55adad712689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44269)\u001b[0m     @     0x7fbb081ce8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44269)\u001b[0m     @     0x7fbb05cfb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44269)\u001b[0m     @     0x7fbb0bda679f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44269)\u001b[0m     @     0x560a56c6afd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44269)\u001b[0m     @     0x560a56bc5b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44269)\u001b[0m     @     0x560a56c50baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44269)\u001b[0m     @     0x560a56c51a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44269)\u001b[0m     @     0x560a56bc5bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44269)\u001b[0m     @     0x560a56c50baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44269)\u001b[0m     @     0x560a56c51643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44269)\u001b[0m     @     0x560a56bc6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44269)\u001b[0m     @     0x560a56c50baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44269)\u001b[0m     @     0x560a56c51643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44269)\u001b[0m     @     0x560a56bc6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44269)\u001b[0m     @     0x560a56c50baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44269)\u001b[0m     @     0x560a56c51643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44269)\u001b[0m     @     0x560a56bc6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44269)\u001b[0m     @     0x560a56c50baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44269)\u001b[0m     @     0x560a56c51643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44269)\u001b[0m     @     0x560a56bc6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44334)\u001b[0m     @     0x7ef5d348d4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44334)\u001b[0m     @     0x7ef5ec28379f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44334)\u001b[0m     @     0x55c4c4fb4fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44334)\u001b[0m     @     0x55c4c4f0fb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44334)\u001b[0m     @     0x55c4c4f9abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44334)\u001b[0m     @     0x55c4c4f9ba20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44334)\u001b[0m     @     0x55c4c4f0fbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44334)\u001b[0m     @     0x55c4c4f9abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44334)\u001b[0m     @     0x55c4c4f9b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44334)\u001b[0m     @     0x55c4c4f10689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44334)\u001b[0m     @     0x55c4c4f9abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44334)\u001b[0m     @     0x55c4c4f9b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44334)\u001b[0m     @     0x55c4c4f10689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44334)\u001b[0m     @     0x55c4c4f9abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44334)\u001b[0m     @     0x55c4c4f9b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44334)\u001b[0m     @     0x55c4c4f10689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44334)\u001b[0m     @     0x55c4c4f9abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44334)\u001b[0m     @     0x55c4c4f9b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44334)\u001b[0m     @     0x55c4c4f10689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44246)\u001b[0m     @     0x7fb687a9079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44246)\u001b[0m     @     0x5613cf8a0fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44246)\u001b[0m     @     0x5613cf7fbb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44246)\u001b[0m     @     0x5613cf886baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44246)\u001b[0m     @     0x5613cf887a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44246)\u001b[0m     @     0x5613cf7fbbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44246)\u001b[0m     @     0x5613cf886baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44246)\u001b[0m     @     0x5613cf887643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44246)\u001b[0m     @     0x5613cf7fc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44246)\u001b[0m     @     0x5613cf886baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44246)\u001b[0m     @     0x5613cf887643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44246)\u001b[0m     @     0x5613cf7fc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44246)\u001b[0m     @     0x5613cf886baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44246)\u001b[0m     @     0x5613cf887643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44246)\u001b[0m     @     0x5613cf7fc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44246)\u001b[0m     @     0x5613cf886baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44246)\u001b[0m     @     0x5613cf887643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44246)\u001b[0m     @     0x5613cf7fc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44297)\u001b[0m     @     0x7f426734b8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44297)\u001b[0m     @     0x7f4264e784f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44297)\u001b[0m     @     0x7f426af2379f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44297)\u001b[0m     @     0x562539c7bfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44297)\u001b[0m     @     0x562539bd6b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44297)\u001b[0m     @     0x562539c61baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44297)\u001b[0m     @     0x562539c62a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44297)\u001b[0m     @     0x562539bd6bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44297)\u001b[0m     @     0x562539c61baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44297)\u001b[0m     @     0x562539c62643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44297)\u001b[0m     @     0x562539bd7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44297)\u001b[0m     @     0x562539c61baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44297)\u001b[0m     @     0x562539c62643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44297)\u001b[0m     @     0x562539bd7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44297)\u001b[0m     @     0x562539c61baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44297)\u001b[0m     @     0x562539c62643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44297)\u001b[0m     @     0x562539bd7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44297)\u001b[0m     @     0x562539c61baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44297)\u001b[0m     @     0x562539c62643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44297)\u001b[0m     @     0x562539bd7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44318)\u001b[0m     @     0x7ee7718cf8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44318)\u001b[0m     @     0x7ee76f3fc4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44318)\u001b[0m     @     0x7ee7754a779f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44318)\u001b[0m     @     0x563541d9ffd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44318)\u001b[0m     @     0x563541cfab08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44318)\u001b[0m     @     0x563541d85baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44318)\u001b[0m     @     0x563541d86a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44318)\u001b[0m     @     0x563541cfabfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44318)\u001b[0m     @     0x563541d85baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44318)\u001b[0m     @     0x563541d86643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44318)\u001b[0m     @     0x563541cfb689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44318)\u001b[0m     @     0x563541d85baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44318)\u001b[0m     @     0x563541d86643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44318)\u001b[0m     @     0x563541cfb689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44318)\u001b[0m     @     0x563541d85baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44318)\u001b[0m     @     0x563541d86643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44318)\u001b[0m     @     0x563541cfb689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44318)\u001b[0m     @     0x563541d85baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44318)\u001b[0m     @     0x563541d86643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44318)\u001b[0m     @     0x563541cfb689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44259)\u001b[0m     @     0x7ed64adea4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44259)\u001b[0m     @     0x7ed650e9579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44259)\u001b[0m     @     0x55780ba0bfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44259)\u001b[0m     @     0x55780b966b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44259)\u001b[0m     @     0x55780b9f1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44259)\u001b[0m     @     0x55780b9f2a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44259)\u001b[0m     @     0x55780b966bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44259)\u001b[0m     @     0x55780b9f1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44259)\u001b[0m     @     0x55780b9f2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44259)\u001b[0m     @     0x55780b967689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44259)\u001b[0m     @     0x55780b9f1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44259)\u001b[0m     @     0x55780b9f2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44259)\u001b[0m     @     0x55780b967689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44259)\u001b[0m     @     0x55780b9f1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44259)\u001b[0m     @     0x55780b9f2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44259)\u001b[0m     @     0x55780b967689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44259)\u001b[0m     @     0x55780b9f1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44259)\u001b[0m     @     0x55780b9f2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44259)\u001b[0m     @     0x55780b967689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44251)\u001b[0m     @     0x7f2e0df0c4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44251)\u001b[0m     @     0x7f2e13fb779f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44251)\u001b[0m     @     0x556f6b874fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44251)\u001b[0m     @     0x556f6b7cfb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44251)\u001b[0m     @     0x556f6b85abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44251)\u001b[0m     @     0x556f6b85ba20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44251)\u001b[0m     @     0x556f6b7cfbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44251)\u001b[0m     @     0x556f6b85abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44251)\u001b[0m     @     0x556f6b85b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44251)\u001b[0m     @     0x556f6b7d0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44251)\u001b[0m     @     0x556f6b85abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44251)\u001b[0m     @     0x556f6b85b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44251)\u001b[0m     @     0x556f6b7d0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44251)\u001b[0m     @     0x556f6b85abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44251)\u001b[0m     @     0x556f6b85b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44251)\u001b[0m     @     0x556f6b7d0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44251)\u001b[0m     @     0x556f6b85abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44251)\u001b[0m     @     0x556f6b85b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44251)\u001b[0m     @     0x556f6b7d0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44252)\u001b[0m     @     0x7f6980aff79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44252)\u001b[0m     @     0x557a8f518fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44252)\u001b[0m     @     0x557a8f473b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44252)\u001b[0m     @     0x557a8f4febaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44252)\u001b[0m     @     0x557a8f4ffa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44252)\u001b[0m     @     0x557a8f473bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44252)\u001b[0m     @     0x557a8f4febaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44252)\u001b[0m     @     0x557a8f4ff643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44252)\u001b[0m     @     0x557a8f474689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44252)\u001b[0m     @     0x557a8f4febaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44252)\u001b[0m     @     0x557a8f4ff643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44252)\u001b[0m     @     0x557a8f474689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44252)\u001b[0m     @     0x557a8f4febaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44252)\u001b[0m     @     0x557a8f4ff643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44252)\u001b[0m     @     0x557a8f474689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44252)\u001b[0m     @     0x557a8f4febaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44252)\u001b[0m     @     0x557a8f4ff643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44252)\u001b[0m     @     0x557a8f474689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44245)\u001b[0m     @     0x7fa34d6838de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44245)\u001b[0m     @     0x7fa34b1b04f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44245)\u001b[0m     @     0x7fa35125b79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44245)\u001b[0m     @     0x5632f5031fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44245)\u001b[0m     @     0x5632f4f8cb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44245)\u001b[0m     @     0x5632f5017baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44245)\u001b[0m     @     0x5632f5018a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44245)\u001b[0m     @     0x5632f4f8cbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44245)\u001b[0m     @     0x5632f5017baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44245)\u001b[0m     @     0x5632f5018643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44245)\u001b[0m     @     0x5632f4f8d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44245)\u001b[0m     @     0x5632f5017baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44245)\u001b[0m     @     0x5632f5018643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44245)\u001b[0m     @     0x5632f4f8d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44245)\u001b[0m     @     0x5632f5017baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44245)\u001b[0m     @     0x5632f5018643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44245)\u001b[0m     @     0x5632f4f8d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44245)\u001b[0m     @     0x5632f5017baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44245)\u001b[0m     @     0x5632f5018643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44245)\u001b[0m     @     0x5632f4f8d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44302)\u001b[0m     @     0x7f2bd03e64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44302)\u001b[0m     @     0x7f2bd649179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44302)\u001b[0m     @     0x55a282f35fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44302)\u001b[0m     @     0x55a282e90b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44302)\u001b[0m     @     0x55a282f1bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44302)\u001b[0m     @     0x55a282f1ca20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44302)\u001b[0m     @     0x55a282e90bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44302)\u001b[0m     @     0x55a282f1bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44302)\u001b[0m     @     0x55a282f1c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44302)\u001b[0m     @     0x55a282e91689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44302)\u001b[0m     @     0x55a282f1bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44302)\u001b[0m     @     0x55a282f1c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44302)\u001b[0m     @     0x55a282e91689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44302)\u001b[0m     @     0x55a282f1bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44302)\u001b[0m     @     0x55a282f1c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44302)\u001b[0m     @     0x55a282e91689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44302)\u001b[0m     @     0x55a282f1bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44302)\u001b[0m     @     0x55a282f1c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44302)\u001b[0m     @     0x55a282e91689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44313)\u001b[0m     @     0x7f1d93a774f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44313)\u001b[0m     @     0x7f1d99b2279f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44313)\u001b[0m     @     0x55cb868a6fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44313)\u001b[0m     @     0x55cb86801b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44313)\u001b[0m     @     0x55cb8688cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44313)\u001b[0m     @     0x55cb8688da20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44313)\u001b[0m     @     0x55cb86801bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44313)\u001b[0m     @     0x55cb8688cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44313)\u001b[0m     @     0x55cb8688d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44313)\u001b[0m     @     0x55cb86802689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44313)\u001b[0m     @     0x55cb8688cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44313)\u001b[0m     @     0x55cb8688d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44313)\u001b[0m     @     0x55cb86802689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44313)\u001b[0m     @     0x55cb8688cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44313)\u001b[0m     @     0x55cb8688d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44313)\u001b[0m     @     0x55cb86802689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44313)\u001b[0m     @     0x55cb8688cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44313)\u001b[0m     @     0x55cb8688d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44313)\u001b[0m     @     0x55cb86802689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44309)\u001b[0m     @     0x7f94ae232388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44309)\u001b[0m     @     0x7f94ae2345a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44309)\u001b[0m     @     0x7f94ae91f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44309)\u001b[0m     @     0x7f94b0df28de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44265)\u001b[0m     @     0x7f0bbadea4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44265)\u001b[0m     @     0x7f0bbd2bd8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44265)\u001b[0m     @     0x7f0bbadea4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44265)\u001b[0m     @     0x7f0bc0e9579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44265)\u001b[0m     @     0x562125469fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44265)\u001b[0m     @     0x5621253c4b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44265)\u001b[0m     @     0x56212544fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44265)\u001b[0m     @     0x562125450a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44265)\u001b[0m     @     0x5621253c4bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44265)\u001b[0m     @     0x56212544fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44265)\u001b[0m     @     0x562125450643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44265)\u001b[0m     @     0x5621253c5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44265)\u001b[0m     @     0x56212544fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44265)\u001b[0m     @     0x562125450643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44265)\u001b[0m     @     0x5621253c5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44265)\u001b[0m     @     0x56212544fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44265)\u001b[0m     @     0x562125450643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44265)\u001b[0m     @     0x5621253c5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44265)\u001b[0m     @     0x56212544fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44265)\u001b[0m     @     0x562125450643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44265)\u001b[0m     @     0x5621253c5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44240)\u001b[0m     @     0x7fbc683354f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44240)\u001b[0m     @     0x7fbc6a8088de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44240)\u001b[0m     @     0x7fbc683354f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44240)\u001b[0m     @     0x7fbc6e3e079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44240)\u001b[0m     @     0x563eed24cfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44240)\u001b[0m     @     0x563eed1a7b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44240)\u001b[0m     @     0x563eed232baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44240)\u001b[0m     @     0x563eed233a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44240)\u001b[0m     @     0x563eed1a7bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44240)\u001b[0m     @     0x563eed232baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44240)\u001b[0m     @     0x563eed233643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44240)\u001b[0m     @     0x563eed1a8689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44240)\u001b[0m     @     0x563eed232baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44240)\u001b[0m     @     0x563eed233643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44240)\u001b[0m     @     0x563eed1a8689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44240)\u001b[0m     @     0x563eed232baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44240)\u001b[0m     @     0x563eed233643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44240)\u001b[0m     @     0x563eed1a8689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44240)\u001b[0m     @     0x563eed232baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44240)\u001b[0m     @     0x563eed233643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44240)\u001b[0m     @     0x563eed1a8689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44312)\u001b[0m     @     0x7ecf5650d4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44312)\u001b[0m     @     0x7ecf589e08de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44324)\u001b[0m     @     0x7fb463fa44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44324)\u001b[0m     @     0x7fb4664778de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44324)\u001b[0m     @     0x7fb463fa44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44324)\u001b[0m     @     0x7fb46a04f79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44324)\u001b[0m     @     0x55c8f062ffd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44324)\u001b[0m     @     0x55c8f058ab08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44324)\u001b[0m     @     0x55c8f0615baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44324)\u001b[0m     @     0x55c8f0616a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44324)\u001b[0m     @     0x55c8f058abfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44324)\u001b[0m     @     0x55c8f0615baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44324)\u001b[0m     @     0x55c8f0616643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44324)\u001b[0m     @     0x55c8f058b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44324)\u001b[0m     @     0x55c8f0615baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44324)\u001b[0m     @     0x55c8f0616643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44324)\u001b[0m     @     0x55c8f058b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44324)\u001b[0m     @     0x55c8f0615baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44324)\u001b[0m     @     0x55c8f0616643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44324)\u001b[0m     @     0x55c8f058b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44324)\u001b[0m     @     0x55c8f0615baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44324)\u001b[0m     @     0x55c8f0616643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44324)\u001b[0m     @     0x55c8f058b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44353)\u001b[0m     @     0x7f85ad517c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44353)\u001b[0m     @     0x7f85ac9b9a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44353)\u001b[0m     @     0x7f85ac9b7388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44353)\u001b[0m     @     0x7f85ac9b95a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44276)\u001b[0m     @     0x7f7f6a5f78de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44276)\u001b[0m     @     0x7f7f681244f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44276)\u001b[0m     @     0x7f7f6e1cf79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44276)\u001b[0m     @     0x556cfcbf6fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44276)\u001b[0m     @     0x556cfcb51b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44276)\u001b[0m     @     0x556cfcbdcbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44276)\u001b[0m     @     0x556cfcbdda20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44276)\u001b[0m     @     0x556cfcb51bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44276)\u001b[0m     @     0x556cfcbdcbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44276)\u001b[0m     @     0x556cfcbdd643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44276)\u001b[0m     @     0x556cfcb52689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44276)\u001b[0m     @     0x556cfcbdcbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44276)\u001b[0m     @     0x556cfcbdd643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44276)\u001b[0m     @     0x556cfcb52689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44276)\u001b[0m     @     0x556cfcbdcbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44276)\u001b[0m     @     0x556cfcbdd643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44276)\u001b[0m     @     0x556cfcb52689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44276)\u001b[0m     @     0x556cfcbdcbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44276)\u001b[0m     @     0x556cfcbdd643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44276)\u001b[0m     @     0x556cfcb52689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "2020-11-05 10:44:18,238\tWARNING worker.py:945 -- The driver may not be able to keep up with the stdout/stderr of the workers. To avoid forwarding logs to the driver, use 'ray.init(log_to_driver=False)'.\n",
+      "\u001b[2m\u001b[36m(pid=44267)\u001b[0m     @     0x7fc5a037aa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44267)\u001b[0m     @     0x7fc5a0378388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44267)\u001b[0m     @     0x7fc5a037a5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44255)\u001b[0m     @     0x7f3e7ec444f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44255)\u001b[0m     @     0x7f3e811178de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44255)\u001b[0m     @     0x7f3e7ec444f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44255)\u001b[0m     @     0x7f3e84cef79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44255)\u001b[0m     @     0x559a9ff60fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44255)\u001b[0m     @     0x559a9febbb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44255)\u001b[0m     @     0x559a9ff46baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44255)\u001b[0m     @     0x559a9ff47a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44255)\u001b[0m     @     0x559a9febbbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44255)\u001b[0m     @     0x559a9ff46baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44255)\u001b[0m     @     0x559a9ff47643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44255)\u001b[0m     @     0x559a9febc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44255)\u001b[0m     @     0x559a9ff46baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44255)\u001b[0m     @     0x559a9ff47643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44255)\u001b[0m     @     0x559a9febc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44255)\u001b[0m     @     0x559a9ff46baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44255)\u001b[0m     @     0x559a9ff47643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44255)\u001b[0m     @     0x559a9febc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44255)\u001b[0m     @     0x559a9ff46baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44255)\u001b[0m     @     0x559a9ff47643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44255)\u001b[0m     @     0x559a9febc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44326)\u001b[0m     @     0x7f6cfa1ffad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44326)\u001b[0m     @     0x7f6cfa1ffd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44326)\u001b[0m     @     0x7f6cfaae2b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44326)\u001b[0m     @     0x7f6cfab05c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44326)\u001b[0m     @     0x7f6cf9fa7a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44326)\u001b[0m     @     0x7f6cf9fa5388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44262)\u001b[0m     @     0x7f098e9714f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44262)\u001b[0m     @     0x7f0990e448de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44262)\u001b[0m     @     0x7f098e9714f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44262)\u001b[0m     @     0x7f0994a1c79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44262)\u001b[0m     @     0x562f4b402fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44262)\u001b[0m     @     0x562f4b35db08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44262)\u001b[0m     @     0x562f4b3e8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44262)\u001b[0m     @     0x562f4b3e9a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44262)\u001b[0m     @     0x562f4b35dbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44262)\u001b[0m     @     0x562f4b3e8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44262)\u001b[0m     @     0x562f4b3e9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44262)\u001b[0m     @     0x562f4b35e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44262)\u001b[0m     @     0x562f4b3e8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44262)\u001b[0m     @     0x562f4b3e9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44262)\u001b[0m     @     0x562f4b35e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44262)\u001b[0m     @     0x562f4b3e8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44262)\u001b[0m     @     0x562f4b3e9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44262)\u001b[0m     @     0x562f4b35e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44262)\u001b[0m     @     0x562f4b3e8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44262)\u001b[0m     @     0x562f4b3e9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44262)\u001b[0m     @     0x562f4b35e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44300)\u001b[0m     @     0x7ee034a654f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44300)\u001b[0m     @     0x7ee036f388de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44300)\u001b[0m     @     0x7ee034a654f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44300)\u001b[0m     @     0x7ee03ab1079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44300)\u001b[0m     @     0x55b398fc9fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44300)\u001b[0m     @     0x55b398f24b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44300)\u001b[0m     @     0x55b398fafbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44300)\u001b[0m     @     0x55b398fb0a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44300)\u001b[0m     @     0x55b398f24bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44300)\u001b[0m     @     0x55b398fafbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44300)\u001b[0m     @     0x55b398fb0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44300)\u001b[0m     @     0x55b398f25689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44300)\u001b[0m     @     0x55b398fafbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44300)\u001b[0m     @     0x55b398fb0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44300)\u001b[0m     @     0x55b398f25689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44300)\u001b[0m     @     0x55b398fafbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44300)\u001b[0m     @     0x55b398fb0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44300)\u001b[0m     @     0x55b398f25689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44300)\u001b[0m     @     0x55b398fafbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44300)\u001b[0m     @     0x55b398fb0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44300)\u001b[0m     @     0x55b398f25689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44350)\u001b[0m     @     0x7f9b27742ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44350)\u001b[0m     @     0x7f9b27742d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44350)\u001b[0m     @     0x7f9b28025b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44350)\u001b[0m     @     0x7f9b28048c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44256)\u001b[0m     @     0x7f14139cc4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44256)\u001b[0m     @     0x7f1419a7779f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44256)\u001b[0m     @     0x562d0e6bbfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44256)\u001b[0m     @     0x562d0e616b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44256)\u001b[0m     @     0x562d0e6a1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44256)\u001b[0m     @     0x562d0e6a2a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44256)\u001b[0m     @     0x562d0e616bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44256)\u001b[0m     @     0x562d0e6a1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44256)\u001b[0m     @     0x562d0e6a2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44256)\u001b[0m     @     0x562d0e617689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44256)\u001b[0m     @     0x562d0e6a1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44256)\u001b[0m     @     0x562d0e6a2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44256)\u001b[0m     @     0x562d0e617689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44256)\u001b[0m     @     0x562d0e6a1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44256)\u001b[0m     @     0x562d0e6a2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44256)\u001b[0m     @     0x562d0e617689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44256)\u001b[0m     @     0x562d0e6a1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44256)\u001b[0m     @     0x562d0e6a2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44256)\u001b[0m     @     0x562d0e617689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44258)\u001b[0m     @     0x7f8f2f6b64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44258)\u001b[0m     @     0x7f8f3576179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44258)\u001b[0m     @     0x562aac9f1fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44258)\u001b[0m     @     0x562aac94cb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44258)\u001b[0m     @     0x562aac9d7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44258)\u001b[0m     @     0x562aac9d8a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44258)\u001b[0m     @     0x562aac94cbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44258)\u001b[0m     @     0x562aac9d7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44258)\u001b[0m     @     0x562aac9d8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44258)\u001b[0m     @     0x562aac94d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44258)\u001b[0m     @     0x562aac9d7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44258)\u001b[0m     @     0x562aac9d8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44258)\u001b[0m     @     0x562aac94d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44258)\u001b[0m     @     0x562aac9d7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44258)\u001b[0m     @     0x562aac9d8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44258)\u001b[0m     @     0x562aac94d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44258)\u001b[0m     @     0x562aac9d7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44258)\u001b[0m     @     0x562aac9d8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44258)\u001b[0m     @     0x562aac94d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44366)\u001b[0m     @     0x7f883736a4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44366)\u001b[0m     @     0x7f883d41579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44366)\u001b[0m     @     0x558edbc87fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44366)\u001b[0m     @     0x558edbbe2b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44366)\u001b[0m     @     0x558edbc6dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44366)\u001b[0m     @     0x558edbc6ea20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44366)\u001b[0m     @     0x558edbbe2bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44366)\u001b[0m     @     0x558edbc6dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44366)\u001b[0m     @     0x558edbc6e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44366)\u001b[0m     @     0x558edbbe3689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44366)\u001b[0m     @     0x558edbc6dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44366)\u001b[0m     @     0x558edbc6e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44366)\u001b[0m     @     0x558edbbe3689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44366)\u001b[0m     @     0x558edbc6dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44366)\u001b[0m     @     0x558edbc6e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44366)\u001b[0m     @     0x558edbbe3689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44366)\u001b[0m     @     0x558edbc6dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44366)\u001b[0m     @     0x558edbc6e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44366)\u001b[0m     @     0x558edbbe3689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44247)\u001b[0m     @     0x7f74dd5cb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44247)\u001b[0m     @     0x7f74e367679f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44247)\u001b[0m     @     0x562d322adfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44247)\u001b[0m     @     0x562d32208b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44247)\u001b[0m     @     0x562d32293baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44247)\u001b[0m     @     0x562d32294a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44247)\u001b[0m     @     0x562d32208bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44247)\u001b[0m     @     0x562d32293baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44247)\u001b[0m     @     0x562d32294643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44247)\u001b[0m     @     0x562d32209689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44247)\u001b[0m     @     0x562d32293baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44247)\u001b[0m     @     0x562d32294643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44247)\u001b[0m     @     0x562d32209689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44247)\u001b[0m     @     0x562d32293baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44247)\u001b[0m     @     0x562d32294643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44247)\u001b[0m     @     0x562d32209689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44247)\u001b[0m     @     0x562d32293baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44247)\u001b[0m     @     0x562d32294643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44247)\u001b[0m     @     0x562d32209689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44238)\u001b[0m     @     0x7f16a2c134f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44238)\u001b[0m     @     0x7f16a8cbe79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44238)\u001b[0m     @     0x5626b6ec1fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44238)\u001b[0m     @     0x5626b6e1cb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44238)\u001b[0m     @     0x5626b6ea7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44238)\u001b[0m     @     0x5626b6ea8a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44238)\u001b[0m     @     0x5626b6e1cbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44238)\u001b[0m     @     0x5626b6ea7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44238)\u001b[0m     @     0x5626b6ea8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44238)\u001b[0m     @     0x5626b6e1d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44238)\u001b[0m     @     0x5626b6ea7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44238)\u001b[0m     @     0x5626b6ea8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44238)\u001b[0m     @     0x5626b6e1d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44238)\u001b[0m     @     0x5626b6ea7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44238)\u001b[0m     @     0x5626b6ea8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44238)\u001b[0m     @     0x5626b6e1d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44238)\u001b[0m     @     0x5626b6ea7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44238)\u001b[0m     @     0x5626b6ea8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44238)\u001b[0m     @     0x5626b6e1d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44335)\u001b[0m     @     0x7f3caa3728de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44335)\u001b[0m     @     0x7f3ca7e9f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44335)\u001b[0m     @     0x7f3cadf4a79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44335)\u001b[0m     @     0x55e2f787ffd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44335)\u001b[0m     @     0x55e2f77dab08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44335)\u001b[0m     @     0x55e2f7865baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44335)\u001b[0m     @     0x55e2f7866a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44335)\u001b[0m     @     0x55e2f77dabfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44335)\u001b[0m     @     0x55e2f7865baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44335)\u001b[0m     @     0x55e2f7866643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44335)\u001b[0m     @     0x55e2f77db689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44335)\u001b[0m     @     0x55e2f7865baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44335)\u001b[0m     @     0x55e2f7866643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44335)\u001b[0m     @     0x55e2f77db689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44335)\u001b[0m     @     0x55e2f7865baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44335)\u001b[0m     @     0x55e2f7866643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44335)\u001b[0m     @     0x55e2f77db689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44335)\u001b[0m     @     0x55e2f7865baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44335)\u001b[0m     @     0x55e2f7866643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44335)\u001b[0m     @     0x55e2f77db689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44264)\u001b[0m     @     0x7f48b89d34f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44264)\u001b[0m     @     0x7f48bea7e79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44264)\u001b[0m     @     0x5603bcaaefd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44264)\u001b[0m     @     0x5603bca09b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44264)\u001b[0m     @     0x5603bca94baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44264)\u001b[0m     @     0x5603bca95a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44264)\u001b[0m     @     0x5603bca09bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44264)\u001b[0m     @     0x5603bca94baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44264)\u001b[0m     @     0x5603bca95643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44264)\u001b[0m     @     0x5603bca0a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44264)\u001b[0m     @     0x5603bca94baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44264)\u001b[0m     @     0x5603bca95643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44264)\u001b[0m     @     0x5603bca0a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44264)\u001b[0m     @     0x5603bca94baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44264)\u001b[0m     @     0x5603bca95643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44264)\u001b[0m     @     0x5603bca0a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44308)\u001b[0m     @     0x7f11119e54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44308)\u001b[0m     @     0x7f1117a9079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44308)\u001b[0m     @     0x56010a34ffd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44308)\u001b[0m     @     0x56010a2aab08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44308)\u001b[0m     @     0x56010a335baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44308)\u001b[0m     @     0x56010a336a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44308)\u001b[0m     @     0x56010a2aabfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44308)\u001b[0m     @     0x56010a335baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44308)\u001b[0m     @     0x56010a336643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44308)\u001b[0m     @     0x56010a2ab689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44308)\u001b[0m     @     0x56010a335baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44308)\u001b[0m     @     0x56010a336643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44308)\u001b[0m     @     0x56010a2ab689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44308)\u001b[0m     @     0x56010a335baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44308)\u001b[0m     @     0x56010a336643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44308)\u001b[0m     @     0x56010a2ab689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44308)\u001b[0m     @     0x56010a335baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44308)\u001b[0m     @     0x56010a336643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44308)\u001b[0m     @     0x56010a2ab689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44316)\u001b[0m     @     0x7efdf577bad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44316)\u001b[0m     @     0x7efdf577bd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44316)\u001b[0m     @     0x7efdf605eb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44316)\u001b[0m     @     0x7efdf6081c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44250)\u001b[0m     @     0x7edfe0e9579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44250)\u001b[0m     @     0x5653bbb73fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44250)\u001b[0m     @     0x5653bbaceb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44250)\u001b[0m     @     0x5653bbb59baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44250)\u001b[0m     @     0x5653bbb5aa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44250)\u001b[0m     @     0x5653bbacebfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44250)\u001b[0m     @     0x5653bbb59baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44250)\u001b[0m     @     0x5653bbb5a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44250)\u001b[0m     @     0x5653bbacf689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44250)\u001b[0m     @     0x5653bbb59baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44250)\u001b[0m     @     0x5653bbb5a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44250)\u001b[0m     @     0x5653bbacf689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44250)\u001b[0m     @     0x5653bbb59baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44250)\u001b[0m     @     0x5653bbb5a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44250)\u001b[0m     @     0x5653bbacf689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44250)\u001b[0m     @     0x5653bbb59baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44250)\u001b[0m     @     0x5653bbb5a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44250)\u001b[0m     @     0x5653bbacf689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44319)\u001b[0m     @     0x7f4d2292ad91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=44319)\u001b[0m     @     0x7f4d2320db22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=44244)\u001b[0m     @     0x7f8a134f2a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44244)\u001b[0m     @     0x7f8a134f0388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44244)\u001b[0m     @     0x7f8a134f25a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44275)\u001b[0m     @     0x7f5f125e24f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44275)\u001b[0m     @     0x7f5f1868d79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44275)\u001b[0m     @     0x55981939efd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44275)\u001b[0m     @     0x5598192f9b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44275)\u001b[0m     @     0x559819384baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44275)\u001b[0m     @     0x559819385a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44275)\u001b[0m     @     0x5598192f9bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44275)\u001b[0m     @     0x559819384baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44275)\u001b[0m     @     0x559819385643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44275)\u001b[0m     @     0x5598192fa689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44275)\u001b[0m     @     0x559819384baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44275)\u001b[0m     @     0x559819385643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44275)\u001b[0m     @     0x5598192fa689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44275)\u001b[0m     @     0x559819384baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44275)\u001b[0m     @     0x559819385643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44275)\u001b[0m     @     0x5598192fa689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44275)\u001b[0m     @     0x559819384baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44275)\u001b[0m     @     0x559819385643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44275)\u001b[0m     @     0x5598192fa689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44358)\u001b[0m     @     0x7fad6be244f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44358)\u001b[0m     @     0x7fad71ecf79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44358)\u001b[0m     @     0x556cca713fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44358)\u001b[0m     @     0x556cca66eb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44358)\u001b[0m     @     0x556cca6f9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44358)\u001b[0m     @     0x556cca6faa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44358)\u001b[0m     @     0x556cca66ebfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44358)\u001b[0m     @     0x556cca6f9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44358)\u001b[0m     @     0x556cca6fa643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44358)\u001b[0m     @     0x556cca66f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44358)\u001b[0m     @     0x556cca6f9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44358)\u001b[0m     @     0x556cca6fa643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44358)\u001b[0m     @     0x556cca66f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44358)\u001b[0m     @     0x556cca6f9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44358)\u001b[0m     @     0x556cca6fa643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44358)\u001b[0m     @     0x556cca66f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44358)\u001b[0m     @     0x556cca6f9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44358)\u001b[0m     @     0x556cca6fa643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44358)\u001b[0m     @     0x556cca66f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44254)\u001b[0m     @     0x7f607928b79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44254)\u001b[0m     @     0x561a2c126fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44254)\u001b[0m     @     0x561a2c081b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44254)\u001b[0m     @     0x561a2c10cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44254)\u001b[0m     @     0x561a2c10da20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44254)\u001b[0m     @     0x561a2c081bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44254)\u001b[0m     @     0x561a2c10cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44254)\u001b[0m     @     0x561a2c10d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44254)\u001b[0m     @     0x561a2c082689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44254)\u001b[0m     @     0x561a2c10cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44254)\u001b[0m     @     0x561a2c10d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44254)\u001b[0m     @     0x561a2c082689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44254)\u001b[0m     @     0x561a2c10cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44254)\u001b[0m     @     0x561a2c10d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44254)\u001b[0m     @     0x561a2c082689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44254)\u001b[0m     @     0x561a2c10cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44254)\u001b[0m     @     0x561a2c10d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44254)\u001b[0m     @     0x561a2c082689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44239)\u001b[0m     @     0x7f7f85cfb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44239)\u001b[0m     @     0x7f7f881ce8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44239)\u001b[0m     @     0x7f7f85cfb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44239)\u001b[0m     @     0x7f7f8bda679f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44239)\u001b[0m     @     0x55fc7b64afd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44239)\u001b[0m     @     0x55fc7b5a5b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44239)\u001b[0m     @     0x55fc7b630baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44239)\u001b[0m     @     0x55fc7b631a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44239)\u001b[0m     @     0x55fc7b5a5bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44239)\u001b[0m     @     0x55fc7b630baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44239)\u001b[0m     @     0x55fc7b631643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44239)\u001b[0m     @     0x55fc7b5a6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44239)\u001b[0m     @     0x55fc7b630baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44239)\u001b[0m     @     0x55fc7b631643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44239)\u001b[0m     @     0x55fc7b5a6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44239)\u001b[0m     @     0x55fc7b630baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44239)\u001b[0m     @     0x55fc7b631643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44239)\u001b[0m     @     0x55fc7b5a6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44239)\u001b[0m     @     0x55fc7b630baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44239)\u001b[0m     @     0x55fc7b631643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44239)\u001b[0m     @     0x55fc7b5a6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44249)\u001b[0m     @     0x7ef0702e04f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44249)\u001b[0m     @     0x7ef07638b79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44249)\u001b[0m     @     0x556ed9357fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44249)\u001b[0m     @     0x556ed92b2b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44249)\u001b[0m     @     0x556ed933dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44249)\u001b[0m     @     0x556ed933ea20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44249)\u001b[0m     @     0x556ed92b2bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44249)\u001b[0m     @     0x556ed933dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44249)\u001b[0m     @     0x556ed933e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44249)\u001b[0m     @     0x556ed92b3689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44249)\u001b[0m     @     0x556ed933dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44249)\u001b[0m     @     0x556ed933e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44249)\u001b[0m     @     0x556ed92b3689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44249)\u001b[0m     @     0x556ed933dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44249)\u001b[0m     @     0x556ed933e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44249)\u001b[0m     @     0x556ed92b3689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44249)\u001b[0m     @     0x556ed933dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44249)\u001b[0m     @     0x556ed933e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44249)\u001b[0m     @     0x556ed92b3689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44242)\u001b[0m     @     0x7f0db87924f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44242)\u001b[0m     @     0x7f0dbe83d79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44242)\u001b[0m     @     0x5603885b9fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44242)\u001b[0m     @     0x560388514b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44242)\u001b[0m     @     0x56038859fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44242)\u001b[0m     @     0x5603885a0a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44242)\u001b[0m     @     0x560388514bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44242)\u001b[0m     @     0x56038859fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44242)\u001b[0m     @     0x5603885a0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44242)\u001b[0m     @     0x560388515689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44242)\u001b[0m     @     0x56038859fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44242)\u001b[0m     @     0x5603885a0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44242)\u001b[0m     @     0x560388515689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44242)\u001b[0m     @     0x56038859fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44242)\u001b[0m     @     0x5603885a0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44242)\u001b[0m     @     0x560388515689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44242)\u001b[0m     @     0x56038859fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44242)\u001b[0m     @     0x5603885a0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44242)\u001b[0m     @     0x560388515689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44331)\u001b[0m     @     0x7f05646fc4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44331)\u001b[0m     @     0x7f056a7a779f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44331)\u001b[0m     @     0x5609edc4bfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44331)\u001b[0m     @     0x5609edba6b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44331)\u001b[0m     @     0x5609edc31baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44331)\u001b[0m     @     0x5609edc32a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44331)\u001b[0m     @     0x5609edba6bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44331)\u001b[0m     @     0x5609edc31baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44331)\u001b[0m     @     0x5609edc32643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44331)\u001b[0m     @     0x5609edba7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44331)\u001b[0m     @     0x5609edc31baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44331)\u001b[0m     @     0x5609edc32643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44331)\u001b[0m     @     0x5609edba7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44331)\u001b[0m     @     0x5609edc31baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44331)\u001b[0m     @     0x5609edc32643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44331)\u001b[0m     @     0x5609edba7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44331)\u001b[0m     @     0x5609edc31baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44331)\u001b[0m     @     0x5609edc32643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44331)\u001b[0m     @     0x5609edba7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44260)\u001b[0m     @     0x7f2c4adea4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44260)\u001b[0m     @     0x7f2c50e9579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44260)\u001b[0m     @     0x55f643903fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44260)\u001b[0m     @     0x55f64385eb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44260)\u001b[0m     @     0x55f6438e9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44260)\u001b[0m     @     0x55f6438eaa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44260)\u001b[0m     @     0x55f64385ebfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44260)\u001b[0m     @     0x55f6438e9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44260)\u001b[0m     @     0x55f6438ea643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44260)\u001b[0m     @     0x55f64385f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44260)\u001b[0m     @     0x55f6438e9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44260)\u001b[0m     @     0x55f6438ea643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44260)\u001b[0m     @     0x55f64385f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44260)\u001b[0m     @     0x55f6438e9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44260)\u001b[0m     @     0x55f6438ea643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44260)\u001b[0m     @     0x55f64385f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44260)\u001b[0m     @     0x55f6438e9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44260)\u001b[0m     @     0x55f6438ea643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44260)\u001b[0m     @     0x55f64385f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44314)\u001b[0m     @     0x7ed30349f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44314)\u001b[0m     @     0x7ed30954a79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44314)\u001b[0m     @     0x55bdc0c19fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44314)\u001b[0m     @     0x55bdc0b74b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44314)\u001b[0m     @     0x55bdc0bffbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44314)\u001b[0m     @     0x55bdc0c00a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44314)\u001b[0m     @     0x55bdc0b74bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44314)\u001b[0m     @     0x55bdc0bffbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44314)\u001b[0m     @     0x55bdc0c00643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44314)\u001b[0m     @     0x55bdc0b75689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44314)\u001b[0m     @     0x55bdc0bffbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44314)\u001b[0m     @     0x55bdc0c00643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44314)\u001b[0m     @     0x55bdc0b75689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44314)\u001b[0m     @     0x55bdc0bffbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44314)\u001b[0m     @     0x55bdc0c00643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44314)\u001b[0m     @     0x55bdc0b75689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44314)\u001b[0m     @     0x55bdc0bffbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44314)\u001b[0m     @     0x55bdc0c00643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44314)\u001b[0m     @     0x55bdc0b75689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44322)\u001b[0m     @     0x7f9f43bdd4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44322)\u001b[0m     @     0x7f9f49c8879f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44322)\u001b[0m     @     0x55afea939fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44322)\u001b[0m     @     0x55afea894b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44322)\u001b[0m     @     0x55afea91fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44322)\u001b[0m     @     0x55afea920a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44322)\u001b[0m     @     0x55afea894bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44322)\u001b[0m     @     0x55afea91fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44322)\u001b[0m     @     0x55afea920643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44322)\u001b[0m     @     0x55afea895689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44322)\u001b[0m     @     0x55afea91fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44322)\u001b[0m     @     0x55afea920643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44322)\u001b[0m     @     0x55afea895689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44322)\u001b[0m     @     0x55afea91fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44322)\u001b[0m     @     0x55afea920643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44322)\u001b[0m     @     0x55afea895689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44322)\u001b[0m     @     0x55afea91fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44322)\u001b[0m     @     0x55afea920643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44322)\u001b[0m     @     0x55afea895689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44307)\u001b[0m     @     0x7f7ad89a54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44307)\u001b[0m     @     0x7f7adea5079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44307)\u001b[0m     @     0x558d8a162fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44307)\u001b[0m     @     0x558d8a0bdb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44307)\u001b[0m     @     0x558d8a148baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44307)\u001b[0m     @     0x558d8a149a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44307)\u001b[0m     @     0x558d8a0bdbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44307)\u001b[0m     @     0x558d8a148baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44307)\u001b[0m     @     0x558d8a149643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44307)\u001b[0m     @     0x558d8a0be689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44307)\u001b[0m     @     0x558d8a148baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44307)\u001b[0m     @     0x558d8a149643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44307)\u001b[0m     @     0x558d8a0be689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44307)\u001b[0m     @     0x558d8a148baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44307)\u001b[0m     @     0x558d8a149643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44307)\u001b[0m     @     0x558d8a0be689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44307)\u001b[0m     @     0x558d8a148baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44307)\u001b[0m     @     0x558d8a149643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44307)\u001b[0m     @     0x558d8a0be689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44311)\u001b[0m     @     0x55bbd8a71baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44311)\u001b[0m     @     0x55bbd8a72a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44311)\u001b[0m     @     0x55bbd89e6bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44311)\u001b[0m     @     0x55bbd8a71baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44311)\u001b[0m     @     0x55bbd8a72643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44311)\u001b[0m     @     0x55bbd89e7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44311)\u001b[0m     @     0x55bbd8a71baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44311)\u001b[0m     @     0x55bbd8a72643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44311)\u001b[0m     @     0x55bbd89e7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44311)\u001b[0m     @     0x55bbd8a71baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44311)\u001b[0m     @     0x55bbd8a72643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44311)\u001b[0m     @     0x55bbd89e7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44311)\u001b[0m     @     0x55bbd8a71baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44311)\u001b[0m     @     0x55bbd8a72643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44311)\u001b[0m     @     0x55bbd89e7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44243)\u001b[0m     @     0x7f7e1814a5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44243)\u001b[0m     @     0x7f7e188354f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44243)\u001b[0m     @     0x7f7e1ad088de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44243)\u001b[0m     @     0x7f7e188354f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44243)\u001b[0m     @     0x7f7e1e8e079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44243)\u001b[0m     @     0x5618156d2fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44243)\u001b[0m     @     0x56181562db08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44243)\u001b[0m     @     0x5618156b8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44243)\u001b[0m     @     0x5618156b9a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44243)\u001b[0m     @     0x56181562dbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44243)\u001b[0m     @     0x5618156b8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44243)\u001b[0m     @     0x5618156b9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44243)\u001b[0m     @     0x56181562e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44243)\u001b[0m     @     0x5618156b8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44243)\u001b[0m     @     0x5618156b9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44243)\u001b[0m     @     0x56181562e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44304)\u001b[0m     @     0x7f6e5e2cb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44304)\u001b[0m     @     0x7f6e6437679f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44304)\u001b[0m     @     0x5576991a6fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44304)\u001b[0m     @     0x557699101b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44304)\u001b[0m     @     0x55769918cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44304)\u001b[0m     @     0x55769918da20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44304)\u001b[0m     @     0x557699101bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44304)\u001b[0m     @     0x55769918cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44304)\u001b[0m     @     0x55769918d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44304)\u001b[0m     @     0x557699102689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44304)\u001b[0m     @     0x55769918cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44304)\u001b[0m     @     0x55769918d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44304)\u001b[0m     @     0x557699102689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44304)\u001b[0m     @     0x55769918cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44304)\u001b[0m     @     0x55769918d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44304)\u001b[0m     @     0x557699102689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44304)\u001b[0m     @     0x55769918cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44304)\u001b[0m     @     0x55769918d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44304)\u001b[0m     @     0x557699102689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44266)\u001b[0m     @     0x556373da5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44266)\u001b[0m     @     0x556373d1a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44352)\u001b[0m     @     0x7f4637eb88de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44352)\u001b[0m     @     0x7f46359e54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44352)\u001b[0m     @     0x7f463ba9079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44352)\u001b[0m     @     0x56191ffb7fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44352)\u001b[0m     @     0x56191ff12b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44352)\u001b[0m     @     0x56191ff9dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44352)\u001b[0m     @     0x56191ff9ea20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44352)\u001b[0m     @     0x56191ff12bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44352)\u001b[0m     @     0x56191ff9dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44352)\u001b[0m     @     0x56191ff9e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44352)\u001b[0m     @     0x56191ff13689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44352)\u001b[0m     @     0x56191ff9dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44352)\u001b[0m     @     0x56191ff9e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44352)\u001b[0m     @     0x56191ff13689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44352)\u001b[0m     @     0x56191ff9dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44352)\u001b[0m     @     0x56191ff9e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44352)\u001b[0m     @     0x56191ff13689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44352)\u001b[0m     @     0x56191ff9dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44352)\u001b[0m     @     0x56191ff9e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44352)\u001b[0m     @     0x56191ff13689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44317)\u001b[0m     @     0x7f20465e24f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44317)\u001b[0m     @     0x7f2048ab58de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44317)\u001b[0m     @     0x7f20465e24f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44317)\u001b[0m     @     0x7f204c68d79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44317)\u001b[0m     @     0x556580197fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44317)\u001b[0m     @     0x5565800f2b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44317)\u001b[0m     @     0x55658017dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44317)\u001b[0m     @     0x55658017ea20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44317)\u001b[0m     @     0x5565800f2bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44317)\u001b[0m     @     0x55658017dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44317)\u001b[0m     @     0x55658017e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44317)\u001b[0m     @     0x5565800f3689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44317)\u001b[0m     @     0x55658017dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44317)\u001b[0m     @     0x55658017e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44317)\u001b[0m     @     0x5565800f3689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44317)\u001b[0m     @     0x55658017dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44317)\u001b[0m     @     0x55658017e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44317)\u001b[0m     @     0x5565800f3689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44317)\u001b[0m     @     0x55658017dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44317)\u001b[0m     @     0x55658017e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44317)\u001b[0m     @     0x5565800f3689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44354)\u001b[0m     @     0x7f0e6cebd4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44354)\u001b[0m     @     0x7f0e6f3908de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44354)\u001b[0m     @     0x7f0e6cebd4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44354)\u001b[0m     @     0x7f0e72f6879f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44354)\u001b[0m     @     0x56540f70efd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44354)\u001b[0m     @     0x56540f669b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44354)\u001b[0m     @     0x56540f6f4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44354)\u001b[0m     @     0x56540f6f5a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44354)\u001b[0m     @     0x56540f669bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44354)\u001b[0m     @     0x56540f6f4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44354)\u001b[0m     @     0x56540f6f5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44354)\u001b[0m     @     0x56540f66a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44354)\u001b[0m     @     0x56540f6f4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44354)\u001b[0m     @     0x56540f6f5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44354)\u001b[0m     @     0x56540f66a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44354)\u001b[0m     @     0x56540f6f4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44354)\u001b[0m     @     0x56540f6f5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44354)\u001b[0m     @     0x56540f66a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44354)\u001b[0m     @     0x56540f6f4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44354)\u001b[0m     @     0x56540f6f5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44354)\u001b[0m     @     0x56540f66a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44296)\u001b[0m     @     0x7f503add279f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44296)\u001b[0m     @     0x559dc7670fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44296)\u001b[0m     @     0x559dc75cbb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44296)\u001b[0m     @     0x559dc7656baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44296)\u001b[0m     @     0x559dc7657a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44296)\u001b[0m     @     0x559dc75cbbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44296)\u001b[0m     @     0x559dc7656baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44296)\u001b[0m     @     0x559dc7657643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44296)\u001b[0m     @     0x559dc75cc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44296)\u001b[0m     @     0x559dc7656baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44296)\u001b[0m     @     0x559dc7657643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44296)\u001b[0m     @     0x559dc75cc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44296)\u001b[0m     @     0x559dc7656baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44296)\u001b[0m     @     0x559dc7657643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44296)\u001b[0m     @     0x559dc75cc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44296)\u001b[0m     @     0x559dc7656baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44296)\u001b[0m     @     0x559dc7657643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44296)\u001b[0m     @     0x559dc75cc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44309)\u001b[0m     @     0x7f94ae91f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44309)\u001b[0m     @     0x7f94b49ca79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44309)\u001b[0m     @     0x560a43026fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44309)\u001b[0m     @     0x560a42f81b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44309)\u001b[0m     @     0x560a4300cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44309)\u001b[0m     @     0x560a4300da20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44309)\u001b[0m     @     0x560a42f81bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44309)\u001b[0m     @     0x560a4300cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44309)\u001b[0m     @     0x560a4300d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44309)\u001b[0m     @     0x560a42f82689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44309)\u001b[0m     @     0x560a4300cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44309)\u001b[0m     @     0x560a4300d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44309)\u001b[0m     @     0x560a42f82689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44309)\u001b[0m     @     0x560a4300cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44309)\u001b[0m     @     0x560a4300d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44309)\u001b[0m     @     0x560a42f82689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44309)\u001b[0m     @     0x560a4300cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44309)\u001b[0m     @     0x560a4300d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44309)\u001b[0m     @     0x560a42f82689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44312)\u001b[0m     @     0x7ecf5650d4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44312)\u001b[0m     @     0x7ecf5c5b879f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44312)\u001b[0m     @     0x55610c614fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44312)\u001b[0m     @     0x55610c56fb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44312)\u001b[0m     @     0x55610c5fabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44312)\u001b[0m     @     0x55610c5fba20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44312)\u001b[0m     @     0x55610c56fbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44312)\u001b[0m     @     0x55610c5fabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44312)\u001b[0m     @     0x55610c5fb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44312)\u001b[0m     @     0x55610c570689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44312)\u001b[0m     @     0x55610c5fabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44312)\u001b[0m     @     0x55610c5fb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44312)\u001b[0m     @     0x55610c570689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44312)\u001b[0m     @     0x55610c5fabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44312)\u001b[0m     @     0x55610c5fb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44312)\u001b[0m     @     0x55610c570689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44312)\u001b[0m     @     0x55610c5fabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44312)\u001b[0m     @     0x55610c5fb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44312)\u001b[0m     @     0x55610c570689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44353)\u001b[0m     @     0x7f85ad0a44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44353)\u001b[0m     @     0x7f85af5778de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44353)\u001b[0m     @     0x7f85ad0a44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44353)\u001b[0m     @     0x7f85b314f79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44353)\u001b[0m     @     0x555b7b048fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44353)\u001b[0m     @     0x555b7afa3b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44353)\u001b[0m     @     0x555b7b02ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44353)\u001b[0m     @     0x555b7b02fa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44353)\u001b[0m     @     0x555b7afa3bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44353)\u001b[0m     @     0x555b7b02ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44353)\u001b[0m     @     0x555b7b02f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44353)\u001b[0m     @     0x555b7afa4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44353)\u001b[0m     @     0x555b7b02ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44353)\u001b[0m     @     0x555b7b02f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44353)\u001b[0m     @     0x555b7afa4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44353)\u001b[0m     @     0x555b7b02ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44353)\u001b[0m     @     0x555b7b02f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44353)\u001b[0m     @     0x555b7afa4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44353)\u001b[0m     @     0x555b7b02ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44353)\u001b[0m     @     0x555b7b02f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44353)\u001b[0m     @     0x555b7afa4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44267)\u001b[0m     @     0x7fc5a0a654f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44267)\u001b[0m     @     0x7fc5a2f388de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44267)\u001b[0m     @     0x7fc5a0a654f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44267)\u001b[0m     @     0x7fc5a6b1079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44267)\u001b[0m     @     0x560f83a35fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44267)\u001b[0m     @     0x560f83990b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44267)\u001b[0m     @     0x560f83a1bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44267)\u001b[0m     @     0x560f83a1ca20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44267)\u001b[0m     @     0x560f83990bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44267)\u001b[0m     @     0x560f83a1bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44267)\u001b[0m     @     0x560f83a1c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44267)\u001b[0m     @     0x560f83991689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44267)\u001b[0m     @     0x560f83a1bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44267)\u001b[0m     @     0x560f83a1c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44267)\u001b[0m     @     0x560f83991689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44267)\u001b[0m     @     0x560f83a1bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44267)\u001b[0m     @     0x560f83a1c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44267)\u001b[0m     @     0x560f83991689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44267)\u001b[0m     @     0x560f83a1bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44267)\u001b[0m     @     0x560f83a1c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44267)\u001b[0m     @     0x560f83991689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44326)\u001b[0m     @     0x7f6cf9fa75a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44326)\u001b[0m     @     0x7f6cfa6924f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44326)\u001b[0m     @     0x7f6cfcb658de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44350)\u001b[0m     @     0x7f9b274eaa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44350)\u001b[0m     @     0x7f9b274e8388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44350)\u001b[0m     @     0x7f9b274ea5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44264)\u001b[0m     @     0x5603bca94baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44264)\u001b[0m     @     0x5603bca95643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44264)\u001b[0m     @     0x5603bca0a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44316)\u001b[0m     @     0x7efdf5523a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44316)\u001b[0m     @     0x7efdf5521388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44316)\u001b[0m     @     0x7efdf55235a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44316)\u001b[0m     @     0x7efdf5c0e4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44319)\u001b[0m     @     0x7f4d23230c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=44319)\u001b[0m     @     0x7f4d226d2a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=44319)\u001b[0m     @     0x7f4d226d0388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=44319)\u001b[0m     @     0x7f4d226d25a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44244)\u001b[0m     @     0x7f8a13bdd4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44244)\u001b[0m     @     0x7f8a160b08de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44244)\u001b[0m     @     0x7f8a13bdd4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44244)\u001b[0m     @     0x7f8a19c8879f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44244)\u001b[0m     @     0x55bfa9179fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44244)\u001b[0m     @     0x55bfa90d4b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44244)\u001b[0m     @     0x55bfa915fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44244)\u001b[0m     @     0x55bfa9160a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44244)\u001b[0m     @     0x55bfa90d4bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44244)\u001b[0m     @     0x55bfa915fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44244)\u001b[0m     @     0x55bfa9160643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44244)\u001b[0m     @     0x55bfa90d5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44244)\u001b[0m     @     0x55bfa915fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44244)\u001b[0m     @     0x55bfa9160643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44244)\u001b[0m     @     0x55bfa90d5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44244)\u001b[0m     @     0x55bfa915fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44244)\u001b[0m     @     0x55bfa9160643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44244)\u001b[0m     @     0x55bfa90d5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44244)\u001b[0m     @     0x55bfa915fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44244)\u001b[0m     @     0x55bfa9160643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44244)\u001b[0m     @     0x55bfa90d5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44243)\u001b[0m     @     0x5618156b8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44243)\u001b[0m     @     0x5618156b9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44243)\u001b[0m     @     0x56181562e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44243)\u001b[0m     @     0x5618156b8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44243)\u001b[0m     @     0x5618156b9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44243)\u001b[0m     @     0x56181562e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44326)\u001b[0m     @     0x7f6cfa6924f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44326)\u001b[0m     @     0x7f6d0073d79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44326)\u001b[0m     @     0x55e062284fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44326)\u001b[0m     @     0x55e0621dfb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44326)\u001b[0m     @     0x55e06226abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44326)\u001b[0m     @     0x55e06226ba20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44326)\u001b[0m     @     0x55e0621dfbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44326)\u001b[0m     @     0x55e06226abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44326)\u001b[0m     @     0x55e06226b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44326)\u001b[0m     @     0x55e0621e0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44326)\u001b[0m     @     0x55e06226abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44326)\u001b[0m     @     0x55e06226b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44326)\u001b[0m     @     0x55e0621e0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44326)\u001b[0m     @     0x55e06226abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44326)\u001b[0m     @     0x55e06226b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44326)\u001b[0m     @     0x55e0621e0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44326)\u001b[0m     @     0x55e06226abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44326)\u001b[0m     @     0x55e06226b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44326)\u001b[0m     @     0x55e0621e0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44316)\u001b[0m     @     0x7efdf80e18de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44316)\u001b[0m     @     0x7efdf5c0e4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44316)\u001b[0m     @     0x7efdfbcb979f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44316)\u001b[0m     @     0x55b52b31efd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44316)\u001b[0m     @     0x55b52b279b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44316)\u001b[0m     @     0x55b52b304baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44316)\u001b[0m     @     0x55b52b305a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44316)\u001b[0m     @     0x55b52b279bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44316)\u001b[0m     @     0x55b52b304baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44316)\u001b[0m     @     0x55b52b305643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44316)\u001b[0m     @     0x55b52b27a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44316)\u001b[0m     @     0x55b52b304baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44316)\u001b[0m     @     0x55b52b305643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44316)\u001b[0m     @     0x55b52b27a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44316)\u001b[0m     @     0x55b52b304baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44316)\u001b[0m     @     0x55b52b305643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44316)\u001b[0m     @     0x55b52b27a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44316)\u001b[0m     @     0x55b52b304baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44316)\u001b[0m     @     0x55b52b305643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44316)\u001b[0m     @     0x55b52b27a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44319)\u001b[0m     @     0x7f4d22dbd4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44319)\u001b[0m     @     0x7f4d252908de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44319)\u001b[0m     @     0x7f4d22dbd4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44319)\u001b[0m     @     0x7f4d28e6879f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44319)\u001b[0m     @     0x561192e62fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=44350)\u001b[0m     @     0x7f9b27bd54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=44319)\u001b[0m     @     0x561192dbdb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44319)\u001b[0m     @     0x561192e48baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44319)\u001b[0m     @     0x561192e49a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=44319)\u001b[0m     @     0x561192dbdbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44319)\u001b[0m     @     0x561192e48baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44319)\u001b[0m     @     0x561192e49643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44319)\u001b[0m     @     0x561192dbe689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44319)\u001b[0m     @     0x561192e48baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44319)\u001b[0m     @     0x561192e49643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44319)\u001b[0m     @     0x561192dbe689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44319)\u001b[0m     @     0x561192e48baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44319)\u001b[0m     @     0x561192e49643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44319)\u001b[0m     @     0x561192dbe689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44319)\u001b[0m     @     0x561192e48baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=44319)\u001b[0m     @     0x561192e49643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=44319)\u001b[0m     @     0x561192dbe689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44350)\u001b[0m     @     0x7f9b2a0a88de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "2020-11-05 10:44:18,369\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff4e242e9f01000000.\n",
+      "2020-11-05 10:44:18,373\tERROR trial_runner.py:567 -- Trial PPO_jss_env_d6abc_00000: Error processing event.\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/trial_runner.py\", line 515, in _process_trial\n",
+      "    result = self.trial_executor.fetch_result(trial)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/ray_trial_executor.py\", line 488, in fetch_result\n",
+      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1428, in get\n",
+      "    raise value.as_instanceof_cause()\n",
+      "ray.exceptions.RayTaskError: \u001b[36mray::PPO.train()\u001b[39m (pid=44367, ip=172.17.0.4)\n",
+      "  File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
+      "  File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\", line 516, in train\n",
+      "    raise e\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\", line 505, in train\n",
+      "    result = Trainable.train(self)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/trainable.py\", line 336, in train\n",
+      "    result = self.step()\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer_template.py\", line 134, in step\n",
+      "    res = next(self.train_exec_impl)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 756, in __next__\n",
+      "    return next(self.built_iterator)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 843, in apply_filter\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 843, in apply_filter\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  [Previous line repeated 1 more time]\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 876, in apply_flatten\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 828, in add_wait_hooks\n",
+      "    item = next(it)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  [Previous line repeated 1 more time]\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 466, in base_iterator\n",
+      "    actor_set.init_actors()\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 1238, in init_actors\n",
+      "    ray.get([a.par_iter_init.remote(self.transforms) for a in self.actors])\n",
+      "ray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 24.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/1 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 ERROR)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_d6abc_00000 | ERROR    |       |\n",
+      "+-------------------------+----------+-------+\n",
+      "Number of errored trials: 1\n",
+      "+-------------------------+--------------+-----------------------------------------------------------------------------------+\n",
+      "| Trial name              |   # failures | error file                                                                        |\n",
+      "|-------------------------+--------------+-----------------------------------------------------------------------------------|\n",
+      "| PPO_jss_env_d6abc_00000 |            1 | /root/ray_results/ppo-jss/PPO_jss_env_d6abc_00000_0_2020-11-05_10-44-10/error.txt |\n",
+      "+-------------------------+--------------+-----------------------------------------------------------------------------------+\n",
+      "\n",
+      "== Status ==\n",
+      "Memory usage on this node: 24.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/1 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 ERROR)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_d6abc_00000 | ERROR    |       |\n",
+      "+-------------------------+----------+-------+\n",
+      "Number of errored trials: 1\n",
+      "+-------------------------+--------------+-----------------------------------------------------------------------------------+\n",
+      "| Trial name              |   # failures | error file                                                                        |\n",
+      "|-------------------------+--------------+-----------------------------------------------------------------------------------|\n",
+      "| PPO_jss_env_d6abc_00000 |            1 | /root/ray_results/ppo-jss/PPO_jss_env_d6abc_00000_0_2020-11-05_10-44-10/error.txt |\n",
+      "+-------------------------+--------------+-----------------------------------------------------------------------------------+\n",
+      "\n",
+      "2020-11-05 10:44:18,390\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff4100f4fd01000000.\n",
+      "2020-11-05 10:44:18,391\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffffbdff035801000000.\n",
+      "2020-11-05 10:44:18,391\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffffe0497dac01000000.\n",
+      "2020-11-05 10:44:18,391\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff9f3cc57a01000000.\n",
+      "2020-11-05 10:44:18,391\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff56c9ec1501000000.\n",
+      "Traceback (most recent call last):\n",
+      "  File \"train.py\", line 74, in <module>\n",
+      "    train_func()\n",
+      "  File \"train.py\", line 56, in train_func\n",
+      "    analysis = tune.run(PPOTrainer, config=config, stop=stop, name=\"ppo-jss\")\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/tune.py\", line 427, in run\n",
+      "    raise TuneError(\"Trials did not complete\", incomplete_trials)\n",
+      "ray.tune.error.TuneError: ('Trials did not complete', [PPO_jss_env_d6abc_00000])\n",
       "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 3998\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
-      "2020-10-14 20:45:02,401 - wandb.wandb_agent - INFO - Running runs: ['3kcee9dt']\n",
+      "--- Logging error ---\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 44138\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 1.  Press ctrl-c to abort syncing.\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff0314ce3001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff091d563401000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "\u001b[2m\u001b[36m(pid=44367)\u001b[0m E1105 10:44:18.364902 44367 45560 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=bf6cd9795b8b23124e242e9f01000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=4e242e9f01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "Traceback (most recent call last):\n",
+      "\u001b[2m\u001b[36m(pid=44367)\u001b[0m E1105 10:44:18.365068 44367 45560 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=c5da4173a1c517cf4e242e9f01000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=4e242e9f01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "\u001b[2m\u001b[36m(pid=44367)\u001b[0m E1105 10:44:18.380470 44367 45560 task_manager.cc:323] Task failed: IOError: cancelling all pending tasks of dead actor: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=626c71df3976eafd4e242e9f01000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=4e242e9f01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "\u001b[2m\u001b[36m(pid=44367)\u001b[0m E1105 10:44:18.383273 44367 45560 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=137dbd5547ea6deabdff035801000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=bdff035801000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "Call stack:\n",
+      "\u001b[2m\u001b[36m(pid=44367)\u001b[0m E1105 10:44:18.383888 44367 45560 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=3f75a43fb9f70f24bdff035801000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=bdff035801000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=44367)\u001b[0m E1105 10:44:18.383991 44367 45560 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=d984ee9d41b92c534100f4fd01000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=4100f4fd01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff9d526f0201000000.'\n",
+      "Arguments: ()\n",
+      "\u001b[2m\u001b[36m(pid=44367)\u001b[0m E1105 10:44:18.384094 44367 45560 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=150a9d56b40e3700bdff035801000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=bdff035801000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "--- Logging error ---\n",
+      "\u001b[2m\u001b[36m(pid=44367)\u001b[0m E1105 10:44:18.384277 44367 45560 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=6c41da4ee8b0b4d04100f4fd01000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=4100f4fd01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "Traceback (most recent call last):\n",
+      "\u001b[2m\u001b[36m(pid=44367)\u001b[0m E1105 10:44:18.384368 44367 45560 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=37f711ca0d66f5bd4100f4fd01000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=4100f4fd01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "\u001b[2m\u001b[36m(pid=44350)\u001b[0m     @     0x7f9b27bd54f5 at::Tensor::copy_()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "\u001b[2m\u001b[36m(pid=44350)\u001b[0m     @     0x7f9b2dc8079f torch::autograd::THPVariable_copy_()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "\u001b[2m\u001b[36m(pid=44350)\u001b[0m     @     0x5606c688ffd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "Call stack:\n",
+      "\u001b[2m\u001b[36m(pid=44350)\u001b[0m     @     0x5606c67eab08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44350)\u001b[0m     @     0x5606c6875baf _PyEval_EvalCodeWithName\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "\u001b[2m\u001b[36m(pid=44350)\u001b[0m     @     0x5606c6876a20 method_vectorcall\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "\u001b[2m\u001b[36m(pid=44350)\u001b[0m     @     0x5606c67eabfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "\u001b[2m\u001b[36m(pid=44350)\u001b[0m     @     0x5606c6875baf _PyEval_EvalCodeWithName\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "\u001b[2m\u001b[36m(pid=44350)\u001b[0m     @     0x5606c6876643 _PyFunction_Vectorcall.localalias.353\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff8edbbd3001000000.'\n",
+      "Arguments: ()\n",
+      "\u001b[2m\u001b[36m(pid=44350)\u001b[0m     @     0x5606c67eb689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "--- Logging error ---\n",
+      "\u001b[2m\u001b[36m(pid=44350)\u001b[0m     @     0x5606c6875baf _PyEval_EvalCodeWithName\n",
+      "Traceback (most recent call last):\n",
+      "\u001b[2m\u001b[36m(pid=44350)\u001b[0m     @     0x5606c6876643 _PyFunction_Vectorcall.localalias.353\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "\u001b[2m\u001b[36m(pid=44350)\u001b[0m     @     0x5606c67eb689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "\u001b[2m\u001b[36m(pid=44350)\u001b[0m     @     0x5606c6875baf _PyEval_EvalCodeWithName\n",
+      "ValueError: I/O operation on closed file.\n",
+      "\u001b[2m\u001b[36m(pid=44350)\u001b[0m     @     0x5606c6876643 _PyFunction_Vectorcall.localalias.353\n",
+      "Call stack:\n",
+      "\u001b[2m\u001b[36m(pid=44350)\u001b[0m     @     0x5606c67eb689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=44350)\u001b[0m     @     0x5606c6875baf _PyEval_EvalCodeWithName\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "\u001b[2m\u001b[36m(pid=44350)\u001b[0m     @     0x5606c6876643 _PyFunction_Vectorcall.localalias.353\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "\u001b[2m\u001b[36m(pid=44350)\u001b[0m     @     0x5606c67eb689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff821ddf4301000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffc2621d1401000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff59d91ef301000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff90aded9101000000.'\n",
+      "Arguments: ()\n",
+      "\u001b[2m\u001b[36m(pid=44367)\u001b[0m E1105 10:44:18.411914 44367 45560 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=170fdfd5d34985a7e0497dac01000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=e0497dac01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=44367)\u001b[0m E1105 10:44:18.412111 44367 45560 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=89f63fee54d6858ee0497dac01000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=e0497dac01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=44367)\u001b[0m E1105 10:44:18.412184 44367 45560 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=c6f8a2750fad0b0de0497dac01000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=e0497dac01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=44367)\u001b[0m E1105 10:44:18.412381 44367 45560 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=f4d9d8a5e202b0910314ce3001000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=0314ce3001000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=44367)\u001b[0m E1105 10:44:18.412451 44367 45560 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=8b0b449b9f08d0430314ce3001000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=0314ce3001000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=44367)\u001b[0m E1105 10:44:18.412565 44367 45560 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=ad47e6e6a1a1660b0314ce3001000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=0314ce3001000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=44367)\u001b[0m E1105 10:44:18.412703 44367 45560 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=4db1cba171d56c3356c9ec1501000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=56c9ec1501000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=44367)\u001b[0m E1105 10:44:18.412887 44367 45560 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=5cf29c5b7b7ed08d56c9ec1501000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=56c9ec1501000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=44367)\u001b[0m E1105 10:44:18.412952 44367 45560 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=9d0a2db204e8f81056c9ec1501000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=56c9ec1501000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=44367)\u001b[0m E1105 10:44:18.413228 44367 45560 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=1f6f5417a7b065f9091d563401000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=091d563401000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=44367)\u001b[0m E1105 10:44:18.413318 44367 45560 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=e76b5820fbdeb0f2091d563401000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=091d563401000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=44367)\u001b[0m E1105 10:44:18.413381 44367 45560 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=7249131d8582b825091d563401000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=091d563401000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=44367)\u001b[0m E1105 10:44:18.413560 44367 45560 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=f26c08df806c9b079d526f0201000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=9d526f0201000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=44367)\u001b[0m E1105 10:44:18.413631 44367 45560 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=3501fe38550fe14a9d526f0201000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=9d526f0201000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=44367)\u001b[0m E1105 10:44:18.413691 44367 45560 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=d9b69b81196304409d526f0201000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=9d526f0201000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=44367)\u001b[0m E1105 10:44:18.413846 44367 45560 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=4027410178b738888edbbd3001000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=8edbbd3001000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=44367)\u001b[0m E1105 10:44:18.413905 44367 45560 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=f4290d8c04f479ac8edbbd3001000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=8edbbd3001000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=44367)\u001b[0m E1105 10:44:18.413966 44367 45560 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=8e79ac7e91b36714821ddf4301000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=821ddf4301000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=44367)\u001b[0m E1105 10:44:18.414021 44367 45560 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=a4e1f5da99aef89f8edbbd3001000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=8edbbd3001000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=44367)\u001b[0m E1105 10:44:18.414081 44367 45560 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=428a4b4025d91890821ddf4301000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=821ddf4301000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=44367)\u001b[0m E1105 10:44:18.414227 44367 45560 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=38e2d2d27b716bfb821ddf4301000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=821ddf4301000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=44367)\u001b[0m E1105 10:44:18.414345 44367 45560 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=9ecf84e34eb8e61dc2621d1401000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=c2621d1401000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=44367)\u001b[0m E1105 10:44:18.414429 44367 45560 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=f3cba62d4c01820bc2621d1401000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=c2621d1401000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=44367)\u001b[0m E1105 10:44:18.414495 44367 45560 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=8fbf1bd7de98d288c2621d1401000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=c2621d1401000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=44367)\u001b[0m E1105 10:44:18.414623 44367 45560 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=8b485cbbeaa005a559d91ef301000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=59d91ef301000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=44367)\u001b[0m E1105 10:44:18.414686 44367 45560 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=ca546fa1af7e507159d91ef301000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=59d91ef301000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=44367)\u001b[0m E1105 10:44:18.414743 44367 45560 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=fd2b07e19848a86a59d91ef301000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=59d91ef301000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=44367)\u001b[0m E1105 10:44:18.414870 44367 45560 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=efaf5dbfabc208739f3cc57a01000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=9f3cc57a01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=44367)\u001b[0m E1105 10:44:18.414937 44367 45560 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=b3b45bae970c41729f3cc57a01000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=9f3cc57a01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=44367)\u001b[0m E1105 10:44:18.415000 44367 45560 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=4f22c19b5f703db99f3cc57a01000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=9f3cc57a01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffa97540c201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff252160a301000000.'\n",
+      "Arguments: ()\n",
+      "\u001b[2m\u001b[36m(pid=44367)\u001b[0m E1105 10:44:18.415226 44367 45560 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=37f0cff2c5fdc1c790aded9101000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=90aded9101000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=44367)\u001b[0m E1105 10:44:18.415302 44367 45560 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=ff02fc67a478da9090aded9101000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=90aded9101000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=44367)\u001b[0m E1105 10:44:18.415371 44367 45560 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=6b6365ef3364d41390aded9101000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=90aded9101000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffb2413f7201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff31c3fed901000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff8168b55d01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff43fb47bd01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff302122d001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff4f9bfece01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff2d1a71ea01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff80993fa801000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task fffffffffffffffff257d30801000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff0d557f6601000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff1e7ae67b01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffccf343cc01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff8d06128001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff7ef9157101000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff32335d4e01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff0fae11b201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff8f9a5fc701000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffe9f6a7cf01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff19fd5b4901000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff58dd50c101000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff51728d3301000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffee8852f401000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff310e963d01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff018c9dac01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff7b2861ac01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff5843697701000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff14da135201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff41e0fbff01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff5cc87e2501000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffef1af81501000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff7f7c936001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffb3cace0801000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff20d842ad01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffd784bf0601000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff8cd168e101000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff7a508a7a01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff0aeae6a301000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff99d0343201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff452e714401000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffd989d1f001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff358dd45601000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task fffffffffffffffff120020c01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff75f329e601000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffffefbd9801000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff50168bc201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff34cbbac201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffa4f7314201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff04668d8f01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffda2cd21f01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffc3083e0c01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff702ed69e01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffa7ad1db301000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff3a9488b101000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffeca600ef01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff10f667b001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff3166f9e301000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffdd5654aa01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff71ca01c001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff244a7d1001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task fffffffffffffffff0f72e3901000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff61dc472601000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffd8f83c3801000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task fffffffffffffffff392716d01000000.'\n",
+      "Arguments: ()\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201014_204459-3kcee9dt/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201014_204459-3kcee9dt/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:       nb_episodes 1\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   avg_best_result 211.84848\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_episode 211.84848\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:     best_timestep 3517\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:             _step 0\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:          _runtime 1\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        _timestamp 1602708300\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:       nb_episodes ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   avg_best_result ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_episode ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:     best_timestep ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:             _step ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:          _runtime ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        _timestamp ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201105_104405-ed9sd7in/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201105_104405-ed9sd7in/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mMTWR\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/3kcee9dt\u001b[0m\n",
-      "2020-10-14 20:45:07,613 - wandb.wandb_agent - INFO - Cleaning up finished run: 3kcee9dt\n",
-      "2020-10-14 20:45:10,058 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-14 20:45:10,059 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tinstance_path: /JSS/JSS/env/instances/ta60\n",
-      "2020-10-14 20:45:10,061 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python MTWR.py --instance_path=/JSS/JSS/env/instances/ta60\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mhonest-sweep-4\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/ed9sd7in\u001b[0m\n",
+      "2020-11-05 10:44:29,882 - wandb.wandb_agent - INFO - Cleaning up finished run: ed9sd7in\n",
+      "2020-11-05 10:44:30,194 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-11-05 10:44:30,195 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tinstance_path: /JSS/JSS/env/instances/ta44\n",
+      "2020-11-05 10:44:30,197 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --instance_path=/JSS/JSS/env/instances/ta44\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.9 is available!  To upgrade, please run:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
+      "2020-11-05 10:44:35,214 - wandb.wandb_agent - INFO - Running runs: ['968941xy']\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mMTWR\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/po3ygyxo\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/kkype8ue\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201014_204512-kkype8ue\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdutiful-sweep-5\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/sweeps/72qf0qyh\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/968941xy\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201105_104432-968941xy\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
+      "2020-11-05 10:44:35,913\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
+      "== Status ==\n",
+      "Memory usage on this node: 12.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/1 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_e6675_00000 | RUNNING  |       |\n",
+      "+-------------------------+----------+-------+\n",
+      "\n",
+      "\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m 2020-11-05 10:44:38,812\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/torch/cuda/__init__.py:125: UserWarning: \n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m GeForce RTX 2080 Ti with CUDA capability sm_75 is not compatible with the current PyTorch installation.\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 compute_37.\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m If you want to use the GeForce RTX 2080 Ti GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m \n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m   warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n",
+      "\u001b[2m\u001b[36m(pid=45857)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45857)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45857)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45857)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45857)\u001b[0m *** SIGSEGV (@0x0) received by PID 45857 (TID 0x7fdd81b05700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45857)\u001b[0m     @     0x7fdd816de390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45857)\u001b[0m     @     0x7fae81687f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45883)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45883)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45883)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45883)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45883)\u001b[0m *** SIGSEGV (@0x0) received by PID 45883 (TID 0x7f5d59184700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45883)\u001b[0m     @     0x7f5d58d5d390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45883)\u001b[0m     @     0x7f2e58cf7f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45883)\u001b[0m     @     0x7f2e584227db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45792)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45792)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45792)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45792)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45792)\u001b[0m *** SIGSEGV (@0x0) received by PID 45792 (TID 0x7f5797328700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45792)\u001b[0m     @     0x7f5796f01390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45874)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45874)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45874)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45874)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45874)\u001b[0m *** SIGSEGV (@0x0) received by PID 45874 (TID 0x7fe7281e6700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45874)\u001b[0m     @     0x7fe727dbf390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45869)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45869)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45869)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45869)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45869)\u001b[0m *** SIGSEGV (@0x0) received by PID 45869 (TID 0x7f26f68f9700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45869)\u001b[0m     @     0x7f26f64d2390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45869)\u001b[0m     @     0x7ef7f6467f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45869)\u001b[0m     @     0x7ef7f5b927db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45869)\u001b[0m     @     0x7ef7f5b958f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45869)\u001b[0m     @     0x7ef7f5b95ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45869)\u001b[0m     @     0x7ef7f5b95d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45869)\u001b[0m     @     0x7ef7f6478b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45869)\u001b[0m     @     0x7ef7f649bc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45869)\u001b[0m     @     0x7ef7f593da93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45869)\u001b[0m     @     0x7ef7f593b388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45869)\u001b[0m     @     0x7ef7f593d5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45869)\u001b[0m     @     0x7ef7f60284f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45869)\u001b[0m     @     0x7ef7f84fb8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45810)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45810)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45810)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45810)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45810)\u001b[0m *** SIGSEGV (@0x0) received by PID 45810 (TID 0x7f6991dc8700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45810)\u001b[0m     @     0x7f69919a1390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45810)\u001b[0m     @     0x7f3a917f9f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45849)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45849)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45849)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45849)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45849)\u001b[0m *** SIGSEGV (@0x0) received by PID 45849 (TID 0x7f8064a80700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45849)\u001b[0m     @     0x7f8064659390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45849)\u001b[0m     @     0x7f5164563f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45849)\u001b[0m     @     0x7f5163c8e7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45905)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45905)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45905)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45905)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45905)\u001b[0m *** SIGSEGV (@0x0) received by PID 45905 (TID 0x7f97519f2700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45905)\u001b[0m     @     0x7f97515cb390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45880)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45880)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45880)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45880)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45880)\u001b[0m *** SIGSEGV (@0x0) received by PID 45880 (TID 0x7fe1f1ff9700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45880)\u001b[0m     @     0x7fe1f1bd2390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45904)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45904)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45904)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45904)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45904)\u001b[0m *** SIGSEGV (@0x0) received by PID 45904 (TID 0x7f1c390d3700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45887)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45887)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45887)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45887)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45887)\u001b[0m *** SIGSEGV (@0x0) received by PID 45887 (TID 0x7fdf7125c700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45887)\u001b[0m     @     0x7fdf70e35390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45887)\u001b[0m     @     0x7fb070dc9f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45887)\u001b[0m     @     0x7fb0704f47db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45887)\u001b[0m     @     0x7fb0704f78f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45887)\u001b[0m     @     0x7fb0704f7ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45887)\u001b[0m     @     0x7fb0704f7d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45887)\u001b[0m     @     0x7fb070ddab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45887)\u001b[0m     @     0x7fb070dfdc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45887)\u001b[0m     @     0x7fb07029fa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45887)\u001b[0m     @     0x7fb07029d388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45887)\u001b[0m     @     0x7fb07029f5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45866)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45866)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45866)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45866)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45866)\u001b[0m *** SIGSEGV (@0x0) received by PID 45866 (TID 0x7f6dd69e9700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45909)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45909)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45909)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45909)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45909)\u001b[0m *** SIGSEGV (@0x0) received by PID 45909 (TID 0x7fca63909700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45909)\u001b[0m     @     0x7fca634e2390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45909)\u001b[0m     @     0x7f9b6348ff90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45909)\u001b[0m     @     0x7f9b62bba7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45909)\u001b[0m     @     0x7f9b62bbd8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45909)\u001b[0m     @     0x7f9b62bbdad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45909)\u001b[0m     @     0x7f9b62bbdd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45909)\u001b[0m     @     0x7f9b634a0b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45909)\u001b[0m     @     0x7f9b634c3c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45909)\u001b[0m     @     0x7f9b62965a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45909)\u001b[0m     @     0x7f9b62963388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45909)\u001b[0m     @     0x7f9b629655a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45868)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45868)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45868)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45868)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45868)\u001b[0m *** SIGSEGV (@0x0) received by PID 45868 (TID 0x7fa20c99b700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45868)\u001b[0m     @     0x7fa20c574390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45868)\u001b[0m     @     0x7f730c4fcf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45868)\u001b[0m     @     0x7f730bc277db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45868)\u001b[0m     @     0x7f730bc2a8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45860)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45860)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45860)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45860)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45860)\u001b[0m *** SIGSEGV (@0x0) received by PID 45860 (TID 0x7f38fbe0b700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45860)\u001b[0m     @     0x7f38fb9e4390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45860)\u001b[0m     @     0x7f09fb751f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45860)\u001b[0m     @     0x7f09fae7c7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45860)\u001b[0m     @     0x7f09fae7f8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45860)\u001b[0m     @     0x7f09fae7fad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45860)\u001b[0m     @     0x7f09fae7fd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45860)\u001b[0m     @     0x7f09fb762b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45860)\u001b[0m     @     0x7f09fb785c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45860)\u001b[0m     @     0x7f09fac27a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45860)\u001b[0m     @     0x7f09fac25388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45860)\u001b[0m     @     0x7f09fac275a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45853)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45853)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45853)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45853)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45853)\u001b[0m *** SIGSEGV (@0x0) received by PID 45853 (TID 0x7fee0a424700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45853)\u001b[0m     @     0x7fee09ffd390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45853)\u001b[0m     @     0x7fbf09e24f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45853)\u001b[0m     @     0x7fbf0954f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45891)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45891)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45891)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45891)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45891)\u001b[0m *** SIGSEGV (@0x0) received by PID 45891 (TID 0x7f19b87c2700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45891)\u001b[0m     @     0x7f19b839b390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45891)\u001b[0m     @     0x7eeab8336f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45891)\u001b[0m     @     0x7eeab7a617db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45921)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45921)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45921)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45921)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45921)\u001b[0m *** SIGSEGV (@0x0) received by PID 45921 (TID 0x7f91920f1700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45921)\u001b[0m     @     0x7f9191cca390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45921)\u001b[0m     @     0x7f6291c0df90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45921)\u001b[0m     @     0x7f62913387db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45921)\u001b[0m     @     0x7f629133b8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45921)\u001b[0m     @     0x7f629133bad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45921)\u001b[0m     @     0x7f629133bd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45921)\u001b[0m     @     0x7f6291c1eb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45921)\u001b[0m     @     0x7f6291c41c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45921)\u001b[0m     @     0x7f62910e3a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45921)\u001b[0m     @     0x7f62910e1388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45921)\u001b[0m     @     0x7f62910e35a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45921)\u001b[0m     @     0x7f62917ce4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45921)\u001b[0m     @     0x7f6293ca18de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45912)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45912)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45912)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45912)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45912)\u001b[0m *** SIGSEGV (@0x0) received by PID 45912 (TID 0x7f219a7c8700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45912)\u001b[0m     @     0x7f219a3a1390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45912)\u001b[0m     @     0x7ef29a34bf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45912)\u001b[0m     @     0x7ef299a767db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45912)\u001b[0m     @     0x7ef299a798f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45912)\u001b[0m     @     0x7ef299a79ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45912)\u001b[0m     @     0x7ef299a79d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45912)\u001b[0m     @     0x7ef29a35cb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45912)\u001b[0m     @     0x7ef29a37fc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45912)\u001b[0m     @     0x7ef299821a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45912)\u001b[0m     @     0x7ef29981f388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45912)\u001b[0m     @     0x7ef2998215a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45912)\u001b[0m     @     0x7ef299f0c4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45912)\u001b[0m     @     0x7ef29c3df8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45889)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45889)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45889)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45889)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45889)\u001b[0m *** SIGSEGV (@0x0) received by PID 45889 (TID 0x7f85213b0700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45889)\u001b[0m     @     0x7f8520f89390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45889)\u001b[0m     @     0x7f5620ea4f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45889)\u001b[0m     @     0x7f56205cf7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45896)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45896)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45896)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45896)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45896)\u001b[0m *** SIGSEGV (@0x0) received by PID 45896 (TID 0x7fe47ed7d700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45896)\u001b[0m     @     0x7fe47e956390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45896)\u001b[0m     @     0x7fb57e70af90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45896)\u001b[0m     @     0x7fb57de357db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45896)\u001b[0m     @     0x7fb57de388f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45896)\u001b[0m     @     0x7fb57de38ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45896)\u001b[0m     @     0x7fb57de38d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45896)\u001b[0m     @     0x7fb57e71bb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45896)\u001b[0m     @     0x7fb57e73ec1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45896)\u001b[0m     @     0x7fb57dbe0a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45896)\u001b[0m     @     0x7fb57dbde388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45896)\u001b[0m     @     0x7fb57dbe05a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45896)\u001b[0m     @     0x7fb57e2cb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45884)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45884)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45884)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45884)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45884)\u001b[0m *** SIGSEGV (@0x0) received by PID 45884 (TID 0x7fdc5ed48700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45884)\u001b[0m     @     0x7fdc5e921390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45884)\u001b[0m     @     0x7fad5e70af90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45884)\u001b[0m     @     0x7fad5de357db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45884)\u001b[0m     @     0x7fad5de388f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45884)\u001b[0m     @     0x7fad5de38ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45884)\u001b[0m     @     0x7fad5de38d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45884)\u001b[0m     @     0x7fad5e71bb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45884)\u001b[0m     @     0x7fad5e73ec1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45884)\u001b[0m     @     0x7fad5dbe0a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45884)\u001b[0m     @     0x7fad5dbde388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45884)\u001b[0m     @     0x7fad5dbe05a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45884)\u001b[0m     @     0x7fad5e2cb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45884)\u001b[0m     @     0x7fad6079e8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45871)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45871)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45871)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45871)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45871)\u001b[0m *** SIGSEGV (@0x0) received by PID 45871 (TID 0x7fbc49c71700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45871)\u001b[0m     @     0x7fbc4984a390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45871)\u001b[0m     @     0x7f8d496f4f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45807)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45807)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45807)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45807)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45807)\u001b[0m *** SIGSEGV (@0x0) received by PID 45807 (TID 0x7feb3a97e700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45807)\u001b[0m     @     0x7feb3a557390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45807)\u001b[0m     @     0x7fbc3a4f7f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45804)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45804)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45804)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45804)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45804)\u001b[0m *** SIGSEGV (@0x0) received by PID 45804 (TID 0x7ff815cbc700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45804)\u001b[0m     @     0x7ff815895390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45858)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45858)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45858)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45858)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45858)\u001b[0m *** SIGSEGV (@0x0) received by PID 45858 (TID 0x7f1943735700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45799)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45799)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45799)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45799)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45799)\u001b[0m *** SIGSEGV (@0x0) received by PID 45799 (TID 0x7f8662b8d700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45799)\u001b[0m     @     0x7f8662766390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45865)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45865)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45865)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45865)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45865)\u001b[0m *** SIGSEGV (@0x0) received by PID 45865 (TID 0x7fd0a2f30700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45865)\u001b[0m     @     0x7fd0a2b09390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45865)\u001b[0m     @     0x7fa1a2aa4f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45865)\u001b[0m     @     0x7fa1a21cf7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45894)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45894)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45894)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45894)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45894)\u001b[0m *** SIGSEGV (@0x0) received by PID 45894 (TID 0x7fcce5e8a700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45894)\u001b[0m     @     0x7fcce5a63390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45894)\u001b[0m     @     0x7f9de57f9f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45894)\u001b[0m     @     0x7f9de4f247db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45894)\u001b[0m     @     0x7f9de4f278f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45894)\u001b[0m     @     0x7f9de4f27ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45894)\u001b[0m     @     0x7f9de4f27d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45894)\u001b[0m     @     0x7f9de580ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45894)\u001b[0m     @     0x7f9de582dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45894)\u001b[0m     @     0x7f9de4ccfa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45894)\u001b[0m     @     0x7f9de4ccd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45894)\u001b[0m     @     0x7f9de4ccf5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45894)\u001b[0m     @     0x7f9de53ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45894)\u001b[0m     @     0x7f9de788d8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45862)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45862)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45862)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45862)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45862)\u001b[0m *** SIGSEGV (@0x0) received by PID 45862 (TID 0x7f625b574700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45862)\u001b[0m     @     0x7f625b14d390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45877)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45877)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45877)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45877)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45877)\u001b[0m *** SIGSEGV (@0x0) received by PID 45877 (TID 0x7f94417ef700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45842)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45842)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45842)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45794)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45794)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45794)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45844)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45844)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45844)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45822)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45822)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45822)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45895)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45895)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45895)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45895)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45895)\u001b[0m *** SIGSEGV (@0x0) received by PID 45895 (TID 0x7f9b3abde700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45906)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45906)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45906)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45906)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45906)\u001b[0m *** SIGSEGV (@0x0) received by PID 45906 (TID 0x7f28f52c7700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45906)\u001b[0m     @     0x7f28f4ea0390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45885)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45885)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45885)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45885)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45885)\u001b[0m *** SIGSEGV (@0x0) received by PID 45885 (TID 0x7fb404e1a700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45885)\u001b[0m     @     0x7fb4049f3390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45885)\u001b[0m     @     0x7f8504825f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45885)\u001b[0m     @     0x7f8503f507db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45809)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45809)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45809)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45809)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45809)\u001b[0m *** SIGSEGV (@0x0) received by PID 45809 (TID 0x7f8fa5c98700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45809)\u001b[0m     @     0x7f8fa5871390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45809)\u001b[0m     @     0x7f60a57f9f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45809)\u001b[0m     @     0x7f60a4f247db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45805)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45805)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45805)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45805)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45805)\u001b[0m *** SIGSEGV (@0x0) received by PID 45805 (TID 0x7fed97d47700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45805)\u001b[0m     @     0x7fed97920390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45805)\u001b[0m     @     0x7fbe978b1f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45805)\u001b[0m     @     0x7fbe96fdc7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45808)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45808)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45808)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45808)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45808)\u001b[0m *** SIGSEGV (@0x0) received by PID 45808 (TID 0x7f439e175700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45808)\u001b[0m     @     0x7f439dd4e390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45808)\u001b[0m     @     0x7f149dceff90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45808)\u001b[0m     @     0x7f149d41a7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45787)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45787)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45787)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45787)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45787)\u001b[0m *** SIGSEGV (@0x0) received by PID 45787 (TID 0x7f215e891700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45787)\u001b[0m     @     0x7f215e46a390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45787)\u001b[0m     @     0x7ef25e34bf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45787)\u001b[0m     @     0x7ef25da767db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45811)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45811)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45811)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45811)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45811)\u001b[0m *** SIGSEGV (@0x0) received by PID 45811 (TID 0x7fe3ef900700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45811)\u001b[0m     @     0x7fe3ef4d9390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45811)\u001b[0m     @     0x7fb4ef46af90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45811)\u001b[0m     @     0x7fb4eeb957db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45811)\u001b[0m     @     0x7fb4eeb988f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45901)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45901)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45901)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45901)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45901)\u001b[0m *** SIGSEGV (@0x0) received by PID 45901 (TID 0x7f6e8ce0f700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45901)\u001b[0m     @     0x7f6e8c9e8390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45901)\u001b[0m     @     0x7f3f8c825f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45901)\u001b[0m     @     0x7f3f8bf507db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45820)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45820)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45820)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45820)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45820)\u001b[0m *** SIGSEGV (@0x0) received by PID 45820 (TID 0x7f35a4efb700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45820)\u001b[0m     @     0x7f35a4ad4390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45820)\u001b[0m     @     0x7f06a4a36f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45820)\u001b[0m     @     0x7f06a41617db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45820)\u001b[0m     @     0x7f06a41648f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45820)\u001b[0m     @     0x7f06a4164ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45820)\u001b[0m     @     0x7f06a4164d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45820)\u001b[0m     @     0x7f06a4a47b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45820)\u001b[0m     @     0x7f06a4a6ac1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45820)\u001b[0m     @     0x7f06a3f0ca93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45820)\u001b[0m     @     0x7f06a3f0a388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45820)\u001b[0m     @     0x7f06a3f0c5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45820)\u001b[0m     @     0x7f06a45f74f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45793)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45793)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45793)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45793)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45793)\u001b[0m *** SIGSEGV (@0x0) received by PID 45793 (TID 0x7fa088361700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45793)\u001b[0m     @     0x7fa087f3a390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45793)\u001b[0m     @     0x7f7187e0ef90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45793)\u001b[0m     @     0x7f71875397db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45802)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45802)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45802)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45802)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45802)\u001b[0m *** SIGSEGV (@0x0) received by PID 45802 (TID 0x7f62309b5700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45802)\u001b[0m     @     0x7f623058e390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45802)\u001b[0m     @     0x7f3330339f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45802)\u001b[0m     @     0x7f332fa647db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45850)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45850)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45850)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45850)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45850)\u001b[0m *** SIGSEGV (@0x0) received by PID 45850 (TID 0x7f38b4bb8700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45850)\u001b[0m     @     0x7f38b4791390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45850)\u001b[0m     @     0x7f09b460ef90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45850)\u001b[0m     @     0x7f09b3d397db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45850)\u001b[0m     @     0x7f09b3d3c8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45850)\u001b[0m     @     0x7f09b3d3cad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45850)\u001b[0m     @     0x7f09b3d3cd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45850)\u001b[0m     @     0x7f09b461fb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45850)\u001b[0m     @     0x7f09b4642c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45850)\u001b[0m     @     0x7f09b3ae4a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45850)\u001b[0m     @     0x7f09b3ae2388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45850)\u001b[0m     @     0x7f09b3ae45a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45863)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45863)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45863)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45806)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45806)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45806)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45806)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45806)\u001b[0m *** SIGSEGV (@0x0) received by PID 45806 (TID 0x7fda8a579700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45806)\u001b[0m     @     0x7fda8a152390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45806)\u001b[0m     @     0x7fab89e24f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45795)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45795)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45795)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45795)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45795)\u001b[0m *** SIGSEGV (@0x0) received by PID 45795 (TID 0x7f6860ef9700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45795)\u001b[0m     @     0x7f6860ad2390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45795)\u001b[0m     @     0x7f3960a36f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45795)\u001b[0m     @     0x7f39601617db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45876)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45876)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45876)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45876)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45876)\u001b[0m *** SIGSEGV (@0x0) received by PID 45876 (TID 0x7f749b744700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45790)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45790)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45790)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45790)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45790)\u001b[0m *** SIGSEGV (@0x0) received by PID 45790 (TID 0x7fab5ec2e700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45790)\u001b[0m     @     0x7fab5e807390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45800)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45800)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45800)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45800)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45800)\u001b[0m *** SIGSEGV (@0x0) received by PID 45800 (TID 0x7f9af0bde700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45852)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45852)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45852)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45852)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45852)\u001b[0m *** SIGSEGV (@0x0) received by PID 45852 (TID 0x7f27ccc3f700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45814)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45814)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45814)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45814)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45814)\u001b[0m *** SIGSEGV (@0x0) received by PID 45814 (TID 0x7fdd75e04700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45872)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45872)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45872)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45872)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45872)\u001b[0m *** SIGSEGV (@0x0) received by PID 45872 (TID 0x7f321b861700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45864)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45864)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45864)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45864)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45864)\u001b[0m *** SIGSEGV (@0x0) received by PID 45864 (TID 0x7f613fe3e700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45785)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45785)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45785)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45785)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45785)\u001b[0m *** SIGSEGV (@0x0) received by PID 45785 (TID 0x7f21da33e700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45786)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45786)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45786)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45786)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45786)\u001b[0m *** SIGSEGV (@0x0) received by PID 45786 (TID 0x7fa2cc9c4700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45786)\u001b[0m     @     0x7fa2cc59d390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45786)\u001b[0m     @     0x7f73c9940f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45789)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45789)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45789)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45789)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45789)\u001b[0m *** SIGSEGV (@0x0) received by PID 45789 (TID 0x7fb96f3fd700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45789)\u001b[0m     @     0x7fb96efd6390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45789)\u001b[0m     @     0x7f8a6ef13f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45789)\u001b[0m     @     0x7f8a6e63e7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45789)\u001b[0m     @     0x7f8a6e6418f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45882)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45882)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45882)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45882)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45882)\u001b[0m *** SIGSEGV (@0x0) received by PID 45882 (TID 0x7f3cc7d37700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45882)\u001b[0m     @     0x7f3cc7910390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45882)\u001b[0m     @     0x7f0dc789ef90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45882)\u001b[0m     @     0x7f0dc6fc97db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45882)\u001b[0m     @     0x7f0dc6fcc8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45879)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45879)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45879)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45879)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45879)\u001b[0m *** SIGSEGV (@0x0) received by PID 45879 (TID 0x7f0e70546700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45879)\u001b[0m     @     0x7f0e7011f390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45879)\u001b[0m     @     0x7edf700cdf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45879)\u001b[0m     @     0x7edf6f7f87db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45798)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45798)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45798)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45798)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45798)\u001b[0m *** SIGSEGV (@0x0) received by PID 45798 (TID 0x7f1b451ea700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45798)\u001b[0m     @     0x7f1b44dc3390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45798)\u001b[0m     @     0x7eec44c74f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45798)\u001b[0m     @     0x7eec4439f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45798)\u001b[0m     @     0x7eec443a28f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45818)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45818)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45818)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45818)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45818)\u001b[0m *** SIGSEGV (@0x0) received by PID 45818 (TID 0x7fa512fa6700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45818)\u001b[0m     @     0x7fa512b7f390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45818)\u001b[0m     @     0x7f7612ad1f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45818)\u001b[0m     @     0x7f76121fc7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45818)\u001b[0m     @     0x7f76121ff8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45878)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45878)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45878)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45878)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45878)\u001b[0m *** SIGSEGV (@0x0) received by PID 45878 (TID 0x7f419af48700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45878)\u001b[0m     @     0x7f419ab21390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45878)\u001b[0m     @     0x7f129aad1f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45878)\u001b[0m     @     0x7f129a1fc7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45878)\u001b[0m     @     0x7f129a1ff8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45791)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45791)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45791)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45791)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45791)\u001b[0m *** SIGSEGV (@0x0) received by PID 45791 (TID 0x7fa61f785700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45791)\u001b[0m     @     0x7fa61f35e390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45791)\u001b[0m     @     0x7f771f2e6f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45791)\u001b[0m     @     0x7f771ea117db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45791)\u001b[0m     @     0x7f771ea148f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45791)\u001b[0m     @     0x7f771ea14ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45898)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45898)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45898)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45898)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45898)\u001b[0m *** SIGSEGV (@0x0) received by PID 45898 (TID 0x7f372ec06700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45898)\u001b[0m     @     0x7f372e7df390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45898)\u001b[0m     @     0x7f082e5a4f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45898)\u001b[0m     @     0x7f082dccf7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45898)\u001b[0m     @     0x7f082dcd28f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45855)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45855)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45855)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45855)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45855)\u001b[0m *** SIGSEGV (@0x0) received by PID 45855 (TID 0x7f9dd35f9700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45855)\u001b[0m     @     0x7f9dd31d2390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45855)\u001b[0m     @     0x7f6ed3124f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45855)\u001b[0m     @     0x7f6ed284f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45855)\u001b[0m     @     0x7f6ed28528f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45855)\u001b[0m     @     0x7f6ed2852ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45788)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45788)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45788)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45788)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45788)\u001b[0m *** SIGSEGV (@0x0) received by PID 45788 (TID 0x7f2c5cd49700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45788)\u001b[0m     @     0x7f2c5c922390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45788)\u001b[0m     @     0x7efd5c774f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45788)\u001b[0m     @     0x7efd5be9f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45788)\u001b[0m     @     0x7efd5bea28f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45796)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45796)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45796)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45796)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45796)\u001b[0m *** SIGSEGV (@0x0) received by PID 45796 (TID 0x7fbb63782700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45796)\u001b[0m     @     0x7fbb6335b390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45796)\u001b[0m     @     0x7f8c63229f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45796)\u001b[0m     @     0x7f8c629547db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45796)\u001b[0m     @     0x7f8c629578f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45796)\u001b[0m     @     0x7f8c62957ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45870)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45870)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45870)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45870)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45870)\u001b[0m *** SIGSEGV (@0x0) received by PID 45870 (TID 0x7f29f11f3700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45870)\u001b[0m     @     0x7f29f0dcc390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45870)\u001b[0m     @     0x7efaf0c74f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45870)\u001b[0m     @     0x7efaf039f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45859)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45859)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45859)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45859)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45859)\u001b[0m *** SIGSEGV (@0x0) received by PID 45859 (TID 0x7fa916c09700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45859)\u001b[0m     @     0x7fa9167e2390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45859)\u001b[0m     @     0x7f7a164f9f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45859)\u001b[0m     @     0x7f7a15c247db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45859)\u001b[0m     @     0x7f7a15c278f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45803)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45803)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45803)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45803)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45803)\u001b[0m *** SIGSEGV (@0x0) received by PID 45803 (TID 0x7f30de795700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45803)\u001b[0m     @     0x7f30de36e390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45803)\u001b[0m     @     0x7f01de31ef90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45803)\u001b[0m     @     0x7f01dda497db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45803)\u001b[0m     @     0x7f01dda4c8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45812)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45812)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45812)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45812)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45812)\u001b[0m *** SIGSEGV (@0x0) received by PID 45812 (TID 0x7fbd8d3b8700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45812)\u001b[0m     @     0x7fbd8cf91390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45812)\u001b[0m     @     0x7f8e8cea4f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45812)\u001b[0m     @     0x7f8e8c5cf7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45812)\u001b[0m     @     0x7f8e8c5d28f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45903)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45903)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45903)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45903)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45903)\u001b[0m *** SIGSEGV (@0x0) received by PID 45903 (TID 0x7fa262f96700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45903)\u001b[0m     @     0x7fa262b6f390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45903)\u001b[0m     @     0x7f7362a21f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45903)\u001b[0m     @     0x7f736214c7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45903)\u001b[0m     @     0x7f736214f8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45861)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45861)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45861)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45861)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45861)\u001b[0m *** SIGSEGV (@0x0) received by PID 45861 (TID 0x7fb36dcf5700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45861)\u001b[0m     @     0x7fb36d8ce390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45861)\u001b[0m     @     0x7f846d6f4f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45861)\u001b[0m     @     0x7f846ce1f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45846)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45846)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45846)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45846)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45846)\u001b[0m *** SIGSEGV (@0x0) received by PID 45846 (TID 0x7f614b3af700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45846)\u001b[0m     @     0x7f614af88390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45846)\u001b[0m     @     0x7f324af13f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45846)\u001b[0m     @     0x7f324a63e7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45857)\u001b[0m     @     0x7fae80db27db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45857)\u001b[0m     @     0x7fae80db58f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45857)\u001b[0m     @     0x7fae80db5ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45857)\u001b[0m     @     0x7fae80db5d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45883)\u001b[0m     @     0x7f2e584258f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45883)\u001b[0m     @     0x7f2e58425ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45883)\u001b[0m     @     0x7f2e58425d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45792)\u001b[0m     @     0x7f2896e81f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45792)\u001b[0m     @     0x7f28965ac7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45792)\u001b[0m     @     0x7f28965af8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45792)\u001b[0m     @     0x7f28965afad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45874)\u001b[0m     @     0x7fb827d81f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45874)\u001b[0m     @     0x7fb8274ac7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45874)\u001b[0m     @     0x7fb8274af8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45874)\u001b[0m     @     0x7fb8274afad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45869)\u001b[0m     @     0x7ef7f60284f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45869)\u001b[0m     @     0x7ef7fc0d379f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45869)\u001b[0m     @     0x5627a62b4fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45869)\u001b[0m     @     0x5627a620fb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45869)\u001b[0m     @     0x5627a629abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45869)\u001b[0m     @     0x5627a629ba20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45869)\u001b[0m     @     0x5627a620fbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45869)\u001b[0m     @     0x5627a629abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45869)\u001b[0m     @     0x5627a629b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45869)\u001b[0m     @     0x5627a6210689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45869)\u001b[0m     @     0x5627a629abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45869)\u001b[0m     @     0x5627a629b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45869)\u001b[0m     @     0x5627a6210689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45869)\u001b[0m     @     0x5627a629abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45869)\u001b[0m     @     0x5627a629b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45869)\u001b[0m     @     0x5627a6210689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45869)\u001b[0m     @     0x5627a629abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45869)\u001b[0m     @     0x5627a629b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45869)\u001b[0m     @     0x5627a6210689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45810)\u001b[0m     @     0x7f3a90f247db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45810)\u001b[0m     @     0x7f3a90f278f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45810)\u001b[0m     @     0x7f3a90f27ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45849)\u001b[0m     @     0x7f5163c918f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45849)\u001b[0m     @     0x7f5163c91ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45849)\u001b[0m     @     0x7f5163c91d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45905)\u001b[0m     @     0x7f6851564f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45905)\u001b[0m     @     0x7f6850c8f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45905)\u001b[0m     @     0x7f6850c928f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45905)\u001b[0m     @     0x7f6850c92ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45880)\u001b[0m     @     0x7fb2f1b7af90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45880)\u001b[0m     @     0x7fb2f12a57db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45880)\u001b[0m     @     0x7fb2f12a88f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45880)\u001b[0m     @     0x7fb2f12a8ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45904)\u001b[0m     @     0x7f1c38cac390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45904)\u001b[0m     @     0x7eed38b3bf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45904)\u001b[0m     @     0x7eed382667db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45904)\u001b[0m     @     0x7eed382698f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45904)\u001b[0m     @     0x7eed38269ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45887)\u001b[0m     @     0x7fb07098a4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45887)\u001b[0m     @     0x7fb072e5d8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45887)\u001b[0m     @     0x7fb07098a4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45887)\u001b[0m     @     0x7fb076a3579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45887)\u001b[0m     @     0x55a07fb0ffd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45887)\u001b[0m     @     0x55a07fa6ab08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45887)\u001b[0m     @     0x55a07faf5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45887)\u001b[0m     @     0x55a07faf6a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45887)\u001b[0m     @     0x55a07fa6abfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45887)\u001b[0m     @     0x55a07faf5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45887)\u001b[0m     @     0x55a07faf6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45887)\u001b[0m     @     0x55a07fa6b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45887)\u001b[0m     @     0x55a07faf5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45887)\u001b[0m     @     0x55a07faf6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45887)\u001b[0m     @     0x55a07fa6b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45887)\u001b[0m     @     0x55a07faf5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45887)\u001b[0m     @     0x55a07faf6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45887)\u001b[0m     @     0x55a07fa6b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45887)\u001b[0m     @     0x55a07faf5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45866)\u001b[0m     @     0x7f6dd65c2390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45866)\u001b[0m     @     0x7f3ed64f9f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45866)\u001b[0m     @     0x7f3ed5c247db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45866)\u001b[0m     @     0x7f3ed5c278f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45866)\u001b[0m     @     0x7f3ed5c27ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45909)\u001b[0m     @     0x7f9b630504f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45909)\u001b[0m     @     0x7f9b655238de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45909)\u001b[0m     @     0x7f9b630504f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45909)\u001b[0m     @     0x7f9b690fb79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45909)\u001b[0m     @     0x5577c9143fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45909)\u001b[0m     @     0x5577c909eb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45909)\u001b[0m     @     0x5577c9129baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45909)\u001b[0m     @     0x5577c912aa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45909)\u001b[0m     @     0x5577c909ebfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45909)\u001b[0m     @     0x5577c9129baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45909)\u001b[0m     @     0x5577c912a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45909)\u001b[0m     @     0x5577c909f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45909)\u001b[0m     @     0x5577c9129baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45909)\u001b[0m     @     0x5577c912a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45909)\u001b[0m     @     0x5577c909f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45909)\u001b[0m     @     0x5577c9129baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45909)\u001b[0m     @     0x5577c912a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45909)\u001b[0m     @     0x5577c909f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45909)\u001b[0m     @     0x5577c9129baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45909)\u001b[0m     @     0x5577c912a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45909)\u001b[0m     @     0x5577c909f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45868)\u001b[0m     @     0x7f730bc2aad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45868)\u001b[0m     @     0x7f730bc2ad91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45868)\u001b[0m     @     0x7f730c50db22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45868)\u001b[0m     @     0x7f730c530c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45860)\u001b[0m     @     0x7f09fb3124f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45860)\u001b[0m     @     0x7f09fd7e58de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45860)\u001b[0m     @     0x7f09fb3124f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45860)\u001b[0m     @     0x7f0a013bd79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45860)\u001b[0m     @     0x559bfa294fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45860)\u001b[0m     @     0x559bfa1efb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45860)\u001b[0m     @     0x559bfa27abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45860)\u001b[0m     @     0x559bfa27ba20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45860)\u001b[0m     @     0x559bfa1efbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45860)\u001b[0m     @     0x559bfa27abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45860)\u001b[0m     @     0x559bfa27b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45860)\u001b[0m     @     0x559bfa1f0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45860)\u001b[0m     @     0x559bfa27abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45860)\u001b[0m     @     0x559bfa27b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45860)\u001b[0m     @     0x559bfa1f0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45860)\u001b[0m     @     0x559bfa27abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45860)\u001b[0m     @     0x559bfa27b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45860)\u001b[0m     @     0x559bfa1f0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45860)\u001b[0m     @     0x559bfa27abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45860)\u001b[0m     @     0x559bfa27b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45860)\u001b[0m     @     0x559bfa1f0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45853)\u001b[0m     @     0x7fbf095528f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45853)\u001b[0m     @     0x7fbf09552ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45891)\u001b[0m     @     0x7eeab7a648f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45891)\u001b[0m     @     0x7eeab7a64ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45891)\u001b[0m     @     0x7eeab7a64d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45921)\u001b[0m     @     0x7f62917ce4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45921)\u001b[0m     @     0x7f629787979f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45921)\u001b[0m     @     0x55c97d799fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45921)\u001b[0m     @     0x55c97d6f4b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45921)\u001b[0m     @     0x55c97d77fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45921)\u001b[0m     @     0x55c97d780a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45921)\u001b[0m     @     0x55c97d6f4bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45921)\u001b[0m     @     0x55c97d77fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45921)\u001b[0m     @     0x55c97d780643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45921)\u001b[0m     @     0x55c97d6f5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45921)\u001b[0m     @     0x55c97d77fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45921)\u001b[0m     @     0x55c97d780643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45921)\u001b[0m     @     0x55c97d6f5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45921)\u001b[0m     @     0x55c97d77fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45921)\u001b[0m     @     0x55c97d780643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45921)\u001b[0m     @     0x55c97d6f5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45921)\u001b[0m     @     0x55c97d77fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45921)\u001b[0m     @     0x55c97d780643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45921)\u001b[0m     @     0x55c97d6f5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45912)\u001b[0m     @     0x7ef299f0c4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45912)\u001b[0m     @     0x7ef29ffb779f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45912)\u001b[0m     @     0x55f857a31fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45912)\u001b[0m     @     0x55f85798cb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45912)\u001b[0m     @     0x55f857a17baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45912)\u001b[0m     @     0x55f857a18a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45912)\u001b[0m     @     0x55f85798cbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45912)\u001b[0m     @     0x55f857a17baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45912)\u001b[0m     @     0x55f857a18643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45912)\u001b[0m     @     0x55f85798d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45912)\u001b[0m     @     0x55f857a17baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45912)\u001b[0m     @     0x55f857a18643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45912)\u001b[0m     @     0x55f85798d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45912)\u001b[0m     @     0x55f857a17baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45912)\u001b[0m     @     0x55f857a18643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45912)\u001b[0m     @     0x55f85798d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45912)\u001b[0m     @     0x55f857a17baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45912)\u001b[0m     @     0x55f857a18643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45912)\u001b[0m     @     0x55f85798d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45889)\u001b[0m     @     0x7f56205d28f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45889)\u001b[0m     @     0x7f56205d2ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45889)\u001b[0m     @     0x7f56205d2d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45889)\u001b[0m     @     0x7f5620eb5b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45896)\u001b[0m     @     0x7fb58079e8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45896)\u001b[0m     @     0x7fb57e2cb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45896)\u001b[0m     @     0x7fb58437679f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45896)\u001b[0m     @     0x56264e27dfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45896)\u001b[0m     @     0x56264e1d8b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45896)\u001b[0m     @     0x56264e263baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45896)\u001b[0m     @     0x56264e264a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45896)\u001b[0m     @     0x56264e1d8bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45896)\u001b[0m     @     0x56264e263baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45896)\u001b[0m     @     0x56264e264643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45896)\u001b[0m     @     0x56264e1d9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45896)\u001b[0m     @     0x56264e263baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45896)\u001b[0m     @     0x56264e264643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45896)\u001b[0m     @     0x56264e1d9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45896)\u001b[0m     @     0x56264e263baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45896)\u001b[0m     @     0x56264e264643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45896)\u001b[0m     @     0x56264e1d9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45896)\u001b[0m     @     0x56264e263baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45896)\u001b[0m     @     0x56264e264643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45896)\u001b[0m     @     0x56264e1d9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "2020-11-05 10:44:44,481\tWARNING worker.py:945 -- The driver may not be able to keep up with the stdout/stderr of the workers. To avoid forwarding logs to the driver, use 'ray.init(log_to_driver=False)'.\n",
+      "\u001b[2m\u001b[36m(pid=45884)\u001b[0m     @     0x7fad5e2cb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45884)\u001b[0m     @     0x7fad6437679f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45884)\u001b[0m     @     0x559b992f8fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45884)\u001b[0m     @     0x559b99253b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45884)\u001b[0m     @     0x559b992debaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45884)\u001b[0m     @     0x559b992dfa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45884)\u001b[0m     @     0x559b99253bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45884)\u001b[0m     @     0x559b992debaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45884)\u001b[0m     @     0x559b992df643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45884)\u001b[0m     @     0x559b99254689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45884)\u001b[0m     @     0x559b992debaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45884)\u001b[0m     @     0x559b992df643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45884)\u001b[0m     @     0x559b99254689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45884)\u001b[0m     @     0x559b992debaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45884)\u001b[0m     @     0x559b992df643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45884)\u001b[0m     @     0x559b99254689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45884)\u001b[0m     @     0x559b992debaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45884)\u001b[0m     @     0x559b992df643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45884)\u001b[0m     @     0x559b99254689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45871)\u001b[0m     @     0x7f8d48e1f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45871)\u001b[0m     @     0x7f8d48e228f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45807)\u001b[0m     @     0x7fbc39c227db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45807)\u001b[0m     @     0x7fbc39c258f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45807)\u001b[0m     @     0x7fbc39c25ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45804)\u001b[0m     @     0x7fc9157f9f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45804)\u001b[0m     @     0x7fc914f247db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45804)\u001b[0m     @     0x7fc914f278f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45804)\u001b[0m     @     0x7fc914f27ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45858)\u001b[0m     @     0x7f194330e390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45858)\u001b[0m     @     0x7eea43229f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45858)\u001b[0m     @     0x7eea429547db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45858)\u001b[0m     @     0x7eea429578f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45858)\u001b[0m     @     0x7eea42957ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45799)\u001b[0m     @     0x7f57625a4f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45799)\u001b[0m     @     0x7f5761ccf7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45799)\u001b[0m     @     0x7f5761cd28f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45799)\u001b[0m     @     0x7f5761cd2ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45865)\u001b[0m     @     0x7fa1a21d28f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45865)\u001b[0m     @     0x7fa1a21d2ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45865)\u001b[0m     @     0x7fa1a21d2d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45894)\u001b[0m     @     0x7f9de53ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45894)\u001b[0m     @     0x7f9deb46579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45894)\u001b[0m     @     0x555dbc731fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45894)\u001b[0m     @     0x555dbc68cb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45894)\u001b[0m     @     0x555dbc717baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45894)\u001b[0m     @     0x555dbc718a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45894)\u001b[0m     @     0x555dbc68cbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45894)\u001b[0m     @     0x555dbc717baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45894)\u001b[0m     @     0x555dbc718643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45894)\u001b[0m     @     0x555dbc68d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45894)\u001b[0m     @     0x555dbc717baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45894)\u001b[0m     @     0x555dbc718643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45894)\u001b[0m     @     0x555dbc68d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45894)\u001b[0m     @     0x555dbc717baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45894)\u001b[0m     @     0x555dbc718643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45894)\u001b[0m     @     0x555dbc68d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45894)\u001b[0m     @     0x555dbc717baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45894)\u001b[0m     @     0x555dbc718643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45894)\u001b[0m     @     0x555dbc68d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45862)\u001b[0m     @     0x7f335b0d5f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45862)\u001b[0m     @     0x7f335a8007db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45862)\u001b[0m     @     0x7f335a8038f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45862)\u001b[0m     @     0x7f335a803ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45862)\u001b[0m     @     0x7f335a803d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45877)\u001b[0m     @     0x7f94413c8390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45877)\u001b[0m     @     0x7f654135ff90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45877)\u001b[0m     @     0x7f6540a8a7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45877)\u001b[0m     @     0x7f6540a8d8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45877)\u001b[0m     @     0x7f6540a8dad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45842)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45842)\u001b[0m *** SIGSEGV (@0x0) received by PID 45842 (TID 0x7f05fdc34700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45842)\u001b[0m     @     0x7f05fd80d390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45842)\u001b[0m     @     0x7ed6fd6f4f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45842)\u001b[0m     @     0x7ed6fce1f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45794)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45794)\u001b[0m *** SIGSEGV (@0x0) received by PID 45794 (TID 0x7f8b007d7700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45794)\u001b[0m     @     0x7f8b003b0390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45794)\u001b[0m     @     0x7f5c00101f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45794)\u001b[0m     @     0x7f5bff82c7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45844)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45844)\u001b[0m *** SIGSEGV (@0x0) received by PID 45844 (TID 0x7f1185fa7700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45844)\u001b[0m     @     0x7f1185b80390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45844)\u001b[0m     @     0x7ee285a0af90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45844)\u001b[0m     @     0x7ee2851357db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45844)\u001b[0m     @     0x7ee2851388f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45822)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45822)\u001b[0m *** SIGSEGV (@0x0) received by PID 45822 (TID 0x7fdc0b4bf700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45822)\u001b[0m     @     0x7fdc0b098390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45822)\u001b[0m     @     0x7fad0af13f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45822)\u001b[0m     @     0x7fad0a63e7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45822)\u001b[0m     @     0x7fad0a6418f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45895)\u001b[0m     @     0x7f9b3a7b7390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45895)\u001b[0m     @     0x7f6c3a4f9f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45895)\u001b[0m     @     0x7f6c39c247db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45895)\u001b[0m     @     0x7f6c39c278f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45895)\u001b[0m     @     0x7f6c39c27ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45906)\u001b[0m     @     0x7ef9f4e37f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45906)\u001b[0m     @     0x7ef9f45627db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45906)\u001b[0m     @     0x7ef9f45658f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45906)\u001b[0m     @     0x7ef9f4565ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45885)\u001b[0m     @     0x7f8503f538f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45885)\u001b[0m     @     0x7f8503f53ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45885)\u001b[0m     @     0x7f8503f53d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45885)\u001b[0m     @     0x7f8504836b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45809)\u001b[0m     @     0x7f60a4f278f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45809)\u001b[0m     @     0x7f60a4f27ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45809)\u001b[0m     @     0x7f60a4f27d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45809)\u001b[0m     @     0x7f60a580ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45809)\u001b[0m     @     0x7f60a582dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45805)\u001b[0m     @     0x7fbe96fdf8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45805)\u001b[0m     @     0x7fbe96fdfad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45805)\u001b[0m     @     0x7fbe96fdfd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45805)\u001b[0m     @     0x7fbe978c2b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45805)\u001b[0m     @     0x7fbe978e5c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45805)\u001b[0m     @     0x7fbe96d87a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45805)\u001b[0m     @     0x7fbe96d85388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45808)\u001b[0m     @     0x7f149d41d8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45808)\u001b[0m     @     0x7f149d41dad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45808)\u001b[0m     @     0x7f149d41dd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45808)\u001b[0m     @     0x7f149dd00b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45808)\u001b[0m     @     0x7f149dd23c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45808)\u001b[0m     @     0x7f149d1c5a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45808)\u001b[0m     @     0x7f149d1c3388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45787)\u001b[0m     @     0x7ef25da798f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45787)\u001b[0m     @     0x7ef25da79ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45787)\u001b[0m     @     0x7ef25da79d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45787)\u001b[0m     @     0x7ef25e35cb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45787)\u001b[0m     @     0x7ef25e37fc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45787)\u001b[0m     @     0x7ef25d821a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45787)\u001b[0m     @     0x7ef25d81f388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45811)\u001b[0m     @     0x7fb4eeb98ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45811)\u001b[0m     @     0x7fb4eeb98d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45811)\u001b[0m     @     0x7fb4ef47bb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45811)\u001b[0m     @     0x7fb4ef49ec1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45811)\u001b[0m     @     0x7fb4ee940a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45811)\u001b[0m     @     0x7fb4ee93e388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45811)\u001b[0m     @     0x7fb4ee9405a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45901)\u001b[0m     @     0x7f3f8bf538f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45901)\u001b[0m     @     0x7f3f8bf53ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45901)\u001b[0m     @     0x7f3f8bf53d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45901)\u001b[0m     @     0x7f3f8c836b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45901)\u001b[0m     @     0x7f3f8c859c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45901)\u001b[0m     @     0x7f3f8bcfba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45901)\u001b[0m     @     0x7f3f8bcf9388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45820)\u001b[0m     @     0x7f06a6aca8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45820)\u001b[0m     @     0x7f06a45f74f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45820)\u001b[0m     @     0x7f06aa6a279f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45820)\u001b[0m     @     0x55c5590dcfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45820)\u001b[0m     @     0x55c559037b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45820)\u001b[0m     @     0x55c5590c2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45820)\u001b[0m     @     0x55c5590c3a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45820)\u001b[0m     @     0x55c559037bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45820)\u001b[0m     @     0x55c5590c2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45820)\u001b[0m     @     0x55c5590c3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45820)\u001b[0m     @     0x55c559038689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45820)\u001b[0m     @     0x55c5590c2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45820)\u001b[0m     @     0x55c5590c3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45820)\u001b[0m     @     0x55c559038689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45820)\u001b[0m     @     0x55c5590c2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45820)\u001b[0m     @     0x55c5590c3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45820)\u001b[0m     @     0x55c559038689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45820)\u001b[0m     @     0x55c5590c2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45820)\u001b[0m     @     0x55c5590c3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45820)\u001b[0m     @     0x55c559038689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45793)\u001b[0m     @     0x7f718753c8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45793)\u001b[0m     @     0x7f718753cad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45793)\u001b[0m     @     0x7f718753cd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45793)\u001b[0m     @     0x7f7187e1fb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45793)\u001b[0m     @     0x7f7187e42c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45793)\u001b[0m     @     0x7f71872e4a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45793)\u001b[0m     @     0x7f71872e2388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45802)\u001b[0m     @     0x7f332fa678f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45802)\u001b[0m     @     0x7f332fa67ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45802)\u001b[0m     @     0x7f332fa67d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45802)\u001b[0m     @     0x7f333034ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45802)\u001b[0m     @     0x7f333036dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45802)\u001b[0m     @     0x7f332f80fa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45802)\u001b[0m     @     0x7f332f80d388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45850)\u001b[0m     @     0x7f09b41cf4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45850)\u001b[0m     @     0x7f09b66a28de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45850)\u001b[0m     @     0x7f09b41cf4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45850)\u001b[0m     @     0x7f09ba27a79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45850)\u001b[0m     @     0x556dd4f26fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45850)\u001b[0m     @     0x556dd4e81b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45850)\u001b[0m     @     0x556dd4f0cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45850)\u001b[0m     @     0x556dd4f0da20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45850)\u001b[0m     @     0x556dd4e81bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45850)\u001b[0m     @     0x556dd4f0cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45850)\u001b[0m     @     0x556dd4f0d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45850)\u001b[0m     @     0x556dd4e82689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45850)\u001b[0m     @     0x556dd4f0cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45850)\u001b[0m     @     0x556dd4f0d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45850)\u001b[0m     @     0x556dd4e82689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45850)\u001b[0m     @     0x556dd4f0cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45850)\u001b[0m     @     0x556dd4f0d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45850)\u001b[0m     @     0x556dd4e82689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45850)\u001b[0m     @     0x556dd4f0cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45850)\u001b[0m     @     0x556dd4f0d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45850)\u001b[0m     @     0x556dd4e82689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45863)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45863)\u001b[0m *** SIGSEGV (@0x0) received by PID 45863 (TID 0x7f78839cd700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45863)\u001b[0m     @     0x7f78835a6390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45863)\u001b[0m     @     0x7f498354df90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45863)\u001b[0m     @     0x7f4982c787db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45863)\u001b[0m     @     0x7f4982c7b8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45863)\u001b[0m     @     0x7f4982c7bad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45806)\u001b[0m     @     0x7fab8954f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45806)\u001b[0m     @     0x7fab895528f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45806)\u001b[0m     @     0x7fab89552ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45806)\u001b[0m     @     0x7fab89552d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45806)\u001b[0m     @     0x7fab89e35b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45806)\u001b[0m     @     0x7fab89e58c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45806)\u001b[0m     @     0x7fab892faa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45795)\u001b[0m     @     0x7f39601648f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45795)\u001b[0m     @     0x7f3960164ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45795)\u001b[0m     @     0x7f3960164d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45795)\u001b[0m     @     0x7f3960a47b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45795)\u001b[0m     @     0x7f3960a6ac1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45795)\u001b[0m     @     0x7f395ff0ca93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45876)\u001b[0m     @     0x7f749b31d390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45876)\u001b[0m     @     0x7f459b229f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45876)\u001b[0m     @     0x7f459a9547db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45876)\u001b[0m     @     0x7f459a9578f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45876)\u001b[0m     @     0x7f459a957ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45876)\u001b[0m     @     0x7f459a957d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45876)\u001b[0m     @     0x7f459b23ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45876)\u001b[0m     @     0x7f459b25dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45790)\u001b[0m     @     0x7f7c5e78ef90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45790)\u001b[0m     @     0x7f7c5deb97db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45790)\u001b[0m     @     0x7f7c5debc8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45790)\u001b[0m     @     0x7f7c5debcad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45790)\u001b[0m     @     0x7f7c5debcd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45790)\u001b[0m     @     0x7f7c5e79fb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45790)\u001b[0m     @     0x7f7c5e7c2c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45800)\u001b[0m     @     0x7f9af07b7390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45800)\u001b[0m     @     0x7f6bf0563f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45800)\u001b[0m     @     0x7f6befc8e7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45800)\u001b[0m     @     0x7f6befc918f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45800)\u001b[0m     @     0x7f6befc91ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45800)\u001b[0m     @     0x7f6befc91d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45800)\u001b[0m     @     0x7f6bf0574b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45800)\u001b[0m     @     0x7f6bf0597c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45852)\u001b[0m     @     0x7f27cc818390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45852)\u001b[0m     @     0x7ef8cc563f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45852)\u001b[0m     @     0x7ef8cbc8e7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45852)\u001b[0m     @     0x7ef8cbc918f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45852)\u001b[0m     @     0x7ef8cbc91ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45852)\u001b[0m     @     0x7ef8cbc91d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45852)\u001b[0m     @     0x7ef8cc574b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45852)\u001b[0m     @     0x7ef8cc597c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45814)\u001b[0m     @     0x7fdd759dd390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45814)\u001b[0m     @     0x7fae757f9f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45814)\u001b[0m     @     0x7fae74f247db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45814)\u001b[0m     @     0x7fae74f278f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45814)\u001b[0m     @     0x7fae74f27ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45814)\u001b[0m     @     0x7fae74f27d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45814)\u001b[0m     @     0x7fae7580ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45814)\u001b[0m     @     0x7fae7582dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45872)\u001b[0m     @     0x7f321b43a390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45872)\u001b[0m     @     0x7f031b229f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45872)\u001b[0m     @     0x7f031a9547db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45872)\u001b[0m     @     0x7f031a9578f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45872)\u001b[0m     @     0x7f031a957ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45872)\u001b[0m     @     0x7f031a957d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45872)\u001b[0m     @     0x7f031b23ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45864)\u001b[0m     @     0x7f613fa17390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45864)\u001b[0m     @     0x7f323f8def90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45864)\u001b[0m     @     0x7f323f0097db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45864)\u001b[0m     @     0x7f323f00c8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45864)\u001b[0m     @     0x7f323f00cad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45864)\u001b[0m     @     0x7f323f00cd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45864)\u001b[0m     @     0x7f323f8efb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45864)\u001b[0m     @     0x7f323f912c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45785)\u001b[0m     @     0x7f21d9f17390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45785)\u001b[0m     @     0x7ef2d9e24f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45785)\u001b[0m     @     0x7ef2d954f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45785)\u001b[0m     @     0x7ef2d95528f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45785)\u001b[0m     @     0x7ef2d9552ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45786)\u001b[0m     @     0x7f73c906b7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45786)\u001b[0m     @     0x7f73c906e8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45786)\u001b[0m     @     0x7f73c906ead3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45786)\u001b[0m     @     0x7f73c906ed91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45786)\u001b[0m     @     0x7f73c9951b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45786)\u001b[0m     @     0x7f73c9974c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45786)\u001b[0m     @     0x7f73c8e16a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45786)\u001b[0m     @     0x7f73c8e14388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45867)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=45867)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=45867)\u001b[0m *** Aborted at 1604573084 (unix time) try \"date -d @1604573084\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=45867)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45867)\u001b[0m *** SIGSEGV (@0x0) received by PID 45867 (TID 0x7f408a84d700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=45867)\u001b[0m     @     0x7f408a426390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=45867)\u001b[0m     @     0x7f118a34bf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=45867)\u001b[0m     @     0x7f1189a767db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=45867)\u001b[0m     @     0x7f1189a798f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45867)\u001b[0m     @     0x7f1189a79ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45789)\u001b[0m     @     0x7f8a6e641ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45789)\u001b[0m     @     0x7f8a6e641d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45789)\u001b[0m     @     0x7f8a6ef24b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45789)\u001b[0m     @     0x7f8a6ef47c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45789)\u001b[0m     @     0x7f8a6e3e9a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45789)\u001b[0m     @     0x7f8a6e3e7388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45882)\u001b[0m     @     0x7f0dc6fccad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45882)\u001b[0m     @     0x7f0dc6fccd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45882)\u001b[0m     @     0x7f0dc78afb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45882)\u001b[0m     @     0x7f0dc78d2c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45882)\u001b[0m     @     0x7f0dc6d74a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45882)\u001b[0m     @     0x7f0dc6d72388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45879)\u001b[0m     @     0x7edf6f7fb8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45879)\u001b[0m     @     0x7edf6f7fbad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45798)\u001b[0m     @     0x7eec443a2ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45798)\u001b[0m     @     0x7eec443a2d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45798)\u001b[0m     @     0x7eec44c85b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45798)\u001b[0m     @     0x7eec44ca8c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45798)\u001b[0m     @     0x7eec4414aa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45798)\u001b[0m     @     0x7eec44148388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45818)\u001b[0m     @     0x7f76121ffad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45818)\u001b[0m     @     0x7f76121ffd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45818)\u001b[0m     @     0x7f7612ae2b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45818)\u001b[0m     @     0x7f7612b05c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45818)\u001b[0m     @     0x7f7611fa7a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45878)\u001b[0m     @     0x7f129a1ffad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45878)\u001b[0m     @     0x7f129a1ffd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45878)\u001b[0m     @     0x7f129aae2b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45878)\u001b[0m     @     0x7f129ab05c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45791)\u001b[0m     @     0x7f771ea14d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45791)\u001b[0m     @     0x7f771f2f7b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45791)\u001b[0m     @     0x7f771f31ac1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45791)\u001b[0m     @     0x7f771e7bca93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45791)\u001b[0m     @     0x7f771e7ba388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45791)\u001b[0m     @     0x7f771e7bc5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45898)\u001b[0m     @     0x7f082dcd2ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45898)\u001b[0m     @     0x7f082dcd2d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45898)\u001b[0m     @     0x7f082e5b5b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45898)\u001b[0m     @     0x7f082e5d8c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45898)\u001b[0m     @     0x7f082da7aa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45898)\u001b[0m     @     0x7f082da78388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45898)\u001b[0m     @     0x7f082da7a5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45855)\u001b[0m     @     0x7f6ed2852d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45855)\u001b[0m     @     0x7f6ed3135b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45855)\u001b[0m     @     0x7f6ed3158c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45855)\u001b[0m     @     0x7f6ed25faa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45855)\u001b[0m     @     0x7f6ed25f8388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45855)\u001b[0m     @     0x7f6ed25fa5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45855)\u001b[0m     @     0x7f6ed2ce54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45788)\u001b[0m     @     0x7efd5bea2ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45788)\u001b[0m     @     0x7efd5bea2d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45788)\u001b[0m     @     0x7efd5c785b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45788)\u001b[0m     @     0x7efd5c7a8c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45788)\u001b[0m     @     0x7efd5bc4aa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45788)\u001b[0m     @     0x7efd5bc48388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45788)\u001b[0m     @     0x7efd5bc4a5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45796)\u001b[0m     @     0x7f8c62957d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45796)\u001b[0m     @     0x7f8c6323ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45796)\u001b[0m     @     0x7f8c6325dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45796)\u001b[0m     @     0x7f8c626ffa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45796)\u001b[0m     @     0x7f8c626fd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45796)\u001b[0m     @     0x7f8c626ff5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45796)\u001b[0m     @     0x7f8c62dea4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45870)\u001b[0m     @     0x7efaf03a28f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45870)\u001b[0m     @     0x7efaf03a2ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45870)\u001b[0m     @     0x7efaf03a2d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45870)\u001b[0m     @     0x7efaf0c85b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45870)\u001b[0m     @     0x7efaf0ca8c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45870)\u001b[0m     @     0x7efaf014aa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45870)\u001b[0m     @     0x7efaf0148388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45859)\u001b[0m     @     0x7f7a15c27ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45859)\u001b[0m     @     0x7f7a15c27d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45859)\u001b[0m     @     0x7f7a1650ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45859)\u001b[0m     @     0x7f7a1652dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45859)\u001b[0m     @     0x7f7a159cfa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45859)\u001b[0m     @     0x7f7a159cd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45803)\u001b[0m     @     0x7f01dda4cad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45803)\u001b[0m     @     0x7f01dda4cd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45803)\u001b[0m     @     0x7f01de32fb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45803)\u001b[0m     @     0x7f01de352c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45803)\u001b[0m     @     0x7f01dd7f4a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45803)\u001b[0m     @     0x7f01dd7f2388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45803)\u001b[0m     @     0x7f01dd7f45a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45812)\u001b[0m     @     0x7f8e8c5d2ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45812)\u001b[0m     @     0x7f8e8c5d2d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45812)\u001b[0m     @     0x7f8e8ceb5b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45812)\u001b[0m     @     0x7f8e8ced8c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45812)\u001b[0m     @     0x7f8e8c37aa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45812)\u001b[0m     @     0x7f8e8c378388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45812)\u001b[0m     @     0x7f8e8c37a5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45903)\u001b[0m     @     0x7f736214fad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45903)\u001b[0m     @     0x7f736214fd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45903)\u001b[0m     @     0x7f7362a32b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45903)\u001b[0m     @     0x7f7362a55c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45903)\u001b[0m     @     0x7f7361ef7a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45903)\u001b[0m     @     0x7f7361ef5388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45903)\u001b[0m     @     0x7f7361ef75a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45861)\u001b[0m     @     0x7f846ce228f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45861)\u001b[0m     @     0x7f846ce22ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45861)\u001b[0m     @     0x7f846ce22d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45861)\u001b[0m     @     0x7f846d705b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45861)\u001b[0m     @     0x7f846d728c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45861)\u001b[0m     @     0x7f846cbcaa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45861)\u001b[0m     @     0x7f846cbc8388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45846)\u001b[0m     @     0x7f324a6418f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45846)\u001b[0m     @     0x7f324a641ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45846)\u001b[0m     @     0x7f324a641d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45846)\u001b[0m     @     0x7f324af24b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45846)\u001b[0m     @     0x7f324af47c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45846)\u001b[0m     @     0x7f324a3e9a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45846)\u001b[0m     @     0x7f324a3e7388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45857)\u001b[0m     @     0x7fae81698b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45857)\u001b[0m     @     0x7fae816bbc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45857)\u001b[0m     @     0x7fae80b5da93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45857)\u001b[0m     @     0x7fae80b5b388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45857)\u001b[0m     @     0x7fae80b5d5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45857)\u001b[0m     @     0x7fae812484f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45857)\u001b[0m     @     0x7fae8371b8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45883)\u001b[0m     @     0x7f2e58d08b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45883)\u001b[0m     @     0x7f2e58d2bc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45883)\u001b[0m     @     0x7f2e581cda93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45883)\u001b[0m     @     0x7f2e581cb388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45883)\u001b[0m     @     0x7f2e581cd5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45883)\u001b[0m     @     0x7f2e588b84f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45883)\u001b[0m     @     0x7f2e5ad8b8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45792)\u001b[0m     @     0x7f28965afd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45792)\u001b[0m     @     0x7f2896e92b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45792)\u001b[0m     @     0x7f2896eb5c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45792)\u001b[0m     @     0x7f2896357a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45792)\u001b[0m     @     0x7f2896355388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45792)\u001b[0m     @     0x7f28963575a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45792)\u001b[0m     @     0x7f2896a424f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45874)\u001b[0m     @     0x7fb8274afd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45874)\u001b[0m     @     0x7fb827d92b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45874)\u001b[0m     @     0x7fb827db5c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45874)\u001b[0m     @     0x7fb827257a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45874)\u001b[0m     @     0x7fb827255388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45874)\u001b[0m     @     0x7fb8272575a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45874)\u001b[0m     @     0x7fb8279424f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45810)\u001b[0m     @     0x7f3a90f27d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45810)\u001b[0m     @     0x7f3a9180ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45810)\u001b[0m     @     0x7f3a9182dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45810)\u001b[0m     @     0x7f3a90ccfa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45810)\u001b[0m     @     0x7f3a90ccd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45849)\u001b[0m     @     0x7f5164574b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45849)\u001b[0m     @     0x7f5164597c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45849)\u001b[0m     @     0x7f5163a39a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45849)\u001b[0m     @     0x7f5163a37388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45849)\u001b[0m     @     0x7f5163a395a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45849)\u001b[0m     @     0x7f51641244f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45849)\u001b[0m     @     0x7f51665f78de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45905)\u001b[0m     @     0x7f6850c92d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45905)\u001b[0m     @     0x7f6851575b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45905)\u001b[0m     @     0x7f6851598c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45905)\u001b[0m     @     0x7f6850a3aa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45905)\u001b[0m     @     0x7f6850a38388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45905)\u001b[0m     @     0x7f6850a3a5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45905)\u001b[0m     @     0x7f68511254f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45880)\u001b[0m     @     0x7fb2f12a8d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45880)\u001b[0m     @     0x7fb2f1b8bb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45880)\u001b[0m     @     0x7fb2f1baec1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45880)\u001b[0m     @     0x7fb2f1050a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45880)\u001b[0m     @     0x7fb2f104e388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45880)\u001b[0m     @     0x7fb2f10505a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45880)\u001b[0m     @     0x7fb2f173b4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45904)\u001b[0m     @     0x7eed38269d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45904)\u001b[0m     @     0x7eed38b4cb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45904)\u001b[0m     @     0x7eed38b6fc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45904)\u001b[0m     @     0x7eed38011a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45904)\u001b[0m     @     0x7eed3800f388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45904)\u001b[0m     @     0x7eed380115a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45887)\u001b[0m     @     0x55a07faf6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45887)\u001b[0m     @     0x55a07fa6b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45866)\u001b[0m     @     0x7f3ed5c27d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45866)\u001b[0m     @     0x7f3ed650ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45866)\u001b[0m     @     0x7f3ed652dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45866)\u001b[0m     @     0x7f3ed59cfa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45866)\u001b[0m     @     0x7f3ed59cd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45866)\u001b[0m     @     0x7f3ed59cf5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45868)\u001b[0m     @     0x7f730b9d2a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45868)\u001b[0m     @     0x7f730b9d0388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45868)\u001b[0m     @     0x7f730b9d25a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45868)\u001b[0m     @     0x7f730c0bd4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45868)\u001b[0m     @     0x7f730e5908de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45868)\u001b[0m     @     0x7f730c0bd4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45868)\u001b[0m     @     0x7f731216879f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45868)\u001b[0m     @     0x560028937fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45868)\u001b[0m     @     0x560028892b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45868)\u001b[0m     @     0x56002891dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45868)\u001b[0m     @     0x56002891ea20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45868)\u001b[0m     @     0x560028892bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45853)\u001b[0m     @     0x7fbf09552d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45853)\u001b[0m     @     0x7fbf09e35b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45853)\u001b[0m     @     0x7fbf09e58c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45853)\u001b[0m     @     0x7fbf092faa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45853)\u001b[0m     @     0x7fbf092f8388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45853)\u001b[0m     @     0x7fbf092fa5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45853)\u001b[0m     @     0x7fbf099e54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45853)\u001b[0m     @     0x7fbf0beb88de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45891)\u001b[0m     @     0x7eeab8347b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45891)\u001b[0m     @     0x7eeab836ac1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45891)\u001b[0m     @     0x7eeab780ca93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45891)\u001b[0m     @     0x7eeab780a388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45891)\u001b[0m     @     0x7eeab780c5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45891)\u001b[0m     @     0x7eeab7ef74f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45891)\u001b[0m     @     0x7eeaba3ca8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45889)\u001b[0m     @     0x7f5620ed8c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45889)\u001b[0m     @     0x7f562037aa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45889)\u001b[0m     @     0x7f5620378388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45889)\u001b[0m     @     0x7f562037a5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45889)\u001b[0m     @     0x7f5620a654f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45889)\u001b[0m     @     0x7f5622f388de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45871)\u001b[0m     @     0x7f8d48e22ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45807)\u001b[0m     @     0x7fbc39c25d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45807)\u001b[0m     @     0x7fbc3a508b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45807)\u001b[0m     @     0x7fbc3a52bc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45807)\u001b[0m     @     0x7fbc399cda93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45807)\u001b[0m     @     0x7fbc399cb388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45807)\u001b[0m     @     0x7fbc399cd5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45807)\u001b[0m     @     0x7fbc3a0b84f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45804)\u001b[0m     @     0x7fc914f27d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45804)\u001b[0m     @     0x7fc91580ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45804)\u001b[0m     @     0x7fc91582dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45804)\u001b[0m     @     0x7fc914ccfa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45804)\u001b[0m     @     0x7fc914ccd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45804)\u001b[0m     @     0x7fc914ccf5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45804)\u001b[0m     @     0x7fc9153ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45858)\u001b[0m     @     0x7eea42957d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45858)\u001b[0m     @     0x7eea4323ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45858)\u001b[0m     @     0x7eea4325dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45858)\u001b[0m     @     0x7eea426ffa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45858)\u001b[0m     @     0x7eea426fd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45858)\u001b[0m     @     0x7eea426ff5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45799)\u001b[0m     @     0x7f5761cd2d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45799)\u001b[0m     @     0x7f57625b5b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45799)\u001b[0m     @     0x7f57625d8c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45799)\u001b[0m     @     0x7f5761a7aa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45799)\u001b[0m     @     0x7f5761a78388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45799)\u001b[0m     @     0x7f5761a7a5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45865)\u001b[0m     @     0x7fa1a2ab5b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45865)\u001b[0m     @     0x7fa1a2ad8c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45865)\u001b[0m     @     0x7fa1a1f7aa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45865)\u001b[0m     @     0x7fa1a1f78388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45865)\u001b[0m     @     0x7fa1a1f7a5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45865)\u001b[0m     @     0x7fa1a26654f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45862)\u001b[0m     @     0x7f335b0e6b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45862)\u001b[0m     @     0x7f335b109c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45862)\u001b[0m     @     0x7f335a5aba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45862)\u001b[0m     @     0x7f335a5a9388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45862)\u001b[0m     @     0x7f335a5ab5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45862)\u001b[0m     @     0x7f335ac964f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45862)\u001b[0m     @     0x7f335d1698de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45877)\u001b[0m     @     0x7f6540a8dd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45877)\u001b[0m     @     0x7f6541370b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45877)\u001b[0m     @     0x7f6541393c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45877)\u001b[0m     @     0x7f6540835a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45877)\u001b[0m     @     0x7f6540833388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45877)\u001b[0m     @     0x7f65408355a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45842)\u001b[0m     @     0x7ed6fce228f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45842)\u001b[0m     @     0x7ed6fce22ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45842)\u001b[0m     @     0x7ed6fce22d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45842)\u001b[0m     @     0x7ed6fd705b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45842)\u001b[0m     @     0x7ed6fd728c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45842)\u001b[0m     @     0x7ed6fcbcaa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45794)\u001b[0m     @     0x7f5bff82f8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45794)\u001b[0m     @     0x7f5bff82fad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45794)\u001b[0m     @     0x7f5bff82fd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45794)\u001b[0m     @     0x7f5c00112b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45794)\u001b[0m     @     0x7f5c00135c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45844)\u001b[0m     @     0x7ee285138ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45844)\u001b[0m     @     0x7ee285138d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45844)\u001b[0m     @     0x7ee285a1bb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45844)\u001b[0m     @     0x7ee285a3ec1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45844)\u001b[0m     @     0x7ee284ee0a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45844)\u001b[0m     @     0x7ee284ede388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45822)\u001b[0m     @     0x7fad0a641ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45822)\u001b[0m     @     0x7fad0a641d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45822)\u001b[0m     @     0x7fad0af24b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45822)\u001b[0m     @     0x7fad0af47c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45822)\u001b[0m     @     0x7fad0a3e9a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45822)\u001b[0m     @     0x7fad0a3e7388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45822)\u001b[0m     @     0x7fad0a3e95a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45895)\u001b[0m     @     0x7f6c39c27d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45895)\u001b[0m     @     0x7f6c3a50ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45895)\u001b[0m     @     0x7f6c3a52dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45895)\u001b[0m     @     0x7f6c399cfa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45895)\u001b[0m     @     0x7f6c399cd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45895)\u001b[0m     @     0x7f6c399cf5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45906)\u001b[0m     @     0x7ef9f4565d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45906)\u001b[0m     @     0x7ef9f4e48b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45906)\u001b[0m     @     0x7ef9f4e6bc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45906)\u001b[0m     @     0x7ef9f430da93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45906)\u001b[0m     @     0x7ef9f430b388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45906)\u001b[0m     @     0x7ef9f430d5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45906)\u001b[0m     @     0x7ef9f49f84f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45885)\u001b[0m     @     0x7f8504859c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45885)\u001b[0m     @     0x7f8503cfba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45885)\u001b[0m     @     0x7f8503cf9388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45885)\u001b[0m     @     0x7f8503cfb5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45885)\u001b[0m     @     0x7f85043e64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45885)\u001b[0m     @     0x7f85068b98de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45809)\u001b[0m     @     0x7f60a4ccfa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45809)\u001b[0m     @     0x7f60a4ccd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45809)\u001b[0m     @     0x7f60a4ccf5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45809)\u001b[0m     @     0x7f60a53ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45809)\u001b[0m     @     0x7f60a788d8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45805)\u001b[0m     @     0x7fbe96d875a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45805)\u001b[0m     @     0x7fbe974724f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45805)\u001b[0m     @     0x7fbe999458de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45808)\u001b[0m     @     0x7f149d1c55a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45808)\u001b[0m     @     0x7f149d8b04f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45808)\u001b[0m     @     0x7f149fd838de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45787)\u001b[0m     @     0x7ef25d8215a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45787)\u001b[0m     @     0x7ef25df0c4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45787)\u001b[0m     @     0x7ef2603df8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45811)\u001b[0m     @     0x7fb4ef02b4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45811)\u001b[0m     @     0x7fb4f14fe8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45811)\u001b[0m     @     0x7fb4ef02b4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45811)\u001b[0m     @     0x7fb4f50d679f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45811)\u001b[0m     @     0x56176fb4ffd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45811)\u001b[0m     @     0x56176faaab08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45811)\u001b[0m     @     0x56176fb35baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45811)\u001b[0m     @     0x56176fb36a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45811)\u001b[0m     @     0x56176faaabfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45811)\u001b[0m     @     0x56176fb35baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45811)\u001b[0m     @     0x56176fb36643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45811)\u001b[0m     @     0x56176faab689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45811)\u001b[0m     @     0x56176fb35baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45811)\u001b[0m     @     0x56176fb36643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45811)\u001b[0m     @     0x56176faab689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45811)\u001b[0m     @     0x56176fb35baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45811)\u001b[0m     @     0x56176fb36643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45811)\u001b[0m     @     0x56176faab689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45811)\u001b[0m     @     0x56176fb35baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45811)\u001b[0m     @     0x56176fb36643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45811)\u001b[0m     @     0x56176faab689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45901)\u001b[0m     @     0x7f3f8bcfb5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45901)\u001b[0m     @     0x7f3f8c3e64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45901)\u001b[0m     @     0x7f3f8e8b98de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45901)\u001b[0m     @     0x7f3f8c3e64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45793)\u001b[0m     @     0x7f71872e45a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45793)\u001b[0m     @     0x7f71879cf4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45793)\u001b[0m     @     0x7f7189ea28de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45793)\u001b[0m     @     0x7f71879cf4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45802)\u001b[0m     @     0x7f332f80f5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45802)\u001b[0m     @     0x7f332fefa4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45802)\u001b[0m     @     0x7f33323cd8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45863)\u001b[0m     @     0x7f4982c7bd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45863)\u001b[0m     @     0x7f498355eb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45863)\u001b[0m     @     0x7f4983581c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45863)\u001b[0m     @     0x7f4982a23a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45863)\u001b[0m     @     0x7f4982a21388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45806)\u001b[0m     @     0x7fab892f8388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45806)\u001b[0m     @     0x7fab892fa5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45806)\u001b[0m     @     0x7fab899e54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45806)\u001b[0m     @     0x7fab8beb88de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45795)\u001b[0m     @     0x7f395ff0a388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45795)\u001b[0m     @     0x7f395ff0c5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45795)\u001b[0m     @     0x7f39605f74f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45795)\u001b[0m     @     0x7f3962aca8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45876)\u001b[0m     @     0x7f459a6ffa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45876)\u001b[0m     @     0x7f459a6fd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45876)\u001b[0m     @     0x7f459a6ff5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45790)\u001b[0m     @     0x7f7c5dc64a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45790)\u001b[0m     @     0x7f7c5dc62388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45790)\u001b[0m     @     0x7f7c5dc645a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45790)\u001b[0m     @     0x7f7c5e34f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45800)\u001b[0m     @     0x7f6befa39a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45800)\u001b[0m     @     0x7f6befa37388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45800)\u001b[0m     @     0x7f6befa395a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45800)\u001b[0m     @     0x7f6bf01244f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45800)\u001b[0m     @     0x7f6bf25f78de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45852)\u001b[0m     @     0x7ef8cba39a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45852)\u001b[0m     @     0x7ef8cba37388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45852)\u001b[0m     @     0x7ef8cba395a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45852)\u001b[0m     @     0x7ef8cc1244f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45852)\u001b[0m     @     0x7ef8ce5f78de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45814)\u001b[0m     @     0x7fae74ccfa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45814)\u001b[0m     @     0x7fae74ccd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45814)\u001b[0m     @     0x7fae74ccf5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45814)\u001b[0m     @     0x7fae753ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45814)\u001b[0m     @     0x7fae7788d8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45872)\u001b[0m     @     0x7f031b25dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45872)\u001b[0m     @     0x7f031a6ffa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45872)\u001b[0m     @     0x7f031a6fd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45872)\u001b[0m     @     0x7f031a6ff5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45872)\u001b[0m     @     0x7f031adea4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45864)\u001b[0m     @     0x7f323edb4a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45864)\u001b[0m     @     0x7f323edb2388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45864)\u001b[0m     @     0x7f323edb45a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45864)\u001b[0m     @     0x7f323f49f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45864)\u001b[0m     @     0x7f32419728de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45785)\u001b[0m     @     0x7ef2d9552d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45785)\u001b[0m     @     0x7ef2d9e35b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45785)\u001b[0m     @     0x7ef2d9e58c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45785)\u001b[0m     @     0x7ef2d92faa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45785)\u001b[0m     @     0x7ef2d92f8388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45785)\u001b[0m     @     0x7ef2d92fa5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45786)\u001b[0m     @     0x7f73c8e165a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45786)\u001b[0m     @     0x7f73c95014f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45786)\u001b[0m     @     0x7f73cb9d48de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45867)\u001b[0m     @     0x7f1189a79d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45867)\u001b[0m     @     0x7f118a35cb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45867)\u001b[0m     @     0x7f118a37fc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45867)\u001b[0m     @     0x7f1189821a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45867)\u001b[0m     @     0x7f118981f388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45789)\u001b[0m     @     0x7f8a6e3e95a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45789)\u001b[0m     @     0x7f8a6ead44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45789)\u001b[0m     @     0x7f8a70fa78de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45789)\u001b[0m     @     0x7f8a6ead44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45789)\u001b[0m     @     0x7f8a74b7f79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45789)\u001b[0m     @     0x560bcec14fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45789)\u001b[0m     @     0x560bceb6fb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45789)\u001b[0m     @     0x560bcebfabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45789)\u001b[0m     @     0x560bcebfba20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45789)\u001b[0m     @     0x560bceb6fbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45789)\u001b[0m     @     0x560bcebfabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45789)\u001b[0m     @     0x560bcebfb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45789)\u001b[0m     @     0x560bceb70689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45789)\u001b[0m     @     0x560bcebfabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45789)\u001b[0m     @     0x560bcebfb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45789)\u001b[0m     @     0x560bceb70689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45789)\u001b[0m     @     0x560bcebfabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45882)\u001b[0m     @     0x7f0dc6d745a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45882)\u001b[0m     @     0x7f0dc745f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45882)\u001b[0m     @     0x7f0dc99328de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45882)\u001b[0m     @     0x7f0dc745f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45879)\u001b[0m     @     0x7edf6f7fbd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45879)\u001b[0m     @     0x7edf700deb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45879)\u001b[0m     @     0x7edf70101c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45879)\u001b[0m     @     0x7edf6f5a3a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45879)\u001b[0m     @     0x7edf6f5a1388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45798)\u001b[0m     @     0x7eec4414a5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45798)\u001b[0m     @     0x7eec448354f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45798)\u001b[0m     @     0x7eec46d088de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45798)\u001b[0m     @     0x7eec448354f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45798)\u001b[0m     @     0x7eec4a8e079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45798)\u001b[0m     @     0x5604e8f50fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45798)\u001b[0m     @     0x5604e8eabb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45818)\u001b[0m     @     0x7f7611fa5388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45818)\u001b[0m     @     0x7f7611fa75a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45818)\u001b[0m     @     0x7f76126924f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45878)\u001b[0m     @     0x7f1299fa7a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45878)\u001b[0m     @     0x7f1299fa5388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45878)\u001b[0m     @     0x7f1299fa75a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45878)\u001b[0m     @     0x7f129a6924f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45878)\u001b[0m     @     0x7f129cb658de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45791)\u001b[0m     @     0x7f771eea74f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45791)\u001b[0m     @     0x7f772137a8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45791)\u001b[0m     @     0x7f771eea74f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45791)\u001b[0m     @     0x7f7724f5279f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45791)\u001b[0m     @     0x55ba13bd8fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45791)\u001b[0m     @     0x55ba13b33b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45791)\u001b[0m     @     0x55ba13bbebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45791)\u001b[0m     @     0x55ba13bbfa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45791)\u001b[0m     @     0x55ba13b33bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45791)\u001b[0m     @     0x55ba13bbebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45791)\u001b[0m     @     0x55ba13bbf643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45791)\u001b[0m     @     0x55ba13b34689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45791)\u001b[0m     @     0x55ba13bbebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45791)\u001b[0m     @     0x55ba13bbf643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45791)\u001b[0m     @     0x55ba13b34689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45791)\u001b[0m     @     0x55ba13bbebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45791)\u001b[0m     @     0x55ba13bbf643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45791)\u001b[0m     @     0x55ba13b34689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45791)\u001b[0m     @     0x55ba13bbebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45791)\u001b[0m     @     0x55ba13bbf643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45791)\u001b[0m     @     0x55ba13b34689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45898)\u001b[0m     @     0x7f082e1654f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45898)\u001b[0m     @     0x7f08306388de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45855)\u001b[0m     @     0x7f6ed51b88de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45855)\u001b[0m     @     0x7f6ed2ce54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45855)\u001b[0m     @     0x7f6ed8d9079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45855)\u001b[0m     @     0x5558f39f8fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45855)\u001b[0m     @     0x5558f3953b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45855)\u001b[0m     @     0x5558f39debaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45855)\u001b[0m     @     0x5558f39dfa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45855)\u001b[0m     @     0x5558f3953bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45855)\u001b[0m     @     0x5558f39debaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45855)\u001b[0m     @     0x5558f39df643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45855)\u001b[0m     @     0x5558f3954689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45855)\u001b[0m     @     0x5558f39debaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45855)\u001b[0m     @     0x5558f39df643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45855)\u001b[0m     @     0x5558f3954689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45855)\u001b[0m     @     0x5558f39debaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45855)\u001b[0m     @     0x5558f39df643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45855)\u001b[0m     @     0x5558f3954689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45855)\u001b[0m     @     0x5558f39debaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45788)\u001b[0m     @     0x7efd5c3354f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45788)\u001b[0m     @     0x7efd5e8088de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45788)\u001b[0m     @     0x7efd5c3354f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45796)\u001b[0m     @     0x7f8c652bd8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45796)\u001b[0m     @     0x7f8c62dea4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45796)\u001b[0m     @     0x7f8c68e9579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45796)\u001b[0m     @     0x55bb1d501fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45796)\u001b[0m     @     0x55bb1d45cb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45796)\u001b[0m     @     0x55bb1d4e7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45796)\u001b[0m     @     0x55bb1d4e8a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45796)\u001b[0m     @     0x55bb1d45cbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45796)\u001b[0m     @     0x55bb1d4e7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45796)\u001b[0m     @     0x55bb1d4e8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45796)\u001b[0m     @     0x55bb1d45d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45796)\u001b[0m     @     0x55bb1d4e7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45796)\u001b[0m     @     0x55bb1d4e8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45796)\u001b[0m     @     0x55bb1d45d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45796)\u001b[0m     @     0x55bb1d4e7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45796)\u001b[0m     @     0x55bb1d4e8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45796)\u001b[0m     @     0x55bb1d45d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45796)\u001b[0m     @     0x55bb1d4e7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45796)\u001b[0m     @     0x55bb1d4e8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45796)\u001b[0m     @     0x55bb1d45d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45870)\u001b[0m     @     0x7efaf014a5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45870)\u001b[0m     @     0x7efaf08354f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45859)\u001b[0m     @     0x7f7a159cf5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45859)\u001b[0m     @     0x7f7a160ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45859)\u001b[0m     @     0x7f7a1858d8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45803)\u001b[0m     @     0x7f01ddedf4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45803)\u001b[0m     @     0x7f01e03b28de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45812)\u001b[0m     @     0x7f8e8ca654f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45812)\u001b[0m     @     0x7f8e8ef388de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45812)\u001b[0m     @     0x7f8e8ca654f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45903)\u001b[0m     @     0x7f73625e24f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45903)\u001b[0m     @     0x7f7364ab58de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45861)\u001b[0m     @     0x7f846cbca5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45861)\u001b[0m     @     0x7f846d2b54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45861)\u001b[0m     @     0x7f846f7888de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45846)\u001b[0m     @     0x7f324a3e95a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45846)\u001b[0m     @     0x7f324aad44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45857)\u001b[0m     @     0x7fae812484f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45857)\u001b[0m     @     0x7fae872f379f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45857)\u001b[0m     @     0x55baa0d8ffd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45857)\u001b[0m     @     0x55baa0ceab08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45857)\u001b[0m     @     0x55baa0d75baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45857)\u001b[0m     @     0x55baa0d76a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45857)\u001b[0m     @     0x55baa0ceabfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45857)\u001b[0m     @     0x55baa0d75baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45857)\u001b[0m     @     0x55baa0d76643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45857)\u001b[0m     @     0x55baa0ceb689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45857)\u001b[0m     @     0x55baa0d75baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45857)\u001b[0m     @     0x55baa0d76643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45857)\u001b[0m     @     0x55baa0ceb689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45857)\u001b[0m     @     0x55baa0d75baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45857)\u001b[0m     @     0x55baa0d76643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45857)\u001b[0m     @     0x55baa0ceb689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45857)\u001b[0m     @     0x55baa0d75baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45857)\u001b[0m     @     0x55baa0d76643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45857)\u001b[0m     @     0x55baa0ceb689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45883)\u001b[0m     @     0x7f2e588b84f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45883)\u001b[0m     @     0x7f2e5e96379f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45883)\u001b[0m     @     0x55c782745fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45883)\u001b[0m     @     0x55c7826a0b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45883)\u001b[0m     @     0x55c78272bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45883)\u001b[0m     @     0x55c78272ca20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45883)\u001b[0m     @     0x55c7826a0bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45883)\u001b[0m     @     0x55c78272bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45883)\u001b[0m     @     0x55c78272c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45883)\u001b[0m     @     0x55c7826a1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45883)\u001b[0m     @     0x55c78272bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45883)\u001b[0m     @     0x55c78272c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45883)\u001b[0m     @     0x55c7826a1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45883)\u001b[0m     @     0x55c78272bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45883)\u001b[0m     @     0x55c78272c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45883)\u001b[0m     @     0x55c7826a1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45883)\u001b[0m     @     0x55c78272bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45883)\u001b[0m     @     0x55c78272c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45883)\u001b[0m     @     0x55c7826a1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45792)\u001b[0m     @     0x7f2898f158de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45792)\u001b[0m     @     0x7f2896a424f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45792)\u001b[0m     @     0x7f289caed79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45792)\u001b[0m     @     0x555798d81fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45792)\u001b[0m     @     0x555798cdcb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45792)\u001b[0m     @     0x555798d67baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45792)\u001b[0m     @     0x555798d68a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45792)\u001b[0m     @     0x555798cdcbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45792)\u001b[0m     @     0x555798d67baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45792)\u001b[0m     @     0x555798d68643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45792)\u001b[0m     @     0x555798cdd689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45792)\u001b[0m     @     0x555798d67baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45792)\u001b[0m     @     0x555798d68643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45792)\u001b[0m     @     0x555798cdd689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45792)\u001b[0m     @     0x555798d67baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45792)\u001b[0m     @     0x555798d68643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45792)\u001b[0m     @     0x555798cdd689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45792)\u001b[0m     @     0x555798d67baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45792)\u001b[0m     @     0x555798d68643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45792)\u001b[0m     @     0x555798cdd689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45874)\u001b[0m     @     0x7fb829e158de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45874)\u001b[0m     @     0x7fb8279424f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45874)\u001b[0m     @     0x7fb82d9ed79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45874)\u001b[0m     @     0x55c849795fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45874)\u001b[0m     @     0x55c8496f0b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45874)\u001b[0m     @     0x55c84977bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45874)\u001b[0m     @     0x55c84977ca20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45874)\u001b[0m     @     0x55c8496f0bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45874)\u001b[0m     @     0x55c84977bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45874)\u001b[0m     @     0x55c84977c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45874)\u001b[0m     @     0x55c8496f1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45874)\u001b[0m     @     0x55c84977bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45874)\u001b[0m     @     0x55c84977c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45874)\u001b[0m     @     0x55c8496f1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45874)\u001b[0m     @     0x55c84977bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45874)\u001b[0m     @     0x55c84977c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45874)\u001b[0m     @     0x55c8496f1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45810)\u001b[0m     @     0x7f3a90ccf5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45810)\u001b[0m     @     0x7f3a913ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45849)\u001b[0m     @     0x7f51641244f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45849)\u001b[0m     @     0x7f516a1cf79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45849)\u001b[0m     @     0x56128ee15fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45849)\u001b[0m     @     0x56128ed70b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45849)\u001b[0m     @     0x56128edfbbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45849)\u001b[0m     @     0x56128edfca20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45849)\u001b[0m     @     0x56128ed70bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45849)\u001b[0m     @     0x56128edfbbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45849)\u001b[0m     @     0x56128edfc643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45849)\u001b[0m     @     0x56128ed71689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45849)\u001b[0m     @     0x56128edfbbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45849)\u001b[0m     @     0x56128edfc643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45849)\u001b[0m     @     0x56128ed71689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45849)\u001b[0m     @     0x56128edfbbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45849)\u001b[0m     @     0x56128edfc643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45849)\u001b[0m     @     0x56128ed71689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45849)\u001b[0m     @     0x56128edfbbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45849)\u001b[0m     @     0x56128edfc643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45849)\u001b[0m     @     0x56128ed71689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45905)\u001b[0m     @     0x7f68535f88de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45905)\u001b[0m     @     0x7f68511254f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45905)\u001b[0m     @     0x7f68571d079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45905)\u001b[0m     @     0x55cefd2e7fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45905)\u001b[0m     @     0x55cefd242b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45905)\u001b[0m     @     0x55cefd2cdbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45905)\u001b[0m     @     0x55cefd2cea20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45905)\u001b[0m     @     0x55cefd242bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45905)\u001b[0m     @     0x55cefd2cdbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45905)\u001b[0m     @     0x55cefd2ce643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45905)\u001b[0m     @     0x55cefd243689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45905)\u001b[0m     @     0x55cefd2cdbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45905)\u001b[0m     @     0x55cefd2ce643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45905)\u001b[0m     @     0x55cefd243689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45905)\u001b[0m     @     0x55cefd2cdbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45905)\u001b[0m     @     0x55cefd2ce643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45905)\u001b[0m     @     0x55cefd243689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45905)\u001b[0m     @     0x55cefd2cdbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45905)\u001b[0m     @     0x55cefd2ce643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45905)\u001b[0m     @     0x55cefd243689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45880)\u001b[0m     @     0x7fb2f3c0e8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45880)\u001b[0m     @     0x7fb2f173b4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45880)\u001b[0m     @     0x7fb2f77e679f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45880)\u001b[0m     @     0x557e384e4fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45880)\u001b[0m     @     0x557e3843fb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45880)\u001b[0m     @     0x557e384cabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45880)\u001b[0m     @     0x557e384cba20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45880)\u001b[0m     @     0x557e3843fbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45880)\u001b[0m     @     0x557e384cabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45880)\u001b[0m     @     0x557e384cb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45880)\u001b[0m     @     0x557e38440689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45880)\u001b[0m     @     0x557e384cabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45880)\u001b[0m     @     0x557e384cb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45880)\u001b[0m     @     0x557e38440689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45880)\u001b[0m     @     0x557e384cabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45880)\u001b[0m     @     0x557e384cb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45880)\u001b[0m     @     0x557e38440689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45880)\u001b[0m     @     0x557e384cabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45880)\u001b[0m     @     0x557e384cb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45904)\u001b[0m     @     0x7eed386fc4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45904)\u001b[0m     @     0x7eed3abcf8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45904)\u001b[0m     @     0x7eed386fc4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45904)\u001b[0m     @     0x7eed3e7a779f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45904)\u001b[0m     @     0x561899383fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45904)\u001b[0m     @     0x5618992deb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45866)\u001b[0m     @     0x7f3ed60ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45866)\u001b[0m     @     0x7f3ed858d8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45866)\u001b[0m     @     0x7f3ed60ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45866)\u001b[0m     @     0x7f3edc16579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45866)\u001b[0m     @     0x557e79c16fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45866)\u001b[0m     @     0x557e79b71b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45866)\u001b[0m     @     0x557e79bfcbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45866)\u001b[0m     @     0x557e79bfda20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45866)\u001b[0m     @     0x557e79b71bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45868)\u001b[0m     @     0x56002891dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45868)\u001b[0m     @     0x56002891e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45868)\u001b[0m     @     0x560028893689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45868)\u001b[0m     @     0x56002891dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45868)\u001b[0m     @     0x56002891e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45868)\u001b[0m     @     0x560028893689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45868)\u001b[0m     @     0x56002891dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45868)\u001b[0m     @     0x56002891e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45868)\u001b[0m     @     0x560028893689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45868)\u001b[0m     @     0x56002891dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45868)\u001b[0m     @     0x56002891e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45868)\u001b[0m     @     0x560028893689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45853)\u001b[0m     @     0x7fbf099e54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45853)\u001b[0m     @     0x7fbf0fa9079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45853)\u001b[0m     @     0x55c1165cafd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45853)\u001b[0m     @     0x55c116525b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45853)\u001b[0m     @     0x55c1165b0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45853)\u001b[0m     @     0x55c1165b1a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45853)\u001b[0m     @     0x55c116525bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45853)\u001b[0m     @     0x55c1165b0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45853)\u001b[0m     @     0x55c1165b1643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45853)\u001b[0m     @     0x55c116526689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45853)\u001b[0m     @     0x55c1165b0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45853)\u001b[0m     @     0x55c1165b1643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45853)\u001b[0m     @     0x55c116526689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45853)\u001b[0m     @     0x55c1165b0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45853)\u001b[0m     @     0x55c1165b1643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45853)\u001b[0m     @     0x55c116526689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45853)\u001b[0m     @     0x55c1165b0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45853)\u001b[0m     @     0x55c1165b1643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45853)\u001b[0m     @     0x55c116526689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45891)\u001b[0m     @     0x7eeab7ef74f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45891)\u001b[0m     @     0x7eeabdfa279f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45891)\u001b[0m     @     0x55cd3de65fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45891)\u001b[0m     @     0x55cd3ddc0b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45891)\u001b[0m     @     0x55cd3de4bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45891)\u001b[0m     @     0x55cd3de4ca20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45891)\u001b[0m     @     0x55cd3ddc0bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45891)\u001b[0m     @     0x55cd3de4bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45891)\u001b[0m     @     0x55cd3de4c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45891)\u001b[0m     @     0x55cd3ddc1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45891)\u001b[0m     @     0x55cd3de4bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45891)\u001b[0m     @     0x55cd3de4c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45891)\u001b[0m     @     0x55cd3ddc1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45891)\u001b[0m     @     0x55cd3de4bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45891)\u001b[0m     @     0x55cd3de4c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45891)\u001b[0m     @     0x55cd3ddc1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45891)\u001b[0m     @     0x55cd3de4bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45891)\u001b[0m     @     0x55cd3de4c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45891)\u001b[0m     @     0x55cd3ddc1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45889)\u001b[0m     @     0x7f5620a654f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45889)\u001b[0m     @     0x7f5626b1079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45889)\u001b[0m     @     0x55cec829ffd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45889)\u001b[0m     @     0x55cec81fab08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45889)\u001b[0m     @     0x55cec8285baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45889)\u001b[0m     @     0x55cec8286a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45889)\u001b[0m     @     0x55cec81fabfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45889)\u001b[0m     @     0x55cec8285baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45889)\u001b[0m     @     0x55cec8286643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45889)\u001b[0m     @     0x55cec81fb689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45889)\u001b[0m     @     0x55cec8285baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45889)\u001b[0m     @     0x55cec8286643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45889)\u001b[0m     @     0x55cec81fb689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45889)\u001b[0m     @     0x55cec8285baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45889)\u001b[0m     @     0x55cec8286643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45889)\u001b[0m     @     0x55cec81fb689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45889)\u001b[0m     @     0x55cec8285baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45889)\u001b[0m     @     0x55cec8286643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45889)\u001b[0m     @     0x55cec81fb689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45871)\u001b[0m     @     0x7f8d48e22d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=45871)\u001b[0m     @     0x7f8d49705b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=45871)\u001b[0m     @     0x7f8d49728c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=45807)\u001b[0m     @     0x7fbc3c58b8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45807)\u001b[0m     @     0x7fbc3a0b84f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45807)\u001b[0m     @     0x7fbc4016379f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45807)\u001b[0m     @     0x563dbf970fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45807)\u001b[0m     @     0x563dbf8cbb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45807)\u001b[0m     @     0x563dbf956baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45807)\u001b[0m     @     0x563dbf957a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45807)\u001b[0m     @     0x563dbf8cbbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45807)\u001b[0m     @     0x563dbf956baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45807)\u001b[0m     @     0x563dbf957643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45807)\u001b[0m     @     0x563dbf8cc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45807)\u001b[0m     @     0x563dbf956baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45807)\u001b[0m     @     0x563dbf957643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45807)\u001b[0m     @     0x563dbf8cc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45807)\u001b[0m     @     0x563dbf956baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45807)\u001b[0m     @     0x563dbf957643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45807)\u001b[0m     @     0x563dbf8cc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45807)\u001b[0m     @     0x563dbf956baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45807)\u001b[0m     @     0x563dbf957643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45807)\u001b[0m     @     0x563dbf8cc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45804)\u001b[0m     @     0x7fc91788d8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45804)\u001b[0m     @     0x7fc9153ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45804)\u001b[0m     @     0x7fc91b46579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45804)\u001b[0m     @     0x561f161a3fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45804)\u001b[0m     @     0x561f160feb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45804)\u001b[0m     @     0x561f16189baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45804)\u001b[0m     @     0x561f1618aa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45804)\u001b[0m     @     0x561f160febfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45804)\u001b[0m     @     0x561f16189baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45804)\u001b[0m     @     0x561f1618a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45804)\u001b[0m     @     0x561f160ff689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45804)\u001b[0m     @     0x561f16189baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45804)\u001b[0m     @     0x561f1618a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45804)\u001b[0m     @     0x561f160ff689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45804)\u001b[0m     @     0x561f16189baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45804)\u001b[0m     @     0x561f1618a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45804)\u001b[0m     @     0x561f160ff689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45804)\u001b[0m     @     0x561f16189baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45804)\u001b[0m     @     0x561f1618a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45804)\u001b[0m     @     0x561f160ff689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45858)\u001b[0m     @     0x7eea42dea4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45858)\u001b[0m     @     0x7eea452bd8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45858)\u001b[0m     @     0x7eea42dea4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45858)\u001b[0m     @     0x7eea48e9579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45858)\u001b[0m     @     0x55e91919efd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45858)\u001b[0m     @     0x55e9190f9b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45858)\u001b[0m     @     0x55e919184baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45858)\u001b[0m     @     0x55e919185a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45858)\u001b[0m     @     0x55e9190f9bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45858)\u001b[0m     @     0x55e919184baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45858)\u001b[0m     @     0x55e919185643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45858)\u001b[0m     @     0x55e9190fa689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45858)\u001b[0m     @     0x55e919184baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45858)\u001b[0m     @     0x55e919185643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45858)\u001b[0m     @     0x55e9190fa689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45858)\u001b[0m     @     0x55e919184baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45858)\u001b[0m     @     0x55e919185643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45858)\u001b[0m     @     0x55e9190fa689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45858)\u001b[0m     @     0x55e919184baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45858)\u001b[0m     @     0x55e919185643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45858)\u001b[0m     @     0x55e9190fa689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45799)\u001b[0m     @     0x7f57621654f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45799)\u001b[0m     @     0x7f57646388de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45799)\u001b[0m     @     0x7f57621654f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45799)\u001b[0m     @     0x7f576821079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45799)\u001b[0m     @     0x55b3081d0fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45799)\u001b[0m     @     0x55b30812bb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45799)\u001b[0m     @     0x55b3081b6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45799)\u001b[0m     @     0x55b3081b7a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45799)\u001b[0m     @     0x55b30812bbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45799)\u001b[0m     @     0x55b3081b6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45799)\u001b[0m     @     0x55b3081b7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45799)\u001b[0m     @     0x55b30812c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45799)\u001b[0m     @     0x55b3081b6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45799)\u001b[0m     @     0x55b3081b7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45799)\u001b[0m     @     0x55b30812c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45799)\u001b[0m     @     0x55b3081b6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45799)\u001b[0m     @     0x55b3081b7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45799)\u001b[0m     @     0x55b30812c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45799)\u001b[0m     @     0x55b3081b6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45799)\u001b[0m     @     0x55b3081b7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45799)\u001b[0m     @     0x55b30812c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45865)\u001b[0m     @     0x7fa1a4b388de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45865)\u001b[0m     @     0x7fa1a26654f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45865)\u001b[0m     @     0x7fa1a871079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45865)\u001b[0m     @     0x56375dda6fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45865)\u001b[0m     @     0x56375dd01b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45865)\u001b[0m     @     0x56375dd8cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45865)\u001b[0m     @     0x56375dd8da20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45865)\u001b[0m     @     0x56375dd01bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45865)\u001b[0m     @     0x56375dd8cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45865)\u001b[0m     @     0x56375dd8d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45865)\u001b[0m     @     0x56375dd02689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45865)\u001b[0m     @     0x56375dd8cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45865)\u001b[0m     @     0x56375dd8d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45865)\u001b[0m     @     0x56375dd02689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45865)\u001b[0m     @     0x56375dd8cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45865)\u001b[0m     @     0x56375dd8d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45865)\u001b[0m     @     0x56375dd02689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45865)\u001b[0m     @     0x56375dd8cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45865)\u001b[0m     @     0x56375dd8d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45865)\u001b[0m     @     0x56375dd02689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45862)\u001b[0m     @     0x7f335ac964f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45862)\u001b[0m     @     0x7f3360d4179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45862)\u001b[0m     @     0x55baa4730fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45862)\u001b[0m     @     0x55baa468bb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45862)\u001b[0m     @     0x55baa4716baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45862)\u001b[0m     @     0x55baa4717a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45862)\u001b[0m     @     0x55baa468bbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45862)\u001b[0m     @     0x55baa4716baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45862)\u001b[0m     @     0x55baa4717643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45862)\u001b[0m     @     0x55baa468c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45862)\u001b[0m     @     0x55baa4716baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45862)\u001b[0m     @     0x55baa4717643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45862)\u001b[0m     @     0x55baa468c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45862)\u001b[0m     @     0x55baa4716baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45862)\u001b[0m     @     0x55baa4717643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45862)\u001b[0m     @     0x55baa468c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45862)\u001b[0m     @     0x55baa4716baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45862)\u001b[0m     @     0x55baa4717643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45862)\u001b[0m     @     0x55baa468c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45877)\u001b[0m     @     0x7f6540f204f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45877)\u001b[0m     @     0x7f65433f38de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45877)\u001b[0m     @     0x7f6540f204f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45877)\u001b[0m     @     0x7f6546fcb79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45877)\u001b[0m     @     0x564621406fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45877)\u001b[0m     @     0x564621361b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45877)\u001b[0m     @     0x5646213ecbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45877)\u001b[0m     @     0x5646213eda20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45877)\u001b[0m     @     0x564621361bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45877)\u001b[0m     @     0x5646213ecbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45877)\u001b[0m     @     0x5646213ed643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45877)\u001b[0m     @     0x564621362689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45877)\u001b[0m     @     0x5646213ecbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45877)\u001b[0m     @     0x5646213ed643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45877)\u001b[0m     @     0x564621362689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45877)\u001b[0m     @     0x5646213ecbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45877)\u001b[0m     @     0x5646213ed643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45877)\u001b[0m     @     0x564621362689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45877)\u001b[0m     @     0x5646213ecbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45877)\u001b[0m     @     0x5646213ed643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45877)\u001b[0m     @     0x564621362689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45842)\u001b[0m     @     0x7ed6fcbc8388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45842)\u001b[0m     @     0x7ed6fcbca5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45842)\u001b[0m     @     0x7ed6fd2b54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45842)\u001b[0m     @     0x7ed6ff7888de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45794)\u001b[0m     @     0x7f5bff5d7a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45794)\u001b[0m     @     0x7f5bff5d5388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45794)\u001b[0m     @     0x7f5bff5d75a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45794)\u001b[0m     @     0x7f5bffcc24f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45844)\u001b[0m     @     0x7ee284ee05a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45844)\u001b[0m     @     0x7ee2855cb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45844)\u001b[0m     @     0x7ee287a9e8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45844)\u001b[0m     @     0x7ee2855cb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45844)\u001b[0m     @     0x7ee28b67679f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45844)\u001b[0m     @     0x5603cf81bfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45822)\u001b[0m     @     0x7fad0aad44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45822)\u001b[0m     @     0x7fad0cfa78de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45822)\u001b[0m     @     0x7fad0aad44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45822)\u001b[0m     @     0x7fad10b7f79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45822)\u001b[0m     @     0x55b02e822fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45822)\u001b[0m     @     0x55b02e77db08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45822)\u001b[0m     @     0x55b02e808baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45822)\u001b[0m     @     0x55b02e809a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45822)\u001b[0m     @     0x55b02e77dbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45822)\u001b[0m     @     0x55b02e808baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45822)\u001b[0m     @     0x55b02e809643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45822)\u001b[0m     @     0x55b02e77e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45822)\u001b[0m     @     0x55b02e808baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45822)\u001b[0m     @     0x55b02e809643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45822)\u001b[0m     @     0x55b02e77e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45822)\u001b[0m     @     0x55b02e808baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45822)\u001b[0m     @     0x55b02e809643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45895)\u001b[0m     @     0x7f6c3a0ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45895)\u001b[0m     @     0x7f6c3c58d8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45895)\u001b[0m     @     0x7f6c3a0ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45895)\u001b[0m     @     0x7f6c4016579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45895)\u001b[0m     @     0x55e6e995ffd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45895)\u001b[0m     @     0x55e6e98bab08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45895)\u001b[0m     @     0x55e6e9945baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45895)\u001b[0m     @     0x55e6e9946a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45895)\u001b[0m     @     0x55e6e98babfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45895)\u001b[0m     @     0x55e6e9945baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45895)\u001b[0m     @     0x55e6e9946643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45895)\u001b[0m     @     0x55e6e98bb689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45895)\u001b[0m     @     0x55e6e9945baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45895)\u001b[0m     @     0x55e6e9946643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45895)\u001b[0m     @     0x55e6e98bb689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45895)\u001b[0m     @     0x55e6e9945baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45895)\u001b[0m     @     0x55e6e9946643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45895)\u001b[0m     @     0x55e6e98bb689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45895)\u001b[0m     @     0x55e6e9945baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45895)\u001b[0m     @     0x55e6e9946643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45895)\u001b[0m     @     0x55e6e98bb689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45906)\u001b[0m     @     0x7ef9f6ecb8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45906)\u001b[0m     @     0x7ef9f49f84f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45906)\u001b[0m     @     0x7ef9faaa379f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45906)\u001b[0m     @     0x555ac34e8fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45906)\u001b[0m     @     0x555ac3443b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45906)\u001b[0m     @     0x555ac34cebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45906)\u001b[0m     @     0x555ac34cfa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45906)\u001b[0m     @     0x555ac3443bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45906)\u001b[0m     @     0x555ac34cebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45906)\u001b[0m     @     0x555ac34cf643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45906)\u001b[0m     @     0x555ac3444689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45906)\u001b[0m     @     0x555ac34cebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45906)\u001b[0m     @     0x555ac34cf643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45906)\u001b[0m     @     0x555ac3444689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45906)\u001b[0m     @     0x555ac34cebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45906)\u001b[0m     @     0x555ac34cf643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45906)\u001b[0m     @     0x555ac3444689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45906)\u001b[0m     @     0x555ac34cebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45906)\u001b[0m     @     0x555ac34cf643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45906)\u001b[0m     @     0x555ac3444689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45885)\u001b[0m     @     0x7f85043e64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45885)\u001b[0m     @     0x7f850a49179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45885)\u001b[0m     @     0x555f17360fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45885)\u001b[0m     @     0x555f172bbb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45885)\u001b[0m     @     0x555f17346baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45885)\u001b[0m     @     0x555f17347a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45885)\u001b[0m     @     0x555f172bbbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45885)\u001b[0m     @     0x555f17346baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45885)\u001b[0m     @     0x555f17347643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45885)\u001b[0m     @     0x555f172bc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45885)\u001b[0m     @     0x555f17346baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45885)\u001b[0m     @     0x555f17347643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45885)\u001b[0m     @     0x555f172bc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45885)\u001b[0m     @     0x555f17346baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45885)\u001b[0m     @     0x555f17347643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45885)\u001b[0m     @     0x555f172bc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45885)\u001b[0m     @     0x555f17346baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45885)\u001b[0m     @     0x555f17347643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45885)\u001b[0m     @     0x555f172bc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45809)\u001b[0m     @     0x7f60a53ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45809)\u001b[0m     @     0x7f60ab46579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45809)\u001b[0m     @     0x5558b45fbfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45809)\u001b[0m     @     0x5558b4556b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45809)\u001b[0m     @     0x5558b45e1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45809)\u001b[0m     @     0x5558b45e2a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45809)\u001b[0m     @     0x5558b4556bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45809)\u001b[0m     @     0x5558b45e1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45809)\u001b[0m     @     0x5558b45e2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45809)\u001b[0m     @     0x5558b4557689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45809)\u001b[0m     @     0x5558b45e1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45809)\u001b[0m     @     0x5558b45e2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45805)\u001b[0m     @     0x7fbe974724f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45805)\u001b[0m     @     0x7fbe9d51d79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45805)\u001b[0m     @     0x55fa7b6e0fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45805)\u001b[0m     @     0x55fa7b63bb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45805)\u001b[0m     @     0x55fa7b6c6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45805)\u001b[0m     @     0x55fa7b6c7a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45805)\u001b[0m     @     0x55fa7b63bbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45805)\u001b[0m     @     0x55fa7b6c6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45805)\u001b[0m     @     0x55fa7b6c7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45805)\u001b[0m     @     0x55fa7b63c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45805)\u001b[0m     @     0x55fa7b6c6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45805)\u001b[0m     @     0x55fa7b6c7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45805)\u001b[0m     @     0x55fa7b63c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45805)\u001b[0m     @     0x55fa7b6c6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45805)\u001b[0m     @     0x55fa7b6c7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45805)\u001b[0m     @     0x55fa7b63c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45805)\u001b[0m     @     0x55fa7b6c6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45805)\u001b[0m     @     0x55fa7b6c7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45805)\u001b[0m     @     0x55fa7b63c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45808)\u001b[0m     @     0x7f149d8b04f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45808)\u001b[0m     @     0x7f14a395b79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45808)\u001b[0m     @     0x562933969fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45808)\u001b[0m     @     0x5629338c4b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45808)\u001b[0m     @     0x56293394fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45808)\u001b[0m     @     0x562933950a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45808)\u001b[0m     @     0x5629338c4bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45808)\u001b[0m     @     0x56293394fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45808)\u001b[0m     @     0x562933950643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45808)\u001b[0m     @     0x5629338c5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45808)\u001b[0m     @     0x56293394fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45808)\u001b[0m     @     0x562933950643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45808)\u001b[0m     @     0x5629338c5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45808)\u001b[0m     @     0x56293394fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45808)\u001b[0m     @     0x562933950643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45808)\u001b[0m     @     0x5629338c5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45808)\u001b[0m     @     0x56293394fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45808)\u001b[0m     @     0x562933950643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45808)\u001b[0m     @     0x5629338c5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45787)\u001b[0m     @     0x7ef25df0c4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45787)\u001b[0m     @     0x7ef263fb779f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45787)\u001b[0m     @     0x564609540fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45787)\u001b[0m     @     0x56460949bb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45787)\u001b[0m     @     0x564609526baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45787)\u001b[0m     @     0x564609527a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45787)\u001b[0m     @     0x56460949bbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45787)\u001b[0m     @     0x564609526baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45787)\u001b[0m     @     0x564609527643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45787)\u001b[0m     @     0x56460949c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45787)\u001b[0m     @     0x564609526baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45787)\u001b[0m     @     0x564609527643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45787)\u001b[0m     @     0x56460949c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45787)\u001b[0m     @     0x564609526baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45787)\u001b[0m     @     0x564609527643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45787)\u001b[0m     @     0x56460949c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45787)\u001b[0m     @     0x564609526baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45787)\u001b[0m     @     0x564609527643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45787)\u001b[0m     @     0x56460949c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45901)\u001b[0m     @     0x7f3f9249179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45901)\u001b[0m     @     0x55abe17c3fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45901)\u001b[0m     @     0x55abe171eb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45901)\u001b[0m     @     0x55abe17a9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45901)\u001b[0m     @     0x55abe17aaa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45901)\u001b[0m     @     0x55abe171ebfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45901)\u001b[0m     @     0x55abe17a9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45901)\u001b[0m     @     0x55abe17aa643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45901)\u001b[0m     @     0x55abe171f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45901)\u001b[0m     @     0x55abe17a9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45901)\u001b[0m     @     0x55abe17aa643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45901)\u001b[0m     @     0x55abe171f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45901)\u001b[0m     @     0x55abe17a9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45901)\u001b[0m     @     0x55abe17aa643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45901)\u001b[0m     @     0x55abe171f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45901)\u001b[0m     @     0x55abe17a9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45901)\u001b[0m     @     0x55abe17aa643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45901)\u001b[0m     @     0x55abe171f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45793)\u001b[0m     @     0x7f718da7a79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45793)\u001b[0m     @     0x560fe090bfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45793)\u001b[0m     @     0x560fe0866b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45793)\u001b[0m     @     0x560fe08f1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45793)\u001b[0m     @     0x560fe08f2a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45793)\u001b[0m     @     0x560fe0866bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45793)\u001b[0m     @     0x560fe08f1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45793)\u001b[0m     @     0x560fe08f2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45793)\u001b[0m     @     0x560fe0867689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45793)\u001b[0m     @     0x560fe08f1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45793)\u001b[0m     @     0x560fe08f2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45793)\u001b[0m     @     0x560fe0867689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45793)\u001b[0m     @     0x560fe08f1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45793)\u001b[0m     @     0x560fe08f2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45793)\u001b[0m     @     0x560fe0867689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45793)\u001b[0m     @     0x560fe08f1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45793)\u001b[0m     @     0x560fe08f2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45793)\u001b[0m     @     0x560fe0867689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45802)\u001b[0m     @     0x7f332fefa4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45802)\u001b[0m     @     0x7f3335fa579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45802)\u001b[0m     @     0x559cf70fbfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45802)\u001b[0m     @     0x559cf7056b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45802)\u001b[0m     @     0x559cf70e1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45802)\u001b[0m     @     0x559cf70e2a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45802)\u001b[0m     @     0x559cf7056bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45802)\u001b[0m     @     0x559cf70e1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45802)\u001b[0m     @     0x559cf70e2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45802)\u001b[0m     @     0x559cf7057689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45802)\u001b[0m     @     0x559cf70e1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45802)\u001b[0m     @     0x559cf70e2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45802)\u001b[0m     @     0x559cf7057689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45802)\u001b[0m     @     0x559cf70e1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45802)\u001b[0m     @     0x559cf70e2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45802)\u001b[0m     @     0x559cf7057689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45802)\u001b[0m     @     0x559cf70e1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45802)\u001b[0m     @     0x559cf70e2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45802)\u001b[0m     @     0x559cf7057689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45863)\u001b[0m     @     0x7f4982a235a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45863)\u001b[0m     @     0x7f498310e4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45863)\u001b[0m     @     0x7f49855e18de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45863)\u001b[0m     @     0x7f498310e4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45806)\u001b[0m     @     0x7fab899e54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45806)\u001b[0m     @     0x7fab8fa9079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45806)\u001b[0m     @     0x55c97bb8afd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45806)\u001b[0m     @     0x55c97bae5b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45806)\u001b[0m     @     0x55c97bb70baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45806)\u001b[0m     @     0x55c97bb71a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45806)\u001b[0m     @     0x55c97bae5bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45806)\u001b[0m     @     0x55c97bb70baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45806)\u001b[0m     @     0x55c97bb71643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45806)\u001b[0m     @     0x55c97bae6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45806)\u001b[0m     @     0x55c97bb70baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45806)\u001b[0m     @     0x55c97bb71643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45806)\u001b[0m     @     0x55c97bae6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45806)\u001b[0m     @     0x55c97bb70baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45806)\u001b[0m     @     0x55c97bb71643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45806)\u001b[0m     @     0x55c97bae6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45806)\u001b[0m     @     0x55c97bb70baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45806)\u001b[0m     @     0x55c97bb71643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45806)\u001b[0m     @     0x55c97bae6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45795)\u001b[0m     @     0x7f39605f74f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45795)\u001b[0m     @     0x7f39666a279f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45795)\u001b[0m     @     0x56111fe87fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45795)\u001b[0m     @     0x56111fde2b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45795)\u001b[0m     @     0x56111fe6dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45795)\u001b[0m     @     0x56111fe6ea20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45795)\u001b[0m     @     0x56111fde2bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45795)\u001b[0m     @     0x56111fe6dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45795)\u001b[0m     @     0x56111fe6e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45795)\u001b[0m     @     0x56111fde3689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45795)\u001b[0m     @     0x56111fe6dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45795)\u001b[0m     @     0x56111fe6e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45795)\u001b[0m     @     0x56111fde3689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45795)\u001b[0m     @     0x56111fe6dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45795)\u001b[0m     @     0x56111fe6e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45795)\u001b[0m     @     0x56111fde3689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45795)\u001b[0m     @     0x56111fe6dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45795)\u001b[0m     @     0x56111fe6e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45795)\u001b[0m     @     0x56111fde3689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45876)\u001b[0m     @     0x7f459adea4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45876)\u001b[0m     @     0x7f459d2bd8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45876)\u001b[0m     @     0x7f459adea4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45876)\u001b[0m     @     0x7f45a0e9579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45876)\u001b[0m     @     0x563cea349fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45876)\u001b[0m     @     0x563cea2a4b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45876)\u001b[0m     @     0x563cea32fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45876)\u001b[0m     @     0x563cea330a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45876)\u001b[0m     @     0x563cea2a4bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45876)\u001b[0m     @     0x563cea32fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45876)\u001b[0m     @     0x563cea330643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45876)\u001b[0m     @     0x563cea2a5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45876)\u001b[0m     @     0x563cea32fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45876)\u001b[0m     @     0x563cea330643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45876)\u001b[0m     @     0x563cea2a5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45876)\u001b[0m     @     0x563cea32fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45876)\u001b[0m     @     0x563cea330643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45876)\u001b[0m     @     0x563cea2a5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45876)\u001b[0m     @     0x563cea32fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45876)\u001b[0m     @     0x563cea330643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45876)\u001b[0m     @     0x563cea2a5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45790)\u001b[0m     @     0x7f7c608228de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45790)\u001b[0m     @     0x7f7c5e34f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45790)\u001b[0m     @     0x7f7c643fa79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45790)\u001b[0m     @     0x55a7e6453fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45790)\u001b[0m     @     0x55a7e63aeb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45790)\u001b[0m     @     0x55a7e6439baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45790)\u001b[0m     @     0x55a7e643aa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45790)\u001b[0m     @     0x55a7e63aebfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45790)\u001b[0m     @     0x55a7e6439baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45790)\u001b[0m     @     0x55a7e643a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45790)\u001b[0m     @     0x55a7e63af689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45790)\u001b[0m     @     0x55a7e6439baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45790)\u001b[0m     @     0x55a7e643a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45790)\u001b[0m     @     0x55a7e63af689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45790)\u001b[0m     @     0x55a7e6439baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45790)\u001b[0m     @     0x55a7e643a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45790)\u001b[0m     @     0x55a7e63af689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45790)\u001b[0m     @     0x55a7e6439baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45790)\u001b[0m     @     0x55a7e643a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45790)\u001b[0m     @     0x55a7e63af689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45800)\u001b[0m     @     0x7f6bf01244f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45800)\u001b[0m     @     0x7f6bf61cf79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45800)\u001b[0m     @     0x5616c2980fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45800)\u001b[0m     @     0x5616c28dbb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45800)\u001b[0m     @     0x5616c2966baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45800)\u001b[0m     @     0x5616c2967a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45800)\u001b[0m     @     0x5616c28dbbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45800)\u001b[0m     @     0x5616c2966baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45800)\u001b[0m     @     0x5616c2967643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45800)\u001b[0m     @     0x5616c28dc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45800)\u001b[0m     @     0x5616c2966baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45800)\u001b[0m     @     0x5616c2967643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45800)\u001b[0m     @     0x5616c28dc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45800)\u001b[0m     @     0x5616c2966baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45800)\u001b[0m     @     0x5616c2967643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45800)\u001b[0m     @     0x5616c28dc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45800)\u001b[0m     @     0x5616c2966baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45800)\u001b[0m     @     0x5616c2967643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45800)\u001b[0m     @     0x5616c28dc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45852)\u001b[0m     @     0x7ef8cc1244f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45852)\u001b[0m     @     0x7ef8d21cf79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45852)\u001b[0m     @     0x556895d62fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45852)\u001b[0m     @     0x556895cbdb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45852)\u001b[0m     @     0x556895d48baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45852)\u001b[0m     @     0x556895d49a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45852)\u001b[0m     @     0x556895cbdbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45852)\u001b[0m     @     0x556895d48baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45852)\u001b[0m     @     0x556895d49643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45852)\u001b[0m     @     0x556895cbe689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45852)\u001b[0m     @     0x556895d48baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45852)\u001b[0m     @     0x556895d49643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45852)\u001b[0m     @     0x556895cbe689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45852)\u001b[0m     @     0x556895d48baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45852)\u001b[0m     @     0x556895d49643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45852)\u001b[0m     @     0x556895cbe689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45852)\u001b[0m     @     0x556895d48baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45852)\u001b[0m     @     0x556895d49643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45852)\u001b[0m     @     0x556895cbe689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45814)\u001b[0m     @     0x7fae753ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45814)\u001b[0m     @     0x7fae7b46579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45814)\u001b[0m     @     0x5620f0261fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45814)\u001b[0m     @     0x5620f01bcb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45814)\u001b[0m     @     0x5620f0247baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45814)\u001b[0m     @     0x5620f0248a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45814)\u001b[0m     @     0x5620f01bcbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45814)\u001b[0m     @     0x5620f0247baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45814)\u001b[0m     @     0x5620f0248643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45814)\u001b[0m     @     0x5620f01bd689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45814)\u001b[0m     @     0x5620f0247baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45814)\u001b[0m     @     0x5620f0248643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45814)\u001b[0m     @     0x5620f01bd689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45814)\u001b[0m     @     0x5620f0247baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45814)\u001b[0m     @     0x5620f0248643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45814)\u001b[0m     @     0x5620f01bd689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45814)\u001b[0m     @     0x5620f0247baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45814)\u001b[0m     @     0x5620f0248643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45814)\u001b[0m     @     0x5620f01bd689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45872)\u001b[0m     @     0x7f031d2bd8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45872)\u001b[0m     @     0x7f031adea4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45872)\u001b[0m     @     0x7f0320e9579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45872)\u001b[0m     @     0x55d22007bfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45872)\u001b[0m     @     0x55d21ffd6b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45872)\u001b[0m     @     0x55d220061baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45872)\u001b[0m     @     0x55d220062a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45872)\u001b[0m     @     0x55d21ffd6bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45872)\u001b[0m     @     0x55d220061baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45872)\u001b[0m     @     0x55d220062643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45872)\u001b[0m     @     0x55d21ffd7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45872)\u001b[0m     @     0x55d220061baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45872)\u001b[0m     @     0x55d220062643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45872)\u001b[0m     @     0x55d21ffd7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45872)\u001b[0m     @     0x55d220061baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45864)\u001b[0m     @     0x7f323f49f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45864)\u001b[0m     @     0x7f324554a79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45864)\u001b[0m     @     0x557f09b44fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45864)\u001b[0m     @     0x557f09a9fb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45864)\u001b[0m     @     0x557f09b2abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45864)\u001b[0m     @     0x557f09b2ba20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45864)\u001b[0m     @     0x557f09a9fbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45864)\u001b[0m     @     0x557f09b2abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45864)\u001b[0m     @     0x557f09b2b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45864)\u001b[0m     @     0x557f09aa0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45864)\u001b[0m     @     0x557f09b2abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45864)\u001b[0m     @     0x557f09b2b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45864)\u001b[0m     @     0x557f09aa0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45864)\u001b[0m     @     0x557f09b2abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45864)\u001b[0m     @     0x557f09b2b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45864)\u001b[0m     @     0x557f09aa0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45864)\u001b[0m     @     0x557f09b2abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45864)\u001b[0m     @     0x557f09b2b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45864)\u001b[0m     @     0x557f09aa0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45785)\u001b[0m     @     0x7ef2d99e54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45785)\u001b[0m     @     0x7ef2dbeb88de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45786)\u001b[0m     @     0x7f73c95014f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45786)\u001b[0m     @     0x7f73f62ae79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45786)\u001b[0m     @     0x55c851c18fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45786)\u001b[0m     @     0x55c851b73b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45786)\u001b[0m     @     0x55c851bfebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45786)\u001b[0m     @     0x55c851bffa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45786)\u001b[0m     @     0x55c851b73bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45786)\u001b[0m     @     0x55c851bfebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45786)\u001b[0m     @     0x55c851bff643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45786)\u001b[0m     @     0x55c851b74689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45786)\u001b[0m     @     0x55c851bfebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45786)\u001b[0m     @     0x55c851bff643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45786)\u001b[0m     @     0x55c851b74689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45786)\u001b[0m     @     0x55c851bfebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45786)\u001b[0m     @     0x55c851bff643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45786)\u001b[0m     @     0x55c851b74689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45786)\u001b[0m     @     0x55c851bfebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45786)\u001b[0m     @     0x55c851bff643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45786)\u001b[0m     @     0x55c851b74689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45867)\u001b[0m     @     0x7f11898215a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45867)\u001b[0m     @     0x7f1189f0c4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45867)\u001b[0m     @     0x7f118c3df8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45789)\u001b[0m     @     0x560bcebfb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45789)\u001b[0m     @     0x560bceb70689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45789)\u001b[0m     @     0x560bcebfabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45789)\u001b[0m     @     0x560bcebfb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45789)\u001b[0m     @     0x560bceb70689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45882)\u001b[0m     @     0x7f0dcd50a79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45882)\u001b[0m     @     0x55da8e771fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45882)\u001b[0m     @     0x55da8e6ccb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45882)\u001b[0m     @     0x55da8e757baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45882)\u001b[0m     @     0x55da8e758a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45882)\u001b[0m     @     0x55da8e6ccbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45882)\u001b[0m     @     0x55da8e757baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45882)\u001b[0m     @     0x55da8e758643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45882)\u001b[0m     @     0x55da8e6cd689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45882)\u001b[0m     @     0x55da8e757baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45882)\u001b[0m     @     0x55da8e758643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45882)\u001b[0m     @     0x55da8e6cd689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45882)\u001b[0m     @     0x55da8e757baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45882)\u001b[0m     @     0x55da8e758643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45882)\u001b[0m     @     0x55da8e6cd689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45882)\u001b[0m     @     0x55da8e757baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45882)\u001b[0m     @     0x55da8e758643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45882)\u001b[0m     @     0x55da8e6cd689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45879)\u001b[0m     @     0x7edf6f5a35a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45879)\u001b[0m     @     0x7edf6fc8e4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45879)\u001b[0m     @     0x7edf721618de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45798)\u001b[0m     @     0x5604e8f36baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45798)\u001b[0m     @     0x5604e8f37a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45798)\u001b[0m     @     0x5604e8eabbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45798)\u001b[0m     @     0x5604e8f36baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45798)\u001b[0m     @     0x5604e8f37643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45798)\u001b[0m     @     0x5604e8eac689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45798)\u001b[0m     @     0x5604e8f36baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45798)\u001b[0m     @     0x5604e8f37643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45798)\u001b[0m     @     0x5604e8eac689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45798)\u001b[0m     @     0x5604e8f36baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45798)\u001b[0m     @     0x5604e8f37643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45798)\u001b[0m     @     0x5604e8eac689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45798)\u001b[0m     @     0x5604e8f36baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45798)\u001b[0m     @     0x5604e8f37643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45798)\u001b[0m     @     0x5604e8eac689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45818)\u001b[0m     @     0x7f7614b658de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45818)\u001b[0m     @     0x7f76126924f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45818)\u001b[0m     @     0x7f761873d79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45818)\u001b[0m     @     0x5567e8972fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45818)\u001b[0m     @     0x5567e88cdb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45818)\u001b[0m     @     0x5567e8958baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45818)\u001b[0m     @     0x5567e8959a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45818)\u001b[0m     @     0x5567e88cdbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45818)\u001b[0m     @     0x5567e8958baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45818)\u001b[0m     @     0x5567e8959643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45818)\u001b[0m     @     0x5567e88ce689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45818)\u001b[0m     @     0x5567e8958baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45818)\u001b[0m     @     0x5567e8959643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45818)\u001b[0m     @     0x5567e88ce689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45818)\u001b[0m     @     0x5567e8958baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45818)\u001b[0m     @     0x5567e8959643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45818)\u001b[0m     @     0x5567e88ce689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45818)\u001b[0m     @     0x5567e8958baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45818)\u001b[0m     @     0x5567e8959643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45818)\u001b[0m     @     0x5567e88ce689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45878)\u001b[0m     @     0x7f129a6924f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45878)\u001b[0m     @     0x7f12a073d79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45878)\u001b[0m     @     0x5607b2c4bfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45878)\u001b[0m     @     0x5607b2ba6b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45878)\u001b[0m     @     0x5607b2c31baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45878)\u001b[0m     @     0x5607b2c32a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45878)\u001b[0m     @     0x5607b2ba6bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45898)\u001b[0m     @     0x7f082e1654f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45898)\u001b[0m     @     0x7f083421079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45898)\u001b[0m     @     0x558574c6efd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45898)\u001b[0m     @     0x558574bc9b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45898)\u001b[0m     @     0x558574c54baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45898)\u001b[0m     @     0x558574c55a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45898)\u001b[0m     @     0x558574bc9bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45898)\u001b[0m     @     0x558574c54baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45898)\u001b[0m     @     0x558574c55643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45898)\u001b[0m     @     0x558574bca689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45898)\u001b[0m     @     0x558574c54baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45898)\u001b[0m     @     0x558574c55643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45898)\u001b[0m     @     0x558574bca689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45898)\u001b[0m     @     0x558574c54baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45898)\u001b[0m     @     0x558574c55643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45898)\u001b[0m     @     0x558574bca689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45898)\u001b[0m     @     0x558574c54baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45898)\u001b[0m     @     0x558574c55643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45898)\u001b[0m     @     0x558574bca689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45855)\u001b[0m     @     0x5558f39df643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45855)\u001b[0m     @     0x5558f3954689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45788)\u001b[0m     @     0x7efd623e079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45788)\u001b[0m     @     0x55fc2c1a5fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45788)\u001b[0m     @     0x55fc2c100b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45788)\u001b[0m     @     0x55fc2c18bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45788)\u001b[0m     @     0x55fc2c18ca20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45788)\u001b[0m     @     0x55fc2c100bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45788)\u001b[0m     @     0x55fc2c18bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45788)\u001b[0m     @     0x55fc2c18c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45788)\u001b[0m     @     0x55fc2c101689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45788)\u001b[0m     @     0x55fc2c18bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45788)\u001b[0m     @     0x55fc2c18c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45788)\u001b[0m     @     0x55fc2c101689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45788)\u001b[0m     @     0x55fc2c18bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45788)\u001b[0m     @     0x55fc2c18c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45788)\u001b[0m     @     0x55fc2c101689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45788)\u001b[0m     @     0x55fc2c18bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45788)\u001b[0m     @     0x55fc2c18c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45788)\u001b[0m     @     0x55fc2c101689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45870)\u001b[0m     @     0x7efaf2d088de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45870)\u001b[0m     @     0x7efaf08354f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45870)\u001b[0m     @     0x7efaf68e079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45870)\u001b[0m     @     0x55c98178ffd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45870)\u001b[0m     @     0x55c9816eab08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45870)\u001b[0m     @     0x55c981775baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45870)\u001b[0m     @     0x55c981776a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45870)\u001b[0m     @     0x55c9816eabfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45870)\u001b[0m     @     0x55c981775baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45870)\u001b[0m     @     0x55c981776643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45870)\u001b[0m     @     0x55c9816eb689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45870)\u001b[0m     @     0x55c981775baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45870)\u001b[0m     @     0x55c981776643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45870)\u001b[0m     @     0x55c9816eb689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45870)\u001b[0m     @     0x55c981775baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45870)\u001b[0m     @     0x55c981776643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45870)\u001b[0m     @     0x55c9816eb689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45870)\u001b[0m     @     0x55c981775baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45870)\u001b[0m     @     0x55c981776643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45870)\u001b[0m     @     0x55c9816eb689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45859)\u001b[0m     @     0x7f7a160ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45859)\u001b[0m     @     0x7f7a1c16579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45859)\u001b[0m     @     0x55c5a6bf0fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45859)\u001b[0m     @     0x55c5a6b4bb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45859)\u001b[0m     @     0x55c5a6bd6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45859)\u001b[0m     @     0x55c5a6bd7a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45859)\u001b[0m     @     0x55c5a6b4bbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45859)\u001b[0m     @     0x55c5a6bd6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45859)\u001b[0m     @     0x55c5a6bd7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45859)\u001b[0m     @     0x55c5a6b4c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45859)\u001b[0m     @     0x55c5a6bd6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45859)\u001b[0m     @     0x55c5a6bd7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45859)\u001b[0m     @     0x55c5a6b4c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45859)\u001b[0m     @     0x55c5a6bd6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45859)\u001b[0m     @     0x55c5a6bd7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45859)\u001b[0m     @     0x55c5a6b4c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45859)\u001b[0m     @     0x55c5a6bd6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45859)\u001b[0m     @     0x55c5a6bd7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45859)\u001b[0m     @     0x55c5a6b4c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45803)\u001b[0m     @     0x7f01ddedf4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45803)\u001b[0m     @     0x7f01e3f8a79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45803)\u001b[0m     @     0x5627bf70cfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45803)\u001b[0m     @     0x5627bf667b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45803)\u001b[0m     @     0x5627bf6f2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45803)\u001b[0m     @     0x5627bf6f3a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45803)\u001b[0m     @     0x5627bf667bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45803)\u001b[0m     @     0x5627bf6f2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45803)\u001b[0m     @     0x5627bf6f3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45803)\u001b[0m     @     0x5627bf668689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45803)\u001b[0m     @     0x5627bf6f2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45803)\u001b[0m     @     0x5627bf6f3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45803)\u001b[0m     @     0x5627bf668689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45803)\u001b[0m     @     0x5627bf6f2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45803)\u001b[0m     @     0x5627bf6f3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45803)\u001b[0m     @     0x5627bf668689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45803)\u001b[0m     @     0x5627bf6f2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45803)\u001b[0m     @     0x5627bf6f3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45803)\u001b[0m     @     0x5627bf668689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45812)\u001b[0m     @     0x7f8e92b1079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45812)\u001b[0m     @     0x558a429d6fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45812)\u001b[0m     @     0x558a42931b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45812)\u001b[0m     @     0x558a429bcbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45812)\u001b[0m     @     0x558a429bda20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45812)\u001b[0m     @     0x558a42931bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45812)\u001b[0m     @     0x558a429bcbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45812)\u001b[0m     @     0x558a429bd643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45812)\u001b[0m     @     0x558a42932689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45812)\u001b[0m     @     0x558a429bcbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45812)\u001b[0m     @     0x558a429bd643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45812)\u001b[0m     @     0x558a42932689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45812)\u001b[0m     @     0x558a429bcbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45812)\u001b[0m     @     0x558a429bd643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45812)\u001b[0m     @     0x558a42932689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45812)\u001b[0m     @     0x558a429bcbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45812)\u001b[0m     @     0x558a429bd643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45812)\u001b[0m     @     0x558a42932689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45903)\u001b[0m     @     0x7f73625e24f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45903)\u001b[0m     @     0x7f736868d79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45903)\u001b[0m     @     0x5590faea5fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45903)\u001b[0m     @     0x5590fae00b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45903)\u001b[0m     @     0x5590fae8bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45903)\u001b[0m     @     0x5590fae8ca20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45903)\u001b[0m     @     0x5590fae00bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45903)\u001b[0m     @     0x5590fae8bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45903)\u001b[0m     @     0x5590fae8c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45903)\u001b[0m     @     0x5590fae01689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45903)\u001b[0m     @     0x5590fae8bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45903)\u001b[0m     @     0x5590fae8c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45903)\u001b[0m     @     0x5590fae01689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45903)\u001b[0m     @     0x5590fae8bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45903)\u001b[0m     @     0x5590fae8c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45903)\u001b[0m     @     0x5590fae01689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45903)\u001b[0m     @     0x5590fae8bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45903)\u001b[0m     @     0x5590fae8c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45903)\u001b[0m     @     0x5590fae01689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45861)\u001b[0m     @     0x7f846d2b54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45861)\u001b[0m     @     0x7f847336079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45861)\u001b[0m     @     0x555be5c6afd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45861)\u001b[0m     @     0x555be5bc5b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45861)\u001b[0m     @     0x555be5c50baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45861)\u001b[0m     @     0x555be5c51a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45861)\u001b[0m     @     0x555be5bc5bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45861)\u001b[0m     @     0x555be5c50baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45861)\u001b[0m     @     0x555be5c51643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45861)\u001b[0m     @     0x555be5bc6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45861)\u001b[0m     @     0x555be5c50baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45861)\u001b[0m     @     0x555be5c51643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45861)\u001b[0m     @     0x555be5bc6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45861)\u001b[0m     @     0x555be5c50baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45861)\u001b[0m     @     0x555be5c51643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45861)\u001b[0m     @     0x555be5bc6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45861)\u001b[0m     @     0x555be5c50baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45861)\u001b[0m     @     0x555be5c51643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45861)\u001b[0m     @     0x555be5bc6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45846)\u001b[0m     @     0x7f324cfa78de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45846)\u001b[0m     @     0x7f324aad44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45846)\u001b[0m     @     0x7f3250b7f79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45846)\u001b[0m     @     0x562503395fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45846)\u001b[0m     @     0x5625032f0b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45846)\u001b[0m     @     0x56250337bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45846)\u001b[0m     @     0x56250337ca20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45846)\u001b[0m     @     0x5625032f0bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45846)\u001b[0m     @     0x56250337bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45846)\u001b[0m     @     0x56250337c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45846)\u001b[0m     @     0x5625032f1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45846)\u001b[0m     @     0x56250337bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45846)\u001b[0m     @     0x56250337c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45846)\u001b[0m     @     0x5625032f1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45846)\u001b[0m     @     0x56250337bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45846)\u001b[0m     @     0x56250337c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45846)\u001b[0m     @     0x5625032f1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45846)\u001b[0m     @     0x56250337bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45846)\u001b[0m     @     0x56250337c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45846)\u001b[0m     @     0x5625032f1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45874)\u001b[0m     @     0x55c84977bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45874)\u001b[0m     @     0x55c84977c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45874)\u001b[0m     @     0x55c8496f1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45810)\u001b[0m     @     0x7f3a9388d8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45810)\u001b[0m     @     0x7f3a913ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45810)\u001b[0m     @     0x7f3a9746579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45810)\u001b[0m     @     0x5617ebca3fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45810)\u001b[0m     @     0x5617ebbfeb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45810)\u001b[0m     @     0x5617ebc89baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45810)\u001b[0m     @     0x5617ebc8aa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45810)\u001b[0m     @     0x5617ebbfebfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45810)\u001b[0m     @     0x5617ebc89baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45810)\u001b[0m     @     0x5617ebc8a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45810)\u001b[0m     @     0x5617ebbff689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45810)\u001b[0m     @     0x5617ebc89baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45810)\u001b[0m     @     0x5617ebc8a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45810)\u001b[0m     @     0x5617ebbff689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45810)\u001b[0m     @     0x5617ebc89baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45810)\u001b[0m     @     0x5617ebc8a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45810)\u001b[0m     @     0x5617ebbff689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45810)\u001b[0m     @     0x5617ebc89baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45810)\u001b[0m     @     0x5617ebc8a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45810)\u001b[0m     @     0x5617ebbff689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45880)\u001b[0m     @     0x557e38440689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45904)\u001b[0m     @     0x561899369baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45904)\u001b[0m     @     0x56189936aa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45904)\u001b[0m     @     0x5618992debfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45904)\u001b[0m     @     0x561899369baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45904)\u001b[0m     @     0x56189936a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45904)\u001b[0m     @     0x5618992df689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45904)\u001b[0m     @     0x561899369baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45904)\u001b[0m     @     0x56189936a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45904)\u001b[0m     @     0x5618992df689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45904)\u001b[0m     @     0x561899369baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45904)\u001b[0m     @     0x56189936a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45904)\u001b[0m     @     0x5618992df689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45904)\u001b[0m     @     0x561899369baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45904)\u001b[0m     @     0x56189936a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45904)\u001b[0m     @     0x5618992df689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45866)\u001b[0m     @     0x557e79bfcbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45866)\u001b[0m     @     0x557e79bfd643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45866)\u001b[0m     @     0x557e79b72689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45866)\u001b[0m     @     0x557e79bfcbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45866)\u001b[0m     @     0x557e79bfd643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45866)\u001b[0m     @     0x557e79b72689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45866)\u001b[0m     @     0x557e79bfcbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45866)\u001b[0m     @     0x557e79bfd643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45866)\u001b[0m     @     0x557e79b72689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45866)\u001b[0m     @     0x557e79bfcbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45866)\u001b[0m     @     0x557e79bfd643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45866)\u001b[0m     @     0x557e79b72689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45871)\u001b[0m     @     0x7f8d48bcaa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=45871)\u001b[0m     @     0x7f8d48bc8388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=45871)\u001b[0m     @     0x7f8d48bca5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45842)\u001b[0m     @     0x7ed6fd2b54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45842)\u001b[0m     @     0x7ed70336079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45842)\u001b[0m     @     0x56115ad9efd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45842)\u001b[0m     @     0x56115acf9b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45842)\u001b[0m     @     0x56115ad84baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45842)\u001b[0m     @     0x56115ad85a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45842)\u001b[0m     @     0x56115acf9bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45842)\u001b[0m     @     0x56115ad84baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45842)\u001b[0m     @     0x56115ad85643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45842)\u001b[0m     @     0x56115acfa689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45842)\u001b[0m     @     0x56115ad84baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45842)\u001b[0m     @     0x56115ad85643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45842)\u001b[0m     @     0x56115acfa689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45842)\u001b[0m     @     0x56115ad84baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45842)\u001b[0m     @     0x56115ad85643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45842)\u001b[0m     @     0x56115acfa689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45842)\u001b[0m     @     0x56115ad84baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45842)\u001b[0m     @     0x56115ad85643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45842)\u001b[0m     @     0x56115acfa689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45794)\u001b[0m     @     0x7f5c021958de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45794)\u001b[0m     @     0x7f5bffcc24f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45794)\u001b[0m     @     0x7f5c05d6d79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45794)\u001b[0m     @     0x5559bd2f9fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45794)\u001b[0m     @     0x5559bd254b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45794)\u001b[0m     @     0x5559bd2dfbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45794)\u001b[0m     @     0x5559bd2e0a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45794)\u001b[0m     @     0x5559bd254bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45794)\u001b[0m     @     0x5559bd2dfbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45794)\u001b[0m     @     0x5559bd2e0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45794)\u001b[0m     @     0x5559bd255689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45844)\u001b[0m     @     0x5603cf776b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45844)\u001b[0m     @     0x5603cf801baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45844)\u001b[0m     @     0x5603cf802a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45844)\u001b[0m     @     0x5603cf776bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45844)\u001b[0m     @     0x5603cf801baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45844)\u001b[0m     @     0x5603cf802643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45844)\u001b[0m     @     0x5603cf777689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45844)\u001b[0m     @     0x5603cf801baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45844)\u001b[0m     @     0x5603cf802643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45844)\u001b[0m     @     0x5603cf777689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45844)\u001b[0m     @     0x5603cf801baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45844)\u001b[0m     @     0x5603cf802643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45844)\u001b[0m     @     0x5603cf777689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45844)\u001b[0m     @     0x5603cf801baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45844)\u001b[0m     @     0x5603cf802643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45844)\u001b[0m     @     0x5603cf777689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45822)\u001b[0m     @     0x55b02e77e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45822)\u001b[0m     @     0x55b02e808baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45822)\u001b[0m     @     0x55b02e809643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45822)\u001b[0m     @     0x55b02e77e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45809)\u001b[0m     @     0x5558b4557689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45809)\u001b[0m     @     0x5558b45e1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45809)\u001b[0m     @     0x5558b45e2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45809)\u001b[0m     @     0x5558b4557689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45809)\u001b[0m     @     0x5558b45e1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45809)\u001b[0m     @     0x5558b45e2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45809)\u001b[0m     @     0x5558b4557689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45863)\u001b[0m     @     0x7f49891b979f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45863)\u001b[0m     @     0x56064cddcfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45863)\u001b[0m     @     0x56064cd37b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45863)\u001b[0m     @     0x56064cdc2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45863)\u001b[0m     @     0x56064cdc3a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45863)\u001b[0m     @     0x56064cd37bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45863)\u001b[0m     @     0x56064cdc2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45863)\u001b[0m     @     0x56064cdc3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45863)\u001b[0m     @     0x56064cd38689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45863)\u001b[0m     @     0x56064cdc2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45863)\u001b[0m     @     0x56064cdc3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45863)\u001b[0m     @     0x56064cd38689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45863)\u001b[0m     @     0x56064cdc2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45863)\u001b[0m     @     0x56064cdc3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45863)\u001b[0m     @     0x56064cd38689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45863)\u001b[0m     @     0x56064cdc2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45863)\u001b[0m     @     0x56064cdc3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45863)\u001b[0m     @     0x56064cd38689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45872)\u001b[0m     @     0x55d220062643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45872)\u001b[0m     @     0x55d21ffd7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45872)\u001b[0m     @     0x55d220061baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45872)\u001b[0m     @     0x55d220062643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45872)\u001b[0m     @     0x55d21ffd7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45785)\u001b[0m     @     0x7ef2d99e54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45785)\u001b[0m     @     0x7ef2dfa9079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45785)\u001b[0m     @     0x56530a5dffd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45785)\u001b[0m     @     0x56530a53ab08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45785)\u001b[0m     @     0x56530a5c5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45785)\u001b[0m     @     0x56530a5c6a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45785)\u001b[0m     @     0x56530a53abfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45785)\u001b[0m     @     0x56530a5c5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45785)\u001b[0m     @     0x56530a5c6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45785)\u001b[0m     @     0x56530a53b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45785)\u001b[0m     @     0x56530a5c5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45785)\u001b[0m     @     0x56530a5c6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45785)\u001b[0m     @     0x56530a53b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45785)\u001b[0m     @     0x56530a5c5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45785)\u001b[0m     @     0x56530a5c6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45785)\u001b[0m     @     0x56530a53b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45785)\u001b[0m     @     0x56530a5c5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45785)\u001b[0m     @     0x56530a5c6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45785)\u001b[0m     @     0x56530a53b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45867)\u001b[0m     @     0x7f1189f0c4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45867)\u001b[0m     @     0x7f118ffb779f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45867)\u001b[0m     @     0x55f3dbd93fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45867)\u001b[0m     @     0x55f3dbceeb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45867)\u001b[0m     @     0x55f3dbd79baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45867)\u001b[0m     @     0x55f3dbd7aa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45867)\u001b[0m     @     0x55f3dbceebfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45867)\u001b[0m     @     0x55f3dbd79baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45867)\u001b[0m     @     0x55f3dbd7a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45867)\u001b[0m     @     0x55f3dbcef689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45867)\u001b[0m     @     0x55f3dbd79baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45867)\u001b[0m     @     0x55f3dbd7a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45867)\u001b[0m     @     0x55f3dbcef689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45867)\u001b[0m     @     0x55f3dbd79baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45867)\u001b[0m     @     0x55f3dbd7a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45867)\u001b[0m     @     0x55f3dbcef689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45867)\u001b[0m     @     0x55f3dbd79baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45867)\u001b[0m     @     0x55f3dbd7a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45867)\u001b[0m     @     0x55f3dbcef689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45879)\u001b[0m     @     0x7edf6fc8e4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45879)\u001b[0m     @     0x7edf75d3979f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45879)\u001b[0m     @     0x55b43acd6fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45879)\u001b[0m     @     0x55b43ac31b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45879)\u001b[0m     @     0x55b43acbcbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45879)\u001b[0m     @     0x55b43acbda20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45879)\u001b[0m     @     0x55b43ac31bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45879)\u001b[0m     @     0x55b43acbcbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45879)\u001b[0m     @     0x55b43acbd643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45879)\u001b[0m     @     0x55b43ac32689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45879)\u001b[0m     @     0x55b43acbcbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45879)\u001b[0m     @     0x55b43acbd643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45879)\u001b[0m     @     0x55b43ac32689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45879)\u001b[0m     @     0x55b43acbcbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45879)\u001b[0m     @     0x55b43acbd643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45879)\u001b[0m     @     0x55b43ac32689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45879)\u001b[0m     @     0x55b43acbcbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45879)\u001b[0m     @     0x55b43acbd643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45879)\u001b[0m     @     0x55b43ac32689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45878)\u001b[0m     @     0x5607b2c31baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45878)\u001b[0m     @     0x5607b2c32643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45878)\u001b[0m     @     0x5607b2ba7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45878)\u001b[0m     @     0x5607b2c31baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45878)\u001b[0m     @     0x5607b2c32643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45878)\u001b[0m     @     0x5607b2ba7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45878)\u001b[0m     @     0x5607b2c31baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45878)\u001b[0m     @     0x5607b2c32643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45878)\u001b[0m     @     0x5607b2ba7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45878)\u001b[0m     @     0x5607b2c31baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45878)\u001b[0m     @     0x5607b2c32643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45878)\u001b[0m     @     0x5607b2ba7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45871)\u001b[0m     @     0x7f8d492b54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45871)\u001b[0m     @     0x7f8d4b7888de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45794)\u001b[0m     @     0x5559bd2dfbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45794)\u001b[0m     @     0x5559bd2e0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45794)\u001b[0m     @     0x5559bd255689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45794)\u001b[0m     @     0x5559bd2dfbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45794)\u001b[0m     @     0x5559bd2e0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45794)\u001b[0m     @     0x5559bd255689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45794)\u001b[0m     @     0x5559bd2dfbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45794)\u001b[0m     @     0x5559bd2e0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45794)\u001b[0m     @     0x5559bd255689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45871)\u001b[0m     @     0x7f8d492b54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45871)\u001b[0m     @     0x7f8d4f36079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=45871)\u001b[0m     @     0x55676dce9fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=45871)\u001b[0m     @     0x55676dc44b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45871)\u001b[0m     @     0x55676dccfbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45871)\u001b[0m     @     0x55676dcd0a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=45871)\u001b[0m     @     0x55676dc44bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45871)\u001b[0m     @     0x55676dccfbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45871)\u001b[0m     @     0x55676dcd0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45871)\u001b[0m     @     0x55676dc45689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45871)\u001b[0m     @     0x55676dccfbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45871)\u001b[0m     @     0x55676dcd0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45871)\u001b[0m     @     0x55676dc45689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45871)\u001b[0m     @     0x55676dccfbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45871)\u001b[0m     @     0x55676dcd0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45871)\u001b[0m     @     0x55676dc45689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=45871)\u001b[0m     @     0x55676dccfbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=45871)\u001b[0m     @     0x55676dcd0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=45871)\u001b[0m     @     0x55676dc45689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "2020-11-05 10:44:44,656\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffffe0497dac01000000.\n",
+      "2020-11-05 10:44:44,656\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff31c3fed901000000.\n",
+      "2020-11-05 10:44:44,666\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff4100f4fd01000000.\n",
+      "2020-11-05 10:44:44,667\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff091d563401000000.\n",
+      "2020-11-05 10:44:44,667\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff43fb47bd01000000.\n",
+      "2020-11-05 10:44:44,678\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff4e242e9f01000000.\n",
+      "2020-11-05 10:44:44,678\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffffa97540c201000000.\n",
+      "2020-11-05 10:44:44,678\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff821ddf4301000000.\n",
+      "2020-11-05 10:44:44,688\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff252160a301000000.\n",
+      "2020-11-05 10:44:44,689\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffffbdff035801000000.\n",
+      "2020-11-05 10:44:44,689\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff9f3cc57a01000000.\n",
+      "2020-11-05 10:44:44,720\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff56c9ec1501000000.\n",
+      "2020-11-05 10:44:44,729\tERROR trial_runner.py:567 -- Trial PPO_jss_env_e6675_00000: Error processing event.\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/trial_runner.py\", line 515, in _process_trial\n",
+      "    result = self.trial_executor.fetch_result(trial)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/ray_trial_executor.py\", line 488, in fetch_result\n",
+      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1428, in get\n",
+      "    raise value.as_instanceof_cause()\n",
+      "ray.exceptions.RayTaskError: \u001b[36mray::PPO.train()\u001b[39m (pid=45908, ip=172.17.0.4)\n",
+      "  File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
+      "  File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\", line 516, in train\n",
+      "    raise e\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\", line 505, in train\n",
+      "    result = Trainable.train(self)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/trainable.py\", line 336, in train\n",
+      "    result = self.step()\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer_template.py\", line 134, in step\n",
+      "    res = next(self.train_exec_impl)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 756, in __next__\n",
+      "    return next(self.built_iterator)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 843, in apply_filter\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 843, in apply_filter\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  [Previous line repeated 1 more time]\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 876, in apply_flatten\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 828, in add_wait_hooks\n",
+      "    item = next(it)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  [Previous line repeated 1 more time]\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 466, in base_iterator\n",
+      "    actor_set.init_actors()\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 1238, in init_actors\n",
+      "    ray.get([a.par_iter_init.remote(self.transforms) for a in self.actors])\n",
+      "ray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.\n",
+      "2020-11-05 10:44:44,730\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff8edbbd3001000000.\n",
+      "2020-11-05 10:44:44,731\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff90aded9101000000.\n",
+      "2020-11-05 10:44:44,732\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff9d526f0201000000.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 22.9/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/1 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 ERROR)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_e6675_00000 | ERROR    |       |\n",
+      "+-------------------------+----------+-------+\n",
+      "Number of errored trials: 1\n",
+      "+-------------------------+--------------+-----------------------------------------------------------------------------------+\n",
+      "| Trial name              |   # failures | error file                                                                        |\n",
+      "|-------------------------+--------------+-----------------------------------------------------------------------------------|\n",
+      "| PPO_jss_env_e6675_00000 |            1 | /root/ray_results/ppo-jss/PPO_jss_env_e6675_00000_0_2020-11-05_10-44-37/error.txt |\n",
+      "+-------------------------+--------------+-----------------------------------------------------------------------------------+\n",
       "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 4096\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
-      "2020-10-14 20:45:15,074 - wandb.wandb_agent - INFO - Running runs: ['kkype8ue']\n",
+      "== Status ==\n",
+      "Memory usage on this node: 22.8/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/1 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 ERROR)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_e6675_00000 | ERROR    |       |\n",
+      "+-------------------------+----------+-------+\n",
+      "Number of errored trials: 1\n",
+      "+-------------------------+--------------+-----------------------------------------------------------------------------------+\n",
+      "| Trial name              |   # failures | error file                                                                        |\n",
+      "|-------------------------+--------------+-----------------------------------------------------------------------------------|\n",
+      "| PPO_jss_env_e6675_00000 |            1 | /root/ray_results/ppo-jss/PPO_jss_env_e6675_00000_0_2020-11-05_10-44-37/error.txt |\n",
+      "+-------------------------+--------------+-----------------------------------------------------------------------------------+\n",
+      "\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m E1105 10:44:44.723598 45908 46700 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=170fdfd5d34985a7e0497dac01000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=e0497dac01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m E1105 10:44:44.723759 45908 46700 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=89f63fee54d6858ee0497dac01000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=e0497dac01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m E1105 10:44:44.723928 45908 46700 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=7dd3b2683d323ffd31c3fed901000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=31c3fed901000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m E1105 10:44:44.724010 45908 46700 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=0a51bbe8b791810831c3fed901000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=31c3fed901000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m E1105 10:44:44.724189 45908 46700 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=d984ee9d41b92c534100f4fd01000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=4100f4fd01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m E1105 10:44:44.724265 45908 46700 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=6c41da4ee8b0b4d04100f4fd01000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=4100f4fd01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m E1105 10:44:44.724407 45908 46700 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=1f6f5417a7b065f9091d563401000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=091d563401000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m E1105 10:44:44.724475 45908 46700 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=e76b5820fbdeb0f2091d563401000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=091d563401000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m E1105 10:44:44.724579 45908 46700 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=1e9c16c25b494a4a43fb47bd01000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=43fb47bd01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m E1105 10:44:44.724642 45908 46700 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=61afdfe40390d0a343fb47bd01000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=43fb47bd01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m E1105 10:44:44.724741 45908 46700 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=bf6cd9795b8b23124e242e9f01000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=4e242e9f01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m E1105 10:44:44.724804 45908 46700 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=c5da4173a1c517cf4e242e9f01000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=4e242e9f01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m E1105 10:44:44.724913 45908 46700 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=fde3d5eda9f525d7a97540c201000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=a97540c201000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m E1105 10:44:44.724972 45908 46700 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=d16c21eef3935840a97540c201000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=a97540c201000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m E1105 10:44:44.725088 45908 46700 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=8e79ac7e91b36714821ddf4301000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=821ddf4301000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m E1105 10:44:44.725147 45908 46700 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=428a4b4025d91890821ddf4301000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=821ddf4301000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m E1105 10:44:44.725251 45908 46700 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=3e4916e36cb3ce60252160a301000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=252160a301000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m E1105 10:44:44.725306 45908 46700 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=c2d663ba592886f5252160a301000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=252160a301000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m E1105 10:44:44.725406 45908 46700 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=137dbd5547ea6deabdff035801000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=bdff035801000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m E1105 10:44:44.725468 45908 46700 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=3f75a43fb9f70f24bdff035801000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=bdff035801000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "2020-11-05 10:44:44,753\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff0314ce3001000000.\n",
+      "2020-11-05 10:44:44,753\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff19fd5b4901000000.\n",
+      "2020-11-05 10:44:44,754\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffffc3083e0c01000000.\n",
+      "Traceback (most recent call last):\n",
+      "  File \"train.py\", line 74, in <module>\n",
+      "    train_func()\n",
+      "  File \"train.py\", line 56, in train_func\n",
+      "    analysis = tune.run(PPOTrainer, config=config, stop=stop, name=\"ppo-jss\")\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/tune.py\", line 427, in run\n",
+      "    raise TuneError(\"Trials did not complete\", incomplete_trials)\n",
+      "ray.tune.error.TuneError: ('Trials did not complete', [PPO_jss_env_e6675_00000])\n",
+      "\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 45685\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 1.  Press ctrl-c to abort syncing.\n",
+      "--- Logging error --- 4.84MB of 4.84MB uploaded (0.00MB deduped)\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff244a7d1001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff0d557f6601000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff04668d8f01000000.'\n",
+      "Arguments: ()\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m E1105 10:44:44.742803 45908 46700 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=efaf5dbfabc208739f3cc57a01000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=9f3cc57a01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m E1105 10:44:44.742998 45908 46700 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=b3b45bae970c41729f3cc57a01000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=9f3cc57a01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m E1105 10:44:44.743170 45908 46700 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=4db1cba171d56c3356c9ec1501000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=56c9ec1501000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m E1105 10:44:44.743234 45908 46700 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=5cf29c5b7b7ed08d56c9ec1501000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=56c9ec1501000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m E1105 10:44:44.743511 45908 46700 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=4027410178b738888edbbd3001000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=8edbbd3001000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m E1105 10:44:44.743645 45908 46700 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=f4290d8c04f479ac8edbbd3001000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=8edbbd3001000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m E1105 10:44:44.743777 45908 46700 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=37f0cff2c5fdc1c790aded9101000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=90aded9101000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m E1105 10:44:44.743845 45908 46700 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=ff02fc67a478da9090aded9101000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=90aded9101000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m E1105 10:44:44.743971 45908 46700 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=f26c08df806c9b079d526f0201000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=9d526f0201000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m E1105 10:44:44.744112 45908 46700 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=3501fe38550fe14a9d526f0201000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=9d526f0201000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m E1105 10:44:44.744720 45908 46700 task_manager.cc:323] Task failed: IOError: cancelling all pending tasks of dead actor: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=150a9d56b40e3700bdff035801000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=bdff035801000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m E1105 10:44:44.744904 45908 46700 task_manager.cc:323] Task failed: IOError: cancelling all pending tasks of dead actor: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=d88ec84d5baca957a97540c201000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=a97540c201000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m E1105 10:44:44.745048 45908 46700 task_manager.cc:323] Task failed: IOError: cancelling all pending tasks of dead actor: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=37f711ca0d66f5bd4100f4fd01000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=4100f4fd01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m E1105 10:44:44.745200 45908 46700 task_manager.cc:323] Task failed: IOError: cancelling all pending tasks of dead actor: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=c6f8a2750fad0b0de0497dac01000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=e0497dac01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m E1105 10:44:44.745330 45908 46700 task_manager.cc:323] Task failed: IOError: cancelling all pending tasks of dead actor: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=10a4a4113c6c36ea43fb47bd01000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=43fb47bd01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m E1105 10:44:44.745469 45908 46700 task_manager.cc:323] Task failed: IOError: cancelling all pending tasks of dead actor: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=d7b1ed864d13e17f31c3fed901000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=31c3fed901000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m E1105 10:44:44.745609 45908 46700 task_manager.cc:323] Task failed: IOError: cancelling all pending tasks of dead actor: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=457f03c785986c89252160a301000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=252160a301000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m E1105 10:44:44.745965 45908 46700 task_manager.cc:323] Task failed: IOError: cancelling all pending tasks of dead actor: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=4f22c19b5f703db99f3cc57a01000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=9f3cc57a01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m E1105 10:44:44.746021 45908 46700 task_manager.cc:323] Task failed: IOError: cancelling all pending tasks of dead actor: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=626c71df3976eafd4e242e9f01000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=4e242e9f01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m E1105 10:44:44.746134 45908 46700 task_manager.cc:323] Task failed: IOError: cancelling all pending tasks of dead actor: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=7249131d8582b825091d563401000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=091d563401000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m E1105 10:44:44.746315 45908 46700 task_manager.cc:323] Task failed: IOError: cancelling all pending tasks of dead actor: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=38e2d2d27b716bfb821ddf4301000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=821ddf4301000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m E1105 10:44:44.746745 45908 46700 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=f4d9d8a5e202b0910314ce3001000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=0314ce3001000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m E1105 10:44:44.746831 45908 46700 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=8b0b449b9f08d0430314ce3001000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=0314ce3001000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m E1105 10:44:44.747231 45908 46700 task_manager.cc:323] Task failed: IOError: cancelling all pending tasks of dead actor: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=6b6365ef3364d41390aded9101000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=90aded9101000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m E1105 10:44:44.747354 45908 46700 task_manager.cc:323] Task failed: IOError: 14: failed to connect to all addresses: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=ad47e6e6a1a1660b0314ce3001000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=0314ce3001000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m E1105 10:44:44.747481 45908 46700 task_manager.cc:323] Task failed: IOError: cancelling all pending tasks of dead actor: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=9d0a2db204e8f81056c9ec1501000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=56c9ec1501000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m E1105 10:44:44.747761 45908 46700 task_manager.cc:323] Task failed: IOError: cancelling all pending tasks of dead actor: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=d9b69b81196304409d526f0201000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=9d526f0201000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m E1105 10:44:44.747942 45908 46700 task_manager.cc:323] Task failed: IOError: cancelling all pending tasks of dead actor: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=a4e1f5da99aef89f8edbbd3001000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=8edbbd3001000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m E1105 10:44:44.750429 45908 46700 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=10f13a6ae4c2def519fd5b4901000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=19fd5b4901000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=45908)\u001b[0m E1105 10:44:44.750509 45908 46700 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=1bca13ad3b6e35d119fd5b4901000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=19fd5b4901000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff8d06128001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff75f329e601000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffa4f7314201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff310e963d01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff32335d4e01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff8f9a5fc701000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff59d91ef301000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff0fae11b201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff99d0343201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff3166f9e301000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff3a9488b101000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff14da135201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task fffffffffffffffff392716d01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff80993fa801000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffc2621d1401000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffd8f83c3801000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff1e7ae67b01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task fffffffffffffffff0f72e3901000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffdd5654aa01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffeca600ef01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff452e714401000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff2d1a71ea01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff51728d3301000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffb2413f7201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffee8852f401000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff34cbbac201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffb3cace0801000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff7a508a7a01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff7b2861ac01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff61dc472601000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff58dd50c101000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffccf343cc01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff7f7c936001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff5843697701000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffa7ad1db301000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff8168b55d01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff71ca01c001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff358dd45601000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff018c9dac01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffd784bf0601000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task fffffffffffffffff120020c01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff4f9bfece01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff302122d001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff10f667b001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffffefbd9801000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff50168bc201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffef1af81501000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff0aeae6a301000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffda2cd21f01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffe9f6a7cf01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff41e0fbff01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff702ed69e01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffd989d1f001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff20d842ad01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff8cd168e101000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff5cc87e2501000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff7ef9157101000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task fffffffffffffffff257d30801000000.'\n",
+      "Arguments: ()\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201014_204512-kkype8ue/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201014_204512-kkype8ue/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:       nb_episodes 1\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   avg_best_result 197.64646\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_episode 197.64646\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:     best_timestep 3735\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:             _step 0\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:          _runtime 1\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        _timestamp 1602708313\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:       nb_episodes ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   avg_best_result ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_episode ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:     best_timestep ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:             _step ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:          _runtime ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        _timestamp ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201105_104432-968941xy/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201105_104432-968941xy/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mMTWR\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/kkype8ue\u001b[0m\n",
-      "2020-10-14 20:45:20,294 - wandb.wandb_agent - INFO - Cleaning up finished run: kkype8ue\n",
-      "2020-10-14 20:45:20,607 - wandb.wandb_agent - INFO - Agent received command: exit\n",
-      "2020-10-14 20:45:20,607 - wandb.wandb_agent - INFO - Received exit command. Killing runs and quitting.\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Terminating and syncing runs. Press ctrl-c to kill.\n"
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mdutiful-sweep-5\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/968941xy\u001b[0m\n"
      ]
     }
    ],
    "source": [
-    "!wandb agent po3ygyxo"
+    "!wandb agent 72qf0qyh"
    ]
   },
   {
diff --git a/JSS/Random.ipynb b/JSS/Random.ipynb
index a16b1ba..30632e8 100644
--- a/JSS/Random.ipynb
+++ b/JSS/Random.ipynb
@@ -2,7 +2,7 @@
  "cells": [
   {
    "cell_type": "code",
-   "execution_count": 1,
+   "execution_count": 7,
    "metadata": {},
    "outputs": [
     {
@@ -56,7 +56,7 @@
     "    print(\"I have detected {} CPUs here, so I'm going to create {} actors\".format(mp.cpu_count(), mp.cpu_count() - 1))\n",
     "    os.environ[\"WANDB_API_KEY\"] = '3487a01956bf67cc7882bca2a38f70c8c95f8463'\n",
     "    sweep_config = {\n",
-    "        'program': 'random_loop.py',\n",
+    "        'program': 'CP.py',\n",
     "        'method': 'grid',\n",
     "        'metric': {\n",
     "            'name': 'time_step_min',\n",
@@ -64,9 +64,9 @@
     "        },\n",
     "        'parameters': {\n",
     "            'instance_path': {\n",
-    "                'values': ['/JSS/JSS/env/instances/ta51', '/JSS/JSS/env/instances/ta52', '/JSS/JSS/env/instances/ta53', '/JSS/JSS/env/instances/ta54',\n",
-    "                           '/JSS/JSS/env/instances/ta55', '/JSS/JSS/env/instances/ta56', '/JSS/JSS/env/instances/ta57', '/JSS/JSS/env/instances/ta58',\n",
-    "                           '/JSS/JSS/env/instances/ta59', '/JSS/JSS/env/instances/ta60']\n",
+    "                'values': ['/JSS/JSS/env/instances/ta40', '/JSS/JSS/env/instances/ta41', '/JSS/JSS/env/instances/ta42', '/JSS/JSS/env/instances/ta43', '/JSS/JSS/env/instances/ta44',\n",
+    "                           '/JSS/JSS/env/instances/ta45', '/JSS/JSS/env/instances/ta46', '/JSS/JSS/env/instances/ta47', '/JSS/JSS/env/instances/ta48',\n",
+    "                           '/JSS/JSS/env/instances/ta49', '/JSS/JSS/env/instances/ta50']\n",
     "            }\n",
     "        }\n",
     "    }"
@@ -74,25 +74,25 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 2,
+   "execution_count": 8,
    "metadata": {},
    "outputs": [
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "Create sweep with ID: lh9x5rb9\n",
-      "Sweep URL: https://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/lh9x5rb9\n"
+      "Create sweep with ID: wnc8ihq1\n",
+      "Sweep URL: https://wandb.ai/ingambe/RLLIB_SWEEP_3/sweeps/wnc8ihq1\n"
      ]
     }
    ],
    "source": [
-    "sweep_id = wandb.sweep(sweep_config, project=\"RLLIB_SWEEP_2\")"
+    "sweep_id = wandb.sweep(sweep_config, project=\"RLLIB_SWEEP_3\")"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 3,
+   "execution_count": 9,
    "metadata": {},
    "outputs": [
     {
@@ -100,1977 +100,422 @@
      "output_type": "stream",
      "text": [
       "\u001b[34m\u001b[1mwandb\u001b[0m: Starting wandb agent üïµÔ∏è\n",
-      "2020-10-14 18:51:58,915 - wandb.wandb_agent - INFO - Running runs: []\n",
-      "2020-10-14 18:51:59,229 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-14 18:51:59,229 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tinstance_path: /JSS/JSS/env/instances/ta51\n",
-      "2020-10-14 18:51:59,231 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python random_loop.py --instance_path=/JSS/JSS/env/instances/ta51\n",
+      "2020-11-04 21:27:40,508 - wandb.wandb_agent - INFO - Running runs: []\n",
+      "2020-11-04 21:27:40,953 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-11-04 21:27:40,953 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tinstance_path: /JSS/JSS/env/instances/ta40\n",
+      "2020-11-04 21:27:40,955 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python CP.py --instance_path=/JSS/JSS/env/instances/ta40\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "2020-10-14 18:52:04,245 - wandb.wandb_agent - INFO - Running runs: ['bgm3l5ts']\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.8 is available!  To upgrade, please run:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33meffortless-sweep-1\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/lh9x5rb9\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/bgm3l5ts\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201014_185201-bgm3l5ts\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mCP\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/sweeps/wnc8ihq1\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/h3u61381\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201104_212741-h3u61381\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
-      "2020-10-14 18:52:04,834\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
-      "== Status ==\n",
-      "Memory usage on this node: 11.7/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 0/3 GPUs, 0.0/557.13 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+----------------------------------+----------+-------+\n",
-      "| Trial name                       | status   | loc   |\n",
-      "|----------------------------------+----------+-------|\n",
-      "| RandomMasked_jss_env_5afa5_00000 | RUNNING  |       |\n",
-      "+----------------------------------+----------+-------+\n",
+      "2020-11-04 21:27:45,971 - wandb.wandb_agent - INFO - Running runs: ['h3u61381']\n",
       "\n",
-      "\n",
-      "\u001b[2m\u001b[36m(pid=25130)\u001b[0m 2020-10-14 18:52:07,658\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "Result for RandomMasked_jss_env_5afa5_00000:\n",
-      "  custom_metrics: {}\n",
-      "  date: 2020-10-14_18-52-11\n",
-      "  done: false\n",
-      "  episode_len_mean: .nan\n",
-      "  episode_reward_max: .nan\n",
-      "  episode_reward_mean: .nan\n",
-      "  episode_reward_min: .nan\n",
-      "  episodes_this_iter: 0\n",
-      "  episodes_total: 0\n",
-      "  experiment_id: 1d2b23a635304ca6bea1e0ffde98d7ee\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    num_steps_sampled: 400\n",
-      "  iterations_since_restore: 1\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 72.94000000000001\n",
-      "    gpu_util_percent0: 0.0\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 2.3600000000000003\n",
-      "    vram_util_percent0: 0.0\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 25130\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf: {}\n",
-      "  time_since_restore: 3.247757911682129\n",
-      "  time_this_iter_s: 3.247757911682129\n",
-      "  time_total_s: 3.247757911682129\n",
-      "  timers: {}\n",
-      "  timestamp: 1602701531\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 400\n",
-      "  training_iteration: 1\n",
-      "  trial_id: 5afa5_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 21.8/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 0/3 GPUs, 0.0/557.13 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+----------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name                       | status   | loc              |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|----------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|\n",
-      "| RandomMasked_jss_env_5afa5_00000 | RUNNING  | 172.17.0.4:25130 |      1 |          3.24776 |  400 |      nan |                  nan |                  nan |                nan |\n",
-      "+----------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for RandomMasked_jss_env_5afa5_00000:\n",
-      "  custom_metrics: {}\n",
-      "  date: 2020-10-14_18-52-16\n",
-      "  done: false\n",
-      "  episode_len_mean: .nan\n",
-      "  episode_reward_max: .nan\n",
-      "  episode_reward_mean: .nan\n",
-      "  episode_reward_min: .nan\n",
-      "  episodes_this_iter: 0\n",
-      "  episodes_total: 0\n",
-      "  experiment_id: 1d2b23a635304ca6bea1e0ffde98d7ee\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    num_steps_sampled: 12000\n",
-      "  iterations_since_restore: 30\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 5.3\n",
-      "    gpu_util_percent0: 0.0\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 2.9\n",
-      "    vram_util_percent0: 0.0\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 25130\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf: {}\n",
-      "  time_since_restore: 8.01456618309021\n",
-      "  time_this_iter_s: 0.16585516929626465\n",
-      "  time_total_s: 8.01456618309021\n",
-      "  timers: {}\n",
-      "  timestamp: 1602701536\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 12000\n",
-      "  training_iteration: 30\n",
-      "  trial_id: 5afa5_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 21.9/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 0/3 GPUs, 0.0/557.13 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name                       | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
-      "| RandomMasked_jss_env_5afa5_00000 | RUNNING  | 172.17.0.4:25130 |     30 |          8.01457 | 12000 |      nan |                  nan |                  nan |                nan |\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for RandomMasked_jss_env_5afa5_00000:\n",
-      "  custom_metrics: {}\n",
-      "  date: 2020-10-14_18-52-21\n",
-      "  done: false\n",
-      "  episode_len_mean: .nan\n",
-      "  episode_reward_max: .nan\n",
-      "  episode_reward_mean: .nan\n",
-      "  episode_reward_min: .nan\n",
-      "  episodes_this_iter: 0\n",
-      "  episodes_total: 0\n",
-      "  experiment_id: 1d2b23a635304ca6bea1e0ffde98d7ee\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    num_steps_sampled: 23600\n",
-      "  iterations_since_restore: 59\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf: {}\n",
-      "  pid: 25130\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf: {}\n",
-      "  time_since_restore: 12.782260656356812\n",
-      "  time_this_iter_s: 0.1621565818786621\n",
-      "  time_total_s: 12.782260656356812\n",
-      "  timers: {}\n",
-      "  timestamp: 1602701541\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 23600\n",
-      "  training_iteration: 59\n",
-      "  trial_id: 5afa5_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 22.0/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 0/3 GPUs, 0.0/557.13 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name                       | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
-      "| RandomMasked_jss_env_5afa5_00000 | RUNNING  | 172.17.0.4:25130 |     59 |          12.7823 | 23600 |      nan |                  nan |                  nan |                nan |\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "== Status ==\n",
-      "Memory usage on this node: 22.0/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 0/3 GPUs, 0.0/557.13 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name                       | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
-      "| RandomMasked_jss_env_5afa5_00000 | RUNNING  | 172.17.0.4:25130 |     87 |          17.4055 | 34800 |      nan |                  nan |                  nan |                nan |\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for RandomMasked_jss_env_5afa5_00000:\n",
-      "  custom_metrics: {}\n",
-      "  date: 2020-10-14_18-52-26\n",
-      "  done: false\n",
-      "  episode_len_mean: .nan\n",
-      "  episode_reward_max: .nan\n",
-      "  episode_reward_mean: .nan\n",
-      "  episode_reward_min: .nan\n",
-      "  episodes_this_iter: 0\n",
-      "  episodes_total: 0\n",
-      "  experiment_id: 1d2b23a635304ca6bea1e0ffde98d7ee\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    num_steps_sampled: 35200\n",
-      "  iterations_since_restore: 88\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf: {}\n",
-      "  pid: 25130\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf: {}\n",
-      "  time_since_restore: 17.567854166030884\n",
-      "  time_this_iter_s: 0.16233396530151367\n",
-      "  time_total_s: 17.567854166030884\n",
-      "  timers: {}\n",
-      "  timestamp: 1602701546\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 35200\n",
-      "  training_iteration: 88\n",
-      "  trial_id: 5afa5_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 22.0/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 0/3 GPUs, 0.0/557.13 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name                       | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
-      "| RandomMasked_jss_env_5afa5_00000 | RUNNING  | 172.17.0.4:25130 |    116 |          22.0842 | 46400 |      nan |                  nan |                  nan |                nan |\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for RandomMasked_jss_env_5afa5_00000:\n",
-      "  custom_metrics: {}\n",
-      "  date: 2020-10-14_18-52-31\n",
-      "  done: false\n",
-      "  episode_len_mean: .nan\n",
-      "  episode_reward_max: .nan\n",
-      "  episode_reward_mean: .nan\n",
-      "  episode_reward_min: .nan\n",
-      "  episodes_this_iter: 0\n",
-      "  episodes_total: 0\n",
-      "  experiment_id: 1d2b23a635304ca6bea1e0ffde98d7ee\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    num_steps_sampled: 46800\n",
-      "  iterations_since_restore: 117\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf: {}\n",
-      "  pid: 25130\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf: {}\n",
-      "  time_since_restore: 22.268078804016113\n",
-      "  time_this_iter_s: 0.18388056755065918\n",
-      "  time_total_s: 22.268078804016113\n",
-      "  timers: {}\n",
-      "  timestamp: 1602701551\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 46800\n",
-      "  training_iteration: 117\n",
-      "  trial_id: 5afa5_00000\n",
-      "  \n",
-      "2020-10-14 18:52:32,975\tERROR worker.py:1018 -- Possible unhandled error from worker: \u001b[36mray::RolloutWorker.par_iter_next_batch()\u001b[39m (pid=25093, ip=172.17.0.4)\n",
-      "  File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
-      "  File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 1158, in par_iter_next_batch\n",
-      "    batch.append(self.par_iter_next())\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 1152, in par_iter_next\n",
-      "    return next(self.local_it)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 288, in gen_rollouts\n",
-      "    yield self.sample()\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 579, in sample\n",
-      "    batches = [self.input_reader.next()]\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 93, in next\n",
-      "    batches = [self.get_data()]\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 209, in get_data\n",
-      "    item = next(self.rollout_provider)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 585, in _env_runner\n",
-      "    active_envs, to_eval, outputs = _process_observations(\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 797, in _process_observations\n",
-      "    prep_obs: EnvObsType = _get_or_raise(preprocessors,\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/models/preprocessors.py\", line 233, in transform\n",
-      "    self.check_shape(observation)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/models/preprocessors.py\", line 61, in check_shape\n",
-      "    raise ValueError(\n",
-      "ValueError: ('Observation outside expected value range', Dict(action_mask:Box(0.0, 1.0, (51,), float32), real_obs:Box(0.0, 1.0, (350,), float64)), {'real_obs': array([0.00000000e+00, 0.00000000e+00, 4.00000000e-01, 2.46153846e-01,\n",
-      "       6.26262626e-01, 5.02564103e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 6.00000000e-01, 4.77948718e-01, 4.44444444e-01,\n",
-      "       8.88205128e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       6.66666667e-01, 6.85128205e-01, 3.73737374e-01, 8.00000000e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.33333333e-01,\n",
-      "       5.07692308e-01, 3.43434343e-01, 9.21025641e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 7.27272727e-01, 6.00000000e-01, 4.10256410e-01,\n",
-      "       1.21212121e-01, 7.73333333e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       1.91919192e-01, 7.33333333e-01, 3.82564103e-01, 2.22222222e-01,\n",
-      "       3.95897436e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       7.33333333e-01, 5.54871795e-01, 1.31313131e-01, 9.23076923e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 2.72727273e-01, 8.00000000e-01,\n",
-      "       6.23589744e-01, 3.23232323e-01, 6.56410256e-04, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 4.66666667e-01, 2.94358974e-01,\n",
-      "       2.02020202e-01, 2.35897436e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 9.33333333e-01, 7.12820513e-01, 4.34343434e-01,\n",
-      "       2.25641026e-04, 0.00000000e+00, 0.00000000e+00, 1.31313131e-01,\n",
-      "       4.00000000e-01, 2.28717949e-01, 7.57575758e-01, 5.10769231e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.00000000e-01,\n",
-      "       4.41025641e-01, 4.54545455e-01, 1.76410256e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 3.23232323e-01, 6.00000000e-01, 6.53333333e-01,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 4.00000000e-01, 1.98974359e-01, 2.02020202e-02,\n",
-      "       3.54871795e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       4.66666667e-01, 3.25128205e-01, 1.91919192e-01, 3.85641026e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.33333333e-01,\n",
-      "       4.20512821e-01, 3.23232323e-01, 2.42051282e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 8.78787879e-01, 6.00000000e-01, 5.18974359e-01,\n",
-      "       7.07070707e-02, 1.12820513e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 8.00000000e-01, 6.83076923e-01, 2.72727273e-01,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       4.66666667e-01, 2.92307692e-01, 2.92929293e-01, 2.56410256e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 8.00000000e-01,\n",
-      "       5.85641026e-01, 2.32323232e-01, 2.44102564e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 7.33333333e-01, 6.56410256e-01,\n",
-      "       4.24242424e-01, 3.22051282e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 6.00000000e-01, 4.48205128e-01, 8.68686869e-01,\n",
-      "       1.76410256e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       6.00000000e-01, 5.00512821e-01, 4.94949495e-01, 4.51282051e-03,\n",
-      "       0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 4.00000000e-01,\n",
-      "       3.61025641e-01, 8.08080808e-02, 6.17435897e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 6.66666667e-01, 5.02564103e-01,\n",
-      "       8.08080808e-01, 1.94871795e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 3.33333333e-01, 3.64102564e-01, 1.21212121e-01,\n",
-      "       7.97948718e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       1.33333333e-01, 9.74358974e-02, 3.03030303e-01, 8.41025641e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.33333333e-01,\n",
-      "       5.41538462e-01, 4.04040404e-01, 3.24102564e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 1.11111111e-01, 4.66666667e-01, 3.84615385e-01,\n",
-      "       8.18181818e-01, 1.66153846e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
-      "       2.17435897e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       1.00000000e+00, 7.37435897e-01, 1.00000000e+00, 1.14256410e-02,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 8.66666667e-01,\n",
-      "       8.32820513e-01, 3.43434343e-01, 6.56410256e-04, 0.00000000e+00,\n",
-      "       0.00000000e+00, 4.04040404e-02, 4.66666667e-01, 4.81025641e-01,\n",
-      "       5.35353535e-01, 1.08717949e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 3.33333333e-01, 1.91794872e-01, 2.02020202e-02,\n",
-      "       4.10256410e-05, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       5.33333333e-01, 3.89743590e-01, 5.85858586e-01, 1.49743590e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 7.33333333e-01,\n",
-      "       6.70769231e-01, 2.92929293e-01, 3.28205128e-04, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 9.33333333e-01, 7.14871795e-01,\n",
-      "       6.66666667e-01, 5.10769231e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       2.02020202e-02, 4.66666667e-01, 4.77948718e-01, 6.66666667e-01,\n",
-      "       4.18461538e-03, 0.00000000e+00, 0.00000000e+00, 2.52525253e-01,\n",
-      "       5.33333333e-01, 5.51794872e-01, 3.83838384e-01, 1.70256410e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.66666667e-01,\n",
-      "       3.20000000e-01, 7.27272727e-01, 1.23076923e-02, 0.00000000e+00,\n",
-      "       0.00000000e+00, 3.43434343e-01, 6.66666667e-01, 5.40512821e-01,\n",
-      "       2.72727273e-01, 3.01538462e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 6.66666667e-01, 5.33333333e-01, 4.94949495e-01,\n",
-      "       7.79487179e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       6.66666667e-01, 4.68717949e-01, 7.57575758e-01, 3.50769231e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 9.33333333e-01,\n",
-      "       8.01025641e-01, 1.41414141e-01, 1.08717949e-03, 0.00000000e+00,\n",
-      "       1.00000000e+00, 0.00000000e+00, 8.66666667e-01, 7.94871795e-01,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 4.66666667e-01, 3.54871795e-01, 5.05050505e-02,\n",
-      "       9.02564103e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       7.33333333e-01, 6.22564103e-01, 4.54545455e-01, 8.82051282e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.33333333e-01,\n",
-      "       5.47692308e-01, 4.04040404e-01, 3.07692308e-04, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 6.66666667e-01, 5.30256410e-01,\n",
-      "       7.07070707e-01, 2.64615385e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 4.66666667e-01, 2.77948718e-01, 3.93939394e-01,\n",
-      "       1.64102564e-03, 0.00000000e+00]), 'action_mask': array([False, False, False, False, False, False, False, False, False,\n",
-      "       False, False, False, False, False, False, False, False, False,\n",
-      "       False, False, False, False, False,  True, False, False, False,\n",
-      "       False, False, False, False, False, False, False, False, False,\n",
-      "       False, False, False, False, False, False, False, False,  True,\n",
-      "       False, False, False, False, False, False])})\n",
-      "== Status ==\n",
-      "Memory usage on this node: 22.0/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 0/3 GPUs, 0.0/557.13 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name                       | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
-      "| RandomMasked_jss_env_5afa5_00000 | RUNNING  | 172.17.0.4:25130 |    145 |           26.762 | 58000 |      nan |                  nan |                  nan |                nan |\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for RandomMasked_jss_env_5afa5_00000:\n",
-      "  custom_metrics: {}\n",
-      "  date: 2020-10-14_18-52-37\n",
-      "  done: false\n",
-      "  episode_len_mean: .nan\n",
-      "  episode_reward_max: .nan\n",
-      "  episode_reward_mean: .nan\n",
-      "  episode_reward_min: .nan\n",
-      "  episodes_this_iter: 0\n",
-      "  episodes_total: 0\n",
-      "  experiment_id: 1d2b23a635304ca6bea1e0ffde98d7ee\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    num_steps_sampled: 58800\n",
-      "  iterations_since_restore: 147\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf: {}\n",
-      "  pid: 25130\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf: {}\n",
-      "  time_since_restore: 27.082104921340942\n",
-      "  time_this_iter_s: 0.1581122875213623\n",
-      "  time_total_s: 27.082104921340942\n",
-      "  timers: {}\n",
-      "  timestamp: 1602701557\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 58800\n",
-      "  training_iteration: 147\n",
-      "  trial_id: 5afa5_00000\n",
-      "  \n",
-      "2020-10-14 18:52:41,582\tERROR trial_runner.py:567 -- Trial RandomMasked_jss_env_5afa5_00000: Error processing event.\n",
-      "Traceback (most recent call last):\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/trial_runner.py\", line 515, in _process_trial\n",
-      "    result = self.trial_executor.fetch_result(trial)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/ray_trial_executor.py\", line 488, in fetch_result\n",
-      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1428, in get\n",
-      "    raise value.as_instanceof_cause()\n",
-      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::RandomMasked.train()\u001b[39m (pid=25130, ip=172.17.0.4)\n",
-      "  File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
-      "  File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\", line 516, in train\n",
-      "    raise e\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\", line 505, in train\n",
-      "    result = Trainable.train(self)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/trainable.py\", line 336, in train\n",
-      "    result = self.step()\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer_template.py\", line 134, in step\n",
-      "    res = next(self.train_exec_impl)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 756, in __next__\n",
-      "    return next(self.built_iterator)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
-      "    for item in it:\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 843, in apply_filter\n",
-      "    for item in it:\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 843, in apply_filter\n",
-      "    for item in it:\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
-      "    for item in it:\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
-      "    for item in it:\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 551, in base_iterator\n",
-      "    batch = ray.get(obj_ref)\n",
-      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::RolloutWorker.par_iter_next_batch()\u001b[39m (pid=25093, ip=172.17.0.4)\n",
-      "  File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
-      "  File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 1158, in par_iter_next_batch\n",
-      "    batch.append(self.par_iter_next())\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 1152, in par_iter_next\n",
-      "    return next(self.local_it)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 288, in gen_rollouts\n",
-      "    yield self.sample()\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 579, in sample\n",
-      "    batches = [self.input_reader.next()]\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 93, in next\n",
-      "    batches = [self.get_data()]\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 209, in get_data\n",
-      "    item = next(self.rollout_provider)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 585, in _env_runner\n",
-      "    active_envs, to_eval, outputs = _process_observations(\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 797, in _process_observations\n",
-      "    prep_obs: EnvObsType = _get_or_raise(preprocessors,\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/models/preprocessors.py\", line 233, in transform\n",
-      "    self.check_shape(observation)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/models/preprocessors.py\", line 61, in check_shape\n",
-      "    raise ValueError(\n",
-      "ValueError: ('Observation outside expected value range', Dict(action_mask:Box(0.0, 1.0, (51,), float32), real_obs:Box(0.0, 1.0, (350,), float64)), {'real_obs': array([0.00000000e+00, 0.00000000e+00, 4.00000000e-01, 2.46153846e-01,\n",
-      "       6.26262626e-01, 5.02564103e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 6.00000000e-01, 4.77948718e-01, 4.44444444e-01,\n",
-      "       8.88205128e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       6.66666667e-01, 6.85128205e-01, 3.73737374e-01, 8.00000000e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.33333333e-01,\n",
-      "       5.07692308e-01, 3.43434343e-01, 9.21025641e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 7.27272727e-01, 6.00000000e-01, 4.10256410e-01,\n",
-      "       1.21212121e-01, 7.73333333e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       1.91919192e-01, 7.33333333e-01, 3.82564103e-01, 2.22222222e-01,\n",
-      "       3.95897436e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       7.33333333e-01, 5.54871795e-01, 1.31313131e-01, 9.23076923e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 2.72727273e-01, 8.00000000e-01,\n",
-      "       6.23589744e-01, 3.23232323e-01, 6.56410256e-04, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 4.66666667e-01, 2.94358974e-01,\n",
-      "       2.02020202e-01, 2.35897436e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 9.33333333e-01, 7.12820513e-01, 4.34343434e-01,\n",
-      "       2.25641026e-04, 0.00000000e+00, 0.00000000e+00, 1.31313131e-01,\n",
-      "       4.00000000e-01, 2.28717949e-01, 7.57575758e-01, 5.10769231e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.00000000e-01,\n",
-      "       4.41025641e-01, 4.54545455e-01, 1.76410256e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 3.23232323e-01, 6.00000000e-01, 6.53333333e-01,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 4.00000000e-01, 1.98974359e-01, 2.02020202e-02,\n",
-      "       3.54871795e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       4.66666667e-01, 3.25128205e-01, 1.91919192e-01, 3.85641026e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.33333333e-01,\n",
-      "       4.20512821e-01, 3.23232323e-01, 2.42051282e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 8.78787879e-01, 6.00000000e-01, 5.18974359e-01,\n",
-      "       7.07070707e-02, 1.12820513e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 8.00000000e-01, 6.83076923e-01, 2.72727273e-01,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       4.66666667e-01, 2.92307692e-01, 2.92929293e-01, 2.56410256e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 8.00000000e-01,\n",
-      "       5.85641026e-01, 2.32323232e-01, 2.44102564e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 7.33333333e-01, 6.56410256e-01,\n",
-      "       4.24242424e-01, 3.22051282e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 6.00000000e-01, 4.48205128e-01, 8.68686869e-01,\n",
-      "       1.76410256e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       6.00000000e-01, 5.00512821e-01, 4.94949495e-01, 4.51282051e-03,\n",
-      "       0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 4.00000000e-01,\n",
-      "       3.61025641e-01, 8.08080808e-02, 6.17435897e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 6.66666667e-01, 5.02564103e-01,\n",
-      "       8.08080808e-01, 1.94871795e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 3.33333333e-01, 3.64102564e-01, 1.21212121e-01,\n",
-      "       7.97948718e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       1.33333333e-01, 9.74358974e-02, 3.03030303e-01, 8.41025641e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.33333333e-01,\n",
-      "       5.41538462e-01, 4.04040404e-01, 3.24102564e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 1.11111111e-01, 4.66666667e-01, 3.84615385e-01,\n",
-      "       8.18181818e-01, 1.66153846e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
-      "       2.17435897e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       1.00000000e+00, 7.37435897e-01, 1.00000000e+00, 1.14256410e-02,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 8.66666667e-01,\n",
-      "       8.32820513e-01, 3.43434343e-01, 6.56410256e-04, 0.00000000e+00,\n",
-      "       0.00000000e+00, 4.04040404e-02, 4.66666667e-01, 4.81025641e-01,\n",
-      "       5.35353535e-01, 1.08717949e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 3.33333333e-01, 1.91794872e-01, 2.02020202e-02,\n",
-      "       4.10256410e-05, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       5.33333333e-01, 3.89743590e-01, 5.85858586e-01, 1.49743590e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 7.33333333e-01,\n",
-      "       6.70769231e-01, 2.92929293e-01, 3.28205128e-04, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 9.33333333e-01, 7.14871795e-01,\n",
-      "       6.66666667e-01, 5.10769231e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       2.02020202e-02, 4.66666667e-01, 4.77948718e-01, 6.66666667e-01,\n",
-      "       4.18461538e-03, 0.00000000e+00, 0.00000000e+00, 2.52525253e-01,\n",
-      "       5.33333333e-01, 5.51794872e-01, 3.83838384e-01, 1.70256410e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.66666667e-01,\n",
-      "       3.20000000e-01, 7.27272727e-01, 1.23076923e-02, 0.00000000e+00,\n",
-      "       0.00000000e+00, 3.43434343e-01, 6.66666667e-01, 5.40512821e-01,\n",
-      "       2.72727273e-01, 3.01538462e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 6.66666667e-01, 5.33333333e-01, 4.94949495e-01,\n",
-      "       7.79487179e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       6.66666667e-01, 4.68717949e-01, 7.57575758e-01, 3.50769231e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 9.33333333e-01,\n",
-      "       8.01025641e-01, 1.41414141e-01, 1.08717949e-03, 0.00000000e+00,\n",
-      "       1.00000000e+00, 0.00000000e+00, 8.66666667e-01, 7.94871795e-01,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 4.66666667e-01, 3.54871795e-01, 5.05050505e-02,\n",
-      "       9.02564103e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       7.33333333e-01, 6.22564103e-01, 4.54545455e-01, 8.82051282e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.33333333e-01,\n",
-      "       5.47692308e-01, 4.04040404e-01, 3.07692308e-04, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 6.66666667e-01, 5.30256410e-01,\n",
-      "       7.07070707e-01, 2.64615385e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 4.66666667e-01, 2.77948718e-01, 3.93939394e-01,\n",
-      "       1.64102564e-03, 0.00000000e+00]), 'action_mask': array([False, False, False, False, False, False, False, False, False,\n",
-      "       False, False, False, False, False, False, False, False, False,\n",
-      "       False, False, False, False, False,  True, False, False, False,\n",
-      "       False, False, False, False, False, False, False, False, False,\n",
-      "       False, False, False, False, False, False, False, False,  True,\n",
-      "       False, False, False, False, False, False])})\n",
-      "== Status ==\n",
-      "Memory usage on this node: 22.0/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.13 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 ERROR)\n",
-      "+----------------------------------+----------+-------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name                       | status   | loc   |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|----------------------------------+----------+-------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
-      "| RandomMasked_jss_env_5afa5_00000 | ERROR    |       |    172 |          31.1614 | 68800 |      nan |                  nan |                  nan |                nan |\n",
-      "+----------------------------------+----------+-------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "Number of errored trials: 1\n",
-      "+----------------------------------+--------------+--------------------------------------------------------------------------------------------+\n",
-      "| Trial name                       |   # failures | error file                                                                                 |\n",
-      "|----------------------------------+--------------+--------------------------------------------------------------------------------------------|\n",
-      "| RandomMasked_jss_env_5afa5_00000 |            1 | /root/ray_results/ppo-jss/RandomMasked_jss_env_5afa5_00000_0_2020-10-14_18-52-06/error.txt |\n",
-      "+----------------------------------+--------------+--------------------------------------------------------------------------------------------+\n",
-      "\n",
-      "Traceback (most recent call last):\n",
-      "  File \"random_loop.py\", line 73, in <module>\n",
-      "    rand_func()\n",
-      "  File \"random_loop.py\", line 55, in rand_func\n",
-      "    analysis = tune.run(RandomMaskedTrainer, config=config, stop=stop, name=\"ppo-jss\")\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/tune.py\", line 427, in run\n",
-      "    raise TuneError(\"Trials did not complete\", incomplete_trials)\n",
-      "ray.tune.error.TuneError: ('Trials did not complete', [RandomMasked_jss_env_5afa5_00000])\n",
-      "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 24896\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 1.  Press ctrl-c to abort syncing.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 32790\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201014_185201-bgm3l5ts/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201014_185201-bgm3l5ts/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201104_212741-h3u61381/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201104_212741-h3u61381/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_timestep 1775.0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step 0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime 601\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp 1604525862\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_timestep ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp ‚ñÅ\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33meffortless-sweep-1\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/bgm3l5ts\u001b[0m\n",
-      "2020-10-14 18:52:51,177 - wandb.wandb_agent - INFO - Cleaning up finished run: bgm3l5ts\n",
-      "2020-10-14 18:52:51,692 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-14 18:52:51,693 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tinstance_path: /JSS/JSS/env/instances/ta52\n",
-      "2020-10-14 18:52:51,700 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python random_loop.py --instance_path=/JSS/JSS/env/instances/ta52\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mCP\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/h3u61381\u001b[0m\n",
+      "2020-11-04 21:37:51,376 - wandb.wandb_agent - INFO - Cleaning up finished run: h3u61381\n",
+      "2020-11-04 21:37:51,696 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-11-04 21:37:51,696 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tinstance_path: /JSS/JSS/env/instances/ta41\n",
+      "2020-11-04 21:37:51,698 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python CP.py --instance_path=/JSS/JSS/env/instances/ta41\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.8 is available!  To upgrade, please run:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msuper-sweep-2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/lh9x5rb9\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/ezglujb0\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201014_185253-ezglujb0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mCP\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/sweeps/wnc8ihq1\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/c18o79jq\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201104_213752-c18o79jq\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
-      "2020-10-14 18:52:56,719 - wandb.wandb_agent - INFO - Running runs: ['ezglujb0']\n",
-      "2020-10-14 18:52:57,270\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
-      "== Status ==\n",
-      "Memory usage on this node: 11.7/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 0/3 GPUs, 0.0/557.08 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+----------------------------------+----------+-------+\n",
-      "| Trial name                       | status   | loc   |\n",
-      "|----------------------------------+----------+-------|\n",
-      "| RandomMasked_jss_env_7a318_00000 | RUNNING  |       |\n",
-      "+----------------------------------+----------+-------+\n",
-      "\n",
-      "\n",
-      "\u001b[2m\u001b[36m(pid=26894)\u001b[0m 2020-10-14 18:53:00,066\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "Result for RandomMasked_jss_env_7a318_00000:\n",
-      "  custom_metrics: {}\n",
-      "  date: 2020-10-14_18-53-03\n",
-      "  done: false\n",
-      "  episode_len_mean: .nan\n",
-      "  episode_reward_max: .nan\n",
-      "  episode_reward_mean: .nan\n",
-      "  episode_reward_min: .nan\n",
-      "  episodes_this_iter: 0\n",
-      "  episodes_total: 0\n",
-      "  experiment_id: a0d7abda875641ee8277cfe989ce99c0\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    num_steps_sampled: 400\n",
-      "  iterations_since_restore: 1\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 71.17999999999999\n",
-      "    gpu_util_percent0: 0.0\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 2.3600000000000003\n",
-      "    vram_util_percent0: 0.0\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 26894\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf: {}\n",
-      "  time_since_restore: 3.277367115020752\n",
-      "  time_this_iter_s: 3.277367115020752\n",
-      "  time_total_s: 3.277367115020752\n",
-      "  timers: {}\n",
-      "  timestamp: 1602701583\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 400\n",
-      "  training_iteration: 1\n",
-      "  trial_id: 7a318_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 21.8/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 0/3 GPUs, 0.0/557.08 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+----------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name                       | status   | loc              |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|----------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|\n",
-      "| RandomMasked_jss_env_7a318_00000 | RUNNING  | 172.17.0.4:26894 |      1 |          3.27737 |  400 |      nan |                  nan |                  nan |                nan |\n",
-      "+----------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for RandomMasked_jss_env_7a318_00000:\n",
-      "  custom_metrics: {}\n",
-      "  date: 2020-10-14_18-53-08\n",
-      "  done: false\n",
-      "  episode_len_mean: .nan\n",
-      "  episode_reward_max: .nan\n",
-      "  episode_reward_mean: .nan\n",
-      "  episode_reward_min: .nan\n",
-      "  episodes_this_iter: 0\n",
-      "  episodes_total: 0\n",
-      "  experiment_id: a0d7abda875641ee8277cfe989ce99c0\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    num_steps_sampled: 11600\n",
-      "  iterations_since_restore: 29\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 5.1\n",
-      "    gpu_util_percent0: 0.0\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 2.9\n",
-      "    vram_util_percent0: 0.0\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 26894\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf: {}\n",
-      "  time_since_restore: 7.904330253601074\n",
-      "  time_this_iter_s: 0.16050171852111816\n",
-      "  time_total_s: 7.904330253601074\n",
-      "  timers: {}\n",
-      "  timestamp: 1602701588\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 11600\n",
-      "  training_iteration: 29\n",
-      "  trial_id: 7a318_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 21.9/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 0/3 GPUs, 0.0/557.08 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name                       | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
-      "| RandomMasked_jss_env_7a318_00000 | RUNNING  | 172.17.0.4:26894 |     29 |          7.90433 | 11600 |      nan |                  nan |                  nan |                nan |\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
+      "2020-11-04 21:37:56,716 - wandb.wandb_agent - INFO - Running runs: ['c18o79jq']\n",
       "\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 33712\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201104_213752-c18o79jq/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201104_213752-c18o79jq/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_timestep 2137.0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step 0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime 601\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp 1604526473\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_timestep ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mCP\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/c18o79jq\u001b[0m\n",
+      "2020-11-04 21:48:02,339 - wandb.wandb_agent - INFO - Cleaning up finished run: c18o79jq\n",
+      "2020-11-04 21:48:02,711 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-11-04 21:48:02,712 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tinstance_path: /JSS/JSS/env/instances/ta42\n",
+      "2020-11-04 21:48:02,713 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python CP.py --instance_path=/JSS/JSS/env/instances/ta42\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.8 is available!  To upgrade, please run:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mCP\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/sweeps/wnc8ihq1\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/sb79yg44\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201104_214803-sb79yg44\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
-      "Result for RandomMasked_jss_env_7a318_00000:\n",
-      "  custom_metrics: {}\n",
-      "  date: 2020-10-14_18-53-13\n",
-      "  done: false\n",
-      "  episode_len_mean: .nan\n",
-      "  episode_reward_max: .nan\n",
-      "  episode_reward_mean: .nan\n",
-      "  episode_reward_min: .nan\n",
-      "  episodes_this_iter: 0\n",
-      "  episodes_total: 0\n",
-      "  experiment_id: a0d7abda875641ee8277cfe989ce99c0\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    num_steps_sampled: 22400\n",
-      "  iterations_since_restore: 56\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf: {}\n",
-      "  pid: 26894\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf: {}\n",
-      "  time_since_restore: 12.449386596679688\n",
-      "  time_this_iter_s: 0.16517019271850586\n",
-      "  time_total_s: 12.449386596679688\n",
-      "  timers: {}\n",
-      "  timestamp: 1602701593\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 22400\n",
-      "  training_iteration: 56\n",
-      "  trial_id: 7a318_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 22.0/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 0/3 GPUs, 0.0/557.08 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name                       | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
-      "| RandomMasked_jss_env_7a318_00000 | RUNNING  | 172.17.0.4:26894 |     56 |          12.4494 | 22400 |      nan |                  nan |                  nan |                nan |\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for RandomMasked_jss_env_7a318_00000:\n",
-      "  custom_metrics: {}\n",
-      "  date: 2020-10-14_18-53-18\n",
-      "  done: false\n",
-      "  episode_len_mean: .nan\n",
-      "  episode_reward_max: .nan\n",
-      "  episode_reward_mean: .nan\n",
-      "  episode_reward_min: .nan\n",
-      "  episodes_this_iter: 0\n",
-      "  episodes_total: 0\n",
-      "  experiment_id: a0d7abda875641ee8277cfe989ce99c0\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    num_steps_sampled: 33600\n",
-      "  iterations_since_restore: 84\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf: {}\n",
-      "  pid: 26894\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf: {}\n",
-      "  time_since_restore: 17.05783486366272\n",
-      "  time_this_iter_s: 0.1567375659942627\n",
-      "  time_total_s: 17.05783486366272\n",
-      "  timers: {}\n",
-      "  timestamp: 1602701598\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 33600\n",
-      "  training_iteration: 84\n",
-      "  trial_id: 7a318_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 22.0/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 0/3 GPUs, 0.0/557.08 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name                       | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
-      "| RandomMasked_jss_env_7a318_00000 | RUNNING  | 172.17.0.4:26894 |     84 |          17.0578 | 33600 |      nan |                  nan |                  nan |                nan |\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for RandomMasked_jss_env_7a318_00000:\n",
-      "  custom_metrics: {}\n",
-      "  date: 2020-10-14_18-53-24\n",
-      "  done: false\n",
-      "  episode_len_mean: .nan\n",
-      "  episode_reward_max: .nan\n",
-      "  episode_reward_mean: .nan\n",
-      "  episode_reward_min: .nan\n",
-      "  episodes_this_iter: 0\n",
-      "  episodes_total: 0\n",
-      "  experiment_id: a0d7abda875641ee8277cfe989ce99c0\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    num_steps_sampled: 45200\n",
-      "  iterations_since_restore: 113\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 4.5\n",
-      "    gpu_util_percent0: 0.0\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 2.9\n",
-      "    vram_util_percent0: 0.0\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 26894\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf: {}\n",
-      "  time_since_restore: 21.754982709884644\n",
-      "  time_this_iter_s: 0.16276907920837402\n",
-      "  time_total_s: 21.754982709884644\n",
-      "  timers: {}\n",
-      "  timestamp: 1602701604\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 45200\n",
-      "  training_iteration: 113\n",
-      "  trial_id: 7a318_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 22.0/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 0/3 GPUs, 0.0/557.08 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name                       | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
-      "| RandomMasked_jss_env_7a318_00000 | RUNNING  | 172.17.0.4:26894 |    113 |           21.755 | 45200 |      nan |                  nan |                  nan |                nan |\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "2020-10-14 18:53:25,585\tERROR worker.py:1018 -- Possible unhandled error from worker: \u001b[36mray::RolloutWorker.par_iter_next_batch()\u001b[39m (pid=26854, ip=172.17.0.4)\n",
-      "  File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
-      "  File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 1158, in par_iter_next_batch\n",
-      "    batch.append(self.par_iter_next())\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 1152, in par_iter_next\n",
-      "    return next(self.local_it)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 288, in gen_rollouts\n",
-      "    yield self.sample()\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 579, in sample\n",
-      "    batches = [self.input_reader.next()]\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 93, in next\n",
-      "    batches = [self.get_data()]\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 209, in get_data\n",
-      "    item = next(self.rollout_provider)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 585, in _env_runner\n",
-      "    active_envs, to_eval, outputs = _process_observations(\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 797, in _process_observations\n",
-      "    prep_obs: EnvObsType = _get_or_raise(preprocessors,\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/models/preprocessors.py\", line 233, in transform\n",
-      "    self.check_shape(observation)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/models/preprocessors.py\", line 61, in check_shape\n",
-      "    raise ValueError(\n",
-      "ValueError: ('Observation outside expected value range', Dict(action_mask:Box(0.0, 1.0, (51,), float32), real_obs:Box(0.0, 1.0, (350,), float64)), {'real_obs': array([0.00000000e+00, 0.00000000e+00, 5.33333333e-01, 3.67179487e-01,\n",
-      "       5.05050505e-01, 6.72820513e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       7.07070707e-02, 4.00000000e-01, 3.89743590e-01, 7.47474747e-01,\n",
-      "       1.20205128e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       7.33333333e-01, 7.47692308e-01, 3.43434343e-01, 5.82564103e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 5.15151515e-01, 5.33333333e-01,\n",
-      "       5.48717949e-01, 6.76767677e-01, 1.37435897e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 7.33333333e-01, 5.56923077e-01,\n",
-      "       1.51515152e-01, 1.12820513e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 6.66666667e-01, 2.81025641e-01, 2.42424242e-01,\n",
-      "       1.47692308e-03, 0.00000000e+00, 0.00000000e+00, 7.07070707e-02,\n",
-      "       6.66666667e-01, 5.47692308e-01, 0.00000000e+00, 6.66666667e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.66666667e-01,\n",
-      "       1.79487179e-01, 7.17171717e-01, 1.95076923e-02, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 6.00000000e-01, 3.72307692e-01,\n",
-      "       1.71717172e-01, 1.12205128e-02, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 9.33333333e-01, 7.12820513e-01, 4.04040404e-02,\n",
-      "       2.58461538e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       6.00000000e-01, 3.48717949e-01, 4.34343434e-01, 1.14256410e-02,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.66666667e-01,\n",
-      "       4.75897436e-01, 1.01010101e-01, 5.90769231e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 8.66666667e-01, 7.82564103e-01,\n",
-      "       6.86868687e-01, 1.25128205e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       6.06060606e-02, 6.66666667e-01, 5.57948718e-01, 2.62626263e-01,\n",
-      "       5.33333333e-04, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
-      "       6.00000000e-01, 4.02051282e-01, 9.69696970e-01, 5.53846154e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.66666667e-01,\n",
-      "       5.22051282e-01, 1.51515152e-01, 1.84615385e-04, 0.00000000e+00,\n",
-      "       0.00000000e+00, 8.08080808e-02, 8.00000000e-01, 7.04615385e-01,\n",
-      "       5.65656566e-01, 1.14871795e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 9.33333333e-01, 7.01538462e-01, 6.66666667e-01,\n",
-      "       6.25641026e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       4.66666667e-01, 2.92307692e-01, 6.36363636e-01, 1.12410256e-02,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 7.33333333e-01,\n",
-      "       5.40512821e-01, 1.51515152e-01, 1.43589744e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 7.33333333e-01, 6.56410256e-01,\n",
-      "       3.33333333e-01, 5.57948718e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       6.86868687e-01, 7.33333333e-01, 5.47692308e-01, 8.58585859e-01,\n",
-      "       1.74358974e-03, 0.00000000e+00, 0.00000000e+00, 2.02020202e-01,\n",
-      "       5.33333333e-01, 4.80000000e-01, 3.63636364e-01, 7.38461538e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.66666667e-01,\n",
-      "       4.86153846e-01, 3.83838384e-01, 6.35897436e-04, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 4.66666667e-01, 4.00000000e-01,\n",
-      "       6.26262626e-01, 3.69230769e-04, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 1.00000000e+00, 8.72820513e-01, 1.00000000e+00,\n",
-      "       8.20512821e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       5.33333333e-01, 4.98461538e-01, 6.76767677e-01, 2.07179487e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 1.51515152e-01, 4.00000000e-01,\n",
-      "       4.74871795e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 3.13131313e-01, 8.00000000e-01, 6.59487179e-01,\n",
-      "       8.58585859e-01, 1.74358974e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
-      "       3.07692308e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       2.66666667e-01, 1.58974359e-01, 3.03030303e-02, 5.21025641e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.00000000e-01,\n",
-      "       3.84615385e-01, 5.65656566e-01, 1.25538462e-02, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 7.68205128e-01,\n",
-      "       1.00000000e+00, 3.36410256e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 1.00000000e+00, 6.26666667e-01, 1.00000000e+00,\n",
-      "       1.24923077e-02, 0.00000000e+00, 0.00000000e+00, 6.06060606e-02,\n",
-      "       5.33333333e-01, 4.31794872e-01, 4.54545455e-01, 9.23076923e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
-      "       9.70256410e-01, 1.00000000e+00, 9.84615385e-04, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 4.66666667e-01, 3.58974359e-01,\n",
-      "       1.01010101e-02, 8.41025641e-04, 0.00000000e+00, 0.00000000e+00,\n",
-      "       4.44444444e-01, 9.33333333e-01, 8.36923077e-01, 4.04040404e-02,\n",
-      "       1.15487179e-02, 0.00000000e+00, 0.00000000e+00, 6.96969697e-01,\n",
-      "       6.00000000e-01, 5.84615385e-01, 2.92929293e-01, 1.07282051e-02,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 7.33333333e-01,\n",
-      "       4.65641026e-01, 0.00000000e+00, 3.38461538e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 9.33333333e-01, 7.02564103e-01,\n",
-      "       7.07070707e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 8.66666667e-01, 6.17435897e-01, 1.51515152e-01,\n",
-      "       3.38461538e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       6.00000000e-01, 3.81538462e-01, 2.02020202e-02, 4.59487179e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 3.13131313e-01, 5.33333333e-01,\n",
-      "       5.09743590e-01, 1.71717172e-01, 2.93333333e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 8.66666667e-01, 7.94871795e-01,\n",
-      "       4.94949495e-01, 6.97435897e-04, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 6.00000000e-01, 4.62564103e-01, 3.23232323e-01,\n",
-      "       1.43589744e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       9.33333333e-01, 7.80512821e-01, 2.62626263e-01, 3.69230769e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 2.52525253e-01, 9.33333333e-01,\n",
-      "       8.87179487e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 6.00000000e-01, 5.10769231e-01,\n",
-      "       6.26262626e-01, 6.40000000e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 8.00000000e-01, 5.94871795e-01, 1.11111111e-01,\n",
-      "       2.21538462e-03, 0.00000000e+00]), 'action_mask': array([False, False, False, False, False, False, False, False, False,\n",
-      "       False, False, False, False, False,  True, False, False, False,\n",
-      "       False, False, False, False, False, False, False, False, False,\n",
-      "       False, False, False, False, False, False, False, False, False,\n",
-      "       False, False, False, False, False, False, False, False, False,\n",
-      "       False, False, False, False, False,  True])})\n",
-      "2020-10-14 18:53:27,586\tERROR worker.py:1018 -- Possible unhandled error from worker: \u001b[36mray::RolloutWorker.par_iter_next_batch()\u001b[39m (pid=26840, ip=172.17.0.4)\n",
-      "  File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
-      "  File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 1158, in par_iter_next_batch\n",
-      "    batch.append(self.par_iter_next())\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 1152, in par_iter_next\n",
-      "    return next(self.local_it)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 288, in gen_rollouts\n",
-      "    yield self.sample()\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 579, in sample\n",
-      "    batches = [self.input_reader.next()]\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 93, in next\n",
-      "    batches = [self.get_data()]\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 209, in get_data\n",
-      "    item = next(self.rollout_provider)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 585, in _env_runner\n",
-      "    active_envs, to_eval, outputs = _process_observations(\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 797, in _process_observations\n",
-      "    prep_obs: EnvObsType = _get_or_raise(preprocessors,\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/models/preprocessors.py\", line 233, in transform\n",
-      "    self.check_shape(observation)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/models/preprocessors.py\", line 61, in check_shape\n",
-      "    raise ValueError(\n",
-      "ValueError: ('Observation outside expected value range', Dict(action_mask:Box(0.0, 1.0, (51,), float32), real_obs:Box(0.0, 1.0, (350,), float64)), {'real_obs': array([0.00000000e+00, 0.00000000e+00, 6.00000000e-01, 3.80512821e-01,\n",
-      "       2.12121212e-01, 3.26153846e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 4.66666667e-01, 3.96923077e-01, 6.56565657e-01,\n",
-      "       1.82564103e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       6.00000000e-01, 6.07179487e-01, 4.84848485e-01, 1.02564103e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 5.35353535e-01, 4.66666667e-01,\n",
-      "       4.53333333e-01, 1.71717172e-01, 3.48717949e-04, 0.00000000e+00,\n",
-      "       0.00000000e+00, 4.44444444e-01, 8.00000000e-01, 6.14358974e-01,\n",
-      "       4.34343434e-01, 8.82051282e-04, 0.00000000e+00, 0.00000000e+00,\n",
-      "       2.02020202e-01, 6.66666667e-01, 3.46666667e-01, 2.72727273e-01,\n",
-      "       1.90769231e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       4.00000000e-01, 3.28205128e-01, 5.35353535e-01, 6.35897436e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 8.08080808e-02, 5.33333333e-01,\n",
-      "       3.95897436e-01, 1.41414141e-01, 2.87179487e-04, 0.00000000e+00,\n",
-      "       0.00000000e+00, 6.06060606e-02, 6.00000000e-01, 3.89743590e-01,\n",
-      "       3.33333333e-01, 4.94358974e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 7.33333333e-01, 5.87692308e-01, 5.15151515e-01,\n",
-      "       1.43589744e-04, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
-      "       8.00000000e-01, 5.33333333e-01, 8.48484848e-01, 1.72307692e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.66666667e-01,\n",
-      "       4.75897436e-01, 9.09090909e-02, 6.83076923e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 6.00000000e-01, 5.92820513e-01,\n",
-      "       8.08080808e-02, 2.46153846e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       4.44444444e-01, 5.33333333e-01, 4.10256410e-01, 7.87878788e-01,\n",
-      "       4.51282051e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       7.33333333e-01, 5.43589744e-01, 1.61616162e-01, 4.82051282e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.00000000e-01,\n",
-      "       4.24615385e-01, 4.64646465e-01, 5.33333333e-04, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 6.66666667e-01, 6.08205128e-01,\n",
-      "       6.56565657e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 6.66666667e-01, 6.03076923e-01, 1.21212121e-01,\n",
-      "       9.47692308e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       2.66666667e-01, 1.62051282e-01, 4.34343434e-01, 6.76923077e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.66666667e-01,\n",
-      "       5.01538462e-01, 2.02020202e-01, 1.43589744e-02, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 8.71794872e-01,\n",
-      "       1.00000000e+00, 1.98974359e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       2.02020202e-01, 7.33333333e-01, 5.96923077e-01, 1.01010101e-01,\n",
-      "       8.41025641e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       1.00000000e+00, 7.61025641e-01, 1.00000000e+00, 1.51794872e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.00000000e-01,\n",
-      "       3.95897436e-01, 5.05050505e-02, 6.15384615e-04, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 8.00000000e-01, 5.81538462e-01,\n",
-      "       6.86868687e-01, 2.03076923e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       9.29292929e-01, 5.33333333e-01, 5.00512821e-01, 6.86868687e-01,\n",
-      "       1.82564103e-03, 0.00000000e+00, 0.00000000e+00, 4.34343434e-01,\n",
-      "       4.66666667e-01, 4.54358974e-01, 2.62626263e-01, 5.33333333e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.66666667e-01,\n",
-      "       4.90256410e-01, 7.77777778e-01, 5.29230769e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 4.14141414e-01, 8.00000000e-01, 6.49230769e-01,\n",
-      "       1.01010101e-02, 2.05128205e-05, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
-      "       3.69230769e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       4.66666667e-01, 3.24102564e-01, 3.23232323e-01, 1.16923077e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.00000000e-01,\n",
-      "       5.93846154e-01, 6.56565657e-01, 3.13846154e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 8.00000000e-01, 6.98461538e-01,\n",
-      "       1.71717172e-01, 2.64615385e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       1.31313131e-01, 8.00000000e-01, 5.05641026e-01, 4.84848485e-01,\n",
-      "       3.44615385e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       5.33333333e-01, 3.89743590e-01, 2.62626263e-01, 2.33846154e-03,\n",
-      "       0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 4.66666667e-01,\n",
-      "       3.53846154e-01, 4.04040404e-02, 8.20512821e-05, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 5.33333333e-01, 4.10256410e-01,\n",
-      "       3.33333333e-01, 8.88205128e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 8.00000000e-01, 7.21025641e-01, 6.76767677e-01,\n",
-      "       4.10256410e-05, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       4.00000000e-01, 3.36410256e-01, 4.04040404e-02, 8.10256410e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 8.66666667e-01,\n",
-      "       5.74358974e-01, 7.07070707e-02, 1.31282051e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 5.33333333e-01, 4.35897436e-01,\n",
-      "       2.82828283e-01, 2.37948718e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 6.66666667e-01, 5.33333333e-01, 7.77777778e-01,\n",
-      "       1.16923077e-03, 0.00000000e+00, 0.00000000e+00, 6.56565657e-01,\n",
-      "       4.66666667e-01, 2.40000000e-01, 1.81818182e-01, 2.29743590e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.00000000e-01,\n",
-      "       4.27692308e-01, 1.51515152e-01, 8.51282051e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 6.66666667e-01, 6.10256410e-01,\n",
-      "       1.71717172e-01, 8.20512821e-05, 0.00000000e+00, 0.00000000e+00,\n",
-      "       2.22222222e-01, 3.33333333e-01, 2.95384615e-01, 7.87878788e-01,\n",
-      "       3.54871795e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       5.33333333e-01, 5.16923077e-01, 3.63636364e-01, 7.79487179e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.00000000e-01,\n",
-      "       6.00000000e-01, 1.31313131e-01, 3.48717949e-04, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 8.66666667e-01, 6.70769231e-01,\n",
-      "       1.61616162e-01, 2.62564103e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 8.00000000e-01, 5.94871795e-01, 2.42424242e-01,\n",
-      "       3.32307692e-03, 0.00000000e+00]), 'action_mask': array([False, False, False, False, False, False, False, False, False,\n",
-      "       False,  True, False, False, False, False, False, False, False,\n",
-      "       False, False, False, False, False, False, False, False, False,\n",
-      "       False, False, False, False, False, False, False, False,  True,\n",
-      "       False, False, False, False, False, False, False, False, False,\n",
-      "       False, False, False, False, False, False])})\n",
-      "Result for RandomMasked_jss_env_7a318_00000:\n",
-      "  custom_metrics: {}\n",
-      "  date: 2020-10-14_18-53-29\n",
-      "  done: false\n",
-      "  episode_len_mean: .nan\n",
-      "  episode_reward_max: .nan\n",
-      "  episode_reward_mean: .nan\n",
-      "  episode_reward_min: .nan\n",
-      "  episodes_this_iter: 0\n",
-      "  episodes_total: 0\n",
-      "  experiment_id: a0d7abda875641ee8277cfe989ce99c0\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    num_steps_sampled: 56800\n",
-      "  iterations_since_restore: 142\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf: {}\n",
-      "  pid: 26894\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf: {}\n",
-      "  time_since_restore: 26.409894704818726\n",
-      "  time_this_iter_s: 0.16816067695617676\n",
-      "  time_total_s: 26.409894704818726\n",
-      "  timers: {}\n",
-      "  timestamp: 1602701609\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 56800\n",
-      "  training_iteration: 142\n",
-      "  trial_id: 7a318_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 22.0/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 0/3 GPUs, 0.0/557.08 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name                       | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
-      "| RandomMasked_jss_env_7a318_00000 | RUNNING  | 172.17.0.4:26894 |    142 |          26.4099 | 56800 |      nan |                  nan |                  nan |                nan |\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
+      "2020-11-04 21:48:07,725 - wandb.wandb_agent - INFO - Running runs: ['sb79yg44']\n",
       "\n",
-      "2020-10-14 18:53:30,587\tERROR worker.py:1018 -- Possible unhandled error from worker: \u001b[36mray::RolloutWorker.par_iter_next_batch()\u001b[39m (pid=26878, ip=172.17.0.4)\n",
-      "  File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
-      "  File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 1158, in par_iter_next_batch\n",
-      "    batch.append(self.par_iter_next())\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 1152, in par_iter_next\n",
-      "    return next(self.local_it)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 288, in gen_rollouts\n",
-      "    yield self.sample()\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 579, in sample\n",
-      "    batches = [self.input_reader.next()]\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 93, in next\n",
-      "    batches = [self.get_data()]\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 209, in get_data\n",
-      "    item = next(self.rollout_provider)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 585, in _env_runner\n",
-      "    active_envs, to_eval, outputs = _process_observations(\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 797, in _process_observations\n",
-      "    prep_obs: EnvObsType = _get_or_raise(preprocessors,\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/models/preprocessors.py\", line 233, in transform\n",
-      "    self.check_shape(observation)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/models/preprocessors.py\", line 61, in check_shape\n",
-      "    raise ValueError(\n",
-      "ValueError: ('Observation outside expected value range', Dict(action_mask:Box(0.0, 1.0, (51,), float32), real_obs:Box(0.0, 1.0, (350,), float64)), {'real_obs': array([0.00000000e+00, 3.03030303e-01, 4.66666667e-01, 3.36410256e-01,\n",
-      "       6.46464646e-01, 1.31282051e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 4.66666667e-01, 3.96923077e-01, 0.00000000e+00,\n",
-      "       1.84615385e-04, 0.00000000e+00, 0.00000000e+00, 1.91919192e-01,\n",
-      "       4.66666667e-01, 5.66153846e-01, 2.72727273e-01, 2.78974359e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.00000000e-01,\n",
-      "       6.01025641e-01, 7.77777778e-01, 1.18974359e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 4.66666667e-01, 3.20000000e-01,\n",
-      "       7.57575758e-01, 1.38051282e-02, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 1.00000000e+00, 5.82564103e-01, 1.00000000e+00,\n",
-      "       6.97435897e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       8.00000000e-01, 5.95897436e-01, 1.61616162e-01, 3.05641026e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.66666667e-01,\n",
-      "       2.87179487e-01, 7.07070707e-02, 3.89743590e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 6.00000000e-01, 3.72307692e-01,\n",
-      "       5.25252525e-01, 6.46153846e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       2.22222222e-01, 6.00000000e-01, 4.82051282e-01, 1.01010101e-02,\n",
-      "       1.57948718e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       8.00000000e-01, 5.33333333e-01, 3.63636364e-01, 1.49743590e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 5.15151515e-01, 4.66666667e-01,\n",
-      "       3.54871795e-01, 3.43434343e-01, 3.01538462e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 8.00000000e-01, 7.41538462e-01,\n",
-      "       1.41414141e-01, 2.74871795e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 4.00000000e-01, 1.98974359e-01, 4.34343434e-01,\n",
-      "       7.67179487e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       7.33333333e-01, 5.43589744e-01, 2.02020202e-02, 8.61538462e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.00000000e-01,\n",
-      "       4.24615385e-01, 4.34343434e-01, 2.46153846e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 3.03030303e-02, 4.66666667e-01, 4.87179487e-01,\n",
-      "       1.01010101e-01, 5.04615385e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 7.33333333e-01, 6.37948718e-01, 1.21212121e-01,\n",
-      "       2.42051282e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       2.00000000e-01, 9.94871795e-02, 4.04040404e-01, 7.38461538e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 3.13131313e-01, 6.66666667e-01,\n",
-      "       5.08717949e-01, 3.33333333e-01, 2.03076923e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 8.71794872e-01,\n",
-      "       1.00000000e+00, 1.14871795e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 6.66666667e-01, 4.81025641e-01, 6.36363636e-01,\n",
-      "       2.46153846e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       6.66666667e-01, 5.50769231e-01, 3.63636364e-01, 3.91794872e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 3.23232323e-01, 6.00000000e-01,\n",
-      "       4.53333333e-01, 1.01010101e-01, 2.99487179e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 2.32323232e-01, 6.00000000e-01, 4.78974359e-01,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 3.33333333e-01, 3.64102564e-01, 4.94949495e-01,\n",
-      "       3.83589744e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       6.00000000e-01, 5.04615385e-01, 1.21212121e-01, 9.43589744e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.00000000e-01,\n",
-      "       5.65128205e-01, 5.75757576e-01, 4.92307692e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 7.33333333e-01, 5.50769231e-01,\n",
-      "       3.83838384e-01, 1.92820513e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
-      "       1.06666667e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       6.00000000e-01, 3.82564103e-01, 2.02020202e-01, 5.80512821e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 7.33333333e-01,\n",
-      "       6.98461538e-01, 6.76767677e-01, 1.06666667e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 8.00000000e-01, 6.98461538e-01,\n",
-      "       7.27272727e-01, 8.20512821e-04, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 6.00000000e-01, 3.65128205e-01, 5.05050505e-02,\n",
-      "       1.88717949e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       8.00000000e-01, 5.88717949e-01, 6.96969697e-01, 7.58974359e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.33333333e-01,\n",
-      "       4.34871795e-01, 1.01010101e-01, 2.13333333e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 5.25252525e-01, 6.66666667e-01, 5.46666667e-01,\n",
-      "       0.00000000e+00, 3.69230769e-04, 0.00000000e+00, 0.00000000e+00,\n",
-      "       1.51515152e-01, 6.00000000e-01, 6.16410256e-01, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.23232323e-01,\n",
-      "       7.33333333e-01, 7.24102564e-01, 8.08080808e-01, 3.05641026e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 1.31313131e-01, 4.66666667e-01,\n",
-      "       3.29230769e-01, 1.11111111e-01, 6.83076923e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 5.33333333e-01, 4.35897436e-01,\n",
-      "       3.03030303e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 8.00000000e-01, 5.84615385e-01, 6.06060606e-02,\n",
-      "       1.78461538e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       5.33333333e-01, 3.06666667e-01, 2.12121212e-01, 9.08717949e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.66666667e-01,\n",
-      "       4.44102564e-01, 2.42424242e-01, 2.42051282e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 6.66666667e-01, 6.10256410e-01,\n",
-      "       3.03030303e-02, 2.52307692e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 8.00000000e-01, 6.01025641e-01, 3.13131313e-01,\n",
-      "       2.21538462e-03, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
-      "       8.00000000e-01, 6.66666667e-01, 1.01010101e-01, 3.26153846e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 4.04040404e-02, 6.00000000e-01,\n",
-      "       6.83076923e-01, 6.06060606e-02, 1.23076923e-04, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 6.00000000e-01, 5.10769231e-01,\n",
-      "       2.32323232e-01, 3.22051282e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       4.44444444e-01, 6.66666667e-01, 4.91282051e-01, 1.01010101e-02,\n",
-      "       1.37435897e-03, 0.00000000e+00]), 'action_mask': array([False, False, False, False, False, False, False, False, False,\n",
-      "       False, False, False, False, False, False, False, False, False,\n",
-      "       False, False, False, False, False, False, False, False, False,\n",
-      "       False, False, False, False, False, False, False, False, False,\n",
-      "       False, False, False, False, False, False, False, False, False,\n",
-      "       False,  True, False, False, False,  True])})\n",
-      "2020-10-14 18:53:33,891\tERROR trial_runner.py:567 -- Trial RandomMasked_jss_env_7a318_00000: Error processing event.\n",
-      "Traceback (most recent call last):\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/trial_runner.py\", line 515, in _process_trial\n",
-      "    result = self.trial_executor.fetch_result(trial)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/ray_trial_executor.py\", line 488, in fetch_result\n",
-      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1428, in get\n",
-      "    raise value.as_instanceof_cause()\n",
-      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::RandomMasked.train()\u001b[39m (pid=26894, ip=172.17.0.4)\n",
-      "  File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
-      "  File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\", line 516, in train\n",
-      "    raise e\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\", line 505, in train\n",
-      "    result = Trainable.train(self)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/trainable.py\", line 336, in train\n",
-      "    result = self.step()\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer_template.py\", line 134, in step\n",
-      "    res = next(self.train_exec_impl)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 756, in __next__\n",
-      "    return next(self.built_iterator)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
-      "    for item in it:\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 843, in apply_filter\n",
-      "    for item in it:\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 843, in apply_filter\n",
-      "    for item in it:\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
-      "    for item in it:\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
-      "    for item in it:\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 551, in base_iterator\n",
-      "    batch = ray.get(obj_ref)\n",
-      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::RolloutWorker.par_iter_next_batch()\u001b[39m (pid=26854, ip=172.17.0.4)\n",
-      "  File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
-      "  File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 1158, in par_iter_next_batch\n",
-      "    batch.append(self.par_iter_next())\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 1152, in par_iter_next\n",
-      "    return next(self.local_it)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 288, in gen_rollouts\n",
-      "    yield self.sample()\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 579, in sample\n",
-      "    batches = [self.input_reader.next()]\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 93, in next\n",
-      "    batches = [self.get_data()]\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 209, in get_data\n",
-      "    item = next(self.rollout_provider)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 585, in _env_runner\n",
-      "    active_envs, to_eval, outputs = _process_observations(\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 797, in _process_observations\n",
-      "    prep_obs: EnvObsType = _get_or_raise(preprocessors,\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/models/preprocessors.py\", line 233, in transform\n",
-      "    self.check_shape(observation)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/models/preprocessors.py\", line 61, in check_shape\n",
-      "    raise ValueError(\n",
-      "ValueError: ('Observation outside expected value range', Dict(action_mask:Box(0.0, 1.0, (51,), float32), real_obs:Box(0.0, 1.0, (350,), float64)), {'real_obs': array([0.00000000e+00, 0.00000000e+00, 5.33333333e-01, 3.67179487e-01,\n",
-      "       5.05050505e-01, 6.72820513e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       7.07070707e-02, 4.00000000e-01, 3.89743590e-01, 7.47474747e-01,\n",
-      "       1.20205128e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       7.33333333e-01, 7.47692308e-01, 3.43434343e-01, 5.82564103e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 5.15151515e-01, 5.33333333e-01,\n",
-      "       5.48717949e-01, 6.76767677e-01, 1.37435897e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 7.33333333e-01, 5.56923077e-01,\n",
-      "       1.51515152e-01, 1.12820513e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 6.66666667e-01, 2.81025641e-01, 2.42424242e-01,\n",
-      "       1.47692308e-03, 0.00000000e+00, 0.00000000e+00, 7.07070707e-02,\n",
-      "       6.66666667e-01, 5.47692308e-01, 0.00000000e+00, 6.66666667e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.66666667e-01,\n",
-      "       1.79487179e-01, 7.17171717e-01, 1.95076923e-02, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 6.00000000e-01, 3.72307692e-01,\n",
-      "       1.71717172e-01, 1.12205128e-02, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 9.33333333e-01, 7.12820513e-01, 4.04040404e-02,\n",
-      "       2.58461538e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       6.00000000e-01, 3.48717949e-01, 4.34343434e-01, 1.14256410e-02,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.66666667e-01,\n",
-      "       4.75897436e-01, 1.01010101e-01, 5.90769231e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 8.66666667e-01, 7.82564103e-01,\n",
-      "       6.86868687e-01, 1.25128205e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       6.06060606e-02, 6.66666667e-01, 5.57948718e-01, 2.62626263e-01,\n",
-      "       5.33333333e-04, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
-      "       6.00000000e-01, 4.02051282e-01, 9.69696970e-01, 5.53846154e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.66666667e-01,\n",
-      "       5.22051282e-01, 1.51515152e-01, 1.84615385e-04, 0.00000000e+00,\n",
-      "       0.00000000e+00, 8.08080808e-02, 8.00000000e-01, 7.04615385e-01,\n",
-      "       5.65656566e-01, 1.14871795e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 9.33333333e-01, 7.01538462e-01, 6.66666667e-01,\n",
-      "       6.25641026e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       4.66666667e-01, 2.92307692e-01, 6.36363636e-01, 1.12410256e-02,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 7.33333333e-01,\n",
-      "       5.40512821e-01, 1.51515152e-01, 1.43589744e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 7.33333333e-01, 6.56410256e-01,\n",
-      "       3.33333333e-01, 5.57948718e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       6.86868687e-01, 7.33333333e-01, 5.47692308e-01, 8.58585859e-01,\n",
-      "       1.74358974e-03, 0.00000000e+00, 0.00000000e+00, 2.02020202e-01,\n",
-      "       5.33333333e-01, 4.80000000e-01, 3.63636364e-01, 7.38461538e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.66666667e-01,\n",
-      "       4.86153846e-01, 3.83838384e-01, 6.35897436e-04, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 4.66666667e-01, 4.00000000e-01,\n",
-      "       6.26262626e-01, 3.69230769e-04, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 1.00000000e+00, 8.72820513e-01, 1.00000000e+00,\n",
-      "       8.20512821e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       5.33333333e-01, 4.98461538e-01, 6.76767677e-01, 2.07179487e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 1.51515152e-01, 4.00000000e-01,\n",
-      "       4.74871795e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 3.13131313e-01, 8.00000000e-01, 6.59487179e-01,\n",
-      "       8.58585859e-01, 1.74358974e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
-      "       3.07692308e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       2.66666667e-01, 1.58974359e-01, 3.03030303e-02, 5.21025641e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.00000000e-01,\n",
-      "       3.84615385e-01, 5.65656566e-01, 1.25538462e-02, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 7.68205128e-01,\n",
-      "       1.00000000e+00, 3.36410256e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 1.00000000e+00, 6.26666667e-01, 1.00000000e+00,\n",
-      "       1.24923077e-02, 0.00000000e+00, 0.00000000e+00, 6.06060606e-02,\n",
-      "       5.33333333e-01, 4.31794872e-01, 4.54545455e-01, 9.23076923e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
-      "       9.70256410e-01, 1.00000000e+00, 9.84615385e-04, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 4.66666667e-01, 3.58974359e-01,\n",
-      "       1.01010101e-02, 8.41025641e-04, 0.00000000e+00, 0.00000000e+00,\n",
-      "       4.44444444e-01, 9.33333333e-01, 8.36923077e-01, 4.04040404e-02,\n",
-      "       1.15487179e-02, 0.00000000e+00, 0.00000000e+00, 6.96969697e-01,\n",
-      "       6.00000000e-01, 5.84615385e-01, 2.92929293e-01, 1.07282051e-02,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 7.33333333e-01,\n",
-      "       4.65641026e-01, 0.00000000e+00, 3.38461538e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 9.33333333e-01, 7.02564103e-01,\n",
-      "       7.07070707e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 8.66666667e-01, 6.17435897e-01, 1.51515152e-01,\n",
-      "       3.38461538e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       6.00000000e-01, 3.81538462e-01, 2.02020202e-02, 4.59487179e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 3.13131313e-01, 5.33333333e-01,\n",
-      "       5.09743590e-01, 1.71717172e-01, 2.93333333e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 8.66666667e-01, 7.94871795e-01,\n",
-      "       4.94949495e-01, 6.97435897e-04, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 6.00000000e-01, 4.62564103e-01, 3.23232323e-01,\n",
-      "       1.43589744e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       9.33333333e-01, 7.80512821e-01, 2.62626263e-01, 3.69230769e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 2.52525253e-01, 9.33333333e-01,\n",
-      "       8.87179487e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 6.00000000e-01, 5.10769231e-01,\n",
-      "       6.26262626e-01, 6.40000000e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 8.00000000e-01, 5.94871795e-01, 1.11111111e-01,\n",
-      "       2.21538462e-03, 0.00000000e+00]), 'action_mask': array([False, False, False, False, False, False, False, False, False,\n",
-      "       False, False, False, False, False,  True, False, False, False,\n",
-      "       False, False, False, False, False, False, False, False, False,\n",
-      "       False, False, False, False, False, False, False, False, False,\n",
-      "       False, False, False, False, False, False, False, False, False,\n",
-      "       False, False, False, False, False,  True])})\n",
-      "== Status ==\n",
-      "Memory usage on this node: 22.0/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.08 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 ERROR)\n",
-      "+----------------------------------+----------+-------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name                       | status   | loc   |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|----------------------------------+----------+-------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
-      "| RandomMasked_jss_env_7a318_00000 | ERROR    |       |    171 |          30.8067 | 68400 |      nan |                  nan |                  nan |                nan |\n",
-      "+----------------------------------+----------+-------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "Number of errored trials: 1\n",
-      "+----------------------------------+--------------+--------------------------------------------------------------------------------------------+\n",
-      "| Trial name                       |   # failures | error file                                                                                 |\n",
-      "|----------------------------------+--------------+--------------------------------------------------------------------------------------------|\n",
-      "| RandomMasked_jss_env_7a318_00000 |            1 | /root/ray_results/ppo-jss/RandomMasked_jss_env_7a318_00000_0_2020-10-14_18-52-58/error.txt |\n",
-      "+----------------------------------+--------------+--------------------------------------------------------------------------------------------+\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 33800\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201104_214803-sb79yg44/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201104_214803-sb79yg44/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_timestep 2071.0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step 0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime 601\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp 1604527084\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_timestep ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mCP\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/sb79yg44\u001b[0m\n",
+      "2020-11-04 21:58:08,292 - wandb.wandb_agent - INFO - Cleaning up finished run: sb79yg44\n",
+      "2020-11-04 21:58:08,653 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-11-04 21:58:08,653 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tinstance_path: /JSS/JSS/env/instances/ta43\n",
+      "2020-11-04 21:58:08,655 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python CP.py --instance_path=/JSS/JSS/env/instances/ta43\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.8 is available!  To upgrade, please run:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mCP\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/sweeps/wnc8ihq1\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/p3hdb6ys\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201104_215809-p3hdb6ys\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
-      "Traceback (most recent call last):\n",
-      "  File \"random_loop.py\", line 73, in <module>\n",
-      "    rand_func()\n",
-      "  File \"random_loop.py\", line 55, in rand_func\n",
-      "    analysis = tune.run(RandomMaskedTrainer, config=config, stop=stop, name=\"ppo-jss\")\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/tune.py\", line 427, in run\n",
-      "    raise TuneError(\"Trials did not complete\", incomplete_trials)\n",
-      "ray.tune.error.TuneError: ('Trials did not complete', [RandomMasked_jss_env_7a318_00000])\n",
+      "2020-11-04 21:58:13,672 - wandb.wandb_agent - INFO - Running runs: ['p3hdb6ys']\n",
       "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 26647\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 1.  Press ctrl-c to abort syncing.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 33846\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201014_185253-ezglujb0/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201014_185253-ezglujb0/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201104_215809-p3hdb6ys/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201104_215809-p3hdb6ys/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_timestep 1967.0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step 0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime 601\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp 1604527690\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_timestep ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33msuper-sweep-2\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/ezglujb0\u001b[0m\n",
-      "2020-10-14 18:53:43,767 - wandb.wandb_agent - INFO - Cleaning up finished run: ezglujb0\n",
-      "2020-10-14 18:53:44,146 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-14 18:53:44,146 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tinstance_path: /JSS/JSS/env/instances/ta53\n",
-      "2020-10-14 18:53:44,148 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python random_loop.py --instance_path=/JSS/JSS/env/instances/ta53\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mCP\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/p3hdb6ys\u001b[0m\n",
+      "2020-11-04 22:08:18,999 - wandb.wandb_agent - INFO - Cleaning up finished run: p3hdb6ys\n",
+      "2020-11-04 22:08:19,334 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-11-04 22:08:19,334 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tinstance_path: /JSS/JSS/env/instances/ta44\n",
+      "2020-11-04 22:08:19,336 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python CP.py --instance_path=/JSS/JSS/env/instances/ta44\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.8 is available!  To upgrade, please run:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mspring-sweep-3\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/lh9x5rb9\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/gx7ht69p\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201014_185345-gx7ht69p\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mCP\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/sweeps/wnc8ihq1\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/q6lvwcdf\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201104_220820-q6lvwcdf\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
-      "2020-10-14 18:53:49,166 - wandb.wandb_agent - INFO - Running runs: ['gx7ht69p']\n",
-      "2020-10-14 18:53:49,662\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
-      "== Status ==\n",
-      "Memory usage on this node: 11.7/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 0/3 GPUs, 0.0/557.08 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+----------------------------------+----------+-------+\n",
-      "| Trial name                       | status   | loc   |\n",
-      "|----------------------------------+----------+-------|\n",
-      "| RandomMasked_jss_env_99699_00000 | RUNNING  |       |\n",
-      "+----------------------------------+----------+-------+\n",
+      "2020-11-04 22:08:24,353 - wandb.wandb_agent - INFO - Running runs: ['q6lvwcdf']\n",
       "\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 33892\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201104_220820-q6lvwcdf/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201104_220820-q6lvwcdf/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_timestep 2091.0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step 0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime 601\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp 1604528301\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_timestep ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mCP\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/q6lvwcdf\u001b[0m\n",
+      "2020-11-04 22:18:29,584 - wandb.wandb_agent - INFO - Cleaning up finished run: q6lvwcdf\n",
+      "2020-11-04 22:18:29,915 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-11-04 22:18:29,916 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tinstance_path: /JSS/JSS/env/instances/ta45\n",
+      "2020-11-04 22:18:29,917 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python CP.py --instance_path=/JSS/JSS/env/instances/ta45\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.8 is available!  To upgrade, please run:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mCP\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/sweeps/wnc8ihq1\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/60frjwtk\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201104_221830-60frjwtk\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
-      "\u001b[2m\u001b[36m(pid=28631)\u001b[0m 2020-10-14 18:53:52,367\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "Result for RandomMasked_jss_env_99699_00000:\n",
-      "  custom_metrics: {}\n",
-      "  date: 2020-10-14_18-53-56\n",
-      "  done: false\n",
-      "  episode_len_mean: .nan\n",
-      "  episode_reward_max: .nan\n",
-      "  episode_reward_mean: .nan\n",
-      "  episode_reward_min: .nan\n",
-      "  episodes_this_iter: 0\n",
-      "  episodes_total: 0\n",
-      "  experiment_id: 00d9f426bb89434f8ae7ff271eb43732\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    num_steps_sampled: 400\n",
-      "  iterations_since_restore: 1\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 68.7\n",
-      "    gpu_util_percent0: 0.0\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 2.3600000000000003\n",
-      "    vram_util_percent0: 0.0\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 28631\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf: {}\n",
-      "  time_since_restore: 3.336198329925537\n",
-      "  time_this_iter_s: 3.336198329925537\n",
-      "  time_total_s: 3.336198329925537\n",
-      "  timers: {}\n",
-      "  timestamp: 1602701636\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 400\n",
-      "  training_iteration: 1\n",
-      "  trial_id: '99699_00000'\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 21.8/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 0/3 GPUs, 0.0/557.08 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+----------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name                       | status   | loc              |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|----------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|\n",
-      "| RandomMasked_jss_env_99699_00000 | RUNNING  | 172.17.0.4:28631 |      1 |           3.3362 |  400 |      nan |                  nan |                  nan |                nan |\n",
-      "+----------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
+      "2020-11-04 22:18:34,933 - wandb.wandb_agent - INFO - Running runs: ['60frjwtk']\n",
       "\n",
-      "Result for RandomMasked_jss_env_99699_00000:\n",
-      "  custom_metrics: {}\n",
-      "  date: 2020-10-14_18-54-01\n",
-      "  done: false\n",
-      "  episode_len_mean: .nan\n",
-      "  episode_reward_max: .nan\n",
-      "  episode_reward_mean: .nan\n",
-      "  episode_reward_min: .nan\n",
-      "  episodes_this_iter: 0\n",
-      "  episodes_total: 0\n",
-      "  experiment_id: 00d9f426bb89434f8ae7ff271eb43732\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    num_steps_sampled: 11600\n",
-      "  iterations_since_restore: 29\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 5.2\n",
-      "    gpu_util_percent0: 0.0\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 2.9\n",
-      "    vram_util_percent0: 0.0\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 28631\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf: {}\n",
-      "  time_since_restore: 7.95437479019165\n",
-      "  time_this_iter_s: 0.16468524932861328\n",
-      "  time_total_s: 7.95437479019165\n",
-      "  timers: {}\n",
-      "  timestamp: 1602701641\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 11600\n",
-      "  training_iteration: 29\n",
-      "  trial_id: '99699_00000'\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 21.9/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 0/3 GPUs, 0.0/557.08 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name                       | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
-      "| RandomMasked_jss_env_99699_00000 | RUNNING  | 172.17.0.4:28631 |     29 |          7.95437 | 11600 |      nan |                  nan |                  nan |                nan |\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 33938\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201104_221830-60frjwtk/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201104_221830-60frjwtk/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_timestep 2032.0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step 0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime 601\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp 1604528911\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_timestep ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mCP\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/60frjwtk\u001b[0m\n",
+      "2020-11-04 22:28:39,901 - wandb.wandb_agent - INFO - Cleaning up finished run: 60frjwtk\n",
+      "2020-11-04 22:28:40,319 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-11-04 22:28:40,320 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tinstance_path: /JSS/JSS/env/instances/ta46\n",
+      "2020-11-04 22:28:40,321 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python CP.py --instance_path=/JSS/JSS/env/instances/ta46\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.8 is available!  To upgrade, please run:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mCP\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/sweeps/wnc8ihq1\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/4w63mxn5\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201104_222841-4w63mxn5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
+      "2020-11-04 22:28:45,337 - wandb.wandb_agent - INFO - Running runs: ['4w63mxn5']\n",
       "\n",
-      "Result for RandomMasked_jss_env_99699_00000:\n",
-      "  custom_metrics: {}\n",
-      "  date: 2020-10-14_18-54-06\n",
-      "  done: false\n",
-      "  episode_len_mean: .nan\n",
-      "  episode_reward_max: .nan\n",
-      "  episode_reward_mean: .nan\n",
-      "  episode_reward_min: .nan\n",
-      "  episodes_this_iter: 0\n",
-      "  episodes_total: 0\n",
-      "  experiment_id: 00d9f426bb89434f8ae7ff271eb43732\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    num_steps_sampled: 23200\n",
-      "  iterations_since_restore: 58\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf: {}\n",
-      "  pid: 28631\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf: {}\n",
-      "  time_since_restore: 12.706214427947998\n",
-      "  time_this_iter_s: 0.1642756462097168\n",
-      "  time_total_s: 12.706214427947998\n",
-      "  timers: {}\n",
-      "  timestamp: 1602701646\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 23200\n",
-      "  training_iteration: 58\n",
-      "  trial_id: '99699_00000'\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 22.0/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 0/3 GPUs, 0.0/557.08 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name                       | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
-      "| RandomMasked_jss_env_99699_00000 | RUNNING  | 172.17.0.4:28631 |     58 |          12.7062 | 23200 |      nan |                  nan |                  nan |                nan |\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 33984\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201104_222841-4w63mxn5/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201104_222841-4w63mxn5/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_timestep 2070.0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step 0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime 601\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp 1604529522\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_timestep ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mCP\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/4w63mxn5\u001b[0m\n",
+      "2020-11-04 22:38:45,728 - wandb.wandb_agent - INFO - Cleaning up finished run: 4w63mxn5\n",
+      "2020-11-04 22:38:46,210 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-11-04 22:38:46,210 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tinstance_path: /JSS/JSS/env/instances/ta47\n",
+      "2020-11-04 22:38:46,212 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python CP.py --instance_path=/JSS/JSS/env/instances/ta47\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.8 is available!  To upgrade, please run:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mCP\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/sweeps/wnc8ihq1\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/qpbtop8x\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201104_223847-qpbtop8x\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
+      "2020-11-04 22:38:51,228 - wandb.wandb_agent - INFO - Running runs: ['qpbtop8x']\n",
       "\n",
-      "Result for RandomMasked_jss_env_99699_00000:\n",
-      "  custom_metrics: {}\n",
-      "  date: 2020-10-14_18-54-11\n",
-      "  done: false\n",
-      "  episode_len_mean: .nan\n",
-      "  episode_reward_max: .nan\n",
-      "  episode_reward_mean: .nan\n",
-      "  episode_reward_min: .nan\n",
-      "  episodes_this_iter: 0\n",
-      "  episodes_total: 0\n",
-      "  experiment_id: 00d9f426bb89434f8ae7ff271eb43732\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    num_steps_sampled: 34800\n",
-      "  iterations_since_restore: 87\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf: {}\n",
-      "  pid: 28631\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf: {}\n",
-      "  time_since_restore: 17.468780755996704\n",
-      "  time_this_iter_s: 0.15766501426696777\n",
-      "  time_total_s: 17.468780755996704\n",
-      "  timers: {}\n",
-      "  timestamp: 1602701651\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 34800\n",
-      "  training_iteration: 87\n",
-      "  trial_id: '99699_00000'\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 22.0/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 0/3 GPUs, 0.0/557.08 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name                       | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
-      "| RandomMasked_jss_env_99699_00000 | RUNNING  | 172.17.0.4:28631 |     87 |          17.4688 | 34800 |      nan |                  nan |                  nan |                nan |\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 34030\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201104_223847-qpbtop8x/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201104_223847-qpbtop8x/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_timestep 1991.0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step 0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime 601\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp 1604530128\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_timestep ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mCP\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/qpbtop8x\u001b[0m\n",
+      "2020-11-04 22:48:56,548 - wandb.wandb_agent - INFO - Cleaning up finished run: qpbtop8x\n",
+      "2020-11-04 22:48:56,937 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-11-04 22:48:56,937 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tinstance_path: /JSS/JSS/env/instances/ta48\n",
+      "2020-11-04 22:48:56,939 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python CP.py --instance_path=/JSS/JSS/env/instances/ta48\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.8 is available!  To upgrade, please run:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mCP\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/sweeps/wnc8ihq1\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/gsihk78x\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201104_224857-gsihk78x\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
+      "2020-11-04 22:49:01,955 - wandb.wandb_agent - INFO - Running runs: ['gsihk78x']\n",
       "\n",
-      "Result for RandomMasked_jss_env_99699_00000:\n",
-      "  custom_metrics: {}\n",
-      "  date: 2020-10-14_18-54-16\n",
-      "  done: false\n",
-      "  episode_len_mean: .nan\n",
-      "  episode_reward_max: .nan\n",
-      "  episode_reward_mean: .nan\n",
-      "  episode_reward_min: .nan\n",
-      "  episodes_this_iter: 0\n",
-      "  episodes_total: 0\n",
-      "  experiment_id: 00d9f426bb89434f8ae7ff271eb43732\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    num_steps_sampled: 46400\n",
-      "  iterations_since_restore: 116\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 4.3\n",
-      "    gpu_util_percent0: 0.0\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 2.9\n",
-      "    vram_util_percent0: 0.0\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 28631\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf: {}\n",
-      "  time_since_restore: 22.175960779190063\n",
-      "  time_this_iter_s: 0.1871342658996582\n",
-      "  time_total_s: 22.175960779190063\n",
-      "  timers: {}\n",
-      "  timestamp: 1602701656\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 46400\n",
-      "  training_iteration: 116\n",
-      "  trial_id: '99699_00000'\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 22.0/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 0/3 GPUs, 0.0/557.08 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name                       | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
-      "| RandomMasked_jss_env_99699_00000 | RUNNING  | 172.17.0.4:28631 |    116 |           22.176 | 46400 |      nan |                  nan |                  nan |                nan |\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 34076\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201104_224857-gsihk78x/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201104_224857-gsihk78x/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_timestep 2052.0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step 0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime 602\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp 1604530739\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_timestep ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mCP\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/gsihk78x\u001b[0m\n",
+      "2020-11-04 22:59:07,301 - wandb.wandb_agent - INFO - Cleaning up finished run: gsihk78x\n",
+      "2020-11-04 22:59:07,606 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-11-04 22:59:07,606 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tinstance_path: /JSS/JSS/env/instances/ta49\n",
+      "2020-11-04 22:59:07,608 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python CP.py --instance_path=/JSS/JSS/env/instances/ta49\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.8 is available!  To upgrade, please run:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mCP\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/sweeps/wnc8ihq1\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/pvt5040k\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201104_225908-pvt5040k\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
+      "2020-11-04 22:59:12,624 - wandb.wandb_agent - INFO - Running runs: ['pvt5040k']\n",
       "\n",
-      "Result for RandomMasked_jss_env_99699_00000:\n",
-      "  custom_metrics: {}\n",
-      "  date: 2020-10-14_18-54-21\n",
-      "  done: false\n",
-      "  episode_len_mean: .nan\n",
-      "  episode_reward_max: .nan\n",
-      "  episode_reward_mean: .nan\n",
-      "  episode_reward_min: .nan\n",
-      "  episodes_this_iter: 0\n",
-      "  episodes_total: 0\n",
-      "  experiment_id: 00d9f426bb89434f8ae7ff271eb43732\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    num_steps_sampled: 58000\n",
-      "  iterations_since_restore: 145\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf: {}\n",
-      "  pid: 28631\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf: {}\n",
-      "  time_since_restore: 26.801780700683594\n",
-      "  time_this_iter_s: 0.15772652626037598\n",
-      "  time_total_s: 26.801780700683594\n",
-      "  timers: {}\n",
-      "  timestamp: 1602701661\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 58000\n",
-      "  training_iteration: 145\n",
-      "  trial_id: '99699_00000'\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 22.1/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 0/3 GPUs, 0.0/557.08 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name                       | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
-      "| RandomMasked_jss_env_99699_00000 | RUNNING  | 172.17.0.4:28631 |    145 |          26.8018 | 58000 |      nan |                  nan |                  nan |                nan |\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 34122\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201104_225908-pvt5040k/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201104_225908-pvt5040k/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_timestep 2072.0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step 0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime 601\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp 1604531349\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_timestep ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mCP\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/pvt5040k\u001b[0m\n",
+      "2020-11-04 23:09:17,980 - wandb.wandb_agent - INFO - Cleaning up finished run: pvt5040k\n",
+      "2020-11-04 23:09:18,328 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-11-04 23:09:18,328 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tinstance_path: /JSS/JSS/env/instances/ta50\n",
+      "2020-11-04 23:09:18,330 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python CP.py --instance_path=/JSS/JSS/env/instances/ta50\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.8 is available!  To upgrade, please run:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mCP\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/sweeps/wnc8ihq1\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/7oeiazwm\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201104_230919-7oeiazwm\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
+      "2020-11-04 23:09:23,346 - wandb.wandb_agent - INFO - Running runs: ['7oeiazwm']\n",
       "\n",
-      "2020-10-14 18:54:21,879\tERROR worker.py:1018 -- Possible unhandled error from worker: \u001b[36mray::RolloutWorker.par_iter_next_batch()\u001b[39m (pid=28512, ip=172.17.0.4)\n",
-      "  File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
-      "  File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 1158, in par_iter_next_batch\n",
-      "    batch.append(self.par_iter_next())\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 1152, in par_iter_next\n",
-      "    return next(self.local_it)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 288, in gen_rollouts\n",
-      "    yield self.sample()\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 579, in sample\n",
-      "    batches = [self.input_reader.next()]\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 93, in next\n",
-      "    batches = [self.get_data()]\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 209, in get_data\n",
-      "    item = next(self.rollout_provider)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 585, in _env_runner\n",
-      "    active_envs, to_eval, outputs = _process_observations(\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 797, in _process_observations\n",
-      "    prep_obs: EnvObsType = _get_or_raise(preprocessors,\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/models/preprocessors.py\", line 233, in transform\n",
-      "    self.check_shape(observation)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/models/preprocessors.py\", line 61, in check_shape\n",
-      "    raise ValueError(\n",
-      "ValueError: ('Observation outside expected value range', Dict(action_mask:Box(0.0, 1.0, (51,), float32), real_obs:Box(0.0, 1.0, (350,), float64)), {'real_obs': array([0.00000000e+00, 0.00000000e+00, 5.33333333e-01, 3.67179487e-01,\n",
-      "       1.31313131e-01, 1.84615385e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 8.00000000e-01, 5.87692308e-01, 2.42424242e-01,\n",
-      "       1.16923077e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       8.66666667e-01, 8.18461538e-01, 1.71717172e-01, 1.84615385e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 6.56565657e-01, 6.66666667e-01,\n",
-      "       6.98461538e-01, 1.01010101e-02, 9.23076923e-04, 0.00000000e+00,\n",
-      "       1.00000000e+00, 0.00000000e+00, 6.66666667e-01, 4.84102564e-01,\n",
-      "       4.44444444e-01, 1.74358974e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       7.17171717e-01, 6.66666667e-01, 2.94358974e-01, 0.00000000e+00,\n",
-      "       1.02564103e-04, 0.00000000e+00, 0.00000000e+00, 4.04040404e-01,\n",
-      "       6.66666667e-01, 5.13846154e-01, 7.77777778e-01, 1.57948718e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.00000000e-01,\n",
-      "       1.30256410e-01, 5.35353535e-01, 7.20000000e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 6.00000000e-01, 3.72307692e-01,\n",
-      "       4.54545455e-01, 1.09333333e-02, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 8.00000000e-01, 6.25641026e-01, 5.45454545e-01,\n",
-      "       8.20512821e-05, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       4.66666667e-01, 2.42051282e-01, 1.61616162e-01, 1.25128205e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.66666667e-01,\n",
-      "       3.11794872e-01, 4.04040404e-02, 1.16923077e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 5.33333333e-01, 4.99487179e-01,\n",
-      "       6.56565657e-01, 8.61538462e-04, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 5.33333333e-01, 3.83589744e-01, 2.22222222e-01,\n",
-      "       5.33333333e-04, 0.00000000e+00, 0.00000000e+00, 2.32323232e-01,\n",
-      "       6.00000000e-01, 4.54358974e-01, 3.13131313e-01, 7.58974359e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.66666667e-01,\n",
-      "       3.66153846e-01, 7.87878788e-01, 5.29230769e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 8.00000000e-01, 6.55384615e-01,\n",
-      "       0.00000000e+00, 2.66666667e-04, 0.00000000e+00, 0.00000000e+00,\n",
-      "       8.08080808e-02, 8.00000000e-01, 6.92307692e-01, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       5.33333333e-01, 3.06666667e-01, 6.46464646e-01, 3.28205128e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 8.66666667e-01,\n",
-      "       6.07179487e-01, 3.33333333e-01, 6.15384615e-04, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 4.66666667e-01, 4.44102564e-01,\n",
-      "       9.09090909e-02, 1.57948718e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       8.08080808e-02, 6.66666667e-02, 8.00000000e-02, 7.07070707e-01,\n",
-      "       8.82051282e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       6.00000000e-01, 5.00512821e-01, 4.14141414e-01, 6.76923077e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.00000000e-01,\n",
-      "       3.95897436e-01, 1.51515152e-01, 8.41025641e-04, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 9.33333333e-01, 6.40000000e-01,\n",
-      "       7.17171717e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       5.05050505e-02, 6.66666667e-01, 6.82051282e-01, 5.05050505e-02,\n",
-      "       2.25641026e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       6.00000000e-01, 5.04615385e-01, 3.03030303e-02, 9.84615385e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.33333333e-01,\n",
-      "       5.41538462e-01, 9.79797980e-01, 5.68205128e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 3.33333333e-01, 2.86153846e-01,\n",
-      "       2.72727273e-01, 9.23076923e-04, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
-      "       1.39487179e-03, 0.00000000e+00, 0.00000000e+00, 5.35353535e-01,\n",
-      "       8.66666667e-01, 5.94871795e-01, 5.45454545e-01, 3.63076923e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.33333333e-01,\n",
-      "       5.68205128e-01, 6.66666667e-01, 3.69230769e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 2.66666667e-01, 2.67692308e-01,\n",
-      "       7.47474747e-01, 5.21025641e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 6.00000000e-01, 3.65128205e-01, 1.51515152e-01,\n",
-      "       7.69230769e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       6.66666667e-01, 4.74871795e-01, 1.21212121e-01, 2.95384615e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 8.66666667e-01,\n",
-      "       8.50256410e-01, 5.35353535e-01, 4.77948718e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 8.00000000e-01, 6.10256410e-01,\n",
-      "       5.45454545e-01, 6.35897436e-04, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 6.66666667e-01, 6.31794872e-01, 7.07070707e-01,\n",
-      "       7.15897436e-03, 0.00000000e+00, 0.00000000e+00, 5.05050505e-01,\n",
-      "       6.00000000e-01, 6.04102564e-01, 4.04040404e-01, 1.09128205e-02,\n",
-      "       0.00000000e+00, 0.00000000e+00, 3.03030303e-02, 7.33333333e-01,\n",
-      "       5.03589744e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 1.11111111e-01, 7.33333333e-01, 5.93846154e-01,\n",
-      "       5.55555556e-01, 2.15384615e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 4.66666667e-01, 4.54358974e-01, 4.94949495e-01,\n",
-      "       4.26666667e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       6.00000000e-01, 3.81538462e-01, 1.71717172e-01, 3.26153846e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 7.33333333e-01,\n",
-      "       5.88717949e-01, 1.71717172e-01, 6.07179487e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 6.00000000e-01, 5.88717949e-01,\n",
-      "       2.92929293e-01, 5.76410256e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       4.84848485e-01, 4.66666667e-01, 3.88717949e-01, 6.36363636e-01,\n",
-      "       1.29230769e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       5.33333333e-01, 5.16923077e-01, 6.06060606e-02, 1.61230769e-02,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.33333333e-01,\n",
-      "       5.47692308e-01, 6.16161616e-01, 4.94358974e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 4.00000000e-01, 3.78461538e-01,\n",
-      "       2.52525253e-01, 8.82051282e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 5.33333333e-01, 2.82051282e-01, 6.06060606e-01,\n",
-      "       4.43076923e-03, 0.00000000e+00]), 'action_mask': array([False, False, False, False,  True, False, False, False, False,\n",
-      "       False, False, False, False, False, False, False, False, False,\n",
-      "       False, False, False, False, False, False, False, False, False,\n",
-      "       False, False, False, False, False, False, False, False, False,\n",
-      "       False, False, False, False, False, False, False, False, False,\n",
-      "       False, False, False, False, False,  True])})\n"
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 34168\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201104_230919-7oeiazwm/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201104_230919-7oeiazwm/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_timestep 2010.0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step 0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime 601\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp 1604531960\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_timestep ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mCP\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/7oeiazwm\u001b[0m\n",
+      "2020-11-04 23:19:23,596 - wandb.wandb_agent - INFO - Cleaning up finished run: 7oeiazwm\n",
+      "2020-11-04 23:19:23,944 - wandb.wandb_agent - INFO - Agent received command: exit\n",
+      "2020-11-04 23:19:23,944 - wandb.wandb_agent - INFO - Received exit command. Killing runs and quitting.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Terminating and syncing runs. Press ctrl-c to kill.\n"
      ]
     }
    ],
    "source": [
-    "!wandb agent lh9x5rb9"
+    "!wandb agent wnc8ihq1"
    ]
   },
   {
diff --git a/JSS/__pycache__/default_config.cpython-38.pyc b/JSS/__pycache__/default_config.cpython-38.pyc
index 14e0018..8fbfc47 100644
Binary files a/JSS/__pycache__/default_config.cpython-38.pyc and b/JSS/__pycache__/default_config.cpython-38.pyc differ
diff --git a/JSS/default_config.py b/JSS/default_config.py
index 46f4d10..4729210 100644
--- a/JSS/default_config.py
+++ b/JSS/default_config.py
@@ -6,7 +6,7 @@ default_config = {
     'env': 'jss_env',
     'seed': 0,
     'framework': 'torch',
-    'log_level': 'INFO',
+    'log_level': 'WARN',
     'num_gpus': 1,
     'instance_path': '/JSS/JSS/env/instances/ta51',
     'num_envs_per_worker': 2,
diff --git a/JSS/env/__pycache__/JSS.cpython-38.pyc b/JSS/env/__pycache__/JSS.cpython-38.pyc
index b190093..143d813 100644
Binary files a/JSS/env/__pycache__/JSS.cpython-38.pyc and b/JSS/env/__pycache__/JSS.cpython-38.pyc differ
diff --git a/JSS/train.py b/JSS/train.py
index d4ac941..0275259 100644
--- a/JSS/train.py
+++ b/JSS/train.py
@@ -47,10 +47,10 @@ def train_func():
     config.pop('layer_size', None)
     config.pop('layer_nb', None)
 
-    ray.init()
+    ray.init(num_gpus=1)
 
     stop = {
-        "time_total_s": 60 * 60,
+        "time_total_s": 10 * 60,
     }
 
     analysis = tune.run(PPOTrainer, config=config, stop=stop, name="ppo-jss")
diff --git a/JSS/wandb/debug-internal.log b/JSS/wandb/debug-internal.log
index f73d8af..31cadcd 120000
--- a/JSS/wandb/debug-internal.log
+++ b/JSS/wandb/debug-internal.log
@@ -1 +1 @@
-run-20201014_204512-kkype8ue/logs/debug-internal.log
\ No newline at end of file
+run-20201105_104643-puyaj569/logs/debug-internal.log
\ No newline at end of file
diff --git a/JSS/wandb/debug.log b/JSS/wandb/debug.log
index db2ed2e..5a77709 120000
--- a/JSS/wandb/debug.log
+++ b/JSS/wandb/debug.log
@@ -1 +1 @@
-run-20201014_204512-kkype8ue/logs/debug.log
\ No newline at end of file
+run-20201105_104643-puyaj569/logs/debug.log
\ No newline at end of file
diff --git a/JSS/wandb/latest-run b/JSS/wandb/latest-run
index f19e5b0..ad39085 120000
--- a/JSS/wandb/latest-run
+++ b/JSS/wandb/latest-run
@@ -1 +1 @@
-run-20201014_204512-kkype8ue
\ No newline at end of file
+run-20201105_104643-puyaj569
\ No newline at end of file
diff --git a/JSS/wandb/run-20201014_185459-4qedwvw4/logs/debug-internal.log b/JSS/wandb/run-20201014_185459-4qedwvw4/logs/debug-internal.log
index 62aefa0..a469c27 100644
--- a/JSS/wandb/run-20201014_185459-4qedwvw4/logs/debug-internal.log
+++ b/JSS/wandb/run-20201014_185459-4qedwvw4/logs/debug-internal.log
@@ -3791,3 +3791,60 @@
 2020-10-14 20:48:22,755 DEBUG   SenderThread:30187 [connectionpool.py:_make_request():428] https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
 2020-10-14 20:48:24,674 DEBUG   SenderThread:30187 [sender.py:send():88] send: stats
 2020-10-14 20:48:29,293 DEBUG   SenderThread:30187 [sender.py:send():88] send: stats
+2020-10-14 20:48:33,903 DEBUG   SenderThread:30187 [sender.py:send():88] send: stats
+2020-10-14 20:48:37,761 DEBUG   HandlerThread:30187 [handler.py:handle_request():54] handle_request: status
+2020-10-14 20:48:37,761 DEBUG   SenderThread:30187 [sender.py:send():88] send: request
+2020-10-14 20:48:37,761 DEBUG   SenderThread:30187 [sender.py:send_request():97] send_request: status
+2020-10-14 20:48:37,765 DEBUG   SenderThread:30187 [connectionpool.py:_new_conn():955] Starting new HTTPS connection (1): api.wandb.ai:443
+2020-10-14 20:48:37,962 DEBUG   SenderThread:30187 [connectionpool.py:_make_request():428] https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
+2020-10-14 20:48:38,519 DEBUG   SenderThread:30187 [sender.py:send():88] send: stats
+2020-10-14 20:48:43,143 DEBUG   SenderThread:30187 [sender.py:send():88] send: stats
+2020-10-14 20:48:47,759 DEBUG   SenderThread:30187 [sender.py:send():88] send: stats
+2020-10-14 20:48:52,385 DEBUG   SenderThread:30187 [sender.py:send():88] send: stats
+2020-10-14 20:48:52,968 DEBUG   HandlerThread:30187 [handler.py:handle_request():54] handle_request: status
+2020-10-14 20:48:52,968 DEBUG   SenderThread:30187 [sender.py:send():88] send: request
+2020-10-14 20:48:52,968 DEBUG   SenderThread:30187 [sender.py:send_request():97] send_request: status
+2020-10-14 20:48:52,975 DEBUG   SenderThread:30187 [connectionpool.py:_new_conn():955] Starting new HTTPS connection (1): api.wandb.ai:443
+2020-10-14 20:48:53,184 DEBUG   SenderThread:30187 [connectionpool.py:_make_request():428] https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
+2020-10-14 20:48:57,005 DEBUG   SenderThread:30187 [sender.py:send():88] send: stats
+2020-10-14 20:49:01,622 DEBUG   SenderThread:30187 [sender.py:send():88] send: stats
+2020-10-14 20:49:06,249 DEBUG   SenderThread:30187 [sender.py:send():88] send: stats
+2020-10-14 20:49:08,189 DEBUG   HandlerThread:30187 [handler.py:handle_request():54] handle_request: status
+2020-10-14 20:49:08,190 DEBUG   SenderThread:30187 [sender.py:send():88] send: request
+2020-10-14 20:49:08,190 DEBUG   SenderThread:30187 [sender.py:send_request():97] send_request: status
+2020-10-14 20:49:08,195 DEBUG   SenderThread:30187 [connectionpool.py:_new_conn():955] Starting new HTTPS connection (1): api.wandb.ai:443
+2020-10-14 20:49:08,392 DEBUG   SenderThread:30187 [connectionpool.py:_make_request():428] https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
+2020-10-14 20:49:10,874 DEBUG   SenderThread:30187 [sender.py:send():88] send: stats
+2020-10-14 20:49:15,492 DEBUG   SenderThread:30187 [sender.py:send():88] send: stats
+2020-10-14 20:49:20,107 DEBUG   SenderThread:30187 [sender.py:send():88] send: stats
+2020-10-14 20:49:23,398 DEBUG   HandlerThread:30187 [handler.py:handle_request():54] handle_request: status
+2020-10-14 20:49:23,398 DEBUG   SenderThread:30187 [sender.py:send():88] send: request
+2020-10-14 20:49:23,398 DEBUG   SenderThread:30187 [sender.py:send_request():97] send_request: status
+2020-10-14 20:49:23,403 DEBUG   SenderThread:30187 [connectionpool.py:_new_conn():955] Starting new HTTPS connection (1): api.wandb.ai:443
+2020-10-14 20:49:23,595 DEBUG   SenderThread:30187 [connectionpool.py:_make_request():428] https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
+2020-10-14 20:49:24,725 DEBUG   SenderThread:30187 [sender.py:send():88] send: stats
+2020-10-14 20:49:29,333 DEBUG   SenderThread:30187 [sender.py:send():88] send: stats
+2020-10-14 20:49:33,953 DEBUG   SenderThread:30187 [sender.py:send():88] send: stats
+2020-10-14 20:49:38,566 DEBUG   SenderThread:30187 [sender.py:send():88] send: stats
+2020-10-14 20:49:38,601 DEBUG   HandlerThread:30187 [handler.py:handle_request():54] handle_request: status
+2020-10-14 20:49:38,601 DEBUG   SenderThread:30187 [sender.py:send():88] send: request
+2020-10-14 20:49:38,601 DEBUG   SenderThread:30187 [sender.py:send_request():97] send_request: status
+2020-10-14 20:49:38,605 DEBUG   SenderThread:30187 [connectionpool.py:_new_conn():955] Starting new HTTPS connection (1): api.wandb.ai:443
+2020-10-14 20:49:38,802 DEBUG   SenderThread:30187 [connectionpool.py:_make_request():428] https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
+2020-10-14 20:49:43,182 DEBUG   SenderThread:30187 [sender.py:send():88] send: stats
+2020-10-14 20:49:47,813 DEBUG   SenderThread:30187 [sender.py:send():88] send: stats
+2020-10-14 20:49:52,436 DEBUG   SenderThread:30187 [sender.py:send():88] send: stats
+2020-10-14 20:49:53,808 DEBUG   HandlerThread:30187 [handler.py:handle_request():54] handle_request: status
+2020-10-14 20:49:53,809 DEBUG   SenderThread:30187 [sender.py:send():88] send: request
+2020-10-14 20:49:53,809 DEBUG   SenderThread:30187 [sender.py:send_request():97] send_request: status
+2020-10-14 20:49:53,813 DEBUG   SenderThread:30187 [connectionpool.py:_new_conn():955] Starting new HTTPS connection (1): api.wandb.ai:443
+2020-10-14 20:49:54,014 DEBUG   SenderThread:30187 [connectionpool.py:_make_request():428] https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
+2020-10-14 20:49:57,041 DEBUG   SenderThread:30187 [sender.py:send():88] send: stats
+2020-10-14 20:50:01,665 DEBUG   SenderThread:30187 [sender.py:send():88] send: stats
+2020-10-14 20:50:06,273 DEBUG   SenderThread:30187 [sender.py:send():88] send: stats
+2020-10-14 20:50:09,020 DEBUG   HandlerThread:30187 [handler.py:handle_request():54] handle_request: status
+2020-10-14 20:50:09,020 DEBUG   SenderThread:30187 [sender.py:send():88] send: request
+2020-10-14 20:50:09,020 DEBUG   SenderThread:30187 [sender.py:send_request():97] send_request: status
+2020-10-14 20:50:09,024 DEBUG   SenderThread:30187 [connectionpool.py:_new_conn():955] Starting new HTTPS connection (1): api.wandb.ai:443
+2020-10-14 20:50:09,226 DEBUG   SenderThread:30187 [connectionpool.py:_make_request():428] https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
+2020-10-14 20:50:10,902 DEBUG   SenderThread:30187 [sender.py:send():88] send: stats
diff --git a/JSS/wandb/run-20201014_185459-4qedwvw4/run-4qedwvw4.wandb b/JSS/wandb/run-20201014_185459-4qedwvw4/run-4qedwvw4.wandb
index fe32750..a173876 100644
Binary files a/JSS/wandb/run-20201014_185459-4qedwvw4/run-4qedwvw4.wandb and b/JSS/wandb/run-20201014_185459-4qedwvw4/run-4qedwvw4.wandb differ
diff --git a/JSS/wandb/run-20201014_185623-es6i30gb/logs/debug-internal.log b/JSS/wandb/run-20201014_185623-es6i30gb/logs/debug-internal.log
index 6c28b35..39056d1 100644
--- a/JSS/wandb/run-20201014_185623-es6i30gb/logs/debug-internal.log
+++ b/JSS/wandb/run-20201014_185623-es6i30gb/logs/debug-internal.log
@@ -3766,3 +3766,55 @@
 2020-10-14 20:48:28,206 DEBUG   SenderThread:34843 [sender.py:send_request():97] send_request: status
 2020-10-14 20:48:28,210 DEBUG   SenderThread:34843 [connectionpool.py:_new_conn():955] Starting new HTTPS connection (1): api.wandb.ai:443
 2020-10-14 20:48:28,411 DEBUG   SenderThread:34843 [connectionpool.py:_make_request():428] https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
+2020-10-14 20:48:32,759 DEBUG   SenderThread:34843 [sender.py:send():88] send: stats
+2020-10-14 20:48:37,379 DEBUG   SenderThread:34843 [sender.py:send():88] send: stats
+2020-10-14 20:48:41,998 DEBUG   SenderThread:34843 [sender.py:send():88] send: stats
+2020-10-14 20:48:43,417 DEBUG   HandlerThread:34843 [handler.py:handle_request():54] handle_request: status
+2020-10-14 20:48:43,417 DEBUG   SenderThread:34843 [sender.py:send():88] send: request
+2020-10-14 20:48:43,418 DEBUG   SenderThread:34843 [sender.py:send_request():97] send_request: status
+2020-10-14 20:48:43,425 DEBUG   SenderThread:34843 [connectionpool.py:_new_conn():955] Starting new HTTPS connection (1): api.wandb.ai:443
+2020-10-14 20:48:43,622 DEBUG   SenderThread:34843 [connectionpool.py:_make_request():428] https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
+2020-10-14 20:48:46,618 DEBUG   SenderThread:34843 [sender.py:send():88] send: stats
+2020-10-14 20:48:51,237 DEBUG   SenderThread:34843 [sender.py:send():88] send: stats
+2020-10-14 20:48:55,878 DEBUG   SenderThread:34843 [sender.py:send():88] send: stats
+2020-10-14 20:48:58,628 DEBUG   HandlerThread:34843 [handler.py:handle_request():54] handle_request: status
+2020-10-14 20:48:58,629 DEBUG   SenderThread:34843 [sender.py:send():88] send: request
+2020-10-14 20:48:58,629 DEBUG   SenderThread:34843 [sender.py:send_request():97] send_request: status
+2020-10-14 20:48:58,634 DEBUG   SenderThread:34843 [connectionpool.py:_new_conn():955] Starting new HTTPS connection (1): api.wandb.ai:443
+2020-10-14 20:48:58,828 DEBUG   SenderThread:34843 [connectionpool.py:_make_request():428] https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
+2020-10-14 20:49:00,486 DEBUG   SenderThread:34843 [sender.py:send():88] send: stats
+2020-10-14 20:49:05,100 DEBUG   SenderThread:34843 [sender.py:send():88] send: stats
+2020-10-14 20:49:09,717 DEBUG   SenderThread:34843 [sender.py:send():88] send: stats
+2020-10-14 20:49:13,834 DEBUG   HandlerThread:34843 [handler.py:handle_request():54] handle_request: status
+2020-10-14 20:49:13,834 DEBUG   SenderThread:34843 [sender.py:send():88] send: request
+2020-10-14 20:49:13,835 DEBUG   SenderThread:34843 [sender.py:send_request():97] send_request: status
+2020-10-14 20:49:13,839 DEBUG   SenderThread:34843 [connectionpool.py:_new_conn():955] Starting new HTTPS connection (1): api.wandb.ai:443
+2020-10-14 20:49:14,032 DEBUG   SenderThread:34843 [connectionpool.py:_make_request():428] https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
+2020-10-14 20:49:14,334 DEBUG   SenderThread:34843 [sender.py:send():88] send: stats
+2020-10-14 20:49:18,948 DEBUG   SenderThread:34843 [sender.py:send():88] send: stats
+2020-10-14 20:49:23,561 DEBUG   SenderThread:34843 [sender.py:send():88] send: stats
+2020-10-14 20:49:28,192 DEBUG   SenderThread:34843 [sender.py:send():88] send: stats
+2020-10-14 20:49:29,038 DEBUG   HandlerThread:34843 [handler.py:handle_request():54] handle_request: status
+2020-10-14 20:49:29,038 DEBUG   SenderThread:34843 [sender.py:send():88] send: request
+2020-10-14 20:49:29,039 DEBUG   SenderThread:34843 [sender.py:send_request():97] send_request: status
+2020-10-14 20:49:29,043 DEBUG   SenderThread:34843 [connectionpool.py:_new_conn():955] Starting new HTTPS connection (1): api.wandb.ai:443
+2020-10-14 20:49:29,241 DEBUG   SenderThread:34843 [connectionpool.py:_make_request():428] https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
+2020-10-14 20:49:32,806 DEBUG   SenderThread:34843 [sender.py:send():88] send: stats
+2020-10-14 20:49:37,429 DEBUG   SenderThread:34843 [sender.py:send():88] send: stats
+2020-10-14 20:49:42,040 DEBUG   SenderThread:34843 [sender.py:send():88] send: stats
+2020-10-14 20:49:44,247 DEBUG   HandlerThread:34843 [handler.py:handle_request():54] handle_request: status
+2020-10-14 20:49:44,247 DEBUG   SenderThread:34843 [sender.py:send():88] send: request
+2020-10-14 20:49:44,247 DEBUG   SenderThread:34843 [sender.py:send_request():97] send_request: status
+2020-10-14 20:49:44,252 DEBUG   SenderThread:34843 [connectionpool.py:_new_conn():955] Starting new HTTPS connection (1): api.wandb.ai:443
+2020-10-14 20:49:44,453 DEBUG   SenderThread:34843 [connectionpool.py:_make_request():428] https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
+2020-10-14 20:49:46,669 DEBUG   SenderThread:34843 [sender.py:send():88] send: stats
+2020-10-14 20:49:51,288 DEBUG   SenderThread:34843 [sender.py:send():88] send: stats
+2020-10-14 20:49:55,904 DEBUG   SenderThread:34843 [sender.py:send():88] send: stats
+2020-10-14 20:49:59,459 DEBUG   HandlerThread:34843 [handler.py:handle_request():54] handle_request: status
+2020-10-14 20:49:59,459 DEBUG   SenderThread:34843 [sender.py:send():88] send: request
+2020-10-14 20:49:59,460 DEBUG   SenderThread:34843 [sender.py:send_request():97] send_request: status
+2020-10-14 20:49:59,464 DEBUG   SenderThread:34843 [connectionpool.py:_new_conn():955] Starting new HTTPS connection (1): api.wandb.ai:443
+2020-10-14 20:49:59,667 DEBUG   SenderThread:34843 [connectionpool.py:_make_request():428] https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
+2020-10-14 20:50:00,513 DEBUG   SenderThread:34843 [sender.py:send():88] send: stats
+2020-10-14 20:50:05,125 DEBUG   SenderThread:34843 [sender.py:send():88] send: stats
+2020-10-14 20:50:09,744 DEBUG   SenderThread:34843 [sender.py:send():88] send: stats
diff --git a/JSS/wandb/run-20201014_185623-es6i30gb/run-es6i30gb.wandb b/JSS/wandb/run-20201014_185623-es6i30gb/run-es6i30gb.wandb
index 6b25ef1..0114685 100644
Binary files a/JSS/wandb/run-20201014_185623-es6i30gb/run-es6i30gb.wandb and b/JSS/wandb/run-20201014_185623-es6i30gb/run-es6i30gb.wandb differ
