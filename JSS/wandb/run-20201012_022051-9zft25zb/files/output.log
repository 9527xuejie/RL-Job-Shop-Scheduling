2020-10-12 02:20:55,181	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_8f7c2_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=3750)[0m 2020-10-12 02:20:57,929	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=3724)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3724)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3718)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3718)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3747)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3747)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3705)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3705)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3737)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3737)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3657)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3657)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3744)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3744)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3695)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3695)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3708)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3708)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3740)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3740)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3721)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3721)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3712)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3712)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3634)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3634)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3733)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3733)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3685)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3685)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3637)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3637)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3753)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3753)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3693)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3693)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3723)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3723)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3707)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3707)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3690)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3690)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3741)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3741)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3697)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3697)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3726)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3726)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3643)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3643)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3732)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3732)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3722)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3722)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3715)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3715)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3731)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3731)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3730)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3730)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3743)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3743)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3758)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3758)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3756)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3756)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3660)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3660)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3745)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3745)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3698)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3698)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3631)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3631)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3748)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3748)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3644)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3644)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3635)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3635)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3651)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3651)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3688)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3688)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3752)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3752)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3650)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3650)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3629)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3629)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3648)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3648)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3735)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3735)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3706)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3706)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3647)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3647)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3645)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3645)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3682)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3682)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3633)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3633)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3632)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3632)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3728)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3728)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3717)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3717)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3653)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3653)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3711)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3711)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3701)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3701)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3640)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3640)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3630)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3630)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3652)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3652)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3703)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3703)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3659)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3659)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3713)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3713)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3636)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3636)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3662)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3662)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3654)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3654)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3639)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3639)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3710)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3710)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3704)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3704)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3702)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3702)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3628)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3628)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3700)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3700)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3716)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3716)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3642)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3642)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3661)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3661)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3649)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3649)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3719)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3719)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3646)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3646)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_8f7c2_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-12_02-21-35
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 4a162891798e400a8397a11715d132af
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 1.183392624060313
        entropy_coeff: 0.0001
        kl: 0.006190886371769011
        model: {}
        policy_loss: -0.012005629949271679
        total_loss: 502.23646545410156
        vf_explained_var: 0.5664147734642029
        vf_loss: 502.24672444661456
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.24473684210527
    gpu_util_percent0: 0.285
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.581578947368421
    vram_util_percent0: 0.08846731456387776
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 3750
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17240728924178017
    mean_env_wait_ms: 1.18165284404419
    mean_inference_ms: 6.121143954666575
    mean_raw_obs_processing_ms: 0.4664748551927257
  time_since_restore: 32.644731760025024
  time_this_iter_s: 32.644731760025024
  time_total_s: 32.644731760025024
  timers:
    learn_throughput: 7001.52
    learn_time_ms: 23108.125
    sample_throughput: 17077.669
    sample_time_ms: 9473.892
    update_time_ms: 29.25
  timestamp: 1602469295
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 8f7c2_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8f7c2_00000 | RUNNING  | 172.17.0.4:3750 |      1 |          32.6447 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8f7c2_00000:
  custom_metrics:
    time_step_max: 4088
    time_step_mean: 3613.6944444444443
    time_step_min: 3373
  date: 2020-10-12_02-22-06
  done: false
  episode_len_mean: 890.9462025316456
  episode_reward_max: 260.8686868686872
  episode_reward_mean: 217.04149085794631
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 4a162891798e400a8397a11715d132af
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 1.1532918711503346
        entropy_coeff: 0.0001
        kl: 0.007446491237108906
        model: {}
        policy_loss: -0.011935493520771464
        total_loss: 124.85494486490886
        vf_explained_var: 0.8155218958854675
        vf_loss: 124.86476071675618
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.119444444444447
    gpu_util_percent0: 0.3452777777777778
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7666666666666675
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 3750
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16728511132703794
    mean_env_wait_ms: 1.1750682978541807
    mean_inference_ms: 5.778064454953939
    mean_raw_obs_processing_ms: 0.4518821541026054
  time_since_restore: 63.26314067840576
  time_this_iter_s: 30.618408918380737
  time_total_s: 63.26314067840576
  timers:
    learn_throughput: 7018.487
    learn_time_ms: 23052.261
    sample_throughput: 19013.302
    sample_time_ms: 8509.411
    update_time_ms: 28.459
  timestamp: 1602469326
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 8f7c2_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8f7c2_00000 | RUNNING  | 172.17.0.4:3750 |      2 |          63.2631 | 323584 |  217.041 |              260.869 |              145.717 |            890.946 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8f7c2_00000:
  custom_metrics:
    time_step_max: 4088
    time_step_mean: 3609.7466367713005
    time_step_min: 3341
  date: 2020-10-12_02-22-36
  done: false
  episode_len_mean: 888.373417721519
  episode_reward_max: 260.8686868686872
  episode_reward_mean: 218.09058943869047
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 4a162891798e400a8397a11715d132af
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 1.1454775134722393
        entropy_coeff: 0.0001
        kl: 0.008900574563692013
        model: {}
        policy_loss: -0.015313072168889144
        total_loss: 51.573896408081055
        vf_explained_var: 0.908707857131958
        vf_loss: 51.586653073628746
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.422857142857143
    gpu_util_percent0: 0.39285714285714285
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7800000000000002
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 3750
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16403503044310816
    mean_env_wait_ms: 1.1719318242281904
    mean_inference_ms: 5.5453522864125775
    mean_raw_obs_processing_ms: 0.4414942304180572
  time_since_restore: 93.26617765426636
  time_this_iter_s: 30.003036975860596
  time_total_s: 93.26617765426636
  timers:
    learn_throughput: 7041.108
    learn_time_ms: 22978.201
    sample_throughput: 20128.024
    sample_time_ms: 8038.146
    update_time_ms: 27.16
  timestamp: 1602469356
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 8f7c2_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8f7c2_00000 | RUNNING  | 172.17.0.4:3750 |      3 |          93.2662 | 485376 |  218.091 |              260.869 |              145.717 |            888.373 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8f7c2_00000:
  custom_metrics:
    time_step_max: 4088
    time_step_mean: 3602.8543046357618
    time_step_min: 3292
  date: 2020-10-12_02-23-06
  done: false
  episode_len_mean: 883.0870253164557
  episode_reward_max: 268.141414141414
  episode_reward_mean: 220.22738460554896
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 4a162891798e400a8397a11715d132af
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 1.129334717988968
        entropy_coeff: 0.0001
        kl: 0.008946505996088186
        model: {}
        policy_loss: -0.018506193824578077
        total_loss: 35.24948660532633
        vf_explained_var: 0.9321489334106445
        vf_loss: 35.26542091369629
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.9
    gpu_util_percent0: 0.34714285714285714
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7771428571428576
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 3750
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16168527882093486
    mean_env_wait_ms: 1.1707625472509744
    mean_inference_ms: 5.378355153526429
    mean_raw_obs_processing_ms: 0.43359517443545825
  time_since_restore: 123.33655762672424
  time_this_iter_s: 30.070379972457886
  time_total_s: 123.33655762672424
  timers:
    learn_throughput: 7028.57
    learn_time_ms: 23019.192
    sample_throughput: 20901.22
    sample_time_ms: 7740.792
    update_time_ms: 26.371
  timestamp: 1602469386
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 8f7c2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8f7c2_00000 | RUNNING  | 172.17.0.4:3750 |      4 |          123.337 | 647168 |  220.227 |              268.141 |              145.717 |            883.087 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8f7c2_00000:
  custom_metrics:
    time_step_max: 4088
    time_step_mean: 3589.3884514435695
    time_step_min: 3279
  date: 2020-10-12_02-23-36
  done: false
  episode_len_mean: 879.220253164557
  episode_reward_max: 269.2020202020201
  episode_reward_mean: 222.27796956910862
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 4a162891798e400a8397a11715d132af
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 1.0972143014272053
        entropy_coeff: 0.0001
        kl: 0.009543176429967085
        model: {}
        policy_loss: -0.017212009008896228
        total_loss: 23.500564416249592
        vf_explained_var: 0.9568281769752502
        vf_loss: 23.515023231506348
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.194285714285712
    gpu_util_percent0: 0.38771428571428573
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7771428571428576
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 3750
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15993513215111482
    mean_env_wait_ms: 1.1706815582043075
    mean_inference_ms: 5.253001240270327
    mean_raw_obs_processing_ms: 0.4274840569470526
  time_since_restore: 153.20539593696594
  time_this_iter_s: 29.8688383102417
  time_total_s: 153.20539593696594
  timers:
    learn_throughput: 7031.424
    learn_time_ms: 23009.847
    sample_throughput: 21406.929
    sample_time_ms: 7557.927
    update_time_ms: 24.918
  timestamp: 1602469416
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 8f7c2_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8f7c2_00000 | RUNNING  | 172.17.0.4:3750 |      5 |          153.205 | 808960 |  222.278 |              269.202 |              145.717 |             879.22 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8f7c2_00000:
  custom_metrics:
    time_step_max: 4088
    time_step_mean: 3567.829268292683
    time_step_min: 3261
  date: 2020-10-12_02-24-06
  done: false
  episode_len_mean: 869.7504570383912
  episode_reward_max: 272.2323232323232
  episode_reward_mean: 225.94389045851548
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 304
  episodes_total: 1094
  experiment_id: 4a162891798e400a8397a11715d132af
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 1.085921933253606
        entropy_coeff: 0.0001
        kl: 0.008905718723932901
        model: {}
        policy_loss: -0.016556774460089702
        total_loss: 27.29594135284424
        vf_explained_var: 0.9652183055877686
        vf_loss: 27.309934457143147
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.662857142857145
    gpu_util_percent0: 0.34885714285714287
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.774285714285715
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 3750
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15764631170454343
    mean_env_wait_ms: 1.1730277369264108
    mean_inference_ms: 5.0894425459167945
    mean_raw_obs_processing_ms: 0.41966828025401737
  time_since_restore: 183.23990321159363
  time_this_iter_s: 30.034507274627686
  time_total_s: 183.23990321159363
  timers:
    learn_throughput: 7028.532
    learn_time_ms: 23019.315
    sample_throughput: 21737.291
    sample_time_ms: 7443.062
    update_time_ms: 28.242
  timestamp: 1602469446
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 8f7c2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8f7c2_00000 | RUNNING  | 172.17.0.4:3750 |      6 |           183.24 | 970752 |  225.944 |              272.232 |              145.717 |             869.75 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8f7c2_00000:
  custom_metrics:
    time_step_max: 4088
    time_step_mean: 3553.224919093851
    time_step_min: 3249
  date: 2020-10-12_02-24-36
  done: false
  episode_len_mean: 864.0134493670886
  episode_reward_max: 274.35353535353516
  episode_reward_mean: 227.80625879043583
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 170
  episodes_total: 1264
  experiment_id: 4a162891798e400a8397a11715d132af
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 1.0837466716766357
        entropy_coeff: 0.0001
        kl: 0.009661028937747082
        model: {}
        policy_loss: -0.016830823578250904
        total_loss: 16.734761714935303
        vf_explained_var: 0.9675487875938416
        vf_loss: 16.74880250295003
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.941176470588232
    gpu_util_percent0: 0.4194117647058823
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.785294117647059
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 3750
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15672561729470788
    mean_env_wait_ms: 1.1744036849851758
    mean_inference_ms: 5.024360791818861
    mean_raw_obs_processing_ms: 0.41645035264117797
  time_since_restore: 213.04717922210693
  time_this_iter_s: 29.807276010513306
  time_total_s: 213.04717922210693
  timers:
    learn_throughput: 7032.368
    learn_time_ms: 23006.76
    sample_throughput: 22011.764
    sample_time_ms: 7350.251
    update_time_ms: 27.665
  timestamp: 1602469476
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 8f7c2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8f7c2_00000 | RUNNING  | 172.17.0.4:3750 |      7 |          213.047 | 1132544 |  227.806 |              274.354 |              145.717 |            864.013 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8f7c2_00000:
  custom_metrics:
    time_step_max: 4088
    time_step_mean: 3541.638450502152
    time_step_min: 3199
  date: 2020-10-12_02-25-06
  done: false
  episode_len_mean: 859.3846694796061
  episode_reward_max: 287.686868686869
  episode_reward_mean: 229.60233133017925
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 4a162891798e400a8397a11715d132af
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 1.059142142534256
        entropy_coeff: 0.0001
        kl: 0.00896404117035369
        model: {}
        policy_loss: -0.016309842467308044
        total_loss: 14.75088620185852
        vf_explained_var: 0.9700682759284973
        vf_loss: 14.764612674713135
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.654285714285713
    gpu_util_percent0: 0.3954285714285714
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.782857142857143
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 3750
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1560034088299318
    mean_env_wait_ms: 1.1756341123325669
    mean_inference_ms: 4.972833428842115
    mean_raw_obs_processing_ms: 0.4138671302189227
  time_since_restore: 243.03253054618835
  time_this_iter_s: 29.98535132408142
  time_total_s: 243.03253054618835
  timers:
    learn_throughput: 7030.216
    learn_time_ms: 23013.802
    sample_throughput: 22201.423
    sample_time_ms: 7287.461
    update_time_ms: 26.62
  timestamp: 1602469506
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 8f7c2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8f7c2_00000 | RUNNING  | 172.17.0.4:3750 |      8 |          243.033 | 1294336 |  229.602 |              287.687 |              145.717 |            859.385 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8f7c2_00000:
  custom_metrics:
    time_step_max: 4088
    time_step_mean: 3528.1903536977493
    time_step_min: 3199
  date: 2020-10-12_02-25-36
  done: false
  episode_len_mean: 854.3790271636134
  episode_reward_max: 287.686868686869
  episode_reward_mean: 231.39013636044575
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 161
  episodes_total: 1583
  experiment_id: 4a162891798e400a8397a11715d132af
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 1.0155416131019592
        entropy_coeff: 0.0001
        kl: 0.008834983843068281
        model: {}
        policy_loss: -0.01620504529758667
        total_loss: 17.08004395167033
        vf_explained_var: 0.9664523601531982
        vf_loss: 17.09369961420695
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.36
    gpu_util_percent0: 0.3345714285714285
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.782857142857143
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 3750
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15536368319450225
    mean_env_wait_ms: 1.176978418097139
    mean_inference_ms: 4.9270807588734264
    mean_raw_obs_processing_ms: 0.411492382859526
  time_since_restore: 272.98809003829956
  time_this_iter_s: 29.955559492111206
  time_total_s: 272.98809003829956
  timers:
    learn_throughput: 7030.541
    learn_time_ms: 23012.739
    sample_throughput: 22342.832
    sample_time_ms: 7241.338
    update_time_ms: 26.343
  timestamp: 1602469536
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 8f7c2_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8f7c2_00000 | RUNNING  | 172.17.0.4:3750 |      9 |          272.988 | 1456128 |   231.39 |              287.687 |              145.717 |            854.379 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8f7c2_00000:
  custom_metrics:
    time_step_max: 4088
    time_step_mean: 3507.295600858369
    time_step_min: 3199
  date: 2020-10-12_02-26-06
  done: false
  episode_len_mean: 845.2832980972515
  episode_reward_max: 287.686868686869
  episode_reward_mean: 234.48687189014873
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 309
  episodes_total: 1892
  experiment_id: 4a162891798e400a8397a11715d132af
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 0.99531489610672
        entropy_coeff: 0.0001
        kl: 0.0079667828977108
        model: {}
        policy_loss: -0.016625145382325474
        total_loss: 21.070435047149658
        vf_explained_var: 0.9718566536903381
        vf_loss: 21.084770043690998
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.251428571428576
    gpu_util_percent0: 0.2591428571428572
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7771428571428576
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 3750
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15437902378318777
    mean_env_wait_ms: 1.1800816917426507
    mean_inference_ms: 4.856613475951293
    mean_raw_obs_processing_ms: 0.4079676725423794
  time_since_restore: 303.0880072116852
  time_this_iter_s: 30.09991717338562
  time_total_s: 303.0880072116852
  timers:
    learn_throughput: 7023.175
    learn_time_ms: 23036.875
    sample_throughput: 22488.626
    sample_time_ms: 7194.392
    update_time_ms: 25.518
  timestamp: 1602469566
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 8f7c2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8f7c2_00000 | RUNNING  | 172.17.0.4:3750 |     10 |          303.088 | 1617920 |  234.487 |              287.687 |              145.717 |            845.283 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8f7c2_00000:
  custom_metrics:
    time_step_max: 4088
    time_step_mean: 3498.383514313919
    time_step_min: 3192
  date: 2020-10-12_02-26-36
  done: false
  episode_len_mean: 841.0389483933787
  episode_reward_max: 287.686868686869
  episode_reward_mean: 236.17835610240664
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 162
  episodes_total: 2054
  experiment_id: 4a162891798e400a8397a11715d132af
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 0.9929528733094534
        entropy_coeff: 0.0001
        kl: 0.00807238214959701
        model: {}
        policy_loss: -0.017932548633931827
        total_loss: 11.670536518096924
        vf_explained_var: 0.9753634929656982
        vf_loss: 11.68614673614502
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.65428571428571
    gpu_util_percent0: 0.3011428571428571
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.782857142857143
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 3750
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15394905027564168
    mean_env_wait_ms: 1.1815438803610339
    mean_inference_ms: 4.826144729354554
    mean_raw_obs_processing_ms: 0.40641254510650954
  time_since_restore: 333.0463111400604
  time_this_iter_s: 29.958303928375244
  time_total_s: 333.0463111400604
  timers:
    learn_throughput: 7023.853
    learn_time_ms: 23034.652
    sample_throughput: 23364.851
    sample_time_ms: 6924.589
    update_time_ms: 26.586
  timestamp: 1602469596
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 8f7c2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8f7c2_00000 | RUNNING  | 172.17.0.4:3750 |     11 |          333.046 | 1779712 |  236.178 |              287.687 |              145.717 |            841.039 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8f7c2_00000:
  custom_metrics:
    time_step_max: 4088
    time_step_mean: 3489.4166666666665
    time_step_min: 3174
  date: 2020-10-12_02-27-07
  done: false
  episode_len_mean: 837.5257685352622
  episode_reward_max: 289.05050505050497
  episode_reward_mean: 237.35616563464652
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 4a162891798e400a8397a11715d132af
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 0.9715353200833002
        entropy_coeff: 0.0001
        kl: 0.0087262048618868
        model: {}
        policy_loss: -0.017244145506992936
        total_loss: 11.715685526529947
        vf_explained_var: 0.9753227233886719
        vf_loss: 11.730408906936646
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.705714285714286
    gpu_util_percent0: 0.3165714285714285
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7857142857142865
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 3750
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1535712211486131
    mean_env_wait_ms: 1.1828955736279867
    mean_inference_ms: 4.799307554421485
    mean_raw_obs_processing_ms: 0.4050065169420952
  time_since_restore: 363.16482377052307
  time_this_iter_s: 30.118512630462646
  time_total_s: 363.16482377052307
  timers:
    learn_throughput: 7018.301
    learn_time_ms: 23052.873
    sample_throughput: 23597.456
    sample_time_ms: 6856.332
    update_time_ms: 26.046
  timestamp: 1602469627
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 8f7c2_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8f7c2_00000 | RUNNING  | 172.17.0.4:3750 |     12 |          363.165 | 1941504 |  237.356 |              289.051 |              145.717 |            837.526 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8f7c2_00000:
  custom_metrics:
    time_step_max: 4088
    time_step_mean: 3477.312964492155
    time_step_min: 3174
  date: 2020-10-12_02-27-37
  done: false
  episode_len_mean: 832.9628571428572
  episode_reward_max: 289.05050505050497
  episode_reward_mean: 239.16472892187164
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 238
  episodes_total: 2450
  experiment_id: 4a162891798e400a8397a11715d132af
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 0.9326319247484207
        entropy_coeff: 0.0001
        kl: 0.008634898656358322
        model: {}
        policy_loss: -0.017584041071434815
        total_loss: 14.788169304529825
        vf_explained_var: 0.9777825474739075
        vf_loss: 14.803256273269653
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.134285714285717
    gpu_util_percent0: 0.364
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.774285714285715
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 3750
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1530830649296296
    mean_env_wait_ms: 1.1850460614260667
    mean_inference_ms: 4.763235474368383
    mean_raw_obs_processing_ms: 0.4031418166070282
  time_since_restore: 393.1061325073242
  time_this_iter_s: 29.941308736801147
  time_total_s: 393.1061325073242
  timers:
    learn_throughput: 7011.623
    learn_time_ms: 23074.83
    sample_throughput: 23695.406
    sample_time_ms: 6827.99
    update_time_ms: 25.563
  timestamp: 1602469657
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 8f7c2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8f7c2_00000 | RUNNING  | 172.17.0.4:3750 |     13 |          393.106 | 2103296 |  239.165 |              289.051 |              145.717 |            832.963 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8f7c2_00000:
  custom_metrics:
    time_step_max: 4088
    time_step_mean: 3467.1346877351393
    time_step_min: 3171
  date: 2020-10-12_02-28-07
  done: false
  episode_len_mean: 829.0740878629933
  episode_reward_max: 295.26262626262576
  episode_reward_mean: 240.6301887076272
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 236
  episodes_total: 2686
  experiment_id: 4a162891798e400a8397a11715d132af
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 0.9424490580956141
        entropy_coeff: 0.0001
        kl: 0.007455545865620176
        model: {}
        policy_loss: -0.014552954671671614
        total_loss: 12.702921787897745
        vf_explained_var: 0.9777204394340515
        vf_loss: 12.71533211072286
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.18529411764706
    gpu_util_percent0: 0.43000000000000005
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.770588235294117
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 3750
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15264571630664384
    mean_env_wait_ms: 1.1868776844336701
    mean_inference_ms: 4.733250979472718
    mean_raw_obs_processing_ms: 0.4015576405169078
  time_since_restore: 422.8217918872833
  time_this_iter_s: 29.715659379959106
  time_total_s: 422.8217918872833
  timers:
    learn_throughput: 7019.028
    learn_time_ms: 23050.486
    sample_throughput: 23737.2
    sample_time_ms: 6815.968
    update_time_ms: 25.3
  timestamp: 1602469687
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 8f7c2_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8f7c2_00000 | RUNNING  | 172.17.0.4:3750 |     14 |          422.822 | 2265088 |   240.63 |              295.263 |              145.717 |            829.074 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8f7c2_00000:
  custom_metrics:
    time_step_max: 4088
    time_step_mean: 3460.892400568182
    time_step_min: 3136
  date: 2020-10-12_02-28-36
  done: false
  episode_len_mean: 826.6845991561181
  episode_reward_max: 295.26262626262576
  episode_reward_mean: 241.6654200230149
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: 4a162891798e400a8397a11715d132af
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 0.9254664679368337
        entropy_coeff: 0.0001
        kl: 0.007928619743324816
        model: {}
        policy_loss: -0.016745945167106886
        total_loss: 10.117039680480957
        vf_explained_var: 0.9777747988700867
        vf_loss: 10.131499449412027
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.805714285714284
    gpu_util_percent0: 0.3862857142857143
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.774285714285715
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 3750
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15239136253826965
    mean_env_wait_ms: 1.1880250605018352
    mean_inference_ms: 4.715024576038494
    mean_raw_obs_processing_ms: 0.4005941490022876
  time_since_restore: 452.68989157676697
  time_this_iter_s: 29.868099689483643
  time_total_s: 452.68989157676697
  timers:
    learn_throughput: 7019.386
    learn_time_ms: 23049.31
    sample_throughput: 23743.808
    sample_time_ms: 6814.071
    update_time_ms: 25.515
  timestamp: 1602469716
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 8f7c2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8f7c2_00000 | RUNNING  | 172.17.0.4:3750 |     15 |           452.69 | 2426880 |  241.665 |              295.263 |              145.717 |            826.685 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8f7c2_00000:
  custom_metrics:
    time_step_max: 4088
    time_step_mean: 3453.750582750583
    time_step_min: 3136
  date: 2020-10-12_02-29-06
  done: false
  episode_len_mean: 823.9204882876938
  episode_reward_max: 295.26262626262576
  episode_reward_mean: 242.7061642488894
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 187
  episodes_total: 3031
  experiment_id: 4a162891798e400a8397a11715d132af
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 0.8821414212385813
        entropy_coeff: 0.0001
        kl: 0.008632305543869734
        model: {}
        policy_loss: -0.014175740138549978
        total_loss: 12.378796259562174
        vf_explained_var: 0.9782941937446594
        vf_loss: 12.390470584233602
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.365714285714283
    gpu_util_percent0: 0.3291428571428571
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.780000000000001
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 3750
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.152119838983202
    mean_env_wait_ms: 1.189382233406411
    mean_inference_ms: 4.695138421769177
    mean_raw_obs_processing_ms: 0.39952916671398087
  time_since_restore: 482.5642774105072
  time_this_iter_s: 29.874385833740234
  time_total_s: 482.5642774105072
  timers:
    learn_throughput: 7024.118
    learn_time_ms: 23033.78
    sample_throughput: 23738.058
    sample_time_ms: 6815.722
    update_time_ms: 22.774
  timestamp: 1602469746
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 8f7c2_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8f7c2_00000 | RUNNING  | 172.17.0.4:3750 |     16 |          482.564 | 2588672 |  242.706 |              295.263 |              145.717 |             823.92 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8f7c2_00000:
  custom_metrics:
    time_step_max: 4088
    time_step_mean: 3443.6285714285714
    time_step_min: 3130
  date: 2020-10-12_02-29-37
  done: false
  episode_len_mean: 819.6983122362869
  episode_reward_max: 295.26262626262576
  episode_reward_mean: 244.23275247958784
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 287
  episodes_total: 3318
  experiment_id: 4a162891798e400a8397a11715d132af
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 0.8938080618778864
        entropy_coeff: 0.0001
        kl: 0.007519473088905215
        model: {}
        policy_loss: -0.014826448905902604
        total_loss: 12.312981685002645
        vf_explained_var: 0.9802420735359192
        vf_loss: 12.325641552607218
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.357142857142858
    gpu_util_percent0: 0.2651428571428572
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.774285714285715
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 3750
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1517352686456025
    mean_env_wait_ms: 1.1913467695675073
    mean_inference_ms: 4.6681687498925175
    mean_raw_obs_processing_ms: 0.3980912324224699
  time_since_restore: 512.5958225727081
  time_this_iter_s: 30.031545162200928
  time_total_s: 512.5958225727081
  timers:
    learn_throughput: 7020.376
    learn_time_ms: 23046.059
    sample_throughput: 23702.157
    sample_time_ms: 6826.045
    update_time_ms: 22.107
  timestamp: 1602469777
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 8f7c2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8f7c2_00000 | RUNNING  | 172.17.0.4:3750 |     17 |          512.596 | 2750464 |  244.233 |              295.263 |              145.717 |            819.698 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8f7c2_00000:
  custom_metrics:
    time_step_max: 4088
    time_step_mean: 3438.7505800464037
    time_step_min: 3130
  date: 2020-10-12_02-30-07
  done: false
  episode_len_mean: 817.7154775604142
  episode_reward_max: 295.26262626262576
  episode_reward_mean: 244.92424533017163
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 3476
  experiment_id: 4a162891798e400a8397a11715d132af
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 0.8822861065467199
        entropy_coeff: 0.0001
        kl: 0.008465220996489128
        model: {}
        policy_loss: -0.018576244086337585
        total_loss: 8.83013359705607
        vf_explained_var: 0.9810693860054016
        vf_loss: 8.846258401870728
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.242857142857147
    gpu_util_percent0: 0.2894285714285714
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7857142857142856
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 3750
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15154776463665343
    mean_env_wait_ms: 1.1923313676681278
    mean_inference_ms: 4.654866241697075
    mean_raw_obs_processing_ms: 0.39737621679361473
  time_since_restore: 542.621728181839
  time_this_iter_s: 30.02590560913086
  time_total_s: 542.621728181839
  timers:
    learn_throughput: 7022.822
    learn_time_ms: 23038.033
    sample_throughput: 23663.511
    sample_time_ms: 6837.193
    update_time_ms: 22.066
  timestamp: 1602469807
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 8f7c2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8f7c2_00000 | RUNNING  | 172.17.0.4:3750 |     18 |          542.622 | 2912256 |  244.924 |              295.263 |              145.717 |            817.715 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8f7c2_00000:
  custom_metrics:
    time_step_max: 4088
    time_step_mean: 3434.485651214128
    time_step_min: 3128
  date: 2020-10-12_02-30-37
  done: false
  episode_len_mean: 815.539156626506
  episode_reward_max: 295.26262626262576
  episode_reward_mean: 245.74164979477132
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 176
  episodes_total: 3652
  experiment_id: 4a162891798e400a8397a11715d132af
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 0.8445806403954824
        entropy_coeff: 0.0001
        kl: 0.009025353860730926
        model: {}
        policy_loss: -0.01688784678117372
        total_loss: 10.9605819384257
        vf_explained_var: 0.9795268177986145
        vf_loss: 10.974846919377645
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.497142857142858
    gpu_util_percent0: 0.3211428571428572
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.782857142857143
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 3750
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15135717612546185
    mean_env_wait_ms: 1.193418682460028
    mean_inference_ms: 4.641031076257839
    mean_raw_obs_processing_ms: 0.3966206910270281
  time_since_restore: 572.4741766452789
  time_this_iter_s: 29.85244846343994
  time_total_s: 572.4741766452789
  timers:
    learn_throughput: 7028.494
    learn_time_ms: 23019.44
    sample_throughput: 23664.559
    sample_time_ms: 6836.89
    update_time_ms: 28.895
  timestamp: 1602469837
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 8f7c2_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8f7c2_00000 | RUNNING  | 172.17.0.4:3750 |     19 |          572.474 | 3074048 |  245.742 |              295.263 |              145.717 |            815.539 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8f7c2_00000:
  custom_metrics:
    time_step_max: 4088
    time_step_mean: 3426.510584034685
    time_step_min: 3128
  date: 2020-10-12_02-31-07
  done: true
  episode_len_mean: 812.3740187389212
  episode_reward_max: 295.26262626262576
  episode_reward_mean: 246.96133019227466
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 297
  episodes_total: 3949
  experiment_id: 4a162891798e400a8397a11715d132af
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 0.8423571238915125
        entropy_coeff: 0.0001
        kl: 0.00841277368211498
        model: {}
        policy_loss: -0.015481088038844367
        total_loss: 10.911441882451376
        vf_explained_var: 0.9832115173339844
        vf_loss: 10.924483299255371
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.644117647058827
    gpu_util_percent0: 0.3244117647058824
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7735294117647054
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 3750
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15105329078403748
    mean_env_wait_ms: 1.1951639129721687
    mean_inference_ms: 4.620018362994192
    mean_raw_obs_processing_ms: 0.39548246373874263
  time_since_restore: 602.4649391174316
  time_this_iter_s: 29.99076247215271
  time_total_s: 602.4649391174316
  timers:
    learn_throughput: 7034.668
    learn_time_ms: 22999.238
    sample_throughput: 23637.778
    sample_time_ms: 6844.637
    update_time_ms: 30.125
  timestamp: 1602469867
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 8f7c2_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8f7c2_00000 | TERMINATED |       |     20 |          602.465 | 3235840 |  246.961 |              295.263 |              145.717 |            812.374 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8f7c2_00000 | TERMINATED |       |     20 |          602.465 | 3235840 |  246.961 |              295.263 |              145.717 |            812.374 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


