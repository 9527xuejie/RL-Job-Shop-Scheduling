2020-10-11 22:04:49,426	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_c8c0d_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=33831)[0m 2020-10-11 22:04:52,210	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=33776)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33776)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33824)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33824)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33807)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33807)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33830)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33830)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33813)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33813)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33790)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33790)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33797)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33797)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33783)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33783)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33791)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33791)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33837)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33837)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33800)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33800)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33827)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33827)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33786)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33786)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33821)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33821)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33799)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33799)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33823)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33823)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33829)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33829)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33723)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33723)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33713)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33713)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33779)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33779)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33725)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33725)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33721)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33721)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33705)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33705)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33727)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33727)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33717)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33717)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33724)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33724)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33774)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33774)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33775)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33775)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33719)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33719)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33789)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33789)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33712)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33712)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33784)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33784)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33777)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33777)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33728)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33728)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33814)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33814)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33715)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33715)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33708)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33708)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33718)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33718)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33703)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33703)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33735)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33735)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33707)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33707)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33763)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33763)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33704)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33704)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33808)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33808)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33805)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33805)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33726)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33726)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33767)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33767)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33794)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33794)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33803)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33803)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33702)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33702)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33770)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33770)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33732)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33732)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33722)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33722)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33706)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33706)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33736)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33736)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33773)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33773)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33714)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33714)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33816)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33816)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33709)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33709)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33730)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33730)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33720)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33720)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33781)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33781)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33785)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33785)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33834)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33834)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33811)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33811)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33780)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33780)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33710)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33710)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33788)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33788)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33771)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33771)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33778)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33778)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33796)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33796)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33762)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33762)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33815)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33815)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33765)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33765)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33782)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33782)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33734)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33734)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33768)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33768)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33801)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33801)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=33793)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33793)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_c8c0d_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-11_22-05-28
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: b35c6d5ee75a4d3c9572e42579560903
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.182049185037613
        entropy_coeff: 0.0001
        kl: 0.007551352377049625
        model: {}
        policy_loss: -0.010913141391938552
        total_loss: 502.23646545410156
        vf_explained_var: 0.5664147734642029
        vf_loss: 502.24672444661456
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.432432432432428
    gpu_util_percent0: 0.30675675675675673
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.581081081081081
    vram_util_percent0: 0.08933146002676999
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33831
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16674774301828665
    mean_env_wait_ms: 1.1671363928318759
    mean_inference_ms: 5.406368584793341
    mean_raw_obs_processing_ms: 0.4415674760187802
  time_since_restore: 31.127429008483887
  time_this_iter_s: 31.127429008483887
  time_total_s: 31.127429008483887
  timers:
    learn_throughput: 7200.691
    learn_time_ms: 22468.956
    sample_throughput: 18823.104
    sample_time_ms: 8595.394
    update_time_ms: 29.16
  timestamp: 1602453928
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: c8c0d_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c8c0d_00000 | RUNNING  | 172.17.0.4:33831 |      1 |          31.1274 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c8c0d_00000:
  custom_metrics:
    time_step_max: 4312
    time_step_mean: 3632.8541666666665
    time_step_min: 3314
  date: 2020-10-11_22-05-58
  done: false
  episode_len_mean: 889.3101265822785
  episode_reward_max: 269.5050505050499
  episode_reward_mean: 215.79436772791178
  episode_reward_min: 112.68686868686893
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: b35c6d5ee75a4d3c9572e42579560903
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1453526318073273
        entropy_coeff: 0.0001
        kl: 0.009452068867782751
        model: {}
        policy_loss: -0.011007799611737331
        total_loss: 134.11668078104654
        vf_explained_var: 0.8060848712921143
        vf_loss: 134.1268571217855
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.80857142857143
    gpu_util_percent0: 0.2657142857142857
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7628571428571433
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33831
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16298400257973292
    mean_env_wait_ms: 1.1658205870294556
    mean_inference_ms: 5.2563436039125255
    mean_raw_obs_processing_ms: 0.43327431025791313
  time_since_restore: 61.266196966171265
  time_this_iter_s: 30.138767957687378
  time_total_s: 61.266196966171265
  timers:
    learn_throughput: 7213.843
    learn_time_ms: 22427.992
    sample_throughput: 19910.362
    sample_time_ms: 8126.02
    update_time_ms: 34.758
  timestamp: 1602453958
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: c8c0d_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c8c0d_00000 | RUNNING  | 172.17.0.4:33831 |      2 |          61.2662 | 323584 |  215.794 |              269.505 |              112.687 |             889.31 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c8c0d_00000:
  custom_metrics:
    time_step_max: 4522
    time_step_mean: 3628.8699551569507
    time_step_min: 3314
  date: 2020-10-11_22-06-28
  done: false
  episode_len_mean: 885.3438818565401
  episode_reward_max: 269.5050505050499
  episode_reward_mean: 216.5524229638152
  episode_reward_min: 80.86868686868688
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: b35c6d5ee75a4d3c9572e42579560903
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1347288091977437
        entropy_coeff: 0.0001
        kl: 0.010311113592858115
        model: {}
        policy_loss: -0.015043995168525726
        total_loss: 54.328972498575844
        vf_explained_var: 0.9071841239929199
        vf_loss: 54.34309800465902
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.142857142857142
    gpu_util_percent0: 0.45228571428571435
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7714285714285722
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33831
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16036798786566014
    mean_env_wait_ms: 1.1659678474005444
    mean_inference_ms: 5.120628653823777
    mean_raw_obs_processing_ms: 0.4260360700423862
  time_since_restore: 90.83030652999878
  time_this_iter_s: 29.564109563827515
  time_total_s: 90.83030652999878
  timers:
    learn_throughput: 7222.791
    learn_time_ms: 22400.204
    sample_throughput: 20749.59
    sample_time_ms: 7797.359
    update_time_ms: 31.374
  timestamp: 1602453988
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: c8c0d_00000
  
== Status ==
Memory usage on this node: 28.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c8c0d_00000 | RUNNING  | 172.17.0.4:33831 |      3 |          90.8303 | 485376 |  216.552 |              269.505 |              80.8687 |            885.344 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c8c0d_00000:
  custom_metrics:
    time_step_max: 4522
    time_step_mean: 3619.6324503311257
    time_step_min: 3314
  date: 2020-10-11_22-06-57
  done: false
  episode_len_mean: 881.9113924050633
  episode_reward_max: 269.5050505050499
  episode_reward_mean: 218.1368590973019
  episode_reward_min: 80.86868686868688
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: b35c6d5ee75a4d3c9572e42579560903
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1214884221553802
        entropy_coeff: 0.0001
        kl: 0.00854602719967564
        model: {}
        policy_loss: -0.014675869412409762
        total_loss: 37.11895306905111
        vf_explained_var: 0.9335862994194031
        vf_loss: 37.13288593292236
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.897058823529413
    gpu_util_percent0: 0.33705882352941174
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7764705882352945
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33831
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1585426770655388
    mean_env_wait_ms: 1.1666232888012298
    mean_inference_ms: 5.01847130836946
    mean_raw_obs_processing_ms: 0.4205202904372033
  time_since_restore: 120.1779716014862
  time_this_iter_s: 29.347665071487427
  time_total_s: 120.1779716014862
  timers:
    learn_throughput: 7231.052
    learn_time_ms: 22374.613
    sample_throughput: 21319.215
    sample_time_ms: 7589.022
    update_time_ms: 31.922
  timestamp: 1602454017
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: c8c0d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c8c0d_00000 | RUNNING  | 172.17.0.4:33831 |      4 |          120.178 | 647168 |  218.137 |              269.505 |              80.8687 |            881.911 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c8c0d_00000:
  custom_metrics:
    time_step_max: 4522
    time_step_mean: 3612.259842519685
    time_step_min: 3314
  date: 2020-10-11_22-07-27
  done: false
  episode_len_mean: 877.3860759493671
  episode_reward_max: 269.5050505050499
  episode_reward_mean: 219.35775476281788
  episode_reward_min: 80.86868686868688
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: b35c6d5ee75a4d3c9572e42579560903
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0927320222059886
        entropy_coeff: 0.0001
        kl: 0.007997790079874298
        model: {}
        policy_loss: -0.012647588194037477
        total_loss: 27.162280400594074
        vf_explained_var: 0.9551887512207031
        vf_loss: 27.17423677444458
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.031428571428574
    gpu_util_percent0: 0.33885714285714286
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7714285714285722
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33831
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15717953783388738
    mean_env_wait_ms: 1.1676550561038936
    mean_inference_ms: 4.9399948571618975
    mean_raw_obs_processing_ms: 0.4161317173816791
  time_since_restore: 149.71420884132385
  time_this_iter_s: 29.536237239837646
  time_total_s: 149.71420884132385
  timers:
    learn_throughput: 7228.516
    learn_time_ms: 22382.463
    sample_throughput: 21635.522
    sample_time_ms: 7478.072
    update_time_ms: 33.301
  timestamp: 1602454047
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: c8c0d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c8c0d_00000 | RUNNING  | 172.17.0.4:33831 |      5 |          149.714 | 808960 |  219.358 |              269.505 |              80.8687 |            877.386 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c8c0d_00000:
  custom_metrics:
    time_step_max: 4522
    time_step_mean: 3587.578154425612
    time_step_min: 3261
  date: 2020-10-11_22-07-56
  done: false
  episode_len_mean: 870.7412844036697
  episode_reward_max: 275.41414141414145
  episode_reward_mean: 222.6144472245388
  episode_reward_min: 80.86868686868688
  episodes_this_iter: 300
  episodes_total: 1090
  experiment_id: b35c6d5ee75a4d3c9572e42579560903
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.080180694659551
        entropy_coeff: 0.0001
        kl: 0.008575074064234892
        model: {}
        policy_loss: -0.012925466289743781
        total_loss: 28.642674605051678
        vf_explained_var: 0.9654786586761475
        vf_loss: 28.654850482940674
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.720588235294116
    gpu_util_percent0: 0.36323529411764705
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7735294117647062
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33831
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15544867348491603
    mean_env_wait_ms: 1.1705238480934954
    mean_inference_ms: 4.837401317415994
    mean_raw_obs_processing_ms: 0.41065823671374013
  time_since_restore: 179.06362080574036
  time_this_iter_s: 29.349411964416504
  time_total_s: 179.06362080574036
  timers:
    learn_throughput: 7228.772
    learn_time_ms: 22381.67
    sample_throughput: 21919.193
    sample_time_ms: 7381.294
    update_time_ms: 31.288
  timestamp: 1602454076
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: c8c0d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c8c0d_00000 | RUNNING  | 172.17.0.4:33831 |      6 |          179.064 | 970752 |  222.614 |              275.414 |              80.8687 |            870.741 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c8c0d_00000:
  custom_metrics:
    time_step_max: 4522
    time_step_mean: 3576.089805825243
    time_step_min: 3261
  date: 2020-10-11_22-08-26
  done: false
  episode_len_mean: 866.814082278481
  episode_reward_max: 275.41414141414145
  episode_reward_mean: 224.14364371563724
  episode_reward_min: 80.86868686868688
  episodes_this_iter: 174
  episodes_total: 1264
  experiment_id: b35c6d5ee75a4d3c9572e42579560903
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0738942821820576
        entropy_coeff: 0.0001
        kl: 0.007970173804399868
        model: {}
        policy_loss: -0.012571407307405025
        total_loss: 18.30706278483073
        vf_explained_var: 0.9684243202209473
        vf_loss: 18.318944931030273
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.444117647058828
    gpu_util_percent0: 0.35441176470588237
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.785294117647059
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33831
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1546806207165575
    mean_env_wait_ms: 1.1717799385294299
    mean_inference_ms: 4.793550978418919
    mean_raw_obs_processing_ms: 0.4081919402785905
  time_since_restore: 208.3722529411316
  time_this_iter_s: 29.308632135391235
  time_total_s: 208.3722529411316
  timers:
    learn_throughput: 7234.972
    learn_time_ms: 22362.493
    sample_throughput: 22084.518
    sample_time_ms: 7326.037
    update_time_ms: 29.598
  timestamp: 1602454106
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: c8c0d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c8c0d_00000 | RUNNING  | 172.17.0.4:33831 |      7 |          208.372 | 1132544 |  224.144 |              275.414 |              80.8687 |            866.814 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c8c0d_00000:
  custom_metrics:
    time_step_max: 4522
    time_step_mean: 3566.503586800574
    time_step_min: 3250
  date: 2020-10-11_22-08-55
  done: false
  episode_len_mean: 863.3150492264416
  episode_reward_max: 275.41414141414145
  episode_reward_mean: 225.59314665643765
  episode_reward_min: 80.86868686868688
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: b35c6d5ee75a4d3c9572e42579560903
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0539574424425762
        entropy_coeff: 0.0001
        kl: 0.008322946106394133
        model: {}
        policy_loss: -0.013784848541642228
        total_loss: 16.247241258621216
        vf_explained_var: 0.9710695147514343
        vf_loss: 16.260299285252888
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.95714285714286
    gpu_util_percent0: 0.4362857142857142
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7771428571428576
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33831
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15410570950446295
    mean_env_wait_ms: 1.1729278852302842
    mean_inference_ms: 4.759576045174256
    mean_raw_obs_processing_ms: 0.40629141560428594
  time_since_restore: 237.75887799263
  time_this_iter_s: 29.386625051498413
  time_total_s: 237.75887799263
  timers:
    learn_throughput: 7233.435
    learn_time_ms: 22367.244
    sample_throughput: 22249.891
    sample_time_ms: 7271.586
    update_time_ms: 31.149
  timestamp: 1602454135
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: c8c0d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c8c0d_00000 | RUNNING  | 172.17.0.4:33831 |      8 |          237.759 | 1294336 |  225.593 |              275.414 |              80.8687 |            863.315 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c8c0d_00000:
  custom_metrics:
    time_step_max: 4522
    time_step_mean: 3557.6771907216494
    time_step_min: 3185
  date: 2020-10-11_22-09-25
  done: false
  episode_len_mean: 859.9841772151899
  episode_reward_max: 283.89898989898984
  episode_reward_mean: 226.9330328602479
  episode_reward_min: 80.86868686868688
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: b35c6d5ee75a4d3c9572e42579560903
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.027761032183965
        entropy_coeff: 0.0001
        kl: 0.007686047426735361
        model: {}
        policy_loss: -0.015301749265442291
        total_loss: 15.311313072840372
        vf_explained_var: 0.9706330299377441
        vf_loss: 15.32594887415568
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.85142857142857
    gpu_util_percent0: 0.3742857142857143
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7771428571428576
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33831
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15360308289777652
    mean_env_wait_ms: 1.173987651873764
    mean_inference_ms: 4.72963012680843
    mean_raw_obs_processing_ms: 0.40455992985027833
  time_since_restore: 267.3826837539673
  time_this_iter_s: 29.62380576133728
  time_total_s: 267.3826837539673
  timers:
    learn_throughput: 7228.864
    learn_time_ms: 22381.386
    sample_throughput: 22332.359
    sample_time_ms: 7244.734
    update_time_ms: 33.105
  timestamp: 1602454165
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: c8c0d_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c8c0d_00000 | RUNNING  | 172.17.0.4:33831 |      9 |          267.383 | 1456128 |  226.933 |              283.899 |              80.8687 |            859.984 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c8c0d_00000:
  custom_metrics:
    time_step_max: 4522
    time_step_mean: 3540.6910523353968
    time_step_min: 3185
  date: 2020-10-11_22-09-54
  done: false
  episode_len_mean: 855.2493074792244
  episode_reward_max: 283.89898989898984
  episode_reward_mean: 229.43252469291235
  episode_reward_min: 80.86868686868688
  episodes_this_iter: 225
  episodes_total: 1805
  experiment_id: b35c6d5ee75a4d3c9572e42579560903
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9827874700228373
        entropy_coeff: 0.0001
        kl: 0.007619641721248627
        model: {}
        policy_loss: -0.01453872595448047
        total_loss: 18.606468041737873
        vf_explained_var: 0.9740291237831116
        vf_loss: 18.62034336725871
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.299999999999997
    gpu_util_percent0: 0.3091176470588235
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.770588235294117
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33831
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15301746936330785
    mean_env_wait_ms: 1.1758462404464551
    mean_inference_ms: 4.693195468781013
    mean_raw_obs_processing_ms: 0.40249695945411285
  time_since_restore: 296.6694552898407
  time_this_iter_s: 29.286771535873413
  time_total_s: 296.6694552898407
  timers:
    learn_throughput: 7226.592
    learn_time_ms: 22388.422
    sample_throughput: 22481.472
    sample_time_ms: 7196.682
    update_time_ms: 31.656
  timestamp: 1602454194
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: c8c0d_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c8c0d_00000 | RUNNING  | 172.17.0.4:33831 |     10 |          296.669 | 1617920 |  229.433 |              283.899 |              80.8687 |            855.249 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c8c0d_00000:
  custom_metrics:
    time_step_max: 4522
    time_step_mean: 3524.64461994077
    time_step_min: 3183
  date: 2020-10-11_22-10-24
  done: false
  episode_len_mean: 850.7609542356378
  episode_reward_max: 283.89898989898984
  episode_reward_mean: 231.41580852340334
  episode_reward_min: 80.86868686868688
  episodes_this_iter: 249
  episodes_total: 2054
  experiment_id: b35c6d5ee75a4d3c9572e42579560903
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9761624534924825
        entropy_coeff: 0.0001
        kl: 0.007394542490753035
        model: {}
        policy_loss: -0.013663030564202927
        total_loss: 16.230537335077923
        vf_explained_var: 0.9739797115325928
        vf_loss: 16.243558168411255
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.694285714285712
    gpu_util_percent0: 0.30228571428571427
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7685714285714287
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33831
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15242918721591844
    mean_env_wait_ms: 1.1774133532385902
    mean_inference_ms: 4.659315328690162
    mean_raw_obs_processing_ms: 0.4005192455798488
  time_since_restore: 326.41850996017456
  time_this_iter_s: 29.749054670333862
  time_total_s: 326.41850996017456
  timers:
    learn_throughput: 7213.733
    learn_time_ms: 22428.332
    sample_throughput: 23064.272
    sample_time_ms: 7014.832
    update_time_ms: 33.057
  timestamp: 1602454224
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: c8c0d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c8c0d_00000 | RUNNING  | 172.17.0.4:33831 |     11 |          326.419 | 1779712 |  231.416 |              283.899 |              80.8687 |            850.761 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c8c0d_00000:
  custom_metrics:
    time_step_max: 4522
    time_step_mean: 3516.8539377289376
    time_step_min: 3183
  date: 2020-10-11_22-10-54
  done: false
  episode_len_mean: 848.2884267631104
  episode_reward_max: 283.89898989898984
  episode_reward_mean: 232.45507516393582
  episode_reward_min: 80.86868686868688
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: b35c6d5ee75a4d3c9572e42579560903
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9594109505414963
        entropy_coeff: 0.0001
        kl: 0.007153257029131055
        model: {}
        policy_loss: -0.01684795777691761
        total_loss: 13.36912433306376
        vf_explained_var: 0.9753032326698303
        vf_loss: 13.385352691014608
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.632352941176475
    gpu_util_percent0: 0.4047058823529412
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7823529411764705
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33831
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1521224433852395
    mean_env_wait_ms: 1.1784244468804077
    mean_inference_ms: 4.64074258171687
    mean_raw_obs_processing_ms: 0.39943788067706903
  time_since_restore: 355.6771559715271
  time_this_iter_s: 29.25864601135254
  time_total_s: 355.6771559715271
  timers:
    learn_throughput: 7217.077
    learn_time_ms: 22417.939
    sample_throughput: 23336.931
    sample_time_ms: 6932.874
    update_time_ms: 30.799
  timestamp: 1602454254
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: c8c0d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c8c0d_00000 | RUNNING  | 172.17.0.4:33831 |     12 |          355.677 | 1941504 |  232.455 |              283.899 |              80.8687 |            848.288 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c8c0d_00000:
  custom_metrics:
    time_step_max: 4522
    time_step_mean: 3508.874466268147
    time_step_min: 3183
  date: 2020-10-11_22-11-23
  done: false
  episode_len_mean: 845.8565400843881
  episode_reward_max: 283.89898989898984
  episode_reward_mean: 233.7132080296636
  episode_reward_min: 80.86868686868688
  episodes_this_iter: 158
  episodes_total: 2370
  experiment_id: b35c6d5ee75a4d3c9572e42579560903
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9389941543340683
        entropy_coeff: 0.0001
        kl: 0.008192686946131289
        model: {}
        policy_loss: -0.016213593364227563
        total_loss: 13.86211665471395
        vf_explained_var: 0.9729334712028503
        vf_loss: 13.877604961395264
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.238235294117647
    gpu_util_percent0: 0.39705882352941174
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7794117647058822
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33831
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15184206409371817
    mean_env_wait_ms: 1.179370960880637
    mean_inference_ms: 4.623741312558495
    mean_raw_obs_processing_ms: 0.3984145362999832
  time_since_restore: 384.6740701198578
  time_this_iter_s: 28.99691414833069
  time_total_s: 384.6740701198578
  timers:
    learn_throughput: 7225.375
    learn_time_ms: 22392.193
    sample_throughput: 23464.574
    sample_time_ms: 6895.16
    update_time_ms: 37.069
  timestamp: 1602454283
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: c8c0d_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c8c0d_00000 | RUNNING  | 172.17.0.4:33831 |     13 |          384.674 | 2103296 |  233.713 |              283.899 |              80.8687 |            845.857 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c8c0d_00000:
  custom_metrics:
    time_step_max: 4522
    time_step_mean: 3496.5633154259403
    time_step_min: 3170
  date: 2020-10-11_22-11-52
  done: false
  episode_len_mean: 842.1879271070615
  episode_reward_max: 285.7171717171715
  episode_reward_mean: 235.55225374473653
  episode_reward_min: 80.86868686868688
  episodes_this_iter: 264
  episodes_total: 2634
  experiment_id: b35c6d5ee75a4d3c9572e42579560903
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9021535366773605
        entropy_coeff: 0.0001
        kl: 0.007475868216715753
        model: {}
        policy_loss: -0.014935279090423137
        total_loss: 17.207210222880047
        vf_explained_var: 0.9770586490631104
        vf_loss: 17.221487681070965
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.938235294117646
    gpu_util_percent0: 0.3305882352941176
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7676470588235293
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33831
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15143974715252262
    mean_env_wait_ms: 1.1810547558113547
    mean_inference_ms: 4.598771045790807
    mean_raw_obs_processing_ms: 0.3969447679401016
  time_since_restore: 413.990079164505
  time_this_iter_s: 29.316009044647217
  time_total_s: 413.990079164505
  timers:
    learn_throughput: 7221.465
    learn_time_ms: 22404.317
    sample_throughput: 23521.023
    sample_time_ms: 6878.612
    update_time_ms: 37.195
  timestamp: 1602454312
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: c8c0d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c8c0d_00000 | RUNNING  | 172.17.0.4:33831 |     14 |           413.99 | 2265088 |  235.552 |              285.717 |              80.8687 |            842.188 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c8c0d_00000:
  custom_metrics:
    time_step_max: 4522
    time_step_mean: 3488.631747159091
    time_step_min: 3170
  date: 2020-10-11_22-12-21
  done: false
  episode_len_mean: 839.4440928270042
  episode_reward_max: 285.7171717171715
  episode_reward_mean: 236.82625836423296
  episode_reward_min: 80.86868686868688
  episodes_this_iter: 210
  episodes_total: 2844
  experiment_id: b35c6d5ee75a4d3c9572e42579560903
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8882889697949091
        entropy_coeff: 0.0001
        kl: 0.0071082609162355466
        model: {}
        policy_loss: -0.012677921447902918
        total_loss: 11.254780530929565
        vf_explained_var: 0.9805288314819336
        vf_loss: 11.266835927963257
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.54705882352941
    gpu_util_percent0: 0.39323529411764707
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7794117647058822
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33831
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15114612187695534
    mean_env_wait_ms: 1.1821059540125793
    mean_inference_ms: 4.581195518445403
    mean_raw_obs_processing_ms: 0.39588127817797825
  time_since_restore: 443.0969681739807
  time_this_iter_s: 29.106889009475708
  time_total_s: 443.0969681739807
  timers:
    learn_throughput: 7225.889
    learn_time_ms: 22390.602
    sample_throughput: 23619.036
    sample_time_ms: 6850.068
    update_time_ms: 35.337
  timestamp: 1602454341
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: c8c0d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c8c0d_00000 | RUNNING  | 172.17.0.4:33831 |     15 |          443.097 | 2426880 |  236.826 |              285.717 |              80.8687 |            839.444 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c8c0d_00000:
  custom_metrics:
    time_step_max: 4522
    time_step_mean: 3482.8873570948217
    time_step_min: 3170
  date: 2020-10-11_22-12-51
  done: false
  episode_len_mean: 837.4447035309794
  episode_reward_max: 285.7171717171715
  episode_reward_mean: 237.69201676996474
  episode_reward_min: 80.86868686868688
  episodes_this_iter: 158
  episodes_total: 3002
  experiment_id: b35c6d5ee75a4d3c9572e42579560903
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8826610545317332
        entropy_coeff: 0.0001
        kl: 0.006892223881247143
        model: {}
        policy_loss: -0.015726669148231547
        total_loss: 10.717865069707235
        vf_explained_var: 0.9785811305046082
        vf_loss: 10.732990980148315
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.56470588235294
    gpu_util_percent0: 0.4185294117647058
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.785294117647059
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33831
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15095116820124466
    mean_env_wait_ms: 1.1829167378368763
    mean_inference_ms: 4.569257949275166
    mean_raw_obs_processing_ms: 0.39515718546077067
  time_since_restore: 472.58812737464905
  time_this_iter_s: 29.491159200668335
  time_total_s: 472.58812737464905
  timers:
    learn_throughput: 7221.498
    learn_time_ms: 22404.217
    sample_throughput: 23622.205
    sample_time_ms: 6849.149
    update_time_ms: 36.635
  timestamp: 1602454371
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: c8c0d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c8c0d_00000 | RUNNING  | 172.17.0.4:33831 |     16 |          472.588 | 2588672 |  237.692 |              285.717 |              80.8687 |            837.445 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c8c0d_00000:
  custom_metrics:
    time_step_max: 4522
    time_step_mean: 3478.5744274809163
    time_step_min: 3170
  date: 2020-10-11_22-13-20
  done: false
  episode_len_mean: 835.4432534678436
  episode_reward_max: 285.7171717171715
  episode_reward_mean: 238.41057803762715
  episode_reward_min: 80.86868686868688
  episodes_this_iter: 170
  episodes_total: 3172
  experiment_id: b35c6d5ee75a4d3c9572e42579560903
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8574890792369843
        entropy_coeff: 0.0001
        kl: 0.007288574629152815
        model: {}
        policy_loss: -0.013488512253388762
        total_loss: 13.795198122660318
        vf_explained_var: 0.9763004183769226
        vf_loss: 13.808043479919434
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.774285714285718
    gpu_util_percent0: 0.35771428571428576
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7800000000000002
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33831
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15075421582792697
    mean_env_wait_ms: 1.183795584489048
    mean_inference_ms: 4.557221842561182
    mean_raw_obs_processing_ms: 0.3944132114608052
  time_since_restore: 501.9921782016754
  time_this_iter_s: 29.404050827026367
  time_total_s: 501.9921782016754
  timers:
    learn_throughput: 7213.7
    learn_time_ms: 22428.434
    sample_throughput: 23683.244
    sample_time_ms: 6831.497
    update_time_ms: 38.487
  timestamp: 1602454400
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: c8c0d_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c8c0d_00000 | RUNNING  | 172.17.0.4:33831 |     17 |          501.992 | 2750464 |  238.411 |              285.717 |              80.8687 |            835.443 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c8c0d_00000:
  custom_metrics:
    time_step_max: 4522
    time_step_mean: 3471.3938336242
    time_step_min: 3170
  date: 2020-10-11_22-13-50
  done: false
  episode_len_mean: 832.8139065204847
  episode_reward_max: 286.62626262626253
  episode_reward_mean: 239.643363817051
  episode_reward_min: 80.86868686868688
  episodes_this_iter: 294
  episodes_total: 3466
  experiment_id: b35c6d5ee75a4d3c9572e42579560903
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8298000395298004
        entropy_coeff: 0.0001
        kl: 0.0071812961250543594
        model: {}
        policy_loss: -0.012893385905044852
        total_loss: 15.218006372451782
        vf_explained_var: 0.9796459674835205
        vf_loss: 15.230264663696289
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.052941176470586
    gpu_util_percent0: 0.4105882352941177
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7735294117647062
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33831
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15045401609998216
    mean_env_wait_ms: 1.185196134707307
    mean_inference_ms: 4.538920807624855
    mean_raw_obs_processing_ms: 0.39329614928922246
  time_since_restore: 531.1222357749939
  time_this_iter_s: 29.13005757331848
  time_total_s: 531.1222357749939
  timers:
    learn_throughput: 7218.315
    learn_time_ms: 22414.095
    sample_throughput: 23717.061
    sample_time_ms: 6821.756
    update_time_ms: 36.261
  timestamp: 1602454430
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: c8c0d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c8c0d_00000 | RUNNING  | 172.17.0.4:33831 |     18 |          531.122 | 2912256 |  239.643 |              286.626 |              80.8687 |            832.814 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c8c0d_00000:
  custom_metrics:
    time_step_max: 4522
    time_step_mean: 3466.8394342762062
    time_step_min: 3170
  date: 2020-10-11_22-14-19
  done: false
  episode_len_mean: 831.5082553659879
  episode_reward_max: 293.8989898989897
  episode_reward_mean: 240.33321381119944
  episode_reward_min: 80.86868686868688
  episodes_this_iter: 168
  episodes_total: 3634
  experiment_id: b35c6d5ee75a4d3c9572e42579560903
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8227459987004598
        entropy_coeff: 0.0001
        kl: 0.006117262567083041
        model: {}
        policy_loss: -0.014611590168594072
        total_loss: 9.03051527341207
        vf_explained_var: 0.9830945134162903
        vf_loss: 9.044597387313843
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.99705882352941
    gpu_util_percent0: 0.40470588235294125
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7911764705882356
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33831
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15029680398966608
    mean_env_wait_ms: 1.185902842289134
    mean_inference_ms: 4.52932034339256
    mean_raw_obs_processing_ms: 0.39271402008182266
  time_since_restore: 560.2396283149719
  time_this_iter_s: 29.117392539978027
  time_total_s: 560.2396283149719
  timers:
    learn_throughput: 7225.775
    learn_time_ms: 22390.953
    sample_throughput: 23810.089
    sample_time_ms: 6795.103
    update_time_ms: 34.626
  timestamp: 1602454459
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: c8c0d_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c8c0d_00000 | RUNNING  | 172.17.0.4:33831 |     19 |           560.24 | 3074048 |  240.333 |              293.899 |              80.8687 |            831.508 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c8c0d_00000:
  custom_metrics:
    time_step_max: 4522
    time_step_mean: 3462.8684909670565
    time_step_min: 3170
  date: 2020-10-11_22-14-49
  done: false
  episode_len_mean: 830.1321202531645
  episode_reward_max: 293.8989898989897
  episode_reward_mean: 240.97816775348414
  episode_reward_min: 80.86868686868688
  episodes_this_iter: 158
  episodes_total: 3792
  experiment_id: b35c6d5ee75a4d3c9572e42579560903
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8213989535967509
        entropy_coeff: 0.0001
        kl: 0.007206167055604358
        model: {}
        policy_loss: -0.01460233423858881
        total_loss: 9.455604235331217
        vf_explained_var: 0.9809656143188477
        vf_loss: 9.469567934672037
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.00588235294118
    gpu_util_percent0: 0.37117647058823533
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7941176470588234
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33831
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1501599205108148
    mean_env_wait_ms: 1.1865651388761345
    mean_inference_ms: 4.520922255014712
    mean_raw_obs_processing_ms: 0.3921906178403831
  time_since_restore: 589.7007462978363
  time_this_iter_s: 29.46111798286438
  time_total_s: 589.7007462978363
  timers:
    learn_throughput: 7221.302
    learn_time_ms: 22404.825
    sample_throughput: 23804.796
    sample_time_ms: 6796.614
    update_time_ms: 35.548
  timestamp: 1602454489
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: c8c0d_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c8c0d_00000 | RUNNING  | 172.17.0.4:33831 |     20 |          589.701 | 3235840 |  240.978 |              293.899 |              80.8687 |            830.132 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c8c0d_00000:
  custom_metrics:
    time_step_max: 4522
    time_step_mean: 3457.8680050188204
    time_step_min: 3170
  date: 2020-10-11_22-15-18
  done: true
  episode_len_mean: 828.4983802641416
  episode_reward_max: 293.8989898989897
  episode_reward_mean: 241.80209269369493
  episode_reward_min: 80.86868686868688
  episodes_this_iter: 221
  episodes_total: 4013
  experiment_id: b35c6d5ee75a4d3c9572e42579560903
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7923551996548971
        entropy_coeff: 0.0001
        kl: 0.0064417937537655234
        model: {}
        policy_loss: -0.01274624653160572
        total_loss: 11.403072595596313
        vf_explained_var: 0.9824736714363098
        vf_loss: 11.41525403658549
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.094117647058823
    gpu_util_percent0: 0.32852941176470585
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7676470588235293
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 33831
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14998742619187774
    mean_env_wait_ms: 1.1875390410112583
    mean_inference_ms: 4.510077361527858
    mean_raw_obs_processing_ms: 0.39152274663176334
  time_since_restore: 618.8667004108429
  time_this_iter_s: 29.165954113006592
  time_total_s: 618.8667004108429
  timers:
    learn_throughput: 7241.575
    learn_time_ms: 22342.102
    sample_throughput: 23789.337
    sample_time_ms: 6801.03
    update_time_ms: 35.6
  timestamp: 1602454518
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: c8c0d_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c8c0d_00000 | TERMINATED |       |     21 |          618.867 | 3397632 |  241.802 |              293.899 |              80.8687 |            828.498 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c8c0d_00000 | TERMINATED |       |     21 |          618.867 | 3397632 |  241.802 |              293.899 |              80.8687 |            828.498 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


